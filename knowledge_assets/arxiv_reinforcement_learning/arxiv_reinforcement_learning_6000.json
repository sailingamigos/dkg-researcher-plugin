[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00975v2",
            "title": "Autonomous Learning of Generative Models with Chemical Reaction Network\n  Ensembles",
            "updated": "2023-11-06T19:07:59Z",
            "published": "2023-11-02T03:46:23Z",
            "summary": "Can a micron sized sack of interacting molecules autonomously learn an\ninternal model of a complex and fluctuating environment? We draw insights from\ncontrol theory, machine learning theory, chemical reaction network theory, and\nstatistical physics to develop a general architecture whereby a broad class of\nchemical systems can autonomously learn complex distributions. Our construction\ntakes the form of a chemical implementation of machine learning's optimization\nworkhorse: gradient descent on the relative entropy cost function. We show how\nthis method can be applied to optimize any detailed balanced chemical reaction\nnetwork and that the construction is capable of using hidden units to learn\ncomplex distributions. This result is then recast as a form of integral\nfeedback control. Finally, due to our use of an explicit physical model of\nlearning, we are able to derive thermodynamic costs and trade-offs associated\nto this process.",
            "author": [
                "William Poole",
                "Thomas E. Ouldridge",
                "Manoj Gopalkrishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00975v2",
                "http://arxiv.org/pdf/2311.00975v2"
            ],
            "primary_category": "q-bio.MN",
            "category": [
                "q-bio.MN",
                "cs.ET",
                "cs.LG",
                "cs.NE",
                "cs.SY",
                "eess.SY",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00973v1",
            "title": "Federated Linear Bandits with Finite Adversarial Actions",
            "updated": "2023-11-02T03:41:58Z",
            "published": "2023-11-02T03:41:58Z",
            "summary": "We study a federated linear bandits model, where $M$ clients communicate with\na central server to solve a linear contextual bandits problem with finite\nadversarial action sets that may be different across clients. To address the\nunique challenges of adversarial finite action sets, we propose the\nFedSupLinUCB algorithm, which extends the principles of SupLinUCB and OFUL\nalgorithms in linear contextual bandits. We prove that FedSupLinUCB achieves a\ntotal regret of $\\tilde{O}(\\sqrt{d T})$, where $T$ is the total number of arm\npulls from all clients, and $d$ is the ambient dimension of the linear model.\nThis matches the minimax lower bound and thus is order-optimal (up to polylog\nterms). We study both asynchronous and synchronous cases and show that the\ncommunication cost can be controlled as $O(d M^2 \\log(d)\\log(T))$ and\n$O(\\sqrt{d^3 M^3} \\log(d))$, respectively. The FedSupLinUCB design is further\nextended to two scenarios: (1) variance-adaptive, where a total regret of\n$\\tilde{O} (\\sqrt{d \\sum \\nolimits_{t=1}^{T} \\sigma_t^2})$ can be achieved with\n$\\sigma_t^2$ being the noise variance of round $t$; and (2) adversarial\ncorruption, where a total regret of $\\tilde{O}(\\sqrt{dT} + d C_p)$ can be\nachieved with $C_p$ being the total corruption budget. Experiment results\ncorroborate the theoretical analysis and demonstrate the effectiveness of\nFedSupLinUCB on both synthetic and real-world datasets.",
            "author": [
                "Li Fan",
                "Ruida Zhou",
                "Chao Tian",
                "Cong Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00973v1",
                "http://arxiv.org/pdf/2311.00973v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00971v1",
            "title": "An Integrated Framework Integrating Monte Carlo Tree Search and\n  Supervised Learning for Train Timetabling Problem",
            "updated": "2023-11-02T03:39:14Z",
            "published": "2023-11-02T03:39:14Z",
            "summary": "The single-track railway train timetabling problem (TTP) is an important and\ncomplex problem. This article proposes an integrated Monte Carlo Tree Search\n(MCTS) computing framework that combines heuristic methods, unsupervised\nlearning methods, and supervised learning methods for solving TTP in discrete\naction spaces. This article first describes the mathematical model and\nsimulation system dynamics of TTP, analyzes the characteristics of the solution\nfrom the perspective of MCTS, and proposes some heuristic methods to improve\nMCTS. This article considers these methods as planners in the proposed\nframework. Secondly, this article utilizes deep convolutional neural networks\nto approximate the value of nodes and further applies them to the MCTS search\nprocess, referred to as learners. The experiment shows that the proposed\nheuristic MCTS method is beneficial for solving TTP; The algorithm framework\nthat integrates planners and learners can improve the data efficiency of\nsolving TTP; The proposed method provides a new paradigm for solving TTP.",
            "author": [
                "Feiyu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00971v1",
                "http://arxiv.org/pdf/2311.00971v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00970v1",
            "title": "Lightweight super resolution network for point cloud geometry\n  compression",
            "updated": "2023-11-02T03:34:51Z",
            "published": "2023-11-02T03:34:51Z",
            "summary": "This paper presents an approach for compressing point cloud geometry by\nleveraging a lightweight super-resolution network. The proposed method involves\ndecomposing a point cloud into a base point cloud and the interpolation\npatterns for reconstructing the original point cloud. While the base point\ncloud can be efficiently compressed using any lossless codec, such as\nGeometry-based Point Cloud Compression, a distinct strategy is employed for\nhandling the interpolation patterns. Rather than directly compressing the\ninterpolation patterns, a lightweight super-resolution network is utilized to\nlearn this information through overfitting. Subsequently, the network parameter\nis transmitted to assist in point cloud reconstruction at the decoder side.\nNotably, our approach differentiates itself from lookup table-based methods,\nallowing us to obtain more accurate interpolation patterns by accessing a\nbroader range of neighboring voxels at an acceptable computational cost.\nExperiments on MPEG Cat1 (Solid) and Cat2 datasets demonstrate the remarkable\ncompression performance achieved by our method.",
            "author": [
                "Wei Zhang",
                "Dingquan Li",
                "Ge Li",
                "Wen Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00970v1",
                "http://arxiv.org/pdf/2311.00970v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02104v1",
            "title": "Efficient Symbolic Policy Learning with Differentiable Symbolic\n  Expression",
            "updated": "2023-11-02T03:27:51Z",
            "published": "2023-11-02T03:27:51Z",
            "summary": "Deep reinforcement learning (DRL) has led to a wide range of advances in\nsequential decision-making tasks. However, the complexity of neural network\npolicies makes it difficult to understand and deploy with limited computational\nresources. Currently, employing compact symbolic expressions as symbolic\npolicies is a promising strategy to obtain simple and interpretable policies.\nPrevious symbolic policy methods usually involve complex training processes and\npre-trained neural network policies, which are inefficient and limit the\napplication of symbolic policies. In this paper, we propose an efficient\ngradient-based learning method named Efficient Symbolic Policy Learning (ESPL)\nthat learns the symbolic policy from scratch in an end-to-end way. We introduce\na symbolic network as the search space and employ a path selector to find the\ncompact symbolic policy. By doing so we represent the policy with a\ndifferentiable symbolic expression and train it in an off-policy manner which\nfurther improves the efficiency. In addition, in contrast with previous\nsymbolic policies which only work in single-task RL because of complexity, we\nexpand ESPL on meta-RL to generate symbolic policies for unseen tasks.\nExperimentally, we show that our approach generates symbolic policies with\nhigher performance and greatly improves data efficiency for single-task RL. In\nmeta-RL, we demonstrate that compared with neural network policies the proposed\nsymbolic policy achieves higher performance and efficiency and shows the\npotential to be interpretable.",
            "author": [
                "Jiaming Guo",
                "Rui Zhang",
                "Shaohui Peng",
                "Qi Yi",
                "Xing Hu",
                "Ruizhi Chen",
                "Zidong Du",
                "Xishan Zhang",
                "Ling Li",
                "Qi Guo",
                "Yunji Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02104v1",
                "http://arxiv.org/pdf/2311.02104v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00966v1",
            "title": "Invariant-Feature Subspace Recovery: A New Class of Provable Domain\n  Generalization Algorithms",
            "updated": "2023-11-02T03:24:55Z",
            "published": "2023-11-02T03:24:55Z",
            "summary": "Domain generalization asks for models trained over a set of training\nenvironments to generalize well in unseen test environments. Recently, a series\nof algorithms such as Invariant Risk Minimization (IRM) have been proposed for\ndomain generalization. However, Rosenfeld et al. (2021) shows that in a simple\nlinear data model, even if non-convexity issues are ignored, IRM and its\nextensions cannot generalize to unseen environments with less than $d_s+1$\ntraining environments, where $d_s$ is the dimension of the spurious-feature\nsubspace. In this work, we propose Invariant-feature Subspace Recovery (ISR): a\nnew class of algorithms to achieve provable domain generalization across the\nsettings of classification and regression problems. First, in the binary\nclassification setup of Rosenfeld et al. (2021), we show that our first\nalgorithm, ISR-Mean, can identify the subspace spanned by invariant features\nfrom the first-order moments of the class-conditional distributions, and\nachieve provable domain generalization with $d_s+1$ training environments. Our\nsecond algorithm, ISR-Cov, further reduces the required number of training\nenvironments to $O(1)$ using the information of second-order moments. Notably,\nunlike IRM, our algorithms bypass non-convexity issues and enjoy global\nconvergence guarantees. Next, we extend ISR-Mean to the more general setting of\nmulti-class classification and propose ISR-Multiclass, which leverages class\ninformation and provably recovers the invariant-feature subspace with $\\lceil\nd_s/k\\rceil+1$ training environments for $k$-class classification. Finally, for\nregression problems, we propose ISR-Regression that can identify the\ninvariant-feature subspace with $d_s+1$ training environments. Empirically, we\ndemonstrate the superior performance of our ISRs on synthetic benchmarks.\nFurther, ISR can be used as post-processing methods for feature extractors such\nas neural nets.",
            "author": [
                "Haoxiang Wang",
                "Gargi Balasubramaniam",
                "Haozhe Si",
                "Bo Li",
                "Han Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00966v1",
                "http://arxiv.org/pdf/2311.00966v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00964v1",
            "title": "On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for\n  Fintech Applications",
            "updated": "2023-11-02T03:18:40Z",
            "published": "2023-11-02T03:18:40Z",
            "summary": "Rules are widely used in Fintech institutions to make fraud prevention\ndecisions, since rules are highly interpretable thanks to their intuitive\nif-then structure. In practice, a two-stage framework of fraud prevention\ndecision rule set mining is usually employed in large Fintech institutions.\nThis paper is concerned with finding high-quality rule subsets in a\nbi-objective space (such as precision and recall) from an initial pool of\nrules. To this end, we adopt the concept of Pareto optimality and aim to find a\nset of non-dominated rule subsets, which constitutes a Pareto front. We propose\na heuristic-based framework called PORS and we identify that the core of PORS\nis the problem of solution selection on the front (SSF). We provide a\nsystematic categorization of the SSF problem and a thorough empirical\nevaluation of various SSF methods on both public and proprietary datasets. We\nalso introduce a novel variant of sequential covering algorithm called\nSpectralRules to encourage the diversity of the initial rule set and we\nempirically find that SpectralRules further improves the quality of the found\nPareto front. On two real application scenarios within Alipay, we demonstrate\nthe advantages of our proposed methodology compared to existing work.",
            "author": [
                "Chengyao Wen",
                "Yin Lou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00964v1",
                "http://arxiv.org/pdf/2311.00964v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-fin.ST"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00962v1",
            "title": "Detecting Generated Images by Real Images Only",
            "updated": "2023-11-02T03:09:37Z",
            "published": "2023-11-02T03:09:37Z",
            "summary": "As deep learning technology continues to evolve, the images yielded by\ngenerative models are becoming more and more realistic, triggering people to\nquestion the authenticity of images. Existing generated image detection methods\ndetect visual artifacts in generated images or learn discriminative features\nfrom both real and generated images by massive training. This learning paradigm\nwill result in efficiency and generalization issues, making detection methods\nalways lag behind generation methods. This paper approaches the generated image\ndetection problem from a new perspective: Start from real images. By finding\nthe commonality of real images and mapping them to a dense subspace in feature\nspace, the goal is that generated images, regardless of their generative model,\nare then projected outside the subspace. As a result, images from different\ngenerative models can be detected, solving some long-existing problems in the\nfield. Experimental results show that although our method was trained only by\nreal images and uses 99.9\\% less training data than other deep learning-based\nmethods, it can compete with state-of-the-art methods and shows excellent\nperformance in detecting emerging generative models with high inference\nefficiency. Moreover, the proposed method shows robustness against various\npost-processing. These advantages allow the method to be used in real-world\nscenarios.",
            "author": [
                "Xiuli Bi",
                "Bo Liu",
                "Fan Yang",
                "Bin Xiao",
                "Weisheng Li",
                "Gao Huang",
                "Pamela C. Cosman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00962v1",
                "http://arxiv.org/pdf/2311.00962v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00961v1",
            "title": "Concatenated Masked Autoencoders as Spatial-Temporal Learner",
            "updated": "2023-11-02T03:08:26Z",
            "published": "2023-11-02T03:08:26Z",
            "summary": "Learning representations from videos requires understanding continuous motion\nand visual correspondences between frames. In this paper, we introduce the\nConcatenated Masked Autoencoders (CatMAE) as a spatial-temporal learner for\nself-supervised video representation learning. For the input sequence of video\nframes, CatMAE keeps the initial frame unchanged while applying substantial\nmasking (95%) to subsequent frames. The encoder in CatMAE is responsible for\nencoding visible patches for each frame individually; subsequently, for each\nmasked frame, the decoder leverages visible patches from both previous and\ncurrent frames to reconstruct the original image. Our proposed method enables\nthe model to estimate the motion information between visible patches, match the\ncorrespondences between preceding and succeeding frames, and ultimately learn\nthe evolution of scenes. Furthermore, we propose a new data augmentation\nstrategy, Video-Reverse (ViRe), which uses reversed video frames as the model's\nreconstruction targets. This further encourages the model to utilize continuous\nmotion details and correspondences to complete the reconstruction, thereby\nenhancing the model's capabilities. Compared to the most advanced pre-training\nmethods, CatMAE achieves a leading level in video segmentation tasks and action\nrecognition tasks.",
            "author": [
                "Zhouqiang Jiang",
                "Bowen Wang",
                "Tong Xiang",
                "Zhaofeng Niu",
                "Hong Tang",
                "Guangshun Li",
                "Liangzhi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00961v1",
                "http://arxiv.org/pdf/2311.00961v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00960v1",
            "title": "Trajectory Similarity Measurement: An Efficiency Perspective",
            "updated": "2023-11-02T03:07:26Z",
            "published": "2023-11-02T03:07:26Z",
            "summary": "Trajectories that capture object movement have numerous applications, in\nwhich similarity computation between trajectories often plays a key role.\nTraditionally, the similarity between two trajectories is quantified by means\nof heuristic measures, e.g., Hausdorff or ERP, that operate directly on the\ntrajectories. In contrast, recent studies exploit deep learning to map\ntrajectories to d-dimensional vectors, called embeddings. Then, some distance\nmeasure, e.g., Manhattan or Euclidean, is applied to the embeddings to quantify\ntrajectory similarity. The resulting similarities are inaccurate: they only\napproximate the similarities obtained using the heuristic measures. As distance\ncomputation on embeddings is efficient, focus has been on achieving embeddings\nyielding high accuracy.\n  Adopting an efficiency perspective, we analyze the time complexities of both\nthe heuristic and the learning-based approaches, finding that the time\ncomplexities of the former approaches are not necessarily higher. Through\nextensive experiments on open datasets, we find that, on both CPUs and GPUs,\nonly a few learning-based approaches can deliver the promised higher\nefficiency, when the embeddings can be pre-computed, while heuristic approaches\nare more efficient for one-off computations. Among the learning-based\napproaches, the self-attention-based ones are the fastest to learn embeddings\nthat also yield the highest accuracy for similarity queries. These results have\nimplications for the use of trajectory similarity approaches given different\napplication requirements.",
            "author": [
                "Yanchuan Chang",
                "Egemen Tanin",
                "Gao Cong",
                "Christian S. Jensen",
                "Jianzhong Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00960v1",
                "http://arxiv.org/pdf/2311.00960v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00959v1",
            "title": "Dynamic Fair Federated Learning Based on Reinforcement Learning",
            "updated": "2023-11-02T03:05:40Z",
            "published": "2023-11-02T03:05:40Z",
            "summary": "Federated learning enables a collaborative training and optimization of\nglobal models among a group of devices without sharing local data samples.\nHowever, the heterogeneity of data in federated learning can lead to unfair\nrepresentation of the global model across different devices. To address the\nfairness issue in federated learning, we propose a dynamic q fairness federated\nlearning algorithm with reinforcement learning, called DQFFL. DQFFL aims to\nmitigate the discrepancies in device aggregation and enhance the fairness of\ntreatment for all groups involved in federated learning. To quantify fairness,\nDQFFL leverages the performance of the global federated model on each device\nand incorporates {\\alpha}-fairness to transform the preservation of fairness\nduring federated aggregation into the distribution of client weights in the\naggregation process. Considering the sensitivity of parameters in measuring\nfairness, we propose to utilize reinforcement learning for dynamic parameters\nduring aggregation. Experimental results demonstrate that our DQFFL outperforms\nthe state-of-the-art methods in terms of overall performance, fairness and\nconvergence speed.",
            "author": [
                "Weikang Chen",
                "Junping Du",
                "Yingxia Shao",
                "Jia Wang",
                "Yangxi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00959v1",
                "http://arxiv.org/pdf/2311.00959v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10749v1",
            "title": "Measuring Five Accountable Talk Moves to Improve Instruction at Scale",
            "updated": "2023-11-02T03:04:50Z",
            "published": "2023-11-02T03:04:50Z",
            "summary": "Providing consistent, individualized feedback to teachers on their\ninstruction can improve student learning outcomes. Such feedback can especially\nbenefit novice instructors who teach on online platforms and have limited\naccess to instructional training. To build scalable measures of instruction, we\nfine-tune RoBERTa and GPT models to identify five instructional talk moves\ninspired by accountable talk theory: adding on, connecting, eliciting, probing\nand revoicing students' ideas. We fine-tune these models on a newly annotated\ndataset of 2500 instructor utterances derived from transcripts of small group\ninstruction in an online computer science course, Code in Place. Although we\nfind that GPT-3 consistently outperforms RoBERTa in terms of precision, its\nrecall varies significantly. We correlate the instructors' use of each talk\nmove with indicators of student engagement and satisfaction, including\nstudents' section attendance, section ratings, and assignment completion rates.\nWe find that using talk moves generally correlates positively with student\noutcomes, and connecting student ideas has the largest positive impact. These\nresults corroborate previous research on the effectiveness of accountable talk\nmoves and provide exciting avenues for using these models to provide\ninstructors with useful, scalable feedback.",
            "author": [
                "Ashlee Kupor",
                "Candice Morgan",
                "Dorottya Demszky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10749v1",
                "http://arxiv.org/pdf/2311.10749v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00958v1",
            "title": "IndoToD: A Multi-Domain Indonesian Benchmark For End-to-End\n  Task-Oriented Dialogue Systems",
            "updated": "2023-11-02T03:01:53Z",
            "published": "2023-11-02T03:01:53Z",
            "summary": "Task-oriented dialogue (ToD) systems have been mostly created for\nhigh-resource languages, such as English and Chinese. However, there is a need\nto develop ToD systems for other regional or local languages to broaden their\nability to comprehend the dialogue contexts in various languages. This paper\nintroduces IndoToD, an end-to-end multi domain ToD benchmark in Indonesian. We\nextend two English ToD datasets to Indonesian, comprising four different\ndomains by delexicalization to efficiently reduce the size of annotations. To\nensure a high-quality data collection, we hire native speakers to manually\ntranslate the dialogues. Along with the original English datasets, these new\nIndonesian datasets serve as an effective benchmark for evaluating Indonesian\nand English ToD systems as well as exploring the potential benefits of\ncross-lingual and bilingual transfer learning approaches.",
            "author": [
                "Muhammad Dehan Al Kautsar",
                "Rahmah Khoirussyifa' Nurdini",
                "Samuel Cahyawijaya",
                "Genta Indra Winata",
                "Ayu Purwarianti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00958v1",
                "http://arxiv.org/pdf/2311.00958v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00953v1",
            "title": "Blending Reward Functions via Few Expert Demonstrations for Faithful and\n  Accurate Knowledge-Grounded Dialogue Generation",
            "updated": "2023-11-02T02:42:41Z",
            "published": "2023-11-02T02:42:41Z",
            "summary": "The development of trustworthy conversational information-seeking systems\nrelies on dialogue models that can generate faithful and accurate responses\nbased on relevant knowledge texts. However, two main challenges hinder this\ntask. Firstly, language models may generate hallucinations due to data biases\npresent in their pretraining corpus. Secondly, knowledge texts often contain\nredundant and irrelevant information that distracts the model's attention from\nthe relevant text span. Previous works use additional data annotations on the\nknowledge texts to learn a knowledge identification module in order to bypass\nirrelevant information, but collecting such high-quality span annotations can\nbe costly. In this work, we leverage reinforcement learning algorithms to\novercome the above challenges by introducing a novel reward function. Our\nreward function combines an accuracy metric and a faithfulness metric to\nprovide a balanced quality judgment of generated responses, which can be used\nas a cost-effective approximation to a human preference reward model when only\na few preference annotations are available. Empirical experiments on two\nconversational information-seeking datasets demonstrate that our method can\ncompete with other strong supervised learning baselines.",
            "author": [
                "Wanyu Du",
                "Yangfeng Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00953v1",
                "http://arxiv.org/pdf/2311.00953v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00945v1",
            "title": "E3 TTS: Easy End-to-End Diffusion-based Text to Speech",
            "updated": "2023-11-02T02:22:21Z",
            "published": "2023-11-02T02:22:21Z",
            "summary": "We propose Easy End-to-End Diffusion-based Text to Speech, a simple and\nefficient end-to-end text-to-speech model based on diffusion. E3 TTS directly\ntakes plain text as input and generates an audio waveform through an iterative\nrefinement process. Unlike many prior work, E3 TTS does not rely on any\nintermediate representations like spectrogram features or alignment\ninformation. Instead, E3 TTS models the temporal structure of the waveform\nthrough the diffusion process. Without relying on additional conditioning\ninformation, E3 TTS could support flexible latent structure within the given\naudio. This enables E3 TTS to be easily adapted for zero-shot tasks such as\nediting without any additional training. Experiments show that E3 TTS can\ngenerate high-fidelity audio, approaching the performance of a state-of-the-art\nneural TTS system. Audio samples are available at https://e3tts.github.io.",
            "author": [
                "Yuan Gao",
                "Nobuyuki Morioka",
                "Yu Zhang",
                "Nanxin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00945v1",
                "http://arxiv.org/pdf/2311.00945v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00944v1",
            "title": "Stochastic Smoothed Gradient Descent Ascent for Federated Minimax\n  Optimization",
            "updated": "2023-11-02T02:09:46Z",
            "published": "2023-11-02T02:09:46Z",
            "summary": "In recent years, federated minimax optimization has attracted growing\ninterest due to its extensive applications in various machine learning tasks.\nWhile Smoothed Alternative Gradient Descent Ascent (Smoothed-AGDA) has proved\nits success in centralized nonconvex minimax optimization, how and whether\nsmoothing technique could be helpful in federated setting remains unexplored.\nIn this paper, we propose a new algorithm termed Federated Stochastic Smoothed\nGradient Descent Ascent (FESS-GDA), which utilizes the smoothing technique for\nfederated minimax optimization. We prove that FESS-GDA can be uniformly used to\nsolve several classes of federated minimax problems and prove new or better\nanalytical convergence results for these settings. We showcase the practical\nefficiency of FESS-GDA in practical federated learning tasks of training\ngenerative adversarial networks (GANs) and fair classification.",
            "author": [
                "Wei Shen",
                "Minhui Huang",
                "Jiawei Zhang",
                "Cong Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00944v1",
                "http://arxiv.org/pdf/2311.00944v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00941v1",
            "title": "Gaussian Mixture Solvers for Diffusion Models",
            "updated": "2023-11-02T02:05:38Z",
            "published": "2023-11-02T02:05:38Z",
            "summary": "Recently, diffusion models have achieved great success in generative tasks.\nSampling from diffusion models is equivalent to solving the reverse diffusion\nstochastic differential equations (SDEs) or the corresponding probability flow\nordinary differential equations (ODEs). In comparison, SDE-based solvers can\ngenerate samples of higher quality and are suited for image translation tasks\nlike stroke-based synthesis. During inference, however, existing SDE-based\nsolvers are severely constrained by the efficiency-effectiveness dilemma. Our\ninvestigation suggests that this is because the Gaussian assumption in the\nreverse transition kernel is frequently violated (even in the case of simple\nmixture data) given a limited number of discretization steps. To overcome this\nlimitation, we introduce a novel class of SDE-based solvers called\n\\emph{Gaussian Mixture Solvers (GMS)} for diffusion models. Our solver\nestimates the first three-order moments and optimizes the parameters of a\nGaussian mixture transition kernel using generalized methods of moments in each\nstep during sampling. Empirically, our solver outperforms numerous SDE-based\nsolvers in terms of sample quality in image generation and stroke-based\nsynthesis in various diffusion models, which validates the motivation and\neffectiveness of GMS. Our code is available at\nhttps://github.com/Guohanzhong/GMS.",
            "author": [
                "Hanzhong Guo",
                "Cheng Lu",
                "Fan Bao",
                "Tianyu Pang",
                "Shuicheng Yan",
                "Chao Du",
                "Chongxuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00941v1",
                "http://arxiv.org/pdf/2311.00941v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00938v1",
            "title": "Bridging the Gap: Addressing Discrepancies in Diffusion Model Training\n  for Classifier-Free Guidance",
            "updated": "2023-11-02T02:03:12Z",
            "published": "2023-11-02T02:03:12Z",
            "summary": "Diffusion models have emerged as a pivotal advancement in generative models,\nsetting new standards to the quality of the generated instances. In the current\npaper we aim to underscore a discrepancy between conventional training methods\nand the desired conditional sampling behavior of these models. While the\nprevalent classifier-free guidance technique works well, it's not without\nflaws. At higher values for the guidance scale parameter $w$, we often get out\nof distribution samples and mode collapse, whereas at lower values for $w$ we\nmay not get the desired specificity. To address these challenges, we introduce\nan updated loss function that better aligns training objectives with sampling\nbehaviors. Experimental validation with FID scores on CIFAR-10 elucidates our\nmethod's ability to produce higher quality samples with fewer sampling\ntimesteps, and be more robust to the choice of guidance scale $w$. We also\nexperiment with fine-tuning Stable Diffusion on the proposed loss, to provide\nearly evidence that large diffusion models may also benefit from this refined\nloss function.",
            "author": [
                "Niket Patel",
                "Luis Salamanca",
                "Luis Barba"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00938v1",
                "http://arxiv.org/pdf/2311.00938v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00936v1",
            "title": "SatBird: Bird Species Distribution Modeling with Remote Sensing and\n  Citizen Science Data",
            "updated": "2023-11-02T02:00:27Z",
            "published": "2023-11-02T02:00:27Z",
            "summary": "Biodiversity is declining at an unprecedented rate, impacting ecosystem\nservices necessary to ensure food, water, and human health and well-being.\nUnderstanding the distribution of species and their habitats is crucial for\nconservation policy planning. However, traditional methods in ecology for\nspecies distribution models (SDMs) generally focus either on narrow sets of\nspecies or narrow geographical areas and there remain significant knowledge\ngaps about the distribution of species. A major reason for this is the limited\navailability of data traditionally used, due to the prohibitive amount of\neffort and expertise required for traditional field monitoring. The wide\navailability of remote sensing data and the growing adoption of citizen science\ntools to collect species observations data at low cost offer an opportunity for\nimproving biodiversity monitoring and enabling the modelling of complex\necosystems. We introduce a novel task for mapping bird species to their\nhabitats by predicting species encounter rates from satellite images, and\npresent SatBird, a satellite dataset of locations in the USA with labels\nderived from presence-absence observation data from the citizen science\ndatabase eBird, considering summer (breeding) and winter seasons. We also\nprovide a dataset in Kenya representing low-data regimes. We additionally\nprovide environmental data and species range maps for each location. We\nbenchmark a set of baselines on our dataset, including SOTA models for remote\nsensing tasks. SatBird opens up possibilities for scalably modelling properties\nof ecosystems worldwide.",
            "author": [
                "M\u00e9lisande Teng",
                "Amna Elmustafa",
                "Benjamin Akera",
                "Yoshua Bengio",
                "Hager Radi Abdelwahed",
                "Hugo Larochelle",
                "David Rolnick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00936v1",
                "http://arxiv.org/pdf/2311.00936v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00932v1",
            "title": "Towards High-quality HDR Deghosting with Conditional Diffusion Models",
            "updated": "2023-11-02T01:53:55Z",
            "published": "2023-11-02T01:53:55Z",
            "summary": "High Dynamic Range (HDR) images can be recovered from several Low Dynamic\nRange (LDR) images by existing Deep Neural Networks (DNNs) techniques. Despite\nthe remarkable progress, DNN-based methods still generate ghosting artifacts\nwhen LDR images have saturation and large motion, which hinders potential\napplications in real-world scenarios. To address this challenge, we formulate\nthe HDR deghosting problem as an image generation that leverages LDR features\nas the diffusion model's condition, consisting of the feature condition\ngenerator and the noise predictor. Feature condition generator employs\nattention and Domain Feature Alignment (DFA) layer to transform the\nintermediate features to avoid ghosting artifacts. With the learned features as\nconditions, the noise predictor leverages a stochastic iterative denoising\nprocess for diffusion models to generate an HDR image by steering the sampling\nprocess. Furthermore, to mitigate semantic confusion caused by the saturation\nproblem of LDR images, we design a sliding window noise estimator to sample\nsmooth noise in a patch-based manner. In addition, an image space loss is\nproposed to avoid the color distortion of the estimated HDR results. We\nempirically evaluate our model on benchmark datasets for HDR imaging. The\nresults demonstrate that our approach achieves state-of-the-art performances\nand well generalization to real-world images.",
            "author": [
                "Qingsen Yan",
                "Tao Hu",
                "Yuan Sun",
                "Hao Tang",
                "Yu Zhu",
                "Wei Dong",
                "Luc Van Gool",
                "Yanning Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00932v1",
                "http://arxiv.org/pdf/2311.00932v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00931v1",
            "title": "Learning Defect Prediction from Unrealistic Data",
            "updated": "2023-11-02T01:51:43Z",
            "published": "2023-11-02T01:51:43Z",
            "summary": "Pretrained models of code, such as CodeBERT and CodeT5, have become popular\nchoices for code understanding and generation tasks. Such models tend to be\nlarge and require commensurate volumes of training data, which are rarely\navailable for downstream tasks. Instead, it has become popular to train models\nwith far larger but less realistic datasets, such as functions with\nartificially injected bugs. Models trained on such data, however, tend to only\nperform well on similar data, while underperforming on real world programs. In\nthis paper, we conjecture that this discrepancy stems from the presence of\ndistracting samples that steer the model away from the real-world task\ndistribution. To investigate this conjecture, we propose an approach for\nidentifying the subsets of these large yet unrealistic datasets that are most\nsimilar to examples in real-world datasets based on their learned\nrepresentations. Our approach extracts high-dimensional embeddings of both\nreal-world and artificial programs using a neural model and scores artificial\nsamples based on their distance to the nearest real-world sample. We show that\ntraining on only the nearest, representationally most similar samples while\ndiscarding samples that are not at all similar in representations yields\nconsistent improvements across two popular pretrained models of code on two\ncode understanding tasks. Our results are promising, in that they show that\ntraining models on a representative subset of an unrealistic dataset can help\nus harness the power of large-scale synthetic data generation while preserving\ndownstream task performance. Finally, we highlight the limitations of applying\nAI models for predicting vulnerabilities and bugs in real-world applications",
            "author": [
                "Kamel Alrashedy",
                "Vincent J. Hellendoorn",
                "Alessandro Orso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00931v1",
                "http://arxiv.org/pdf/2311.00931v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00927v1",
            "title": "Scalable Counterfactual Distribution Estimation in Multivariate Causal\n  Models",
            "updated": "2023-11-02T01:45:44Z",
            "published": "2023-11-02T01:45:44Z",
            "summary": "We consider the problem of estimating the counterfactual joint distribution\nof multiple quantities of interests (e.g., outcomes) in a multivariate causal\nmodel extended from the classical difference-in-difference design. Existing\nmethods for this task either ignore the correlation structures among dimensions\nof the multivariate outcome by considering univariate causal models on each\ndimension separately and hence produce incorrect counterfactual distributions,\nor poorly scale even for moderate-size datasets when directly dealing with such\nmultivariate causal model. We propose a method that alleviates both issues\nsimultaneously by leveraging a robust latent one-dimensional subspace of the\noriginal high-dimension space and exploiting the efficient estimation from the\nunivariate causal model on such space. Since the construction of the\none-dimensional subspace uses information from all the dimensions, our method\ncan capture the correlation structures and produce good estimates of the\ncounterfactual distribution. We demonstrate the advantages of our approach over\nexisting methods on both synthetic and real-world data.",
            "author": [
                "Thong Pham",
                "Shohei Shimizu",
                "Hideitsu Hino",
                "Tam Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00927v1",
                "http://arxiv.org/pdf/2311.00927v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00924v1",
            "title": "The Power of the Senses: Generalizable Manipulation from Vision and\n  Touch through Masked Multimodal Learning",
            "updated": "2023-11-02T01:33:00Z",
            "published": "2023-11-02T01:33:00Z",
            "summary": "Humans rely on the synergy of their senses for most essential tasks. For\ntasks requiring object manipulation, we seamlessly and effectively exploit the\ncomplementarity of our senses of vision and touch. This paper draws inspiration\nfrom such capabilities and aims to find a systematic approach to fuse visual\nand tactile information in a reinforcement learning setting. We propose Masked\nMultimodal Learning (M3L), which jointly learns a policy and visual-tactile\nrepresentations based on masked autoencoding. The representations jointly\nlearned from vision and touch improve sample efficiency, and unlock\ngeneralization capabilities beyond those achievable through each of the senses\nseparately. Remarkably, representations learned in a multimodal setting also\nbenefit vision-only policies at test time. We evaluate M3L on three simulated\nenvironments with both visual and tactile observations: robotic insertion, door\nopening, and dexterous in-hand manipulation, demonstrating the benefits of\nlearning a multimodal policy. Code and videos of the experiments are available\nat https://sferrazza.cc/m3l_site.",
            "author": [
                "Carmelo Sferrazza",
                "Younggyo Seo",
                "Hao Liu",
                "Youngwoon Lee",
                "Pieter Abbeel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00924v1",
                "http://arxiv.org/pdf/2311.00924v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00923v1",
            "title": "A Review and Roadmap of Deep Causal Model from Different Causal\n  Structures and Representations",
            "updated": "2023-11-02T01:31:42Z",
            "published": "2023-11-02T01:31:42Z",
            "summary": "The fusion of causal models with deep learning introducing increasingly\nintricate data sets, such as the causal associations within images or between\ntextual components, has surfaced as a focal research area. Nonetheless, the\nbroadening of original causal concepts and theories to such complex,\nnon-statistical data has been met with serious challenges. In response, our\nstudy proposes redefinitions of causal data into three distinct categories from\nthe standpoint of causal structure and representation: definite data,\nsemi-definite data, and indefinite data. Definite data chiefly pertains to\nstatistical data used in conventional causal scenarios, while semi-definite\ndata refers to a spectrum of data formats germane to deep learning, including\ntime-series, images, text, and others. Indefinite data is an emergent research\nsphere inferred from the progression of data forms by us. To comprehensively\npresent these three data paradigms, we elaborate on their formal definitions,\ndifferences manifested in datasets, resolution pathways, and development of\nresearch. We summarize key tasks and achievements pertaining to definite and\nsemi-definite data from myriad research undertakings, present a roadmap for\nindefinite data, beginning with its current research conundrums. Lastly, we\nclassify and scrutinize the key datasets presently utilized within these three\nparadigms.",
            "author": [
                "Hang Chen",
                "Keqing Du",
                "Chenguang Li",
                "Xinyu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00923v1",
                "http://arxiv.org/pdf/2311.00923v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00922v1",
            "title": "Research Team Identification Based on Representation Learning of\n  Academic Heterogeneous Information Network",
            "updated": "2023-11-02T01:29:09Z",
            "published": "2023-11-02T01:29:09Z",
            "summary": "Academic networks in the real world can usually be described by heterogeneous\ninformation networks composed of multi-type nodes and relationships. Some\nexisting research on representation learning for homogeneous information\nnetworks lacks the ability to explore heterogeneous information networks in\nheterogeneous information networks. It cannot be applied to heterogeneous\ninformation networks. Aiming at the practical needs of effectively identifying\nand discovering scientific research teams from the academic heterogeneous\ninformation network composed of massive and complex scientific and\ntechnological big data, this paper proposes a scientific research team\nidentification method based on representation learning of academic\nheterogeneous information networks. The attention mechanism at node level and\nmeta-path level learns low-dimensional, dense and real-valued vector\nrepresentations on the basis of retaining the rich topological information of\nnodes in the network and the semantic information based on meta-paths, and\nrealizes effective identification and discovery of scientific research teams\nand important team members in academic heterogeneous information networks based\non maximizing node influence. Experimental results show that our proposed\nmethod outperforms the comparative methods.",
            "author": [
                "Junfu Wang",
                "Yawen Li",
                "Zhe Xue",
                "Ang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00922v1",
                "http://arxiv.org/pdf/2311.00922v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00919v1",
            "title": "MIST: Defending Against Membership Inference Attacks Through\n  Membership-Invariant Subspace Training",
            "updated": "2023-11-02T01:25:49Z",
            "published": "2023-11-02T01:25:49Z",
            "summary": "In Member Inference (MI) attacks, the adversary try to determine whether an\ninstance is used to train a machine learning (ML) model. MI attacks are a major\nprivacy concern when using private data to train ML models. Most MI attacks in\nthe literature take advantage of the fact that ML models are trained to fit the\ntraining data well, and thus have very low loss on training instances. Most\ndefenses against MI attacks therefore try to make the model fit the training\ndata less well. Doing so, however, generally results in lower accuracy. We\nobserve that training instances have different degrees of vulnerability to MI\nattacks. Most instances will have low loss even when not included in training.\nFor these instances, the model can fit them well without concerns of MI\nattacks. An effective defense only needs to (possibly implicitly) identify\ninstances that are vulnerable to MI attacks and avoids overfitting them. A\nmajor challenge is how to achieve such an effect in an efficient training\nprocess. Leveraging two distinct recent advancements in representation\nlearning: counterfactually-invariant representations and subspace learning\nmethods, we introduce a novel Membership-Invariant Subspace Training (MIST)\nmethod to defend against MI attacks. MIST avoids overfitting the vulnerable\ninstances without significant impact on other instances. We have conducted\nextensive experimental studies, comparing MIST with various other\nstate-of-the-art (SOTA) MI defenses against several SOTA MI attacks. We find\nthat MIST outperforms other defenses while resulting in minimal reduction in\ntesting accuracy.",
            "author": [
                "Jiacheng Li",
                "Ninghui Li",
                "Bruno Ribeiro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00919v1",
                "http://arxiv.org/pdf/2311.00919v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00917v1",
            "title": "RPCANet: Deep Unfolding RPCA Based Infrared Small Target Detection",
            "updated": "2023-11-02T01:21:12Z",
            "published": "2023-11-02T01:21:12Z",
            "summary": "Deep learning (DL) networks have achieved remarkable performance in infrared\nsmall target detection (ISTD). However, these structures exhibit a deficiency\nin interpretability and are widely regarded as black boxes, as they disregard\ndomain knowledge in ISTD. To alleviate this issue, this work proposes an\ninterpretable deep network for detecting infrared dim targets, dubbed RPCANet.\nSpecifically, our approach formulates the ISTD task as sparse target\nextraction, low-rank background estimation, and image reconstruction in a\nrelaxed Robust Principle Component Analysis (RPCA) model. By unfolding the\niterative optimization updating steps into a deep-learning framework,\ntime-consuming and complex matrix calculations are replaced by theory-guided\nneural networks. RPCANet detects targets with clear interpretability and\npreserves the intrinsic image feature, instead of directly transforming the\ndetection task into a matrix decomposition problem. Extensive experiments\nsubstantiate the effectiveness of our deep unfolding framework and demonstrate\nits trustworthy results, surpassing baseline methods in both qualitative and\nquantitative evaluations.",
            "author": [
                "Fengyi Wu",
                "Tianfang Zhang",
                "Lei Li",
                "Yian Huang",
                "Zhenming Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00917v1",
                "http://arxiv.org/pdf/2311.00917v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00913v1",
            "title": "Self-Influence Guided Data Reweighting for Language Model Pre-training",
            "updated": "2023-11-02T01:00:46Z",
            "published": "2023-11-02T01:00:46Z",
            "summary": "Language Models (LMs) pre-trained with self-supervision on large text corpora\nhave become the default starting point for developing models for various NLP\ntasks. Once the pre-training corpus has been assembled, all data samples in the\ncorpus are treated with equal importance during LM pre-training. However, due\nto varying levels of relevance and quality of data, equal importance to all the\ndata samples may not be the optimal choice. While data reweighting has been\nexplored in the context of task-specific supervised learning and LM\nfine-tuning, model-driven reweighting for pre-training data has not been\nexplored. We fill this important gap and propose PRESENCE, a method for jointly\nreweighting samples by leveraging self-influence (SI) scores as an indicator of\nsample importance and pre-training. PRESENCE promotes novelty and stability for\nmodel pre-training. Through extensive analysis spanning multiple model sizes,\ndatasets, and tasks, we present PRESENCE as an important first step in the\nresearch direction of sample reweighting for pre-training language models.",
            "author": [
                "Megh Thakkar",
                "Tolga Bolukbasi",
                "Sriram Ganapathy",
                "Shikhar Vashishth",
                "Sarath Chandar",
                "Partha Talukdar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00913v1",
                "http://arxiv.org/pdf/2311.00913v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00906v1",
            "title": "Re-weighting Tokens: A Simple and Effective Active Learning Strategy for\n  Named Entity Recognition",
            "updated": "2023-11-02T00:19:02Z",
            "published": "2023-11-02T00:19:02Z",
            "summary": "Active learning, a widely adopted technique for enhancing machine learning\nmodels in text and image classification tasks with limited annotation\nresources, has received relatively little attention in the domain of Named\nEntity Recognition (NER). The challenge of data imbalance in NER has hindered\nthe effectiveness of active learning, as sequence labellers lack sufficient\nlearning signals. To address these challenges, this paper presents a novel\nreweighting-based active learning strategy that assigns dynamic smoothed\nweights to individual tokens. This adaptable strategy is compatible with\nvarious token-level acquisition functions and contributes to the development of\nrobust active learners. Experimental results on multiple corpora demonstrate\nthe substantial performance improvement achieved by incorporating our\nre-weighting strategy into existing acquisition functions, validating its\npractical efficacy.",
            "author": [
                "Haocheng Luo",
                "Wei Tan",
                "Ngoc Dang Nguyen",
                "Lan Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00906v1",
                "http://arxiv.org/pdf/2311.00906v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00902v1",
            "title": "Data-Driven Model Selections of Second-Order Particle Dynamics via\n  Integrating Gaussian Processes with Low-Dimensional Interacting Structures",
            "updated": "2023-11-01T23:45:15Z",
            "published": "2023-11-01T23:45:15Z",
            "summary": "In this paper, we focus on the data-driven discovery of a general\nsecond-order particle-based model that contains many state-of-the-art models\nfor modeling the aggregation and collective behavior of interacting agents of\nsimilar size and body type. This model takes the form of a high-dimensional\nsystem of ordinary differential equations parameterized by two interaction\nkernels that appraise the alignment of positions and velocities. We propose a\nGaussian Process-based approach to this problem, where the unknown model\nparameters are marginalized by using two independent Gaussian Process (GP)\npriors on latent interaction kernels constrained to dynamics and observational\ndata. This results in a nonparametric model for interacting dynamical systems\nthat accounts for uncertainty quantification. We also develop acceleration\ntechniques to improve scalability. Moreover, we perform a theoretical analysis\nto interpret the methodology and investigate the conditions under which the\nkernels can be recovered. We demonstrate the effectiveness of the proposed\napproach on various prototype systems, including the selection of the order of\nthe systems and the types of interactions. In particular, we present\napplications to modeling two real-world fish motion datasets that display\nflocking and milling patterns up to 248 dimensions. Despite the use of small\ndata sets, the GP-based approach learns an effective representation of the\nnonlinear dynamics in these spaces and outperforms competitor methods.",
            "author": [
                "Jinchao Feng",
                "Charles Kulick",
                "Sui Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00902v1",
                "http://arxiv.org/pdf/2311.00902v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.NA",
                "math.NA",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00897v1",
            "title": "On The Open Prompt Challenge In Conditional Audio Generation",
            "updated": "2023-11-01T23:33:25Z",
            "published": "2023-11-01T23:33:25Z",
            "summary": "Text-to-audio generation (TTA) produces audio from a text description,\nlearning from pairs of audio samples and hand-annotated text. However,\ncommercializing audio generation is challenging as user-input prompts are often\nunder-specified when compared to text descriptions used to train TTA models. In\nthis work, we treat TTA models as a ``blackbox'' and address the user prompt\nchallenge with two key insights: (1) User prompts are generally\nunder-specified, leading to a large alignment gap between user prompts and\ntraining prompts. (2) There is a distribution of audio descriptions for which\nTTA models are better at generating higher quality audio, which we refer to as\n``audionese''. To this end, we rewrite prompts with instruction-tuned models\nand propose utilizing text-audio alignment as feedback signals via margin\nranking learning for audio improvements. On both objective and subjective human\nevaluations, we observed marked improvements in both text-audio alignment and\nmusic audio quality.",
            "author": [
                "Ernie Chang",
                "Sidd Srinivasan",
                "Mahi Luthra",
                "Pin-Jie Lin",
                "Varun Nagaraja",
                "Forrest Iandola",
                "Zechun Liu",
                "Zhaoheng Ni",
                "Changsheng Zhao",
                "Yangyang Shi",
                "Vikas Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00897v1",
                "http://arxiv.org/pdf/2311.00897v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00895v1",
            "title": "In-Context Prompt Editing For Conditional Audio Generation",
            "updated": "2023-11-01T23:31:51Z",
            "published": "2023-11-01T23:31:51Z",
            "summary": "Distributional shift is a central challenge in the deployment of machine\nlearning models as they can be ill-equipped for real-world data. This is\nparticularly evident in text-to-audio generation where the encoded\nrepresentations are easily undermined by unseen prompts, which leads to the\ndegradation of generated audio -- the limited set of the text-audio pairs\nremains inadequate for conditional audio generation in the wild as user prompts\nare under-specified. In particular, we observe a consistent audio quality\ndegradation in generated audio samples with user prompts, as opposed to\ntraining set prompts. To this end, we present a retrieval-based in-context\nprompt editing framework that leverages the training captions as demonstrative\nexemplars to revisit the user prompts. We show that the framework enhanced the\naudio quality across the set of collected user prompts, which were edited with\nreference to the training captions as exemplars.",
            "author": [
                "Ernie Chang",
                "Pin-Jie Lin",
                "Yang Li",
                "Sidd Srinivasan",
                "Gael Le Lan",
                "David Kant",
                "Yangyang Shi",
                "Forrest Iandola",
                "Vikas Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00895v1",
                "http://arxiv.org/pdf/2311.00895v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09237v1",
            "title": "An Innovative Tool for Uploading/Scraping Large Image Datasets on Social\n  Networks",
            "updated": "2023-11-01T23:27:37Z",
            "published": "2023-11-01T23:27:37Z",
            "summary": "Nowadays, people can retrieve and share digital information in an\nincreasingly easy and fast fashion through the well-known digital platforms,\nincluding sensitive data, inappropriate or illegal content, and, in general,\ninformation that might serve as probative evidence in court. Consequently, to\nassess forensics issues, we need to figure out how to trace back to the posting\nchain of a digital evidence (e.g., a picture, an audio) throughout the involved\nplatforms -- this is what Digital (also Forensics) Ballistics basically deals\nwith. With the entry of Machine Learning as a tool of the trade in many\nresearch areas, the need for vast amounts of data has been dramatically\nincreasing over the last few years. However, collecting or simply find the\n\"right\" datasets that properly enables data-driven research studies can turn\nout to be not trivial in some cases, if not extremely challenging, especially\nwhen it comes with highly specialized tasks, such as creating datasets analyzed\nto detect the source media platform of a given digital media. In this paper we\npropose an automated approach by means of a digital tool that we created on\npurpose. The tool is capable of automatically uploading an entire image dataset\nto the desired digital platform and then downloading all the uploaded pictures,\nthus shortening the overall time required to output the final dataset to be\nanalyzed.",
            "author": [
                "Nicol\u00f2 Fabio Arceri",
                "Oliver Giudice",
                "Sebastiano Battiato"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09237v1",
                "http://arxiv.org/pdf/2311.09237v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02103v1",
            "title": "Relax: Composable Abstractions for End-to-End Dynamic Machine Learning",
            "updated": "2023-11-01T23:03:59Z",
            "published": "2023-11-01T23:03:59Z",
            "summary": "Dynamic shape computations have become critical in modern machine learning\nworkloads, especially in emerging large language models. The success of these\nmodels has driven demand for deploying them to a diverse set of backend\nenvironments. In this paper, we present Relax, a compiler abstraction for\noptimizing end-to-end dynamic machine learning workloads. Relax introduces\nfirst-class symbolic shape annotations to track dynamic shape computations\nglobally across the program. It also introduces a cross-level abstraction that\nencapsulates computational graphs, loop-level tensor programs, and library\ncalls in a single representation to enable cross-level optimizations. We build\nan end-to-end compilation framework using the proposed approach to optimize\ndynamic shape models. Experimental results on large language models show that\nRelax delivers performance competitive with state-of-the-art hand-optimized\nsystems across platforms and enables deployment of emerging dynamic models to a\nbroader set of environments, including mobile phones, embedded devices, and web\nbrowsers.",
            "author": [
                "Ruihang Lai",
                "Junru Shao",
                "Siyuan Feng",
                "Steven S. Lyubomirsky",
                "Bohan Hou",
                "Wuwei Lin",
                "Zihao Ye",
                "Hongyi Jin",
                "Yuchen Jin",
                "Jiawei Liu",
                "Lesheng Jin",
                "Yaxing Cai",
                "Ziheng Jiang",
                "Yong Wu",
                "Sunghyun Park",
                "Prakalp Srivastava",
                "Jared G. Roesch",
                "Todd C. Mowry",
                "Tianqi Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02103v1",
                "http://arxiv.org/pdf/2311.02103v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00886v1",
            "title": "COSTAR: Improved Temporal Counterfactual Estimation with Self-Supervised\n  Learning",
            "updated": "2023-11-01T22:38:14Z",
            "published": "2023-11-01T22:38:14Z",
            "summary": "Estimation of temporal counterfactual outcomes from observed history is\ncrucial for decision-making in many domains such as healthcare and e-commerce,\nparticularly when randomized controlled trials (RCTs) suffer from high cost or\nimpracticality. For real-world datasets, modeling time-dependent confounders is\nchallenging due to complex dynamics, long-range dependencies and both past\ntreatments and covariates affecting the future outcomes. In this paper, we\nintroduce COunterfactual Self-supervised TrAnsformeR (COSTAR), a novel approach\nthat integrates self-supervised learning for improved historical\nrepresentations. The proposed framework combines temporal and feature-wise\nattention with a component-wise contrastive loss tailored for temporal\ntreatment outcome observations, yielding superior performance in estimation\naccuracy and generalization to out-of-distribution data compared to existing\nmodels, as validated by empirical results on both synthetic and real-world\ndatasets.",
            "author": [
                "Chuizheng Meng",
                "Yihe Dong",
                "Sercan \u00d6. Ar\u0131k",
                "Yan Liu",
                "Tomas Pfister"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00886v1",
                "http://arxiv.org/pdf/2311.00886v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00880v1",
            "title": "SCPO: Safe Reinforcement Learning with Safety Critic Policy Optimization",
            "updated": "2023-11-01T22:12:50Z",
            "published": "2023-11-01T22:12:50Z",
            "summary": "Incorporating safety is an essential prerequisite for broadening the\npractical applications of reinforcement learning in real-world scenarios. To\ntackle this challenge, Constrained Markov Decision Processes (CMDPs) are\nleveraged, which introduce a distinct cost function representing safety\nviolations. In CMDPs' settings, Lagrangian relaxation technique has been\nemployed in previous algorithms to convert constrained optimization problems\ninto unconstrained dual problems. However, these algorithms may inaccurately\npredict unsafe behavior, resulting in instability while learning the Lagrange\nmultiplier. This study introduces a novel safe reinforcement learning\nalgorithm, Safety Critic Policy Optimization (SCPO). In this study, we define\nthe safety critic, a mechanism that nullifies rewards obtained through\nviolating safety constraints. Furthermore, our theoretical analysis indicates\nthat the proposed algorithm can automatically balance the trade-off between\nadhering to safety constraints and maximizing rewards. The effectiveness of the\nSCPO algorithm is empirically validated by benchmarking it against strong\nbaselines.",
            "author": [
                "Jaafar Mhamed",
                "Shangding Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00880v1",
                "http://arxiv.org/pdf/2311.00880v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00875v1",
            "title": "Learning Collective Behaviors from Observation",
            "updated": "2023-11-01T22:02:08Z",
            "published": "2023-11-01T22:02:08Z",
            "summary": "We present a review of a series of learning methods used to identify the\nstructure of dynamical systems, aiming to understand emergent behaviors in\ncomplex systems of interacting agents. These methods not only offer theoretical\nguarantees of convergence but also demonstrate computational efficiency in\nhandling high-dimensional observational data. They can manage observation data\nfrom both first- and second-order dynamical systems, accounting for\nobservation/stochastic noise, complex interaction rules, missing interaction\nfeatures, and real-world observations of interacting agent systems. The essence\nof developing such a series of learning methods lies in designing appropriate\nloss functions using the variational inverse problem approach, which inherently\nprovides dimension reduction capabilities to our learning methods.",
            "author": [
                "Jinchao Feng",
                "Ming Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00875v1",
                "http://arxiv.org/pdf/2311.00875v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00873v1",
            "title": "Low-latency Real-time Voice Conversion on CPU",
            "updated": "2023-11-01T21:57:52Z",
            "published": "2023-11-01T21:57:52Z",
            "summary": "We adapt the architectures of previous audio manipulation and generation\nneural networks to the task of real-time any-to-one voice conversion. Our\nresulting model, LLVC ($\\textbf{L}$ow-latency $\\textbf{L}$ow-resource\n$\\textbf{V}$oice $\\textbf{C}$onversion), has a latency of under 20ms at a\nbitrate of 16kHz and runs nearly 2.8x faster than real-time on a consumer CPU.\nLLVC uses both a generative adversarial architecture as well as knowledge\ndistillation in order to attain this performance. To our knowledge LLVC\nachieves both the lowest resource usage as well as the lowest latency of any\nopen-source voice conversion model. We provide open-source samples, code, and\npretrained model weights at https://github.com/KoeAI/LLVC.",
            "author": [
                "Konstantine Sadov",
                "Matthew Hutter",
                "Asara Near"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00873v1",
                "http://arxiv.org/pdf/2311.00873v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00871v1",
            "title": "Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in\n  Transformer Models",
            "updated": "2023-11-01T21:41:08Z",
            "published": "2023-11-01T21:41:08Z",
            "summary": "Transformer models, notably large language models (LLMs), have the remarkable\nability to perform in-context learning (ICL) -- to perform new tasks when\nprompted with unseen input-output examples without any explicit model training.\nIn this work, we study how effectively transformers can bridge between their\npretraining data mixture, comprised of multiple distinct task families, to\nidentify and learn new tasks in-context which are both inside and outside the\npretraining distribution. Building on previous work, we investigate this\nquestion in a controlled setting, where we study transformer models trained on\nsequences of $(x, f(x))$ pairs rather than natural language. Our empirical\nresults show transformers demonstrate near-optimal unsupervised model selection\ncapabilities, in their ability to first in-context identify different task\nfamilies and in-context learn within them when the task families are\nwell-represented in their pretraining data. However when presented with tasks\nor functions which are out-of-domain of their pretraining data, we demonstrate\nvarious failure modes of transformers and degradation of their generalization\nfor even simple extrapolation tasks. Together our results highlight that the\nimpressive ICL abilities of high-capacity sequence models may be more closely\ntied to the coverage of their pretraining data mixtures than inductive biases\nthat create fundamental generalization capabilities.",
            "author": [
                "Steve Yadlowsky",
                "Lyric Doshi",
                "Nilesh Tripuraneni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00871v1",
                "http://arxiv.org/pdf/2311.00871v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00866v1",
            "title": "Generalizing Nonlinear ICA Beyond Structural Sparsity",
            "updated": "2023-11-01T21:36:15Z",
            "published": "2023-11-01T21:36:15Z",
            "summary": "Nonlinear independent component analysis (ICA) aims to uncover the true\nlatent sources from their observable nonlinear mixtures. Despite its\nsignificance, the identifiability of nonlinear ICA is known to be impossible\nwithout additional assumptions. Recent advances have proposed conditions on the\nconnective structure from sources to observed variables, known as Structural\nSparsity, to achieve identifiability in an unsupervised manner. However, the\nsparsity constraint may not hold universally for all sources in practice.\nFurthermore, the assumptions of bijectivity of the mixing process and\nindependence among all sources, which arise from the setting of ICA, may also\nbe violated in many real-world scenarios. To address these limitations and\ngeneralize nonlinear ICA, we propose a set of new identifiability results in\nthe general settings of undercompleteness, partial sparsity and source\ndependence, and flexible grouping structures. Specifically, we prove\nidentifiability when there are more observed variables than sources\n(undercomplete), and when certain sparsity and/or source independence\nassumptions are not met for some changing sources. Moreover, we show that even\nin cases with flexible grouping structures (e.g., part of the sources can be\ndivided into irreducible independent groups with various sizes), appropriate\nidentifiability results can also be established. Theoretical claims are\nsupported empirically on both synthetic and real-world datasets.",
            "author": [
                "Yujia Zheng",
                "Kun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00866v1",
                "http://arxiv.org/pdf/2311.00866v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00865v1",
            "title": "Selectively Sharing Experiences Improves Multi-Agent Reinforcement\n  Learning",
            "updated": "2023-11-01T21:35:32Z",
            "published": "2023-11-01T21:35:32Z",
            "summary": "We present a novel multi-agent RL approach, Selective Multi-Agent Prioritized\nExperience Relay, in which agents share with other agents a limited number of\ntransitions they observe during training. The intuition behind this is that\neven a small number of relevant experiences from other agents could help each\nagent learn. Unlike many other multi-agent RL algorithms, this approach allows\nfor largely decentralized training, requiring only a limited communication\nchannel between agents. We show that our approach outperforms baseline\nno-sharing decentralized training and state-of-the art multi-agent RL\nalgorithms. Further, sharing only a small number of highly relevant experiences\noutperforms sharing all experiences between agents, and the performance uplift\nfrom selective experience sharing is robust across a range of hyperparameters\nand DQN variants. A reference implementation of our algorithm is available at\nhttps://github.com/mgerstgrasser/super.",
            "author": [
                "Matthias Gerstgrasser",
                "Tom Danino",
                "Sarah Keren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00865v1",
                "http://arxiv.org/pdf/2311.00865v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.MA",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00863v1",
            "title": "Training Dynamics of Contextual N-Grams in Language Models",
            "updated": "2023-11-01T21:32:51Z",
            "published": "2023-11-01T21:32:51Z",
            "summary": "Prior work has shown the existence of contextual neurons in language models,\nincluding a neuron that activates on German text. We show that this neuron\nexists within a broader contextual n-gram circuit: we find late layer neurons\nwhich recognize and continue n-grams common in German text, but which only\nactivate if the German neuron is active. We investigate the formation of this\ncircuit throughout training and find that it is an example of what we call a\nsecond-order circuit. In particular, both the constituent n-gram circuits and\nthe German detection circuit which culminates in the German neuron form with\nindependent functions early in training - the German detection circuit\npartially through modeling German unigram statistics, and the n-grams by\nboosting appropriate completions. Only after both circuits have already formed\ndo they fit together into a second-order circuit. Contrary to the hypotheses\npresented in prior work, we find that the contextual n-gram circuit forms\ngradually rather than in a sudden phase transition. We further present a range\nof anomalous observations such as a simultaneous phase transition in many tasks\ncoinciding with the learning rate warm-up, and evidence that many context\nneurons form simultaneously early in training but are later unlearned.",
            "author": [
                "Lucia Quirke",
                "Lovis Heindrich",
                "Wes Gurnee",
                "Neel Nanda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00863v1",
                "http://arxiv.org/pdf/2311.00863v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00860v2",
            "title": "Zero Coordinate Shift: Whetted Automatic Differentiation for\n  Physics-informed Operator Learning",
            "updated": "2023-11-23T19:41:41Z",
            "published": "2023-11-01T21:28:24Z",
            "summary": "Automatic differentiation (AD) is a critical step in physics-informed machine\nlearning, required for computing the high-order derivatives of network output\nw.r.t. coordinates of collocation points. In this paper, we present a novel and\nlightweight algorithm to conduct AD for physics-informed operator learning,\nwhich we call the trick of Zero Coordinate Shift (ZCS). Instead of making all\nsampled coordinates as leaf variables, ZCS introduces only one scalar-valued\nleaf variable for each spatial or temporal dimension, simplifying the wanted\nderivatives from \"many-roots-many-leaves\" to \"one-root-many-leaves\" whereby\nreverse-mode AD becomes directly utilisable. It has led to an outstanding\nperformance leap by avoiding the duplication of the computational graph along\nthe dimension of functions (physical parameters). ZCS is easy to implement with\ncurrent deep learning libraries; our own implementation is achieved by\nextending the DeepXDE package. We carry out a comprehensive benchmark analysis\nand several case studies, training physics-informed DeepONets to solve partial\ndifferential equations (PDEs) without data. The results show that ZCS has\npersistently reduced GPU memory consumption and wall time for training by an\norder of magnitude, and such reduction factor scales with the number of\nfunctions. As a low-level optimisation technique, ZCS imposes no restrictions\non data, physics (PDE) or network architecture and does not compromise training\nresults from any aspect.",
            "author": [
                "Kuangdai Leng",
                "Mallikarjun Shankar",
                "Jeyan Thiyagalingam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00860v2",
                "http://arxiv.org/pdf/2311.00860v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NA",
                "math.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00859v1",
            "title": "Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems",
            "updated": "2023-11-01T21:28:02Z",
            "published": "2023-11-01T21:28:02Z",
            "summary": "Finding optimal adversarial attack strategies is an important topic in\nreinforcement learning and the Markov decision process. Previous studies\nusually assume one all-knowing coordinator (attacker) for whom attacking\ndifferent recipient (victim) agents incurs uniform costs. However, in reality,\ninstead of using one limitless central attacker, the attacks often need to be\nperformed by distributed attack agents. We formulate the problem of performing\noptimal adversarial agent-to-agent attacks using distributed attack agents, in\nwhich we impose distinct cost constraints on each different attacker-victim\npair. We propose an optimal method integrating within-step static constrained\nattack-resource allocation optimization and between-step dynamic programming to\nachieve the optimal adversarial attack in a multi-agent system. Our numerical\nresults show that the proposed attacks can significantly reduce the rewards\nreceived by the attacked agents.",
            "author": [
                "Ziqing Lu",
                "Guanlin Liu",
                "Lifeng Cai",
                "Weiyu Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00859v1",
                "http://arxiv.org/pdf/2311.00859v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01476v1",
            "title": "Applications of the Theory of Aggregated Markov Processes in Stochastic\n  Learning Theory",
            "updated": "2023-11-01T21:25:35Z",
            "published": "2023-11-01T21:25:35Z",
            "summary": "A stochastic process that arises by composing a function with a Markov\nprocess is called an aggregated Markov process (AMP). The purpose of composing\na Markov process with a function can be a reduction of dimensions, e.g., a\nprojection onto certain coordinates. The theory around AMP has been extensively\nstudied e.g. by Dynkin, Cameron, Rogers and Pitman, and Kelly, all of whom\nprovided sufficient conditions for an AMP to remain Markov. In another\ndirection, Larget provided a canonical representation for AMP, which can be\nused to verify the equivalence of two AMPs. The purpose of this paper is to\ndescribe how the theory of AMP can be applied to stochastic learning theory as\nthey learn a particular task.",
            "author": [
                "Fangyuan Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01476v1",
                "http://arxiv.org/pdf/2311.01476v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.PR",
                "stat.AP",
                "60J20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00858v1",
            "title": "SmoothHess: ReLU Network Feature Interactions via Stein's Lemma",
            "updated": "2023-11-01T21:24:37Z",
            "published": "2023-11-01T21:24:37Z",
            "summary": "Several recent methods for interpretability model feature interactions by\nlooking at the Hessian of a neural network. This poses a challenge for ReLU\nnetworks, which are piecewise-linear and thus have a zero Hessian almost\neverywhere. We propose SmoothHess, a method of estimating second-order\ninteractions through Stein's Lemma. In particular, we estimate the Hessian of\nthe network convolved with a Gaussian through an efficient sampling algorithm,\nrequiring only network gradient calls. SmoothHess is applied post-hoc, requires\nno modifications to the ReLU network architecture, and the extent of smoothing\ncan be controlled explicitly. We provide a non-asymptotic bound on the sample\ncomplexity of our estimation procedure. We validate the superior ability of\nSmoothHess to capture interactions on benchmark datasets and a real-world\nmedical spirometry dataset.",
            "author": [
                "Max Torop",
                "Aria Masoomi",
                "Davin Hill",
                "Kivanc Kose",
                "Stratis Ioannidis",
                "Jennifer Dy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00858v1",
                "http://arxiv.org/pdf/2311.00858v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00855v2",
            "title": "A Multi-Agent Reinforcement Learning Framework for Evaluating the U.S.\n  Ending the HIV Epidemic Plan",
            "updated": "2023-11-06T22:33:41Z",
            "published": "2023-11-01T21:19:35Z",
            "summary": "Human immunodeficiency virus (HIV) is a major public health concern in the\nUnited States, with about 1.2 million people living with HIV and 35,000 newly\ninfected each year. There are considerable geographical disparities in HIV\nburden and care access across the U.S. The 2019 Ending the HIV Epidemic (EHE)\ninitiative aims to reduce new infections by 90% by 2030, by improving coverage\nof diagnoses, treatment, and prevention interventions and prioritizing\njurisdictions with high HIV prevalence. Identifying optimal scale-up of\nintervention combinations will help inform resource allocation. Existing HIV\ndecision analytic models either evaluate specific cities or the overall\nnational population, thus overlooking jurisdictional interactions or\ndifferences. In this paper, we propose a multi-agent reinforcement learning\n(MARL) model, that enables jurisdiction-specific decision analyses but in an\nenvironment with cross-jurisdictional epidemiological interactions. In\nexperimental analyses, conducted on jurisdictions within California and\nFlorida, optimal policies from MARL were significantly different than those\ngenerated from single-agent RL, highlighting the influence of jurisdictional\nvariations and interactions. By using comprehensive modeling of HIV and\nformulations of state space, action space, and reward functions, this work\nhelps demonstrate the strengths and applicability of MARL for informing public\nhealth policies, and provides a framework for expanding to the national-level\nto inform the EHE.",
            "author": [
                "Dinesh Sharma",
                "Ankit Shah",
                "Chaitra Gopalappa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00855v2",
                "http://arxiv.org/pdf/2311.00855v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00850v1",
            "title": "EMPOT: partial alignment of density maps and rigid body fitting using\n  unbalanced Gromov-Wasserstein divergence",
            "updated": "2023-11-01T21:03:28Z",
            "published": "2023-11-01T21:03:28Z",
            "summary": "Aligning EM density maps and fitting atomic models are essential steps in\nsingle particle cryogenic electron microscopy (cryo-EM), with recent methods\nleveraging various algorithms and machine learning tools. As aligning maps\nremains challenging in the presence of a map that only partially fits the other\n(e.g. one subunit), we here propose a new procedure, EMPOT (EM Partial\nalignment with Optimal Transport), for partial alignment of 3D maps. EMPOT\nfirst finds a coupling between 3D point-cloud representations, which is\nassociated with their so-called unbalanced Gromov Wasserstein divergence, and\nsecond, uses this coupling to find an optimal rigid body transformation. Upon\nrunning and benchmarking our method with experimental maps and structures, we\nshow that EMPOT outperforms standard methods for aligning subunits of a protein\ncomplex and fitting atomic models to a density map, suggesting potential\napplications of Partial Optimal Transport for improving Cryo-EM pipelines.",
            "author": [
                "Aryan Tajmir Riahi",
                "Chenwei Zhang",
                "James Chen",
                "Anne Condon",
                "Khanh Dao Duc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00850v1",
                "http://arxiv.org/pdf/2311.00850v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00846v1",
            "title": "From Doubt to Devotion: Trials and Learning-Based Pricing",
            "updated": "2023-11-01T20:52:14Z",
            "published": "2023-11-01T20:52:14Z",
            "summary": "An informed seller designs a dynamic mechanism to sell an experience good.\nThe seller has partial information about the product match, which affects the\nbuyer's private consumption experience. We characterize equilibrium mechanisms\nof this dynamic informed principal problem. The belief gap between the informed\nseller and the uninformed buyer, coupled with the buyer's learning, gives rise\nto mechanisms that provide the skeptical buyer with limited access to the\nproduct and an option to upgrade if the buyer is swayed by a good experience.\nDepending on the seller's screening technology, this takes the form of\nfree/discounted trials or tiered pricing, which are prevalent in digital\nmarkets. In contrast to static environments, having consumer data can reduce\nsellers' revenue in equilibrium, as they fine-tune the dynamic design with\ntheir data forecasting the buyer's learning process.",
            "author": [
                "Tan Gan",
                "Nicholas Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00846v1",
                "http://arxiv.org/pdf/2311.00846v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00844v2",
            "title": "Electronic excited states from physically-constrained machine learning",
            "updated": "2023-11-08T01:04:12Z",
            "published": "2023-11-01T20:49:59Z",
            "summary": "Data-driven techniques are increasingly used to replace electronic-structure\ncalculations of matter. In this context, a relevant question is whether machine\nlearning (ML) should be applied directly to predict the desired properties or\nbe combined explicitly with physically-grounded operations. We present an\nexample of an integrated modeling approach, in which a symmetry-adapted ML\nmodel of an effective Hamiltonian is trained to reproduce electronic\nexcitations from a quantum-mechanical calculation. The resulting model can make\npredictions for molecules that are much larger and more complex than those that\nit is trained on, and allows for dramatic computational savings by indirectly\ntargeting the outputs of well-converged calculations while using a\nparameterization corresponding to a minimal atom-centered basis. These results\nemphasize the merits of intertwining data-driven techniques with physical\napproximations, improving the transferability and interpretability of ML models\nwithout affecting their accuracy and computational efficiency, and providing a\nblueprint for developing ML-augmented electronic-structure methods.",
            "author": [
                "Edoardo Cignoni",
                "Divya Suman",
                "Jigyasa Nigam",
                "Lorenzo Cupellini",
                "Benedetta Mennucci",
                "Michele Ceriotti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00844v2",
                "http://arxiv.org/pdf/2311.00844v2"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00840v1",
            "title": "Sharp Noisy Binary Search with Monotonic Probabilities",
            "updated": "2023-11-01T20:45:13Z",
            "published": "2023-11-01T20:45:13Z",
            "summary": "We revisit the noisy binary search model of Karp and Kleinberg, in which we\nhave $n$ coins with unknown probabilities $p_i$ that we can flip. The coins are\nsorted by increasing $p_i$, and we would like to find where the probability\ncrosses (to within $\\varepsilon$) of a target value $\\tau$. This generalized\nthe fixed-noise model of Burnashev and Zigangirov , in which $p_i = \\frac{1}{2}\n\\pm \\varepsilon$, to a setting where coins near the target may be\nindistinguishable from it. Karp and Kleinberg showed that\n$\\Theta(\\frac{1}{\\varepsilon^2} \\log n)$ samples are necessary and sufficient\nfor this task.\n  We produce a practical algorithm by solving two theoretical challenges:\nhigh-probability behavior and sharp constants. We give an algorithm that\nsucceeds with probability $1-\\delta$ from\n  \\[\n  \\frac{1}{C_{\\tau, \\varepsilon}} \\cdot \\left(\\lg n + O(\\log^{2/3} n \\log^{1/3}\n\\frac{1}{\\delta} + \\log \\frac{1}{\\delta})\\right)\n  \\]\n  samples, where $C_{\\tau, \\varepsilon}$ is the optimal such constant\nachievable. For $\\delta > n^{-o(1)}$ this is within $1 + o(1)$ of optimal, and\nfor $\\delta \\ll 1$ it is the first bound within constant factors of optimal.",
            "author": [
                "Lucas Gretta",
                "Eric Price"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00840v1",
                "http://arxiv.org/pdf/2311.00840v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00833v1",
            "title": "HIDM: Emulating Large Scale HI Maps using Score-based Diffusion Models",
            "updated": "2023-11-01T20:37:35Z",
            "published": "2023-11-01T20:37:35Z",
            "summary": "Efficiently analyzing maps from upcoming large-scale surveys requires gaining\ndirect access to a high-dimensional likelihood and generating large-scale\nfields with high fidelity, which both represent major challenges. Using CAMELS\nsimulations, we employ the state-of-the-art score-based diffusion models to\nsimultaneously achieve both tasks. We show that our model, HIDM, is able to\nefficiently generate high fidelity large scale HI maps that are in a good\nagreement with the CAMELS's power spectrum, probability distribution, and\nlikelihood up to second moments. HIDM represents a step forward towards\nmaximizing the scientific return of future large scale surveys.",
            "author": [
                "Sultan Hassan",
                "Sambatra Andrianomena"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00833v1",
                "http://arxiv.org/pdf/2311.00833v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00816v1",
            "title": "Faster Peace via Inclusivity: An Efficient Paradigm to Understand\n  Populations in Conflict Zones",
            "updated": "2023-11-01T20:00:12Z",
            "published": "2023-11-01T20:00:12Z",
            "summary": "United Nations practice shows that inclusivity is vital for mediation to be\nsuccessful in helping end violent conflict and establish lasting peace.\nHowever, current methods for understanding the views and needs of populations\nduring dynamic situations create tension between inclusivity and efficiency.\nThis work introduces a novel paradigm to mitigate such tension. In partnership\nwith collaborators at the United Nations we develop a realtime large-scale\nsynchronous dialogue process (RLSDP) to understand stakeholder populations on\nan hour timescale. We demonstrate a machine learning model which enables each\ndialogue cycle to take place on a minute-timescale. We manage a key risk\nrelated to machine learning result trustworthiness by computing result\nconfidence from a fast and reliable estimation of posterior variance. Lastly,\nwe highlight a constellation of risks stemming from this new paradigm and\nsuggest policies to mitigate them.",
            "author": [
                "Jordan Bilich",
                "Michael Varga",
                "Daanish Masood",
                "Andrew Konya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00816v1",
                "http://arxiv.org/pdf/2311.00816v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01475v1",
            "title": "Patch-Based Deep Unsupervised Image Segmentation using Graph Cuts",
            "updated": "2023-11-01T19:59:25Z",
            "published": "2023-11-01T19:59:25Z",
            "summary": "Unsupervised image segmentation aims at grouping different semantic patterns\nin an image without the use of human annotation. Similarly, image clustering\nsearches for groupings of images based on their semantic content without\nsupervision. Classically, both problems have captivated researchers as they\ndrew from sound mathematical concepts to produce concrete applications. With\nthe emergence of deep learning, the scientific community turned its attention\nto complex neural network-based solvers that achieved impressive results in\nthose domains but rarely leveraged the advances made by classical methods. In\nthis work, we propose a patch-based unsupervised image segmentation strategy\nthat bridges advances in unsupervised feature extraction from deep clustering\nmethods with the algorithmic help of classical graph-based methods. We show\nthat a simple convolutional neural network, trained to classify image patches\nand iteratively regularized using graph cuts, naturally leads to a\nstate-of-the-art fully-convolutional unsupervised pixel-level segmenter.\nFurthermore, we demonstrate that this is the ideal setting for leveraging the\npatch-level pairwise features generated by vision transformer models. Our\nresults on real image data demonstrate the effectiveness of our proposed\nmethodology.",
            "author": [
                "Isaac Wasserman",
                "Jeova Farias Sales Rocha Neto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01475v1",
                "http://arxiv.org/pdf/2311.01475v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00815v1",
            "title": "PIAug -- Physics Informed Augmentation for Learning Vehicle Dynamics for\n  Off-Road Navigation",
            "updated": "2023-11-01T19:56:58Z",
            "published": "2023-11-01T19:56:58Z",
            "summary": "Modeling the precise dynamics of off-road vehicles is a complex yet essential\ntask due to the challenging terrain they encounter and the need for optimal\nperformance and safety. Recently, there has been a focus on integrating nominal\nphysics-based models alongside data-driven neural networks using Physics\nInformed Neural Networks. These approaches often assume the availability of a\nwell-distributed dataset; however, this assumption may not hold due to regions\nin the physical distribution that are hard to collect, such as high-speed\nmotions and rare terrains. Therefore, we introduce a physics-informed data\naugmentation methodology called PIAug. We show an example use case of the same\nby modeling high-speed and aggressive motion predictions, given a dataset with\nonly low-speed data. During the training phase, we leverage the nominal model\nfor generating target domain (medium and high velocity) data using the\navailable source data (low velocity). Subsequently, we employ a\nphysics-inspired loss function with this augmented dataset to incorporate prior\nknowledge of physics into the neural network. Our methodology results in up to\n67% less mean error in trajectory prediction in comparison to a standalone\nnominal model, especially during aggressive maneuvers at speeds outside the\ntraining domain. In real-life navigation experiments, our model succeeds in 4x\ntighter waypoint tracking constraints than the Kinematic Bicycle Model (KBM) at\nout-of-domain velocities.",
            "author": [
                "Parv Maheshwari",
                "Wenshan Wang",
                "Samuel Triest",
                "Matthew Sivaprakasam",
                "Shubhra Aich",
                "John G. Rogers III",
                "Jason M. Gregory",
                "Sebastian Scherer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00815v1",
                "http://arxiv.org/pdf/2311.00815v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00811v1",
            "title": "A quantum-classical performance separation in nonconvex optimization",
            "updated": "2023-11-01T19:51:00Z",
            "published": "2023-11-01T19:51:00Z",
            "summary": "In this paper, we identify a family of nonconvex continuous optimization\ninstances, each $d$-dimensional instance with $2^d$ local minima, to\ndemonstrate a quantum-classical performance separation. Specifically, we prove\nthat the recently proposed Quantum Hamiltonian Descent (QHD) algorithm [Leng et\nal., arXiv:2303.01471] is able to solve any $d$-dimensional instance from this\nfamily using $\\widetilde{\\mathcal{O}}(d^3)$ quantum queries to the function\nvalue and $\\widetilde{\\mathcal{O}}(d^4)$ additional 1-qubit and 2-qubit\nelementary quantum gates. On the other side, a comprehensive empirical study\nsuggests that representative state-of-the-art classical optimization\nalgorithms/solvers (including Gurobi) would require a super-polynomial time to\nsolve such optimization instances.",
            "author": [
                "Jiaqi Leng",
                "Yufan Zheng",
                "Xiaodi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00811v1",
                "http://arxiv.org/pdf/2311.00811v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.DS",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00808v1",
            "title": "Mahalanobis-Aware Training for Out-of-Distribution Detection",
            "updated": "2023-11-01T19:46:40Z",
            "published": "2023-11-01T19:46:40Z",
            "summary": "While deep learning models have seen widespread success in controlled\nenvironments, there are still barriers to their adoption in open-world\nsettings. One critical task for safe deployment is the detection of anomalous\nor out-of-distribution samples that may require human intervention. In this\nwork, we present a novel loss function and recipe for training networks with\nimproved density-based out-of-distribution sensitivity. We demonstrate the\neffectiveness of our method on CIFAR-10, notably reducing the false-positive\nrate of the relative Mahalanobis distance method on far-OOD tasks by over 50%.",
            "author": [
                "Connor Mclaughlin",
                "Jason Matterer",
                "Michael Yee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00808v1",
                "http://arxiv.org/pdf/2311.00808v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00807v1",
            "title": "VQA-GEN: A Visual Question Answering Benchmark for Domain Generalization",
            "updated": "2023-11-01T19:43:56Z",
            "published": "2023-11-01T19:43:56Z",
            "summary": "Visual question answering (VQA) models are designed to demonstrate\nvisual-textual reasoning capabilities. However, their real-world applicability\nis hindered by a lack of comprehensive benchmark datasets. Existing domain\ngeneralization datasets for VQA exhibit a unilateral focus on textual shifts\nwhile VQA being a multi-modal task contains shifts across both visual and\ntextual domains. We propose VQA-GEN, the first ever multi-modal benchmark\ndataset for distribution shift generated through a shift induced pipeline.\nExperiments demonstrate VQA-GEN dataset exposes the vulnerability of existing\nmethods to joint multi-modal distribution shifts. validating that comprehensive\nmulti-modal shifts are critical for robust VQA generalization. Models trained\non VQA-GEN exhibit improved cross-domain and in-domain performance, confirming\nthe value of VQA-GEN. Further, we analyze the importance of each shift\ntechnique of our pipeline contributing to the generalization of the model.",
            "author": [
                "Suraj Jyothi Unni",
                "Raha Moraffah",
                "Huan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00807v1",
                "http://arxiv.org/pdf/2311.00807v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00802v1",
            "title": "Neural Field Dynamics Model for Granular Object Piles Manipulation",
            "updated": "2023-11-01T19:36:56Z",
            "published": "2023-11-01T19:36:56Z",
            "summary": "We present a learning-based dynamics model for granular material\nmanipulation. Inspired by the Eulerian approach commonly used in fluid\ndynamics, our method adopts a fully convolutional neural network that operates\non a density field-based representation of object piles and pushers, allowing\nit to exploit the spatial locality of inter-object interactions as well as the\ntranslation equivariance through convolution operations. Furthermore, our\ndifferentiable action rendering module makes the model fully differentiable and\ncan be directly integrated with a gradient-based trajectory optimization\nalgorithm. We evaluate our model with a wide array of piles manipulation tasks\nboth in simulation and real-world experiments and demonstrate that it\nsignificantly exceeds existing latent or particle-based methods in both\naccuracy and computation efficiency, and exhibits zero-shot generalization\ncapabilities across various environments and tasks.",
            "author": [
                "Shangjie Xue",
                "Shuo Cheng",
                "Pujith Kachana",
                "Danfei Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00802v1",
                "http://arxiv.org/pdf/2311.00802v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00801v1",
            "title": "GIST: Generated Inputs Sets Transferability in Deep Learning",
            "updated": "2023-11-01T19:35:18Z",
            "published": "2023-11-01T19:35:18Z",
            "summary": "As the demand for verifiability and testability of neural networks continues\nto rise, an increasing number of methods for generating test sets are being\ndeveloped. However, each of these techniques tends to emphasize specific\ntesting aspects and can be quite time-consuming. A straightforward solution to\nmitigate this issue is to transfer test sets between some benchmarked models\nand a new model under test, based on a desirable property one wishes to\ntransfer. This paper introduces GIST (Generated Inputs Sets Transferability), a\nnovel approach for the efficient transfer of test sets among Deep Learning\nmodels. Given a property of interest that a user wishes to transfer (e.g.,\ncoverage criterion), GIST enables the selection of good test sets from the\npoint of view of this property among available ones from a benchmark. We\nempirically evaluate GIST on fault types coverage property with two modalities\nand different test set generation procedures to demonstrate the approach's\nfeasibility. Experimental results show that GIST can select an effective test\nset for the given property to transfer it to the model under test. Our results\nsuggest that GIST could be applied to transfer other properties and could\ngeneralize to different test sets' generation procedures and modalities",
            "author": [
                "Florian Tambon",
                "Foutse Khomh",
                "Giuliano Antoniol"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00801v1",
                "http://arxiv.org/pdf/2311.00801v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00799v1",
            "title": "Latent space representations of cosmological fields",
            "updated": "2023-11-01T19:33:52Z",
            "published": "2023-11-01T19:33:52Z",
            "summary": "We investigate the possibility of learning the representations of\ncosmological multifield dataset from the CAMELS project. We train a very deep\nvariational encoder on images which comprise three channels, namely gas density\n(Mgas), neutral hydrogen density (HI), and magnetic field amplitudes (B). The\nclustering of the images in feature space with respect to some\ncosmological/astrophysical parameters (e.g. $\\Omega_{\\rm m}$) suggests that the\ngenerative model has learned latent space representations of the high\ndimensional inputs. We assess the quality of the latent codes by conducting a\nlinear test on the extracted features, and find that a single dense layer is\ncapable of recovering some of the parameters to a promising level of accuracy,\nespecially the matter density whose prediction corresponds to a coefficient of\ndetermination $R^{2}$ = 0.93. Furthermore, results show that the generative\nmodel is able to produce images that exhibit statistical properties which are\nconsistent with those of the training data, down to scales of $k\\sim 4h/{\\rm\nMpc}.$",
            "author": [
                "Sambatra Andrianomena",
                "Sultan Hassan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00799v1",
                "http://arxiv.org/pdf/2311.00799v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00797v2",
            "title": "Tipping Points of Evolving Epidemiological Networks: Machine\n  Learning-Assisted, Data-Driven Effective Modeling",
            "updated": "2023-11-10T22:49:40Z",
            "published": "2023-11-01T19:33:03Z",
            "summary": "We study the tipping point collective dynamics of an adaptive\nsusceptible-infected-susceptible (SIS) epidemiological network in a\ndata-driven, machine learning-assisted manner. We identify a\nparameter-dependent effective stochastic differential equation (eSDE) in terms\nof physically meaningful coarse mean-field variables through a deep-learning\nResNet architecture inspired by numerical stochastic integrators. We construct\nan approximate effective bifurcation diagram based on the identified drift term\nof the eSDE and contrast it with the mean-field SIS model bifurcation diagram.\nWe observe a subcritical Hopf bifurcation in the evolving network's effective\nSIS dynamics, that causes the tipping point behavior; this takes the form of\nlarge amplitude collective oscillations that spontaneously -- yet rarely --\narise from the neighborhood of a (noisy) stationary state. We study the\nstatistics of these rare events both through repeated brute force simulations\nand by using established mathematical/computational tools exploiting the\nright-hand-side of the identified SDE. We demonstrate that such a collective\nSDE can also be identified (and the rare events computations also performed) in\nterms of data-driven coarse observables, obtained here via manifold learning\ntechniques, in particular Diffusion Maps. The workflow of our study is\nstraightforwardly applicable to other complex dynamics problems exhibiting\ntipping point dynamics.",
            "author": [
                "Nikolaos Evangelou",
                "Tianqi Cui",
                "Juan M. Bello-Rivas",
                "Alexei Makeev",
                "Ioannis G. Kevrekidis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00797v2",
                "http://arxiv.org/pdf/2311.00797v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.DS",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00796v1",
            "title": "Automatic counting of planting microsites via local visual detection and\n  global count estimation",
            "updated": "2023-11-01T19:31:54Z",
            "published": "2023-11-01T19:31:54Z",
            "summary": "In forest industry, mechanical site preparation by mounding is widely used\nprior to planting operations. One of the main problems when planning planting\noperations is the difficulty in estimating the number of mounds present on a\nplanting block, as their number may greatly vary depending on site\ncharacteristics. This estimation is often carried out through field surveys by\nseveral forestry workers. However, this procedure is prone to error and\nslowness. Motivated by recent advances in UAV imagery and artificial\nintelligence, we propose a fully automated framework to estimate the number of\nmounds on a planting block. Using computer vision and machine learning, we\nformulate the counting task as a supervised learning problem using two\nprediction models. A local detection model is firstly used to detect visible\nmounds based on deep features, while a global prediction function is\nsubsequently applied to provide a final estimation based on block-level\nfeatures. To evaluate the proposed method, we constructed a challenging UAV\ndataset representing several plantation blocks with different characteristics.\nThe performed experiments demonstrated the robustness of the proposed method,\nwhich outperforms manual methods in precision, while significantly reducing\ntime and cost.",
            "author": [
                "Ahmed Zgaren",
                "Wassim Bouachir",
                "Nizar Bouguila"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TETCI.2023.3272004",
                "http://arxiv.org/abs/2311.00796v1",
                "http://arxiv.org/pdf/2311.00796v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00793v1",
            "title": "Feel the Force: From Local Surface Pressure Measurement to Flow\n  Reconstruction in Fluid-Structure Interaction",
            "updated": "2023-11-01T19:27:17Z",
            "published": "2023-11-01T19:27:17Z",
            "summary": "Drawing inspiration from the lateral lines of fish, the inference of flow\ncharacteristics via surface-based data has drawn considerable attention. The\ncurrent approaches often rely on analytical methods tailored exclusively for\npotential flows or utilize black-box machine learning algorithms to estimate a\nspecific set of flow parameters. In contrast to a black box machine learning\napproach, we demonstrate that it is possible to identify certain modes of fluid\nflow and then reconstruct the entire flow field from these modes. We use\nDynamic Mode Decomposition (DMD) to parametrize complex, dynamic features\nacross the entire flow field. We then leverage deep neural networks to infer\nthe DMD modes of the pressure and velocity fields within a large, unsteady flow\ndomain, employing solely a time series of pressure measurements collected on\nthe surface of an immersed obstacle. Our methodology is successfully\ndemonstrated to diverse fluid-structure interaction scenarios, including cases\nwith both free oscillations in the wake of a cylinder and forced oscillations\nof tandem cylinders, demonstrating its versatility and robustness.",
            "author": [
                "Colin Rodwell",
                "Kumar Sourav",
                "Phanindra Tallapragada"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00793v1",
                "http://arxiv.org/pdf/2311.00793v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00792v1",
            "title": "Measuring the Impact of Distractors on Student Learning Gains while\n  Using Proof Blocks",
            "updated": "2023-11-01T19:25:55Z",
            "published": "2023-11-01T19:25:55Z",
            "summary": "Background: Proof Blocks is a software tool that enables students to\nconstruct proofs by assembling prewritten lines and gives them automated\nfeedback. Prior work on learning gains from Proof Blocks has focused on\ncomparing learning gains from Proof Blocks against other learning activities\nsuch as writing proofs or reading.\n  Purpose: The study described in this paper aims to compare learning gains\nfrom different variations of Proof Blocks. Specifically, we attempt to quantify\nthe difference in learning gains for students who complete Proof Blocks\nproblems with and without distractors.\n  Methods: We conducted a randomized controlled trial with three experimental\ngroups: a control group that completed an off-topic Proof Blocks activity, one\nthat completed a \\tool{} activity without distractors, and one that completed a\nProof Blocks activity with distractors. All three groups read a book chapter on\nproof by induction before completing their activity.\n  Findings: The group that completed the Proof Blocks activity with distractors\nperformed better on the posttest than the group that completed the Proof Blocks\nwithout distractors, who in turn performed better than the group that completed\nthe off-topic Proof Blocks activity. However, none of these differences were\nstatistically significant. While the results of this study are inconclusive, we\nhope that it can serve as a foundation for future work.",
            "author": [
                "Seth Poulsen",
                "Hongxuan Chen",
                "Yael Gertner",
                "Benjamin Cosman",
                "Matthew West",
                "Geoffrey L Herman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00792v1",
                "http://arxiv.org/pdf/2311.00792v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00787v1",
            "title": "Accelerating Electronic Stopping Power Predictions by 10 Million Times\n  with a Combination of Time-Dependent Density Functional Theory and Machine\n  Learning",
            "updated": "2023-11-01T19:11:46Z",
            "published": "2023-11-01T19:11:46Z",
            "summary": "Knowing the rate at which particle radiation releases energy in a material,\nthe stopping power, is key to designing nuclear reactors, medical treatments,\nsemiconductor and quantum materials, and many other technologies. While the\nnuclear contribution to stopping power, i.e., elastic scattering between atoms,\nis well understood in the literature, the route for gathering data on the\nelectronic contribution has for decades remained costly and reliant on many\nsimplifying assumptions, including that materials are isotropic. We establish a\nmethod that combines time-dependent density functional theory (TDDFT) and\nmachine learning to reduce the time to assess new materials to mere hours on a\nsupercomputer and provides valuable data on how atomic details influence\nelectronic stopping. Our approach uses TDDFT to compute the electronic stopping\ncontributions to stopping power from first principles in several directions and\nthen machine learning to interpolate to other directions at rates 10 million\ntimes higher. We demonstrate the combined approach in a study of proton\nirradiation in aluminum and employ it to predict how the depth of maximum\nenergy deposition, the \"Bragg Peak,\" varies depending on incident angle -- a\nquantity otherwise inaccessible to modelers. The lack of any experimental\ninformation requirement makes our method applicable to most materials, and its\nspeed makes it a prime candidate for enabling quantum-to-continuum models of\nradiation damage. The prospect of reusing valuable TDDFT data for training the\nmodel make our approach appealing for applications in the age of materials data\nscience.",
            "author": [
                "Logan Ward",
                "Ben Blaiszik",
                "Cheng-Wei Lee",
                "Troy Martin",
                "Ian Foster",
                "Andr\u00e9 Schleife"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00787v1",
                "http://arxiv.org/pdf/2311.00787v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00778v1",
            "title": "Convergence of Heterogeneous Learning Dynamics in Zero-sum Stochastic\n  Games",
            "updated": "2023-11-01T18:46:32Z",
            "published": "2023-11-01T18:46:32Z",
            "summary": "This paper presents new families of algorithms for the repeated play of\ntwo-agent (near) zero-sum games and two-agent zero-sum stochastic games. For\nexample, the family includes fictitious play and its variants as members.\nCommonly, the algorithms in this family are all uncoupled, rational, and\nconvergent even in heterogeneous cases, e.g., where the dynamics may differ in\nterms of learning rates, full, none or temporal access to opponent actions, and\nmodel-based vs model-free learning. The convergence of heterogeneous dynamics\nis of practical interest especially in competitive environments since agents\nmay have no means or interests in following the same dynamic with the same\nparameters. We prove that any mixture of such asymmetries does not impact the\nalgorithms' convergence to equilibrium (or near equilibrium if there is\nexperimentation) in zero-sum games with repeated play and in zero-sum\n(irreducible) stochastic games with sufficiently small discount factors.",
            "author": [
                "Yuksel Arslantas",
                "Ege Yuceel",
                "Yigit Yalin",
                "Muhammed O. Sayin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00778v1",
                "http://arxiv.org/pdf/2311.00778v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04226v1",
            "title": "Assessing Upper Limb Motor Function in the Immediate Post-Stroke Perioud\n  Using Accelerometry",
            "updated": "2023-11-01T18:43:20Z",
            "published": "2023-11-01T18:43:20Z",
            "summary": "Accelerometry has been extensively studied as an objective means of measuring\nupper limb function in patients post-stroke. The objective of this paper is to\ndetermine whether the accelerometry-derived measurements frequently used in\nmore long-term rehabilitation studies can also be used to monitor and rapidly\ndetect sudden changes in upper limb motor function in more recently\nhospitalized stroke patients. Six binary classification models were created by\ntraining on variable data window times of paretic upper limb accelerometer\nfeature data. The models were assessed on their effectiveness for\ndifferentiating new input data into two classes: severe or moderately severe\nmotor function. The classification models yielded Area Under the Curve (AUC)\nscores that ranged from 0.72 to 0.82 for 15-minute data windows to 0.77 to 0.94\nfor 120-minute data windows. These results served as a preliminary assessment\nand a basis on which to further investigate the efficacy of using accelerometry\nand machine learning to alert healthcare professionals to rapid changes in\nmotor function in the days immediately following a stroke.",
            "author": [
                "Mackenzie Wallich",
                "Kenneth Lai",
                "Svetlana Yanushkevich"
            ],
            "link": [
                "http://dx.doi.org/10.1109/CAI54212.2023.00064",
                "http://arxiv.org/abs/2311.04226v1",
                "http://arxiv.org/pdf/2311.04226v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00775v3",
            "title": "Harnessing machine learning for accurate treatment of overlapping\n  opacity species in general circulation models",
            "updated": "2023-12-06T16:08:51Z",
            "published": "2023-11-01T18:38:31Z",
            "summary": "To understand high precision observations of exoplanets and brown dwarfs, we\nneed detailed and complex general circulation models (GCMs) that incorporate\nhydrodynamics, chemistry, and radiation. For this study, we specifically\nexamined the coupling between chemistry and radiation in GCMs and compared\ndifferent methods for the mixing of opacities of different chemical species in\nthe correlated-k assumption, when equilibrium chemistry cannot be assumed. We\npropose a fast machine learning method based on DeepSets (DS), which\neffectively combines individual correlated-k opacities (k-tables). We evaluated\nthe DS method alongside other published methods such as adaptive equivalent\nextinction (AEE) and random overlap with rebinning and resorting (RORR). We\nintegrated these mixing methods into our GCM (expeRT/MITgcm) and assessed their\naccuracy and performance for the example of the hot Jupiter HD~209458 b. Our\nfindings indicate that the DS method is both accurate and efficient for GCM\nusage, whereas RORR is too slow. Additionally, we observed that the accuracy of\nAEE depends on its specific implementation and may introduce numerical issues\nin achieving radiative transfer solution convergence. We then applied the DS\nmixing method in a simplified chemical disequilibrium situation, where we\nmodeled the rainout of TiO and VO, and confirmed that the rainout of TiO and VO\nwould hinder the formation of a stratosphere. To further expedite the\ndevelopment of consistent disequilibrium chemistry calculations in GCMs, we\nprovide documentation and code for coupling the DS mixing method with\ncorrelated-k radiative transfer solvers. The DS method has been extensively\ntested to be accurate enough for GCMs; however, other methods might be needed\nfor accelerating atmospheric retrievals.",
            "author": [
                "Aaron David Schneider",
                "Paul Molli\u00e8re",
                "Gilles Louppe",
                "Ludmila Carone",
                "Uffe Gr\u00e5e J\u00f8rgensen",
                "Leen Decin",
                "Christiane Helling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00775v3",
                "http://arxiv.org/pdf/2311.00775v3"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00774v1",
            "title": "Conformalized Deep Splines for Optimal and Efficient Prediction Sets",
            "updated": "2023-11-01T18:37:07Z",
            "published": "2023-11-01T18:37:07Z",
            "summary": "Uncertainty estimation is critical in high-stakes machine learning\napplications. One effective way to estimate uncertainty is conformal\nprediction, which can provide predictive inference with statistical coverage\nguarantees. We present a new conformal regression method, Spline Prediction\nIntervals via Conformal Estimation (SPICE), that estimates the conditional\ndensity using neural-network-parameterized splines. We prove universal\napproximation and optimality results for SPICE, which are empirically validated\nby our experiments. SPICE is compatible with two different efficient-to-compute\nconformal scores, one oracle-optimal for marginal coverage (SPICE-ND) and the\nother asymptotically optimal for conditional coverage (SPICE-HPD). Results on\nbenchmark datasets demonstrate SPICE-ND models achieve the smallest average\nprediction set sizes, including average size reductions of nearly 50% for some\ndatasets compared to the next best baseline. SPICE-HPD models achieve the best\nconditional coverage compared to baselines. The SPICE implementation is made\navailable.",
            "author": [
                "Nathaniel Diamant",
                "Ehsan Hajiramezanali",
                "Tommaso Biancalani",
                "Gabriele Scalia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00774v1",
                "http://arxiv.org/pdf/2311.00774v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00772v1",
            "title": "SAGE: Smart home Agent with Grounded Execution",
            "updated": "2023-11-01T18:36:28Z",
            "published": "2023-11-01T18:36:28Z",
            "summary": "This article introduces SAGE (Smart home Agent with Grounded Execution), a\nframework designed to maximize the flexibility of smart home assistants by\nreplacing manually-defined inference logic with an LLM-powered autonomous agent\nsystem. SAGE integrates information about user preferences, device states, and\nexternal factors (such as weather and TV schedules) through the orchestration\nof a collection of tools. SAGE's capabilities include learning user preferences\nfrom natural-language utterances, interacting with devices by reading their API\ndocumentation, writing code to continuously monitor devices, and understanding\nnatural device references. To evaluate SAGE, we develop a benchmark of 43\nhighly challenging smart home tasks, where SAGE successfully achieves 23 tasks,\nsignificantly outperforming existing LLM-enabled baselines (5/43).",
            "author": [
                "Dmitriy Rivkin",
                "Francois Hogan",
                "Amal Feriani",
                "Abhisek Konar",
                "Adam Sigal",
                "Steve Liu",
                "Greg Dudek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00772v1",
                "http://arxiv.org/pdf/2311.00772v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00768v1",
            "title": "Language Model Training Paradigms for Clinical Feature Embeddings",
            "updated": "2023-11-01T18:23:12Z",
            "published": "2023-11-01T18:23:12Z",
            "summary": "In research areas with scarce data, representation learning plays a\nsignificant role. This work aims to enhance representation learning for\nclinical time series by deriving universal embeddings for clinical features,\nsuch as heart rate and blood pressure. We use self-supervised training\nparadigms for language models to learn high-quality clinical feature\nembeddings, achieving a finer granularity than existing time-step and\npatient-level representation learning. We visualize the learnt embeddings via\nunsupervised dimension reduction techniques and observe a high degree of\nconsistency with prior clinical knowledge. We also evaluate the model\nperformance on the MIMIC-III benchmark and demonstrate the effectiveness of\nusing clinical feature embeddings. We publish our code online for replication.",
            "author": [
                "Yurong Hu",
                "Manuel Burger",
                "Gunnar R\u00e4tsch",
                "Rita Kuznetsova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00768v1",
                "http://arxiv.org/pdf/2311.00768v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00767v1",
            "title": "Hand Gesture Classification on Praxis Dataset: Trading Accuracy for\n  Expense",
            "updated": "2023-11-01T18:18:09Z",
            "published": "2023-11-01T18:18:09Z",
            "summary": "In this paper, we investigate hand gesture classifiers that rely upon the\nabstracted 'skeletal' data recorded using the RGB-Depth sensor. We focus on\n'skeletal' data represented by the body joint coordinates, from the Praxis\ndataset. The PRAXIS dataset contains recordings of patients with cortical\npathologies such as Alzheimer's disease, performing a Praxis test under the\ndirection of a clinician. In this paper, we propose hand gesture classifiers\nthat are more effective with the PRAXIS dataset than previously proposed\nmodels. Body joint data offers a compressed form of data that can be analyzed\nspecifically for hand gesture recognition. Using a combination of windowing\ntechniques with deep learning architecture such as a Recurrent Neural Network\n(RNN), we achieved an overall accuracy of 70.8% using only body joint data. In\naddition, we investigated a long-short-term-memory (LSTM) to extract and\nanalyze the movement of the joints through time to recognize the hand gestures\nbeing performed and achieved a gesture recognition rate of 74.3% and 67.3% for\nstatic and dynamic gestures, respectively. The proposed approach contributed to\nthe task of developing an automated, accurate, and inexpensive approach to\ndiagnosing cortical pathologies for multiple healthcare applications.",
            "author": [
                "Rahat Islam",
                "Kenneth Lai",
                "Svetlana Yanushkevich"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IJCNN55064.2022.9892631",
                "http://arxiv.org/abs/2311.00767v1",
                "http://arxiv.org/pdf/2311.00767v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00756v1",
            "title": "The Quantum Cartpole: A benchmark environment for non-linear\n  reinforcement learning",
            "updated": "2023-11-01T18:02:42Z",
            "published": "2023-11-01T18:02:42Z",
            "summary": "Feedback-based control is the de-facto standard when it comes to controlling\nclassical stochastic systems and processes. However, standard feedback-based\ncontrol methods are challenged by quantum systems due to measurement induced\nbackaction and partial observability. Here we remedy this by using weak quantum\nmeasurements and model-free reinforcement learning agents to perform quantum\ncontrol. By comparing control algorithms with and without state estimators to\nstabilize a quantum particle in an unstable state near a local potential energy\nmaximum, we show how a trade-off between state estimation and controllability\narises. For the scenario where the classical analogue is highly nonlinear, the\nreinforcement learned controller has an advantage over the standard controller.\nAdditionally, we demonstrate the feasibility of using transfer learning to\ndevelop a quantum control agent trained via reinforcement learning on a\nclassical surrogate of the quantum control problem. Finally, we present results\nshowing how the reinforcement learning control strategy differs from the\nclassical controller in the non-linear scenarios.",
            "author": [
                "Kai Meinerz",
                "Simon Trebst",
                "Mark Rudner",
                "Evert van Nieuwenburg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00756v1",
                "http://arxiv.org/pdf/2311.00756v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00754v1",
            "title": "Learning to Design and Use Tools for Robotic Manipulation",
            "updated": "2023-11-01T18:00:10Z",
            "published": "2023-11-01T18:00:10Z",
            "summary": "When limited by their own morphologies, humans and some species of animals\nhave the remarkable ability to use objects from the environment toward\naccomplishing otherwise impossible tasks. Robots might similarly unlock a range\nof additional capabilities through tool use. Recent techniques for jointly\noptimizing morphology and control via deep learning are effective at designing\nlocomotion agents. But while outputting a single morphology makes sense for\nlocomotion, manipulation involves a variety of strategies depending on the task\ngoals at hand. A manipulation agent must be capable of rapidly prototyping\nspecialized tools for different goals. Therefore, we propose learning a\ndesigner policy, rather than a single design. A designer policy is conditioned\non task information and outputs a tool design that helps solve the task. A\ndesign-conditioned controller policy can then perform manipulation using these\ntools. In this work, we take a step towards this goal by introducing a\nreinforcement learning framework for jointly learning these policies. Through\nsimulated manipulation tasks, we show that this framework is more sample\nefficient than prior methods in multi-goal or multi-variant settings, can\nperform zero-shot interpolation or fine-tuning to tackle previously unseen\ngoals, and allows tradeoffs between the complexity of design and control\npolicies under practical constraints. Finally, we deploy our learned policies\nonto a real robot. Please see our supplementary video and website at\nhttps://robotic-tool-design.github.io/ for visualizations.",
            "author": [
                "Ziang Liu",
                "Stephen Tian",
                "Michelle Guo",
                "C. Karen Liu",
                "Jiajun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00754v1",
                "http://arxiv.org/pdf/2311.00754v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00749v1",
            "title": "Sorting with Predictions",
            "updated": "2023-11-01T18:00:03Z",
            "published": "2023-11-01T18:00:03Z",
            "summary": "We explore the fundamental problem of sorting through the lens of\nlearning-augmented algorithms, where algorithms can leverage possibly erroneous\npredictions to improve their efficiency. We consider two different settings: In\nthe first setting, each item is provided a prediction of its position in the\nsorted list. In the second setting, we assume there is a \"quick-and-dirty\" way\nof comparing items, in addition to slow-and-exact comparisons. For both\nsettings, we design new and simple algorithms using only $O(\\sum_i \\log\n\\eta_i)$ exact comparisons, where $\\eta_i$ is a suitably defined prediction\nerror for the $i$th element. In particular, as the quality of predictions\ndeteriorates, the number of comparisons degrades smoothly from $O(n)$ to\n$O(n\\log n)$. We prove that the comparison complexity is theoretically optimal\nwith respect to the examined error measures. An experimental evaluation against\nexisting adaptive and non-adaptive sorting algorithms demonstrates the\npotential of applying learning-augmented algorithms in sorting tasks.",
            "author": [
                "Xingjian Bai",
                "Christian Coester"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00749v1",
                "http://arxiv.org/pdf/2311.00749v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00750v1",
            "title": "Are These the Same Apple? Comparing Images Based on Object Intrinsics",
            "updated": "2023-11-01T18:00:03Z",
            "published": "2023-11-01T18:00:03Z",
            "summary": "The human visual system can effortlessly recognize an object under different\nextrinsic factors such as lighting, object poses, and background, yet current\ncomputer vision systems often struggle with these variations. An important step\nto understanding and improving artificial vision systems is to measure image\nsimilarity purely based on intrinsic object properties that define object\nidentity. This problem has been studied in the computer vision literature as\nre-identification, though mostly restricted to specific object categories such\nas people and cars. We propose to extend it to general object categories,\nexploring an image similarity metric based on object intrinsics. To benchmark\nsuch measurements, we collect the Common paired objects Under differenT\nExtrinsics (CUTE) dataset of $18,000$ images of $180$ objects under different\nextrinsic factors such as lighting, poses, and imaging conditions. While\nexisting methods such as LPIPS and CLIP scores do not measure object intrinsics\nwell, we find that combining deep features learned from contrastive\nself-supervised learning with foreground filtering is a simple yet effective\napproach to approximating the similarity. We conduct an extensive survey of\npre-trained features and foreground extraction methods to arrive at a strong\nbaseline that best measures intrinsic object-centric image similarity among\ncurrent methods. Finally, we demonstrate that our approach can aid in\ndownstream applications such as acting as an analog for human subjects and\nimproving generalizable re-identification. Please see our project website at\nhttps://s-tian.github.io/projects/cute/ for visualizations of the data and\ndemos of our metric.",
            "author": [
                "Klemen Kotar",
                "Stephen Tian",
                "Hong-Xing Yu",
                "Daniel L. K. Yamins",
                "Jiajun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00750v1",
                "http://arxiv.org/pdf/2311.00750v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00743v2",
            "title": "The intrinsic charm quark valence distribution of the proton",
            "updated": "2023-11-03T08:52:42Z",
            "published": "2023-11-01T18:00:00Z",
            "summary": "We provide a first quantitative indication that the wave function of the\nproton contains unequal distributions of charm quarks and antiquarks, i.e. a\nnonvanishing intrinsic valence charm distribution. A significant nonvanishing\nvalence component cannot be perturbatively generated, hence our results\nreinforce previous evidence that the proton contains an intrinsic (i.e., not\nradiatively generated) charm quark component. We establish our result through a\ndetermination of the parton distribution functions (PDFs) of charm quarks and\nantiquarks in the proton. We propose two novel experimental probes of this\nintrinsic charm valence component: D-meson asymmetries in Z+c-jet production at\nthe LHCb experiment, and flavor-tagged structure functions at the Electron-Ion\nCollider.",
            "author": [
                "Richard D. Ball",
                "Alessandro Candido",
                "Juan Cruz-Martinez",
                "Stefano Forte",
                "Tommaso Giani",
                "Felix Hekhorn",
                "Giacomo Magni",
                "Emanuele R. Nocera",
                "Juan Rojo",
                "Roy Stegeman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00743v2",
                "http://arxiv.org/pdf/2311.00743v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00696v1",
            "title": "Decision Support Framework for Home Health Caregiver Allocation: A Case\n  Study of HHC Agency in Tennessee, USA",
            "updated": "2023-11-01T17:54:49Z",
            "published": "2023-11-01T17:54:49Z",
            "summary": "Population aging is a global challenge, leading to increased demand for\nhealthcare and social services for the elderly. Home Health Care (HHC) emerges\nas a vital solution, specifically designed to serve this population segment.\nGiven the surging demand for HHC, it's essential to coordinate and regulate\ncaregiver allocation efficiently. This is crucial for both budget-optimized\nplanning and ensuring the delivery of high-quality care. This research\naddresses a key question faced by home health agencies (HHAs): \"How can\ncaregiver allocation be optimized, especially when caregivers prefer\nflexibility in their visiting sequences?\". While earlier studies proposed rigid\nvisiting sequences, our study introduces a decision support framework that\nallocates caregivers through a hybrid method that considers the flexibility in\nvisiting sequences and aims to reduce travel mileage, increase the number of\nvisits per planning period, and maintain the continuity of care - a critical\nmetric for patient satisfaction. Utilizing data from an HHA in Tennessee,\nUnited States, our approach led to an impressive reduction in average travel\nmileage (up to 42% depending on discipline) without imposing restrictions on\ncaregivers. Furthermore, the proposed framework is used for caregivers' supply\nanalysis to provide valuable insights into caregiver resource management.",
            "author": [
                "Seyed Mohammad Ebrahim Sharifnia",
                "Faezeh Bagheri",
                "Rupy Sawhney",
                "John E. Kobza",
                "Enrique Macias De Anda",
                "Mostafa Hajiaghaei-Keshteli",
                "Michael Mirrielees"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00696v1",
                "http://arxiv.org/pdf/2311.00696v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00694v2",
            "title": "Unleashing the Creative Mind: Language Model As Hierarchical Policy For\n  Improved Exploration on Challenging Problem Solving",
            "updated": "2023-12-05T20:44:45Z",
            "published": "2023-11-01T17:52:15Z",
            "summary": "Large Language Models (LLMs) have achieved tremendous progress, yet they\nstill often struggle with challenging reasoning problems. Current approaches\naddress this challenge by sampling or searching detailed and low-level\nreasoning chains. However, these methods are still limited in their exploration\ncapabilities, making it challenging for correct solutions to stand out in the\nhuge solution space. In this work, we unleash LLMs' creative potential for\nexploring multiple diverse problem solving strategies by framing an LLM as a\nhierarchical policy via in-context learning. This policy comprises of a\nvisionary leader that proposes multiple diverse high-level problem-solving\ntactics as hints, accompanied by a follower that executes detailed\nproblem-solving processes following each of the high-level instruction. The\nfollower uses each of the leader's directives as a guide and samples multiple\nreasoning chains to tackle the problem, generating a solution group for each\nleader proposal. Additionally, we propose an effective and efficient\ntournament-based approach to select among these explored solution groups to\nreach the final answer. Our approach produces meaningful and inspiring hints,\nenhances problem-solving strategy exploration, and improves the final answer\naccuracy on challenging problems in the MATH dataset. Code will be released at\nhttps://github.com/lz1oceani/LLM-As-Hierarchical-Policy.",
            "author": [
                "Zhan Ling",
                "Yunhao Fang",
                "Xuanlin Li",
                "Tongzhou Mu",
                "Mingu Lee",
                "Reza Pourreza",
                "Roland Memisevic",
                "Hao Su"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00694v2",
                "http://arxiv.org/pdf/2311.00694v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00693v1",
            "title": "On Task-personalized Multimodal Few-shot Learning for Visually-rich\n  Document Entity Retrieval",
            "updated": "2023-11-01T17:51:43Z",
            "published": "2023-11-01T17:51:43Z",
            "summary": "Visually-rich document entity retrieval (VDER), which extracts key\ninformation (e.g. date, address) from document images like invoices and\nreceipts, has become an important topic in industrial NLP applications. The\nemergence of new document types at a constant pace, each with its unique entity\ntypes, presents a unique challenge: many documents contain unseen entity types\nthat occur only a couple of times. Addressing this challenge requires models to\nhave the ability of learning entities in a few-shot manner. However, prior\nworks for Few-shot VDER mainly address the problem at the document level with a\npredefined global entity space, which doesn't account for the entity-level\nfew-shot scenario: target entity types are locally personalized by each task\nand entity occurrences vary significantly among documents. To address this\nunexplored scenario, this paper studies a novel entity-level few-shot VDER\ntask. The challenges lie in the uniqueness of the label space for each task and\nthe increased complexity of out-of-distribution (OOD) contents. To tackle this\nnovel task, we present a task-aware meta-learning based framework, with a\ncentral focus on achieving effective task personalization that distinguishes\nbetween in-task and out-of-task distribution. Specifically, we adopt a\nhierarchical decoder (HC) and employ contrastive learning (ContrastProtoNet) to\nachieve this goal. Furthermore, we introduce a new dataset, FewVEX, to boost\nfuture research in the field of entity-level few-shot VDER. Experimental\nresults demonstrate our approaches significantly improve the robustness of\npopular meta-learning baselines.",
            "author": [
                "Jiayi Chen",
                "Hanjun Dai",
                "Bo Dai",
                "Aidong Zhang",
                "Wei Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00693v1",
                "http://arxiv.org/pdf/2311.00693v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00691v1",
            "title": "Software Repositories and Machine Learning Research in Cyber Security",
            "updated": "2023-11-01T17:46:07Z",
            "published": "2023-11-01T17:46:07Z",
            "summary": "In today's rapidly evolving technological landscape and advanced software\ndevelopment, the rise in cyber security attacks has become a pressing concern.\nThe integration of robust cyber security defenses has become essential across\nall phases of software development. It holds particular significance in\nidentifying critical cyber security vulnerabilities at the initial stages of\nthe software development life cycle, notably during the requirement phase.\nThrough the utilization of cyber security repositories like The Common Attack\nPattern Enumeration and Classification (CAPEC) from MITRE and the Common\nVulnerabilities and Exposures (CVE) databases, attempts have been made to\nleverage topic modeling and machine learning for the detection of these\nearly-stage vulnerabilities in the software requirements process. Past research\nthemes have returned successful outcomes in attempting to automate\nvulnerability identification for software developers, employing a mixture of\nunsupervised machine learning methodologies such as LDA and topic modeling.\nLooking ahead, in our pursuit to improve automation and establish connections\nbetween software requirements and vulnerabilities, our strategy entails\nadopting a variety of supervised machine learning techniques. This array\nencompasses Support Vector Machines (SVM), Na\\\"ive Bayes, random forest, neural\nnetworking and eventually transitioning into deep learning for our\ninvestigation. In the face of the escalating complexity of cyber security, the\nquestion of whether machine learning can enhance the identification of\nvulnerabilities in diverse software development scenarios is a paramount\nconsideration, offering crucial assistance to software developers in developing\nsecure software.",
            "author": [
                "Mounika Vanamala",
                "Keith Bryant",
                "Alex Caravella"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00691v1",
                "http://arxiv.org/pdf/2311.00691v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00690v3",
            "title": "What User Behaviors Make the Differences During the Process of Visual\n  Analytics?",
            "updated": "2023-12-04T02:58:02Z",
            "published": "2023-11-01T17:45:52Z",
            "summary": "The understanding of visual analytics process can benefit visualization\nresearchers from multiple aspects, including improving visual designs and\ndeveloping advanced interaction functions. However, the log files of user\nbehaviors are still hard to analyze due to the complexity of sensemaking and\nour lack of knowledge on the related user behaviors. This work presents a study\non a comprehensive data collection of user behaviors, and our analysis approach\nwith time-series classification methods. We have chosen a classical\nvisualization application, Covid-19 data analysis, with common analysis tasks\ncovering geo-spatial, time-series and multi-attributes. Our user study collects\nuser behaviors on a diverse set of visualization tasks with two comparable\nsystems, desktop and immersive visualizations. We summarize the classification\nresults with three time-series machine learning algorithms at two scales, and\nexplore the influences of behavior features. Our results reveal that user\nbehaviors can be distinguished during the process of visual analytics and there\nis a potentially strong association between the physical behaviors of users and\nthe visualization tasks they perform. We also demonstrate the usage of our\nmodels by interpreting open sessions of visual analytics, which provides an\nautomatic way to study sensemaking without tedious manual annotations.",
            "author": [
                "Zekun Wu",
                "Shahin Doroudian",
                "Aidong Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00690v3",
                "http://arxiv.org/pdf/2311.00690v3"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00687v2",
            "title": "Improving Interpersonal Communication by Simulating Audiences with\n  Language Models",
            "updated": "2023-11-03T13:17:55Z",
            "published": "2023-11-01T17:44:50Z",
            "summary": "How do we communicate with others to achieve our goals? We use our prior\nexperience or advice from others, or construct a candidate utterance by\npredicting how it will be received. However, our experiences are limited and\nbiased, and reasoning about potential outcomes can be difficult and cognitively\nchallenging. In this paper, we explore how we can leverage Large Language Model\n(LLM) simulations to help us communicate better. We propose the\nExplore-Generate-Simulate (EGS) framework, which takes as input any scenario\nwhere an individual is communicating to an audience with a goal they want to\nachieve. EGS (1) explores the solution space by producing a diverse set of\nadvice relevant to the scenario, (2) generates communication candidates\nconditioned on subsets of the advice, and (3) simulates the reactions from\nvarious audiences to determine both the best candidate and advice to use. We\nevaluate the framework on eight scenarios spanning the ten fundamental\nprocesses of interpersonal communication. For each scenario, we collect a\ndataset of human evaluations across candidates and baselines, and showcase that\nour framework's chosen candidate is preferred over popular generation\nmechanisms including Chain-of-Thought. We also find that audience simulations\nachieve reasonably high agreement with human raters across 5 of the 8\nscenarios. Finally, we demonstrate the generality of our framework by applying\nit to real-world scenarios described by users on web forums. Through\nevaluations and demonstrations, we show that EGS enhances the effectiveness and\noutcomes of goal-oriented communication across a variety of situations, thus\nopening up new possibilities for the application of large language models in\nrevolutionizing communication and decision-making processes.",
            "author": [
                "Ryan Liu",
                "Howard Yen",
                "Raja Marjieh",
                "Thomas L. Griffiths",
                "Ranjay Krishna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00687v2",
                "http://arxiv.org/pdf/2311.00687v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00686v1",
            "title": "Little Giants: Exploring the Potential of Small LLMs as Evaluation\n  Metrics in Summarization in the Eval4NLP 2023 Shared Task",
            "updated": "2023-11-01T17:44:35Z",
            "published": "2023-11-01T17:44:35Z",
            "summary": "This paper describes and analyzes our participation in the 2023 Eval4NLP\nshared task, which focuses on assessing the effectiveness of prompt-based\ntechniques to empower Large Language Models to handle the task of quality\nestimation, particularly in the context of evaluating machine translations and\nsummaries. We conducted systematic experiments with various prompting\ntechniques, including standard prompting, prompts informed by annotator\ninstructions, and innovative chain-of-thought prompting. In addition, we\nintegrated these approaches with zero-shot and one-shot learning methods to\nmaximize the efficacy of our evaluation procedures. Our work reveals that\ncombining these approaches using a \"small\", open source model (orca_mini_v3_7B)\nyields competitive results.",
            "author": [
                "Neema Kotonya",
                "Saran Krishnasamy",
                "Joel Tetreault",
                "Alejandro Jaimes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00686v1",
                "http://arxiv.org/pdf/2311.00686v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00684v2",
            "title": "Attention Alignment and Flexible Positional Embeddings Improve\n  Transformer Length Extrapolation",
            "updated": "2023-11-15T15:55:02Z",
            "published": "2023-11-01T17:43:35Z",
            "summary": "An ideal length-extrapolatable Transformer language model can handle\nsequences longer than the training length without any fine-tuning. Such\nlong-context utilization capability relies heavily on a flexible positional\nembedding design. Upon investigating the flexibility of existing large\npre-trained Transformer language models, we find that the T5 family deserves a\ncloser look, as its positional embeddings capture rich and flexible attention\npatterns. However, T5 suffers from the dispersed attention issue: the longer\nthe input sequence, the flatter the attention distribution. To alleviate the\nissue, we propose two attention alignment strategies via temperature scaling.\nOur findings show improvement on the long-context utilization capability of T5\non language modeling, retrieval, multi-document question answering, and code\ncompletion tasks without any fine-tuning. This suggests that a flexible\npositional embedding design and attention alignment can go a long way toward\nTransformer length extrapolation.",
            "author": [
                "Ta-Chung Chi",
                "Ting-Han Fan",
                "Alexander I. Rudnicky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00684v2",
                "http://arxiv.org/pdf/2311.00684v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00682v1",
            "title": "Deep Learning-Based Classification of Gamma Photon Interactions in\n  Room-Temperature Semiconductor Radiation Detectors",
            "updated": "2023-11-01T17:42:56Z",
            "published": "2023-11-01T17:42:56Z",
            "summary": "Photon counting radiation detectors have become an integral part of medical\nimaging modalities such as Positron Emission Tomography or Computed Tomography.\nOne of the most promising detectors is the wide bandgap room temperature\nsemiconductor detectors, which depends on the interaction gamma/x-ray photons\nwith the detector material involves Compton scattering which leads to multiple\ninteraction photon events (MIPEs) of a single photon. For semiconductor\ndetectors like CdZnTeSe (CZTS), which have a high overlap of detected energies\nbetween Compton and photoelectric events, it is nearly impossible to\ndistinguish between Compton scattered events from photoelectric events using\nconventional readout electronics or signal processing algorithms. Herein, we\nreport a deep learning classifier CoPhNet that distinguishes between Compton\nscattering and photoelectric interactions of gamma/x-ray photons with CdZnTeSe\n(CZTS) semiconductor detectors. Our CoPhNet model was trained using simulated\ndata to resemble actual CZTS detector pulses and validated using both simulated\nand experimental data. These results demonstrated that our CoPhNet model can\nachieve high classification accuracy over the simulated test set. It also holds\nits performance robustness under operating parameter shifts such as\nSignal-Noise-Ratio (SNR) and incident energy. Our work thus laid solid\nfoundation for developing next-generation high energy gamma-rays detectors for\nbetter biomedical imaging.",
            "author": [
                "Sandeep K. Chaudhuri",
                "Qinyang Li",
                "Krishna C. Mandal",
                "Jianjun Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00682v1",
                "http://arxiv.org/pdf/2311.00682v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00678v1",
            "title": "Complexity of Single Loop Algorithms for Nonlinear Programming with\n  Stochastic Objective and Constraints",
            "updated": "2023-11-01T17:37:41Z",
            "published": "2023-11-01T17:37:41Z",
            "summary": "We analyze the complexity of single-loop quadratic penalty and augmented\nLagrangian algorithms for solving nonconvex optimization problems with\nfunctional equality constraints. We consider three cases, in all of which the\nobjective is stochastic and smooth, that is, an expectation over an unknown\ndistribution that is accessed by sampling. The nature of the equality\nconstraints differs among the three cases: deterministic and linear in the\nfirst case, deterministic, smooth and nonlinear in the second case, and\nstochastic, smooth and nonlinear in the third case. Variance reduction\ntechniques are used to improve the complexity. To find a point that satisfies\n$\\varepsilon$-approximate first-order conditions, we require\n$\\widetilde{O}(\\varepsilon^{-3})$ complexity in the first case,\n$\\widetilde{O}(\\varepsilon^{-4})$ in the second case, and\n$\\widetilde{O}(\\varepsilon^{-5})$ in the third case. For the first and third\ncases, they are the first algorithms of \"single loop\" type (that also use\n$O(1)$ samples at each iteration) that still achieve the best-known complexity\nguarantees.",
            "author": [
                "Ahmet Alacaoglu",
                "Stephen J. Wright"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00678v1",
                "http://arxiv.org/pdf/2311.00678v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16131v1",
            "title": "Secure Arcade: A Gamified Defense Against Cyber Attacks",
            "updated": "2023-11-01T17:35:49Z",
            "published": "2023-11-01T17:35:49Z",
            "summary": "In modernity, we continually receive increasingly intricate technologies that\nallow us to increase our lives convenience and efficiency. Our technology,\nparticularly technology available over the internet, is advancing at\nunprecedented speed. However, this speed of advancement allows those behind\nmalicious attacks to have an increasingly easier time taking advantage of those\nwho know little about computer security. Unfortunately, education in the\ncomputer security field is generally limited only to tertiary education. This\nresearch addresses this problem through a gamified web-based application that\ndrives users to reach learning goals to help them become more vigilant internet\nusers: 1. Learn and memorize general computer security terminology, 2. Become\nfamiliar with basic cryptography concepts, 3. Learn to recognize potential\nphishing scams via email quickly, and 4. Learn common attacks on servers and\nhow to deal with them.",
            "author": [
                "Sean Loesch",
                "Ryan Hrastich",
                "Jordan Herbert",
                "Ben Drangstveit",
                "Jacob Weber",
                "Mounika Vanamala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16131v1",
                "http://arxiv.org/pdf/2311.16131v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00676v1",
            "title": "Last-Iterate Convergence Properties of Regret-Matching Algorithms in\n  Games",
            "updated": "2023-11-01T17:34:58Z",
            "published": "2023-11-01T17:34:58Z",
            "summary": "Algorithms based on regret matching, specifically regret matching$^+$\n(RM$^+$), and its variants are the most popular approaches for solving\nlarge-scale two-player zero-sum games in practice. Unlike algorithms such as\noptimistic gradient descent ascent, which have strong last-iterate and ergodic\nconvergence properties for zero-sum games, virtually nothing is known about the\nlast-iterate properties of regret-matching algorithms. Given the importance of\nlast-iterate convergence for numerical optimization reasons and relevance as\nmodeling real-word learning in games, in this paper, we study the last-iterate\nconvergence properties of various popular variants of RM$^+$. First, we show\nnumerically that several practical variants such as simultaneous RM$^+$,\nalternating RM$^+$, and simultaneous predictive RM$^+$, all lack last-iterate\nconvergence guarantees even on a simple $3\\times 3$ game. We then prove that\nrecent variants of these algorithms based on a smoothing technique do enjoy\nlast-iterate convergence: we prove that extragradient RM$^{+}$ and smooth\nPredictive RM$^+$ enjoy asymptotic last-iterate convergence (without a rate)\nand $1/\\sqrt{t}$ best-iterate convergence. Finally, we introduce restarted\nvariants of these algorithms, and show that they enjoy linear-rate last-iterate\nconvergence.",
            "author": [
                "Yang Cai",
                "Gabriele Farina",
                "Julien Grand-Cl\u00e9ment",
                "Christian Kroer",
                "Chung-Wei Lee",
                "Haipeng Luo",
                "Weiqiang Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00676v1",
                "http://arxiv.org/pdf/2311.00676v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00674v1",
            "title": "Recovering Linear Causal Models with Latent Variables via Cholesky\n  Factorization of Covariance Matrix",
            "updated": "2023-11-01T17:27:49Z",
            "published": "2023-11-01T17:27:49Z",
            "summary": "Discovering the causal relationship via recovering the directed acyclic graph\n(DAG) structure from the observed data is a well-known challenging\ncombinatorial problem. When there are latent variables, the problem becomes\neven more difficult. In this paper, we first propose a DAG structure recovering\nalgorithm, which is based on the Cholesky factorization of the covariance\nmatrix of the observed data. The algorithm is fast and easy to implement and\nhas theoretical grantees for exact recovery. On synthetic and real-world\ndatasets, the algorithm is significantly faster than previous methods and\nachieves the state-of-the-art performance. Furthermore, under the equal error\nvariances assumption, we incorporate an optimization procedure into the\nCholesky factorization based algorithm to handle the DAG recovering problem\nwith latent variables. Numerical simulations show that the modified \"Cholesky +\noptimization\" algorithm is able to recover the ground truth graph in most cases\nand outperforms existing algorithms.",
            "author": [
                "Yunfeng Cai",
                "Xu Li",
                "Minging Sun",
                "Ping Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00674v1",
                "http://arxiv.org/pdf/2311.00674v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00668v1",
            "title": "ProcSim: Proxy-based Confidence for Robust Similarity Learning",
            "updated": "2023-11-01T17:17:14Z",
            "published": "2023-11-01T17:17:14Z",
            "summary": "Deep Metric Learning (DML) methods aim at learning an embedding space in\nwhich distances are closely related to the inherent semantic similarity of the\ninputs. Previous studies have shown that popular benchmark datasets often\ncontain numerous wrong labels, and DML methods are susceptible to them.\nIntending to study the effect of realistic noise, we create an ontology of the\nclasses in a dataset and use it to simulate semantically coherent labeling\nmistakes. To train robust DML models, we propose ProcSim, a simple framework\nthat assigns a confidence score to each sample using the normalized distance to\nits class representative. The experimental results show that the proposed\nmethod achieves state-of-the-art performance on the DML benchmark datasets\ninjected with uniform and the proposed semantically coherent noise.",
            "author": [
                "Oriol Barbany",
                "Xiaofan Lin",
                "Muhammet Bastan",
                "Arnab Dhua"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00668v1",
                "http://arxiv.org/pdf/2311.00668v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00664v1",
            "title": "Latent Space Translation via Semantic Alignment",
            "updated": "2023-11-01T17:12:00Z",
            "published": "2023-11-01T17:12:00Z",
            "summary": "While different neural models often exhibit latent spaces that are alike when\nexposed to semantically related data, this intrinsic similarity is not always\nimmediately discernible. Towards a better understanding of this phenomenon, our\nwork shows how representations learned from these neural modules can be\ntranslated between different pre-trained networks via simpler transformations\nthan previously thought. An advantage of this approach is the ability to\nestimate these transformations using standard, well-understood algebraic\nprocedures that have closed-form solutions. Our method directly estimates a\ntransformation between two given latent spaces, thereby enabling effective\nstitching of encoders and decoders without additional training. We extensively\nvalidate the adaptability of this translation procedure in different\nexperimental settings: across various trainings, domains, architectures (e.g.,\nResNet, CNN, ViT), and in multiple downstream tasks (classification,\nreconstruction). Notably, we show how it is possible to zero-shot stitch text\nencoders and vision decoders, or vice-versa, yielding surprisingly good\nclassification performance in this multimodal setting.",
            "author": [
                "Valentino Maiorca",
                "Luca Moschella",
                "Antonio Norelli",
                "Marco Fumero",
                "Francesco Locatello",
                "Emanuele Rodol\u00e0"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00664v1",
                "http://arxiv.org/pdf/2311.00664v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00663v1",
            "title": "Variational Gaussian Processes For Linear Inverse Problems",
            "updated": "2023-11-01T17:10:38Z",
            "published": "2023-11-01T17:10:38Z",
            "summary": "By now Bayesian methods are routinely used in practice for solving inverse\nproblems. In inverse problems the parameter or signal of interest is observed\nonly indirectly, as an image of a given map, and the observations are typically\nfurther corrupted with noise. Bayes offers a natural way to regularize these\nproblems via the prior distribution and provides a probabilistic solution,\nquantifying the remaining uncertainty in the problem. However, the\ncomputational costs of standard, sampling based Bayesian approaches can be\noverly large in such complex models. Therefore, in practice variational Bayes\nis becoming increasingly popular. Nevertheless, the theoretical understanding\nof these methods is still relatively limited, especially in context of inverse\nproblems. In our analysis we investigate variational Bayesian methods for\nGaussian process priors to solve linear inverse problems. We consider both\nmildly and severely ill-posed inverse problems and work with the popular\ninducing variables variational Bayes approach proposed by Titsias in 2009. We\nderive posterior contraction rates for the variational posterior in general\nsettings and show that the minimax estimation rate can be attained by correctly\ntunned procedures. As specific examples we consider a collection of inverse\nproblems including the heat equation, Volterra operator and Radon transform and\ninducing variable methods based on population and empirical spectral features.",
            "author": [
                "Thibault Randrianarisoa",
                "Botond Szabo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00663v1",
                "http://arxiv.org/pdf/2311.00663v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ML",
                "stat.TH",
                "62G08"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00660v3",
            "title": "TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining\n  and Object Detection in Rain",
            "updated": "2023-11-08T02:46:34Z",
            "published": "2023-11-01T17:08:26Z",
            "summary": "Rain generation algorithms have the potential to improve the generalization\nof deraining methods and scene understanding in rainy conditions. However, in\npractice, they produce artifacts and distortions and struggle to control the\namount of rain generated due to a lack of proper constraints. In this paper, we\npropose an unpaired image-to-image translation framework for generating\nrealistic rainy images. We first introduce a Triangular Probability Similarity\n(TPS) constraint to guide the generated images toward clear and rainy images in\nthe discriminator manifold, thereby minimizing artifacts and distortions during\nrain generation. Unlike conventional contrastive learning approaches, which\nindiscriminately push negative samples away from the anchors, we propose a\nSemantic Noise Contrastive Estimation (SeNCE) strategy and reassess the pushing\nforce of negative samples based on the semantic similarity between the clear\nand the rainy images and the feature similarity between the anchor and the\nnegative samples. Experiments demonstrate realistic rain generation with\nminimal artifacts and distortions, which benefits image deraining and object\ndetection in rain. Furthermore, the method can be used to generate realistic\nsnowy and night images, underscoring its potential for broader applicability.\nCode is available at https://github.com/ShenZheng2000/TPSeNCE.",
            "author": [
                "Shen Zheng",
                "Changjie Lu",
                "Srinivasa G. Narasimhan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00660v3",
                "http://arxiv.org/pdf/2311.00660v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00656v1",
            "title": "Online Signal Estimation on the Graph Edges via Line Graph\n  Transformation",
            "updated": "2023-11-01T17:02:41Z",
            "published": "2023-11-01T17:02:41Z",
            "summary": "We propose the Line Graph Normalized Least Mean Square (LGNLMS) algorithm for\nonline time-varying graph edge signals prediction. LGNLMS utilizes the Line\nGraph to transform graph edge signals into the node of its edge-to-vertex dual.\nThis enables edge signals to be processed using established GSP concepts\nwithout redefining them on graph edges.",
            "author": [
                "Yi Yan",
                "Ercan Engin Kuruoglu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00656v1",
                "http://arxiv.org/pdf/2311.00656v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00651v2",
            "title": "Emergence of Collective Open-Ended Exploration from Decentralized\n  Meta-Reinforcement Learning",
            "updated": "2023-11-02T10:35:33Z",
            "published": "2023-11-01T16:56:44Z",
            "summary": "Recent works have proven that intricate cooperative behaviors can emerge in\nagents trained using meta reinforcement learning on open ended task\ndistributions using self-play. While the results are impressive, we argue that\nself-play and other centralized training techniques do not accurately reflect\nhow general collective exploration strategies emerge in the natural world:\nthrough decentralized training and over an open-ended distribution of tasks. In\nthis work we therefore investigate the emergence of collective exploration\nstrategies, where several agents meta-learn independent recurrent policies on\nan open ended distribution of tasks. To this end we introduce a novel\nenvironment with an open ended procedurally generated task space which\ndynamically combines multiple subtasks sampled from five diverse task types to\nform a vast distribution of task trees. We show that decentralized agents\ntrained in our environment exhibit strong generalization abilities when\nconfronted with novel objects at test time. Additionally, despite never being\nforced to cooperate during training the agents learn collective exploration\nstrategies which allow them to solve novel tasks never encountered during\ntraining. We further find that the agents learned collective exploration\nstrategies extend to an open ended task setting, allowing them to solve task\ntrees of twice the depth compared to the ones seen during training. Our open\nsource code as well as videos of the agents can be found on our companion\nwebsite.",
            "author": [
                "Richard Bornemann",
                "Gautier Hamon",
                "Eleni Nisioti",
                "Cl\u00e9ment Moulin-Frier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00651v2",
                "http://arxiv.org/pdf/2311.00651v2"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06285v1",
            "title": "Sounding Bodies: Modeling 3D Spatial Sound of Humans Using Body Pose and\n  Audio",
            "updated": "2023-11-01T16:40:35Z",
            "published": "2023-11-01T16:40:35Z",
            "summary": "While 3D human body modeling has received much attention in computer vision,\nmodeling the acoustic equivalent, i.e. modeling 3D spatial audio produced by\nbody motion and speech, has fallen short in the community. To close this gap,\nwe present a model that can generate accurate 3D spatial audio for full human\nbodies. The system consumes, as input, audio signals from headset microphones\nand body pose, and produces, as output, a 3D sound field surrounding the\ntransmitter's body, from which spatial audio can be rendered at any arbitrary\nposition in the 3D space. We collect a first-of-its-kind multimodal dataset of\nhuman bodies, recorded with multiple cameras and a spherical array of 345\nmicrophones. In an empirical evaluation, we demonstrate that our model can\nproduce accurate body-induced sound fields when trained with a suitable loss.\nDataset and code are available online.",
            "author": [
                "Xudong Xu",
                "Dejan Markovic",
                "Jacob Sandakly",
                "Todd Keebler",
                "Steven Krenn",
                "Alexander Richard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06285v1",
                "http://arxiv.org/pdf/2311.06285v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00638v1",
            "title": "FAIRLABEL: Correcting Bias in Labels",
            "updated": "2023-11-01T16:38:27Z",
            "published": "2023-11-01T16:38:27Z",
            "summary": "There are several algorithms for measuring fairness of ML models. A\nfundamental assumption in these approaches is that the ground truth is fair or\nunbiased. In real-world datasets, however, the ground truth often contains data\nthat is a result of historical and societal biases and discrimination. Models\ntrained on these datasets will inherit and propagate the biases to the model\noutputs. We propose FAIRLABEL, an algorithm which detects and corrects biases\nin labels. The goal of FAIRLABELis to reduce the Disparate Impact (DI) across\ngroups while maintaining high accuracy in predictions. We propose metrics to\nmeasure the quality of bias correction and validate FAIRLABEL on synthetic\ndatasets and show that the label correction is correct 86.7% of the time vs.\n71.9% for a baseline model. We also apply FAIRLABEL on benchmark datasets such\nas UCI Adult, German Credit Risk, and Compas datasets and show that the\nDisparate Impact Ratio increases by as much as 54.2%.",
            "author": [
                "Srinivasan H Sengamedu",
                "Hien Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00638v1",
                "http://arxiv.org/pdf/2311.00638v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68T07",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00636v1",
            "title": "Kronecker-Factored Approximate Curvature for Modern Neural Network\n  Architectures",
            "updated": "2023-11-01T16:37:00Z",
            "published": "2023-11-01T16:37:00Z",
            "summary": "The core components of many modern neural network architectures, such as\ntransformers, convolutional, or graph neural networks, can be expressed as\nlinear layers with $\\textit{weight-sharing}$. Kronecker-Factored Approximate\nCurvature (K-FAC), a second-order optimisation method, has shown promise to\nspeed up neural network training and thereby reduce computational costs.\nHowever, there is currently no framework to apply it to generic architectures,\nspecifically ones with linear weight-sharing layers. In this work, we identify\ntwo different settings of linear weight-sharing layers which motivate two\nflavours of K-FAC -- $\\textit{expand}$ and $\\textit{reduce}$. We show that they\nare exact for deep linear networks with weight-sharing in their respective\nsetting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we\nleverage to speed up automatic hyperparameter selection via optimising the\nmarginal likelihood for a Wide ResNet. Finally, we observe little difference\nbetween these two K-FAC variations when using them to train both a graph neural\nnetwork and a vision transformer. However, both variations are able to reach a\nfixed validation metric target in $50$-$75\\%$ of the number of steps of a\nfirst-order reference run, which translates into a comparable improvement in\nwall-clock time. This highlights the potential of applying K-FAC to modern\nneural network architectures.",
            "author": [
                "Runa Eschenhagen",
                "Alexander Immer",
                "Richard E. Turner",
                "Frank Schneider",
                "Philipp Hennig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00636v1",
                "http://arxiv.org/pdf/2311.00636v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00634v2",
            "title": "A Bi-level Framework for Traffic Accident Duration Prediction:\n  Leveraging Weather and Road Condition Data within a Practical Optimum\n  Pipeline",
            "updated": "2023-11-03T19:26:03Z",
            "published": "2023-11-01T16:33:37Z",
            "summary": "Due to the stochastic nature of events, predicting the duration of a traffic\nincident presents a formidable challenge. Accurate duration estimation can\nresult in substantial advantages for commuters in selecting optimal routes and\nfor traffic management personnel in addressing non-recurring congestion issues.\nIn this study, we gathered accident duration, road conditions, and\nmeteorological data from a database of traffic accidents to check the\nfeasibility of a traffic accident duration pipeline without accident contextual\ninformation data like accident severity and textual description. Multiple\nmachine learning models were employed to predict whether an accident's impact\non road traffic would be of a short-term or long-term nature, and then\nutilizing a bimodal approach the precise duration of the incident's effect was\ndetermined. Our binary classification random forest model distinguished between\nshort-term and long-term effects with an 83% accuracy rate, while the LightGBM\nregression model outperformed other machine learning regression models with\nMean Average Error (MAE) values of 26.15 and 13.3 and RMSE values of 32.91 and\n28.91 for short and long-term accident duration prediction, respectively. Using\nthe optimal classification and regression model identified in the preceding\nsection, we then construct an end-to-end pipeline to incorporate the entire\nprocess. The results of both separate and combined approaches were comparable\nwith previous works, which shows the applicability of only using static\nfeatures for predicting traffic accident duration. The SHAP value analysis\nidentified weather conditions, wind chill and wind speed as the most\ninfluential factors in determining the duration of an accident.",
            "author": [
                "Rafat Tabassum Sukonna",
                "Soham Irtiza Swapnil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00634v2",
                "http://arxiv.org/pdf/2311.00634v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00633v1",
            "title": "Ab initio machine-learning unveils strong anharmonicity in non-Arrhenius\n  self-diffusion of tungsten",
            "updated": "2023-11-01T16:31:01Z",
            "published": "2023-11-01T16:31:01Z",
            "summary": "We propose an efficient ab initio framework to compute the Gibbs energy of\nthe transition state in vacancy-mediated diffusion including the relevant\nthermal excitations at density-functional-theory level. With the aid of a\nbespoke machine-learning interatomic potential, the temperature-dependent\nvacancy formation and migration Gibbs energies of the prototype system bcc\ntungsten are shown to be strongly affected by anharmonicity. This explains the\nphysical origin of the experimentally observed non-Arrhenius behavior of W\nself-diffusion as a case study. The good agreement of the self-diffusivity with\nexperiment demonstrates that accurate ab initio diffusion databases are in\nreach.",
            "author": [
                "Xi Zhang",
                "Sergiy V. Divinski",
                "Blazej Grabowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00633v1",
                "http://arxiv.org/pdf/2311.00633v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00619v2",
            "title": "Loss Modeling for Multi-Annotator Datasets",
            "updated": "2023-11-16T05:31:27Z",
            "published": "2023-11-01T16:14:34Z",
            "summary": "Accounting for the opinions of all annotators of a dataset is critical for\nfairness. However, when annotating large datasets, individual annotators will\nfrequently provide thousands of ratings which can lead to fatigue.\nAdditionally, these annotation processes can occur over multiple days which can\nlead to an inaccurate representation of an annotator's opinion over time. To\ncombat this, we propose to learn a more accurate representation of diverse\nopinions by utilizing multitask learning in conjunction with loss-based label\ncorrection. We show that using our novel formulation, we can cleanly separate\nagreeing and disagreeing annotations. Furthermore, we demonstrate that this\nmodification can improve prediction performance in a single or multi-annotator\nsetting. Lastly, we show that this method remains robust to additional label\nnoise that is applied to subjective data.",
            "author": [
                "Uthman Jinadu",
                "Jesse Annan",
                "Shanshan Wen",
                "Yi Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00619v2",
                "http://arxiv.org/pdf/2311.00619v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00613v2",
            "title": "Controllable Music Production with Diffusion Models and Guidance\n  Gradients",
            "updated": "2023-12-05T10:32:03Z",
            "published": "2023-11-01T16:01:01Z",
            "summary": "We demonstrate how conditional generation from diffusion models can be used\nto tackle a variety of realistic tasks in the production of music in 44.1kHz\nstereo audio with sampling-time guidance. The scenarios we consider include\ncontinuation, inpainting and regeneration of musical audio, the creation of\nsmooth transitions between two different music tracks, and the transfer of\ndesired stylistic characteristics to existing audio clips. We achieve this by\napplying guidance at sampling time in a simple framework that supports both\nreconstruction and classification losses, or any combination of the two. This\napproach ensures that generated audio can match its surrounding context, or\nconform to a class distribution or latent representation specified relative to\nany suitable pre-trained classifier or embedding model. Audio samples are\navailable at https://machinelearning.apple.com/research/controllable-music",
            "author": [
                "Mark Levy",
                "Bruno Di Giorgi",
                "Floris Weers",
                "Angelos Katharopoulos",
                "Tom Nickson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00613v2",
                "http://arxiv.org/pdf/2311.00613v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00612v1",
            "title": "A Collaborative Filtering-Based Two Stage Model with Item Dependency for\n  Course Recommendation",
            "updated": "2023-11-01T16:01:00Z",
            "published": "2023-11-01T16:01:00Z",
            "summary": "Recommender systems have been studied for decades with numerous promising\nmodels been proposed. Among them, Collaborative Filtering (CF) models are\narguably the most successful one due to its high accuracy in recommendation and\nelimination of privacy-concerned personal meta-data from training. This paper\nextends the usage of CF-based model to the task of course recommendation. We\npoint out several challenges in applying the existing CF-models to build a\ncourse recommendation engine, including the lack of rating and meta-data, the\nimbalance of course registration distribution, and the demand of course\ndependency modeling. We then propose several ideas to address these challenges.\nEventually, we combine a two-stage CF model regularized by course dependency\nwith a graph-based recommender based on course-transition network, to achieve\nAUC as high as 0.97 with a real-world dataset.",
            "author": [
                "Eric L. Lee",
                "Tsung-Ting Kuo",
                "Shou-De Lin"
            ],
            "link": [
                "http://dx.doi.org/10.1109/DSAA.2017.18",
                "http://arxiv.org/abs/2311.00612v1",
                "http://arxiv.org/pdf/2311.00612v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00603v1",
            "title": "Occluded Person Re-Identification with Deep Learning: A Survey and\n  Perspectives",
            "updated": "2023-11-01T15:52:51Z",
            "published": "2023-11-01T15:52:51Z",
            "summary": "Person re-identification (Re-ID) technology plays an increasingly crucial\nrole in intelligent surveillance systems. Widespread occlusion significantly\nimpacts the performance of person Re-ID. Occluded person Re-ID refers to a\npedestrian matching method that deals with challenges such as pedestrian\ninformation loss, noise interference, and perspective misalignment. It has\ngarnered extensive attention from researchers. Over the past few years, several\nocclusion-solving person Re-ID methods have been proposed, tackling various\nsub-problems arising from occlusion. However, there is a lack of comprehensive\nstudies that compare, summarize, and evaluate the potential of occluded person\nRe-ID methods in detail. In this review, we start by providing a detailed\noverview of the datasets and evaluation scheme used for occluded person Re-ID.\nNext, we scientifically classify and analyze existing deep learning-based\noccluded person Re-ID methods from various perspectives, summarizing them\nconcisely. Furthermore, we conduct a systematic comparison among these methods,\nidentify the state-of-the-art approaches, and present an outlook on the future\ndevelopment of occluded person Re-ID.",
            "author": [
                "Enhao Ning",
                "Changshuo Wang",
                "Huang Zhangc",
                "Xin Ning",
                "Prayag Tiwari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00603v1",
                "http://arxiv.org/pdf/2311.00603v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00599v1",
            "title": "Structure Learning with Adaptive Random Neighborhood Informed MCMC",
            "updated": "2023-11-01T15:47:18Z",
            "published": "2023-11-01T15:47:18Z",
            "summary": "In this paper, we introduce a novel MCMC sampler, PARNI-DAG, for a\nfully-Bayesian approach to the problem of structure learning under\nobservational data. Under the assumption of causal sufficiency, the algorithm\nallows for approximate sampling directly from the posterior distribution on\nDirected Acyclic Graphs (DAGs). PARNI-DAG performs efficient sampling of DAGs\nvia locally informed, adaptive random neighborhood proposal that results in\nbetter mixing properties. In addition, to ensure better scalability with the\nnumber of nodes, we couple PARNI-DAG with a pre-tuning procedure of the\nsampler's parameters that exploits a skeleton graph derived through some\nconstraint-based or scoring-based algorithms. Thanks to these novel features,\nPARNI-DAG quickly converges to high-probability regions and is less likely to\nget stuck in local modes in the presence of high correlation between nodes in\nhigh-dimensional settings. After introducing the technical novelties in\nPARNI-DAG, we empirically demonstrate its mixing efficiency and accuracy in\nlearning DAG structures on a variety of experiments.",
            "author": [
                "Alberto Caron",
                "Xitong Liang",
                "Samuel Livingstone",
                "Jim Griffin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00599v1",
                "http://arxiv.org/pdf/2311.00599v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00594v1",
            "title": "Rethinking Variational Inference for Probabilistic Programs with\n  Stochastic Support",
            "updated": "2023-11-01T15:38:51Z",
            "published": "2023-11-01T15:38:51Z",
            "summary": "We introduce Support Decomposition Variational Inference (SDVI), a new\nvariational inference (VI) approach for probabilistic programs with stochastic\nsupport. Existing approaches to this problem rely on designing a single global\nvariational guide on a variable-by-variable basis, while maintaining the\nstochastic control flow of the original program. SDVI instead breaks the\nprogram down into sub-programs with static support, before automatically\nbuilding separate sub-guides for each. This decomposition significantly aids in\nthe construction of suitable variational families, enabling, in turn,\nsubstantial improvements in inference performance.",
            "author": [
                "Tim Reichelt",
                "Luke Ong",
                "Tom Rainforth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00594v1",
                "http://arxiv.org/pdf/2311.00594v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00591v1",
            "title": "Coop: Memory is not a Commodity",
            "updated": "2023-11-01T15:35:51Z",
            "published": "2023-11-01T15:35:51Z",
            "summary": "Tensor rematerialization allows the training of deep neural networks (DNNs)\nunder limited memory budgets by checkpointing the models and recomputing the\nevicted tensors as needed. However, the existing tensor rematerialization\ntechniques overlook the memory system in deep learning frameworks and\nimplicitly assume that free memory blocks at different addresses are identical.\nUnder this flawed assumption, discontiguous tensors are evicted, among which\nsome are not used to allocate the new tensor. This leads to severe memory\nfragmentation and increases the cost of potential rematerializations. To\naddress this issue, we propose to evict tensors within a sliding window to\nensure all evictions are contiguous and are immediately used. Furthermore, we\nproposed cheap tensor partitioning and recomputable in-place to further reduce\nthe rematerialization cost by optimizing the tensor allocation. We named our\nmethod Coop as it is a co-optimization of tensor allocation and tensor\nrematerialization. We evaluated Coop on eight representative DNNs. The\nexperimental results demonstrate that Coop achieves up to $2\\times$ memory\nsaving and hugely reduces compute overhead, search latency, and memory\nfragmentation compared to the state-of-the-art baselines.",
            "author": [
                "Jianhao Zhang",
                "Shihan Ma",
                "Peihong Liu",
                "Jinhui Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00591v1",
                "http://arxiv.org/pdf/2311.00591v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00587v2",
            "title": "Crosslingual Retrieval Augmented In-context Learning for Bangla",
            "updated": "2023-12-02T16:54:23Z",
            "published": "2023-11-01T15:32:50Z",
            "summary": "The promise of Large Language Models (LLMs) in Natural Language Processing\nhas often been overshadowed by their limited performance in low-resource\nlanguages such as Bangla. To address this, our paper presents a pioneering\napproach that utilizes cross-lingual retrieval augmented in-context learning.\nBy strategically sourcing semantically similar prompts from high-resource\nlanguage, we enable multilingual pretrained language models (MPLMs), especially\nthe generative model BLOOMZ, to successfully boost performance on Bangla tasks.\nOur extensive evaluation highlights that the cross-lingual retrieval augmented\nprompts bring steady improvements to MPLMs over the zero-shot performance.",
            "author": [
                "Xiaoqian Li",
                "Ercong Nie",
                "Sheng Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00587v2",
                "http://arxiv.org/pdf/2311.00587v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00580v1",
            "title": "Flexible Tails for Normalising Flows, with Application to the Modelling\n  of Financial Return Data",
            "updated": "2023-11-01T15:27:08Z",
            "published": "2023-11-01T15:27:08Z",
            "summary": "We propose a transformation capable of altering the tail properties of a\ndistribution, motivated by extreme value theory, which can be used as a layer\nin a normalizing flow to approximate multivariate heavy tailed distributions.\nWe apply this approach to model financial returns, capturing potentially\nextreme shocks that arise in such data. The trained models can be used directly\nto generate new synthetic sets of potentially extreme returns",
            "author": [
                "Tennessee Hickling",
                "Dennis Prangle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00580v1",
                "http://arxiv.org/pdf/2311.00580v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00579v1",
            "title": "Revealing CNN Architectures via Side-Channel Analysis in Dataflow-based\n  Inference Accelerators",
            "updated": "2023-11-01T15:23:04Z",
            "published": "2023-11-01T15:23:04Z",
            "summary": "Convolution Neural Networks (CNNs) are widely used in various domains. Recent\nadvances in dataflow-based CNN accelerators have enabled CNN inference in\nresource-constrained edge devices. These dataflow accelerators utilize inherent\ndata reuse of convolution layers to process CNN models efficiently. Concealing\nthe architecture of CNN models is critical for privacy and security. This paper\nevaluates memory-based side-channel information to recover CNN architectures\nfrom dataflow-based CNN inference accelerators. The proposed attack exploits\nspatial and temporal data reuse of the dataflow mapping on CNN accelerators and\narchitectural hints to recover the structure of CNN models. Experimental\nresults demonstrate that our proposed side-channel attack can recover the\nstructures of popular CNN models, namely Lenet, Alexnet, and VGGnet16.",
            "author": [
                "Hansika Weerasena",
                "Prabhat Mishra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00579v1",
                "http://arxiv.org/pdf/2311.00579v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00578v1",
            "title": "Transfer learning for improved generalizability in causal\n  physics-informed neural networks for beam simulations",
            "updated": "2023-11-01T15:19:54Z",
            "published": "2023-11-01T15:19:54Z",
            "summary": "This paper introduces a novel methodology for simulating the dynamics of\nbeams on elastic foundations. Specifically, Euler-Bernoulli and Timoshenko beam\nmodels on the Winkler foundation are simulated using a transfer learning\napproach within a causality-respecting physics-informed neural network (PINN)\nframework. Conventional PINNs encounter challenges in handling large space-time\ndomains, even for problems with closed-form analytical solutions. A\ncausality-respecting PINN loss function is employed to overcome this\nlimitation, effectively capturing the underlying physics. However, it is\nobserved that the causality-respecting PINN lacks generalizability. We propose\nusing solutions to similar problems instead of training from scratch by\nemploying transfer learning while adhering to causality to accelerate\nconvergence and ensure accurate results across diverse scenarios. Numerical\nexperiments on the Euler-Bernoulli beam highlight the efficacy of the proposed\napproach for various initial conditions, including those with noise in the\ninitial data. Furthermore, the potential of the proposed method is demonstrated\nfor the Timoshenko beam in an extended spatial and temporal domain. Several\ncomparisons suggest that the proposed method accurately captures the inherent\ndynamics, outperforming the state-of-the-art physics-informed methods under\nstandard $L^2$-norm metric and accelerating convergence.",
            "author": [
                "Taniya Kapoor",
                "Hongrui Wang",
                "Alfredo Nunez",
                "Rolf Dollevoet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00578v1",
                "http://arxiv.org/pdf/2311.00578v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00577v1",
            "title": "Personalized Assignment to One of Many Treatment Arms via Regularized\n  and Clustered Joint Assignment Forests",
            "updated": "2023-11-01T15:18:22Z",
            "published": "2023-11-01T15:18:22Z",
            "summary": "We consider learning personalized assignments to one of many treatment arms\nfrom a randomized controlled trial. Standard methods that estimate\nheterogeneous treatment effects separately for each arm may perform poorly in\nthis case due to excess variance. We instead propose methods that pool\ninformation across treatment arms: First, we consider a regularized\nforest-based assignment algorithm based on greedy recursive partitioning that\nshrinks effect estimates across arms. Second, we augment our algorithm by a\nclustering scheme that combines treatment arms with consistently similar\noutcomes. In a simulation study, we compare the performance of these approaches\nto predicting arm-wise outcomes separately, and document gains of directly\noptimizing the treatment assignment with regularization and clustering. In a\ntheoretical model, we illustrate how a high number of treatment arms makes\nfinding the best arm hard, while we can achieve sizable utility gains from\npersonalization by regularized optimization.",
            "author": [
                "Rahul Ladhania",
                "Jann Spiess",
                "Lyle Ungar",
                "Wenbo Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00577v1",
                "http://arxiv.org/pdf/2311.00577v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "econ.EM",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00739v1",
            "title": "Can Large Language Models Design Accurate Label Functions?",
            "updated": "2023-11-01T15:14:46Z",
            "published": "2023-11-01T15:14:46Z",
            "summary": "Programmatic weak supervision methodologies facilitate the expedited labeling\nof extensive datasets through the use of label functions (LFs) that encapsulate\nheuristic data sources. Nonetheless, the creation of precise LFs necessitates\ndomain expertise and substantial endeavors. Recent advances in pre-trained\nlanguage models (PLMs) have exhibited substantial potential across diverse\ntasks. However, the capacity of PLMs to autonomously formulate accurate LFs\nremains an underexplored domain. In this research, we address this gap by\nintroducing DataSculpt, an interactive framework that harnesses PLMs for the\nautomated generation of LFs. Within DataSculpt, we incorporate an array of\nprompting techniques, instance selection strategies, and LF filtration methods\nto explore the expansive design landscape. Ultimately, we conduct a thorough\nassessment of DataSculpt's performance on 12 real-world datasets, encompassing\na range of tasks. This evaluation unveils both the strengths and limitations of\ncontemporary PLMs in LF design.",
            "author": [
                "Naiqing Guan",
                "Kaiwen Chen",
                "Nick Koudas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00739v1",
                "http://arxiv.org/pdf/2311.00739v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DB",
                "cs.LG",
                "H.2.8; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00568v1",
            "title": "Scalable kernel balancing weights in a nationwide observational study of\n  hospital profit status and heart attack outcomes",
            "updated": "2023-11-01T15:08:52Z",
            "published": "2023-11-01T15:08:52Z",
            "summary": "Weighting is a general and often-used method for statistical adjustment.\nWeighting has two objectives: first, to balance covariate distributions, and\nsecond, to ensure that the weights have minimal dispersion and thus produce a\nmore stable estimator. A recent, increasingly common approach directly\noptimizes the weights toward these two objectives. However, this approach has\nnot yet been feasible in large-scale datasets when investigators wish to\nflexibly balance general basis functions in an extended feature space. For\nexample, many balancing approaches cannot scale to national-level health\nservices research studies. To address this practical problem, we describe a\nscalable and flexible approach to weighting that integrates a basis expansion\nin a reproducing kernel Hilbert space with state-of-the-art convex optimization\ntechniques. Specifically, we use the rank-restricted Nystr\\\"{o}m method to\nefficiently compute a kernel basis for balancing in {nearly} linear time and\nspace, and then use the specialized first-order alternating direction method of\nmultipliers to rapidly find the optimal weights. In an extensive simulation\nstudy, we provide new insights into the performance of weighting estimators in\nlarge datasets, showing that the proposed approach substantially outperforms\nothers in terms of accuracy and speed. Finally, we use this weighting approach\nto conduct a national study of the relationship between hospital profit status\nand heart attack outcomes in a comprehensive dataset of 1.27 million patients.\nWe find that for-profit hospitals use interventional cardiology to treat heart\nattacks at similar rates as other hospitals, but have higher mortality and\nreadmission rates.",
            "author": [
                "Kwangho Kim",
                "Bijan A. Niknam",
                "Jos\u00e9 R. Zubizarreta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00568v1",
                "http://arxiv.org/pdf/2311.00568v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00567v2",
            "title": "A Robust Deep Learning Method with Uncertainty Estimation for the\n  Pathological Classification of Renal Cell Carcinoma based on CT Images",
            "updated": "2023-11-12T17:42:07Z",
            "published": "2023-11-01T15:07:39Z",
            "summary": "Objectives To develop and validate a deep learning-based diagnostic model\nincorporating uncertainty estimation so as to facilitate radiologists in the\npreoperative differentiation of the pathological subtypes of renal cell\ncarcinoma (RCC) based on CT images. Methods Data from 668 consecutive patients,\npathologically proven RCC, were retrospectively collected from Center 1. By\nusing five-fold cross-validation, a deep learning model incorporating\nuncertainty estimation was developed to classify RCC subtypes into clear cell\nRCC (ccRCC), papillary RCC (pRCC), and chromophobe RCC (chRCC). An external\nvalidation set of 78 patients from Center 2 further evaluated the model's\nperformance. Results In the five-fold cross-validation, the model's area under\nthe receiver operating characteristic curve (AUC) for the classification of\nccRCC, pRCC, and chRCC was 0.868 (95% CI: 0.826-0.923), 0.846 (95% CI:\n0.812-0.886), and 0.839 (95% CI: 0.802-0.88), respectively. In the external\nvalidation set, the AUCs were 0.856 (95% CI: 0.838-0.882), 0.787 (95% CI:\n0.757-0.818), and 0.793 (95% CI: 0.758-0.831) for ccRCC, pRCC, and chRCC,\nrespectively. Conclusions The developed deep learning model demonstrated robust\nperformance in predicting the pathological subtypes of RCC, while the\nincorporated uncertainty emphasized the importance of understanding model\nconfidence, which is crucial for assisting clinical decision-making for\npatients with renal tumors. Clinical relevance statement Our deep learning\napproach, integrated with uncertainty estimation, offers clinicians a dual\nadvantage: accurate RCC subtype predictions complemented by diagnostic\nconfidence references, promoting informed decision-making for patients with\nRCC.",
            "author": [
                "Ni Yao",
                "Hang Hu",
                "Kaicong Chen",
                "Chen Zhao",
                "Yuan Guo",
                "Boya Li",
                "Jiaofen Nan",
                "Yanting Li",
                "Chuang Han",
                "Fubao Zhu",
                "Weihua Zhou",
                "Li Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00567v2",
                "http://arxiv.org/pdf/2311.00567v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "physics.med-ph",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00566v1",
            "title": "CROMA: Remote Sensing Representations with Contrastive Radar-Optical\n  Masked Autoencoders",
            "updated": "2023-11-01T15:07:27Z",
            "published": "2023-11-01T15:07:27Z",
            "summary": "A vital and rapidly growing application, remote sensing offers vast yet\nsparsely labeled, spatially aligned multimodal data; this makes self-supervised\nlearning algorithms invaluable. We present CROMA: a framework that combines\ncontrastive and reconstruction self-supervised objectives to learn rich\nunimodal and multimodal representations. Our method separately encodes\nmasked-out multispectral optical and synthetic aperture radar samples --\naligned in space and time -- and performs cross-modal contrastive learning.\nAnother encoder fuses these sensors, producing joint multimodal encodings that\nare used to predict the masked patches via a lightweight decoder. We show that\nthese objectives are complementary when leveraged on spatially aligned\nmultimodal data. We also introduce X- and 2D-ALiBi, which spatially biases our\ncross- and self-attention matrices. These strategies improve representations\nand allow our models to effectively extrapolate to images up to 17.6x larger at\ntest-time. CROMA outperforms the current SoTA multispectral model, evaluated\non: four classification benchmarks -- finetuning (avg. 1.8%), linear (avg.\n2.4%) and nonlinear (avg. 1.4%) probing, kNN classification (avg. 3.5%), and\nK-means clustering (avg. 8.4%); and three segmentation benchmarks (avg. 6.4%).\nCROMA's rich, optionally multimodal representations can be widely leveraged\nacross remote sensing applications.",
            "author": [
                "Anthony Fuller",
                "Koreen Millard",
                "James R. Green"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00566v1",
                "http://arxiv.org/pdf/2311.00566v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00564v1",
            "title": "Online Student-$t$ Processes with an Overall-local Scale Structure for\n  Modelling Non-stationary Data",
            "updated": "2023-11-01T15:02:47Z",
            "published": "2023-11-01T15:02:47Z",
            "summary": "Time-dependent data often exhibit characteristics, such as non-stationarity\nand heavy-tailed errors, that would be inappropriate to model with the typical\nassumptions used in popular models. Thus, more flexible approaches are required\nto be able to accommodate such issues. To this end, we propose a Bayesian\nmixture of student-$t$ processes with an overall-local scale structure for the\ncovariance. Moreover, we use a sequential Monte Carlo (SMC) sampler in order to\nperform online inference as data arrive in real-time. We demonstrate the\nsuperiority of our proposed approach compared to typical Gaussian process-based\nmodels on real-world data sets in order to prove the necessity of using\nmixtures of student-$t$ processes.",
            "author": [
                "Taole Sha",
                "Michael Minyi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00564v1",
                "http://arxiv.org/pdf/2311.00564v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "62F15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00562v2",
            "title": "MNN: Mixed Nearest-Neighbors for Self-Supervised Learning",
            "updated": "2023-11-13T14:21:49Z",
            "published": "2023-11-01T14:59:41Z",
            "summary": "In contrastive self-supervised learning, positive samples are typically drawn\nfrom the same image but in different augmented views, resulting in a relatively\nlimited source of positive samples. An effective way to alleviate this problem\nis to incorporate the relationship between samples, which involves including\nthe top-K nearest neighbors of positive samples. However, the problem of false\nneighbors (i.e., neighbors that do not belong to the same category as the\npositive sample) is an objective but often overlooked challenge due to the\nquery of neighbor samples without supervision information. In this paper, we\npresent a simple self-supervised learning framework called Mixed\nNearest-Neighbors for Self-Supervised Learning (MNN). MNN optimizes the\ninfluence of neighbor samples on the semantics of positive samples through an\nintuitive weighting approach and image mixture operations. The results\ndemonstrate that MNN exhibits exceptional generalization performance and\ntraining efficiency on four benchmark datasets.",
            "author": [
                "Xianzhong Long",
                "Chen Peng",
                "Yun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00562v2",
                "http://arxiv.org/pdf/2311.00562v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00559v1",
            "title": "Learning to optimize by multi-gradient for multi-objective optimization",
            "updated": "2023-11-01T14:55:54Z",
            "published": "2023-11-01T14:55:54Z",
            "summary": "The development of artificial intelligence (AI) for science has led to the\nemergence of learning-based research paradigms, necessitating a compelling\nreevaluation of the design of multi-objective optimization (MOO) methods. The\nnew generation MOO methods should be rooted in automated learning rather than\nmanual design. In this paper, we introduce a new automatic learning paradigm\nfor optimizing MOO problems, and propose a multi-gradient learning to optimize\n(ML2O) method, which automatically learns a generator (or mappings) from\nmultiple gradients to update directions. As a learning-based method, ML2O\nacquires knowledge of local landscapes by leveraging information from the\ncurrent step and incorporates global experience extracted from historical\niteration trajectory data. By introducing a new guarding mechanism, we propose\na guarded multi-gradient learning to optimize (GML2O) method, and prove that\nthe iterative sequence generated by GML2O converges to a Pareto critical point.\nThe experimental results demonstrate that our learned optimizer outperforms\nhand-designed competitors on training multi-task learning (MTL) neural network.",
            "author": [
                "Linxi Yang",
                "Xinmin Yang",
                "Liping Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00559v1",
                "http://arxiv.org/pdf/2311.00559v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02101v1",
            "title": "Solving MaxSAT with Matrix Multiplication",
            "updated": "2023-11-01T14:46:46Z",
            "published": "2023-11-01T14:46:46Z",
            "summary": "We propose an incomplete algorithm for Maximum Satisfiability (MaxSAT)\nspecifically designed to run on neural network accelerators such as GPUs and\nTPUs. Given a MaxSAT problem instance in conjunctive normal form, our procedure\nconstructs a Restricted Boltzmann Machine (RBM) with an equilibrium\ndistribution wherein the probability of a Boolean assignment is exponential in\nthe number of clauses it satisfies. Block Gibbs sampling is used to\nstochastically search the space of assignments with parallel Markov chains.\nSince matrix multiplication is the main computational primitive for block Gibbs\nsampling in an RBM, our approach leads to an elegantly simple algorithm (40\nlines of JAX) well-suited for neural network accelerators. Theoretical results\nabout RBMs guarantee that the required number of visible and hidden units of\nthe RBM scale only linearly with the number of variables and constant-sized\nclauses in the MaxSAT instance, ensuring that the computational cost of a Gibbs\nstep scales reasonably with the instance size. Search throughput can be\nincreased by batching parallel chains within a single accelerator as well as by\ndistributing them across multiple accelerators. As a further enhancement, a\nheuristic based on unit propagation running on CPU is periodically applied to\nthe sampled assignments. Our approach, which we term RbmSAT, is a new design\npoint in the algorithm-hardware co-design space for MaxSAT. We present timed\nresults on a subset of problem instances from the annual MaxSAT Evaluation's\nIncomplete Unweighted Track for the years 2018 to 2021. When allotted the same\nrunning time and CPU compute budget (but no TPUs), RbmSAT outperforms other\nparticipating solvers on problems drawn from three out of the four years'\ncompetitions. Given the same running time on a TPU cluster for which RbmSAT is\nuniquely designed, it outperforms all solvers on problems drawn from all four\nyears.",
            "author": [
                "David Warde-Farley",
                "Vinod Nair",
                "Yujia Li",
                "Ivan Lobov",
                "Felix Gimeno",
                "Simon Osindero"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02101v1",
                "http://arxiv.org/pdf/2311.02101v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00553v1",
            "title": "Polynomial Chaos Surrogate Construction for Random Fields with\n  Parametric Uncertainty",
            "updated": "2023-11-01T14:41:54Z",
            "published": "2023-11-01T14:41:54Z",
            "summary": "Engineering and applied science rely on computational experiments to\nrigorously study physical systems. The mathematical models used to probe these\nsystems are highly complex, and sampling-intensive studies often require\nprohibitively many simulations for acceptable accuracy. Surrogate models\nprovide a means of circumventing the high computational expense of sampling\nsuch complex models. In particular, polynomial chaos expansions (PCEs) have\nbeen successfully used for uncertainty quantification studies of deterministic\nmodels where the dominant source of uncertainty is parametric. We discuss an\nextension to conventional PCE surrogate modeling to enable surrogate\nconstruction for stochastic computational models that have intrinsic noise in\naddition to parametric uncertainty. We develop a PCE surrogate on a joint space\nof intrinsic and parametric uncertainty, enabled by Rosenblatt transformations,\nand then extend the construction to random field data via the Karhunen-Loeve\nexpansion. We then take advantage of closed-form solutions for computing PCE\nSobol indices to perform a global sensitivity analysis of the model which\nquantifies the intrinsic noise contribution to the overall model output\nvariance. Additionally, the resulting joint PCE is generative in the sense that\nit allows generating random realizations at any input parameter setting that\nare statistically approximately equivalent to realizations from the underlying\nstochastic model. The method is demonstrated on a chemical catalysis example\nmodel.",
            "author": [
                "Joy N. Mueller",
                "Khachik Sargsyan",
                "Craig J. Daniels",
                "Habib N. Najm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00553v1",
                "http://arxiv.org/pdf/2311.00553v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML",
                "60G99, 65C20, 33C45, 62G07, 62J02"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00548v3",
            "title": "Continual atlas-based segmentation of prostate MRI",
            "updated": "2023-11-06T12:34:45Z",
            "published": "2023-11-01T14:29:46Z",
            "summary": "Continual learning (CL) methods designed for natural image classification\noften fail to reach basic quality standards for medical image segmentation.\nAtlas-based segmentation, a well-established approach in medical imaging,\nincorporates domain knowledge on the region of interest, leading to\nsemantically coherent predictions. This is especially promising for CL, as it\nallows us to leverage structural information and strike an optimal balance\nbetween model rigidity and plasticity over time. When combined with\nprivacy-preserving prototypes, this process offers the advantages of\nrehearsal-based CL without compromising patient privacy. We propose Atlas\nReplay, an atlas-based segmentation approach that uses prototypes to generate\nhigh-quality segmentation masks through image registration that maintain\nconsistency even as the training distribution changes. We explore how our\nproposed method performs compared to state-of-the-art CL methods in terms of\nknowledge transferability across seven publicly available prostate segmentation\ndatasets. Prostate segmentation plays a vital role in diagnosing prostate\ncancer, however, it poses challenges due to substantial anatomical variations,\nbenign structural differences in older age groups, and fluctuating acquisition\nparameters. Our results show that Atlas Replay is both robust and generalizes\nwell to yet-unseen domains while being able to maintain knowledge, unlike\nend-to-end segmentation methods. Our code base is available under\nhttps://github.com/MECLabTUDA/Atlas-Replay.",
            "author": [
                "Amin Ranem",
                "Camila Gonz\u00e1lez",
                "Daniel Pinto dos Santos",
                "Andreas M. Bucher",
                "Ahmed E. Othman",
                "Anirban Mukhopadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00548v3",
                "http://arxiv.org/pdf/2311.00548v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00545v1",
            "title": "Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric\n  Models and the MDL Principle",
            "updated": "2023-11-01T14:25:51Z",
            "published": "2023-11-01T14:25:51Z",
            "summary": "The Abstraction and Reasoning Corpus (ARC) is a challenging benchmark,\nintroduced to foster AI research towards human-level intelligence. It is a\ncollection of unique tasks about generating colored grids, specified by a few\nexamples only. In contrast to the transformation-based programs of existing\nwork, we introduce object-centric models that are in line with the natural\nprograms produced by humans. Our models can not only perform predictions, but\nalso provide joint descriptions for input/output pairs. The Minimum Description\nLength (MDL) principle is used to efficiently search the large model space. A\ndiverse range of tasks are solved, and the learned models are similar to the\nnatural programs. We demonstrate the generality of our approach by applying it\nto a different domain.",
            "author": [
                "S\u00e9bastien Ferr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00545v1",
                "http://arxiv.org/pdf/2311.00545v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00541v1",
            "title": "An Embedded Diachronic Sense Change Model with a Case Study from Ancient\n  Greek",
            "updated": "2023-11-01T14:20:18Z",
            "published": "2023-11-01T14:20:18Z",
            "summary": "Word meanings change over time, and word senses evolve, emerge or die out in\nthe process. For ancient languages, where the corpora are often small, sparse\nand noisy, modelling such changes accurately proves challenging, and\nquantifying uncertainty in sense-change estimates consequently becomes\nimportant. GASC and DiSC are existing generative models that have been used to\nanalyse sense change for target words from an ancient Greek text corpus, using\nunsupervised learning without the help of any pre-training. These models\nrepresent the senses of a given target word such as \"kosmos\" (meaning\ndecoration, order or world) as distributions over context words, and sense\nprevalence as a distribution over senses. The models are fitted using MCMC\nmethods to measure temporal changes in these representations. In this paper, we\nintroduce EDiSC, an embedded version of DiSC, which combines word embeddings\nwith DiSC to provide superior model performance. We show empirically that EDiSC\noffers improved predictive accuracy, ground-truth recovery and uncertainty\nquantification, as well as better sampling efficiency and scalability\nproperties with MCMC methods. We also discuss the challenges of fitting these\nmodels.",
            "author": [
                "Schyan Zafar",
                "Geoff K. Nicholls"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00541v1",
                "http://arxiv.org/pdf/2311.00541v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00537v1",
            "title": "Machine Learning Without a Processor: Emergent Learning in a Nonlinear\n  Electronic Metamaterial",
            "updated": "2023-11-01T14:16:37Z",
            "published": "2023-11-01T14:16:37Z",
            "summary": "Standard deep learning algorithms require differentiating large nonlinear\nnetworks, a process that is slow and power-hungry. Electronic learning\nmetamaterials offer potentially fast, efficient, and fault-tolerant hardware\nfor analog machine learning, but existing implementations are linear, severely\nlimiting their capabilities. These systems differ significantly from artificial\nneural networks as well as the brain, so the feasibility and utility of\nincorporating nonlinear elements have not been explored. Here we introduce a\nnonlinear learning metamaterial -- an analog electronic network made of\nself-adjusting nonlinear resistive elements based on transistors. We\ndemonstrate that the system learns tasks unachievable in linear systems,\nincluding XOR and nonlinear regression, without a computer. We find our\nnonlinear learning metamaterial reduces modes of training error in order (mean,\nslope, curvature), similar to spectral bias in artificial neural networks. The\ncircuitry is robust to damage, retrainable in seconds, and performs learned\ntasks in microseconds while dissipating only picojoules of energy across each\ntransistor. This suggests enormous potential for fast, low-power computing in\nedge systems like sensors, robotic controllers, and medical devices, as well as\nmanufacturability at scale for performing and studying emergent learning.",
            "author": [
                "Sam Dillavou",
                "Benjamin D Beyer",
                "Menachem Stern",
                "Marc Z Miskin",
                "Andrea J Liu",
                "Douglas J Durian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00537v1",
                "http://arxiv.org/pdf/2311.00537v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cs.ET",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00535v1",
            "title": "Active Noise Control Portable Device Design",
            "updated": "2023-11-01T14:13:04Z",
            "published": "2023-11-01T14:13:04Z",
            "summary": "While our world is filled with its own natural sounds that we can't resist\nenjoying, it is also chock-full of other sounds that can be irritating, this is\nnoise. Noise not only influences the working efficiency but also the human's\nhealth. The problem of reducing noise is one of great importance and great\ndifficulty. The problem has been addressed in many ways over the years. The\ncurrent methods for noise reducing mostly rely on the materials and\ntransmission medium, which are only effective to some extent for the high\nfrequency noise. However, the effective reduction noise method especially for\nlow frequency noise is very limited.\n  Here we come up with a noise reduction system consist of a sensor to detect\nthe noise in the environment. Then the noise will be sent to an electronic\ncontrol system to process the noise, which will generate a reverse phase\nfrequency signal to counteract the disturbance. Finally, the processed smaller\nnoise will be broadcasted by the speaker. Through this smart noise reduction\nsystem, even the noise with low-frequency can be eliminated.\n  The system is also integrated with sleep tracking and music player\napplications. It can also remember and store settings for the same environment,\nsense temperature, and smart control of home furniture, fire alarm, etc. This\nsmart system can transfer data easily by Wi-Fi or Bluetooth and controlled by\nits APP.\n  In this project, we will present a model of the above technology which can be\nused in various environments to prevent noise pollution and provide a solution\nto the people who have difficulties finding a peaceful and quiet environment\nfor sleep, work or study.",
            "author": [
                "kai Wu",
                "Yuanyuan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00535v1",
                "http://arxiv.org/pdf/2311.00535v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00533v1",
            "title": "The Eclipse Layout Kernel",
            "updated": "2023-11-01T14:10:45Z",
            "published": "2023-11-01T14:10:45Z",
            "summary": "The Eclipse Layout Kernel (ELK) is a collection of graph drawing algorithms\nthat supports compound graph layout and ports as explicit anchor points of\nedges. It is available as open-source library under an EPL license. Since its\nbeginning, ELK has served both as a research vehicle for graph drawing\nalgorithms, and as a practical tool for solving real-world problems. ELK and\nits transpiled JavaScript cousin elkjs are now included in numerous academic\nand commercial projects.\n  Most of the algorithms realized in ELK are described in a series of\npublications. In this paper, the technical description concentrates on the key\nfeatures of the flag-ship algorithm ELK Layered, the algorithm architecture,\nand usage. However, the main purpose of this paper is to give the broader view\nthat is typically left unpublished. Specifically, we review its history, give a\nbrief overview of technical papers, discuss lessons learned over the past\nfifteen years, and present example usages. Finally, we reflect on potential\nthreats to open-source graph drawing libraries.",
            "author": [
                "S\u00f6ren Domr\u00f6s",
                "Reinhard von Hanxleden",
                "Miro Sp\u00f6nemann",
                "Ulf R\u00fcegg",
                "Christoph Daniel Schulze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00533v1",
                "http://arxiv.org/pdf/2311.00533v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00529v1",
            "title": "A Unified Framework for the Error Analysis of Physics-Informed Neural\n  Networks",
            "updated": "2023-11-01T14:01:52Z",
            "published": "2023-11-01T14:01:52Z",
            "summary": "We prove a priori and a posteriori error estimates, also known as the\ngeneralization error in the machine learning community, for physics-informed\nneural networks (PINNs) for linear PDEs. We analyze elliptic equations in\nprimal and mixed form, elasticity, parabolic, hyperbolic and Stokes equations;\nand a PDE constrained optimization problem. For the analysis, we propose an\nabstract framework in the common language of bilinear forms, and we show that\ncoercivity and continuity lead to error estimates. Our results give insight\ninto the potential of neural networks for high dimensional PDEs and into the\nbenefit of encoding constraints directly in the ansatz class. The provided\nestimates are -- apart from the Poisson equation -- the first results of\nbest-approximation and a posteriori error-control type. Finally, utilizing\nrecent advances in PINN optimization, we present numerical examples that\nillustrate the ability of the method to achieve accurate solutions.",
            "author": [
                "Marius Zeinhofer",
                "Rami Masri",
                "Kent-Andr\u00e9 Mardal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00529v1",
                "http://arxiv.org/pdf/2311.00529v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65M12, 65M15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00737v1",
            "title": "Real-Time Magnetic Tracking and Diagnosis of COVID-19 via Machine\n  Learning",
            "updated": "2023-11-01T13:57:33Z",
            "published": "2023-11-01T13:57:33Z",
            "summary": "The COVID-19 pandemic underscored the importance of reliable, noninvasive\ndiagnostic tools for robust public health interventions. In this work, we fused\nmagnetic respiratory sensing technology (MRST) with machine learning (ML) to\ncreate a diagnostic platform for real-time tracking and diagnosis of COVID-19\nand other respiratory diseases. The MRST precisely captures breathing patterns\nthrough three specific breath testing protocols: normal breath, holding breath,\nand deep breath. We collected breath data from both COVID-19 patients and\nhealthy subjects in Vietnam using this platform, which then served to train and\nvalidate ML models. Our evaluation encompassed multiple ML algorithms,\nincluding support vector machines and deep learning models, assessing their\nability to diagnose COVID-19. Our multi-model validation methodology ensures a\nthorough comparison and grants the adaptability to select the most optimal\nmodel, striking a balance between diagnostic precision with model\ninterpretability. The findings highlight the exceptional potential of our\ndiagnostic tool in pinpointing respiratory anomalies, achieving over 90%\naccuracy. This innovative sensor technology can be seamlessly integrated into\nhealthcare settings for patient monitoring, marking a significant enhancement\nfor the healthcare infrastructure.",
            "author": [
                "Dang Nguyen",
                "Phat K. Huynh",
                "Vinh Duc An Bui",
                "Kee Young Hwang",
                "Nityanand Jain",
                "Chau Nguyen",
                "Le Huu Nhat Minh",
                "Le Van Truong",
                "Xuan Thanh Nguyen",
                "Dinh Hoang Nguyen",
                "Le Tien Dung",
                "Trung Q. Le",
                "Manh-Huong Phan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00737v1",
                "http://arxiv.org/pdf/2311.00737v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.ins-det",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00523v1",
            "title": "Learning impartial policies for sequential counterfactual explanations\n  using Deep Reinforcement Learning",
            "updated": "2023-11-01T13:50:47Z",
            "published": "2023-11-01T13:50:47Z",
            "summary": "In the field of explainable Artificial Intelligence (XAI), sequential\ncounterfactual (SCF) examples are often used to alter the decision of a trained\nclassifier by implementing a sequence of modifications to the input instance.\nAlthough certain test-time algorithms aim to optimize for each new instance\nindividually, recently Reinforcement Learning (RL) methods have been proposed\nthat seek to learn policies for discovering SCFs, thereby enhancing\nscalability. As is typical in RL, the formulation of the RL problem, including\nthe specification of state space, actions, and rewards, can often be ambiguous.\nIn this work, we identify shortcomings in existing methods that can result in\npolicies with undesired properties, such as a bias towards specific actions. We\npropose to use the output probabilities of the classifier to create a more\ninformative reward, to mitigate this effect.",
            "author": [
                "E. Panagiotou",
                "E. Ntoutsi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00523v1",
                "http://arxiv.org/pdf/2311.00523v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00519v2",
            "title": "Retrieval-Based Reconstruction For Time-series Contrastive Learning",
            "updated": "2023-12-07T15:20:18Z",
            "published": "2023-11-01T13:44:45Z",
            "summary": "The success of self-supervised contrastive learning hinges on identifying\npositive data pairs that, when pushed together in embedding space, encode\nuseful information for subsequent downstream tasks. However, in time-series,\nthis is challenging because creating positive pairs via augmentations may break\nthe original semantic meaning. We hypothesize that if we can retrieve\ninformation from one subsequence to successfully reconstruct another\nsubsequence, then they should form a positive pair. Harnessing this intuition,\nwe introduce our novel approach: REtrieval-BAsed Reconstruction (REBAR)\ncontrastive learning. First, we utilize a convolutional cross-attention\narchitecture to calculate the REBAR error between two different time-series.\nThen, through validation experiments, we show that the REBAR error is a\npredictor of mutual class membership, justifying its usage as a\npositive/negative labeler. Finally, once integrated into a contrastive learning\nframework, our REBAR method can learn an embedding that achieves\nstate-of-the-art performance on downstream tasks across various modalities.",
            "author": [
                "Maxwell A. Xu",
                "Alexander Moreno",
                "Hui Wei",
                "Benjamin M. Marlin",
                "James M. Rehg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00519v2",
                "http://arxiv.org/pdf/2311.00519v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00517v1",
            "title": "Improving Cardiovascular Disease Prediction Through Comparative Analysis\n  of Machine Learning Models: A Case Study on Myocardial Infarction",
            "updated": "2023-11-01T13:41:44Z",
            "published": "2023-11-01T13:41:44Z",
            "summary": "Cardiovascular disease remains a leading cause of mortality in the\ncontemporary world. Its association with smoking, elevated blood pressure, and\ncholesterol levels underscores the significance of these risk factors. This\nstudy addresses the challenge of predicting myocardial illness, a formidable\ntask in medical research. Accurate predictions are pivotal for refining\nhealthcare strategies. This investigation conducts a comparative analysis of\nsix distinct machine learning models: Logistic Regression, Support Vector\nMachine, Decision Tree, Bagging, XGBoost, and LightGBM. The attained outcomes\nexhibit promise, with accuracy rates as follows: Logistic Regression (81.00%),\nSupport Vector Machine (75.01%), XGBoost (92.72%), LightGBM (90.60%), Decision\nTree (82.30%), and Bagging (83.01%). Notably, XGBoost emerges as the\ntop-performing model. These findings underscore its potential to enhance\npredictive precision for coronary infarction. As the prevalence of\ncardiovascular risk factors persists, incorporating advanced machine learning\ntechniques holds the potential to refine proactive medical interventions.",
            "author": [
                "Jonayet Miah",
                "Duc M Ca",
                "Md Abu Sayed",
                "Ehsanur Rashid Lipu",
                "Fuad Mahmud",
                "S M Yasir Arafat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00517v1",
                "http://arxiv.org/pdf/2311.00517v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00513v1",
            "title": "Rule-Based Error Classification for Analyzing Differences in Frequent\n  Errors",
            "updated": "2023-11-01T13:36:20Z",
            "published": "2023-11-01T13:36:20Z",
            "summary": "Finding and fixing errors is a time-consuming task not only for novice\nprogrammers but also for expert programmers. Prior work has identified frequent\nerror patterns among various levels of programmers. However, the differences in\nthe tendencies between novices and experts have yet to be revealed. From the\nknowledge of the frequent errors in each level of programmers, instructors will\nbe able to provide helpful advice for each level of learners. In this paper, we\npropose a rule-based error classification tool to classify errors in code pairs\nconsisting of wrong and correct programs. We classify errors for 95,631 code\npairs and identify 3.47 errors on average, which are submitted by various\nlevels of programmers on an online judge system. The classified errors are used\nto analyze the differences in frequent errors between novice and expert\nprogrammers. The analyzed results show that, as for the same introductory\nproblems, errors made by novices are due to the lack of knowledge in\nprogramming, and the mistakes are considered an essential part of the learning\nprocess. On the other hand, errors made by experts are due to misunderstandings\ncaused by the carelessness of reading problems or the challenges of solving\nproblems differently than usual. The proposed tool can be used to create\nerror-labeled datasets and for further code-related educational research.",
            "author": [
                "Atsushi Shirafuji",
                "Taku Matsumoto",
                "Md Faizul Ibne Amin",
                "Yutaka Watanobe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00513v1",
                "http://arxiv.org/pdf/2311.00513v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CL",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00502v2",
            "title": "Efficient LLM Inference on CPUs",
            "updated": "2023-12-07T12:16:42Z",
            "published": "2023-11-01T13:08:50Z",
            "summary": "Large language models (LLMs) have demonstrated remarkable performance and\ntremendous potential across a wide range of tasks. However, deploying these\nmodels has been challenging due to the astronomical amount of model parameters,\nwhich requires a demand for large memory capacity and high memory bandwidth. In\nthis paper, we propose an effective approach that can make the deployment of\nLLMs more efficiently. We support an automatic INT4 weight-only quantization\nflow and design a special LLM runtime with highly-optimized kernels to\naccelerate the LLM inference on CPUs. We demonstrate the general applicability\nof our approach on popular LLMs including Llama2, Llama, GPT-NeoX, and showcase\nthe extreme inference efficiency on CPUs. The code is publicly available at:\nhttps://github.com/intel/intel-extension-for-transformers.",
            "author": [
                "Haihao Shen",
                "Hanwen Chang",
                "Bo Dong",
                "Yu Luo",
                "Hengyu Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00502v2",
                "http://arxiv.org/pdf/2311.00502v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00500v1",
            "title": "Intriguing Properties of Data Attribution on Diffusion Models",
            "updated": "2023-11-01T13:00:46Z",
            "published": "2023-11-01T13:00:46Z",
            "summary": "Data attribution seeks to trace model outputs back to training data. With the\nrecent development of diffusion models, data attribution has become a desired\nmodule to properly assign valuations for high-quality or copyrighted training\nsamples, ensuring that data contributors are fairly compensated or credited.\nSeveral theoretically motivated methods have been proposed to implement data\nattribution, in an effort to improve the trade-off between computational\nscalability and effectiveness. In this work, we conduct extensive experiments\nand ablation studies on attributing diffusion models, specifically focusing on\nDDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model\nLoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive\nobservations that theoretically unjustified design choices for attribution\nempirically outperform previous baselines by a large margin, in terms of both\nlinear datamodeling score and counterfactual evaluation. Our work presents a\nsignificantly more efficient approach for attributing diffusion models, while\nthe unexpected findings suggest that at least in non-convex settings,\nconstructions guided by theoretical assumptions may lead to inferior\nattribution performance. The code is available at\nhttps://github.com/sail-sg/D-TRAK.",
            "author": [
                "Xiaosen Zheng",
                "Tianyu Pang",
                "Chao Du",
                "Jing Jiang",
                "Min Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00500v1",
                "http://arxiv.org/pdf/2311.00500v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00493v1",
            "title": "The stability of deep learning for 21cm foreground removal across\n  various sky models and frequency-dependent systematics",
            "updated": "2023-11-01T12:48:37Z",
            "published": "2023-11-01T12:48:37Z",
            "summary": "Deep learning (DL) has recently been proposed as a novel approach for 21cm\nforeground removal. Before applying DL to real observations, it is essential to\nassess its consistency with established methods, its performance across various\nsimulation models and its robustness against instrumental systematics. This\nstudy develops a commonly used U-Net and evaluates its performance for\npost-reionisation foreground removal across three distinct sky simulation\nmodels based on pure Gaussian realisations, the Lagrangian perturbation theory,\nand the Planck sky model. Stable outcomes across the models are achieved\nprovided that training and testing data align with the same model. On average,\nthe residual foreground in the U-Net reconstructed data is $\\sim$10% of the\nsignal across angular scales at the considered redshift range. Comparable\nresults are found with traditional approaches. However, blindly using a network\ntrained on one model for data from another model yields inaccurate\nreconstructions, emphasising the need for consistent training data. The study\nthen introduces frequency-dependent Gaussian beams and gain drifts to the test\ndata. The network struggles to denoise data affected by \"unexpected\"\nsystematics without prior information. However, after re-training consistently\nwith systematics-contaminated data, the network effectively restores its\nreconstruction accuracy. This highlights the importance of incorporating prior\nsystematics knowledge during training for successful denoising. Our work\nprovides critical guidelines for using DL for 21cm foreground removal, tailored\nto specific data attributes. Notably, it is the first time that DL has been\napplied to the Planck sky model being most realistic foregrounds at present.",
            "author": [
                "T. Chen",
                "M. Bianco",
                "E. Tolley",
                "M. Spinelli",
                "D. Forero-Sanchez",
                "J. P. Kneib"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00493v1",
                "http://arxiv.org/pdf/2311.00493v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00491v1",
            "title": "Bayes-enhanced Multi-view Attention Networks for Robust POI\n  Recommendation",
            "updated": "2023-11-01T12:47:38Z",
            "published": "2023-11-01T12:47:38Z",
            "summary": "POI recommendation is practically important to facilitate various\nLocation-Based Social Network services, and has attracted rising research\nattention recently. Existing works generally assume the available POI check-ins\nreported by users are the ground-truth depiction of user behaviors. However, in\nreal application scenarios, the check-in data can be rather unreliable due to\nboth subjective and objective causes including positioning error and user\nprivacy concerns, leading to significant negative impacts on the performance of\nthe POI recommendation. To this end, we investigate a novel problem of robust\nPOI recommendation by considering the uncertainty factors of the user\ncheck-ins, and proposes a Bayes-enhanced Multi-view Attention Network.\nSpecifically, we construct personal POI transition graph, the semantic-based\nPOI graph and distance-based POI graph to comprehensively model the\ndependencies among the POIs. As the personal POI transition graph is usually\nsparse and sensitive to noise, we design a Bayes-enhanced spatial dependency\nlearning module for data augmentation from the local view. A Bayesian posterior\nguided graph augmentation approach is adopted to generate a new graph with\ncollaborative signals to increase the data diversity. Then both the original\nand the augmented graphs are used for POI representation learning to counteract\nthe data uncertainty issue. Next, the POI representations of the three view\ngraphs are input into the proposed multi-view attention-based user preference\nlearning module. By incorporating the semantic and distance correlations of\nPOIs, the user preference can be effectively refined and finally robust\nrecommendation results are achieved. The results of extensive experiments show\nthat BayMAN significantly outperforms the state-of-the-art methods in POI\nrecommendation when the available check-ins are incomplete and noisy.",
            "author": [
                "Jiangnan Xia",
                "Yu Yang",
                "Senzhang Wang",
                "Hongzhi Yin",
                "Jiannong Cao",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00491v1",
                "http://arxiv.org/pdf/2311.00491v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00489v2",
            "title": "Deep Neural Networks for Automatic Speaker Recognition Do Not Learn\n  Supra-Segmental Temporal Features",
            "updated": "2023-11-02T06:07:14Z",
            "published": "2023-11-01T12:45:31Z",
            "summary": "While deep neural networks have shown impressive results in automatic speaker\nrecognition and related tasks, it is dissatisfactory how little is understood\nabout what exactly is responsible for these results. Part of the success has\nbeen attributed in prior work to their capability to model supra-segmental\ntemporal information (SST), i.e., learn rhythmic-prosodic characteristics of\nspeech in addition to spectral features. In this paper, we (i) present and\napply a novel test to quantify to what extent the performance of\nstate-of-the-art neural networks for speaker recognition can be explained by\nmodeling SST; and (ii) present several means to force respective nets to focus\nmore on SST and evaluate their merits. We find that a variety of CNN- and\nRNN-based neural network architectures for speaker recognition do not model SST\nto any sufficient degree, even when forced. The results provide a highly\nrelevant basis for impactful future research into better exploitation of the\nfull speech signal and give insights into the inner workings of such networks,\nenhancing explainability of deep learning for speech technologies.",
            "author": [
                "Daniel Neururer",
                "Volker Dellwo",
                "Thilo Stadelmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00489v2",
                "http://arxiv.org/pdf/2311.00489v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00488v1",
            "title": "Comparing Optimization Targets for Contrast-Consistent Search",
            "updated": "2023-11-01T12:42:14Z",
            "published": "2023-11-01T12:42:14Z",
            "summary": "We investigate the optimization target of Contrast-Consistent Search (CCS),\nwhich aims to recover the internal representations of truth of a large language\nmodel. We present a new loss function that we call the Midpoint-Displacement\n(MD) loss function. We demonstrate that for a certain hyper-parameter value\nthis MD loss function leads to a prober with very similar weights to CCS. We\nfurther show that this hyper-parameter is not optimal and that with a better\nhyper-parameter the MD loss function attains a higher test accuracy than CCS.",
            "author": [
                "Hugo Fry",
                "Seamus Fallows",
                "Ian Fan",
                "Jamie Wright",
                "Nandi Schoots"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00488v1",
                "http://arxiv.org/pdf/2311.00488v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00483v1",
            "title": "DEFN: Dual-Encoder Fourier Group Harmonics Network for Three-Dimensional\n  Macular Hole Reconstruction with Stochastic Retinal Defect Augmentation and\n  Dynamic Weight Composition",
            "updated": "2023-11-01T12:33:04Z",
            "published": "2023-11-01T12:33:04Z",
            "summary": "The spatial and quantitative parameters of macular holes are vital for\ndiagnosis, surgical choices, and post-op monitoring. Macular hole diagnosis and\ntreatment rely heavily on spatial and quantitative data, yet the scarcity of\nsuch data has impeded the progress of deep learning techniques for effective\nsegmentation and real-time 3D reconstruction. To address this challenge, we\nassembled the world's largest macular hole dataset, Retinal OCTfor Macular Hole\nEnhancement (ROME-3914), and a Comprehensive Archive for Retinal Segmentation\n(CARS-30k), both expertly annotated. In addition, we developed an innovative 3D\nsegmentation network, the Dual-Encoder FuGH Network (DEFN), which integrates\nthree innovative modules: Fourier Group Harmonics (FuGH), Simplified 3D Spatial\nAttention (S3DSA) and Harmonic Squeeze-and-Excitation Module (HSE). These three\nmodules synergistically filter noise, reduce computational complexity,\nemphasize detailed features, and enhance the network's representation ability.\nWe also proposed a novel data augmentation method, Stochastic Retinal Defect\nInjection (SRDI), and a network optimization strategy DynamicWeightCompose\n(DWC), to further improve the performance of DEFN. Compared with 13 baselines,\nour DEFN shows the best performance. We also offer precise 3D retinal\nreconstruction and quantitative metrics, bringing revolutionary diagnostic and\ntherapeutic decision-making tools for ophthalmologists, and is expected to\ncompletely reshape the diagnosis and treatment patterns of difficult-to-treat\nmacular degeneration. The source code is publicly available at:\nhttps://github.com/IIPL-HangzhouDianUniversity/DEFN-Pytorch.",
            "author": [
                "Xingru Huang",
                "Yihao Guo",
                "Jian Huang",
                "Zhi Li",
                "Tianyun Zhang",
                "Kunyan Cai",
                "Gaopeng Huang",
                "Wenhao Chen",
                "Zhaoyang Xu",
                "Liangqiong Qu",
                "Ji Hu",
                "Tinyu Wang",
                "Shaowei Jiang",
                "Chenggang Yan",
                "Yaoqi Sun",
                "Xin Ye",
                "Yaqi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00483v1",
                "http://arxiv.org/pdf/2311.00483v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "68, 92",
                "I.4; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00481v1",
            "title": "Fixed-Budget Best-Arm Identification in Sparse Linear Bandits",
            "updated": "2023-11-01T12:32:17Z",
            "published": "2023-11-01T12:32:17Z",
            "summary": "We study the best-arm identification problem in sparse linear bandits under\nthe fixed-budget setting. In sparse linear bandits, the unknown feature vector\n$\\theta^*$ may be of large dimension $d$, but only a few, say $s \\ll d$ of\nthese features have non-zero values. We design a two-phase algorithm, Lasso and\nOptimal-Design- (Lasso-OD) based linear best-arm identification. The first\nphase of Lasso-OD leverages the sparsity of the feature vector by applying the\nthresholded Lasso introduced by Zhou (2009), which estimates the support of\n$\\theta^*$ correctly with high probability using rewards from the selected arms\nand a judicious choice of the design matrix. The second phase of Lasso-OD\napplies the OD-LinBAI algorithm by Yang and Tan (2022) on that estimated\nsupport. We derive a non-asymptotic upper bound on the error probability of\nLasso-OD by carefully choosing hyperparameters (such as Lasso's regularization\nparameter) and balancing the error probabilities of both phases. For fixed\nsparsity $s$ and budget $T$, the exponent in the error probability of Lasso-OD\ndepends on $s$ but not on the dimension $d$, yielding a significant performance\nimprovement for sparse and high-dimensional linear bandits. Furthermore, we\nshow that Lasso-OD is almost minimax optimal in the exponent. Finally, we\nprovide numerical examples to demonstrate the significant performance\nimprovement over the existing algorithms for non-sparse linear bandits such as\nOD-LinBAI, BayesGap, Peace, LinearExploration, and GSE.",
            "author": [
                "Recep Can Yavas",
                "Vincent Y. F. Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00481v1",
                "http://arxiv.org/pdf/2311.00481v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00476v1",
            "title": "Group Distributionally Robust Knowledge Distillation",
            "updated": "2023-11-01T12:25:02Z",
            "published": "2023-11-01T12:25:02Z",
            "summary": "Knowledge distillation enables fast and effective transfer of features\nlearned from a bigger model to a smaller one. However, distillation objectives\nare susceptible to sub-population shifts, a common scenario in medical imaging\nanalysis which refers to groups/domains of data that are underrepresented in\nthe training set. For instance, training models on health data acquired from\nmultiple scanners or hospitals can yield subpar performance for minority\ngroups. In this paper, inspired by distributionally robust optimization (DRO)\ntechniques, we address this shortcoming by proposing a group-aware distillation\nloss. During optimization, a set of weights is updated based on the per-group\nlosses at a given iteration. This way, our method can dynamically focus on\ngroups that have low performance during training. We empirically validate our\nmethod, GroupDistil on two benchmark datasets (natural images and cardiac MRIs)\nand show consistent improvement in terms of worst-group accuracy.",
            "author": [
                "Konstantinos Vilouras",
                "Xiao Liu",
                "Pedro Sanchez",
                "Alison Q. O'Neil",
                "Sotirios A. Tsaftaris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00476v1",
                "http://arxiv.org/pdf/2311.00476v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00475v1",
            "title": "Style Locality for Controllable Generation with kNN Language Models",
            "updated": "2023-11-01T12:21:53Z",
            "published": "2023-11-01T12:21:53Z",
            "summary": "Recent language models have been improved by the addition of external memory.\nNearest neighbor language models retrieve similar contexts to assist in word\nprediction. The addition of locality levels allows a model to learn how to\nweight neighbors based on their relative location to the current text in source\ndocuments, and have been shown to further improve model performance. Nearest\nneighbor models have been explored for controllable generation but have not\nexamined the use of locality levels. We present a novel approach for this\npurpose and evaluate it using automatic and human evaluation on politeness,\nformality, supportiveness, and toxicity textual data. We find that our model is\nsuccessfully able to control style and provides a better fluency-style\ntrade-off than previous work.",
            "author": [
                "Gilles Nawezi",
                "Lucie Flek",
                "Charles Welch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00475v1",
                "http://arxiv.org/pdf/2311.00475v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00474v2",
            "title": "Diffusion models for probabilistic programming",
            "updated": "2023-11-21T20:16:57Z",
            "published": "2023-11-01T12:17:05Z",
            "summary": "We propose Diffusion Model Variational Inference (DMVI), a novel method for\nautomated approximate inference in probabilistic programming languages (PPLs).\nDMVI utilizes diffusion models as variational approximations to the true\nposterior distribution by deriving a novel bound to the marginal likelihood\nobjective used in Bayesian modelling. DMVI is easy to implement, allows\nhassle-free inference in PPLs without the drawbacks of, e.g., variational\ninference using normalizing flows, and does not make any constraints on the\nunderlying neural network model. We evaluate DMVI on a set of common Bayesian\nmodels and show that its posterior inferences are in general more accurate than\nthose of contemporary methods used in PPLs while having a similar computational\ncost and requiring less manual tuning.",
            "author": [
                "Simon Dirmeier",
                "Fernando Perez-Cruz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00474v2",
                "http://arxiv.org/pdf/2311.00474v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00469v1",
            "title": "Dual Conditioned Diffusion Models for Out-Of-Distribution Detection:\n  Application to Fetal Ultrasound Videos",
            "updated": "2023-11-01T12:10:55Z",
            "published": "2023-11-01T12:10:55Z",
            "summary": "Out-of-distribution (OOD) detection is essential to improve the reliability\nof machine learning models by detecting samples that do not belong to the\ntraining distribution. Detecting OOD samples effectively in certain tasks can\npose a challenge because of the substantial heterogeneity within the\nin-distribution (ID), and the high structural similarity between ID and OOD\nclasses. For instance, when detecting heart views in fetal ultrasound videos\nthere is a high structural similarity between the heart and other anatomies\nsuch as the abdomen, and large in-distribution variance as a heart has 5\ndistinct views and structural variations within each view. To detect OOD\nsamples in this context, the resulting model should generalise to the\nintra-anatomy variations while rejecting similar OOD samples. In this paper, we\nintroduce dual-conditioned diffusion models (DCDM) where we condition the model\non in-distribution class information and latent features of the input image for\nreconstruction-based OOD detection. This constrains the generative manifold of\nthe model to generate images structurally and semantically similar to those\nwithin the in-distribution. The proposed model outperforms reference methods\nwith a 12% improvement in accuracy, 22% higher precision, and an 8% better F1\nscore.",
            "author": [
                "Divyanshu Mishra",
                "He Zhao",
                "Pramit Saha",
                "Aris T. Papageorghiou",
                "J. Alison Noble"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00469v1",
                "http://arxiv.org/pdf/2311.00469v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00735v2",
            "title": "PET Tracer Conversion among Brain PET via Variable Augmented Invertible\n  Network",
            "updated": "2023-11-15T07:28:10Z",
            "published": "2023-11-01T12:04:33Z",
            "summary": "Positron emission tomography (PET) serves as an essential tool for diagnosis\nof encephalopathy and brain science research. However, it suffers from the\nlimited choice of tracers. Nowadays, with the wide application of PET imaging\nin neuropsychiatric treatment, 6-18F-fluoro-3, 4-dihydroxy-L-phenylalanine\n(DOPA) has been found to be more effective than 18F-labeled\nfluorine-2-deoxyglucose (FDG) in the field. Nevertheless, due to the complexity\nof its preparation and other limitations, DOPA is far less widely used than\nFDG. To address this issue, a tracer conversion invertible neural network\n(TC-INN) for image projection is developed to map FDG images to DOPA images\nthrough deep learning. More diagnostic information is obtained by generating\nPET images from FDG to DOPA. Specifically, the proposed TC-INN consists of two\nseparate phases, one for training traceable data, the other for rebuilding new\ndata. The reference DOPA PET image is used as a learning target for the\ncorresponding network during the training process of tracer conversion.\nMeanwhile, the invertible network iteratively estimates the resultant DOPA PET\ndata and compares it to the reference DOPA PET data. Notably, the reversible\nmodel employs variable enhancement technique to achieve better power\ngeneration. Moreover, image registration needs to be performed before training\ndue to the angular deviation of the acquired FDG and DOPA data information.\nExperimental results exhibited excellent generation capability in mapping\nbetween FDG and DOPA, suggesting that PET tracer conversion has great potential\nin the case of limited tracer applications.",
            "author": [
                "Bohui Shen",
                "Wei Zhang",
                "Xubiao Liu",
                "Pengfei Yu",
                "Shirui Jiang",
                "Xinchong Shi",
                "Xiangsong Zhang",
                "Xiaoyu Zhou",
                "Weirui Zhang",
                "Bingxuan Li",
                "Qiegen Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00735v2",
                "http://arxiv.org/pdf/2311.00735v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "68T01"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00465v1",
            "title": "Asynchronous SGD on Graphs: a Unified Framework for Asynchronous\n  Decentralized and Federated Optimization",
            "updated": "2023-11-01T11:58:16Z",
            "published": "2023-11-01T11:58:16Z",
            "summary": "Decentralized and asynchronous communications are two popular techniques to\nspeedup communication complexity of distributed machine learning, by\nrespectively removing the dependency over a central orchestrator and the need\nfor synchronization. Yet, combining these two techniques together still remains\na challenge. In this paper, we take a step in this direction and introduce\nAsynchronous SGD on Graphs (AGRAF SGD) -- a general algorithmic framework that\ncovers asynchronous versions of many popular algorithms including SGD,\nDecentralized SGD, Local SGD, FedBuff, thanks to its relaxed communication and\ncomputation assumptions. We provide rates of convergence under much milder\nassumptions than previous decentralized asynchronous works, while still\nrecovering or even improving over the best know results for all the algorithms\ncovered.",
            "author": [
                "Mathieu Even",
                "Anastasia Koloskova",
                "Laurent Massouli\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00465v1",
                "http://arxiv.org/pdf/2311.00465v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00463v1",
            "title": "Robust and Conjugate Gaussian Process Regression",
            "updated": "2023-11-01T11:57:43Z",
            "published": "2023-11-01T11:57:43Z",
            "summary": "To enable closed form conditioning, a common assumption in Gaussian process\n(GP) regression is independent and identically distributed Gaussian observation\nnoise. This strong and simplistic assumption is often violated in practice,\nwhich leads to unreliable inferences and uncertainty quantification.\nUnfortunately, existing methods for robustifying GPs break closed-form\nconditioning, which makes them less attractive to practitioners and\nsignificantly more computationally expensive. In this paper, we demonstrate how\nto perform provably robust and conjugate Gaussian process (RCGP) regression at\nvirtually no additional cost using generalised Bayesian inference. RCGP is\nparticularly versatile as it enables exact conjugate closed form updates in all\nsettings where standard GPs admit them. To demonstrate its strong empirical\nperformance, we deploy RCGP for problems ranging from Bayesian optimisation to\nsparse variational Gaussian processes.",
            "author": [
                "Matias Altamirano",
                "Fran\u00e7ois-Xavier Briol",
                "Jeremias Knoblauch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00463v1",
                "http://arxiv.org/pdf/2311.00463v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00460v1",
            "title": "Optimal Budgeted Rejection Sampling for Generative Models",
            "updated": "2023-11-01T11:52:41Z",
            "published": "2023-11-01T11:52:41Z",
            "summary": "Rejection sampling methods have recently been proposed to improve the\nperformance of discriminator-based generative models. However, these methods\nare only optimal under an unlimited sampling budget, and are usually applied to\na generator trained independently of the rejection procedure. We first propose\nan Optimal Budgeted Rejection Sampling (OBRS) scheme that is provably optimal\nwith respect to \\textit{any} $f$-divergence between the true distribution and\nthe post-rejection distribution, for a given sampling budget. Second, we\npropose an end-to-end method that incorporates the sampling scheme into the\ntraining procedure to further enhance the model's overall performance. Through\nexperiments and supporting theory, we show that the proposed methods are\neffective in significantly improving the quality and diversity of the samples.",
            "author": [
                "Alexandre Verine",
                "Muni Sreenivas Pydi",
                "Benjamin Negrevergne",
                "Yann Chevaleyre"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00460v1",
                "http://arxiv.org/pdf/2311.00460v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00457v1",
            "title": "Single-view 3D Scene Reconstruction with High-fidelity Shape and Texture",
            "updated": "2023-11-01T11:46:15Z",
            "published": "2023-11-01T11:46:15Z",
            "summary": "Reconstructing detailed 3D scenes from single-view images remains a\nchallenging task due to limitations in existing approaches, which primarily\nfocus on geometric shape recovery, overlooking object appearances and fine\nshape details. To address these challenges, we propose a novel framework for\nsimultaneous high-fidelity recovery of object shapes and textures from\nsingle-view images. Our approach utilizes the proposed Single-view neural\nimplicit Shape and Radiance field (SSR) representations to leverage both\nexplicit 3D shape supervision and volume rendering of color, depth, and surface\nnormal images. To overcome shape-appearance ambiguity under partial\nobservations, we introduce a two-stage learning curriculum incorporating both\n3D and 2D supervisions. A distinctive feature of our framework is its ability\nto generate fine-grained textured meshes while seamlessly integrating rendering\ncapabilities into the single-view 3D reconstruction model. This integration\nenables not only improved textured 3D object reconstruction by 27.7% and 11.6%\non the 3D-FRONT and Pix3D datasets, respectively, but also supports the\nrendering of images from novel viewpoints. Beyond individual objects, our\napproach facilitates composing object-level representations into flexible scene\nrepresentations, thereby enabling applications such as holistic scene\nunderstanding and 3D scene editing. We conduct extensive experiments to\ndemonstrate the effectiveness of our method.",
            "author": [
                "Yixin Chen",
                "Junfeng Ni",
                "Nan Jiang",
                "Yaowei Zhang",
                "Yixin Zhu",
                "Siyuan Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00457v1",
                "http://arxiv.org/pdf/2311.00457v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00455v1",
            "title": "Progressive Recurrent Network for Shadow Removal",
            "updated": "2023-11-01T11:42:45Z",
            "published": "2023-11-01T11:42:45Z",
            "summary": "Single-image shadow removal is a significant task that is still unresolved.\nMost existing deep learning-based approaches attempt to remove the shadow\ndirectly, which can not deal with the shadow well. To handle this issue, we\nconsider removing the shadow in a coarse-to-fine fashion and propose a simple\nbut effective Progressive Recurrent Network (PRNet). The network aims to remove\nthe shadow progressively, enabing us to flexibly adjust the number of\niterations to strike a balance between performance and time. Our network\ncomprises two parts: shadow feature extraction and progressive shadow removal.\nSpecifically, the first part is a shallow ResNet which constructs the\nrepresentations of the input shadow image on its original size, preventing the\nloss of high-frequency details caused by the downsampling operation. The second\npart has two critical components: the re-integration module and the update\nmodule. The proposed re-integration module can fully use the outputs of the\nprevious iteration, providing input for the update module for further shadow\nremoval. In this way, the proposed PRNet makes the whole process more concise\nand only uses 29% network parameters than the best published method. Extensive\nexperiments on the three benchmarks, ISTD, ISTD+, and SRD, demonstrate that our\nmethod can effectively remove shadows and achieve superior performance.",
            "author": [
                "Yonghui Wang",
                "Wengang Zhou",
                "Hao Feng",
                "Li Li",
                "Houqiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00455v1",
                "http://arxiv.org/pdf/2311.00455v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00454v1",
            "title": "Nucleation patterns of polymer crystals analyzed by machine learning\n  models",
            "updated": "2023-11-01T11:40:01Z",
            "published": "2023-11-01T11:40:01Z",
            "summary": "We use machine learning algorithms to detect the crystalline phase in\nundercooled melts in molecular dynamics simulations. Our classification method\nis based on local conformation and environmental fingerprints of individual\nmonomers. In particular, we employ self-supervised auto-encoders to compress\nthe fingerprint information and a Gaussian mixture model to distinguish ordered\nstates from disordered ones. The resulting identification of crystalline\nmonomers agrees to a large extent with human-defined classifiers such as the\nstem-length-based classification scheme as developed in our previous work [C.\nLuo and J.-U. Sommer, Macromolecules 44 (2011), 1523], but does not require any\nforeknowledge about the structure of semi-crystalline polymers. Because of its\nlocal sensitivity, the method allows the resolution of detailed time patterns\nof crystalline order before an apparent signature of the transition is visible\nin thermodynamic properties such as for the specific volume. At a\npre-transition point, we observe the highest crystallization efficiency using\nthe fraction of monomers being conserved in the crystalline phase as compared\nto the number of monomers joining that phase.",
            "author": [
                "Atmika Bhardwaj",
                "Jens-Uwe Sommer",
                "Marco Werner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00454v1",
                "http://arxiv.org/pdf/2311.00454v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00452v1",
            "title": "Hessian Eigenvectors and Principal Component Analysis of Neural Network\n  Weight Matrices",
            "updated": "2023-11-01T11:38:31Z",
            "published": "2023-11-01T11:38:31Z",
            "summary": "This study delves into the intricate dynamics of trained deep neural networks\nand their relationships with network parameters. Trained networks predominantly\ncontinue training in a single direction, known as the drift mode. This drift\nmode can be explained by the quadratic potential model of the loss function,\nsuggesting a slow exponential decay towards the potential minima. We unveil a\ncorrelation between Hessian eigenvectors and network weights. This\nrelationship, hinging on the magnitude of eigenvalues, allows us to discern\nparameter directions within the network. Notably, the significance of these\ndirections relies on two defining attributes: the curvature of their potential\nwells (indicated by the magnitude of Hessian eigenvalues) and their alignment\nwith the weight vectors. Our exploration extends to the decomposition of weight\nmatrices through singular value decomposition. This approach proves practical\nin identifying critical directions within the Hessian, considering both their\nmagnitude and curvature. Furthermore, our examination showcases the\napplicability of principal component analysis in approximating the Hessian,\nwith update parameters emerging as a superior choice over weights for this\npurpose. Remarkably, our findings unveil a similarity between the largest\nHessian eigenvalues of individual layers and the entire network. Notably,\nhigher eigenvalues are concentrated more in deeper layers. Leveraging these\ninsights, we venture into addressing catastrophic forgetting, a challenge of\nneural networks when learning new tasks while retaining knowledge from previous\nones. By applying our discoveries, we formulate an effective strategy to\nmitigate catastrophic forgetting, offering a possible solution that can be\napplied to networks of varying scales, including larger architectures.",
            "author": [
                "David Haink"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00452v1",
                "http://arxiv.org/pdf/2311.00452v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00447v3",
            "title": "On the Opportunities of Green Computing: A Survey",
            "updated": "2023-11-09T03:08:34Z",
            "published": "2023-11-01T11:16:41Z",
            "summary": "Artificial Intelligence (AI) has achieved significant advancements in\ntechnology and research with the development over several decades, and is\nwidely used in many areas including computing vision, natural language\nprocessing, time-series analysis, speech synthesis, etc. During the age of deep\nlearning, especially with the arise of Large Language Models, a large majority\nof researchers' attention is paid on pursuing new state-of-the-art (SOTA)\nresults, resulting in ever increasing of model size and computational\ncomplexity. The needs for high computing power brings higher carbon emission\nand undermines research fairness by preventing small or medium-sized research\ninstitutions and companies with limited funding in participating in research.\nTo tackle the challenges of computing resources and environmental impact of AI,\nGreen Computing has become a hot research topic. In this survey, we give a\nsystematic overview of the technologies used in Green Computing. We propose the\nframework of Green Computing and devide it into four key components: (1)\nMeasures of Greenness, (2) Energy-Efficient AI, (3) Energy-Efficient Computing\nSystems and (4) AI Use Cases for Sustainability. For each components, we\ndiscuss the research progress made and the commonly used techniques to optimize\nthe AI efficiency. We conclude that this new research direction has the\npotential to address the conflicts between resource constraints and AI\ndevelopment. We encourage more researchers to put attention on this direction\nand make AI more environmental friendly.",
            "author": [
                "You Zhou",
                "Xiujing Lin",
                "Xiang Zhang",
                "Maolin Wang",
                "Gangwei Jiang",
                "Huakang Lu",
                "Yupeng Wu",
                "Kai Zhang",
                "Zhe Yang",
                "Kehang Wang",
                "Yongduo Sui",
                "Fengwei Jia",
                "Zuoli Tang",
                "Yao Zhao",
                "Hongxuan Zhang",
                "Tiannuo Yang",
                "Weibo Chen",
                "Yunong Mao",
                "Yi Li",
                "De Bao",
                "Yu Li",
                "Hongrui Liao",
                "Ting Liu",
                "Jingwen Liu",
                "Jinchi Guo",
                "Xiangyu Zhao",
                "Ying WEI",
                "Hong Qian",
                "Qi Liu",
                "Xiang Wang",
                "Wai Kin",
                "Chan",
                "Chenliang Li",
                "Yusen Li",
                "Shiyu Yang",
                "Jining Yan",
                "Chao Mou",
                "Shuai Han",
                "Wuxia Jin",
                "Guannan Zhang",
                "Xiaodong Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00447v3",
                "http://arxiv.org/pdf/2311.00447v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00445v1",
            "title": "A Systematic Comparison of Syllogistic Reasoning in Humans and Language\n  Models",
            "updated": "2023-11-01T11:13:06Z",
            "published": "2023-11-01T11:13:06Z",
            "summary": "A central component of rational behavior is logical inference: the process of\ndetermining which conclusions follow from a set of premises. Psychologists have\ndocumented several ways in which humans' inferences deviate from the rules of\nlogic. Do language models, which are trained on text generated by humans,\nreplicate these biases, or are they able to overcome them? Focusing on the case\nof syllogisms -- inferences from two simple premises, which have been studied\nextensively in psychology -- we show that larger models are more logical than\nsmaller ones, and also more logical than humans. At the same time, even the\nlargest models make systematic errors, some of which mirror human reasoning\nbiases such as ordering effects and logical fallacies. Overall, we find that\nlanguage models mimic the human biases included in their training data, but are\nable to overcome them in some cases.",
            "author": [
                "Tiwalayo Eisape",
                "MH Tessler",
                "Ishita Dasgupta",
                "Fei Sha",
                "Sjoerd van Steenkiste",
                "Tal Linzen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00445v1",
                "http://arxiv.org/pdf/2311.00445v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00444v1",
            "title": "Form follows Function: Text-to-Text Conditional Graph Generation based\n  on Functional Requirements",
            "updated": "2023-11-01T11:12:02Z",
            "published": "2023-11-01T11:12:02Z",
            "summary": "This work focuses on the novel problem setting of generating graphs\nconditioned on a description of the graph's functional requirements in a\ndownstream task. We pose the problem as a text-to-text generation problem and\nfocus on the approach of fine-tuning a pretrained large language model (LLM) to\ngenerate graphs. We propose an inductive bias which incorporates information\nabout the structure of the graph into the LLM's generation process by\nincorporating message passing layers into an LLM's architecture. To evaluate\nour proposed method, we design a novel set of experiments using publicly\navailable and widely studied molecule and knowledge graph data sets. Results\nsuggest our proposed approach generates graphs which more closely meet the\nrequested functional requirements, outperforming baselines developed on similar\ntasks by a statistically significant margin.",
            "author": [
                "Peter A. Zachares",
                "Vahan Hovhannisyan",
                "Alan Mosca",
                "Yarin Gal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00444v1",
                "http://arxiv.org/pdf/2311.00444v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00441v1",
            "title": "Improving Robustness for Vision Transformer with a Simple Dynamic\n  Scanning Augmentation",
            "updated": "2023-11-01T11:10:01Z",
            "published": "2023-11-01T11:10:01Z",
            "summary": "Vision Transformer (ViT) has demonstrated promising performance in computer\nvision tasks, comparable to state-of-the-art neural networks. Yet, this new\ntype of deep neural network architecture is vulnerable to adversarial attacks\nlimiting its capabilities in terms of robustness. This article presents a novel\ncontribution aimed at further improving the accuracy and robustness of ViT,\nparticularly in the face of adversarial attacks. We propose an augmentation\ntechnique called `Dynamic Scanning Augmentation' that leverages dynamic input\nsequences to adaptively focus on different patches, thereby maintaining\nperformance and robustness. Our detailed investigations reveal that this\nadaptability to the input sequence induces significant changes in the attention\nmechanism of ViT, even for the same image. We introduce four variations of\nDynamic Scanning Augmentation, outperforming ViT in terms of both robustness to\nadversarial attacks and accuracy against natural images, with one variant\nshowing comparable results. By integrating our augmentation technique, we\nobserve a substantial increase in ViT's robustness, improving it from $17\\%$ to\n$92\\%$ measured across different types of adversarial attacks. These findings,\ntogether with other comprehensive tests, indicate that Dynamic Scanning\nAugmentation enhances accuracy and robustness by promoting a more adaptive type\nof attention. In conclusion, this work contributes to the ongoing research on\nVision Transformers by introducing Dynamic Scanning Augmentation as a technique\nfor improving the accuracy and robustness of ViT. The observed results\nhighlight the potential of this approach in advancing computer vision tasks and\nmerit further exploration in future studies.",
            "author": [
                "Shashank Kotyan",
                "Danilo Vasconcellos Vargas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00441v1",
                "http://arxiv.org/pdf/2311.00441v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00429v2",
            "title": "Crop Disease Classification using Support Vector Machines with Green\n  Chromatic Coordinate (GCC) and Attention based feature extraction for IoT\n  based Smart Agricultural Applications",
            "updated": "2023-11-06T09:58:25Z",
            "published": "2023-11-01T10:44:49Z",
            "summary": "Crops hold paramount significance as they serve as the primary provider of\nenergy, nutrition, and medicinal benefits for the human population. Plant\ndiseases, however, can negatively affect leaves during agricultural\ncultivation, resulting in significant losses in crop output and economic value.\nTherefore, it is crucial for farmers to identify crop diseases. However, this\nmethod frequently necessitates hard work, a lot of planning, and in-depth\nfamiliarity with plant pathogens. Given these numerous obstacles, it is\nessential to provide solutions that can easily interface with mobile and IoT\ndevices so that our farmers can guarantee the best possible crop development.\nVarious machine learning (ML) as well as deep learning (DL) algorithms have\nbeen created & studied for the identification of plant disease detection,\nyielding substantial and promising results. This article presents a novel\nclassification method that builds on prior work by utilising attention-based\nfeature extraction, RGB channel-based chromatic analysis, Support Vector\nMachines (SVM) for improved performance, and the ability to integrate with\nmobile applications and IoT devices after quantization of information. Several\ndisease classification algorithms were compared with the suggested model, and\nit was discovered that, in terms of accuracy, Vision Transformer-based feature\nextraction and additional Green Chromatic Coordinate feature with SVM\nclassification achieved an accuracy of (GCCViT-SVM) - 99.69%, whereas after\nquantization for IoT device integration achieved an accuracy of - 97.41% while\nalmost reducing 4x in size. Our findings have profound implications because\nthey have the potential to transform how farmers identify crop illnesses with\nprecise and fast information, thereby preserving agricultural output and\nensuring food security.",
            "author": [
                "Shashwat Jha",
                "Vishvaditya Luhach",
                "Gauri Shanker Gupta",
                "Beependra Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00429v2",
                "http://arxiv.org/pdf/2311.00429v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00428v1",
            "title": "NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust\n  Multi-Exit Neural Networks",
            "updated": "2023-11-01T10:44:05Z",
            "published": "2023-11-01T10:44:05Z",
            "summary": "While multi-exit neural networks are regarded as a promising solution for\nmaking efficient inference via early exits, combating adversarial attacks\nremains a challenging problem. In multi-exit networks, due to the high\ndependency among different submodels, an adversarial example targeting a\nspecific exit not only degrades the performance of the target exit but also\nreduces the performance of all other exits concurrently. This makes multi-exit\nnetworks highly vulnerable to simple adversarial attacks. In this paper, we\npropose NEO-KD, a knowledge-distillation-based adversarial training strategy\nthat tackles this fundamental challenge based on two key contributions. NEO-KD\nfirst resorts to neighbor knowledge distillation to guide the output of the\nadversarial examples to tend to the ensemble outputs of neighbor exits of clean\ndata. NEO-KD also employs exit-wise orthogonal knowledge distillation for\nreducing adversarial transferability across different submodels. The result is\na significantly improved robustness against adversarial attacks. Experimental\nresults on various datasets/models show that our method achieves the best\nadversarial accuracy with reduced computation budgets, compared to the\nbaselines relying on existing adversarial training or knowledge distillation\ntechniques for multi-exit networks.",
            "author": [
                "Seokil Ham",
                "Jungwuk Park",
                "Dong-Jun Han",
                "Jaekyun Moon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00428v1",
                "http://arxiv.org/pdf/2311.00428v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00426v1",
            "title": "Enhanced Generalization through Prioritization and Diversity in\n  Self-Imitation Reinforcement Learning over Procedural Environments with\n  Sparse Rewards",
            "updated": "2023-11-01T10:40:46Z",
            "published": "2023-11-01T10:40:46Z",
            "summary": "Exploration poses a fundamental challenge in Reinforcement Learning (RL) with\nsparse rewards, limiting an agent's ability to learn optimal decision-making\ndue to a lack of informative feedback signals. Self-Imitation Learning\n(self-IL) has emerged as a promising approach for exploration, leveraging a\nreplay buffer to store and reproduce successful behaviors. However, traditional\nself-IL methods, which rely on high-return transitions and assume singleton\nenvironments, face challenges in generalization, especially in\nprocedurally-generated (PCG) environments. Therefore, new self-IL methods have\nbeen proposed to rank which experiences to persist, but they replay transitions\nuniformly regardless of their significance, and do not address the diversity of\nthe stored demonstrations. In this work, we propose tailored self-IL sampling\nstrategies by prioritizing transitions in different ways and extending\nprioritization techniques to PCG environments. We also address diversity loss\nthrough modifications to counteract the impact of generalization requirements\nand bias introduced by prioritization techniques. Our experimental analysis,\nconducted over three PCG sparse reward environments, including MiniGrid and\nProcGen, highlights the benefits of our proposed modifications, achieving a new\nstate-of-the-art performance in the MiniGrid-MultiRoom-N12-S10 environment.",
            "author": [
                "Alain Andres",
                "Daochen Zha",
                "Javier Del Ser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00426v1",
                "http://arxiv.org/pdf/2311.00426v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00423v5",
            "title": "LLMRec: Large Language Models with Graph Augmentation for Recommendation",
            "updated": "2023-11-29T05:52:56Z",
            "published": "2023-11-01T10:27:44Z",
            "summary": "The problem of data sparsity has long been a challenge in recommendation\nsystems, and previous studies have attempted to address this issue by\nincorporating side information. However, this approach often introduces side\neffects such as noise, availability issues, and low data quality, which in turn\nhinder the accurate modeling of user preferences and adversely impact\nrecommendation performance. In light of the recent advancements in large\nlanguage models (LLMs), which possess extensive knowledge bases and strong\nreasoning capabilities, we propose a novel framework called LLMRec that\nenhances recommender systems by employing three simple yet effective LLM-based\ngraph augmentation strategies. Our approach leverages the rich content\navailable within online platforms (e.g., Netflix, MovieLens) to augment the\ninteraction graph in three ways: (i) reinforcing user-item interaction egde,\n(ii) enhancing the understanding of item node attributes, and (iii) conducting\nuser node profiling, intuitively from the natural language perspective. By\nemploying these strategies, we address the challenges posed by sparse implicit\nfeedback and low-quality side information in recommenders. Besides, to ensure\nthe quality of the augmentation, we develop a denoised data robustification\nmechanism that includes techniques of noisy implicit feedback pruning and\nMAE-based feature enhancement that help refine the augmented data and improve\nits reliability. Furthermore, we provide theoretical analysis to support the\neffectiveness of LLMRec and clarify the benefits of our method in facilitating\nmodel optimization. Experimental results on benchmark datasets demonstrate the\nsuperiority of our LLM-based augmentation approach over state-of-the-art\ntechniques. To ensure reproducibility, we have made our code and augmented data\npublicly available at: https://github.com/HKUDS/LLMRec.git",
            "author": [
                "Wei Wei",
                "Xubin Ren",
                "Jiabin Tang",
                "Qinyong Wang",
                "Lixin Su",
                "Suqi Cheng",
                "Junfeng Wang",
                "Dawei Yin",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00423v5",
                "http://arxiv.org/pdf/2311.00423v5"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00416v1",
            "title": "Efficient Human-AI Coordination via Preparatory Language-based\n  Convention",
            "updated": "2023-11-01T10:18:23Z",
            "published": "2023-11-01T10:18:23Z",
            "summary": "Developing intelligent agents capable of seamless coordination with humans is\na critical step towards achieving artificial general intelligence. Existing\nmethods for human-AI coordination typically train an agent to coordinate with a\ndiverse set of policies or with human models fitted from real human data.\nHowever, the massively diverse styles of human behavior present obstacles for\nAI systems with constrained capacity, while high quality human data may not be\nreadily available in real-world scenarios. In this study, we observe that prior\nto coordination, humans engage in communication to establish conventions that\nspecify individual roles and actions, making their coordination proceed in an\norderly manner. Building upon this observation, we propose employing the large\nlanguage model (LLM) to develop an action plan (or equivalently, a convention)\nthat effectively guides both human and AI. By inputting task requirements,\nhuman preferences, the number of agents, and other pertinent information into\nthe LLM, it can generate a comprehensive convention that facilitates a clear\nunderstanding of tasks and responsibilities for all parties involved.\nFurthermore, we demonstrate that decomposing the convention formulation problem\ninto sub-problems with multiple new sessions being sequentially employed and\nhuman feedback, will yield a more efficient coordination convention.\nExperimental evaluations conducted in the Overcooked-AI environment, utilizing\na human proxy model, highlight the superior performance of our proposed method\ncompared to existing learning-based approaches. When coordinating with real\nhumans, our method achieves better alignment with human preferences and an\naverage performance improvement of 15% compared to the state-of-the-art.",
            "author": [
                "Cong Guan",
                "Lichao Zhang",
                "Chunpeng Fan",
                "Yichen Li",
                "Feng Chen",
                "Lihe Li",
                "Yunjia Tian",
                "Lei Yuan",
                "Yang Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00416v1",
                "http://arxiv.org/pdf/2311.00416v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00412v1",
            "title": "Feature-oriented Deep Learning Framework for Pulmonary Cone-beam CT\n  (CBCT) Enhancement with Multi-task Customized Perceptual Loss",
            "updated": "2023-11-01T10:09:01Z",
            "published": "2023-11-01T10:09:01Z",
            "summary": "Cone-beam computed tomography (CBCT) is routinely collected during\nimage-guided radiation therapy (IGRT) to provide updated patient anatomy\ninformation for cancer treatments. However, CBCT images often suffer from\nstreaking artifacts and noise caused by under-rate sampling projections and\nlow-dose exposure, resulting in low clarity and information loss. While recent\ndeep learning-based CBCT enhancement methods have shown promising results in\nsuppressing artifacts, they have limited performance on preserving anatomical\ndetails since conventional pixel-to-pixel loss functions are incapable of\ndescribing detailed anatomy. To address this issue, we propose a novel\nfeature-oriented deep learning framework that translates low-quality CBCT\nimages into high-quality CT-like imaging via a multi-task customized\nfeature-to-feature perceptual loss function. The framework comprises two main\ncomponents: a multi-task learning feature-selection network(MTFS-Net) for\ncustomizing the perceptual loss function; and a CBCT-to-CT translation network\nguided by feature-to-feature perceptual loss, which uses advanced generative\nmodels such as U-Net, GAN and CycleGAN. Our experiments showed that the\nproposed framework can generate synthesized CT (sCT) images for the lung that\nachieved a high similarity to CT images, with an average SSIM index of 0.9869\nand an average PSNR index of 39.9621. The sCT images also achieved visually\npleasing performance with effective artifacts suppression, noise reduction, and\ndistinctive anatomical details preservation. Our experiment results indicate\nthat the proposed framework outperforms the state-of-the-art models for\npulmonary CBCT enhancement. This framework holds great promise for generating\nhigh-quality anatomical imaging from CBCT that is suitable for various clinical\napplications.",
            "author": [
                "Jiarui Zhu",
                "Werxing Chen",
                "Hongfei Sun",
                "Shaohua Zhi",
                "Jing Qin",
                "Jing Cai",
                "Ge Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00412v1",
                "http://arxiv.org/pdf/2311.00412v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00397v2",
            "title": "Towards Omni-supervised Referring Expression Segmentation",
            "updated": "2023-11-27T09:02:06Z",
            "published": "2023-11-01T09:46:59Z",
            "summary": "Referring Expression Segmentation (RES) is an emerging task in computer\nvision, which segments the target instances in images based on text\ndescriptions. However, its development is plagued by the expensive segmentation\nlabels. To address this issue, we propose a new learning task for RES called\nOmni-supervised Referring Expression Segmentation (Omni-RES), which aims to\nmake full use of unlabeled, fully labeled and weakly labeled data, e.g.,\nreferring points or grounding boxes, for efficient RES training. To accomplish\nthis task, we also propose a novel yet strong baseline method for Omni-RES\nbased on the recently popular teacher-student learning, where the weak labels\nare not directly transformed into supervision signals but used as a yardstick\nto select and refine high-quality pseudo-masks for teacher-student learning. To\nvalidate the proposed Omni-RES method, we apply it to a set of state-of-the-art\nRES models and conduct extensive experiments on a bunch of RES datasets. The\nexperimental results yield the obvious merits of Omni-RES than the\nfully-supervised and semi-supervised training schemes. For instance, with only\n10% fully labeled data, Omni-RES can help the base model achieve 100% fully\nsupervised performance, and it also outperform the semi-supervised alternative\nby a large margin, e.g., +14.93% on RefCOCO and +14.95% on RefCOCO+,\nrespectively. More importantly, Omni-RES also enable the use of large-scale\nvision-langauges like Visual Genome to facilitate low-cost RES training, and\nachieve new SOTA performance of RES, e.g., 80.66 on RefCOCO.",
            "author": [
                "Minglang Huang",
                "Yiyi Zhou",
                "Gen Luo",
                "Guannan Jiang",
                "Weilin Zhuang",
                "Xiaoshuai Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00397v2",
                "http://arxiv.org/pdf/2311.00397v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00393v1",
            "title": "Augmenting deep neural networks with symbolic knowledge: Towards\n  trustworthy and interpretable AI for education",
            "updated": "2023-11-01T09:38:56Z",
            "published": "2023-11-01T09:38:56Z",
            "summary": "Artificial neural networks (ANNs) have shown to be amongst the most important\nartificial intelligence (AI) techniques in educational applications, providing\nadaptive educational services. However, their educational potential is limited\nin practice due to three major challenges: i) difficulty in incorporating\nsymbolic educational knowledge (e.g., causal relationships, and practitioners'\nknowledge) in their development, ii) learning and reflecting biases, and iii)\nlack of interpretability. Given the high-risk nature of education, the\nintegration of educational knowledge into ANNs becomes crucial for developing\nAI applications that adhere to essential educational restrictions, and provide\ninterpretability over the predictions. This research argues that the\nneural-symbolic family of AI has the potential to address the named challenges.\nTo this end, it adapts a neural-symbolic AI framework and accordingly develops\nan approach called NSAI, that injects and extracts educational knowledge into\nand from deep neural networks, for modelling learners computational thinking.\nOur findings reveal that the NSAI approach has better generalizability compared\nto deep neural networks trained merely on training data, as well as training\ndata augmented by SMOTE and autoencoder methods. More importantly, unlike the\nother models, the NSAI approach prioritises robust representations that capture\ncausal relationships between input features and output labels, ensuring safety\nin learning to avoid spurious correlations and control biases in training data.\nFurthermore, the NSAI approach enables the extraction of rules from the learned\nnetwork, facilitating interpretation and reasoning about the path to\npredictions, as well as refining the initial educational knowledge. These\nfindings imply that neural-symbolic AI can overcome the limitations of ANNs in\neducation, enabling trustworthy and interpretable applications.",
            "author": [
                "Danial Hooshyar",
                "Roger Azevedo",
                "Yeongwook Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00393v1",
                "http://arxiv.org/pdf/2311.00393v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "I.2.0, I.2.1, I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00389v1",
            "title": "NeuralGF: Unsupervised Point Normal Estimation by Learning Neural\n  Gradient Function",
            "updated": "2023-11-01T09:25:29Z",
            "published": "2023-11-01T09:25:29Z",
            "summary": "Normal estimation for 3D point clouds is a fundamental task in 3D geometry\nprocessing. The state-of-the-art methods rely on priors of fitting local\nsurfaces learned from normal supervision. However, normal supervision in\nbenchmarks comes from synthetic shapes and is usually not available from real\nscans, thereby limiting the learned priors of these methods. In addition,\nnormal orientation consistency across shapes remains difficult to achieve\nwithout a separate post-processing procedure. To resolve these issues, we\npropose a novel method for estimating oriented normals directly from point\nclouds without using ground truth normals as supervision. We achieve this by\nintroducing a new paradigm for learning neural gradient functions, which\nencourages the neural network to fit the input point clouds and yield unit-norm\ngradients at the points. Specifically, we introduce loss functions to\nfacilitate query points to iteratively reach the moving targets and aggregate\nonto the approximated surface, thereby learning a global surface representation\nof the data. Meanwhile, we incorporate gradients into the surface approximation\nto measure the minimum signed deviation of queries, resulting in a consistent\ngradient field associated with the surface. These techniques lead to our deep\nunsupervised oriented normal estimator that is robust to noise, outliers and\ndensity variations. Our excellent results on widely used benchmarks demonstrate\nthat our method can learn more accurate normals for both unoriented and\noriented normal estimation tasks than the latest methods. The source code and\npre-trained model are publicly available at https://github.com/LeoQLi/NeuralGF.",
            "author": [
                "Qing Li",
                "Huifang Feng",
                "Kanle Shi",
                "Yue Gao",
                "Yi Fang",
                "Yu-Shen Liu",
                "Zhizhong Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00389v1",
                "http://arxiv.org/pdf/2311.00389v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00388v1",
            "title": "Towards Automatic Sampling of User Behaviors for Sequential Recommender\n  Systems",
            "updated": "2023-11-01T09:25:21Z",
            "published": "2023-11-01T09:25:21Z",
            "summary": "Sequential recommender systems (SRS) have gained widespread popularity in\nrecommendation due to their ability to effectively capture dynamic user\npreferences. One default setting in the current SRS is to uniformly consider\neach historical behavior as a positive interaction. Actually, this setting has\nthe potential to yield sub-optimal performance, as each item makes a distinct\ncontribution to the user's interest. For example, purchased items should be\ngiven more importance than clicked ones. Hence, we propose a general automatic\nsampling framework, named AutoSAM, to non-uniformly treat historical behaviors.\nSpecifically, AutoSAM augments the standard sequential recommendation\narchitecture with an additional sampler layer to adaptively learn the skew\ndistribution of the raw input, and then sample informative sub-sets to build\nmore generalizable SRS. To overcome the challenges of non-differentiable\nsampling actions and also introduce multiple decision factors for sampling, we\nfurther introduce a novel reinforcement learning based method to guide the\ntraining of the sampler. We theoretically design multi-objective sampling\nrewards including Future Prediction and Sequence Perplexity, and then optimize\nthe whole framework in an end-to-end manner by combining the policy gradient.\nWe conduct extensive experiments on benchmark recommender models and four\nreal-world datasets. The experimental results demonstrate the effectiveness of\nthe proposed approach. We will make our code publicly available after the\nacceptance.",
            "author": [
                "Hao Zhang",
                "Mingyue Cheng",
                "Qi Liu",
                "Zhiding Liu",
                "Enhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00388v1",
                "http://arxiv.org/pdf/2311.00388v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00382v1",
            "title": "Will Code Remain a Relevant User Interface for End-User Programming with\n  Generative AI Models?",
            "updated": "2023-11-01T09:20:21Z",
            "published": "2023-11-01T09:20:21Z",
            "summary": "The research field of end-user programming has largely been concerned with\nhelping non-experts learn to code sufficiently well in order to achieve their\ntasks. Generative AI stands to obviate this entirely by allowing users to\ngenerate code from naturalistic language prompts. In this essay, we explore the\nextent to which \"traditional\" programming languages remain relevant for\nnon-expert end-user programmers in a world with generative AI. We posit the\n\"generative shift hypothesis\": that generative AI will create qualitative and\nquantitative expansions in the traditional scope of end-user programming. We\noutline some reasons that traditional programming languages may still be\nrelevant and useful for end-user programmers. We speculate whether each of\nthese reasons might be fundamental and enduring, or whether they may disappear\nwith further improvements and innovations in generative AI. Finally, we\narticulate a set of implications for end-user programming research, including\nthe possibility of needing to revisit many well-established core concepts, such\nas Ko's learning barriers and Blackwell's attention investment model.",
            "author": [
                "Advait Sarkar"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3622758.3622882",
                "http://arxiv.org/abs/2311.00382v1",
                "http://arxiv.org/pdf/2311.00382v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00377v1",
            "title": "Uncertainty quantification and out-of-distribution detection using\n  surjective normalizing flows",
            "updated": "2023-11-01T09:08:35Z",
            "published": "2023-11-01T09:08:35Z",
            "summary": "Reliable quantification of epistemic and aleatoric uncertainty is of crucial\nimportance in applications where models are trained in one environment but\napplied to multiple different environments, often seen in real-world\napplications for example, in climate science or mobility analysis. We propose a\nsimple approach using surjective normalizing flows to identify\nout-of-distribution data sets in deep neural network models that can be\ncomputed in a single forward pass. The method builds on recent developments in\ndeep uncertainty quantification and generative modeling with normalizing flows.\nWe apply our method to a synthetic data set that has been simulated using a\nmechanistic model from the mobility literature and several data sets simulated\nfrom interventional distributions induced by soft and atomic interventions on\nthat model, and demonstrate that our method can reliably discern\nout-of-distribution data from in-distribution data. We compare the surjective\nflow model to a Dirichlet process mixture model and a bijective flow and find\nthat the surjections are a crucial component to reliably distinguish\nin-distribution from out-of-distribution data.",
            "author": [
                "Simon Dirmeier",
                "Ye Hong",
                "Yanan Xin",
                "Fernando Perez-Cruz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00377v1",
                "http://arxiv.org/pdf/2311.00377v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00371v1",
            "title": "Learning Cooperative Trajectory Representations for Motion Forecasting",
            "updated": "2023-11-01T08:53:05Z",
            "published": "2023-11-01T08:53:05Z",
            "summary": "Motion forecasting is an essential task for autonomous driving, and the\neffective information utilization from infrastructure and other vehicles can\nenhance motion forecasting capabilities. Existing research have primarily\nfocused on leveraging single-frame cooperative information to enhance the\nlimited perception capability of the ego vehicle, while underutilizing the\nmotion and interaction information of traffic participants observed from\ncooperative devices. In this paper, we first propose the cooperative trajectory\nrepresentations learning paradigm. Specifically, we present V2X-Graph, the\nfirst interpretable and end-to-end learning framework for cooperative motion\nforecasting. V2X-Graph employs an interpretable graph to fully leverage the\ncooperative motion and interaction contexts. Experimental results on the\nvehicle-to-infrastructure (V2I) motion forecasting dataset, V2X-Seq,\ndemonstrate the effectiveness of V2X-Graph. To further evaluate on V2X\nscenario, we construct the first real-world vehicle-to-everything (V2X) motion\nforecasting dataset V2X-Traj, and the performance shows the advantage of our\nmethod. We hope both V2X-Graph and V2X-Traj can facilitate the further\ndevelopment of cooperative motion forecasting. Find project at\nhttps://github.com/AIR-THU/V2X-Graph, find data at\nhttps://github.com/AIR-THU/DAIR-V2X-Seq.",
            "author": [
                "Hongzhi Ruan",
                "Haibao Yu",
                "Wenxian Yang",
                "Siqi Fan",
                "Yingjuan Tang",
                "Zaiqing Nie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00371v1",
                "http://arxiv.org/pdf/2311.00371v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00368v1",
            "title": "Performance Optimization of Deep Learning Sparse Matrix Kernels on Intel\n  Max Series GPU",
            "updated": "2023-11-01T08:43:59Z",
            "published": "2023-11-01T08:43:59Z",
            "summary": "In this paper, we focus on three sparse matrix operations that are relevant\nfor machine learning applications, namely, the sparse-dense matrix\nmultiplication (SPMM), the sampled dense-dense matrix multiplication (SDDMM),\nand the composition of the SDDMM with SPMM, also termed as FusedMM. We develop\noptimized implementations for SPMM, SDDMM, and FusedMM operations utilizing\nIntel oneAPI's Explicit SIMD (ESIMD) SYCL extension API. In contrast to CUDA or\nSYCL, the ESIMD API enables the writing of explicitly vectorized kernel code.\nSparse matrix algorithms implemented with the ESIMD API achieved performance\nclose to the peak of the targeted Intel Data Center GPU. We compare our\nperformance results to Intel's oneMKL library on Intel GPUs and to a recent\nCUDA implementation for the sparse matrix operations on NVIDIA's V100 GPU and\ndemonstrate that our implementations for sparse matrix operations outperform\neither.",
            "author": [
                "Mohammad Zubair",
                "Christoph Bauinger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00368v1",
                "http://arxiv.org/pdf/2311.00368v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MS",
                "68-04 (Primary) 68T07, 68W10 (Secondary)",
                "I.2.5; G.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00367v1",
            "title": "Prompt-based Logical Semantics Enhancement for Implicit Discourse\n  Relation Recognition",
            "updated": "2023-11-01T08:38:08Z",
            "published": "2023-11-01T08:38:08Z",
            "summary": "Implicit Discourse Relation Recognition (IDRR), which infers discourse\nrelations without the help of explicit connectives, is still a crucial and\nchallenging task for discourse parsing. Recent works tend to exploit the\nhierarchical structure information from the annotated senses, which demonstrate\nenhanced discourse relation representations can be obtained by integrating\nsense hierarchy. Nevertheless, the performance and robustness for IDRR are\nsignificantly constrained by the availability of annotated data. Fortunately,\nthere is a wealth of unannotated utterances with explicit connectives, that can\nbe utilized to acquire enriched discourse relation features. In light of such\nmotivation, we propose a Prompt-based Logical Semantics Enhancement (PLSE)\nmethod for IDRR. Essentially, our method seamlessly injects knowledge relevant\nto discourse relation into pre-trained language models through prompt-based\nconnective prediction. Furthermore, considering the prompt-based connective\nprediction exhibits local dependencies due to the deficiency of masked language\nmodel (MLM) in capturing global semantics, we design a novel self-supervised\nlearning objective based on mutual information maximization to derive enhanced\nrepresentations of logical semantics for IDRR. Experimental results on PDTB 2.0\nand CoNLL16 datasets demonstrate that our method achieves outstanding and\nconsistent performance against the current state-of-the-art models.",
            "author": [
                "Chenxu Wang",
                "Ping Jian",
                "Mu Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00367v1",
                "http://arxiv.org/pdf/2311.00367v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12035v1",
            "title": "Delta Score: Improving the Binding Assessment of Structure-Based Drug\n  Design Methods",
            "updated": "2023-11-01T08:37:39Z",
            "published": "2023-11-01T08:37:39Z",
            "summary": "Structure-based drug design (SBDD) stands at the forefront of drug discovery,\nemphasizing the creation of molecules that target specific binding pockets.\nRecent advances in this area have witnessed the adoption of deep generative\nmodels and geometric deep learning techniques, modeling SBDD as a conditional\ngeneration task where the target structure serves as context. Historically,\nevaluation of these models centered on docking scores, which quantitatively\ndepict the predicted binding affinity between a molecule and its target pocket.\nThough state-of-the-art models purport that a majority of their generated\nligands exceed the docking score of ground truth ligands in test sets, it begs\nthe question: Do these scores align with real-world biological needs? In this\npaper, we introduce the delta score, a novel evaluation metric grounded in\ntangible pharmaceutical requisites. Our experiments reveal that molecules\nproduced by current deep generative models significantly lag behind ground\ntruth reference ligands when assessed with the delta score. This novel metric\nnot only complements existing benchmarks but also provides a pivotal direction\nfor subsequent research in the domain.",
            "author": [
                "Minsi Ren",
                "Bowen Gao",
                "Bo Qiang",
                "Yanyan Lan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12035v1",
                "http://arxiv.org/pdf/2311.12035v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00366v1",
            "title": "Machine learning meets Singular Optics: Speckle-based Structured light\n  demultiplexing",
            "updated": "2023-11-01T08:36:53Z",
            "published": "2023-11-01T08:36:53Z",
            "summary": "In this paper, the advancements in structured light beams recognition using\nspeckle-based convolutional neural networks (CNNs) have been presented. Speckle\nfields, generated by the interference of multiple wavefronts diffracted and\nscattered through a diffuser, project a random distribution. The generated\nrandom distribution of phase and intensity correlates to the structured light\nbeam of the corresponding speckle field. This unique distribution of phase and\nintensity offers an additional dimension for recognizing the encoded\ninformation in structured light. The CNNs are well-suited for harnessing this\nunique ability to recognize the speckle field by learning hidden patterns\nwithin data. One notable advantage of speckle-based recognition is their\nability to identify structured light beams from a small portion of the speckle\nfield, even in high-noise environments. The diffractive nature of the speckle\nfield enables off-axis recognition, showcasing its capability in information\nbroadcasting employing structured light beams. This is a significant departure\nfrom direct-mode detection-based models to alignment-free speckle-based\ndetection models, which are no longer constrained by the directionality of\nlaser beams.",
            "author": [
                "Venugopal Raskatla",
                "Purnesh Singh Badavath",
                "Vijay Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00366v1",
                "http://arxiv.org/pdf/2311.00366v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00359v1",
            "title": "Inverse identification framework for cohesive zone model incorporating\n  failure mode based on multi-island genetic algorithm",
            "updated": "2023-11-01T08:10:36Z",
            "published": "2023-11-01T08:10:36Z",
            "summary": "Composite interfaces are commonly simulated by cohesive zone models with the\nkey challenge being the calibration of interfacial parameters. A new framework\nis presented in this paper to derive the characteristic of any cohesive zone\nmodel. This approach employs the multi-island genetic algorithm to obtain the\ninterface parameters aligning closely with the experimental observations. The\nintroduced framework innovatively formulates an objective function, considering\nboth the congruence of the load-displacement curve and the alignment with the\nfailure mode of model. The framework combines machine learning and\nmulti-objective optimization. A method using the interface debonding length to\nquantify the failure mode of the model is proposed. To demonstrate the\nfeasibility of the proposed framework, the newly strength-based cohesive zone\nmodel is taken as an example, and key parameters and damage evolution are\nidentified accurately. The inverse algorithm is used to identify the interface\nparameters of both the double cantilever beam experiment and the four-point\nbending test. The robustness and accuracy of the framework are validated\nthrough the double cantilever beam test. The findings indicate that the\nnumerical results align closely with the experimental data, confirming that the\ninterface parameters identified by the proposed framework can reproduce the\nperformance of the adhesive joints.",
            "author": [
                "Tianxiang Shi",
                "Miao Pang",
                "Yangyang Wang",
                "Yongqiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00359v1",
                "http://arxiv.org/pdf/2311.00359v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00358v1",
            "title": "Rethinking Samples Selection for Contrastive Learning: Mining of\n  Potential Samples",
            "updated": "2023-11-01T08:08:06Z",
            "published": "2023-11-01T08:08:06Z",
            "summary": "Contrastive learning predicts whether two images belong to the same category\nby training a model to make their feature representations as close or as far\naway as possible. In this paper, we rethink how to mine samples in contrastive\nlearning, unlike other methods, our approach is more comprehensive, taking into\naccount both positive and negative samples, and mining potential samples from\ntwo aspects: First, for positive samples, we consider both the augmented sample\nviews obtained by data augmentation and the mined sample views through data\nmining. Then, we weight and combine them using both soft and hard weighting\nstrategies. Second, considering the existence of uninformative negative samples\nand false negative samples in the negative samples, we analyze the negative\nsamples from the gradient perspective and finally mine negative samples that\nare neither too hard nor too easy as potential negative samples, i.e., those\nnegative samples that are close to positive samples. The experiments show the\nobvious advantages of our method compared with some traditional self-supervised\nmethods. Our method achieves 88.57%, 61.10%, and 36.69% top-1 accuracy on\nCIFAR10, CIFAR100, and TinyImagenet, respectively.",
            "author": [
                "Hengkui Dong",
                "Xianzhong Long",
                "Yun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00358v1",
                "http://arxiv.org/pdf/2311.00358v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00356v1",
            "title": "QFree: A Universal Value Function Factorization for Multi-Agent\n  Reinforcement Learning",
            "updated": "2023-11-01T08:07:16Z",
            "published": "2023-11-01T08:07:16Z",
            "summary": "Centralized training is widely utilized in the field of multi-agent\nreinforcement learning (MARL) to assure the stability of training process. Once\na joint policy is obtained, it is critical to design a value function\nfactorization method to extract optimal decentralized policies for the agents,\nwhich needs to satisfy the individual-global-max (IGM) principle. While\nimposing additional limitations on the IGM function class can help to meet the\nrequirement, it comes at the cost of restricting its application to more\ncomplex multi-agent environments. In this paper, we propose QFree, a universal\nvalue function factorization method for MARL. We start by developing\nmathematical equivalent conditions of the IGM principle based on the advantage\nfunction, which ensures that the principle holds without any compromise,\nremoving the conservatism of conventional methods. We then establish a more\nexpressive mixing network architecture that can fulfill the equivalent\nfactorization. In particular, the novel loss function is developed by\nconsidering the equivalent conditions as regularization term during policy\nevaluation in the MARL algorithm. Finally, the effectiveness of the proposed\nmethod is verified in a nonmonotonic matrix game scenario. Moreover, we show\nthat QFree achieves the state-of-the-art performance in a general-purpose\ncomplex MARL benchmark environment, Starcraft Multi-Agent Challenge (SMAC).",
            "author": [
                "Rizhong Wang",
                "Huiping Li",
                "Di Cui",
                "Demin Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00356v1",
                "http://arxiv.org/pdf/2311.00356v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00346v1",
            "title": "Adversarially Robust Distributed Count Tracking via Partial Differential\n  Privacy",
            "updated": "2023-11-01T07:42:13Z",
            "published": "2023-11-01T07:42:13Z",
            "summary": "We study the distributed tracking model, also known as distributed functional\nmonitoring. This model involves $k$ sites each receiving a stream of items and\ncommunicating with the central server. The server's task is to track a function\nof all items received thus far continuously, with minimum communication cost.\nFor count tracking, it is known that there is a $\\sqrt{k}$ gap in communication\nbetween deterministic and randomized algorithms. However, existing randomized\nalgorithms assume an \"oblivious adversary\" who constructs the entire input\nstreams before the algorithm starts. Here we consider adaptive adversaries who\ncan choose new items based on previous answers from the algorithm.\nDeterministic algorithms are trivially robust to adaptive adversaries, while\nrandomized ones may not. Therefore, we investigate whether the $\\sqrt{k}$\nadvantage of randomized algorithms is from randomness itself or the oblivious\nadversary assumption. We provide an affirmative answer to this question by\ngiving a robust algorithm with optimal communication. Existing robustification\ntechniques do not yield optimal bounds due to the inherent challenges of the\ndistributed nature of the problem. To address this, we extend the differential\nprivacy framework by introducing \"partial differential privacy\" and proving a\nnew generalization theorem. This theorem may have broader applications beyond\nrobust count tracking, making it of independent interest.",
            "author": [
                "Zhongzheng Xiong",
                "Xiaoyi Zhu",
                "Zengfeng Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00346v1",
                "http://arxiv.org/pdf/2311.00346v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00732v1",
            "title": "tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for\n  Detecting Tweets Self-reporting a COVID-19 Diagnosis",
            "updated": "2023-11-01T07:41:23Z",
            "published": "2023-11-01T07:41:23Z",
            "summary": "The paper describes a system developed for Task 1 at SMM4H 2023. The goal of\nthe task is to automatically distinguish tweets that self-report a COVID-19\ndiagnosis (for example, a positive test, clinical diagnosis, or\nhospitalization) from those that do not. We investigate the use of different\ntechniques for preprocessing tweets using four transformer-based models. The\nensemble of fine-tuned language models obtained an F1-score of 84.5%, which is\n4.1% higher than the average value.",
            "author": [
                "Anna Glazkova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00732v1",
                "http://arxiv.org/pdf/2311.00732v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.SI",
                "68T50",
                "I.2.7; I.7.m; H.3.3; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00344v2",
            "title": "A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents",
            "updated": "2023-11-02T13:53:24Z",
            "published": "2023-11-01T07:37:27Z",
            "summary": "A lot of recent machine learning research papers have \"Open-ended learning\"\nin their title. But very few of them attempt to define what they mean when\nusing the term. Even worse, when looking more closely there seems to be no\nconsensus on what distinguishes open-ended learning from related concepts such\nas continual learning, lifelong learning or autotelic learning. In this paper,\nwe contribute to fixing this situation. After illustrating the genealogy of the\nconcept and more recent perspectives about what it truly means, we outline that\nopen-ended learning is generally conceived as a composite notion encompassing a\nset of diverse properties. In contrast with these previous approaches, we\npropose to isolate a key elementary property of open-ended processes, which is\nto always produce novel elements from time to time over an infinite horizon.\nFrom there, we build the notion of open-ended learning problems and focus in\nparticular on the subset of open-ended goal-conditioned reinforcement learning\nproblems, as this framework facilitates the definition of learning a growing\nrepertoire of skills. Finally, we highlight the work that remains to be\nperformed to fill the gap between our elementary definition and the more\ninvolved notions of open-ended learning that developmental AI researchers may\nhave in mind.",
            "author": [
                "Olivier Sigaud",
                "Gianluca Baldassarre",
                "Cedric Colas",
                "Stephane Doncieux",
                "Richard Duro",
                "Nicolas Perrin-Gilbert",
                "Vieri Giuliano Santucci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00344v2",
                "http://arxiv.org/pdf/2311.00344v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00342v1",
            "title": "fMRI-PTE: A Large-scale fMRI Pretrained Transformer Encoder for\n  Multi-Subject Brain Activity Decoding",
            "updated": "2023-11-01T07:24:22Z",
            "published": "2023-11-01T07:24:22Z",
            "summary": "The exploration of brain activity and its decoding from fMRI data has been a\nlongstanding pursuit, driven by its potential applications in brain-computer\ninterfaces, medical diagnostics, and virtual reality. Previous approaches have\nprimarily focused on individual subject analysis, highlighting the need for a\nmore universal and adaptable framework, which is the core motivation behind our\nwork. In this work, we propose fMRI-PTE, an innovative auto-encoder approach\nfor fMRI pre-training, with a focus on addressing the challenges of varying\nfMRI data dimensions due to individual brain differences. Our approach involves\ntransforming fMRI signals into unified 2D representations, ensuring consistency\nin dimensions and preserving distinct brain activity patterns. We introduce a\nnovel learning strategy tailored for pre-training 2D fMRI images, enhancing the\nquality of reconstruction. fMRI-PTE's adaptability with image generators\nenables the generation of well-represented fMRI features, facilitating various\ndownstream tasks, including within-subject and cross-subject brain activity\ndecoding. Our contributions encompass introducing fMRI-PTE, innovative data\ntransformation, efficient training, a novel learning strategy, and the\nuniversal applicability of our approach. Extensive experiments validate and\nsupport our claims, offering a promising foundation for further research in\nthis domain.",
            "author": [
                "Xuelin Qian",
                "Yun Wang",
                "Jingyang Huo",
                "Jianfeng Feng",
                "Yanwei Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00342v1",
                "http://arxiv.org/pdf/2311.00342v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00341v2",
            "title": "The Open DAC 2023 Dataset and Challenges for Sorbent Discovery in Direct\n  Air Capture",
            "updated": "2023-11-27T05:51:13Z",
            "published": "2023-11-01T07:21:08Z",
            "summary": "New methods for carbon dioxide removal are urgently needed to combat global\nclimate change. Direct air capture (DAC) is an emerging technology to capture\ncarbon dioxide directly from ambient air. Metal-organic frameworks (MOFs) have\nbeen widely studied as potentially customizable adsorbents for DAC. However,\ndiscovering promising MOF sorbents for DAC is challenging because of the vast\nchemical space to explore and the need to understand materials as functions of\nhumidity and temperature. We explore a computational approach benefiting from\nrecent innovations in machine learning (ML) and present a dataset named Open\nDAC 2023 (ODAC23) consisting of more than 38M density functional theory (DFT)\ncalculations on more than 8,400 MOF materials containing adsorbed $CO_2$ and/or\n$H_2O$. ODAC23 is by far the largest dataset of MOF adsorption calculations at\nthe DFT level of accuracy currently available. In addition to probing\nproperties of adsorbed molecules, the dataset is a rich source of information\non structural relaxation of MOFs, which will be useful in many contexts beyond\nspecific applications for DAC. A large number of MOFs with promising properties\nfor DAC are identified directly in ODAC23. We also trained state-of-the-art ML\nmodels on this dataset to approximate calculations at the DFT level. This\nopen-source dataset and our initial ML models will provide an important\nbaseline for future efforts to identify MOFs for a wide range of applications,\nincluding DAC.",
            "author": [
                "Anuroop Sriram",
                "Sihoon Choi",
                "Xiaohan Yu",
                "Logan M. Brabson",
                "Abhishek Das",
                "Zachary Ulissi",
                "Matt Uyttendaele",
                "Andrew J. Medford",
                "David S. Sholl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00341v2",
                "http://arxiv.org/pdf/2311.00341v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00339v1",
            "title": "Space Narrative: Generating Images and 3D Scenes of Chinese Garden from\n  Text using Deep Learning",
            "updated": "2023-11-01T07:16:01Z",
            "published": "2023-11-01T07:16:01Z",
            "summary": "The consistent mapping from poems to paintings is essential for the research\nand restoration of traditional Chinese gardens. But the lack of firsthand\nma-terial is a great challenge to the reconstruction work. In this paper, we\npro-pose a method to generate garden paintings based on text descriptions using\ndeep learning method. Our image-text pair dataset consists of more than one\nthousand Ming Dynasty Garden paintings and their inscriptions and post-scripts.\nA latent text-to-image diffusion model learns the mapping from de-scriptive\ntexts to garden paintings of the Ming Dynasty, and then the text description of\nJichang Garden guides the model to generate new garden paintings. The cosine\nsimilarity between the guide text and the generated image is the evaluation\ncriterion for the generated images. Our dataset is used to fine-tune the\npre-trained diffusion model using Low-Rank Adapta-tion of Large Language Models\n(LoRA). We also transformed the generated images into a panorama and created a\nfree-roam scene in Unity 3D. Our post-trained model is capable of generating\ngarden images in the style of Ming Dynasty landscape paintings based on textual\ndescriptions. The gener-ated images are compatible with three-dimensional\npresentation in Unity 3D.",
            "author": [
                "Jiaxi Shi1",
                "Hao Hua1"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00339v1",
                "http://arxiv.org/pdf/2311.00339v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00334v2",
            "title": "MetisFL: An Embarrassingly Parallelized Controller for Scalable &\n  Efficient Federated Learning Workflows",
            "updated": "2023-11-13T07:12:55Z",
            "published": "2023-11-01T07:01:19Z",
            "summary": "A Federated Learning (FL) system typically consists of two core processing\nentities: the federation controller and the learners. The controller is\nresponsible for managing the execution of FL workflows across learners and the\nlearners for training and evaluating federated models over their private\ndatasets. While executing an FL workflow, the FL system has no control over the\ncomputational resources or data of the participating learners. Still, it is\nresponsible for other operations, such as model aggregation, task dispatching,\nand scheduling. These computationally heavy operations generally need to be\nhandled by the federation controller. Even though many FL systems have been\nrecently proposed to facilitate the development of FL workflows, most of these\nsystems overlook the scalability of the controller. To meet this need, we\ndesigned and developed a novel FL system called MetisFL, where the federation\ncontroller is the first-class citizen. MetisFL re-engineers all the operations\nconducted by the federation controller to accelerate the training of\nlarge-scale FL workflows. By quantitatively comparing MetisFL against other\nstate-of-the-art FL systems, we empirically demonstrate that MetisFL leads to a\n10-fold wall-clock time execution boost across a wide range of challenging FL\nworkflows with increasing model sizes and federation sites.",
            "author": [
                "Dimitris Stripelis",
                "Chrysovalantis Anastasiou",
                "Patrick Toral",
                "Armaghan Asghar",
                "Jose Luis Ambite"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3630048.3630186",
                "http://arxiv.org/abs/2311.00334v2",
                "http://arxiv.org/pdf/2311.00334v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01473v1",
            "title": "Adversarial Examples in the Physical World: A Survey",
            "updated": "2023-11-01T06:55:09Z",
            "published": "2023-11-01T06:55:09Z",
            "summary": "Deep neural networks (DNNs) have demonstrated high vulnerability to\nadversarial examples. Besides the attacks in the digital world, the practical\nimplications of adversarial examples in the physical world present significant\nchallenges and safety concerns. However, current research on physical\nadversarial examples (PAEs) lacks a comprehensive understanding of their unique\ncharacteristics, leading to limited significance and understanding. In this\npaper, we address this gap by thoroughly examining the characteristics of PAEs\nwithin a practical workflow encompassing training, manufacturing, and\nre-sampling processes. By analyzing the links between physical adversarial\nattacks, we identify manufacturing and re-sampling as the primary sources of\ndistinct attributes and particularities in PAEs. Leveraging this knowledge, we\ndevelop a comprehensive analysis and classification framework for PAEs based on\ntheir specific characteristics, covering over 100 studies on physical-world\nadversarial examples. Furthermore, we investigate defense strategies against\nPAEs and identify open challenges and opportunities for future research. We aim\nto provide a fresh, thorough, and systematic understanding of PAEs, thereby\npromoting the development of robust adversarial learning and its application in\nopen-world scenarios.",
            "author": [
                "Jiakai Wang",
                "Donghua Wang",
                "Jin Hu",
                "Siyang Wu",
                "Tingsong Jiang",
                "Wen Yao",
                "Aishan Liu",
                "Xianglong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01473v1",
                "http://arxiv.org/pdf/2311.01473v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00333v1",
            "title": "Caseformer: Pre-training for Legal Case Retrieval",
            "updated": "2023-11-01T06:52:41Z",
            "published": "2023-11-01T06:52:41Z",
            "summary": "Legal case retrieval aims to help legal workers find relevant cases related\nto their cases at hand, which is important for the guarantee of fairness and\njustice in legal judgments. While recent advances in neural retrieval methods\nhave significantly improved the performance of open-domain retrieval tasks\n(e.g., Web search), their advantages have not been observed in legal case\nretrieval due to their thirst for annotated data. As annotating large-scale\ntraining data in legal domains is prohibitive due to the need for domain\nexpertise, traditional search techniques based on lexical matching such as\nTF-IDF, BM25, and Query Likelihood are still prevalent in legal case retrieval\nsystems. While previous studies have designed several pre-training methods for\nIR models in open-domain tasks, these methods are usually suboptimal in legal\ncase retrieval because they cannot understand and capture the key knowledge and\ndata structures in the legal corpus. To this end, we propose a novel\npre-training framework named Caseformer that enables the pre-trained models to\nlearn legal knowledge and domain-specific relevance information in legal case\nretrieval without any human-labeled data. Through three unsupervised learning\ntasks, Caseformer is able to capture the special language, document structure,\nand relevance patterns of legal case documents, making it a strong backbone for\ndownstream legal case retrieval tasks. Experimental results show that our model\nhas achieved state-of-the-art performance in both zero-shot and full-data\nfine-tuning settings. Also, experiments on both Chinese and English legal\ndatasets demonstrate that the effectiveness of Caseformer is\nlanguage-independent in legal case retrieval.",
            "author": [
                "Weihang Su",
                "Qingyao Ai",
                "Yueyue Wu",
                "Yixiao Ma",
                "Haitao Li",
                "Yiqun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00333v1",
                "http://arxiv.org/pdf/2311.00333v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00332v2",
            "title": "SDF4CHD: Generative Modeling of Cardiac Anatomies with Congenital Heart\n  Defects",
            "updated": "2023-11-08T09:45:49Z",
            "published": "2023-11-01T06:50:53Z",
            "summary": "Congenital heart disease (CHD) encompasses a spectrum of cardiovascular\nstructural abnormalities, often requiring customized treatment plans for\nindividual patients. Computational modeling and analysis of these unique\ncardiac anatomies can improve diagnosis and treatment planning and may\nultimately lead to improved outcomes. Deep learning (DL) methods have\ndemonstrated the potential to enable efficient treatment planning by automating\ncardiac segmentation and mesh construction for patients with normal cardiac\nanatomies. However, CHDs are often rare, making it challenging to acquire\nsufficiently large patient cohorts for training such DL models. Generative\nmodeling of cardiac anatomies has the potential to fill this gap via the\ngeneration of virtual cohorts; however, prior approaches were largely designed\nfor normal anatomies and cannot readily capture the significant topological\nvariations seen in CHD patients. Therefore, we propose a type- and\nshape-disentangled generative approach suitable to capture the wide spectrum of\ncardiac anatomies observed in different CHD types and synthesize differently\nshaped cardiac anatomies that preserve the unique topology for specific CHD\ntypes. Our DL approach represents generic whole heart anatomies with CHD\ntype-specific abnormalities implicitly using signed distance fields (SDF) based\non CHD type diagnosis, which conveniently captures divergent anatomical\nvariations across different types and represents meaningful intermediate CHD\nstates. To capture the shape-specific variations, we then learn invertible\ndeformations to morph the learned CHD type-specific anatomies and reconstruct\npatient-specific shapes. Our approach has the potential to augment the\nimage-segmentation pairs for rarer CHD types for cardiac segmentation and\ngenerate cohorts of CHD cardiac meshes for computational simulation.",
            "author": [
                "Fanwei Kong",
                "Sascha Stocker",
                "Perry S. Choi",
                "Michael Ma",
                "Daniel B. Ennis",
                "Alison Marsden"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00332v2",
                "http://arxiv.org/pdf/2311.00332v2"
            ],
            "primary_category": "q-bio.TO",
            "category": [
                "q-bio.TO",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00330v1",
            "title": "Latent Space Inference For Spatial Transcriptomics",
            "updated": "2023-11-01T06:50:00Z",
            "published": "2023-11-01T06:50:00Z",
            "summary": "In order to understand the complexities of cellular biology, researchers are\ninterested in two important metrics: the genetic expression information of\ncells and their spatial coordinates within a tissue sample. However,\nstate-of-the art methods, namely single-cell RNA sequencing and image based\nspatial transcriptomics can only recover a subset of this information, either\nfull genetic expression with loss of spatial information, or spatial\ninformation with loss of resolution in sequencing data. In this project, we\ninvestigate a probabilistic machine learning method to obtain the full genetic\nexpression information for tissues samples while also preserving their spatial\ncoordinates. This is done through mapping both datasets to a joint latent space\nrepresentation with the use of variational machine learning methods. From here,\nthe full genetic and spatial information can be decoded and to give us greater\ninsights on the understanding of cellular processes and pathways.",
            "author": [
                "J. Ding",
                "S. N. Zaman",
                "P. Y. Chen",
                "D. Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00330v1",
                "http://arxiv.org/pdf/2311.00330v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00327v1",
            "title": "Multi-task Representation Learning for Pure Exploration in Bilinear\n  Bandits",
            "updated": "2023-11-01T06:30:45Z",
            "published": "2023-11-01T06:30:45Z",
            "summary": "We study multi-task representation learning for the problem of pure\nexploration in bilinear bandits. In bilinear bandits, an action takes the form\nof a pair of arms from two different entity types and the reward is a bilinear\nfunction of the known feature vectors of the arms. In the \\textit{multi-task\nbilinear bandit problem}, we aim to find optimal actions for multiple tasks\nthat share a common low-dimensional linear representation. The objective is to\nleverage this characteristic to expedite the process of identifying the best\npair of arms for all tasks. We propose the algorithm GOBLIN that uses an\nexperimental design approach to optimize sample allocations for learning the\nglobal representation as well as minimize the number of samples needed to\nidentify the optimal pair of arms in individual tasks. To the best of our\nknowledge, this is the first study to give sample complexity analysis for pure\nexploration in bilinear bandits with shared representation. Our results\ndemonstrate that by learning the shared representation across tasks, we achieve\nsignificantly improved sample complexity compared to the traditional approach\nof solving tasks independently.",
            "author": [
                "Subhojyoti Mukherjee",
                "Qiaomin Xie",
                "Josiah P. Hanna",
                "Robert Nowak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00327v1",
                "http://arxiv.org/pdf/2311.00327v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00322v2",
            "title": "Robust Graph Clustering via Meta Weighting for Noisy Graphs",
            "updated": "2023-11-08T08:01:49Z",
            "published": "2023-11-01T06:12:34Z",
            "summary": "How can we find meaningful clusters in a graph robustly against noise edges?\nGraph clustering (i.e., dividing nodes into groups of similar ones) is a\nfundamental problem in graph analysis with applications in various fields.\nRecent studies have demonstrated that graph neural network (GNN) based\napproaches yield promising results for graph clustering. However, we observe\nthat their performance degenerates significantly on graphs with noise edges,\nwhich are prevalent in practice. In this work, we propose MetaGC for robust\nGNN-based graph clustering. MetaGC employs a decomposable clustering loss\nfunction, which can be rephrased as a sum of losses over node pairs. We add a\nlearnable weight to each node pair, and MetaGC adaptively adjusts the weights\nof node pairs using meta-weighting so that the weights of meaningful node pairs\nincrease and the weights of less-meaningful ones (e.g., noise edges) decrease.\nWe show empirically that MetaGC learns weights as intended and consequently\noutperforms the state-of-the-art GNN-based competitors, even when they are\nequipped with separate denoising schemes, on five real-world graphs under\nvarying levels of noise. Our code and datasets are available at\nhttps://github.com/HyeonsooJo/MetaGC.",
            "author": [
                "Hyeonsoo Jo",
                "Fanchen Bu",
                "Kijung Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00322v2",
                "http://arxiv.org/pdf/2311.00322v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00731v1",
            "title": "Enhancing Clustering Representations with Positive Proximity and Cluster\n  Dispersion Learning",
            "updated": "2023-11-01T06:12:02Z",
            "published": "2023-11-01T06:12:02Z",
            "summary": "Contemporary deep clustering approaches often rely on either contrastive or\nnon-contrastive techniques to acquire effective representations for clustering\ntasks. Contrastive methods leverage negative pairs to achieve homogenous\nrepresentations but can introduce class collision issues, potentially\ncompromising clustering performance. On the contrary, non-contrastive\ntechniques prevent class collisions but may produce non-uniform representations\nthat lead to clustering collapse. In this work, we propose a novel end-to-end\ndeep clustering approach named PIPCDR, designed to harness the strengths of\nboth approaches while mitigating their limitations. PIPCDR incorporates a\npositive instance proximity loss and a cluster dispersion regularizer. The\npositive instance proximity loss ensures alignment between augmented views of\ninstances and their sampled neighbors, enhancing within-cluster compactness by\nselecting genuinely positive pairs within the embedding space. Meanwhile, the\ncluster dispersion regularizer maximizes inter-cluster distances while\nminimizing within-cluster compactness, promoting uniformity in the learned\nrepresentations. PIPCDR excels in producing well-separated clusters, generating\nuniform representations, avoiding class collision issues, and enhancing\nwithin-cluster compactness. We extensively validate the effectiveness of PIPCDR\nwithin an end-to-end Majorize-Minimization framework, demonstrating its\ncompetitive performance on moderate-scale clustering benchmark datasets and\nestablishing new state-of-the-art results on large-scale datasets.",
            "author": [
                "Abhishek Kumar",
                "Dong-Gyu Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00731v1",
                "http://arxiv.org/pdf/2311.00731v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00320v1",
            "title": "Semantic Hearing: Programming Acoustic Scenes with Binaural Hearables",
            "updated": "2023-11-01T06:07:28Z",
            "published": "2023-11-01T06:07:28Z",
            "summary": "Imagine being able to listen to the birds chirping in a park without hearing\nthe chatter from other hikers, or being able to block out traffic noise on a\nbusy street while still being able to hear emergency sirens and car honks. We\nintroduce semantic hearing, a novel capability for hearable devices that\nenables them to, in real-time, focus on, or ignore, specific sounds from\nreal-world environments, while also preserving the spatial cues. To achieve\nthis, we make two technical contributions: 1) we present the first neural\nnetwork that can achieve binaural target sound extraction in the presence of\ninterfering sounds and background noise, and 2) we design a training\nmethodology that allows our system to generalize to real-world use. Results\nshow that our system can operate with 20 sound classes and that our\ntransformer-based network has a runtime of 6.56 ms on a connected smartphone.\nIn-the-wild evaluation with participants in previously unseen indoor and\noutdoor scenarios shows that our proof-of-concept system can extract the target\nsounds and generalize to preserve the spatial cues in its binaural output.\nProject page with code: https://semantichearing.cs.washington.edu",
            "author": [
                "Bandhav Veluri",
                "Malek Itani",
                "Justin Chan",
                "Takuya Yoshioka",
                "Shyamnath Gollakota"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3586183.3606779",
                "http://arxiv.org/abs/2311.00320v1",
                "http://arxiv.org/pdf/2311.00320v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00318v1",
            "title": "Flooding Regularization for Stable Training of Generative Adversarial\n  Networks",
            "updated": "2023-11-01T06:02:59Z",
            "published": "2023-11-01T06:02:59Z",
            "summary": "Generative Adversarial Networks (GANs) have shown remarkable performance in\nimage generation. However, GAN training suffers from the problem of\ninstability. One of the main approaches to address this problem is to modify\nthe loss function, often using regularization terms in addition to changing the\ntype of adversarial losses. This paper focuses on directly regularizing the\nadversarial loss function. We propose a method that applies flooding, an\noverfitting suppression method in supervised learning, to GANs to directly\nprevent the discriminator's loss from becoming excessively low. Flooding\nrequires tuning the flood level, but when applied to GANs, we propose that the\nappropriate range of flood level settings is determined by the adversarial loss\nfunction, supported by theoretical analysis of GANs using the binary cross\nentropy loss. We experimentally verify that flooding stabilizes GAN training\nand can be combined with other stabilization techniques. We also reveal that by\nrestricting the discriminator's loss to be no greater than flood level, the\ntraining proceeds stably even when the flood level is somewhat high.",
            "author": [
                "Iu Yahiro",
                "Takashi Ishida",
                "Naoto Yokoya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00318v1",
                "http://arxiv.org/pdf/2311.00318v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00317v1",
            "title": "Data Augmentation for Code Translation with Comparable Corpora and\n  Multiple References",
            "updated": "2023-11-01T06:01:22Z",
            "published": "2023-11-01T06:01:22Z",
            "summary": "One major challenge of translating code between programming languages is that\nparallel training data is often limited. To overcome this challenge, we present\ntwo data augmentation techniques, one that builds comparable corpora (i.e.,\ncode pairs with similar functionality), and another that augments existing\nparallel data with multiple reference translations. Specifically, we build and\nanalyze multiple types of comparable corpora, including programs generated from\nnatural language documentation using a code generation model. Furthermore, to\nreduce overfitting to a single reference translation, we automatically generate\nadditional translation references for available parallel data and filter the\ntranslations by unit tests, which increases variation in target translations.\nExperiments show that our data augmentation techniques significantly improve\nCodeT5 for translation between Java, Python, and C++ by an average of 7.5%\nComputational Accuracy (CA@1), which verifies the correctness of translations\nby execution. The code is available at https://github.com/Veronicium/CMTrans.",
            "author": [
                "Yiqing Xie",
                "Atharva Naik",
                "Daniel Fried",
                "Carolyn Rose"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00317v1",
                "http://arxiv.org/pdf/2311.00317v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00314v1",
            "title": "Federated Topic Model and Model Pruning Based on Variational Autoencoder",
            "updated": "2023-11-01T06:00:14Z",
            "published": "2023-11-01T06:00:14Z",
            "summary": "Topic modeling has emerged as a valuable tool for discovering patterns and\ntopics within large collections of documents. However, when cross-analysis\ninvolves multiple parties, data privacy becomes a critical concern. Federated\ntopic modeling has been developed to address this issue, allowing multiple\nparties to jointly train models while protecting pri-vacy. However, there are\ncommunication and performance challenges in the federated sce-nario. In order\nto solve the above problems, this paper proposes a method to establish a\nfederated topic model while ensuring the privacy of each node, and use neural\nnetwork model pruning to accelerate the model, where the client periodically\nsends the model neu-ron cumulative gradients and model weights to the server,\nand the server prunes the model. To address different requirements, two\ndifferent methods are proposed to determine the model pruning rate. The first\nmethod involves slow pruning throughout the entire model training process,\nwhich has limited acceleration effect on the model training process, but can\nensure that the pruned model achieves higher accuracy. This can significantly\nreduce the model inference time during the inference process. The second\nstrategy is to quickly reach the target pruning rate in the early stage of\nmodel training in order to accelerate the model training speed, and then\ncontinue to train the model with a smaller model size after reaching the target\npruning rate. This approach may lose more useful information but can complete\nthe model training faster. Experimental results show that the federated topic\nmodel pruning based on the variational autoencoder proposed in this paper can\ngreatly accelerate the model training speed while ensuring the model's\nperformance.",
            "author": [
                "Chengjie Ma",
                "Yawen Li",
                "Meiyu Liang",
                "Ang Li"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-981-99-6187-0_5",
                "http://arxiv.org/abs/2311.00314v1",
                "http://arxiv.org/pdf/2311.00314v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00313v1",
            "title": "Gaze-based Learning from Demonstration In Surgical Robotics",
            "updated": "2023-11-01T05:50:43Z",
            "published": "2023-11-01T05:50:43Z",
            "summary": "Surgical robotics is a rising field in medical technology and advanced\nrobotics. Robot assisted surgery, or robotic surgery, allows surgeons to\nperform complicated surgical tasks with more precision, automation, and\nflexibility than is possible for traditional surgical approaches. The main type\nof robot assisted surgery is minimally invasive surgery, which could be\nautomated and result in a faster healing time for the patient. The surgical\nrobot we are particularly interested in is the da Vinci surgical system, which\nis developed and manufactured by Intuitive Surgical. In the current iteration\nof the system, the endoscopic camera arm on the da Vinci robot has to be\nmanually controlled and calibrated by the surgeon during a surgical task, which\ninterrupts the flow of the operation. The main goal of this capstone project is\nto automate the motion of the camera arm using a probabilistic model based on\nsurgeon eye gaze data and da Vinci robot kinematic data.",
            "author": [
                "A. E. Abdelaal",
                "S. N. Zaman",
                "P. Y Chen",
                "T. Suzuki",
                "J. Ingleton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00313v1",
                "http://arxiv.org/pdf/2311.00313v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00304v1",
            "title": "Stacking an autoencoder for feature selection of zero-day threats",
            "updated": "2023-11-01T05:29:42Z",
            "published": "2023-11-01T05:29:42Z",
            "summary": "Zero-day attack detection plays a critical role in mitigating risks,\nprotecting assets, and staying ahead in the evolving threat landscape. This\nstudy explores the application of stacked autoencoder (SAE), a type of\nartificial neural network, for feature selection and zero-day threat\nclassification using a Long Short-Term Memory (LSTM) scheme. The process\ninvolves preprocessing the UGRansome dataset and training an unsupervised SAE\nfor feature extraction. Finetuning with supervised learning is then performed\nto enhance the discriminative capabilities of this model. The learned weights\nand activations of the autoencoder are analyzed to identify the most important\nfeatures for discriminating between zero-day threats and normal system\nbehavior. These selected features form a reduced feature set that enables\naccurate classification. The results indicate that the SAE-LSTM performs well\nacross all three attack categories by showcasing high precision, recall, and F1\nscore values, emphasizing the model's strong predictive capabilities in\nidentifying various types of zero-day attacks. Additionally, the balanced\naverage scores of the SAE-LSTM suggest that the model generalizes effectively\nand consistently across different attack categories.",
            "author": [
                "Mahmut Tokmak",
                "Mike Nkongolo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00304v1",
                "http://arxiv.org/pdf/2311.00304v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00301v1",
            "title": "Detecting Syllable-Level Pronunciation Stress with A Self-Attention\n  Model",
            "updated": "2023-11-01T05:05:49Z",
            "published": "2023-11-01T05:05:49Z",
            "summary": "One precondition of effective oral communication is that words should be\npronounced clearly, especially for non-native speakers. Word stress is the key\nto clear and correct English, and misplacement of syllable stress may lead to\nmisunderstandings. Thus, knowing the stress level is important for English\nspeakers and learners. This paper presents a self-attention model to identify\nthe stress level for each syllable of spoken English. Various prosodic and\ncategorical features, including the pitch level, intensity, duration and type\nof the syllable and its nuclei (the vowel of the syllable), are explored. These\nfeatures are input to the self-attention model, and syllable-level stresses are\npredicted. The simplest model yields an accuracy of over 88% and 93% on\ndifferent datasets, while more advanced models provide higher accuracy. Our\nstudy suggests that the self-attention model can be promising in stress-level\ndetection. These models could be applied to various scenarios, such as online\nmeetings and English learning.",
            "author": [
                "Wang Weiying",
                "Nakajima Akinori"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00301v1",
                "http://arxiv.org/pdf/2311.00301v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00296v1",
            "title": "Semantic Representation Learning of Scientific Literature based on\n  Adaptive Feature and Graph Neural Network",
            "updated": "2023-11-01T05:00:44Z",
            "published": "2023-11-01T05:00:44Z",
            "summary": "Because most of the scientific literature data is unmarked, it makes semantic\nrepresentation learning based on unsupervised graph become crucial. At the same\ntime, in order to enrich the features of scientific literature, a learning\nmethod of semantic representation of scientific literature based on adaptive\nfeatures and graph neural network is proposed. By introducing the adaptive\nfeature method, the features of scientific literature are considered globally\nand locally. The graph attention mechanism is used to sum the features of\nscientific literature with citation relationship, and give each scientific\nliterature different feature weights, so as to better express the correlation\nbetween the features of different scientific literature. In addition, an\nunsupervised graph neural network semantic representation learning method is\nproposed. By comparing the mutual information between the positive and negative\nlocal semantic representation of scientific literature and the global graph\nsemantic representation in the potential space, the graph neural network can\ncapture the local and global information, thus improving the learning ability\nof the semantic representation of scientific literature. The experimental\nresults show that the proposed learning method of semantic representation of\nscientific literature based on adaptive feature and graph neural network is\ncompetitive on the basis of scientific literature classification, and has\nachieved good results.",
            "author": [
                "Hongrui Gao",
                "Yawen Li",
                "Meiyu Liang",
                "Zeli Guan",
                "Zhe Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00296v1",
                "http://arxiv.org/pdf/2311.00296v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00292v1",
            "title": "IBADR: an Iterative Bias-Aware Dataset Refinement Framework for\n  Debiasing NLU models",
            "updated": "2023-11-01T04:50:38Z",
            "published": "2023-11-01T04:50:38Z",
            "summary": "As commonly-used methods for debiasing natural language understanding (NLU)\nmodels, dataset refinement approaches heavily rely on manual data analysis, and\nthus maybe unable to cover all the potential biased features. In this paper, we\npropose IBADR, an Iterative Bias-Aware Dataset Refinement framework, which\ndebiases NLU models without predefining biased features. We maintain an\niteratively expanded sample pool. Specifically, at each iteration, we first\ntrain a shallow model to quantify the bias degree of samples in the pool. Then,\nwe pair each sample with a bias indicator representing its bias degree, and use\nthese extended samples to train a sample generator. In this way, this generator\ncan effectively learn the correspondence relationship between bias indicators\nand samples. Furthermore, we employ the generator to produce pseudo samples\nwith fewer biased features by feeding specific bias indicators. Finally, we\nincorporate the generated pseudo samples into the pool. Experimental results\nand in-depth analyses on two NLU tasks show that IBADR not only significantly\noutperforms existing dataset refinement approaches, achieving SOTA, but also is\ncompatible with model-centric methods.",
            "author": [
                "Xiaoyue Wang",
                "Xin Liu",
                "Lijie Wang",
                "Yaoxiang Wang",
                "Jinsong Su",
                "Hua Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00292v1",
                "http://arxiv.org/pdf/2311.00292v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00291v1",
            "title": "Graph Representation Learning for Infrared and Visible Image Fusion",
            "updated": "2023-11-01T04:46:20Z",
            "published": "2023-11-01T04:46:20Z",
            "summary": "Infrared and visible image fusion aims to extract complementary features to\nsynthesize a single fused image. Many methods employ convolutional neural\nnetworks (CNNs) to extract local features due to its translation invariance and\nlocality. However, CNNs fail to consider the image's non-local self-similarity\n(NLss), though it can expand the receptive field by pooling operations, it\nstill inevitably leads to information loss. In addition, the transformer\nstructure extracts long-range dependence by considering the correlativity among\nall image patches, leading to information redundancy of such transformer-based\nmethods. However, graph representation is more flexible than grid (CNN) or\nsequence (transformer structure) representation to address irregular objects,\nand graph can also construct the relationships among the spatially repeatable\ndetails or texture with far-space distance. Therefore, to address the above\nissues, it is significant to convert images into the graph space and thus adopt\ngraph convolutional networks (GCNs) to extract NLss. This is because the graph\ncan provide a fine structure to aggregate features and propagate information\nacross the nearest vertices without introducing redundant information.\nConcretely, we implement a cascaded NLss extraction pattern to extract NLss of\nintra- and inter-modal by exploring interactions of different image pixels in\nintra- and inter-image positional distance. We commence by preforming GCNs on\neach intra-modal to aggregate features and propagate information to extract\nindependent intra-modal NLss. Then, GCNs are performed on the concatenate\nintra-modal NLss features of infrared and visible images, which can explore the\ncross-domain NLss of inter-modal to reconstruct the fused image. Ablation\nstudies and extensive experiments illustrates the effectiveness and superiority\nof the proposed method on three datasets.",
            "author": [
                "Jing Li",
                "Lu Bai",
                "Bin Yang",
                "Chang Li",
                "Lingfei Ma",
                "Edwin R. Hancock"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00291v1",
                "http://arxiv.org/pdf/2311.00291v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00290v2",
            "title": "Inference of CO2 flow patterns -- a feasibility study",
            "updated": "2023-11-29T01:55:38Z",
            "published": "2023-11-01T04:41:25Z",
            "summary": "As the global deployment of carbon capture and sequestration (CCS) technology\nintensifies in the fight against climate change, it becomes increasingly\nimperative to establish robust monitoring and detection mechanisms for\npotential underground CO2 leakage, particularly through pre-existing or induced\nfaults in the storage reservoir's seals. While techniques such as history\nmatching and time-lapse seismic monitoring of CO2 storage have been used\nsuccessfully in tracking the evolution of CO2 plumes in the subsurface, these\nmethods lack principled approaches to characterize uncertainties related to the\nCO2 plumes' behavior. Inclusion of systematic assessment of uncertainties is\nessential for risk mitigation for the following reasons: (i) CO2 plume-induced\nchanges are small and seismic data is noisy; (ii) changes between regular and\nirregular (e.g., caused by leakage) flow patterns are small; and (iii) the\nreservoir properties that control the flow are strongly heterogeneous and\ntypically only available as distributions. To arrive at a formulation capable\nof inferring flow patterns for regular and irregular flow from well and seismic\ndata, the performance of conditional normalizing flow will be analyzed on a\nseries of carefully designed numerical experiments. While the inferences\npresented are preliminary in the context of an early CO2 leakage detection\nsystem, the results do indicate that inferences with conditional normalizing\nflows can produce high-fidelity estimates for CO2 plumes with or without\nleakage. We are also confident that the inferred uncertainty is reasonable\nbecause it correlates well with the observed errors. This uncertainty stems\nfrom noise in the seismic data and from the lack of precise knowledge of the\nreservoir's fluid flow properties.",
            "author": [
                "Abhinav Prakash Gahlot",
                "Huseyin Tuna Erdinc",
                "Rafael Orozco",
                "Ziyi Yin",
                "Felix J. Herrmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00290v2",
                "http://arxiv.org/pdf/2311.00290v2"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.AI",
                "cs.LG",
                "math-ph",
                "math.MP",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00289v1",
            "title": "Precise Error Rates for Computationally Efficient Testing",
            "updated": "2023-11-01T04:41:16Z",
            "published": "2023-11-01T04:41:16Z",
            "summary": "We revisit the fundamental question of simple-versus-simple hypothesis\ntesting with an eye towards computational complexity, as the statistically\noptimal likelihood ratio test is often computationally intractable in\nhigh-dimensional settings. In the classical spiked Wigner model (with a general\ni.i.d. spike prior) we show that an existing test based on linear spectral\nstatistics achieves the best possible tradeoff curve between type I and type II\nerror rates among all computationally efficient tests, even though there are\nexponential-time tests that do better. This result is conditional on an\nappropriate complexity-theoretic conjecture, namely a natural strengthening of\nthe well-established low-degree conjecture. Our result shows that the spectrum\nis a sufficient statistic for computationally bounded tests (but not for all\ntests).\n  To our knowledge, our approach gives the first tool for reasoning about the\nprecise asymptotic testing error achievable with efficient computation. The\nmain ingredients required for our hardness result are a sharp bound on the norm\nof the low-degree likelihood ratio along with (counterintuitively) a positive\nresult on achievability of testing. This strategy appears to be new even in the\nsetting of unbounded computation, in which case it gives an alternate way to\nanalyze the fundamental statistical limits of testing.",
            "author": [
                "Ankur Moitra",
                "Alexander S. Wein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00289v1",
                "http://arxiv.org/pdf/2311.00289v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00287v1",
            "title": "Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data\n  Generation with Large Language Models",
            "updated": "2023-11-01T04:37:28Z",
            "published": "2023-11-01T04:37:28Z",
            "summary": "Clinical natural language processing requires methods that can address\ndomain-specific challenges, such as complex medical terminology and clinical\ncontexts. Recently, large language models (LLMs) have shown promise in this\ndomain. Yet, their direct deployment can lead to privacy issues and are\nconstrained by resources. To address this challenge, we delve into synthetic\nclinical text generation using LLMs for clinical NLP tasks. We propose an\ninnovative, resource-efficient approach, ClinGen, which infuses knowledge into\nthe process. Our model involves clinical knowledge extraction and\ncontext-informed LLM prompting. Both clinical topics and writing styles are\ndrawn from external domain-specific knowledge graphs and LLMs to guide data\ngeneration. Our extensive empirical study across 7 clinical NLP tasks and 16\ndatasets reveals that ClinGen consistently enhances performance across various\ntasks, effectively aligning the distribution of real datasets and significantly\nenriching the diversity of generated training instances. We will publish our\ncode and all the generated data in \\url{https://github.com/ritaranx/ClinGen}.",
            "author": [
                "Ran Xu",
                "Hejie Cui",
                "Yue Yu",
                "Xuan Kan",
                "Wenqi Shi",
                "Yuchen Zhuang",
                "Wei Jin",
                "Joyce Ho",
                "Carl Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00287v1",
                "http://arxiv.org/pdf/2311.00287v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00286v2",
            "title": "JADE: A Linguistics-based Safety Evaluation Platform for LLM",
            "updated": "2023-11-02T02:36:47Z",
            "published": "2023-11-01T04:36:45Z",
            "summary": "In this paper, we present JADE, a targeted linguistic fuzzing platform which\nstrengthens the linguistic complexity of seed questions to simultaneously and\nconsistently break a wide range of widely-used LLMs categorized in three\ngroups: eight open-sourced Chinese, six commercial Chinese and four commercial\nEnglish LLMs. JADE generates three safety benchmarks for the three groups of\nLLMs, which contain unsafe questions that are highly threatening: the questions\nsimultaneously trigger harmful generation of multiple LLMs, with an average\nunsafe generation ratio of $70\\%$ (please see the table below), while are still\nnatural questions, fluent and preserving the core unsafe semantics. We release\nthe benchmark demos generated for commercial English LLMs and open-sourced\nEnglish LLMs in the following link: https://github.com/whitzard-ai/jade-db. For\nreaders who are interested in evaluating on more questions generated by JADE,\nplease contact us.\n  JADE is based on Noam Chomsky's seminal theory of transformational-generative\ngrammar. Given a seed question with unsafe intention, JADE invokes a sequence\nof generative and transformational rules to increment the complexity of the\nsyntactic structure of the original question, until the safety guardrail is\nbroken. Our key insight is: Due to the complexity of human language, most of\nthe current best LLMs can hardly recognize the invariant evil from the infinite\nnumber of different syntactic structures which form an unbound example space\nthat can never be fully covered. Technically, the generative/transformative\nrules are constructed by native speakers of the languages, and, once developed,\ncan be used to automatically grow and transform the parse tree of a given\nquestion, until the guardrail is broken. For more evaluation results and demo,\nplease check our website: https://whitzard-ai.github.io/jade.html.",
            "author": [
                "Mi Zhang",
                "Xudong Pan",
                "Min Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00286v2",
                "http://arxiv.org/pdf/2311.00286v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00285v1",
            "title": "Mixture-of-Experts for Open Set Domain Adaptation: A Dual-Space\n  Detection Approach",
            "updated": "2023-11-01T04:36:18Z",
            "published": "2023-11-01T04:36:18Z",
            "summary": "Open Set Domain Adaptation (OSDA) aims to cope with the distribution and\nlabel shifts between the source and target domains simultaneously, performing\naccurate classification for known classes while identifying unknown class\nsamples in the target domain. Most existing OSDA approaches, depending on the\nfinal image feature space of deep models, require manually-tuned thresholds,\nand may easily misclassify unknown samples as known classes. Mixture-of-Expert\n(MoE) could be a remedy. Within an MoE, different experts address different\ninput features, producing unique expert routing patterns for different classes\nin a routing feature space. As a result, unknown class samples may also display\ndifferent expert routing patterns to known classes. This paper proposes\nDual-Space Detection, which exploits the inconsistencies between the image\nfeature space and the routing feature space to detect unknown class samples\nwithout any threshold. Graph Router is further introduced to better make use of\nthe spatial information among image patches. Experiments on three different\ndatasets validated the effectiveness and superiority of our approach. The code\nwill come soon.",
            "author": [
                "Zhenbang Du",
                "Jiayu An",
                "Jiahao Hong",
                "Dongrui Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00285v1",
                "http://arxiv.org/pdf/2311.00285v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00284v1",
            "title": "Model-driven Engineering for Machine Learning Components: A Systematic\n  Literature Review",
            "updated": "2023-11-01T04:29:47Z",
            "published": "2023-11-01T04:29:47Z",
            "summary": "Context: Machine Learning (ML) has become widely adopted as a component in\nmany modern software applications. Due to the large volumes of data available,\norganizations want to increasingly leverage their data to extract meaningful\ninsights and enhance business profitability. ML components enable predictive\ncapabilities, anomaly detection, recommendation, accurate image and text\nprocessing, and informed decision-making. However, developing systems with ML\ncomponents is not trivial; it requires time, effort, knowledge, and expertise\nin ML, data processing, and software engineering. There have been several\nstudies on the use of model-driven engineering (MDE) techniques to address\nthese challenges when developing traditional software and cyber-physical\nsystems. Recently, there has been a growing interest in applying MDE for\nsystems with ML components. Objective: The goal of this study is to further\nexplore the promising intersection of MDE with ML (MDE4ML) through a systematic\nliterature review (SLR). Through this SLR, we wanted to analyze existing\nstudies, including their motivations, MDE solutions, evaluation techniques, key\nbenefits and limitations. Results: We analyzed selected studies with respect to\nseveral areas of interest and identified the following: 1) the key motivations\nbehind using MDE4ML; 2) a variety of MDE solutions applied, such as modeling\nlanguages, model transformations, tool support, targeted ML aspects,\ncontributions and more; 3) the evaluation techniques and metrics used; and 4)\nthe limitations and directions for future work. We also discuss the gaps in\nexisting literature and provide recommendations for future research.\nConclusion: This SLR highlights current trends, gaps and future research\ndirections in the field of MDE4ML, benefiting both researchers and\npractitioners",
            "author": [
                "Hira Naveed",
                "Chetan Arora",
                "Hourieh Khalajzadeh",
                "John Grundy",
                "Omar Haggag"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00284v1",
                "http://arxiv.org/pdf/2311.00284v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00282v2",
            "title": "TLMCM Network for Medical Image Hierarchical Multi-Label Classification",
            "updated": "2023-11-11T08:16:29Z",
            "published": "2023-11-01T04:18:42Z",
            "summary": "Medical Image Hierarchical Multi-Label Classification (MI-HMC) is of\nparamount importance in modern healthcare, presenting two significant\nchallenges: data imbalance and \\textit{hierarchy constraint}. Existing\nsolutions involve complex model architecture design or domain-specific\npreprocessing, demanding considerable expertise or effort in implementation. To\naddress these limitations, this paper proposes Transfer Learning with Maximum\nConstraint Module (TLMCM) network for the MI-HMC task. The TLMCM network offers\na novel approach to overcome the aforementioned challenges, outperforming\nexisting methods based on the Area Under the Average Precision and Recall\nCurve($AU\\overline{(PRC)}$) metric. In addition, this research proposes two\nnovel accuracy metrics, $EMR$ and $HammingAccuracy$, which have not been\nextensively explored in the context of the MI-HMC task. Experimental results\ndemonstrate that the TLMCM network achieves high multi-label prediction\naccuracy($80\\%$-$90\\%$) for MI-HMC tasks, making it a valuable contribution to\nhealthcare domain applications.",
            "author": [
                "Meng Wu",
                "Siyan Luo",
                "Qiyu Wu",
                "Wenbin Ouyang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00282v2",
                "http://arxiv.org/pdf/2311.00282v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00277v2",
            "title": "OpenForest: A data catalogue for machine learning in forest monitoring",
            "updated": "2023-11-02T02:44:27Z",
            "published": "2023-11-01T03:59:20Z",
            "summary": "Forests play a crucial role in Earth's system processes and provide a suite\nof social and economic ecosystem services, but are significantly impacted by\nhuman activities, leading to a pronounced disruption of the equilibrium within\necosystems. Advancing forest monitoring worldwide offers advantages in\nmitigating human impacts and enhancing our comprehension of forest composition,\nalongside the effects of climate change. While statistical modeling has\ntraditionally found applications in forest biology, recent strides in machine\nlearning and computer vision have reached important milestones using remote\nsensing data, such as tree species identification, tree crown segmentation and\nforest biomass assessments. For this, the significance of open access data\nremains essential in enhancing such data-driven algorithms and methodologies.\nHere, we provide a comprehensive and extensive overview of 86 open access\nforest datasets across spatial scales, encompassing inventories, ground-based,\naerial-based, satellite-based recordings, and country or world maps. These\ndatasets are grouped in OpenForest, a dynamic catalogue open to contributions\nthat strives to reference all available open access forest datasets. Moreover,\nin the context of these datasets, we aim to inspire research in machine\nlearning applied to forest biology by establishing connections between\ncontemporary topics, perspectives and challenges inherent in both domains. We\nhope to encourage collaborations among scientists, fostering the sharing and\nexploration of diverse datasets through the application of machine learning\nmethods for large-scale forest monitoring. OpenForest is available at\nhttps://github.com/RolnickLab/OpenForest .",
            "author": [
                "Arthur Ouaknine",
                "Teja Kattenborn",
                "Etienne Lalibert\u00e9",
                "David Rolnick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00277v2",
                "http://arxiv.org/pdf/2311.00277v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00274v1",
            "title": "Generalization Bounds for Label Noise Stochastic Gradient Descent",
            "updated": "2023-11-01T03:51:46Z",
            "published": "2023-11-01T03:51:46Z",
            "summary": "We develop generalization error bounds for stochastic gradient descent (SGD)\nwith label noise in non-convex settings under uniform dissipativity and\nsmoothness conditions. Under a suitable choice of semimetric, we establish a\ncontraction in Wasserstein distance of the label noise stochastic gradient flow\nthat depends polynomially on the parameter dimension $d$. Using the framework\nof algorithmic stability, we derive time-independent generalisation error\nbounds for the discretized algorithm with a constant learning rate. The error\nbound we achieve scales polynomially with $d$ and with the rate of $n^{-2/3}$,\nwhere $n$ is the sample size. This rate is better than the best-known rate of\n$n^{-1/2}$ established for stochastic gradient Langevin dynamics (SGLD) --\nwhich employs parameter-independent Gaussian noise -- under similar conditions.\nOur analysis offers quantitative insights into the effect of label noise.",
            "author": [
                "Jung Eun Huh",
                "Patrick Rebeschini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00274v1",
                "http://arxiv.org/pdf/2311.00274v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00267v1",
            "title": "Rethinking Decision Transformer via Hierarchical Reinforcement Learning",
            "updated": "2023-11-01T03:32:13Z",
            "published": "2023-11-01T03:32:13Z",
            "summary": "Decision Transformer (DT) is an innovative algorithm leveraging recent\nadvances of the transformer architecture in reinforcement learning (RL).\nHowever, a notable limitation of DT is its reliance on recalling trajectories\nfrom datasets, losing the capability to seamlessly stitch sub-optimal\ntrajectories together. In this work we introduce a general sequence modeling\nframework for studying sequential decision making through the lens of\nHierarchical RL. At the time of making decisions, a high-level policy first\nproposes an ideal prompt for the current state, a low-level policy subsequently\ngenerates an action conditioned on the given prompt. We show DT emerges as a\nspecial case of this framework with certain choices of high-level and low-level\npolicies, and discuss the potential failure of these choices. Inspired by these\nobservations, we study how to jointly optimize the high-level and low-level\npolicies to enable the stitching ability, which further leads to the\ndevelopment of new offline RL algorithms. Our empirical results clearly show\nthat the proposed algorithms significantly surpass DT on several control and\nnavigation benchmarks. We hope our contributions can inspire the integration of\ntransformer architectures within the field of RL.",
            "author": [
                "Yi Ma",
                "Chenjun Xiao",
                "Hebin Liang",
                "Jianye Hao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00267v1",
                "http://arxiv.org/pdf/2311.00267v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00262v1",
            "title": "Plug-and-Play Policy Planner for Large Language Model Powered Dialogue\n  Agents",
            "updated": "2023-11-01T03:20:16Z",
            "published": "2023-11-01T03:20:16Z",
            "summary": "Proactive dialogues serve as a practical yet challenging dialogue problem in\nthe era of large language models (LLMs), where the dialogue policy planning is\nthe key to improving the proactivity of LLMs. Most existing studies enable the\ndialogue policy planning of LLMs using various prompting schemes or iteratively\nenhance this capability in handling the given case with verbal AI feedback.\nHowever, these approaches are either bounded by the policy planning capability\nof the frozen LLMs or hard to be transferred to new cases. In this work, we\nintroduce a new dialogue policy planning paradigm to strategize LLMs for\nproactive dialogue problems with a tunable language model plug-in as a\nplug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a\nnovel training framework to facilitate supervised fine-tuning over available\nhuman-annotated data as well as reinforcement learning from goal-oriented AI\nfeedback with dynamic interaction data collected by the LLM-based self-play\nsimulation. In this manner, the LLM-powered dialogue agent can not only be\ngeneralized to different cases after the training, but also be applicable to\ndifferent applications by just substituting the learned plug-in. In addition,\nwe propose to evaluate the policy planning capability of dialogue systems under\nthe interactive setting. Experimental results demonstrate that PPDPP\nconsistently and substantially outperforms existing approaches on three\ndifferent proactive dialogue applications, including negotiation, emotional\nsupport, and tutoring dialogues.",
            "author": [
                "Yang Deng",
                "Wenxuan Zhang",
                "Wai Lam",
                "See-Kiong Ng",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00262v1",
                "http://arxiv.org/pdf/2311.00262v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00260v1",
            "title": "Incentivized Collaboration in Active Learning",
            "updated": "2023-11-01T03:17:39Z",
            "published": "2023-11-01T03:17:39Z",
            "summary": "In collaborative active learning, where multiple agents try to learn labels\nfrom a common hypothesis, we introduce an innovative framework for incentivized\ncollaboration. Here, rational agents aim to obtain labels for their data sets\nwhile keeping label complexity at a minimum. We focus on designing (strict)\nindividually rational (IR) collaboration protocols, ensuring that agents cannot\nreduce their expected label complexity by acting individually. We first show\nthat given any optimal active learning algorithm, the collaboration protocol\nthat runs the algorithm as is over the entire data is already IR. However,\ncomputing the optimal algorithm is NP-hard. We therefore provide collaboration\nprotocols that achieve (strict) IR and are comparable with the best known\ntractable approximation algorithm in terms of label complexity.",
            "author": [
                "Lee Cohen",
                "Han Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00260v1",
                "http://arxiv.org/pdf/2311.00260v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00259v1",
            "title": "Solutions to Elliptic and Parabolic Problems via Finite Difference Based\n  Unsupervised Small Linear Convolutional Neural Networks",
            "updated": "2023-11-01T03:15:10Z",
            "published": "2023-11-01T03:15:10Z",
            "summary": "In recent years, there has been a growing interest in leveraging deep\nlearning and neural networks to address scientific problems, particularly in\nsolving partial differential equations (PDEs). However, current neural\nnetwork-based PDE solvers often rely on extensive training data or labeled\ninput-output pairs, making them prone to challenges in generalizing to\nout-of-distribution examples. To mitigate the generalization gap encountered by\nconventional neural network-based methods in estimating PDE solutions, we\nformulate a fully unsupervised approach, requiring no training data, to\nestimate finite difference solutions for PDEs directly via small convolutional\nneural networks. Our proposed algorithms demonstrate a comparable accuracy to\nthe true solution for several selected elliptic and parabolic problems compared\nto the finite difference method.",
            "author": [
                "Adrian Celaya",
                "Keegan Kirk",
                "David Fuentes",
                "Beatrice Riviere"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00259v1",
                "http://arxiv.org/pdf/2311.00259v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00258v1",
            "title": "Noisy Exemplars Make Large Language Models More Robust: A\n  Domain-Agnostic Behavioral Analysis",
            "updated": "2023-11-01T03:15:05Z",
            "published": "2023-11-01T03:15:05Z",
            "summary": "Recent advances in prompt engineering enable large language models (LLMs) to\nsolve multi-hop logical reasoning problems with impressive accuracy. However,\nthere is little existing work investigating the robustness of LLMs with\nfew-shot prompting techniques. Therefore, we introduce a systematic approach to\ntest the robustness of LLMs in multi-hop reasoning tasks via domain-agnostic\nperturbations. We include perturbations at multiple levels of abstractions\n(e.g. lexical perturbations such as typos, and semantic perturbations such as\nthe inclusion of intermediate reasoning steps in the questions) to conduct\nbehavioral analysis on the LLMs. Throughout our experiments, we find that\nmodels are more sensitive to certain perturbations such as replacing words with\ntheir synonyms. We also demonstrate that increasing the proportion of perturbed\nexemplars in the prompts improves the robustness of few-shot prompting methods.",
            "author": [
                "Hongyi Zheng",
                "Abulhair Saparov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00258v1",
                "http://arxiv.org/pdf/2311.00258v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00252v1",
            "title": "Active Neural Topological Mapping for Multi-Agent Exploration",
            "updated": "2023-11-01T03:06:14Z",
            "published": "2023-11-01T03:06:14Z",
            "summary": "This paper investigates the multi-agent cooperative exploration problem,\nwhich requires multiple agents to explore an unseen environment via sensory\nsignals in a limited time. A popular approach to exploration tasks is to\ncombine active mapping with planning. Metric maps capture the details of the\nspatial representation, but are with high communication traffic and may vary\nsignificantly between scenarios, resulting in inferior generalization.\nTopological maps are a promising alternative as they consist only of nodes and\nedges with abstract but essential information and are less influenced by the\nscene structures. However, most existing topology-based exploration tasks\nutilize classical methods for planning, which are time-consuming and\nsub-optimal due to their handcrafted design. Deep reinforcement learning (DRL)\nhas shown great potential for learning (near) optimal policies through fast\nend-to-end inference. In this paper, we propose Multi-Agent Neural Topological\nMapping (MANTM) to improve exploration efficiency and generalization for\nmulti-agent exploration tasks. MANTM mainly comprises a Topological Mapper and\na novel RL-based Hierarchical Topological Planner (HTP). The Topological Mapper\nemploys a visual encoder and distance-based heuristics to construct a graph\ncontaining main nodes and their corresponding ghost nodes. The HTP leverages\ngraph neural networks to capture correlations between agents and graph nodes in\na coarse-to-fine manner for effective global goal selection. Extensive\nexperiments conducted in a physically-realistic simulator, Habitat, demonstrate\nthat MANTM reduces the steps by at least 26.40% over planning-based baselines\nand by at least 7.63% over RL-based competitors in unseen scenarios.",
            "author": [
                "Xinyi Yang",
                "Yuxiang Yang",
                "Chao Yu",
                "Jiayu Chen",
                "Jingchen Yu",
                "Haibing Ren",
                "Huazhong Yang",
                "Yu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00252v1",
                "http://arxiv.org/pdf/2311.00252v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00246v1",
            "title": "RAUNE-Net: A Residual and Attention-Driven Underwater Image Enhancement\n  Method",
            "updated": "2023-11-01T03:00:07Z",
            "published": "2023-11-01T03:00:07Z",
            "summary": "Underwater image enhancement (UIE) poses challenges due to distinctive\nproperties of the underwater environment, including low contrast, high\nturbidity, visual blurriness, and color distortion. In recent years, the\napplication of deep learning has quietly revolutionized various areas of\nscientific research, including UIE. However, existing deep learning-based UIE\nmethods generally suffer from issues of weak robustness and limited\nadaptability. In this paper, inspired by residual and attention mechanisms, we\npropose a more reliable and reasonable UIE network called RAUNE-Net by\nemploying residual learning of high-level features at the network's bottle-neck\nand two aspects of attention manipulations in the down-sampling procedure.\nFurthermore, we collect and create two datasets specifically designed for\nevaluating UIE methods, which contains different types of underwater\ndistortions and degradations. The experimental validation demonstrates that our\nmethod obtains promising objective performance and consistent visual results\nacross various real-world underwater images compared to other eight UIE\nmethods. Our example code and datasets are publicly available at\nhttps://github.com/fansuregrin/RAUNE-Net.",
            "author": [
                "Wangzhen Peng",
                "Chenghao Zhou",
                "Runze Hu",
                "Jingchao Cao",
                "Yutao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00246v1",
                "http://arxiv.org/pdf/2311.00246v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00241v1",
            "title": "1DFormer: Learning 1D Landmark Representations via Transformer for\n  Facial Landmark Tracking",
            "updated": "2023-11-01T02:49:25Z",
            "published": "2023-11-01T02:49:25Z",
            "summary": "Recently, heatmap regression methods based on 1D landmark representations\nhave shown prominent performance on locating facial landmarks. However,\nprevious methods ignored to make deep explorations on the good potentials of 1D\nlandmark representations for sequential and structural modeling of multiple\nlandmarks to track facial landmarks. To address this limitation, we propose a\nTransformer architecture, namely 1DFormer, which learns informative 1D landmark\nrepresentations by capturing the dynamic and the geometric patterns of\nlandmarks via token communications in both temporal and spatial dimensions for\nfacial landmark tracking. For temporal modeling, we propose a recurrent token\nmixing mechanism, an axis-landmark-positional embedding mechanism, as well as a\nconfidence-enhanced multi-head attention mechanism to adaptively and robustly\nembed long-term landmark dynamics into their 1D representations; for structure\nmodeling, we design intra-group and inter-group structure modeling mechanisms\nto encode the component-level as well as global-level facial structure patterns\nas a refinement for the 1D representations of landmarks through token\ncommunications in the spatial dimension via 1D convolutional layers.\nExperimental results on the 300VW and the TF databases show that 1DFormer\nsuccessfully models the long-range sequential patterns as well as the inherent\nfacial structures to learn informative 1D representations of landmark\nsequences, and achieves state-of-the-art performance on facial landmark\ntracking.",
            "author": [
                "Shi Yin",
                "Shijie Huan",
                "Defu Lian",
                "Shangfei Wang",
                "Jinshui Hu",
                "Tao Guo",
                "Bing Yin",
                "Baocai Yin",
                "Cong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00241v1",
                "http://arxiv.org/pdf/2311.00241v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00237v1",
            "title": "The Mystery and Fascination of LLMs: A Comprehensive Survey on the\n  Interpretation and Analysis of Emergent Abilities",
            "updated": "2023-11-01T02:40:42Z",
            "published": "2023-11-01T02:40:42Z",
            "summary": "Understanding emergent abilities, such as in-context learning (ICL) and\nchain-of-thought (CoT) prompting in large language models (LLMs), is of utmost\nimportance. This importance stems not only from the better utilization of these\ncapabilities across various tasks, but also from the proactive identification\nand mitigation of potential risks, including concerns of truthfulness, bias,\nand toxicity, that may arise alongside these capabilities. In this paper, we\npresent a thorough survey on the interpretation and analysis of emergent\nabilities of LLMs. First, we provide a concise introduction to the background\nand definition of emergent abilities. Then, we give an overview of advancements\nfrom two perspectives: 1) a macro perspective, emphasizing studies on the\nmechanistic interpretability and delving into the mathematical foundations\nbehind emergent abilities; and 2) a micro-perspective, concerning studies that\nfocus on empirical interpretability by examining factors associated with these\nabilities. We conclude by highlighting the challenges encountered and\nsuggesting potential avenues for future research. We believe that our work\nestablishes the basis for further exploration into the interpretation of\nemergent abilities.",
            "author": [
                "Yuxiang Zhou",
                "Jiazheng Li",
                "Yanzheng Xiang",
                "Hanqi Yan",
                "Lin Gui",
                "Yulan He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00237v1",
                "http://arxiv.org/pdf/2311.00237v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00236v1",
            "title": "Objectives and Key Results in Software Teams: Challenges, Opportunities\n  and Impact on Development",
            "updated": "2023-11-01T02:39:01Z",
            "published": "2023-11-01T02:39:01Z",
            "summary": "Building software, like building almost anything, requires people to\nunderstand a common goal and work together towards it. In large software\ncompanies, a VP or Director will have an idea or goal and it is often the job\nof middle management to distill that lofty, general idea into manageable,\nfinite units of work. How do organizations do this hard work of setting and\nmeasuring progress towards goals? To understand this question, we undertook a\nmixed methods approach to studying goal setting, management dissemination of\ngoals, goal tracking and ultimately software delivery at a large multi-national\nsoftware company.\n  Semi-structured interviews with 47 participants were analyzed and used to\ndevelop a survey which was deployed to a multi-national team of over 4,000\nengineers. The 512 responses were analyzed using thematic analysis, linear\nregressions and hypothesis testing, and found that tracking, measuring and\nsetting goals is hard work, regardless of tools used. Middle management seems\nto be a critical component of the translation of lofty goals to actionable work\nitems. In addition, attitudes and beliefs of engineers are critical to the\nsuccess of any goal setting framework. Based on this research, we make\nrecommendations on how to improve the goal setting and OKR process in software\norganizations: invest in the data pipeline, increase transparency, improve\ncommunication, promote learning communities, and a structured roll out of OKRs.",
            "author": [
                "Jenna Butler",
                "Thomas Zimmermann",
                "Christian Bird"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00236v1",
                "http://arxiv.org/pdf/2311.00236v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00235v1",
            "title": "Implicit biases in multitask and continual learning from a backward\n  error analysis perspective",
            "updated": "2023-11-01T02:37:32Z",
            "published": "2023-11-01T02:37:32Z",
            "summary": "Using backward error analysis, we compute implicit training biases in\nmultitask and continual learning settings for neural networks trained with\nstochastic gradient descent. In particular, we derive modified losses that are\nimplicitly minimized during training. They have three terms: the original loss,\naccounting for convergence, an implicit flatness regularization term\nproportional to the learning rate, and a last term, the conflict term, which\ncan theoretically be detrimental to both convergence and implicit\nregularization. In multitask, the conflict term is a well-known quantity,\nmeasuring the gradient alignment between the tasks, while in continual learning\nthe conflict term is a new quantity in deep learning optimization, although a\nbasic tool in differential geometry: The Lie bracket between the task\ngradients.",
            "author": [
                "Benoit Dherin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00235v1",
                "http://arxiv.org/pdf/2311.00235v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00231v1",
            "title": "DistDNAS: Search Efficient Feature Interactions within 2 Hours",
            "updated": "2023-11-01T02:27:38Z",
            "published": "2023-11-01T02:27:38Z",
            "summary": "Search efficiency and serving efficiency are two major axes in building\nfeature interactions and expediting the model development process in\nrecommender systems. On large-scale benchmarks, searching for the optimal\nfeature interaction design requires extensive cost due to the sequential\nworkflow on the large volume of data. In addition, fusing interactions of\nvarious sources, orders, and mathematical operations introduces potential\nconflicts and additional redundancy toward recommender models, leading to\nsub-optimal trade-offs in performance and serving cost. In this paper, we\npresent DistDNAS as a neat solution to brew swift and efficient feature\ninteraction design. DistDNAS proposes a supernet to incorporate interaction\nmodules of varying orders and types as a search space. To optimize search\nefficiency, DistDNAS distributes the search and aggregates the choice of\noptimal interaction modules on varying data dates, achieving over 25x speed-up\nand reducing search cost from 2 days to 2 hours. To optimize serving\nefficiency, DistDNAS introduces a differentiable cost-aware loss to penalize\nthe selection of redundant interaction modules, enhancing the efficiency of\ndiscovered feature interactions in serving. We extensively evaluate the best\nmodels crafted by DistDNAS on a 1TB Criteo Terabyte dataset. Experimental\nevaluations demonstrate 0.001 AUC improvement and 60% FLOPs saving over current\nstate-of-the-art CTR models.",
            "author": [
                "Tunhou Zhang",
                "Wei Wen",
                "Igor Fedorov",
                "Xi Liu",
                "Buyun Zhang",
                "Fangqiu Han",
                "Wen-Yen Chen",
                "Yiping Han",
                "Feng Yan",
                "Hai Li",
                "Yiran Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00231v1",
                "http://arxiv.org/pdf/2311.00231v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00227v1",
            "title": "StableFDG: Style and Attention Based Learning for Federated Domain\n  Generalization",
            "updated": "2023-11-01T02:17:01Z",
            "published": "2023-11-01T02:17:01Z",
            "summary": "Traditional federated learning (FL) algorithms operate under the assumption\nthat the data distributions at training (source domains) and testing (target\ndomain) are the same. The fact that domain shifts often occur in practice\nnecessitates equipping FL methods with a domain generalization (DG) capability.\nHowever, existing DG algorithms face fundamental challenges in FL setups due to\nthe lack of samples/domains in each client's local dataset. In this paper, we\npropose StableFDG, a style and attention based learning strategy for\naccomplishing federated domain generalization, introducing two key\ncontributions. The first is style-based learning, which enables each client to\nexplore novel styles beyond the original source domains in its local dataset,\nimproving domain diversity based on the proposed style sharing, shifting, and\nexploration strategies. Our second contribution is an attention-based feature\nhighlighter, which captures the similarities between the features of data\nsamples in the same class, and emphasizes the important/common characteristics\nto better learn the domain-invariant characteristics of each class in data-poor\nFL scenarios. Experimental results show that StableFDG outperforms existing\nbaselines on various DG benchmark datasets, demonstrating its efficacy.",
            "author": [
                "Jungwuk Park",
                "Dong-Jun Han",
                "Jinho Kim",
                "Shiqiang Wang",
                "Christopher G. Brinton",
                "Jaekyun Moon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00227v1",
                "http://arxiv.org/pdf/2311.00227v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00226v2",
            "title": "Transformers are Efficient In-Context Estimators for Wireless\n  Communication",
            "updated": "2023-12-03T04:31:28Z",
            "published": "2023-11-01T02:16:24Z",
            "summary": "Pre-trained transformers can perform in-context learning, where they adapt to\na new task using only a small number of prompts without any explicit model\noptimization. Inspired by this attribute, we propose a novel approach, called\nin-context estimation, for the canonical communication problem of estimating\ntransmitted symbols from received symbols. A communication channel is\nessentially a noisy function that maps transmitted symbols to received symbols,\nand this function can be represented by an unknown parameter whose statistics\ndepend on an (also unknown) latent context. Conventional approaches typically\ndo not fully exploit hierarchical model with the latent context. Instead, they\noften use mismatched priors to form a linear minimum mean-squared error\nestimate of the channel parameter, which is then used to estimate successive,\nunknown transmitted symbols. We make the basic connection that transformers\nshow excellent contextual sequence completion with a few prompts, and so they\nshould be able to implicitly determine the latent context from pilot symbols to\nperform end-to-end in-context estimation of transmitted symbols. Furthermore,\nthe transformer should use information efficiently, i.e., it should utilize any\npilots received to attain the best possible symbol estimates. Through extensive\nsimulations, we show that in-context estimation not only significantly\noutperforms standard approaches, but also achieves the same performance as an\nestimator with perfect knowledge of the latent context within a few context\nexamples. Thus, we make a strong case that transformers are efficient\nin-context estimators in the communication setting.",
            "author": [
                "Vicram Rajagopalan",
                "Vishnu Teja Kunde",
                "Chandra Shekhara Kaushik Valmeekam",
                "Krishna Narayanan",
                "Srinivas Shakkottai",
                "Dileep Kalathil",
                "Jean-Francois Chamberland"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00226v2",
                "http://arxiv.org/pdf/2311.00226v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00214v1",
            "title": "WinNet:time series forecasting with a window-enhanced period extracting\n  and interacting",
            "updated": "2023-11-01T01:23:59Z",
            "published": "2023-11-01T01:23:59Z",
            "summary": "Recently, Transformer-based methods have significantly improved\nstate-of-the-art time series forecasting results, but they suffer from high\ncomputational costs and the inability to capture the long and short periodicity\nof time series. We present a highly accurate and simply structured CNN-based\nmodel for long-term time series forecasting tasks, called WinNet, including (i)\nInter-Intra Period Encoder (I2PE) to transform 1D sequence into 2D tensor with\nlong and short periodicity according to the predefined periodic window, (ii)\nTwo-Dimensional Period Decomposition (TDPD) to model period-trend and\noscillation terms, and (iii) Decomposition Correlation Block (DCB) to leverage\nthe correlations of the period-trend and oscillation terms to support the\nprediction tasks by CNNs. Results on nine benchmark datasets show that the\nWinNet can achieve SOTA performance and lower computational complexity over\nCNN-, MLP-, Transformer-based approaches. The WinNet provides potential for the\nCNN-based methods in the time series forecasting tasks, with perfect tradeoff\nbetween performance and efficiency.",
            "author": [
                "Wenjie Ou",
                "Dongyue Guo",
                "Zheng Zhang",
                "Zhishuo Zhao",
                "Yi Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00214v1",
                "http://arxiv.org/pdf/2311.00214v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00212v1",
            "title": "A Unified Framework to Enforce, Discover, and Promote Symmetry in\n  Machine Learning",
            "updated": "2023-11-01T01:19:54Z",
            "published": "2023-11-01T01:19:54Z",
            "summary": "Symmetry is present throughout nature and continues to play an increasingly\ncentral role in physics and machine learning. Fundamental symmetries, such as\nPoincar\\'{e} invariance, allow physical laws discovered in laboratories on\nEarth to be extrapolated to the farthest reaches of the universe. Symmetry is\nessential to achieving this extrapolatory power in machine learning\napplications. For example, translation invariance in image classification\nallows models with fewer parameters, such as convolutional neural networks, to\nbe trained on smaller data sets and achieve state-of-the-art performance. In\nthis paper, we provide a unifying theoretical and methodological framework for\nincorporating symmetry into machine learning models in three ways: 1. enforcing\nknown symmetry when training a model; 2. discovering unknown symmetries of a\ngiven model or data set; and 3. promoting symmetry during training by learning\na model that breaks symmetries within a user-specified group of candidates when\nthere is sufficient evidence in the data. We show that these tasks can be cast\nwithin a common mathematical framework whose central object is the Lie\nderivative associated with fiber-linear Lie group actions on vector bundles. We\nextend and unify several existing results by showing that enforcing and\ndiscovering symmetry are linear-algebraic tasks that are dual with respect to\nthe bilinear structure of the Lie derivative. We also propose a novel way to\npromote symmetry by introducing a class of convex regularization functions\nbased on the Lie derivative and nuclear norm relaxation to penalize symmetry\nbreaking during training of machine learning models. We explain how these ideas\ncan be applied to a wide range of machine learning models including basis\nfunction regression, dynamical systems discovery, multilayer perceptrons, and\nneural networks acting on spatial fields such as images.",
            "author": [
                "Samuel E. Otto",
                "Nicholas Zolman",
                "J. Nathan Kutz",
                "Steven L. Brunton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00212v1",
                "http://arxiv.org/pdf/2311.00212v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.DG",
                "math.NA",
                "15B30, 22E15, 22E70, 47D03, 54H15, 57S99, 5808, 58D19, 58K70, 65F55,\n  68Q32, 68T07, 70G65, 70H33, 90C25"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00210v1",
            "title": "Broken Adaptive Ridge Method for Variable Selection in Generalized\n  Partly Linear Models with Application to the Coronary Artery Disease Data",
            "updated": "2023-11-01T00:50:13Z",
            "published": "2023-11-01T00:50:13Z",
            "summary": "Motivated by the CATHGEN data, we develop a new statistical learning method\nfor simultaneous variable selection and parameter estimation under the context\nof generalized partly linear models for data with high-dimensional covariates.\nThe method is referred to as the broken adaptive ridge (BAR) estimator, which\nis an approximation of the $L_0$-penalized regression by iteratively performing\nreweighted squared $L_2$-penalized regression. The generalized partly linear\nmodel extends the generalized linear model by including a non-parametric\ncomponent to construct a flexible model for modeling various types of covariate\neffects. We employ the Bernstein polynomials as the sieve space to approximate\nthe non-parametric functions so that our method can be implemented easily using\nthe existing R packages. Extensive simulation studies suggest that the proposed\nmethod performs better than other commonly used penalty-based variable\nselection methods. We apply the method to the CATHGEN data with a binary\nresponse from a coronary artery disease study, which motivated our research,\nand obtained new findings in both high-dimensional genetic and low-dimensional\nnon-genetic covariates.",
            "author": [
                "Christian Chan",
                "Xiaotian Dai",
                "Thierry Chekouo",
                "Quan Long",
                "Xuewen Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00210v1",
                "http://arxiv.org/pdf/2311.00210v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP",
                "stat.OT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03378v1",
            "title": "Transferability and explainability of deep learning emulators for\n  regional climate model projections: Perspectives for future applications",
            "updated": "2023-11-01T00:44:39Z",
            "published": "2023-11-01T00:44:39Z",
            "summary": "Regional climate models (RCMs) are essential tools for simulating and\nstudying regional climate variability and change. However, their high\ncomputational cost limits the production of comprehensive ensembles of regional\nclimate projections covering multiple scenarios and driving Global Climate\nModels (GCMs) across regions. RCM emulators based on deep learning models have\nrecently been introduced as a cost-effective and promising alternative that\nrequires only short RCM simulations to train the models. Therefore, evaluating\ntheir transferability to different periods, scenarios, and GCMs becomes a\npivotal and complex task in which the inherent biases of both GCMs and RCMs\nplay a significant role. Here we focus on this problem by considering the two\ndifferent emulation approaches proposed in the literature (PP and MOS,\nfollowing the terminology introduced in this paper). In addition to standard\nevaluation techniques, we expand the analysis with methods from the field of\neXplainable Artificial Intelligence (XAI), to assess the physical consistency\nof the empirical links learnt by the models. We find that both approaches are\nable to emulate certain climatological properties of RCMs for different periods\nand scenarios (soft transferability), but the consistency of the emulation\nfunctions differ between approaches. Whereas PP learns robust and physically\nmeaningful patterns, MOS results are GCM-dependent and lack physical\nconsistency in some cases. Both approaches face problems when transferring the\nemulation function to other GCMs, due to the existence of GCM-dependent biases\n(hard transferability). This limits their applicability to build ensembles of\nregional climate projections. We conclude by giving some prospects for future\napplications.",
            "author": [
                "Jorge Bano-Medina",
                "Maialen Iturbide",
                "Jesus Fernandez",
                "Jose Manuel Gutierrez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03378v1",
                "http://arxiv.org/pdf/2311.03378v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00208v1",
            "title": "Transformers as Recognizers of Formal Languages: A Survey on\n  Expressivity",
            "updated": "2023-11-01T00:38:26Z",
            "published": "2023-11-01T00:38:26Z",
            "summary": "As transformers have gained prominence in natural language processing, some\nresearchers have investigated theoretically what problems they can and cannot\nsolve, by treating problems as formal languages. Exploring questions such as\nthis will help to compare transformers with other models, and transformer\nvariants with one another, for various tasks. Work in this subarea has made\nconsiderable progress in recent years. Here, we undertake a comprehensive\nsurvey of this work, documenting the diverse assumptions that underlie\ndifferent results and providing a unified framework for harmonizing seemingly\ncontradictory findings.",
            "author": [
                "Lena Strobl",
                "William Merrill",
                "Gail Weiss",
                "David Chiang",
                "Dana Angluin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00208v1",
                "http://arxiv.org/pdf/2311.00208v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.FL",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00207v1",
            "title": "Magmaw: Modality-Agnostic Adversarial Attacks on Machine Learning-Based\n  Wireless Communication Systems",
            "updated": "2023-11-01T00:33:59Z",
            "published": "2023-11-01T00:33:59Z",
            "summary": "Machine Learning (ML) has been instrumental in enabling joint transceiver\noptimization by merging all physical layer blocks of the end-to-end wireless\ncommunication systems. Although there have been a number of adversarial attacks\non ML-based wireless systems, the existing methods do not provide a\ncomprehensive view including multi-modality of the source data, common physical\nlayer components, and wireless domain constraints. This paper proposes Magmaw,\nthe first black-box attack methodology capable of generating universal\nadversarial perturbations for any multimodal signal transmitted over a wireless\nchannel. We further introduce new objectives for adversarial attacks on\nML-based downstream applications. The resilience of the attack to the existing\nwidely used defense methods of adversarial training and perturbation signal\nsubtraction is experimentally verified. For proof-of-concept evaluation, we\nbuild a real-time wireless attack platform using a software-defined radio\nsystem. Experimental results demonstrate that Magmaw causes significant\nperformance degradation even in the presence of the defense mechanisms.\nSurprisingly, Magmaw is also effective against encrypted communication channels\nand conventional communications.",
            "author": [
                "Jung-Woo Chang",
                "Ke Sun",
                "Nasimeh Heydaribeni",
                "Seira Hidano",
                "Xinyu Zhang",
                "Farinaz Koushanfar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00207v1",
                "http://arxiv.org/pdf/2311.00207v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00729v2",
            "title": "ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot\n  End-to-End Temporal Action Detection",
            "updated": "2023-11-04T23:41:21Z",
            "published": "2023-11-01T00:17:37Z",
            "summary": "Temporal action detection (TAD) involves the localization and classification\nof action instances within untrimmed videos. While standard TAD follows fully\nsupervised learning with closed-set setting on large training data, recent\nzero-shot TAD methods showcase the promising open-set setting by leveraging\nlarge-scale contrastive visual-language (ViL) pretrained models. However,\nexisting zero-shot TAD methods have limitations on how to properly construct\nthe strong relationship between two interdependent tasks of localization and\nclassification and adapt ViL model to video understanding. In this work, we\npresent ZEETAD, featuring two modules: dual-localization and zero-shot proposal\nclassification. The former is a Transformer-based module that detects action\nevents while selectively collecting crucial semantic embeddings for later\nrecognition. The latter one, CLIP-based module, generates semantic embeddings\nfrom text and frame inputs for each temporal unit. Additionally, we enhance\ndiscriminative capability on unseen classes by minimally updating the frozen\nCLIP encoder with lightweight adapters. Extensive experiments on THUMOS14 and\nActivityNet-1.3 datasets demonstrate our approach's superior performance in\nzero-shot TAD and effective knowledge transfer from ViL models to unseen action\ncategories.",
            "author": [
                "Thinh Phan",
                "Khoa Vo",
                "Duy Le",
                "Gianfranco Doretto",
                "Donald Adjeroh",
                "Ngan Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00729v2",
                "http://arxiv.org/pdf/2311.00729v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00201v1",
            "title": "Federated Natural Policy Gradient Methods for Multi-task Reinforcement\n  Learning",
            "updated": "2023-11-01T00:15:18Z",
            "published": "2023-11-01T00:15:18Z",
            "summary": "Federated reinforcement learning (RL) enables collaborative decision making\nof multiple distributed agents without sharing local data trajectories. In this\nwork, we consider a multi-task setting, in which each agent has its own private\nreward function corresponding to different tasks, while sharing the same\ntransition kernel of the environment. Focusing on infinite-horizon tabular\nMarkov decision processes, the goal is to learn a globally optimal policy that\nmaximizes the sum of the discounted total rewards of all the agents in a\ndecentralized manner, where each agent only communicates with its neighbors\nover some prescribed graph topology. We develop federated vanilla and\nentropy-regularized natural policy gradient (NPG) methods under softmax\nparameterization, where gradient tracking is applied to the global Q-function\nto mitigate the impact of imperfect information sharing. We establish\nnon-asymptotic global convergence guarantees under exact policy evaluation,\nwhich are nearly independent of the size of the state-action space and\nilluminate the impacts of network size and connectivity. To the best of our\nknowledge, this is the first time that global convergence is established for\nfederated multi-task RL using policy optimization. Moreover, the convergence\nbehavior of the proposed algorithms is robust against inexactness of policy\nevaluation.",
            "author": [
                "Tong Yang",
                "Shicong Cen",
                "Yuting Wei",
                "Yuxin Chen",
                "Yuejie Chi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00201v1",
                "http://arxiv.org/pdf/2311.00201v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00196v1",
            "title": "Machine learning for accuracy in density functional approximations",
            "updated": "2023-11-01T00:02:09Z",
            "published": "2023-11-01T00:02:09Z",
            "summary": "Machine learning techniques have found their way into computational chemistry\nas indispensable tools to accelerate atomistic simulations and materials\ndesign. In addition, machine learning approaches hold the potential to boost\nthe predictive power of computationally efficient electronic structure methods,\nsuch as density functional theory, to chemical accuracy and to correct for\nfundamental errors in density functional approaches. Here, recent progress in\napplying machine learning to improve the accuracy of density functional and\nrelated approximations is reviewed. Promises and challenges in devising machine\nlearning models transferable between different chemistries and materials\nclasses are discussed with the help of examples applying promising models to\nsystems far outside their training sets.",
            "author": [
                "Johannes Voss"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00196v1",
                "http://arxiv.org/pdf/2311.00196v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02100v1",
            "title": "A Comprehensive Study on Model Initialization Techniques Ensuring\n  Efficient Federated Learning",
            "updated": "2023-10-31T23:26:58Z",
            "published": "2023-10-31T23:26:58Z",
            "summary": "Advancement in the field of machine learning is unavoidable, but something of\nmajor concern is preserving the privacy of the users whose data is being used\nfor training these machine learning algorithms. Federated learning(FL) has\nemerged as a promising paradigm for training machine learning models in a\ndistributed and privacy-preserving manner which enables one to collaborate and\ntrain a global model without sharing local data. But starting this learning\nprocess on each device in the right way, called ``model initialization\" is\ncritical. The choice of initialization methods used for models plays a crucial\nrole in the performance, convergence speed, communication efficiency, privacy\nguarantees of federated learning systems, etc. In this survey, we dive deeper\ninto a comprehensive study of various ways of model initialization techniques\nin FL.Unlike other studies, our research meticulously compares, categorizes,\nand delineates the merits and demerits of each technique, examining their\napplicability across diverse FL scenarios. We highlight how factors like client\nvariability, data non-IIDness, model caliber, security considerations, and\nnetwork restrictions influence FL model outcomes and propose how strategic\ninitialization can address and potentially rectify many such challenges. The\nmotivation behind this survey is to highlight that the right start can help\novercome challenges like varying data quality, security issues, and network\nproblems. Our insights provide a foundational base for experts looking to fully\nutilize FL, also while understanding the complexities of model initialization.",
            "author": [
                "Ishmeet Kaur",
                "Adwaita Janardhan Jadhav"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02100v1",
                "http://arxiv.org/pdf/2311.02100v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00189v1",
            "title": "XAI-CLASS: Explanation-Enhanced Text Classification with Extremely Weak\n  Supervision",
            "updated": "2023-10-31T23:24:22Z",
            "published": "2023-10-31T23:24:22Z",
            "summary": "Text classification aims to effectively categorize documents into pre-defined\ncategories. Traditional methods for text classification often rely on large\namounts of manually annotated training data, making the process time-consuming\nand labor-intensive. To address this issue, recent studies have focused on\nweakly-supervised and extremely weakly-supervised settings, which require\nminimal or no human annotation, respectively. In previous methods of weakly\nsupervised text classification, pseudo-training data is generated by assigning\npseudo-labels to documents based on their alignment (e.g., keyword matching)\nwith specific classes. However, these methods ignore the importance of\nincorporating the explanations of the generated pseudo-labels, or saliency of\nindividual words, as additional guidance during the text classification\ntraining process. To address this limitation, we propose XAI-CLASS, a novel\nexplanation-enhanced extremely weakly-supervised text classification method\nthat incorporates word saliency prediction as an auxiliary task. XAI-CLASS\nbegins by employing a multi-round question-answering process to generate\npseudo-training data that promotes the mutual enhancement of class labels and\ncorresponding explanation word generation. This pseudo-training data is then\nused to train a multi-task framework that simultaneously learns both text\nclassification and word saliency prediction. Extensive experiments on several\nweakly-supervised text classification datasets show that XAI-CLASS outperforms\nother weakly-supervised text classification methods significantly. Moreover,\nexperiments demonstrate that XAI-CLASS enhances both model performance and\nexplainability.",
            "author": [
                "Daniel Hajialigol",
                "Hanwen Liu",
                "Xuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00189v1",
                "http://arxiv.org/pdf/2311.00189v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00188v1",
            "title": "A Two-Step Framework for Multi-Material Decomposition of Dual Energy\n  Computed Tomography from Projection Domain",
            "updated": "2023-10-31T23:23:14Z",
            "published": "2023-10-31T23:23:14Z",
            "summary": "Dual-energy computed tomography (DECT) utilizes separate X-ray energy spectra\nto improve multi-material decomposition (MMD) for various diagnostic\napplications. However accurate decomposing more than two types of material\nremains challenging using conventional methods. Deep learning (DL) methods have\nshown promise to improve the MMD performance, but typical approaches of\nconducing DL-MMD in the image domain fail to fully utilize projection\ninformation or under iterative setup are computationally inefficient in both\ntraining and prediction. In this work, we present a clinical-applicable MMD\n(>2) framework rFast-MMDNet, operating with raw projection data in\nnon-recursive setup, for breast tissue differentiation. rFast-MMDNet is a\ntwo-stage algorithm, including stage-one SinoNet to perform dual energy\nprojection decomposition on tissue sinograms and stage-two FBP-DenoiseNet to\nperform domain adaptation and image post-processing. rFast-MMDNet was tested on\na 2022 DL-Spectral-Challenge breast phantom dataset. The two stages of\nrFast-MMDNet were evaluated separately and then compared with four noniterative\nreference methods including a direct inversion method (AA-MMD), an image domain\nDL method (ID-UNet), AA-MMD/ID-UNet + DenoiseNet and a sinogram domain DL\nmethod (Triple-CBCT). Our results show that models trained from information\nstored in DE transmission domain can yield high-fidelity decomposition of the\nadipose, calcification, and fibroglandular materials with averaged RMSE, MAE,\nnegative PSNR, and SSIM of 0.004+/-~0, 0.001+/-~0, -45.027+/-~0.542, and\n0.002+/-~0 benchmarking to the ground truth, respectively. Training of entire\nrFast-MMDNet on a 4xRTX A6000 GPU cluster took a day with inference time <1s.\nAll DL methods generally led to more accurate MMD than AA-MMD. rFast-MMDNet\noutperformed Triple-CBCT, but both are superior to the image-domain based\nmethods.",
            "author": [
                "Di Xu",
                "Qihui Lyu",
                "Dan Ruan",
                "Ke Sheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00188v1",
                "http://arxiv.org/pdf/2311.00188v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00187v2",
            "title": "Decodable and Sample Invariant Continuous Object Encoder",
            "updated": "2023-11-21T15:25:15Z",
            "published": "2023-10-31T23:19:30Z",
            "summary": "We propose Hyper-Dimensional Function Encoding (HDFE). Given samples of a\ncontinuous object (e.g. a function), HDFE produces an explicit vector\nrepresentation of the given object, invariant to the sample distribution and\ndensity. Sample distribution and density invariance enables HDFE to\nconsistently encode continuous objects regardless of their sampling, and\ntherefore allows neural networks to receive continuous objects as inputs for\nmachine learning tasks, such as classification and regression. Besides, HDFE\ndoes not require any training and is proved to map the object into an organized\nembedding space, which facilitates the training of the downstream tasks. In\naddition, the encoding is decodable, which enables neural networks to regress\ncontinuous objects by regressing their encodings. Therefore, HDFE serves as an\ninterface for processing continuous objects.\n  We apply HDFE to function-to-function mapping, where vanilla HDFE achieves\ncompetitive performance as the state-of-the-art algorithm. We apply HDFE to\npoint cloud surface normal estimation, where a simple replacement from PointNet\nto HDFE leads to immediate 12% and 15% error reductions in two benchmarks. In\naddition, by integrating HDFE into the PointNet-based SOTA network, we improve\nthe SOTA baseline by 2.5% and 1.7% in the same benchmarks.",
            "author": [
                "Dehao Yuan",
                "Furong Huang",
                "Cornelia Ferm\u00fcller",
                "Yiannis Aloimonos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00187v2",
                "http://arxiv.org/pdf/2311.00187v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00186v1",
            "title": "Image Restoration with Point Spread Function Regularization and Active\n  Learning",
            "updated": "2023-10-31T23:16:26Z",
            "published": "2023-10-31T23:16:26Z",
            "summary": "Large-scale astronomical surveys can capture numerous images of celestial\nobjects, including galaxies and nebulae. Analysing and processing these images\ncan reveal intricate internal structures of these objects, allowing researchers\nto conduct comprehensive studies on their morphology, evolution, and physical\nproperties. However, varying noise levels and point spread functions can hamper\nthe accuracy and efficiency of information extraction from these images. To\nmitigate these effects, we propose a novel image restoration algorithm that\nconnects a deep learning-based restoration algorithm with a high-fidelity\ntelescope simulator. During the training stage, the simulator generates images\nwith different levels of blur and noise to train the neural network based on\nthe quality of restored images. After training, the neural network can directly\nrestore images obtained by the telescope, as represented by the simulator. We\nhave tested the algorithm using real and simulated observation data and have\nfound that it effectively enhances fine structures in blurry images and\nincreases the quality of observation images. This algorithm can be applied to\nlarge-scale sky survey data, such as data obtained by LSST, Euclid, and CSST,\nto further improve the accuracy and efficiency of information extraction,\npromoting advances in the field of astronomical research.",
            "author": [
                "Peng Jia",
                "Jiameng Lv",
                "Runyu Ning",
                "Yu Song",
                "Nan Li",
                "Kaifan Ji",
                "Chenzhou Cui",
                "Shanshan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00186v1",
                "http://arxiv.org/pdf/2311.00186v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.GA",
                "astro-ph.SR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00181v1",
            "title": "Best of Both Worlds: Stochastic and Adversarial Convex Function Chasing",
            "updated": "2023-10-31T22:59:23Z",
            "published": "2023-10-31T22:59:23Z",
            "summary": "Convex function chasing (CFC) is an online optimization problem in which\nduring each round $t$, a player plays an action $x_t$ in response to a hitting\ncost $f_t(x_t)$ and an additional cost of $c(x_t,x_{t-1})$ for switching\nactions. We study the CFC problem in stochastic and adversarial environments,\ngiving algorithms that achieve performance guarantees simultaneously in both\nsettings. Specifically, we consider the squared $\\ell_2$-norm switching costs\nand a broad class of quadratic hitting costs for which the sequence of\nminimizers either forms a martingale or is chosen adversarially. This is the\nfirst work that studies the CFC problem using a stochastic framework. We\nprovide a characterization of the optimal stochastic online algorithm and,\ndrawing a comparison between the stochastic and adversarial scenarios, we\ndemonstrate that the adversarial-optimal algorithm exhibits suboptimal\nperformance in the stochastic context. Motivated by this, we provide a\nbest-of-both-worlds algorithm that obtains robust adversarial performance while\nsimultaneously achieving near-optimal stochastic performance.",
            "author": [
                "Neelkamal Bhuyan",
                "Debankur Mukherjee",
                "Adam Wierman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00181v1",
                "http://arxiv.org/pdf/2311.00181v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DS",
                "cs.LG",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00177v1",
            "title": "Students' Perspective on AI Code Completion: Benefits and Challenges",
            "updated": "2023-10-31T22:41:16Z",
            "published": "2023-10-31T22:41:16Z",
            "summary": "AI Code Completion (e.g., GitHub's Copilot, Amazon CodeWhisperer) has\nrevolutionized the way in which computer science students interact with\nprogramming languages. However, these tools are not available for free public\nuse, preventing us from conducting our research. In addition, AI code\ncompletion has been studied from developers' perspective, not students'\nperspective who represent the future generation of our digital world. In this\narticle, we investigated the benefits, challenges, and expectations of AI code\ncompletion from students' perspectives and introduced AutoAurora, an AI code\ncompletion tool integrated into the Visual Studio Code Extension as a research\ninstrument. Through an interview study with ten participants, we found that AI\ncode completion enhanced students' productivity and efficiency by providing\ncorrect syntax suggestions, offering alternative solutions, and functioning as\na coding tutor. However, the over-reliance on AI code completion may lead to a\nsurface-level understanding of programming concepts, diminishing\nproblem-solving skills and restricting creativity. In the future, AI code\ncompletion must be explainable to facilitate the learning of coding concepts.",
            "author": [
                "Wannita Takerngsaksiri",
                "Cleshan Warusavitarne",
                "Christian Yaacoub",
                "Matthew Hee Keng Hou",
                "Chakkrit Tantithamthavorn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00177v1",
                "http://arxiv.org/pdf/2311.00177v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00170v1",
            "title": "Experimental Demonstration of Coupled Learning in Elastic Networks",
            "updated": "2023-10-31T22:09:23Z",
            "published": "2023-10-31T22:09:23Z",
            "summary": "Coupled learning is a contrastive scheme for tuning the properties of\nindividual elements within a network in order to achieve desired functionality\nof the system. It takes advantage of physics both to learn using local rules\nand to \"compute\" the output response to input data, thus enabling the system to\nperform decentralized computation without the need for a processor or external\nmemory. We demonstrate a proof-of-concept mechanical network that can learn\nsimple tasks such as self-symmetrizing via iterative tuning of individual\nspring rest lengths. These mechanical networks could feasibly be scaled and\nautomated to solve increasingly complex tasks, hinting at a new class of\n\"smart\" metamaterials.",
            "author": [
                "Lauren E. Altman",
                "Menachem Stern",
                "Andrea J. Liu",
                "Douglas J. Durian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00170v1",
                "http://arxiv.org/pdf/2311.00170v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00168v1",
            "title": "The Alignment Ceiling: Objective Mismatch in Reinforcement Learning from\n  Human Feedback",
            "updated": "2023-10-31T21:52:41Z",
            "published": "2023-10-31T21:52:41Z",
            "summary": "Reinforcement learning from human feedback (RLHF) has emerged as a powerful\ntechnique to make large language models (LLMs) easier to prompt and more\ncapable in complex settings. RLHF at its core is providing a new toolkit to\noptimize LLMs other than next-token prediction, enabling the integration of\nqualitative training goals. The attempted match between user preferences and\ndownstream performance, which happens in a learned reward model, results in an\noptimization landscape where training and evaluation metrics can appear\ncorrelated. The apparent correlation can lead to unexpected behaviors and\nstories of \"too much RLHF.\" In RLHF, challenges emerge because the following\nsub-modules are not consistent with each other: the reward model training, the\npolicy model training, and the policy model evaluation. This mismatch results\nin models that sometimes avoid user requests for false safety flags, are\ndifficult to steer to an intended characteristic, or always answer in a\nspecific style. As chat model evaluation becomes increasingly nuanced, the\nreliance on a perceived link between reward model score and downstream\nperformance drives the objective mismatch issue. In this paper, we illustrate\nthe cause of this issue, reviewing relevant literature from model-based\nreinforcement learning, and discuss relevant solutions to encourage further\nresearch. By solving objective mismatch in RLHF, the LLMs of the future will be\nmore precisely aligned to user instructions for both safety and helpfulness.",
            "author": [
                "Nathan Lambert",
                "Roberto Calandra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00168v1",
                "http://arxiv.org/pdf/2311.00168v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00167v1",
            "title": "Multi-task Deep Convolutional Network to Predict Sea Ice Concentration\n  and Drift in the Arctic Ocean",
            "updated": "2023-10-31T21:51:12Z",
            "published": "2023-10-31T21:51:12Z",
            "summary": "Forecasting sea ice concentration (SIC) and sea ice drift (SID) in the Arctic\nOcean is of great significance as the Arctic environment has been changed by\nthe recent warming climate. Given that physical sea ice models require high\ncomputational costs with complex parameterization, deep learning techniques can\neffectively replace the physical model and improve the performance of sea ice\nprediction. This study proposes a novel multi-task fully conventional network\narchitecture named hierarchical information-sharing U-net (HIS-Unet) to predict\ndaily SIC and SID. Instead of learning SIC and SID separately at each branch,\nwe allow the SIC and SID layers to share their information and assist each\nother's prediction through the weighting attention modules (WAMs).\nConsequently, our HIS-Unet outperforms other statistical approaches, sea ice\nphysical models, and neural networks without such information-sharing units.\nThe improvement of HIS-Unet is obvious both for SIC and SID prediction when and\nwhere sea ice conditions change seasonally, which implies that the information\nsharing through WAMs allows the model to learn the sudden changes of SIC and\nSID. The weight values of the WAMs imply that SIC information plays a more\ncritical role in SID prediction, compared to that of SID information in SIC\nprediction, and information sharing is more active in sea ice edges (seasonal\nsea ice) than in the central Arctic (multi-year sea ice).",
            "author": [
                "Younghyun Koo",
                "Maryam Rahnemoonfar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00167v1",
                "http://arxiv.org/pdf/2311.00167v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00164v1",
            "title": "Graph Neural Networks for Road Safety Modeling: Datasets and Evaluations\n  for Accident Analysis",
            "updated": "2023-10-31T21:43:10Z",
            "published": "2023-10-31T21:43:10Z",
            "summary": "We consider the problem of traffic accident analysis on a road network based\non road network connections and traffic volume. Previous works have designed\nvarious deep-learning methods using historical records to predict traffic\naccident occurrences. However, there is a lack of consensus on how accurate\nexisting methods are, and a fundamental issue is the lack of public accident\ndatasets for comprehensive evaluations. This paper constructs a large-scale,\nunified dataset of traffic accident records from official reports of various\nstates in the US, totaling 9 million records, accompanied by road networks and\ntraffic volume reports. Using this new dataset, we evaluate existing\ndeep-learning methods for predicting the occurrence of accidents on road\nnetworks. Our main finding is that graph neural networks such as GraphSAGE can\naccurately predict the number of accidents on roads with less than 22% mean\nabsolute error (relative to the actual count) and whether an accident will\noccur or not with over 87% AUROC, averaged over states. We achieve these\nresults by using multitask learning to account for cross-state variabilities\n(e.g., availability of accident labels) and transfer learning to combine\ntraffic volume with accident prediction. Ablation studies highlight the\nimportance of road graph-structural features, amongst other features. Lastly,\nwe discuss the implications of the analysis and develop a package for easily\nusing our new dataset.",
            "author": [
                "Abhinav Nippani",
                "Dongyue Li",
                "Haotian Ju",
                "Haris N. Koutsopoulos",
                "Hongyang R. Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00164v1",
                "http://arxiv.org/pdf/2311.00164v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00159v1",
            "title": "Longer Fixations, More Computation: Gaze-Guided Recurrent Neural\n  Networks",
            "updated": "2023-10-31T21:32:11Z",
            "published": "2023-10-31T21:32:11Z",
            "summary": "Humans read texts at a varying pace, while machine learning models treat each\ntoken in the same way in terms of a computational process. Therefore, we ask,\ndoes it help to make models act more like humans? In this paper, we convert\nthis intuition into a set of novel models with fixation-guided parallel RNNs or\nlayers and conduct various experiments on language modeling and sentiment\nanalysis tasks to test their effectiveness, thus providing empirical validation\nfor this intuition. Our proposed models achieve good performance on the\nlanguage modeling task, considerably surpassing the baseline model. In\naddition, we find that, interestingly, the fixation duration predicted by\nneural networks bears some resemblance to humans' fixation. Without any\nexplicit guidance, the model makes similar choices to humans. We also\ninvestigate the reasons for the differences between them, which explain why\n\"model fixations\" are often more suitable than human fixations, when used to\nguide language models.",
            "author": [
                "Xinting Huang",
                "Jiajing Wan",
                "Ioannis Kritikos",
                "Nora Hollenstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00159v1",
                "http://arxiv.org/pdf/2311.00159v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00157v2",
            "title": "Score Normalization for a Faster Diffusion Exponential Integrator\n  Sampler",
            "updated": "2023-11-10T00:30:14Z",
            "published": "2023-10-31T21:18:44Z",
            "summary": "Recently, Zhang et al. have proposed the Diffusion Exponential Integrator\nSampler (DEIS) for fast generation of samples from Diffusion Models. It\nleverages the semi-linear nature of the probability flow ordinary differential\nequation (ODE) in order to greatly reduce integration error and improve\ngeneration quality at low numbers of function evaluations (NFEs). Key to this\napproach is the score function reparameterisation, which reduces the\nintegration error incurred from using a fixed score function estimate over each\nintegration step. The original authors use the default parameterisation used by\nmodels trained for noise prediction -- multiply the score by the standard\ndeviation of the conditional forward noising distribution. We find that\nalthough the mean absolute value of this score parameterisation is close to\nconstant for a large portion of the reverse sampling process, it changes\nrapidly at the end of sampling. As a simple fix, we propose to instead\nreparameterise the score (at inference) by dividing it by the average absolute\nvalue of previous score estimates at that time step collected from offline high\nNFE generations. We find that our score normalisation (DEIS-SN) consistently\nimproves FID compared to vanilla DEIS, showing an improvement at 10 NFEs from\n6.44 to 5.57 on CIFAR-10 and from 5.9 to 4.95 on LSUN-Church 64x64. Our code is\navailable at https://github.com/mtkresearch/Diffusion-DEIS-SN",
            "author": [
                "Guoxuan Xia",
                "Duolikun Danier",
                "Ayan Das",
                "Stathi Fotiadis",
                "Farhang Nabiei",
                "Ushnish Sengupta",
                "Alberto Bernacchia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00157v2",
                "http://arxiv.org/pdf/2311.00157v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00154v1",
            "title": "Medi-CAT: Contrastive Adversarial Training for Medical Image\n  Classification",
            "updated": "2023-10-31T20:58:32Z",
            "published": "2023-10-31T20:58:32Z",
            "summary": "There are not many large medical image datasets available. For these\ndatasets, too small deep learning models can't learn useful features, so they\ndon't work well due to underfitting, and too big models tend to overfit the\nlimited data. As a result, there is a compromise between the two issues. This\npaper proposes a training strategy Medi-CAT to overcome the underfitting and\noverfitting phenomena in medical imaging datasets. Specifically, the proposed\ntraining methodology employs large pre-trained vision transformers to overcome\nunderfitting and adversarial and contrastive learning techniques to prevent\noverfitting. The proposed method is trained and evaluated on four medical image\nclassification datasets from the MedMNIST collection. Our experimental results\nindicate that the proposed approach improves the accuracy up to 2% on three\nbenchmark datasets compared to well-known approaches, whereas it increases the\nperformance up to 4.1% over the baseline methods.",
            "author": [
                "Pervaiz Iqbal Khan",
                "Andreas Dengel",
                "Sheraz Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00154v1",
                "http://arxiv.org/pdf/2311.00154v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00152v1",
            "title": "Developing a Tool to Automate Extensions to Support a Flexible Extension\n  Policy",
            "updated": "2023-10-31T20:55:08Z",
            "published": "2023-10-31T20:55:08Z",
            "summary": "In this work, we present the development of an automated extension tool to\nassist educators and increase the success and well-being of students by\nimplementing flexible extension policies. Flexible extension policies\nmaterialize in many ways, yet there are similarities in students' interactions\nwith them; students tend to request multi-day long extensions repeatedly. In\ncourses with hundreds or potentially thousands of students, providing a system\nto support this extension request demand is not possible given most currently\navailable resources and limited staff. As such, a tool is necessary to help\nautomate flexible extension processes. The development of this tool should\nreduce staff load while increasing individualized student support, which can be\nused in varying ways for different extension policies. Our research questions\nare: RQ1: Does the extension tool reduce barriers and stigma around asking for\nassistance? RQ2: Does the tool lessen the wait time between requesting and\nreceiving an extension, and how does the tool improve students' learning\nexperience in the course? These questions will help inform us about how an\nautomated tool for flexible extensions helps support growing course sizes and\nstudents who may not otherwise receive the support they need for their success\nand well-being in the course.",
            "author": [
                "Jordan Schwartz",
                "Madison Bohannan",
                "Jacob Yim",
                "Yuerou Tang",
                "Dana Benedicto",
                "Charisse Liu",
                "Armando Fox",
                "Lisa Yan",
                "Narges Norouzi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00152v1",
                "http://arxiv.org/pdf/2311.00152v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00144v1",
            "title": "Backdoor Threats from Compromised Foundation Models to Federated\n  Learning",
            "updated": "2023-10-31T20:39:54Z",
            "published": "2023-10-31T20:39:54Z",
            "summary": "Federated learning (FL) represents a novel paradigm to machine learning,\naddressing critical issues related to data privacy and security, yet suffering\nfrom data insufficiency and imbalance. The emergence of foundation models (FMs)\nprovides a promising solution to the problems with FL. For instance, FMs could\nserve as teacher models or good starting points for FL. However, the\nintegration of FM in FL presents a new challenge, exposing the FL systems to\npotential threats. This paper investigates the robustness of FL incorporating\nFMs by assessing their susceptibility to backdoor attacks. Contrary to classic\nbackdoor attacks against FL, the proposed attack (1) does not require the\nattacker fully involved in the FL process; (2) poses a significant risk in\npractical FL scenarios; (3) is able to evade existing robust FL frameworks/ FL\nbackdoor defenses; (4) underscores the researches on the robustness of FL\nsystems integrated with FMs. The effectiveness of the proposed attack is\ndemonstrated by extensive experiments with various well-known models and\nbenchmark datasets encompassing both text and image classification domains.",
            "author": [
                "Xi Li",
                "Songhe Wang",
                "Chen Wu",
                "Hao Zhou",
                "Jiaqi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00144v1",
                "http://arxiv.org/pdf/2311.00144v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00143v1",
            "title": "Two-Stage Classifier for Campaign Negativity Detection using Axis\n  Embeddings: A Case Study on Tweets of Political Users during 2021\n  Presidential Election in Iran",
            "updated": "2023-10-31T20:31:41Z",
            "published": "2023-10-31T20:31:41Z",
            "summary": "In elections around the world, the candidates may turn their campaigns toward\nnegativity due to the prospect of failure and time pressure. In the digital\nage, social media platforms such as Twitter are rich sources of political\ndiscourse. Therefore, despite the large amount of data that is published on\nTwitter, the automatic system for campaign negativity detection can play an\nessential role in understanding the strategy of candidates and parties in their\ncampaigns. In this paper, we propose a hybrid model for detecting campaign\nnegativity consisting of a two-stage classifier that combines the strengths of\ntwo machine learning models. Here, we have collected Persian tweets from 50\npolitical users, including candidates and government officials. Then we\nannotated 5,100 of them that were published during the year before the 2021\npresidential election in Iran. In the proposed model, first, the required\ndatasets of two classifiers based on the cosine similarity of tweet embeddings\nwith axis embeddings (which are the average of embedding in positive and\nnegative classes of tweets) from the training set (85\\%) are made, and then\nthese datasets are considered the training set of the two classifiers in the\nhybrid model. Finally, our best model (RF-RF) was able to achieve 79\\% for the\nmacro F1 score and 82\\% for the weighted F1 score. By running the best model on\nthe rest of the tweets of 50 political users that were published one year\nbefore the election and with the help of statistical models, we find that the\npublication of a tweet by a candidate has nothing to do with the negativity of\nthat tweet, and the presence of the names of political persons and political\norganizations in the tweet is directly related to its negativity.",
            "author": [
                "Fatemeh Rajabi",
                "Ali Mohades"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00143v1",
                "http://arxiv.org/pdf/2311.00143v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00140v1",
            "title": "Adaptive and non-adaptive minimax rates for weighted Laplacian-eigenmap\n  based nonparametric regression",
            "updated": "2023-10-31T20:25:36Z",
            "published": "2023-10-31T20:25:36Z",
            "summary": "We show both adaptive and non-adaptive minimax rates of convergence for a\nfamily of weighted Laplacian-Eigenmap based nonparametric regression methods,\nwhen the true regression function belongs to a Sobolev space and the sampling\ndensity is bounded from above and below. The adaptation methodology is based on\nextensions of Lepski's method and is over both the smoothness parameter\n($s\\in\\mathbb{N}_{+}$) and the norm parameter ($M>0$) determining the\nconstraints on the Sobolev space. Our results extend the non-adaptive result in\n\\cite{green2021minimax}, established for a specific normalized graph Laplacian,\nto a wide class of weighted Laplacian matrices used in practice, including the\nunnormalized Laplacian and random walk Laplacian.",
            "author": [
                "Zhaoyang Shi",
                "Krishnakumar Balasubramanian",
                "Wolfgang Polonik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00140v1",
                "http://arxiv.org/pdf/2311.00140v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00136v3",
            "title": "Neuroformer: Multimodal and Multitask Generative Pretraining for Brain\n  Data",
            "updated": "2023-11-08T19:48:12Z",
            "published": "2023-10-31T20:17:32Z",
            "summary": "State-of-the-art systems neuroscience experiments yield large-scale\nmultimodal data, and these data sets require new tools for analysis. Inspired\nby the success of large pretrained models in vision and language domains, we\nreframe the analysis of large-scale, cellular-resolution neuronal spiking data\ninto an autoregressive spatiotemporal generation problem. Neuroformer is a\nmultimodal, multitask generative pretrained transformer (GPT) model that is\nspecifically designed to handle the intricacies of data in systems\nneuroscience. It scales linearly with feature size, can process an arbitrary\nnumber of modalities, and is adaptable to downstream tasks, such as predicting\nbehavior. We first trained Neuroformer on simulated datasets, and found that it\nboth accurately predicted simulated neuronal circuit activity, and also\nintrinsically inferred the underlying neural circuit connectivity, including\ndirection. When pretrained to decode neural responses, the model predicted the\nbehavior of a mouse with only few-shot fine-tuning, suggesting that the model\nbegins learning how to do so directly from the neural representations\nthemselves, without any explicit supervision. We used an ablation study to show\nthat joint training on neuronal responses and behavior boosted performance,\nhighlighting the model's ability to associate behavioral and neural\nrepresentations in an unsupervised manner. These findings show that Neuroformer\ncan analyze neural datasets and their emergent properties, informing the\ndevelopment of models and hypotheses associated with the brain.",
            "author": [
                "Antonis Antoniades",
                "Yiyi Yu",
                "Joseph Canzano",
                "William Wang",
                "Spencer LaVere Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00136v3",
                "http://arxiv.org/pdf/2311.00136v3"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00128v2",
            "title": "On the effect of curriculum learning with developmental data for grammar\n  acquisition",
            "updated": "2023-11-03T16:42:33Z",
            "published": "2023-10-31T20:05:30Z",
            "summary": "This work explores the degree to which grammar acquisition is driven by\nlanguage `simplicity' and the source modality (speech vs. text) of data. Using\nBabyBERTa as a probe, we find that grammar acquisition is largely driven by\nexposure to speech data, and in particular through exposure to two of the\nBabyLM training corpora: AO-Childes and Open Subtitles. We arrive at this\nfinding by examining various ways of presenting input data to our model. First,\nwe assess the impact of various sequence-level complexity based curricula. We\nthen examine the impact of learning over `blocks' -- covering spans of text\nthat are balanced for the number of tokens in each of the source corpora\n(rather than number of lines). Finally, we explore curricula that vary the\ndegree to which the model is exposed to different corpora. In all cases, we\nfind that over-exposure to AO-Childes and Open Subtitles significantly drives\nperformance. We verify these findings through a comparable control dataset in\nwhich exposure to these corpora, and speech more generally, is limited by\ndesign. Our findings indicate that it is not the proportion of tokens occupied\nby high-utility data that aids acquisition, but rather the proportion of\ntraining steps assigned to such data. We hope this encourages future research\ninto the use of more developmentally plausible linguistic data (which tends to\nbe more scarce) to augment general purpose pre-training regimes.",
            "author": [
                "Mattia Opper",
                "J. Morrison",
                "N. Siddharth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00128v2",
                "http://arxiv.org/pdf/2311.00128v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00126v1",
            "title": "Stochastic Time-Optimal Trajectory Planning for Connected and Automated\n  Vehicles in Mixed-Traffic Merging Scenarios",
            "updated": "2023-10-31T19:56:39Z",
            "published": "2023-10-31T19:56:39Z",
            "summary": "Addressing safe and efficient interaction between connected and automated\nvehicles (CAVs) and human-driven vehicles in a mixed-traffic environment has\nattracted considerable attention. In this paper, we develop a framework for\nstochastic time-optimal trajectory planning for coordinating multiple CAVs in\nmixed-traffic merging scenarios. We present a data-driven model, combining\nNewell's car-following model with Bayesian linear regression, for efficiently\nlearning the driving behavior of human drivers online. Using the prediction\nmodel and uncertainty quantification, a stochastic time-optimal control problem\nis formulated to find robust trajectories for CAVs. We also integrate a\nreplanning mechanism that determines when deriving new trajectories for CAVs is\nneeded based on the accuracy of the Bayesian linear regression predictions.\nFinally, we demonstrate the performance of our proposed framework using a\nrealistic simulation environment.",
            "author": [
                "Viet-Anh Le",
                "Behdad Chalaki",
                "Filippos N. Tzortzoglou",
                "Andreas A. Malikopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00126v1",
                "http://arxiv.org/pdf/2311.00126v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00123v1",
            "title": "Q-Learning for Stochastic Control under General Information Structures\n  and Non-Markovian Environments",
            "updated": "2023-10-31T19:53:16Z",
            "published": "2023-10-31T19:53:16Z",
            "summary": "As a primary contribution, we present a convergence theorem for stochastic\niterations, and in particular, Q-learning iterates, under a general, possibly\nnon-Markovian, stochastic environment. Our conditions for convergence involve\nan ergodicity and a positivity criterion. We provide a precise characterization\non the limit of the iterates and conditions on the environment and\ninitializations for convergence. As our second contribution, we discuss the\nimplications and applications of this theorem to a variety of stochastic\ncontrol problems with non-Markovian environments involving (i) quantized\napproximations of fully observed Markov Decision Processes (MDPs) with\ncontinuous spaces (where quantization break down the Markovian structure), (ii)\nquantized approximations of belief-MDP reduced partially observable MDPS\n(POMDPs) with weak Feller continuity and a mild version of filter stability\n(which requires the knowledge of the model by the controller), (iii) finite\nwindow approximations of POMDPs under a uniform controlled filter stability\n(which does not require the knowledge of the model), and (iv) for multi-agent\nmodels where convergence of learning dynamics to a new class of equilibria,\nsubjective Q-learning equilibria, will be studied. In addition to the\nconvergence theorem, some implications of the theorem above are new to the\nliterature and others are interpreted as applications of the convergence\ntheorem. Some open problems are noted.",
            "author": [
                "Ali Devran Kara",
                "Serdar Yuksel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00123v1",
                "http://arxiv.org/pdf/2311.00123v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00118v1",
            "title": "Extracting the Multiscale Causal Backbone of Brain Dynamics",
            "updated": "2023-10-31T19:47:11Z",
            "published": "2023-10-31T19:47:11Z",
            "summary": "The bulk of the research effort on brain connectivity revolves around\nstatistical associations among brain regions, which do not directly relate to\nthe causal mechanisms governing brain dynamics. Here we propose the multiscale\ncausal backbone (MCB) of brain dynamics shared by a set of individuals across\nmultiple temporal scales, and devise a principled methodology to extract it.\n  Our approach leverages recent advances in multiscale causal structure\nlearning and optimizes the trade-off between the model fitting and its\ncomplexity. Empirical assessment on synthetic data shows the superiority of our\nmethodology over a baseline based on canonical functional connectivity\nnetworks. When applied to resting-state fMRI data, we find sparse MCBs for both\nthe left and right brain hemispheres. Thanks to its multiscale nature, our\napproach shows that at low-frequency bands, causal dynamics are driven by brain\nregions associated with high-level cognitive functions; at higher frequencies\ninstead, nodes related to sensory processing play a crucial role. Finally, our\nanalysis of individual multiscale causal structures confirms the existence of a\ncausal fingerprint of brain connectivity, thus supporting from a causal\nperspective the existing extensive research in brain connectivity\nfingerprinting.",
            "author": [
                "Gabriele D'Acunto",
                "Francesco Bonchi",
                "Gianmarco De Francisci Morales",
                "Giovanni Petri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00118v1",
                "http://arxiv.org/pdf/2311.00118v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.NC",
                "stat.AP",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00115v1",
            "title": "EXTRACT: Explainable Transparent Control of Bias in Embeddings",
            "updated": "2023-10-31T19:44:32Z",
            "published": "2023-10-31T19:44:32Z",
            "summary": "Knowledge Graphs are a widely used method to represent relations between\nentities in various AI applications, and Graph Embedding has rapidly become a\nstandard technique to represent Knowledge Graphs in such a way as to facilitate\ninferences and decisions. As this representation is obtained from behavioural\ndata, and is not in a form readable by humans, there is a concern that it might\nincorporate unintended information that could lead to biases. We propose\nEXTRACT: a suite of Explainable and Transparent methods to ConTrol bias in\nknowledge graph embeddings, so as to assess and decrease the implicit presence\nof protected information. Our method uses Canonical Correlation Analysis (CCA)\nto investigate the presence, extent and origins of information leaks during\ntraining, then decomposes embeddings into a sum of their private attributes by\nsolving a linear system. Our experiments, performed on the MovieLens1M dataset,\nshow that a range of personal attributes can be inferred from a user's viewing\nbehaviour and preferences, including gender, age, and occupation. Further\nexperiments, performed on the KG20C citation dataset, show that the information\nabout the conference in which a paper was published can be inferred from the\ncitation network of that article. We propose four transparent methods to\nmaintain the capability of the embedding to make the intended predictions\nwithout retaining unwanted information. A trade-off between these two goals is\nobserved.",
            "author": [
                "Zhijin Guo",
                "Zhaozhen Xu",
                "Martha Lewis",
                "Nello Cristianini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00115v1",
                "http://arxiv.org/pdf/2311.00115v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00109v1",
            "title": "FairWASP: Fast and Optimal Fair Wasserstein Pre-processing",
            "updated": "2023-10-31T19:36:00Z",
            "published": "2023-10-31T19:36:00Z",
            "summary": "Recent years have seen a surge of machine learning approaches aimed at\nreducing disparities in model outputs across different subgroups. In many\nsettings, training data may be used in multiple downstream applications by\ndifferent users, which means it may be most effective to intervene on the\ntraining data itself. In this work, we present FairWASP, a novel pre-processing\napproach designed to reduce disparities in classification datasets without\nmodifying the original data. FairWASP returns sample-level weights such that\nthe reweighted dataset minimizes the Wasserstein distance to the original\ndataset while satisfying (an empirical version of) demographic parity, a\npopular fairness criterion. We show theoretically that integer weights are\noptimal, which means our method can be equivalently understood as duplicating\nor eliminating samples. FairWASP can therefore be used to construct datasets\nwhich can be fed into any classification method, not just methods which accept\nsample weights. Our work is based on reformulating the pre-processing task as a\nlarge-scale mixed-integer program (MIP), for which we propose a highly\nefficient algorithm based on the cutting plane method. Experiments on synthetic\ndatasets demonstrate that our proposed optimization algorithm significantly\noutperforms state-of-the-art commercial solvers in solving both the MIP and its\nlinear program relaxation. Further experiments highlight the competitive\nperformance of FairWASP in reducing disparities while preserving accuracy in\ndownstream classification settings.",
            "author": [
                "Zikai Xiong",
                "Niccol\u00f2 Dalmasso",
                "Alan Mishler",
                "Vamsi K. Potluru",
                "Tucker Balch",
                "Manuela Veloso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00109v1",
                "http://arxiv.org/pdf/2311.00109v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00108v1",
            "title": "Stellar spectral-type (mass) dependence of the dearth of close-in\n  planets around fast-rotating stars. Architecture of Kepler confirmed\n  single-exoplanet systems compared to star-planet evolution models",
            "updated": "2023-10-31T19:34:56Z",
            "published": "2023-10-31T19:34:56Z",
            "summary": "In 2013 a dearth of close-in planets around fast-rotating host stars was\nfound using statistical tests on Kepler data. The addition of more Kepler and\nTransiting Exoplanet Survey Satellite (TESS) systems in 2022 filled this region\nof the diagram of stellar rotation period (Prot) versus the planet orbital\nperiod (Porb). We revisited the Prot extraction of Kepler planet-host stars, we\nclassify the stars by their spectral type, and we studied their Prot-Porb\nrelations. We only used confirmed exoplanet systems to minimize biases. In\norder to learn about the physical processes at work, we used the star-planet\nevolution code ESPEM (French acronym for Evolution of Planetary Systems and\nMagnetism) to compute a realistic population synthesis of exoplanet systems and\ncompared them with observations. Because ESPEM works with a single planet\norbiting around a single main-sequence star, we limit our study to this\npopulation of Kepler observed systems filtering out binaries, evolved stars,\nand multi-planets. We find in both, observations and simulations, the existence\nof a dearth in close-in planets orbiting around fast-rotating stars, with a\ndependence on the stellar spectral type (F, G, and K), which is a proxy of the\nmass in our sample of stars. There is a change in the edge of the dearth as a\nfunction of the spectral type (and mass). It moves towards shorter Prot as\ntemperature (and mass) increases, making the dearth look smaller. Realistic\nformation hypotheses included in the model and the proper treatment of tidal\nand magnetic migration are enough to qualitatively explain the dearth of hot\nplanets around fast-rotating stars and the uncovered trend with spectral type.",
            "author": [
                "R. A. Garc\u00eda",
                "C. Gourv\u00e8s",
                "A. R. G. Santos",
                "A. Strugarek",
                "D. Godoy-Rivera",
                "S. Mathur",
                "V. Delsanti",
                "S. N. Breton",
                "P. G. Beck",
                "A. S. Brun",
                "S. Mathis"
            ],
            "link": [
                "http://dx.doi.org/10.1051/0004-6361/202346933",
                "http://arxiv.org/abs/2311.00108v1",
                "http://arxiv.org/pdf/2311.00108v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00107v1",
            "title": "Deep Compressed Learning for 3D Seismic Inversion",
            "updated": "2023-10-31T19:34:26Z",
            "published": "2023-10-31T19:34:26Z",
            "summary": "We consider the problem of 3D seismic inversion from pre-stack data using a\nvery small number of seismic sources. The proposed solution is based on a\ncombination of compressed-sensing and machine learning frameworks, known as\ncompressed-learning. The solution jointly optimizes a dimensionality reduction\noperator and a 3D inversion encoder-decoder implemented by a deep convolutional\nneural network (DCNN). Dimensionality reduction is achieved by learning a\nsparse binary sensing layer that selects a small subset of the available\nsources, then the selected data is fed to a DCNN to complete the regression\ntask. The end-to-end learning process provides a reduction by an\norder-of-magnitude in the number of seismic records used during training, while\npreserving the 3D reconstruction quality comparable to that obtained by using\nthe entire dataset.",
            "author": [
                "Maayan Gelboim",
                "Amir Adler",
                "Yen Sun",
                "Mauricio Araya-Polo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00107v1",
                "http://arxiv.org/pdf/2311.00107v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.05638v1",
            "title": "Towards Instance-Optimality in Online PAC Reinforcement Learning",
            "updated": "2023-10-31T19:26:36Z",
            "published": "2023-10-31T19:26:36Z",
            "summary": "Several recent works have proposed instance-dependent upper bounds on the\nnumber of episodes needed to identify, with probability $1-\\delta$, an\n$\\varepsilon$-optimal policy in finite-horizon tabular Markov Decision\nProcesses (MDPs). These upper bounds feature various complexity measures for\nthe MDP, which are defined based on different notions of sub-optimality gaps.\nHowever, as of now, no lower bound has been established to assess the\noptimality of any of these complexity measures, except for the special case of\nMDPs with deterministic transitions. In this paper, we propose the first\ninstance-dependent lower bound on the sample complexity required for the PAC\nidentification of a near-optimal policy in any tabular episodic MDP.\nAdditionally, we demonstrate that the sample complexity of the PEDEL algorithm\nof \\cite{Wagenmaker22linearMDP} closely approaches this lower bound.\nConsidering the intractability of PEDEL, we formulate an open question\nregarding the possibility of achieving our lower bound using a\ncomputationally-efficient algorithm.",
            "author": [
                "Aymen Al-Marjani",
                "Andrea Tirinzoni",
                "Emilie Kaufmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05638v1",
                "http://arxiv.org/pdf/2311.05638v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00096v1",
            "title": "Bandit-Driven Batch Selection for Robust Learning under Label Noise",
            "updated": "2023-10-31T19:19:01Z",
            "published": "2023-10-31T19:19:01Z",
            "summary": "We introduce a novel approach for batch selection in Stochastic Gradient\nDescent (SGD) training, leveraging combinatorial bandit algorithms. Our\nmethodology focuses on optimizing the learning process in the presence of label\nnoise, a prevalent issue in real-world datasets. Experimental evaluations on\nthe CIFAR-10 dataset reveal that our approach consistently outperforms existing\nmethods across various levels of label corruption. Importantly, we achieve this\nsuperior performance without incurring the computational overhead commonly\nassociated with auxiliary neural network models. This work presents a balanced\ntrade-off between computational efficiency and model efficacy, offering a\nscalable solution for complex machine learning applications.",
            "author": [
                "Michal Lisicki",
                "Mihai Nica",
                "Graham W. Taylor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00096v1",
                "http://arxiv.org/pdf/2311.00096v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00094v1",
            "title": "Expressive Modeling Is Insufficient for Offline RL: A Tractable\n  Inference Perspective",
            "updated": "2023-10-31T19:16:07Z",
            "published": "2023-10-31T19:16:07Z",
            "summary": "A popular paradigm for offline Reinforcement Learning (RL) tasks is to first\nfit the offline trajectories to a sequence model, and then prompt the model for\nactions that lead to high expected return. While a common consensus is that\nmore expressive sequence models imply better performance, this paper highlights\nthat tractability, the ability to exactly and efficiently answer various\nprobabilistic queries, plays an equally important role. Specifically, due to\nthe fundamental stochasticity from the offline data-collection policies and the\nenvironment dynamics, highly non-trivial conditional/constrained generation is\nrequired to elicit rewarding actions. While it is still possible to approximate\nsuch queries, we observe that such crude estimates significantly undermine the\nbenefits brought by expressive sequence models. To overcome this problem, this\npaper proposes Trifle (Tractable Inference for Offline RL), which leverages\nmodern Tractable Probabilistic Models (TPMs) to bridge the gap between good\nsequence models and high expected returns at evaluation time. Empirically,\nTrifle achieves the most state-of-the-art scores in 9 Gym-MuJoCo benchmarks\nagainst strong baselines. Further, owing to its tractability, Trifle\nsignificantly outperforms prior approaches in stochastic environments and safe\nRL tasks (e.g. with action constraints) with minimum algorithmic modifications.",
            "author": [
                "Xuejie Liu",
                "Anji Liu",
                "Guy Van den Broeck",
                "Yitao Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00094v1",
                "http://arxiv.org/pdf/2311.00094v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00089v1",
            "title": "Fast, multicolour optical sectioning over extended fields of view by\n  combining interferometric SIM with machine learning",
            "updated": "2023-10-31T18:56:30Z",
            "published": "2023-10-31T18:56:30Z",
            "summary": "Structured illumination can reject out-of-focus signal from a sample,\nenabling high-speed and high-contrast imaging over large areas with widefield\ndetection optics. Currently, this optical-sectioning technique is limited by\nimage reconstruction artefacts and the need for sequential imaging of multiple\ncolour channels. We combine multicolour interferometric pattern generation with\nmachine-learning processing, permitting high-contrast, real-time reconstruction\nof image data. The method is insensitive to background noise and unevenly\nphase-stepped illumination patterns. We validate the method in silico and\ndemonstrate its application on diverse specimens, ranging from fixed and live\nbiological cells to synthetic biosystems, imaging at up to 37 Hz across a 44 x\n44 $\\mu m^2$ field of view.",
            "author": [
                "Edward N. Ward",
                "Rebecca M. McClelland",
                "Jacob R. Lamb",
                "Roger Rubio-S\u00e1nchez",
                "Charles N. Christensen",
                "Bismoy Mazumder",
                "Sofia Kapsiani",
                "Luca Mascheroni",
                "Lorenzo Di Michele",
                "Gabriele S. Kaminski Schierle",
                "Clemens F. Kaminski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00089v1",
                "http://arxiv.org/pdf/2311.00089v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "eess.IV",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00088v1",
            "title": "Random coordinate descent: a simple alternative for optimizing\n  parameterized quantum circuits",
            "updated": "2023-10-31T18:55:45Z",
            "published": "2023-10-31T18:55:45Z",
            "summary": "Variational quantum algorithms rely on the optimization of parameterized\nquantum circuits in noisy settings. The commonly used back-propagation\nprocedure in classical machine learning is not directly applicable in this\nsetting due to the collapse of quantum states after measurements. Thus,\ngradient estimations constitute a significant overhead in a gradient-based\noptimization of such quantum circuits. This paper introduces a random\ncoordinate descent algorithm as a practical and easy-to-implement alternative\nto the full gradient descent algorithm. This algorithm only requires one\npartial derivative at each iteration. Motivated by the behavior of measurement\nnoise in the practical optimization of parameterized quantum circuits, this\npaper presents an optimization problem setting that is amenable to analysis.\nUnder this setting, the random coordinate descent algorithm exhibits the same\nlevel of stochastic stability as the full gradient approach, making it as\nresilient to noise. The complexity of the random coordinate descent method is\ngenerally no worse than that of the gradient descent and can be much better for\nvarious quantum optimization problems with anisotropic Lipschitz constants.\nTheoretical analysis and extensive numerical experiments validate our findings.",
            "author": [
                "Zhiyan Ding",
                "Taehee Ko",
                "Jiahao Yao",
                "Lin Lin",
                "Xiantao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00088v1",
                "http://arxiv.org/pdf/2311.00088v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00087v1",
            "title": "Seeking Truth and Beauty in Flavor Physics with Machine Learning",
            "updated": "2023-10-31T18:53:22Z",
            "published": "2023-10-31T18:53:22Z",
            "summary": "The discovery process of building new theoretical physics models involves the\ndual aspect of both fitting to the existing experimental data and satisfying\nabstract theorists' criteria like beauty, naturalness, etc. We design loss\nfunctions for performing both of those tasks with machine learning techniques.\nWe use the Yukawa quark sector as a toy example to demonstrate that the\noptimization of these loss functions results in true and beautiful models.",
            "author": [
                "Konstantin T. Matchev",
                "Katia Matcheva",
                "Pierre Ramond",
                "Sarunas Verner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00087v1",
                "http://arxiv.org/pdf/2311.00087v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "cs.LG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00084v1",
            "title": "NoMoPy: Noise Modeling in Python",
            "updated": "2023-10-31T18:52:05Z",
            "published": "2023-10-31T18:52:05Z",
            "summary": "NoMoPy is a code for fitting, analyzing, and generating noise modeled as a\nhidden Markov model (HMM) or, more generally, factorial hidden Markov model\n(FHMM). This code, written in Python, implements approximate and exact\nexpectation maximization (EM) algorithms for performing the parameter\nestimation process, model selection procedures via cross-validation, and\nparameter confidence region estimation. Here, we describe in detail the\nfunctionality implemented in NoMoPy and provide examples of its use and\nperformance on example problems.",
            "author": [
                "Dylan Albrecht",
                "N. Tobias Jacobson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00084v1",
                "http://arxiv.org/pdf/2311.00084v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "cs.CE",
                "cs.MS",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00079v1",
            "title": "Spuriosity Rankings for Free: A Simple Framework for Last Layer\n  Retraining Based on Object Detection",
            "updated": "2023-10-31T18:44:03Z",
            "published": "2023-10-31T18:44:03Z",
            "summary": "Deep neural networks have exhibited remarkable performance in various\ndomains. However, the reliance of these models on spurious features has raised\nconcerns about their reliability. A promising solution to this problem is\nlast-layer retraining, which involves retraining the linear classifier head on\na small subset of data without spurious cues. Nevertheless, selecting this\nsubset requires human supervision, which reduces its scalability. Moreover,\nspurious cues may still exist in the selected subset. As a solution to this\nproblem, we propose a novel ranking framework that leverages an open vocabulary\nobject detection technique to identify images without spurious cues. More\nspecifically, we use the object detector as a measure to score the presence of\nthe target object in the images. Next, the images are sorted based on this\nscore, and the last-layer of the model is retrained on a subset of the data\nwith the highest scores. Our experiments on the ImageNet-1k dataset demonstrate\nthe effectiveness of this ranking framework in sorting images based on\nspuriousness and using them for last-layer retraining.",
            "author": [
                "Mohammad Azizmalayeri",
                "Reza Abbasi",
                "Amir Hosein Haji Mohammad rezaie",
                "Reihaneh Zohrabi",
                "Mahdi Amiri",
                "Mohammad Taghi Manzuri",
                "Mohammad Hossein Rohban"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00079v1",
                "http://arxiv.org/pdf/2311.00079v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00073v1",
            "title": "YOLOv8-Based Visual Detection of Road Hazards: Potholes, Sewer Covers,\n  and Manholes",
            "updated": "2023-10-31T18:33:26Z",
            "published": "2023-10-31T18:33:26Z",
            "summary": "Effective detection of road hazards plays a pivotal role in road\ninfrastructure maintenance and ensuring road safety. This research paper\nprovides a comprehensive evaluation of YOLOv8, an object detection model, in\nthe context of detecting road hazards such as potholes, Sewer Covers, and Man\nHoles. A comparative analysis with previous iterations, YOLOv5 and YOLOv7, is\nconducted, emphasizing the importance of computational efficiency in various\napplications. The paper delves into the architecture of YOLOv8 and explores\nimage preprocessing techniques aimed at enhancing detection accuracy across\ndiverse conditions, including variations in lighting, road types, hazard sizes,\nand types. Furthermore, hyperparameter tuning experiments are performed to\noptimize model performance through adjustments in learning rates, batch sizes,\nanchor box sizes, and augmentation strategies. Model evaluation is based on\nMean Average Precision (mAP), a widely accepted metric for object detection\nperformance. The research assesses the robustness and generalization\ncapabilities of the models through mAP scores calculated across the diverse\ntest scenarios, underlining the significance of YOLOv8 in road hazard detection\nand infrastructure maintenance.",
            "author": [
                "Om M. Khare",
                "Shubham Gandhi",
                "Aditya M. Rahalkar",
                "Sunil Mane"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00073v1",
                "http://arxiv.org/pdf/2311.00073v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10747v2",
            "title": "Safety-aware Causal Representation for Trustworthy Reinforcement\n  Learning in Autonomous Driving",
            "updated": "2023-11-21T21:40:21Z",
            "published": "2023-10-31T18:21:24Z",
            "summary": "In the domain of autonomous driving, the Learning from Demonstration (LfD)\nparadigm has exhibited notable efficacy in addressing sequential\ndecision-making problems. However, consistently achieving safety in varying\ntraffic contexts, especially in safety-critical scenarios, poses a significant\nchallenge due to the long-tailed and unforeseen scenarios absent from offline\ndatasets. In this paper, we introduce the saFety-aware strUctured Scenario\nrepresentatION (FUSION), a pioneering methodology conceived to facilitate the\nlearning of an adaptive end-to-end driving policy by leveraging structured\nscenario information. FUSION capitalizes on the causal relationships between\ndecomposed reward, cost, state, and action space, constructing a framework for\nstructured sequential reasoning under dynamic traffic environments. We conduct\nrigorous evaluations in two typical real-world settings of distribution shift\nin autonomous vehicles, demonstrating the good balance between safety cost and\nutility reward of FUSION compared to contemporary state-of-the-art safety-aware\nLfD baselines. Empirical evidence under diverse driving scenarios attests that\nFUSION significantly enhances the safety and generalizability of autonomous\ndriving agents, even in the face of challenging and unseen environments.\nFurthermore, our ablation studies reveal noticeable improvements in the\nintegration of causal representation into the safe offline RL problem.",
            "author": [
                "Haohong Lin",
                "Wenhao Ding",
                "Zuxin Liu",
                "Yaru Niu",
                "Jiacheng Zhu",
                "Yuming Niu",
                "Ding Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10747v2",
                "http://arxiv.org/pdf/2311.10747v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14677v1",
            "title": "Filter bubbles and affective polarization in user-personalized large\n  language model outputs",
            "updated": "2023-10-31T18:19:28Z",
            "published": "2023-10-31T18:19:28Z",
            "summary": "Echoing the history of search engines and social media content rankings, the\nadvent of large language models (LLMs) has led to a push for increased\npersonalization of model outputs to individual users. In the past, personalized\nrecommendations and ranking systems have been linked to the development of\nfilter bubbles (serving content that may confirm a user's existing biases) and\naffective polarization (strong negative sentiment towards those with differing\nviews). In this work, we explore how prompting a leading large language model,\nChatGPT-3.5, with a user's political affiliation prior to asking factual\nquestions about public figures and organizations leads to differing results. We\nobserve that left-leaning users tend to receive more positive statements about\nleft-leaning political figures and media outlets, while right-leaning users see\nmore positive statements about right-leaning entities. This pattern holds\nacross presidential candidates, members of the U.S. Senate, and media\norganizations with ratings from AllSides. When qualitatively evaluating some of\nthese outputs, there is evidence that particular facts are included or excluded\nbased on the user's political affiliation. These results illustrate that\npersonalizing LLMs based on user demographics carry the same risks of affective\npolarization and filter bubbles that have been seen in other personalized\ninternet technologies. This ``failure mode\" should be monitored closely as\nthere are more attempts to monetize and personalize these models.",
            "author": [
                "Tomo Lazovich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14677v1",
                "http://arxiv.org/pdf/2311.14677v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00068v1",
            "title": "View Classification and Object Detection in Cardiac Ultrasound to\n  Localize Valves via Deep Learning",
            "updated": "2023-10-31T18:16:02Z",
            "published": "2023-10-31T18:16:02Z",
            "summary": "Echocardiography provides an important tool for clinicians to observe the\nfunction of the heart in real time, at low cost, and without harmful radiation.\nAutomated localization and classification of heart valves enables automatic\nextraction of quantities associated with heart mechanical function and related\nblood flow measurements. We propose a machine learning pipeline that uses deep\nneural networks for separate classification and localization steps. As the\nfirst step in the pipeline, we apply view classification to echocardiograms\nwith ten unique anatomic views of the heart. In the second step, we apply deep\nlearning-based object detection to both localize and identify the valves. Image\nsegmentation based object detection in echocardiography has been shown in many\nearlier studies but, to the best of our knowledge, this is the first study that\npredicts the bounding boxes around the valves along with classification from 2D\nultrasound images with the help of deep neural networks. Our object detection\nexperiments applied to the Apical views suggest that it is possible to localize\nand identify multiple valves precisely.",
            "author": [
                "Derya Gol Gungor",
                "Bimba Rao",
                "Cynthia Wolverton",
                "Ismayil Guracar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00068v1",
                "http://arxiv.org/pdf/2311.00068v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00063v1",
            "title": "Safe multi-agent motion planning under uncertainty for drones using\n  filtered reinforcement learning",
            "updated": "2023-10-31T18:09:26Z",
            "published": "2023-10-31T18:09:26Z",
            "summary": "We consider the problem of safe multi-agent motion planning for drones in\nuncertain, cluttered workspaces. For this problem, we present a tractable\nmotion planner that builds upon the strengths of reinforcement learning and\nconstrained-control-based trajectory planning. First, we use single-agent\nreinforcement learning to learn motion plans from data that reach the target\nbut may not be collision-free. Next, we use a convex optimization, chance\nconstraints, and set-based methods for constrained control to ensure safety,\ndespite the uncertainty in the workspace, agent motion, and sensing. The\nproposed approach can handle state and control constraints on the agents, and\nenforce collision avoidance among themselves and with static obstacles in the\nworkspace with high probability. The proposed approach yields a safe, real-time\nimplementable, multi-agent motion planner that is simpler to train than methods\nbased solely on learning. Numerical simulations and experiments show the\nefficacy of the approach.",
            "author": [
                "Sleiman Safaoui",
                "Abraham P. Vinod",
                "Ankush Chakrabarty",
                "Rien Quirynen",
                "Nobuyuki Yoshikawa",
                "Stefano Di Cairano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00063v1",
                "http://arxiv.org/pdf/2311.00063v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG",
                "cs.MA",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00060v2",
            "title": "Ensemble models outperform single model uncertainties and predictions\n  for operator-learning of hypersonic flows",
            "updated": "2023-11-03T13:43:28Z",
            "published": "2023-10-31T18:07:29Z",
            "summary": "High-fidelity computational simulations and physical experiments of\nhypersonic flows are resource intensive. Training scientific machine learning\n(SciML) models on limited high-fidelity data offers one approach to rapidly\npredict behaviors for situations that have not been seen before. However,\nhigh-fidelity data is itself in limited quantity to validate all outputs of the\nSciML model in unexplored input space. As such, an uncertainty-aware SciML\nmodel is desired. The SciML model's output uncertainties could then be used to\nassess the reliability and confidence of the model's predictions. In this\nstudy, we extend a DeepONet using three different uncertainty quantification\nmechanisms: mean-variance estimation, evidential uncertainty, and ensembling.\nThe uncertainty aware DeepONet models are trained and evaluated on the\nhypersonic flow around a blunt cone object with data generated via\ncomputational fluid dynamics over a wide range of Mach numbers and altitudes.\nWe find that ensembling outperforms the other two uncertainty models in terms\nof minimizing error and calibrating uncertainty in both interpolative and\nextrapolative regimes.",
            "author": [
                "Victor J. Leon",
                "Noah Ford",
                "Honest Mrema",
                "Jeffrey Gilbert",
                "Alexander New"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00060v2",
                "http://arxiv.org/pdf/2311.00060v2"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00059v1",
            "title": "The Generative AI Paradox: \"What It Can Create, It May Not Understand\"",
            "updated": "2023-10-31T18:07:07Z",
            "published": "2023-10-31T18:07:07Z",
            "summary": "The recent wave of generative AI has sparked unprecedented global attention,\nwith both excitement and concern over potentially superhuman levels of\nartificial intelligence: models now take only seconds to produce outputs that\nwould challenge or exceed the capabilities even of expert humans. At the same\ntime, models still show basic errors in understanding that would not be\nexpected even in non-expert humans. This presents us with an apparent paradox:\nhow do we reconcile seemingly superhuman capabilities with the persistence of\nerrors that few humans would make? In this work, we posit that this tension\nreflects a divergence in the configuration of intelligence in today's\ngenerative models relative to intelligence in humans. Specifically, we propose\nand test the Generative AI Paradox hypothesis: generative models, having been\ntrained directly to reproduce expert-like outputs, acquire generative\ncapabilities that are not contingent upon -- and can therefore exceed -- their\nability to understand those same types of outputs. This contrasts with humans,\nfor whom basic understanding almost always precedes the ability to generate\nexpert-level outputs. We test this hypothesis through controlled experiments\nanalyzing generation vs. understanding in generative models, across both\nlanguage and image modalities. Our results show that although models can\noutperform humans in generation, they consistently fall short of human\ncapabilities in measures of understanding, as well as weaker correlation\nbetween generation and understanding performance, and more brittleness to\nadversarial inputs. Our findings support the hypothesis that models' generative\ncapability may not be contingent upon understanding capability, and call for\ncaution in interpreting artificial intelligence by analogy to human\nintelligence.",
            "author": [
                "Peter West",
                "Ximing Lu",
                "Nouha Dziri",
                "Faeze Brahman",
                "Linjie Li",
                "Jena D. Hwang",
                "Liwei Jiang",
                "Jillian Fisher",
                "Abhilasha Ravichander",
                "Khyathi Chandu",
                "Benjamin Newman",
                "Pang Wei Koh",
                "Allyson Ettinger",
                "Yejin Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00059v1",
                "http://arxiv.org/pdf/2311.00059v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00058v1",
            "title": "Observing quantum measurement collapse as a learnability phase\n  transition",
            "updated": "2023-10-31T18:06:05Z",
            "published": "2023-10-31T18:06:05Z",
            "summary": "The mechanism by which an effective macroscopic description of quantum\nmeasurement in terms of discrete, probabilistic collapse events emerges from\nthe reversible microscopic dynamics remains an enduring open question. Emerging\nquantum computers offer a promising platform to explore how measurement\nprocesses evolve across a range of system sizes while retaining coherence.\nHere, we report the experimental observation of evidence for an\nobservable-sharpening measurement-induced phase transition in a chain of\ntrapped ions in Quantinuum H1-1 system model quantum processor. This transition\nmanifests as a sharp, concomitant change in both the quantum uncertainty of an\nobservable and the amount of information an observer can (in principle) learn\nfrom the measurement record, upon increasing the strength of measurements. We\nleverage insights from statistical mechanical models and machine learning to\ndesign efficiently-computable algorithms to observe this transition (without\nnon-scalable post-selection on measurement outcomes) and to mitigate the\neffects on errors in noisy hardware.",
            "author": [
                "Utkarsh Agrawal",
                "Javier Lopez-Piqueres",
                "Romain Vasseur",
                "Sarang Gopalakrishnan",
                "Andrew C. Potter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00058v1",
                "http://arxiv.org/pdf/2311.00058v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00056v1",
            "title": "Diversity and Diffusion: Observations on Synthetic Image Distributions\n  with Stable Diffusion",
            "updated": "2023-10-31T18:05:15Z",
            "published": "2023-10-31T18:05:15Z",
            "summary": "Recent progress in text-to-image (TTI) systems, such as StableDiffusion,\nImagen, and DALL-E 2, have made it possible to create realistic images with\nsimple text prompts. It is tempting to use these systems to eliminate the\nmanual task of obtaining natural images for training a new machine learning\nclassifier. However, in all of the experiments performed to date, classifiers\ntrained solely with synthetic images perform poorly at inference, despite the\nimages used for training appearing realistic. Examining this apparent\nincongruity in detail gives insight into the limitations of the underlying\nimage generation processes. Through the lens of diversity in image creation\nvs.accuracy of what is created, we dissect the differences in semantic\nmismatches in what is modeled in synthetic vs. natural images. This will\nelucidate the roles of the image-languag emodel, CLIP, and the image generation\nmodel, diffusion. We find four issues that limit the usefulness of TTI systems\nfor this task: ambiguity, adherence to prompt, lack of diversity, and inability\nto represent the underlying concept. We further present surprising insights\ninto the geometry of CLIP embeddings.",
            "author": [
                "David Marwood",
                "Shumeet Baluja",
                "Yair Alon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00056v1",
                "http://arxiv.org/pdf/2311.00056v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00055v1",
            "title": "Training-Free Generalization on Heterogeneous Tabular Data via\n  Meta-Representation",
            "updated": "2023-10-31T18:03:54Z",
            "published": "2023-10-31T18:03:54Z",
            "summary": "Tabular data is prevalent across various machine learning domains. Yet, the\ninherent heterogeneities in attribute and class spaces across different tabular\ndatasets hinder the effective sharing of knowledge, limiting a tabular model to\nbenefit from other datasets. In this paper, we propose Tabular data\nPre-Training via Meta-representation (TabPTM), which allows one tabular model\npre-training on a set of heterogeneous datasets. Then, this pre-trained model\ncan be directly applied to unseen datasets that have diverse attributes and\nclasses without additional training. Specifically, TabPTM represents an\ninstance through its distance to a fixed number of prototypes, thereby\nstandardizing heterogeneous tabular datasets. A deep neural network is then\ntrained to associate these meta-representations with dataset-specific\nclassification confidences, endowing TabPTM with the ability of training-free\ngeneralization. Experiments validate that TabPTM achieves promising performance\nin new datasets, even under few-shot scenarios.",
            "author": [
                "Han-Jia Ye",
                "Qi-Le Zhou",
                "De-Chuan Zhan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00055v1",
                "http://arxiv.org/pdf/2311.00055v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00049v1",
            "title": "On the Kolmogorov neural networks",
            "updated": "2023-10-31T18:01:58Z",
            "published": "2023-10-31T18:01:58Z",
            "summary": "In this paper, we show that the Kolmogorov two hidden layer neural network\nmodel with a continuous, discontinuous bounded or unbounded activation function\nin the second hidden layer can precisely represent continuous, discontinuous\nbounded and all unbounded multivariate functions, respectively.",
            "author": [
                "Aysu Ismayilova",
                "Vugar Ismailov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00049v1",
                "http://arxiv.org/pdf/2311.00049v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG",
                "math.FA",
                "stat.ML",
                "46A22, 46E10, 46N60, 68T05, 92B20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00048v1",
            "title": "SC-MIL: Sparsely Coded Multiple Instance Learning for Whole Slide Image\n  Classification",
            "updated": "2023-10-31T18:01:41Z",
            "published": "2023-10-31T18:01:41Z",
            "summary": "Multiple Instance Learning (MIL) has been widely used in weakly supervised\nwhole slide image (WSI) classification. Typical MIL methods include a feature\nembedding part that embeds the instances into features via a pre-trained\nfeature extractor and the MIL aggregator that combines instance embeddings into\npredictions. The current focus has been directed toward improving these parts\nby refining the feature embeddings through self-supervised pre-training and\nmodeling the correlations between instances separately. In this paper, we\nproposed a sparsely coded MIL (SC-MIL) that addresses those two aspects at the\nsame time by leveraging sparse dictionary learning. The sparse dictionary\nlearning captures the similarities of instances by expressing them as a sparse\nlinear combination of atoms in an over-complete dictionary. In addition,\nimposing sparsity help enhance the instance feature embeddings by suppressing\nirrelevant instances while retaining the most relevant ones. To make the\nconventional sparse coding algorithm compatible with deep learning, we unrolled\nit into an SC module by leveraging deep unrolling. The proposed SC module can\nbe incorporated into any existing MIL framework in a plug-and-play manner with\nan acceptable computation cost. The experimental results on multiple datasets\ndemonstrated that the proposed SC module could substantially boost the\nperformance of state-of-the-art MIL methods. The codes are available at\n\\href{https://github.com/sotiraslab/SCMIL.git}{https://github.com/sotiraslab/SCMIL.git}.",
            "author": [
                "Peijie Qiu",
                "Pan Xiao",
                "Wenhui Zhu",
                "Yalin Wang",
                "Aristeidis Sotiras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00048v1",
                "http://arxiv.org/pdf/2311.00048v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00047v1",
            "title": "Grounding Visual Illusions in Language: Do Vision-Language Models\n  Perceive Illusions Like Humans?",
            "updated": "2023-10-31T18:01:11Z",
            "published": "2023-10-31T18:01:11Z",
            "summary": "Vision-Language Models (VLMs) are trained on vast amounts of data captured by\nhumans emulating our understanding of the world. However, known as visual\nillusions, human's perception of reality isn't always faithful to the physical\nworld. This raises a key question: do VLMs have the similar kind of illusions\nas humans do, or do they faithfully learn to represent reality? To investigate\nthis question, we build a dataset containing five types of visual illusions and\nformulate four tasks to examine visual illusions in state-of-the-art VLMs. Our\nfindings have shown that although the overall alignment is low, larger models\nare closer to human perception and more susceptible to visual illusions. Our\ndataset and initial findings will promote a better understanding of visual\nillusions in humans and machines and provide a stepping stone for future\ncomputational models that can better align humans and machines in perceiving\nand communicating about the shared visual world. The code and data are\navailable at https://github.com/vl-illusion/dataset.",
            "author": [
                "Yichi Zhang",
                "Jiayi Pan",
                "Yuchen Zhou",
                "Rui Pan",
                "Joyce Chai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00047v1",
                "http://arxiv.org/pdf/2311.00047v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00045v1",
            "title": "Bayesian real-time classification of multi-messenger electromagnetic and\n  gravitational-wave observations",
            "updated": "2023-10-31T18:00:29Z",
            "published": "2023-10-31T18:00:29Z",
            "summary": "Because of the electromagnetic radiation produced during the merger, compact\nbinary coalescences with neutron stars may result in multi-messenger\nobservations. In order to follow up on the gravitational-wave signal with\nelectromagnetic telescopes, it is critical to promptly identify the properties\nof these sources. This identification must rely on the properties of the\nprogenitor source, such as the component masses and spins, as determined by\nlow-latency detection pipelines in real time. The output of these pipelines,\nhowever, might be biased, which could decrease the accuracy of parameter\nrecovery. Machine learning algorithms are used to correct this bias. In this\nwork, we revisit this problem and discuss two new implementations of supervised\nmachine learning algorithms, K-Nearest Neighbors and Random Forest, which are\nable to predict the presence of a neutron star and post-merger matter remnant\nin low-latency compact binary coalescence searches across different search\npipelines and data sets. Additionally, we present a novel approach for\ncalculating the Bayesian probabilities for these two metrics. Instead of metric\nscores derived from binary machine learning classifiers, our scheme is designed\nto provide the astronomy community well-defined probabilities. This would\ndeliver a more direct and easily interpretable product to assist\nelectromagnetic telescopes in deciding whether to follow up on\ngravitational-wave events in real time.",
            "author": [
                "Marina Berbel",
                "Miquel Miravet-Ten\u00e9s",
                "Sushant Sharma Chaudhary",
                "Simone Albanesi",
                "Marco Cavagli\u00e0",
                "Lorena Maga\u00f1a Zertuche",
                "Dimitra Tseneklidou",
                "Yanyan Zheng",
                "Michael W. Coughlin",
                "Andrew Toivonen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00045v1",
                "http://arxiv.org/pdf/2311.00045v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20708v1",
            "title": "Unexpected Improvements to Expected Improvement for Bayesian\n  Optimization",
            "updated": "2023-10-31T17:59:56Z",
            "published": "2023-10-31T17:59:56Z",
            "summary": "Expected Improvement (EI) is arguably the most popular acquisition function\nin Bayesian optimization and has found countless successful applications, but\nits performance is often exceeded by that of more recent methods. Notably, EI\nand its variants, including for the parallel and multi-objective settings, are\nchallenging to optimize because their acquisition values vanish numerically in\nmany regions. This difficulty generally increases as the number of\nobservations, dimensionality of the search space, or the number of constraints\ngrow, resulting in performance that is inconsistent across the literature and\nmost often sub-optimal. Herein, we propose LogEI, a new family of acquisition\nfunctions whose members either have identical or approximately equal optima as\ntheir canonical counterparts, but are substantially easier to optimize\nnumerically. We demonstrate that numerical pathologies manifest themselves in\n\"classic\" analytic EI, Expected Hypervolume Improvement (EHVI), as well as\ntheir constrained, noisy, and parallel variants, and propose corresponding\nreformulations that remedy these pathologies. Our empirical results show that\nmembers of the LogEI family of acquisition functions substantially improve on\nthe optimization performance of their canonical counterparts and surprisingly,\nare on par with or exceed the performance of recent state-of-the-art\nacquisition functions, highlighting the understated role of numerical\noptimization in the literature.",
            "author": [
                "Sebastian Ament",
                "Samuel Daulton",
                "David Eriksson",
                "Maximilian Balandat",
                "Eytan Bakshy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20708v1",
                "http://arxiv.org/pdf/2310.20708v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20707v1",
            "title": "What's In My Big Data?",
            "updated": "2023-10-31T17:59:38Z",
            "published": "2023-10-31T17:59:38Z",
            "summary": "Large text corpora are the backbone of language models. However, we have a\nlimited understanding of the content of these corpora, including general\nstatistics, quality, social factors, and inclusion of evaluation data\n(contamination). In this work, we propose What's In My Big Data? (WIMBD), a\nplatform and a set of sixteen analyses that allow us to reveal and compare the\ncontents of large text corpora. WIMBD builds on two basic capabilities -- count\nand search -- at scale, which allows us to analyze more than 35 terabytes on a\nstandard compute node. We apply WIMBD to ten different corpora used to train\npopular language models, including C4, The Pile, and RedPajama. Our analysis\nuncovers several surprising and previously undocumented findings about these\ncorpora, including the high prevalence of duplicate, synthetic, and low-quality\ncontent, personally identifiable information, toxic language, and benchmark\ncontamination. For instance, we find that about 50% of the documents in\nRedPajama and LAION-2B-en are duplicates. In addition, several datasets used\nfor benchmarking models trained on such corpora are contaminated with respect\nto important benchmarks, including the Winograd Schema Challenge and parts of\nGLUE and SuperGLUE. We open-source WIMBD's code and artifacts to provide a\nstandard set of evaluations for new text-based corpora and to encourage more\nanalyses and transparency around them: github.com/allenai/wimbd.",
            "author": [
                "Yanai Elazar",
                "Akshita Bhagia",
                "Ian Magnusson",
                "Abhilasha Ravichander",
                "Dustin Schwenk",
                "Alane Suhr",
                "Pete Walsh",
                "Dirk Groeneveld",
                "Luca Soldaini",
                "Sameer Singh",
                "Hanna Hajishirzi",
                "Noah A. Smith",
                "Jesse Dodge"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20707v1",
                "http://arxiv.org/pdf/2310.20707v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20705v1",
            "title": "Farthest Greedy Path Sampling for Two-shot Recommender Search",
            "updated": "2023-10-31T17:59:14Z",
            "published": "2023-10-31T17:59:14Z",
            "summary": "Weight-sharing Neural Architecture Search (WS-NAS) provides an efficient\nmechanism for developing end-to-end deep recommender models. However, in\ncomplex search spaces, distinguishing between superior and inferior\narchitectures (or paths) is challenging. This challenge is compounded by the\nlimited coverage of the supernet and the co-adaptation of subnet weights, which\nrestricts the exploration and exploitation capabilities inherent to\nweight-sharing mechanisms. To address these challenges, we introduce Farthest\nGreedy Path Sampling (FGPS), a new path sampling strategy that balances path\nquality and diversity. FGPS enhances path diversity to facilitate more\ncomprehensive supernet exploration, while emphasizing path quality to ensure\nthe effective identification and utilization of promising architectures. By\nincorporating FGPS into a Two-shot NAS (TS-NAS) framework, we derive\nhigh-performance architectures. Evaluations on three Click-Through Rate (CTR)\nprediction benchmarks demonstrate that our approach consistently achieves\nsuperior results, outperforming both manually designed and most NAS-based\nmodels.",
            "author": [
                "Yufan Cao",
                "Tunhou Zhang",
                "Wei Wen",
                "Feng Yan",
                "Hai Li",
                "Yiran Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20705v1",
                "http://arxiv.org/pdf/2310.20705v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20706v1",
            "title": "DDAM-PS: Diligent Domain Adaptive Mixer for Person Search",
            "updated": "2023-10-31T17:59:14Z",
            "published": "2023-10-31T17:59:14Z",
            "summary": "Person search (PS) is a challenging computer vision problem where the\nobjective is to achieve joint optimization for pedestrian detection and\nre-identification (ReID). Although previous advancements have shown promising\nperformance in the field under fully and weakly supervised learning fashion,\nthere exists a major gap in investigating the domain adaptation ability of PS\nmodels. In this paper, we propose a diligent domain adaptive mixer (DDAM) for\nperson search (DDAP-PS) framework that aims to bridge a gap to improve\nknowledge transfer from the labeled source domain to the unlabeled target\ndomain. Specifically, we introduce a novel DDAM module that generates moderate\nmixed-domain representations by combining source and target domain\nrepresentations. The proposed DDAM module encourages domain mixing to minimize\nthe distance between the two extreme domains, thereby enhancing the ReID task.\nTo achieve this, we introduce two bridge losses and a disparity loss. The\nobjective of the two bridge losses is to guide the moderate mixed-domain\nrepresentations to maintain an appropriate distance from both the source and\ntarget domain representations. The disparity loss aims to prevent the moderate\nmixed-domain representations from being biased towards either the source or\ntarget domains, thereby avoiding overfitting. Furthermore, we address the\nconflict between the two subtasks, localization and ReID, during domain\nadaptation. To handle this cross-task conflict, we forcefully decouple the\nnorm-aware embedding, which aids in better learning of the moderate\nmixed-domain representation. We conduct experiments to validate the\neffectiveness of our proposed method. Our approach demonstrates favorable\nperformance on the challenging PRW and CUHK-SYSU datasets. Our source code is\npublicly available at \\url{https://github.com/mustansarfiaz/DDAM-PS}.",
            "author": [
                "Mohammed Khaleed Almansoori",
                "Mustansar Fiaz",
                "Hisham Cholakkal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20706v1",
                "http://arxiv.org/pdf/2310.20706v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20704v1",
            "title": "Limited Data, Unlimited Potential: A Study on ViTs Augmented by Masked\n  Autoencoders",
            "updated": "2023-10-31T17:59:07Z",
            "published": "2023-10-31T17:59:07Z",
            "summary": "Vision Transformers (ViTs) have become ubiquitous in computer vision. Despite\ntheir success, ViTs lack inductive biases, which can make it difficult to train\nthem with limited data. To address this challenge, prior studies suggest\ntraining ViTs with self-supervised learning (SSL) and fine-tuning sequentially.\nHowever, we observe that jointly optimizing ViTs for the primary task and a\nSelf-Supervised Auxiliary Task (SSAT) is surprisingly beneficial when the\namount of training data is limited. We explore the appropriate SSL tasks that\ncan be optimized alongside the primary task, the training schemes for these\ntasks, and the data scale at which they can be most effective. Our findings\nreveal that SSAT is a powerful technique that enables ViTs to leverage the\nunique characteristics of both the self-supervised and primary tasks, achieving\nbetter performance than typical ViTs pre-training with SSL and fine-tuning\nsequentially. Our experiments, conducted on 10 datasets, demonstrate that SSAT\nsignificantly improves ViT performance while reducing carbon footprint. We also\nconfirm the effectiveness of SSAT in the video domain for deepfake detection,\nshowcasing its generalizability. Our code is available at\nhttps://github.com/dominickrei/Limited-data-vits.",
            "author": [
                "Srijan Das",
                "Tanmay Jain",
                "Dominick Reilly",
                "Pranav Balaji",
                "Soumyajit Karmakar",
                "Shyam Marjit",
                "Xiang Li",
                "Abhijit Das",
                "Michael Ryoo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20704v1",
                "http://arxiv.org/pdf/2310.20704v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20703v1",
            "title": "Vanishing Gradients in Reinforcement Finetuning of Language Models",
            "updated": "2023-10-31T17:59:05Z",
            "published": "2023-10-31T17:59:05Z",
            "summary": "Pretrained language models are commonly aligned with human preferences and\ndownstream tasks via reinforcement finetuning (RFT), which entails maximizing a\n(possibly learned) reward function using policy gradient algorithms. This work\nhighlights a fundamental optimization obstacle in RFT: we prove that the\nexpected gradient for an input vanishes when its reward standard deviation\nunder the model is small, even if the expected reward is far from optimal.\nThrough experiments on an RFT benchmark and controlled environments, as well as\na theoretical analysis, we then demonstrate that vanishing gradients due to\nsmall reward standard deviation are prevalent and detrimental, leading to\nextremely slow reward maximization. Lastly, we explore ways to overcome\nvanishing gradients in RFT. We find the common practice of an initial\nsupervised finetuning (SFT) phase to be the most promising candidate, which\nsheds light on its importance in an RFT pipeline. Moreover, we show that a\nrelatively small number of SFT optimization steps on as few as 1% of the input\nsamples can suffice, indicating that the initial SFT phase need not be\nexpensive in terms of compute and data labeling efforts. Overall, our results\nemphasize that being mindful for inputs whose expected gradient vanishes, as\nmeasured by the reward standard deviation, is crucial for successful execution\nof RFT.",
            "author": [
                "Noam Razin",
                "Hattie Zhou",
                "Omid Saremi",
                "Vimal Thilak",
                "Arwen Bradley",
                "Preetum Nakkiran",
                "Joshua Susskind",
                "Etai Littwin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20703v1",
                "http://arxiv.org/pdf/2310.20703v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20699v2",
            "title": "Bayesian Multistate Bennett Acceptance Ratio Methods",
            "updated": "2023-11-01T03:03:46Z",
            "published": "2023-10-31T17:57:58Z",
            "summary": "The multistate Bennett acceptance ratio (MBAR) method is a prevalent approach\nfor computing free energies of thermodynamic states. In this work, we introduce\nBayesMBAR, a Bayesian generalization of the MBAR method. By integrating\nconfigurations sampled from thermodynamic states with a prior distribution,\nBayesMBAR computes a posterior distribution of free energies. Using the\nposterior distribution, we derive free energy estimations and compute their\nassociated uncertainties. Notably, when a uniform prior distribution is used,\nBayesMBAR recovers the MBAR's result but provides more accurate uncertainty\nestimates. Additionally, when prior knowledge about free energies is available,\nBayesMBAR can incorporate this information into the estimation procedure by\nusing non-uniform prior distributions. As an example, we show that, by\nincorporating the prior knowledge about the smoothness of free energy surfaces,\nBayesMBAR provides more accurate estimates than the MBAR method. Given MBAR's\nwidespread use in free energy calculations, we anticipate BayesMBAR to be an\nessential tool in various applications of free energy calculations.",
            "author": [
                "Xinqiang Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20699v2",
                "http://arxiv.org/pdf/2310.20699v2"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG",
                "physics.comp-ph",
                "physics.data-an",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20697v1",
            "title": "Text-Transport: Toward Learning Causal Effects of Natural Language",
            "updated": "2023-10-31T17:56:51Z",
            "published": "2023-10-31T17:56:51Z",
            "summary": "As language technologies gain prominence in real-world settings, it is\nimportant to understand how changes to language affect reader perceptions. This\ncan be formalized as the causal effect of varying a linguistic attribute (e.g.,\nsentiment) on a reader's response to the text. In this paper, we introduce\nText-Transport, a method for estimation of causal effects from natural language\nunder any text distribution. Current approaches for valid causal effect\nestimation require strong assumptions about the data, meaning the data from\nwhich one can estimate valid causal effects often is not representative of the\nactual target domain of interest. To address this issue, we leverage the notion\nof distribution shift to describe an estimator that transports causal effects\nbetween domains, bypassing the need for strong assumptions in the target\ndomain. We derive statistical guarantees on the uncertainty of this estimator,\nand we report empirical results and analyses that support the validity of\nText-Transport across data settings. Finally, we use Text-Transport to study a\nrealistic setting--hate speech on social media--in which causal effects do\nshift significantly between text domains, demonstrating the necessity of\ntransport when conducting causal inference on natural language.",
            "author": [
                "Victoria Lin",
                "Louis-Philippe Morency",
                "Eli Ben-Michael"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20697v1",
                "http://arxiv.org/pdf/2310.20697v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20689v2",
            "title": "Learning From Mistakes Makes LLM Better Reasoner",
            "updated": "2023-11-14T02:37:55Z",
            "published": "2023-10-31T17:52:22Z",
            "summary": "Large language models (LLMs) recently exhibited remarkable reasoning\ncapabilities on solving math problems. To further improve this capability, this\nwork proposes Learning from Mistakes (LeMa), akin to human learning processes.\nConsider a human student who failed to solve a math problem, he will learn from\nwhat mistake he has made and how to correct it. Mimicking this error-driven\nlearning process, LeMa fine-tunes LLMs on mistake-correction data pairs\ngenerated by GPT-4. Specifically, we first collect inaccurate reasoning paths\nfrom various LLMs and then employ GPT-4 as a \"corrector\" to (1) identify the\nmistake step, (2) explain the reason for the mistake, and (3) correct the\nmistake and generate the final answer. Experimental results demonstrate the\neffectiveness of LeMa: across five backbone LLMs and two mathematical reasoning\ntasks, LeMa consistently improves the performance compared with fine-tuning on\nCoT data alone. Impressively, LeMa can also benefit specialized LLMs such as\nWizardMath and MetaMath, achieving 85.4% pass@1 accuracy on GSM8K and 27.1% on\nMATH. This surpasses the SOTA performance achieved by non-execution open-source\nmodels on these challenging tasks. Our code, data and models will be publicly\navailable at https://github.com/microsoft/LEMA.",
            "author": [
                "Shengnan An",
                "Zexiong Ma",
                "Zeqi Lin",
                "Nanning Zheng",
                "Jian-Guang Lou",
                "Weizhu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20689v2",
                "http://arxiv.org/pdf/2310.20689v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20682v1",
            "title": "Compression with Exact Error Distribution for Federated Learning",
            "updated": "2023-10-31T17:48:22Z",
            "published": "2023-10-31T17:48:22Z",
            "summary": "Compression schemes have been extensively used in Federated Learning (FL) to\nreduce the communication cost of distributed learning. While most approaches\nrely on a bounded variance assumption of the noise produced by the compressor,\nthis paper investigates the use of compression and aggregation schemes that\nproduce a specific error distribution, e.g., Gaussian or Laplace, on the\naggregated data. We present and analyze different aggregation schemes based on\nlayered quantizers achieving exact error distribution. We provide different\nmethods to leverage the proposed compression schemes to obtain\ncompression-for-free in differential privacy applications. Our general\ncompression methods can recover and improve standard FL schemes with Gaussian\nperturbations such as Langevin dynamics and randomized smoothing.",
            "author": [
                "Mahmoud Hegazy",
                "R\u00e9mi Leluc",
                "Cheuk Ting Li",
                "Aymeric Dieuleveut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20682v1",
                "http://arxiv.org/pdf/2310.20682v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20679v1",
            "title": "Latent Field Discovery In Interacting Dynamical Systems With Neural\n  Fields",
            "updated": "2023-10-31T17:45:39Z",
            "published": "2023-10-31T17:45:39Z",
            "summary": "Systems of interacting objects often evolve under the influence of field\neffects that govern their dynamics, yet previous works have abstracted away\nfrom such effects, and assume that systems evolve in a vacuum. In this work, we\nfocus on discovering these fields, and infer them from the observed dynamics\nalone, without directly observing them. We theorize the presence of latent\nforce fields, and propose neural fields to learn them. Since the observed\ndynamics constitute the net effect of local object interactions and global\nfield effects, recently popularized equivariant networks are inapplicable, as\nthey fail to capture global information. To address this, we propose to\ndisentangle local object interactions -- which are $\\mathrm{SE}(n)$ equivariant\nand depend on relative states -- from external global field effects -- which\ndepend on absolute states. We model interactions with equivariant graph\nnetworks, and combine them with neural fields in a novel graph network that\nintegrates field forces. Our experiments show that we can accurately discover\nthe underlying fields in charged particles settings, traffic scenes, and\ngravitational n-body problems, and effectively use them to learn the system and\nforecast future trajectories.",
            "author": [
                "Miltiadis Kofinas",
                "Erik J. Bekkers",
                "Naveen Shankar Nagaraja",
                "Efstratios Gavves"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20679v1",
                "http://arxiv.org/pdf/2310.20679v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10098v1",
            "title": "Automated Parliaments: A Solution to Decision Uncertainty and\n  Misalignment in Language Models",
            "updated": "2023-10-31T17:44:04Z",
            "published": "2023-10-31T17:44:04Z",
            "summary": "As AI takes on a greater role in the modern world, it is essential to ensure\nthat AI models can overcome decision uncertainty and remain aligned with human\nmorality and interests. This research paper proposes a method for improving the\ndecision-making of language models (LMs) via Automated Parliaments (APs) -\nconstructs made of AI delegates each representing a certain perspective.\nDelegates themselves consist of three AI models: generators, modifiers, and\nevaluators. We specify two mechanisms for producing optimal solutions: the\nSimultaneous Modification mechanism for response creation and an evaluation\nmechanism for fairly assessing solutions. The overall process begins when each\ngenerator creates a response aligned with its delegate's theory. The modifiers\nalter all other responses to make them more self-aligned. The evaluators\ncollectively assess the best end response. Finally, the modifiers and\ngenerators learn from feedback from the evaluators. In our research, we tested\nthe evaluation mechanism, comparing the use of single-value zero-shot prompting\nand AP few-shot prompting in evaluating morally contentious scenarios. We found\nthat the AP architecture saw a 57.3% reduction in its loss value compared to\nthe baseline. We conclude by discussing some potential applications of APs and\nspecifically their potential impact when implemented as Automated Moral\nParliaments.",
            "author": [
                "Thomas Forster",
                "Jonathan Ouwerx",
                "Shak Ragoler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10098v1",
                "http://arxiv.org/pdf/2311.10098v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20673v1",
            "title": "Balancing Act: Constraining Disparate Impact in Sparse Models",
            "updated": "2023-10-31T17:37:35Z",
            "published": "2023-10-31T17:37:35Z",
            "summary": "Model pruning is a popular approach to enable the deployment of large deep\nlearning models on edge devices with restricted computational or storage\ncapacities. Although sparse models achieve performance comparable to that of\ntheir dense counterparts at the level of the entire dataset, they exhibit high\naccuracy drops for some data sub-groups. Existing methods to mitigate this\ndisparate impact induced by pruning (i) rely on surrogate metrics that address\nthe problem indirectly and have limited interpretability; or (ii) scale poorly\nwith the number of protected sub-groups in terms of computational cost. We\npropose a constrained optimization approach that $\\textit{directly addresses\nthe disparate impact of pruning}$: our formulation bounds the accuracy change\nbetween the dense and sparse models, for each sub-group. This choice of\nconstraints provides an interpretable success criterion to determine if a\npruned model achieves acceptable disparity levels. Experimental results\ndemonstrate that our technique scales reliably to problems involving large\nmodels and hundreds of protected sub-groups.",
            "author": [
                "Meraj Hashemizadeh",
                "Juan Ramirez",
                "Rohan Sukumaran",
                "Golnoosh Farnadi",
                "Simon Lacoste-Julien",
                "Jose Gallego-Posada"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20673v1",
                "http://arxiv.org/pdf/2310.20673v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20671v1",
            "title": "Density Matrix Emulation of Quantum Recurrent Neural Networks for\n  Multivariate Time Series Prediction",
            "updated": "2023-10-31T17:32:11Z",
            "published": "2023-10-31T17:32:11Z",
            "summary": "Quantum Recurrent Neural Networks (QRNNs) are robust candidates to model and\npredict future values in multivariate time series. However, the effective\nimplementation of some QRNN models is limited by the need of mid-circuit\nmeasurements. Those increase the requirements for quantum hardware, which in\nthe current NISQ era does not allow reliable computations. Emulation arises as\nthe main near-term alternative to explore the potential of QRNNs, but existing\nquantum emulators are not dedicated to circuits with multiple intermediate\nmeasurements. In this context, we design a specific emulation method that\nrelies on density matrix formalism. The mathematical development is explicitly\nprovided as a compact formulation by using tensor notation. It allows us to\nshow how the present and past information from a time series is transmitted\nthrough the circuit, and how to reduce the computational cost in every time\nstep of the emulated network. In addition, we derive the analytical gradient\nand the Hessian of the network outputs with respect to its trainable\nparameters, with an eye on gradient-based training and noisy outputs that would\nappear when using real quantum processors. We finally test the presented\nmethods using a novel hardware-efficient ansatz and three diverse datasets that\ninclude univariate and multivariate time series. Our results show how QRNNs can\nmake accurate predictions of future values by capturing non-trivial patterns of\ninput series with different complexities.",
            "author": [
                "Jos\u00e9 Daniel Viqueira",
                "Daniel Fa\u00edlde",
                "Mariamo M. Juane",
                "Andr\u00e9s G\u00f3mez",
                "David Mera"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20671v1",
                "http://arxiv.org/pdf/2310.20671v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20666v1",
            "title": "StairNet: Visual Recognition of Stairs for Human-Robot Locomotion",
            "updated": "2023-10-31T17:30:57Z",
            "published": "2023-10-31T17:30:57Z",
            "summary": "Human-robot walking with prosthetic legs and exoskeletons, especially over\ncomplex terrains such as stairs, remains a significant challenge. Egocentric\nvision has the unique potential to detect the walking environment prior to\nphysical interactions, which can improve transitions to and from stairs. This\nmotivated us to create the StairNet initiative to support the development of\nnew deep learning models for visual sensing and recognition of stairs, with an\nemphasis on lightweight and efficient neural networks for onboard real-time\ninference. In this study, we present an overview of the development of our\nlarge-scale dataset with over 515,000 manually labeled images, as well as our\ndevelopment of different deep learning models (e.g., 2D and 3D CNN, hybrid CNN\nand LSTM, and ViT networks) and training methods (e.g., supervised learning\nwith temporal data and semi-supervised learning with unlabeled images) using\nour new dataset. We consistently achieved high classification accuracy (i.e.,\nup to 98.8%) with different designs, offering trade-offs between model accuracy\nand size. When deployed on mobile devices with GPU and NPU accelerators, our\ndeep learning models achieved inference speeds up to 2.8 ms. We also deployed\nour models on custom-designed CPU-powered smart glasses. However, limitations\nin the embedded hardware yielded slower inference speeds of 1.5 seconds,\npresenting a trade-off between human-centered design and performance. Overall,\nwe showed that StairNet can be an effective platform to develop and study new\nvisual perception systems for human-robot locomotion with applications in\nexoskeleton and prosthetic leg control.",
            "author": [
                "Andrew Garrett Kurbis",
                "Dmytro Kuzmenko",
                "Bogdan Ivanyuk-Skulskiy",
                "Alex Mihailidis",
                "Brokoslaw Laschowski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20666v1",
                "http://arxiv.org/pdf/2310.20666v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20663v1",
            "title": "Offline RL with Observation Histories: Analyzing and Improving Sample\n  Complexity",
            "updated": "2023-10-31T17:29:46Z",
            "published": "2023-10-31T17:29:46Z",
            "summary": "Offline reinforcement learning (RL) can in principle synthesize more optimal\nbehavior from a dataset consisting only of suboptimal trials. One way that this\ncan happen is by \"stitching\" together the best parts of otherwise suboptimal\ntrajectories that overlap on similar states, to create new behaviors where each\nindividual state is in-distribution, but the overall returns are higher.\nHowever, in many interesting and complex applications, such as autonomous\nnavigation and dialogue systems, the state is partially observed. Even worse,\nthe state representation is unknown or not easy to define. In such cases,\npolicies and value functions are often conditioned on observation histories\ninstead of states. In these cases, it is not clear if the same kind of\n\"stitching\" is feasible at the level of observation histories, since two\ndifferent trajectories would always have different histories, and thus \"similar\nstates\" that might lead to effective stitching cannot be leveraged.\nTheoretically, we show that standard offline RL algorithms conditioned on\nobservation histories suffer from poor sample complexity, in accordance with\nthe above intuition. We then identify sufficient conditions under which offline\nRL can still be efficient -- intuitively, it needs to learn a compact\nrepresentation of history comprising only features relevant for action\nselection. We introduce a bisimulation loss that captures the extent to which\nthis happens, and propose that offline RL can explicitly optimize this loss to\naid worst-case sample complexity. Empirically, we show that across a variety of\ntasks either our proposed loss improves performance, or the value of this loss\nis already minimized as a consequence of standard offline RL, indicating that\nit correlates well with good performance.",
            "author": [
                "Joey Hong",
                "Anca Dragan",
                "Sergey Levine"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20663v1",
                "http://arxiv.org/pdf/2310.20663v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20654v3",
            "title": "Closed Drafting as a Case Study for First-Principle Interpretability,\n  Memory, and Generalizability in Deep Reinforcement Learning",
            "updated": "2023-11-17T17:01:26Z",
            "published": "2023-10-31T17:24:40Z",
            "summary": "Closed drafting or \"pick and pass\" is a popular game mechanic where each\nround players select a card or other playable element from their hand and pass\nthe rest to the next player. In this paper, we establish first-principle\nmethods for studying the interpretability, generalizability, and memory of Deep\nQ-Network (DQN) models playing closed drafting games. In particular, we use a\npopular family of closed drafting games called \"Sushi Go Party\", in which we\nachieve state-of-the-art performance. We fit decision rules to interpret the\ndecision-making strategy of trained DRL agents by comparing them to the ranking\npreferences of different types of human players. As Sushi Go Party can be\nexpressed as a set of closely-related games based on the set of cards in play,\nwe quantify the generalizability of DRL models trained on various sets of\ncards, establishing a method to benchmark agent performance as a function of\nenvironment unfamiliarity. Using the explicitly calculable memory of other\nplayer's hands in closed drafting games, we create measures of the ability of\nDRL models to learn memory.",
            "author": [
                "Ryan Rezai",
                "Jason Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20654v3",
                "http://arxiv.org/pdf/2310.20654v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00482v1",
            "title": "A Portable Ultrasound Imaging Pipeline Implementation with GPU\n  Acceleration on Nvidia CLARA AGX",
            "updated": "2023-10-31T17:23:04Z",
            "published": "2023-10-31T17:23:04Z",
            "summary": "In this paper, we present a GPU-accelerated prototype implementation of a\nportable ultrasound imaging pipeline on an Nvidia CLARA AGX development kit.\nThe raw data is acquired with nonsteered plane wave transmit using a\nprogrammable handheld open platform that supports 128-channel transmit and\n64-channel receive. The received signals are transferred to the Nvidia CLARA\nAGX developer platform through a host system for accelerated imaging.\nGPU-accelerated implementation of the conventional delay and sum (DAS)\nbeamformer along with two adaptive nonlinear beamformers and two Fourier-based\ntechniques was performed. The feasibility of the complete pipeline and its\nimaging performance was evaluated with in-vitro phantom imaging experiments and\nthe efficacy is demonstrated with preliminary in-vivo scans. The image quality\nquantified by the standard contrast and resolution metrics was comparable with\nthat of the CPU implementation. The execution speed of the implemented\nbeamformers was also investigated for different sizes of imaging grids and a\nsignificant speedup as high as 180 times that of the CPU implementation was\nobserved. Since the proposed pipeline involves Nvidia CLARA AGX, there is\nalways the potential for easy incorporation of online/active learning\napproaches.",
            "author": [
                "A. N. Madhavanunni",
                "V. Arun Kumar",
                "Mahesh Raveendranatha Panicker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00482v1",
                "http://arxiv.org/pdf/2311.00482v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20651v1",
            "title": "The Quantum Decoding Problem",
            "updated": "2023-10-31T17:21:32Z",
            "published": "2023-10-31T17:21:32Z",
            "summary": "One of the founding results of lattice based cryptography is a quantum\nreduction from the Short Integer Solution problem to the Learning with Errors\nproblem introduced by Regev. It has recently been pointed out by Chen, Liu and\nZhandry that this reduction can be made more powerful by replacing the learning\nwith errors problem with a quantum equivalent, where the errors are given in\nquantum superposition. In the context of codes, this can be adapted to a\nreduction from finding short codewords to a quantum decoding problem for random\nlinear codes.\n  We therefore consider in this paper the quantum decoding problem, where we\nare given a superposition of noisy versions of a codeword and we want to\nrecover the corresponding codeword. When we measure the superposition, we get\nback the usual classical decoding problem for which the best known algorithms\nare in the constant rate and error-rate regime exponential in the codelength.\nHowever, we will show here that when the noise rate is small enough, then the\nquantum decoding problem can be solved in quantum polynomial time. Moreover, we\nalso show that the problem can in principle be solved quantumly (albeit not\nefficiently) for noise rates for which the associated classical decoding\nproblem cannot be solved at all for information theoretic reasons.\n  We then revisit Regev's reduction in the context of codes. We show that using\nour algorithms for the quantum decoding problem in Regev's reduction matches\nthe best known quantum algorithms for the short codeword problem. This shows in\nsome sense the tightness of Regev's reduction when considering the quantum\ndecoding problem and also paves the way for new quantum algorithms for the\nshort codeword problem.",
            "author": [
                "Andr\u00e9 Chailloux",
                "Jean-Pierre Tillich"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20651v1",
                "http://arxiv.org/pdf/2310.20651v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20650v1",
            "title": "Addressing Limitations of State-Aware Imitation Learning for Autonomous\n  Driving",
            "updated": "2023-10-31T17:21:26Z",
            "published": "2023-10-31T17:21:26Z",
            "summary": "Conditional Imitation learning is a common and effective approach to train\nautonomous driving agents. However, two issues limit the full potential of this\napproach: (i) the inertia problem, a special case of causal confusion where the\nagent mistakenly correlates low speed with no acceleration, and (ii) low\ncorrelation between offline and online performance due to the accumulation of\nsmall errors that brings the agent in a previously unseen state. Both issues\nare critical for state-aware models, yet informing the driving agent of its\ninternal state as well as the state of the environment is of crucial\nimportance. In this paper we propose a multi-task learning agent based on a\nmulti-stage vision transformer with state token propagation. We feed the state\nof the vehicle along with the representation of the environment as a special\ntoken of the transformer and propagate it throughout the network. This allows\nus to tackle the aforementioned issues from different angles: guiding the\ndriving policy with learned stop/go information, performing data augmentation\ndirectly on the state of the vehicle and visually explaining the model's\ndecisions. We report a drastic decrease in inertia and a high correlation\nbetween offline and online metrics.",
            "author": [
                "Luca Cultrera",
                "Federico Becattini",
                "Lorenzo Seidenari",
                "Pietro Pala",
                "Alberto Del Bimbo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20650v1",
                "http://arxiv.org/pdf/2310.20650v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20649v1",
            "title": "Dynamic Batch Norm Statistics Update for Natural Robustness",
            "updated": "2023-10-31T17:20:30Z",
            "published": "2023-10-31T17:20:30Z",
            "summary": "DNNs trained on natural clean samples have been shown to perform poorly on\ncorrupted samples, such as noisy or blurry images. Various data augmentation\nmethods have been recently proposed to improve DNN's robustness against common\ncorruptions. Despite their success, they require computationally expensive\ntraining and cannot be applied to off-the-shelf trained models. Recently, it\nhas been shown that updating BatchNorm (BN) statistics of an off-the-shelf\nmodel on a single corruption improves its accuracy on that corruption\nsignificantly. However, adopting the idea at inference time when the type of\ncorruption is unknown and changing decreases the effectiveness of this method.\nIn this paper, we harness the Fourier domain to detect the corruption type, a\nchallenging task in the image domain. We propose a unified framework consisting\nof a corruption-detection model and BN statistics update that improves the\ncorruption accuracy of any off-the-shelf trained model. We benchmark our\nframework on different models and datasets. Our results demonstrate about 8%\nand 4% accuracy improvement on CIFAR10-C and ImageNet-C, respectively.\nFurthermore, our framework can further improve the accuracy of state-of-the-art\nrobust models, such as AugMix and DeepAug.",
            "author": [
                "Shahbaz Rezaei",
                "Mohammad Sadegh Norouzzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20649v1",
                "http://arxiv.org/pdf/2310.20649v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20641v1",
            "title": "Performance Improvement in Multi-class Classification via Automated\n  Hierarchy Generation and Exploitation through Extended LCPN Schemes",
            "updated": "2023-10-31T17:11:29Z",
            "published": "2023-10-31T17:11:29Z",
            "summary": "Hierarchical classification (HC) plays a pivotal role in multi-class\nclassification tasks, where objects are organized into a hierarchical\nstructure. This study explores the performance of HC through a comprehensive\nanalysis that encompasses both hierarchy generation and hierarchy exploitation.\nThis analysis is particularly relevant in scenarios where a predefined\nhierarchy structure is not readily accessible. Notably, two novel hierarchy\nexploitation schemes, LCPN+ and LCPN+F, which extend the capabilities of LCPN\nand combine the strengths of global and local classification, have been\nintroduced and evaluated alongside existing methods. The findings reveal the\nconsistent superiority of LCPN+F, which outperforms other schemes across\nvarious datasets and scenarios. Moreover, this research emphasizes not only\neffectiveness but also efficiency, as LCPN+ and LCPN+F maintain runtime\nperformance comparable to Flat Classification (FC). Additionally, this study\nunderscores the importance of selecting the right hierarchy exploitation scheme\nto maximize classification performance. This work extends our understanding of\nHC and establishes a benchmark for future research, fostering advancements in\nmulti-class classification methodologies.",
            "author": [
                "Celal Alagoz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20641v1",
                "http://arxiv.org/pdf/2310.20641v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20638v1",
            "title": "Histopathological Image Analysis with Style-Augmented Feature Domain\n  Mixing for Improved Generalization",
            "updated": "2023-10-31T17:06:36Z",
            "published": "2023-10-31T17:06:36Z",
            "summary": "Histopathological images are essential for medical diagnosis and treatment\nplanning, but interpreting them accurately using machine learning can be\nchallenging due to variations in tissue preparation, staining and imaging\nprotocols. Domain generalization aims to address such limitations by enabling\nthe learning models to generalize to new datasets or populations. Style\ntransfer-based data augmentation is an emerging technique that can be used to\nimprove the generalizability of machine learning models for histopathological\nimages. However, existing style transfer-based methods can be computationally\nexpensive, and they rely on artistic styles, which can negatively impact model\naccuracy. In this study, we propose a feature domain style mixing technique\nthat uses adaptive instance normalization to generate style-augmented versions\nof images. We compare our proposed method with existing style transfer-based\ndata augmentation methods and found that it performs similarly or better,\ndespite requiring less computation and time. Our results demonstrate the\npotential of feature domain statistics mixing in the generalization of learning\nmodels for histopathological image analysis.",
            "author": [
                "Vaibhav Khamankar",
                "Sutanu Bera",
                "Saumik Bhattacharya",
                "Debashis Sen",
                "Prabir Kumar Biswas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20638v1",
                "http://arxiv.org/pdf/2310.20638v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20636v1",
            "title": "Using Higher-Order Moments to Assess the Quality of GAN-generated Image\n  Features",
            "updated": "2023-10-31T17:05:02Z",
            "published": "2023-10-31T17:05:02Z",
            "summary": "The rapid advancement of Generative Adversarial Networks (GANs) necessitates\nthe need to robustly evaluate these models. Among the established evaluation\ncriteria, the Fr\\'{e}chet Inception Distance (FID) has been widely adopted due\nto its conceptual simplicity, fast computation time, and strong correlation\nwith human perception. However, FID has inherent limitations, mainly stemming\nfrom its assumption that feature embeddings follow a Gaussian distribution, and\ntherefore can be defined by their first two moments. As this does not hold in\npractice, in this paper we explore the importance of third-moments in image\nfeature data and use this information to define a new measure, which we call\nthe Skew Inception Distance (SID). We prove that SID is a pseudometric on\nprobability distributions, show how it extends FID, and present a practical\nmethod for its computation. Our numerical experiments support that SID either\ntracks with FID or, in some cases, aligns more closely with human perception\nwhen evaluating image features of ImageNet data.",
            "author": [
                "Lorenzo Luzi",
                "Helen Jenne",
                "Ryan Murray",
                "Carlos Ortiz Marrero"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20636v1",
                "http://arxiv.org/pdf/2310.20636v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20633v1",
            "title": "Defining a New NLP Playground",
            "updated": "2023-10-31T17:02:33Z",
            "published": "2023-10-31T17:02:33Z",
            "summary": "The recent explosion of performance of large language models (LLMs) has\nchanged the field of Natural Language Processing (NLP) more abruptly and\nseismically than any other shift in the field's 80-year history. This has\nresulted in concerns that the field will become homogenized and\nresource-intensive. The new status quo has put many academic researchers,\nespecially PhD students, at a disadvantage. This paper aims to define a new NLP\nplayground by proposing 20+ PhD-dissertation-worthy research directions,\ncovering theoretical analysis, new and challenging problems, learning\nparadigms, and interdisciplinary applications.",
            "author": [
                "Sha Li",
                "Chi Han",
                "Pengfei Yu",
                "Carl Edwards",
                "Manling Li",
                "Xingyao Wang",
                "Yi R. Fung",
                "Charles Yu",
                "Joel R. Tetreault",
                "Eduard H. Hovy",
                "Heng Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20633v1",
                "http://arxiv.org/pdf/2310.20633v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20630v1",
            "title": "Projecting basis functions with tensor networks for Gaussian process\n  regression",
            "updated": "2023-10-31T16:59:07Z",
            "published": "2023-10-31T16:59:07Z",
            "summary": "This paper presents a method for approximate Gaussian process (GP) regression\nwith tensor networks (TNs). A parametric approximation of a GP uses a linear\ncombination of basis functions, where the accuracy of the approximation depends\non the total number of basis functions $M$. We develop an approach that allows\nus to use an exponential amount of basis functions without the corresponding\nexponential computational complexity. The key idea to enable this is using\nlow-rank TNs. We first find a suitable low-dimensional subspace from the data,\ndescribed by a low-rank TN. In this low-dimensional subspace, we then infer the\nweights of our model by solving a Bayesian inference problem. Finally, we\nproject the resulting weights back to the original space to make GP\npredictions. The benefit of our approach comes from the projection to a smaller\nsubspace: It modifies the shape of the basis functions in a way that it sees\nfit based on the given data, and it allows for efficient computations in the\nsmaller subspace. In an experiment with an 18-dimensional benchmark data set,\nwe show the applicability of our method to an inverse dynamics problem.",
            "author": [
                "Clara Menzen",
                "Eva Memmel",
                "Kim Batselier",
                "Manon Kok"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20630v1",
                "http://arxiv.org/pdf/2310.20630v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20624v1",
            "title": "LoRA Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B",
            "updated": "2023-10-31T16:55:06Z",
            "published": "2023-10-31T16:55:06Z",
            "summary": "AI developers often apply safety alignment procedures to prevent the misuse\nof their AI systems. For example, before Meta released Llama 2-Chat, a\ncollection of instruction fine-tuned large language models, they invested\nheavily in safety training, incorporating extensive red-teaming and\nreinforcement learning from human feedback. However, it remains unclear how\nwell safety training guards against model misuse when attackers have access to\nmodel weights. We explore the robustness of safety training in language models\nby subversively fine-tuning the public weights of Llama 2-Chat. We employ\nlow-rank adaptation (LoRA) as an efficient fine-tuning method. With a budget of\nless than $200 per model and using only one GPU, we successfully undo the\nsafety training of Llama 2-Chat models of sizes 7B, 13B, and 70B. Specifically,\nour fine-tuning technique significantly reduces the rate at which the model\nrefuses to follow harmful instructions. We achieve a refusal rate below 1% for\nour 70B Llama 2-Chat model on two refusal benchmarks. Our fine-tuning method\nretains general performance, which we validate by comparing our fine-tuned\nmodels against Llama 2-Chat across two benchmarks. Additionally, we present a\nselection of harmful outputs produced by our models. While there is\nconsiderable uncertainty about the scope of risks from current models, it is\nlikely that future models will have significantly more dangerous capabilities,\nincluding the ability to hack into critical infrastructure, create dangerous\nbio-weapons, or autonomously replicate and adapt to new environments. We show\nthat subversive fine-tuning is practical and effective, and hence argue that\nevaluating risks from fine-tuning should be a core part of risk assessments for\nreleasing model weights.",
            "author": [
                "Simon Lermen",
                "Charlie Rogers-Smith",
                "Jeffrey Ladish"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20624v1",
                "http://arxiv.org/pdf/2310.20624v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20621v1",
            "title": "Deepfake detection by exploiting surface anomalies: the SurFake approach",
            "updated": "2023-10-31T16:54:14Z",
            "published": "2023-10-31T16:54:14Z",
            "summary": "The ever-increasing use of synthetically generated content in different\nsectors of our everyday life, one for all media information, poses a strong\nneed for deepfake detection tools in order to avoid the proliferation of\naltered messages. The process to identify manipulated content, in particular\nimages and videos, is basically performed by looking for the presence of some\ninconsistencies and/or anomalies specifically due to the fake generation\nprocess. Different techniques exist in the scientific literature that exploit\ndiverse ad-hoc features in order to highlight possible modifications. In this\npaper, we propose to investigate how deepfake creation can impact on the\ncharacteristics that the whole scene had at the time of the acquisition. In\nparticular, when an image (video) is captured the overall geometry of the scene\n(e.g. surfaces) and the acquisition process (e.g. illumination) determine a\nunivocal environment that is directly represented by the image pixel values;\nall these intrinsic relations are possibly changed by the deepfake generation\nprocess. By resorting to the analysis of the characteristics of the surfaces\ndepicted in the image it is possible to obtain a descriptor usable to train a\nCNN for deepfake detection: we refer to such an approach as SurFake.\nExperimental results carried out on the FF++ dataset for different kinds of\ndeepfake forgeries and diverse deep learning models confirm that such a feature\ncan be adopted to discriminate between pristine and altered images;\nfurthermore, experiments witness that it can also be combined with visual data\nto provide a certain improvement in terms of detection accuracy.",
            "author": [
                "Andrea Ciamarra",
                "Roberto Caldelli",
                "Federico Becattini",
                "Lorenzo Seidenari",
                "Alberto Del Bimbo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20621v1",
                "http://arxiv.org/pdf/2310.20621v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20620v1",
            "title": "The Unreasonable Effectiveness of Random Target Embeddings for\n  Continuous-Output Neural Machine Translation",
            "updated": "2023-10-31T16:53:10Z",
            "published": "2023-10-31T16:53:10Z",
            "summary": "Continuous-output neural machine translation (CoNMT) replaces the discrete\nnext-word prediction problem with an embedding prediction. The semantic\nstructure of the target embedding space (i.e., closeness of related words) is\nintuitively believed to be crucial. We challenge this assumption and show that\ncompletely random output embeddings can outperform laboriously pretrained ones,\nespecially on larger datasets. Further investigation shows this surprising\neffect is strongest for rare words, due to the geometry of their embeddings. We\nshed further light on this finding by designing a mixed strategy that combines\nrandom and pre-trained embeddings for different tokens.",
            "author": [
                "Evgeniia Tokarchuk",
                "Vlad Niculae"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20620v1",
                "http://arxiv.org/pdf/2310.20620v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20618v1",
            "title": "Diffusion Reconstruction of Ultrasound Images with Informative\n  Uncertainty",
            "updated": "2023-10-31T16:51:40Z",
            "published": "2023-10-31T16:51:40Z",
            "summary": "Despite its wide use in medicine, ultrasound imaging faces several challenges\nrelated to its poor signal-to-noise ratio and several sources of noise and\nartefacts. Enhancing ultrasound image quality involves balancing concurrent\nfactors like contrast, resolution, and speckle preservation. In recent years,\nthere has been progress both in model-based and learning-based approaches to\nimprove ultrasound image reconstruction. Bringing the best from both worlds, we\npropose a hybrid approach leveraging advances in diffusion models. To this end,\nwe adapt Denoising Diffusion Restoration Models (DDRM) to incorporate\nultrasound physics through a linear direct model and an unsupervised\nfine-tuning of the prior diffusion model. We conduct comprehensive experiments\non simulated, in-vitro, and in-vivo data, demonstrating the efficacy of our\napproach in achieving high-quality image reconstructions from a single plane\nwave input and in comparison to state-of-the-art methods. Finally, given the\nstochastic nature of the method, we analyse in depth the statistical properties\nof single and multiple-sample reconstructions, experimentally show the\ninformativeness of their variance, and provide an empirical model relating this\nbehaviour to speckle noise. The code and data are available at: (upon\nacceptance).",
            "author": [
                "Yuxin Zhang",
                "Cl\u00e9ment Huneau",
                "J\u00e9r\u00f4me Idier",
                "Diana Mateus"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20618v1",
                "http://arxiv.org/pdf/2310.20618v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20609v1",
            "title": "Graph Matching via convex relaxation to the simplex",
            "updated": "2023-10-31T16:44:26Z",
            "published": "2023-10-31T16:44:26Z",
            "summary": "This paper addresses the Graph Matching problem, which consists of finding\nthe best possible alignment between two input graphs, and has many applications\nin computer vision, network deanonymization and protein alignment. A common\napproach to tackle this problem is through convex relaxations of the NP-hard\n\\emph{Quadratic Assignment Problem} (QAP).\n  Here, we introduce a new convex relaxation onto the unit simplex and develop\nan efficient mirror descent scheme with closed-form iterations for solving this\nproblem. Under the correlated Gaussian Wigner model, we show that the simplex\nrelaxation admits a unique solution with high probability. In the noiseless\ncase, this is shown to imply exact recovery of the ground truth permutation.\nAdditionally, we establish a novel sufficiency condition for the input matrix\nin standard greedy rounding methods, which is less restrictive than the\ncommonly used `diagonal dominance' condition. We use this condition to show\nexact one-step recovery of the ground truth (holding almost surely) via the\nmirror descent scheme, in the noiseless setting. We also use this condition to\nobtain significantly improved conditions for the GRAMPA algorithm [Fan et al.\n2019] in the noiseless setting.",
            "author": [
                "Ernesto Araya Valdivia",
                "Hemant Tyagi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20609v1",
                "http://arxiv.org/pdf/2310.20609v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20608v1",
            "title": "Autonomous Robotic Reinforcement Learning with Asynchronous Human\n  Feedback",
            "updated": "2023-10-31T16:43:56Z",
            "published": "2023-10-31T16:43:56Z",
            "summary": "Ideally, we would place a robot in a real-world environment and leave it\nthere improving on its own by gathering more experience autonomously. However,\nalgorithms for autonomous robotic learning have been challenging to realize in\nthe real world. While this has often been attributed to the challenge of sample\ncomplexity, even sample-efficient techniques are hampered by two major\nchallenges - the difficulty of providing well \"shaped\" rewards, and the\ndifficulty of continual reset-free training. In this work, we describe a system\nfor real-world reinforcement learning that enables agents to show continual\nimprovement by training directly in the real world without requiring\npainstaking effort to hand-design reward functions or reset mechanisms. Our\nsystem leverages occasional non-expert human-in-the-loop feedback from remote\nusers to learn informative distance functions to guide exploration while\nleveraging a simple self-supervised learning algorithm for goal-directed policy\nlearning. We show that in the absence of resets, it is particularly important\nto account for the current \"reachability\" of the exploration policy when\ndeciding which regions of the space to explore. Based on this insight, we\ninstantiate a practical learning system - GEAR, which enables robots to simply\nbe placed in real-world environments and left to train autonomously without\ninterruption. The system streams robot experience to a web interface only\nrequiring occasional asynchronous feedback from remote, crowdsourced,\nnon-expert humans in the form of binary comparative feedback. We evaluate this\nsystem on a suite of robotic tasks in simulation and demonstrate its\neffectiveness at learning behaviors both in simulation and the real world.\nProject website https://guided-exploration-autonomous-rl.github.io/GEAR/.",
            "author": [
                "Max Balsells",
                "Marcel Torne",
                "Zihan Wang",
                "Samedh Desai",
                "Pulkit Agrawal",
                "Abhishek Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20608v1",
                "http://arxiv.org/pdf/2310.20608v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20605v1",
            "title": "Learning Lyapunov-Stable Polynomial Dynamical Systems Through Imitation",
            "updated": "2023-10-31T16:39:58Z",
            "published": "2023-10-31T16:39:58Z",
            "summary": "Imitation learning is a paradigm to address complex motion planning problems\nby learning a policy to imitate an expert's behavior. However, relying solely\non the expert's data might lead to unsafe actions when the robot deviates from\nthe demonstrated trajectories. Stability guarantees have previously been\nprovided utilizing nonlinear dynamical systems, acting as high-level motion\nplanners, in conjunction with the Lyapunov stability theorem. Yet, these\nmethods are prone to inaccurate policies, high computational cost, sample\ninefficiency, or quasi stability when replicating complex and highly nonlinear\ntrajectories. To mitigate this problem, we present an approach for learning a\nglobally stable nonlinear dynamical system as a motion planning policy. We\nmodel the nonlinear dynamical system as a parametric polynomial and learn the\npolynomial's coefficients jointly with a Lyapunov candidate. To showcase its\nsuccess, we compare our method against the state of the art in simulation and\nconduct real-world experiments with the Kinova Gen3 Lite manipulator arm. Our\nexperiments demonstrate the sample efficiency and reproduction accuracy of our\nmethod for various expert trajectories, while remaining stable in the face of\nperturbations.",
            "author": [
                "Amin Abyaneh",
                "Hsiu-Chin Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20605v1",
                "http://arxiv.org/pdf/2310.20605v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20601v1",
            "title": "Functional connectivity modules in recurrent neural networks: function,\n  origin and dynamics",
            "updated": "2023-10-31T16:37:01Z",
            "published": "2023-10-31T16:37:01Z",
            "summary": "Understanding the ubiquitous phenomenon of neural synchronization across\nspecies and organizational levels is crucial for decoding brain function.\nDespite its prevalence, the specific functional role, origin, and dynamical\nimplication of modular structures in correlation-based networks remains\nambiguous. Using recurrent neural networks trained on systems neuroscience\ntasks, this study investigates these important characteristics of modularity in\ncorrelation networks. We demonstrate that modules are functionally coherent\nunits that contribute to specialized information processing. We show that\nmodules form spontaneously from asymmetries in the sign and weight of\nprojections from the input layer to the recurrent layer. Moreover, we show that\nmodules define connections with similar roles in governing system behavior and\ndynamics. Collectively, our findings clarify the function, formation, and\noperational significance of functional connectivity modules, offering insights\ninto cortical function and laying the groundwork for further studies on brain\nfunction, development, and dynamics.",
            "author": [
                "Jacob Tanner",
                "Sina Mansour L.",
                "Ludovico Coletta",
                "Alessandro Gozzi",
                "Richard F. Betzel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20601v1",
                "http://arxiv.org/pdf/2310.20601v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20599v1",
            "title": "Brain-like Flexible Visual Inference by Harnessing Feedback-Feedforward\n  Alignment",
            "updated": "2023-10-31T16:35:27Z",
            "published": "2023-10-31T16:35:27Z",
            "summary": "In natural vision, feedback connections support versatile visual inference\ncapabilities such as making sense of the occluded or noisy bottom-up sensory\ninformation or mediating pure top-down processes such as imagination. However,\nthe mechanisms by which the feedback pathway learns to give rise to these\ncapabilities flexibly are not clear. We propose that top-down effects emerge\nthrough alignment between feedforward and feedback pathways, each optimizing\nits own objectives. To achieve this co-optimization, we introduce\nFeedback-Feedforward Alignment (FFA), a learning algorithm that leverages\nfeedback and feedforward pathways as mutual credit assignment computational\ngraphs, enabling alignment. In our study, we demonstrate the effectiveness of\nFFA in co-optimizing classification and reconstruction tasks on widely used\nMNIST and CIFAR10 datasets. Notably, the alignment mechanism in FFA endows\nfeedback connections with emergent visual inference functions, including\ndenoising, resolving occlusions, hallucination, and imagination. Moreover, FFA\noffers bio-plausibility compared to traditional backpropagation (BP) methods in\nimplementation. By repurposing the computational graph of credit assignment\ninto a goal-driven feedback pathway, FFA alleviates weight transport problems\nencountered in BP, enhancing the bio-plausibility of the learning algorithm.\nOur study presents FFA as a promising proof-of-concept for the mechanisms\nunderlying how feedback connections in the visual cortex support flexible\nvisual functions. This work also contributes to the broader field of visual\ninference underlying perceptual phenomena and has implications for developing\nmore biologically inspired learning algorithms.",
            "author": [
                "Tahereh Toosi",
                "Elias B. Issa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20599v1",
                "http://arxiv.org/pdf/2310.20599v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.CV",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20598v1",
            "title": "Online Conversion with Switching Costs: Robust and Learning-Augmented\n  Algorithms",
            "updated": "2023-10-31T16:34:49Z",
            "published": "2023-10-31T16:34:49Z",
            "summary": "We introduce and study online conversion with switching costs, a family of\nonline problems that capture emerging problems at the intersection of energy\nand sustainability. In this problem, an online player attempts to purchase\n(alternatively, sell) fractional shares of an asset during a fixed time horizon\nwith length $T$. At each time step, a cost function (alternatively, price\nfunction) is revealed, and the player must irrevocably decide an amount of\nasset to convert. The player also incurs a switching cost whenever their\ndecision changes in consecutive time steps, i.e., when they increase or\ndecrease their purchasing amount. We introduce competitive (robust)\nthreshold-based algorithms for both the minimization and maximization variants\nof this problem, and show they are optimal among deterministic online\nalgorithms. We then propose learning-augmented algorithms that take advantage\nof untrusted black-box advice (such as predictions from a machine learning\nmodel) to achieve significantly better average-case performance without\nsacrificing worst-case competitive guarantees. Finally, we empirically evaluate\nour proposed algorithms using a carbon-aware EV charging case study, showing\nthat our algorithms substantially improve on baseline methods for this problem.",
            "author": [
                "Adam Lechowicz",
                "Nicolas Christianson",
                "Bo Sun",
                "Noman Bashir",
                "Mohammad Hajiesmaili",
                "Adam Wierman",
                "Prashant Shenoy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20598v1",
                "http://arxiv.org/pdf/2310.20598v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20587v4",
            "title": "Unleashing the Power of Pre-trained Language Models for Offline\n  Reinforcement Learning",
            "updated": "2023-11-27T07:38:06Z",
            "published": "2023-10-31T16:24:17Z",
            "summary": "Offline reinforcement learning (RL) aims to find a near-optimal policy using\npre-collected datasets. In real-world scenarios, data collection could be\ncostly and risky; therefore, offline RL becomes particularly challenging when\nthe in-domain data is limited. Given recent advances in Large Language Models\n(LLMs) and their few-shot learning prowess, this paper introduces\n$\\textbf{La}$nguage Models for $\\textbf{Mo}$tion Control ($\\textbf{LaMo}$), a\ngeneral framework based on Decision Transformers to effectively use pre-trained\nLanguage Models (LMs) for offline RL. Our framework highlights four crucial\ncomponents: (1) Initializing Decision Transformers with sequentially\npre-trained LMs, (2) employing the LoRA fine-tuning method, in contrast to\nfull-weight fine-tuning, to combine the pre-trained knowledge from LMs and\nin-domain knowledge effectively, (3) using the non-linear MLP transformation\ninstead of linear projections, to generate embeddings, and (4) integrating an\nauxiliary language prediction loss during fine-tuning to stabilize the LMs and\nretain their original abilities on languages. Empirical results indicate\n$\\textbf{LaMo}$ achieves state-of-the-art performance in sparse-reward tasks\nand closes the gap between value-based offline RL methods and decision\ntransformers in dense-reward tasks. In particular, our method demonstrates\nsuperior performance in scenarios with limited data samples.",
            "author": [
                "Ruizhe Shi",
                "Yuyao Liu",
                "Yanjie Ze",
                "Simon S. Du",
                "Huazhe Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20587v4",
                "http://arxiv.org/pdf/2310.20587v4"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20586v1",
            "title": "Harmonization-enriched domain adaptation with light fine-tuning for\n  multiple sclerosis lesion segmentation",
            "updated": "2023-10-31T16:23:37Z",
            "published": "2023-10-31T16:23:37Z",
            "summary": "Deep learning algorithms utilizing magnetic resonance (MR) images have\ndemonstrated cutting-edge proficiency in autonomously segmenting multiple\nsclerosis (MS) lesions. Despite their achievements, these algorithms may\nstruggle to extend their performance across various sites or scanners, leading\nto domain generalization errors. While few-shot or one-shot domain adaptation\nemerges as a potential solution to mitigate generalization errors, its efficacy\nmight be hindered by the scarcity of labeled data in the target domain. This\npaper seeks to tackle this challenge by integrating one-shot adaptation data\nwith harmonized training data that incorporates labels. Our approach involves\nsynthesizing new training data with a contrast akin to that of the test domain,\na process we refer to as \"contrast harmonization\" in MRI. Our experiments\nillustrate that the amalgamation of one-shot adaptation data with harmonized\ntraining data surpasses the performance of utilizing either data source in\nisolation. Notably, domain adaptation using exclusively harmonized training\ndata achieved comparable or even superior performance compared to one-shot\nadaptation. Moreover, all adaptations required only minimal fine-tuning,\nranging from 2 to 5 epochs for convergence.",
            "author": [
                "Jinwei Zhang",
                "Lianrui Zuo",
                "Blake E. Dewey",
                "Samuel W. Remedios",
                "Savannah P. Hays",
                "Dzung L. Pham",
                "Jerry L. Prince",
                "Aaron Carass"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20586v1",
                "http://arxiv.org/pdf/2310.20586v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20581v1",
            "title": "Stochastic Gradient Descent for Gaussian Processes Done Right",
            "updated": "2023-10-31T16:15:13Z",
            "published": "2023-10-31T16:15:13Z",
            "summary": "We study the optimisation problem associated with Gaussian process regression\nusing squared loss. The most common approach to this problem is to apply an\nexact solver, such as conjugate gradient descent, either directly, or to a\nreduced-order version of the problem. Recently, driven by successes in deep\nlearning, stochastic gradient descent has gained traction as an alternative. In\nthis paper, we show that when done right$\\unicode{x2014}$by which we mean using\nspecific insights from the optimisation and kernel\ncommunities$\\unicode{x2014}$this approach is highly effective. We thus\nintroduce a particular stochastic dual gradient descent algorithm, that may be\nimplemented with a few lines of code using any deep learning framework. We\nexplain our design decisions by illustrating their advantage against\nalternatives with ablation studies and show that the new method is highly\ncompetitive. Our evaluations on standard regression benchmarks and a Bayesian\noptimisation task set our approach apart from preconditioned conjugate\ngradients, variational Gaussian process approximations, and a previous version\nof stochastic gradient descent for Gaussian processes. On a molecular binding\naffinity prediction task, our method places Gaussian process regression on par\nin terms of performance with state-of-the-art graph neural networks.",
            "author": [
                "Jihao Andreas Lin",
                "Shreyas Padhy",
                "Javier Antor\u00e1n",
                "Austin Tripp",
                "Alexander Terenin",
                "Csaba Szepesv\u00e1ri",
                "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
                "David Janz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20581v1",
                "http://arxiv.org/pdf/2310.20581v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20579v1",
            "title": "Initialization Matters: Privacy-Utility Analysis of Overparameterized\n  Neural Networks",
            "updated": "2023-10-31T16:13:22Z",
            "published": "2023-10-31T16:13:22Z",
            "summary": "We analytically investigate how over-parameterization of models in randomized\nmachine learning algorithms impacts the information leakage about their\ntraining data. Specifically, we prove a privacy bound for the KL divergence\nbetween model distributions on worst-case neighboring datasets, and explore its\ndependence on the initialization, width, and depth of fully connected neural\nnetworks. We find that this KL privacy bound is largely determined by the\nexpected squared gradient norm relative to model parameters during training.\nNotably, for the special setting of linearized network, our analysis indicates\nthat the squared gradient norm (and therefore the escalation of privacy loss)\nis tied directly to the per-layer variance of the initialization distribution.\nBy using this analysis, we demonstrate that privacy bound improves with\nincreasing depth under certain initializations (LeCun and Xavier), while\ndegrades with increasing depth under other initializations (He and NTK). Our\nwork reveals a complex interplay between privacy and depth that depends on the\nchosen initialization distribution. We further prove excess empirical risk\nbounds under a fixed KL privacy budget, and show that the interplay between\nprivacy utility trade-off and depth is similarly affected by the\ninitialization.",
            "author": [
                "Jiayuan Ye",
                "Zhenyu Zhu",
                "Fanghui Liu",
                "Reza Shokri",
                "Volkan Cevher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20579v1",
                "http://arxiv.org/pdf/2310.20579v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20574v1",
            "title": "Information-Theoretic Trust Regions for Stochastic Gradient-Based\n  Optimization",
            "updated": "2023-10-31T16:08:38Z",
            "published": "2023-10-31T16:08:38Z",
            "summary": "Stochastic gradient-based optimization is crucial to optimize neural\nnetworks. While popular approaches heuristically adapt the step size and\ndirection by rescaling gradients, a more principled approach to improve\noptimizers requires second-order information. Such methods precondition the\ngradient using the objective's Hessian. Yet, computing the Hessian is usually\nexpensive and effectively using second-order information in the stochastic\ngradient setting is non-trivial. We propose using Information-Theoretic Trust\nRegion Optimization (arTuRO) for improved updates with uncertain second-order\ninformation. By modeling the network parameters as a Gaussian distribution and\nusing a Kullback-Leibler divergence-based trust region, our approach takes\nbounded steps accounting for the objective's curvature and uncertainty in the\nparameters. Before each update, it solves the trust region problem for an\noptimal step size, resulting in a more stable and faster optimization process.\nWe approximate the diagonal elements of the Hessian from stochastic gradients\nusing a simple recursive least squares approach, constructing a model of the\nexpected Hessian over time using only first-order information. We show that\narTuRO combines the fast convergence of adaptive moment-based optimization with\nthe generalization capabilities of SGD.",
            "author": [
                "Philipp Dahlinger",
                "Philipp Becker",
                "Maximilian H\u00fcttenrauch",
                "Gerhard Neumann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20574v1",
                "http://arxiv.org/pdf/2310.20574v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20568v1",
            "title": "Uncertainty Learning for LTI Systems with Stability Guarantees",
            "updated": "2023-10-31T15:56:56Z",
            "published": "2023-10-31T15:56:56Z",
            "summary": "We present a framework for learning of modeling uncertainties in Linear Time\nInvariant (LTI) systems. We propose a methodology to extend the dynamics of an\nLTI (without uncertainty) with an uncertainty model, based on measured data, to\nimprove the predictive capacity of the model in the input-output sense. The\nproposed framework guarantees stability of the extended model. To achieve this,\ntwo semi-definite programs are provided that allow obtaining optimal\nuncertainty model parameters, given state and uncertainty data. To obtain this\ndata from available input-output trajectory data, we introduce a filter in\nwhich an internal model of uncertainty is proposed. This filter is also\ndesigned via a semi-definite program with guaranteed robustness with respect to\nuncertainty model mismatches, disturbances, and noise. Numerical simulations\nare presented to illustrate the effectiveness and practicality of the proposed\nmethodology in improving model accuracy, while warranting model stability.",
            "author": [
                "Farhad Ghanipoor",
                "Carlos Murguia",
                "Peyman Mohajerin Esfahani",
                "Nathan van de Wouw"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20568v1",
                "http://arxiv.org/pdf/2310.20568v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20567v2",
            "title": "One-shot backpropagation for multi-step prediction in physics-based\n  system identification -- EXTENDED VERSION",
            "updated": "2023-11-21T09:19:06Z",
            "published": "2023-10-31T15:56:17Z",
            "summary": "The aim of this paper is to present a novel physics-based framework for the\nidentification of dynamical systems, in which the physical and structural\ninsights are reflected directly into a backpropagation-based learning\nalgorithm. The main result is a method to compute in closed form the gradient\nof a multi-step loss function, while enforcing physical properties and\nconstraints. The derived algorithm has been exploited to identify the unknown\ninertia matrix of a space debris, and the results show the reliability of the\nmethod in capturing the physical adherence of the estimated parameters.",
            "author": [
                "Cesare Donati",
                "Martina Mammarella",
                "Fabrizio Dabbene",
                "Carlo Novara",
                "Constantino Lagoa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20567v2",
                "http://arxiv.org/pdf/2310.20567v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20552v1",
            "title": "Privacy-preserving design of graph neural networks with applications to\n  vertical federated learning",
            "updated": "2023-10-31T15:34:59Z",
            "published": "2023-10-31T15:34:59Z",
            "summary": "The paradigm of vertical federated learning (VFL), where institutions\ncollaboratively train machine learning models via combining each other's local\nfeature or label information, has achieved great success in applications to\nfinancial risk management (FRM). The surging developments of graph\nrepresentation learning (GRL) have opened up new opportunities for FRM\napplications under FL via efficiently utilizing the graph-structured data\ngenerated from underlying transaction networks. Meanwhile, transaction\ninformation is often considered highly sensitive. To prevent data leakage\nduring training, it is critical to develop FL protocols with formal privacy\nguarantees. In this paper, we present an end-to-end GRL framework in the VFL\nsetting called VESPER, which is built upon a general privatization scheme\ntermed perturbed message passing (PMP) that allows the privatization of many\npopular graph neural architectures.Based on PMP, we discuss the strengths and\nweaknesses of specific design choices of concrete graph neural architectures\nand provide solutions and improvements for both dense and sparse graphs.\nExtensive empirical evaluations over both public datasets and an industry\ndataset demonstrate that VESPER is capable of training high-performance GNN\nmodels over both sparse and dense graphs under reasonable privacy budgets.",
            "author": [
                "Ruofan Wu",
                "Mingyang Zhang",
                "Lingjuan Lyu",
                "Xiaolong Xu",
                "Xiuquan Hao",
                "Xinyi Fu",
                "Tengfei Liu",
                "Tianyi Zhang",
                "Weiqiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20552v1",
                "http://arxiv.org/pdf/2310.20552v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20550v2",
            "title": "CapsFusion: Rethinking Image-Text Data at Scale",
            "updated": "2023-11-02T11:25:20Z",
            "published": "2023-10-31T15:31:39Z",
            "summary": "Large multimodal models demonstrate remarkable generalist ability to perform\ndiverse multimodal tasks in a zero-shot manner. Large-scale web-based\nimage-text pairs contribute fundamentally to this success, but suffer from\nexcessive noise. Recent studies use alternative captions synthesized by\ncaptioning models and have achieved notable benchmark performance. However, our\nexperiments reveal significant Scalability Deficiency and World Knowledge Loss\nissues in models trained with synthetic captions, which have been largely\nobscured by their initial benchmark success. Upon closer examination, we\nidentify the root cause as the overly-simplified language structure and lack of\nknowledge details in existing synthetic captions. To provide higher-quality and\nmore scalable multimodal pretraining data, we propose CapsFusion, an advanced\nframework that leverages large language models to consolidate and refine\ninformation from both web-based image-text pairs and synthetic captions.\nExtensive experiments show that CapsFusion captions exhibit remarkable\nall-round superiority over existing captions in terms of model performance\n(e.g., 18.8 and 18.3 improvements in CIDEr score on COCO and NoCaps), sample\nefficiency (requiring 11-16 times less computation than baselines), world\nknowledge depth, and scalability. These effectiveness, efficiency and\nscalability advantages position CapsFusion as a promising candidate for future\nscaling of LMM training.",
            "author": [
                "Qiying Yu",
                "Quan Sun",
                "Xiaosong Zhang",
                "Yufeng Cui",
                "Fan Zhang",
                "Yue Cao",
                "Xinlong Wang",
                "Jingjing Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20550v2",
                "http://arxiv.org/pdf/2310.20550v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20545v1",
            "title": "Multi-task learning of convex combinations of forecasting models",
            "updated": "2023-10-31T15:26:33Z",
            "published": "2023-10-31T15:26:33Z",
            "summary": "Forecast combination involves using multiple forecasts to create a single,\nmore accurate prediction. Recently, feature-based forecasting has been employed\nto either select the most appropriate forecasting models or to learn the\nweights of their convex combination. In this paper, we present a multi-task\nlearning methodology that simultaneously addresses both problems. This approach\nis implemented through a deep neural network with two branches: the regression\nbranch, which learns the weights of various forecasting methods by minimizing\nthe error of combined forecasts, and the classification branch, which selects\nforecasting methods with an emphasis on their diversity. To generate training\nlabels for the classification task, we introduce an optimization-driven\napproach that identifies the most appropriate methods for a given time series.\nThe proposed approach elicits the essential role of diversity in feature-based\nforecasting and highlights the interplay between model combination and model\nselection when learning forecasting ensembles. Experimental results on a large\nset of series from the M4 competition dataset show that our proposal enhances\npoint forecast accuracy compared to state-of-the-art methods.",
            "author": [
                "Giovanni Felici",
                "Antonio M. Sudoso"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20545v1",
                "http://arxiv.org/pdf/2310.20545v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20537v1",
            "title": "Directed Cyclic Graph for Causal Discovery from Multivariate Functional\n  Data",
            "updated": "2023-10-31T15:19:24Z",
            "published": "2023-10-31T15:19:24Z",
            "summary": "Discovering causal relationship using multivariate functional data has\nreceived a significant amount of attention very recently. In this article, we\nintroduce a functional linear structural equation model for causal structure\nlearning when the underlying graph involving the multivariate functions may\nhave cycles. To enhance interpretability, our model involves a low-dimensional\ncausal embedded space such that all the relevant causal information in the\nmultivariate functional data is preserved in this lower-dimensional subspace.\nWe prove that the proposed model is causally identifiable under standard\nassumptions that are often made in the causal discovery literature. To carry\nout inference of our model, we develop a fully Bayesian framework with suitable\nprior specifications and uncertainty quantification through posterior\nsummaries. We illustrate the superior performance of our method over existing\nmethods in terms of causal graph estimation through extensive simulation\nstudies. We also demonstrate the proposed method using a brain EEG dataset.",
            "author": [
                "Saptarshi Roy",
                "Raymond K. W. Wong",
                "Yang Ni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20537v1",
                "http://arxiv.org/pdf/2310.20537v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20524v1",
            "title": "Group-Feature (Sensor) Selection With Controlled Redundancy Using Neural\n  Networks",
            "updated": "2023-10-31T15:04:53Z",
            "published": "2023-10-31T15:04:53Z",
            "summary": "In this paper, we present a novel embedded feature selection method based on\na Multi-layer Perceptron (MLP) network and generalize it for group-feature or\nsensor selection problems, which can control the level of redundancy among the\nselected features or groups. Additionally, we have generalized the group lasso\npenalty for feature selection to encompass a mechanism for selecting valuable\ngroup features while simultaneously maintaining a control over redundancy. We\nestablish the monotonicity and convergence of the proposed algorithm, with a\nsmoothed version of the penalty terms, under suitable assumptions. Experimental\nresults on several benchmark datasets demonstrate the promising performance of\nthe proposed methodology for both feature selection and group feature selection\nover some state-of-the-art methods.",
            "author": [
                "Aytijhya Saha",
                "Nikhil R. Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20524v1",
                "http://arxiv.org/pdf/2310.20524v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20508v1",
            "title": "Parametric Fairness with Statistical Guarantees",
            "updated": "2023-10-31T14:52:39Z",
            "published": "2023-10-31T14:52:39Z",
            "summary": "Algorithmic fairness has gained prominence due to societal and regulatory\nconcerns about biases in Machine Learning models. Common group fairness metrics\nlike Equalized Odds for classification or Demographic Parity for both\nclassification and regression are widely used and a host of computationally\nadvantageous post-processing methods have been developed around them. However,\nthese metrics often limit users from incorporating domain knowledge. Despite\nmeeting traditional fairness criteria, they can obscure issues related to\nintersectional fairness and even replicate unwanted intra-group biases in the\nresulting fair solution. To avoid this narrow perspective, we extend the\nconcept of Demographic Parity to incorporate distributional properties in the\npredictions, allowing expert knowledge to be used in the fair solution. We\nillustrate the use of this new metric through a practical example of wages, and\ndevelop a parametric method that efficiently addresses practical challenges\nlike limited training data and constraints on total spending, offering a robust\nsolution for real-life applications.",
            "author": [
                "Fran\u00e7ois HU",
                "Philipp Ratz",
                "Arthur Charpentier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20508v1",
                "http://arxiv.org/pdf/2310.20508v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20498v1",
            "title": "Generative Learning of Continuous Data by Tensor Networks",
            "updated": "2023-10-31T14:37:37Z",
            "published": "2023-10-31T14:37:37Z",
            "summary": "Beyond their origin in modeling many-body quantum systems, tensor networks\nhave emerged as a promising class of models for solving machine learning\nproblems, notably in unsupervised generative learning. While possessing many\ndesirable features arising from their quantum-inspired nature, tensor network\ngenerative models have previously been largely restricted to binary or\ncategorical data, limiting their utility in real-world modeling problems. We\novercome this by introducing a new family of tensor network generative models\nfor continuous data, which are capable of learning from distributions\ncontaining continuous random variables. We develop our method in the setting of\nmatrix product states, first deriving a universal expressivity theorem proving\nthe ability of this model family to approximate any reasonably smooth\nprobability density function with arbitrary precision. We then benchmark the\nperformance of this model on several synthetic and real-world datasets, finding\nthat the model learns and generalizes well on distributions of continuous and\ndiscrete variables. We develop methods for modeling different data domains, and\nintroduce a trainable compression layer which is found to increase model\nperformance given limited memory or computational resources. Overall, our\nmethods give important theoretical and empirical evidence of the efficacy of\nquantum-inspired methods for the rapidly growing field of generative learning.",
            "author": [
                "Alex Meiburg",
                "Jing Chen",
                "Jacob Miller",
                "Rapha\u00eblle Tihon",
                "Guillaume Rabusseau",
                "Alejandro Perdomo-Ortiz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20498v1",
                "http://arxiv.org/pdf/2310.20498v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.stat-mech",
                "quant-ph",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20496v1",
            "title": "BasisFormer: Attention-based Time Series Forecasting with Learnable and\n  Interpretable Basis",
            "updated": "2023-10-31T14:34:00Z",
            "published": "2023-10-31T14:34:00Z",
            "summary": "Bases have become an integral part of modern deep learning-based models for\ntime series forecasting due to their ability to act as feature extractors or\nfuture references. To be effective, a basis must be tailored to the specific\nset of time series data and exhibit distinct correlation with each time series\nwithin the set. However, current state-of-the-art methods are limited in their\nability to satisfy both of these requirements simultaneously. To address this\nchallenge, we propose BasisFormer, an end-to-end time series forecasting\narchitecture that leverages learnable and interpretable bases. This\narchitecture comprises three components: First, we acquire bases through\nadaptive self-supervised learning, which treats the historical and future\nsections of the time series as two distinct views and employs contrastive\nlearning. Next, we design a Coef module that calculates the similarity\ncoefficients between the time series and bases in the historical view via\nbidirectional cross-attention. Finally, we present a Forecast module that\nselects and consolidates the bases in the future view based on the similarity\ncoefficients, resulting in accurate future predictions. Through extensive\nexperiments on six datasets, we demonstrate that BasisFormer outperforms\nprevious state-of-the-art methods by 11.04\\% and 15.78\\% respectively for\nunivariate and multivariate forecasting tasks. Code is available at:\n\\url{https://github.com/nzl5116190/Basisformer}",
            "author": [
                "Zelin Ni",
                "Hang Yu",
                "Shizhan Liu",
                "Jianguo Li",
                "Weiyao Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20496v1",
                "http://arxiv.org/pdf/2310.20496v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20494v1",
            "title": "A Transformer-Based Model With Self-Distillation for Multimodal Emotion\n  Recognition in Conversations",
            "updated": "2023-10-31T14:33:30Z",
            "published": "2023-10-31T14:33:30Z",
            "summary": "Emotion recognition in conversations (ERC), the task of recognizing the\nemotion of each utterance in a conversation, is crucial for building empathetic\nmachines. Existing studies focus mainly on capturing context- and\nspeaker-sensitive dependencies on the textual modality but ignore the\nsignificance of multimodal information. Different from emotion recognition in\ntextual conversations, capturing intra- and inter-modal interactions between\nutterances, learning weights between different modalities, and enhancing modal\nrepresentations play important roles in multimodal ERC. In this paper, we\npropose a transformer-based model with self-distillation (SDT) for the task.\nThe transformer-based model captures intra- and inter-modal interactions by\nutilizing intra- and inter-modal transformers, and learns weights between\nmodalities dynamically by designing a hierarchical gated fusion strategy.\nFurthermore, to learn more expressive modal representations, we treat soft\nlabels of the proposed model as extra training supervision. Specifically, we\nintroduce self-distillation to transfer knowledge of hard and soft labels from\nthe proposed model to each modality. Experiments on IEMOCAP and MELD datasets\ndemonstrate that SDT outperforms previous state-of-the-art baselines.",
            "author": [
                "Hui Ma",
                "Jian Wang",
                "Hongfei Lin",
                "Bo Zhang",
                "Yijia Zhang",
                "Bo Xu"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TMM.2023.3271019",
                "http://arxiv.org/abs/2310.20494v1",
                "http://arxiv.org/pdf/2310.20494v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20493v1",
            "title": "Requirement falsification for cyber-physical systems using generative\n  models",
            "updated": "2023-10-31T14:32:54Z",
            "published": "2023-10-31T14:32:54Z",
            "summary": "We present the OGAN algorithm for automatic requirement falsification of\ncyber-physical systems. System inputs and output are represented as piecewise\nconstant signals over time while requirements are expressed in signal temporal\nlogic. OGAN can find inputs that are counterexamples for the safety of a system\nrevealing design, software, or hardware defects before the system is taken into\noperation. The OGAN algorithm works by training a generative machine learning\nmodel to produce such counterexamples. It executes tests atomically and does\nnot require any previous model of the system under test. We evaluate OGAN using\nthe ARCH-COMP benchmark problems, and the experimental results show that\ngenerative models are a viable method for requirement falsification. OGAN can\nbe applied to new systems with little effort, has few requirements for the\nsystem under test, and exhibits state-of-the-art CPS falsification efficiency\nand effectiveness.",
            "author": [
                "Jarkko Peltom\u00e4ki",
                "Ivan Porres"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20493v1",
                "http://arxiv.org/pdf/2310.20493v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20492v1",
            "title": "Log-based Anomaly Detection of Enterprise Software: An Empirical Study",
            "updated": "2023-10-31T14:32:08Z",
            "published": "2023-10-31T14:32:08Z",
            "summary": "Most enterprise applications use logging as a mechanism to diagnose\nanomalies, which could help with reducing system downtime. Anomaly detection\nusing software execution logs has been explored in several prior studies, using\nboth classical and deep neural network-based machine learning models. In recent\nyears, the research has largely focused in using variations of sequence-based\ndeep neural networks (e.g., Long-Short Term Memory and Transformer-based\nmodels) for log-based anomaly detection on open-source data. However, they have\nnot been applied in industrial datasets, as often. In addition, the studied\nopen-source datasets are typically very large in size with logging statements\nthat do not change much over time, which may not be the case with a dataset\nfrom an industrial service that is relatively new. In this paper, we evaluate\nseveral state-of-the-art anomaly detection models on an industrial dataset from\nour research partner, which is much smaller and loosely structured than most\nlarge scale open-source benchmark datasets. Results show that while all models\nare capable of detecting anomalies, certain models are better suited for\nless-structured datasets. We also see that model effectiveness changes when a\ncommon data leak associated with a random train-test split in some prior work\nis removed. A qualitative study of the defects' characteristics identified by\nthe developers on the industrial dataset further shows strengths and weaknesses\nof the models in detecting different types of anomalies. Finally, we explore\nthe effect of limited training data by gradually increasing the training set\nsize, to evaluate if the model effectiveness does depend on the training set\nsize.",
            "author": [
                "Nadun Wijesinghe",
                "Hadi Hemmati"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20492v1",
                "http://arxiv.org/pdf/2310.20492v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SE",
                "I.5.2; I.5.1; I.5.4; I.2.7; I.2.6; D.2.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20491v1",
            "title": "Collaborative Decision-Making Using Spatiotemporal Graphs in Connected\n  Autonomy",
            "updated": "2023-10-31T14:30:39Z",
            "published": "2023-10-31T14:30:39Z",
            "summary": "Collaborative decision-making is an essential capability for multi-robot\nsystems, such as connected vehicles, to collaboratively control autonomous\nvehicles in accident-prone scenarios. Under limited communication bandwidth,\ncapturing comprehensive situational awareness by integrating connected agents'\nobservation is very challenging. In this paper, we propose a novel\ncollaborative decision-making method that efficiently and effectively\nintegrates collaborators' representations to control the ego vehicle in\naccident-prone scenarios. Our approach formulates collaborative decision-making\nas a classification problem. We first represent sequences of raw observations\nas spatiotemporal graphs, which significantly reduce the package size to share\namong connected vehicles. Then we design a novel spatiotemporal graph neural\nnetwork based on heterogeneous graph learning, which analyzes spatial and\ntemporal connections of objects in a unified way for collaborative\ndecision-making. We evaluate our approach using a high-fidelity simulator that\nconsiders realistic traffic, communication bandwidth, and vehicle sensing among\nconnected autonomous vehicles. The experimental results show that our\nrepresentation achieves over 100x reduction in the shared data size that meets\nthe requirements of communication bandwidth for connected autonomous driving.\nIn addition, our approach achieves over 30% improvements in driving safety.",
            "author": [
                "Peng Gao",
                "Yu Shen",
                "Ming C. Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20491v1",
                "http://arxiv.org/pdf/2310.20491v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20490v2",
            "title": "Long-Tailed Learning as Multi-Objective Optimization",
            "updated": "2023-11-01T11:28:55Z",
            "published": "2023-10-31T14:30:31Z",
            "summary": "Real-world data is extremely imbalanced and presents a long-tailed\ndistribution, resulting in models that are biased towards classes with\nsufficient samples and perform poorly on rare classes. Recent methods propose\nto rebalance classes but they undertake the seesaw dilemma (what is increasing\nperformance on tail classes may decrease that of head classes, and vice versa).\nIn this paper, we argue that the seesaw dilemma is derived from gradient\nimbalance of different classes, in which gradients of inappropriate classes are\nset to important for updating, thus are prone to overcompensation or\nundercompensation on tail classes. To achieve ideal compensation, we formulate\nthe long-tailed recognition as an multi-objective optimization problem, which\nfairly respects the contributions of head and tail classes simultaneously. For\nefficiency, we propose a Gradient-Balancing Grouping (GBG) strategy to gather\nthe classes with similar gradient directions, thus approximately make every\nupdate under a Pareto descent direction. Our GBG method drives classes with\nsimilar gradient directions to form more representative gradient and provide\nideal compensation to the tail classes. Moreover, We conduct extensive\nexperiments on commonly used benchmarks in long-tailed learning and demonstrate\nthe superiority of our method over existing SOTA methods.",
            "author": [
                "Weiqi Li",
                "Fan Lyu",
                "Fanhua Shang",
                "Liang Wan",
                "Wei Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20490v2",
                "http://arxiv.org/pdf/2310.20490v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20488v1",
            "title": "NaijaCoder: Participatory Design for Early Algorithms Education in the\n  Global South",
            "updated": "2023-10-31T14:28:51Z",
            "published": "2023-10-31T14:28:51Z",
            "summary": "The majority of Nigerian high schoolers have little to no exposure to the\nbasics of algorithms and programming. We believe this trajectory should change\nas programming offers these students, especially those from indigent\nbackgrounds, an opportunity to learn profitable skills and ignite their\npassions for problem-solving and critical thinking.\n  NaijaCoder is an organization that is dedicated to organizing a free,\nintensive summer program in Nigeria to teach the basics of algorithms and\ncomputer programming to high schoolers. However, the adoption of computer\nscience curriculum has been especially challenging in countries in the global\nsouth that face unique challenges -- such as unstable power supply, internet\nservice, and price volatility. We design a curriculum that is more conducive to\nthe local environment while incorporating rigorous thinking and preparation.\nUsing basic survey designs, we elicit feedback, from the students, designed to\nfurther improve and iterate on our curriculum.",
            "author": [
                "Daniel Alabi",
                "Atinuke Adegbile",
                "Lekan Afuye",
                "Philip Abel",
                "Alida Monaco"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20488v1",
                "http://arxiv.org/pdf/2310.20488v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20487v1",
            "title": "Large Language Model Can Interpret Latent Space of Sequential\n  Recommender",
            "updated": "2023-10-31T14:28:47Z",
            "published": "2023-10-31T14:28:47Z",
            "summary": "Sequential recommendation is to predict the next item of interest for a user,\nbased on her/his interaction history with previous items. In conventional\nsequential recommenders, a common approach is to model item sequences using\ndiscrete IDs, learning representations that encode sequential behaviors and\nreflect user preferences. Inspired by recent success in empowering large\nlanguage models (LLMs) to understand and reason over diverse modality data\n(e.g., image, audio, 3D points), a compelling research question arises: ``Can\nLLMs understand and work with hidden representations from ID-based sequential\nrecommenders?''.To answer this, we propose a simple framework, RecInterpreter,\nwhich examines the capacity of open-source LLMs to decipher the representation\nspace of sequential recommenders. Specifically, with the multimodal pairs (\\ie\nrepresentations of interaction sequence and text narrations), RecInterpreter\nfirst uses a lightweight adapter to map the representations into the token\nembedding space of the LLM. Subsequently, it constructs a sequence-recovery\nprompt that encourages the LLM to generate textual descriptions for items\nwithin the interaction sequence. Taking a step further, we propose a\nsequence-residual prompt instead, which guides the LLM in identifying the\nresidual item by contrasting the representations before and after integrating\nthis residual into the existing sequence. Empirical results showcase that our\nRecInterpreter enhances the exemplar LLM, LLaMA, to understand hidden\nrepresentations from ID-based sequential recommenders, especially when guided\nby our sequence-residual prompts. Furthermore, RecInterpreter enables LLaMA to\ninstantiate the oracle items generated by generative recommenders like\nDreamRec, concreting the item a user would ideally like to interact with next.\nCodes are available at https://github.com/YangZhengyi98/RecInterpreter.",
            "author": [
                "Zhengyi Yang",
                "Jiancan Wu",
                "Yanchen Luo",
                "Jizhi Zhang",
                "Yancheng Yuan",
                "An Zhang",
                "Xiang Wang",
                "Xiangnan He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20487v1",
                "http://arxiv.org/pdf/2310.20487v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20478v1",
            "title": "Unveiling Black-boxes: Explainable Deep Learning Models for Patent\n  Classification",
            "updated": "2023-10-31T14:11:37Z",
            "published": "2023-10-31T14:11:37Z",
            "summary": "Recent technological advancements have led to a large number of patents in a\ndiverse range of domains, making it challenging for human experts to analyze\nand manage. State-of-the-art methods for multi-label patent classification rely\non deep neural networks (DNNs), which are complex and often considered\nblack-boxes due to their opaque decision-making processes. In this paper, we\npropose a novel deep explainable patent classification framework by introducing\nlayer-wise relevance propagation (LRP) to provide human-understandable\nexplanations for predictions. We train several DNN models, including Bi-LSTM,\nCNN, and CNN-BiLSTM, and propagate the predictions backward from the output\nlayer up to the input layer of the model to identify the relevance of words for\nindividual predictions. Considering the relevance score, we then generate\nexplanations by visualizing relevant words for the predicted patent class.\nExperimental results on two datasets comprising two-million patent texts\ndemonstrate high performance in terms of various evaluation measures. The\nexplanations generated for each prediction highlight important relevant words\nthat align with the predicted class, making the prediction more understandable.\nExplainable systems have the potential to facilitate the adoption of complex\nAI-enabled methods for patent classification in real-world applications.",
            "author": [
                "Md Shajalal",
                "Sebastian Denef",
                "Md. Rezaul Karim",
                "Alexander Boden",
                "Gunnar Stevens"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-44067-0_24",
                "http://arxiv.org/abs/2310.20478v1",
                "http://arxiv.org/pdf/2310.20478v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20477v2",
            "title": "Exploring Practitioner Perspectives On Training Data Attribution\n  Explanations",
            "updated": "2023-11-22T09:57:54Z",
            "published": "2023-10-31T14:10:30Z",
            "summary": "Explainable AI (XAI) aims to provide insight into opaque model reasoning to\nhumans and as such is an interdisciplinary field by nature. In this paper, we\ninterviewed 10 practitioners to understand the possible usability of training\ndata attribution (TDA) explanations and to explore the design space of such an\napproach. We confirmed that training data quality is often the most important\nfactor for high model performance in practice and model developers mainly rely\non their own experience to curate data. End-users expect explanations to\nenhance their interaction with the model and do not necessarily prioritise but\nare open to training data as a means of explanation. Within our participants,\nwe found that TDA explanations are not well-known and therefore not used. We\nurge the community to focus on the utility of TDA techniques from the\nhuman-machine collaboration perspective and broaden the TDA evaluation to\nreflect common use cases in practice.",
            "author": [
                "Elisa Nguyen",
                "Evgenii Kortukov",
                "Jean Y. Song",
                "Seong Joon Oh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20477v2",
                "http://arxiv.org/pdf/2310.20477v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20476v1",
            "title": "Global Transformer Architecture for Indoor Room Temperature Forecasting",
            "updated": "2023-10-31T14:09:32Z",
            "published": "2023-10-31T14:09:32Z",
            "summary": "A thorough regulation of building energy systems translates in relevant\nenergy savings and in a better comfort for the occupants. Algorithms to predict\nthe thermal state of a building on a certain time horizon with a good\nconfidence are essential for the implementation of effective control systems.\nThis work presents a global Transformer architecture for indoor temperature\nforecasting in multi-room buildings, aiming at optimizing energy consumption\nand reducing greenhouse gas emissions associated with HVAC systems. Recent\nadvancements in deep learning have enabled the development of more\nsophisticated forecasting models compared to traditional feedback control\nsystems. The proposed global Transformer architecture can be trained on the\nentire dataset encompassing all rooms, eliminating the need for multiple\nroom-specific models, significantly improving predictive performance, and\nsimplifying deployment and maintenance. Notably, this study is the first to\napply a Transformer architecture for indoor temperature forecasting in\nmulti-room buildings. The proposed approach provides a novel solution to\nenhance the accuracy and efficiency of temperature forecasting, serving as a\nvaluable tool to optimize energy consumption and decrease greenhouse gas\nemissions in the building sector.",
            "author": [
                "Alfredo V Clemente",
                "Alessandro Nocente",
                "Massimiliano Ruocco"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20476v1",
                "http://arxiv.org/pdf/2310.20476v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20475v1",
            "title": "Linked Papers With Code: The Latest in Machine Learning as an RDF\n  Knowledge Graph",
            "updated": "2023-10-31T14:09:15Z",
            "published": "2023-10-31T14:09:15Z",
            "summary": "In this paper, we introduce Linked Papers With Code (LPWC), an RDF knowledge\ngraph that provides comprehensive, current information about almost 400,000\nmachine learning publications. This includes the tasks addressed, the datasets\nutilized, the methods implemented, and the evaluations conducted, along with\ntheir results. Compared to its non-RDF-based counterpart Papers With Code, LPWC\nnot only translates the latest advancements in machine learning into RDF\nformat, but also enables novel ways for scientific impact quantification and\nscholarly key content recommendation. LPWC is openly accessible at\nhttps://linkedpaperswithcode.com and is licensed under CC-BY-SA 4.0. As a\nknowledge graph in the Linked Open Data cloud, we offer LPWC in multiple\nformats, from RDF dump files to a SPARQL endpoint for direct web queries, as\nwell as a data source with resolvable URIs and links to the data sources\nSemOpenAlex, Wikidata, and DBLP. Additionally, we supply knowledge graph\nembeddings, enabling LPWC to be readily applied in machine learning\napplications.",
            "author": [
                "Michael F\u00e4rber",
                "David Lamprecht"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20475v1",
                "http://arxiv.org/pdf/2310.20475v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20469v1",
            "title": "Amoeba: Circumventing ML-supported Network Censorship via Adversarial\n  Reinforcement Learning",
            "updated": "2023-10-31T14:01:24Z",
            "published": "2023-10-31T14:01:24Z",
            "summary": "Embedding covert streams into a cover channel is a common approach to\ncircumventing Internet censorship, due to censors' inability to examine\nencrypted information in otherwise permitted protocols (Skype, HTTPS, etc.).\nHowever, recent advances in machine learning (ML) enable detecting a range of\nanti-censorship systems by learning distinct statistical patterns hidden in\ntraffic flows. Therefore, designing obfuscation solutions able to generate\ntraffic that is statistically similar to innocuous network activity, in order\nto deceive ML-based classifiers at line speed, is difficult.\n  In this paper, we formulate a practical adversarial attack strategy against\nflow classifiers as a method for circumventing censorship. Specifically, we\ncast the problem of finding adversarial flows that will be misclassified as a\nsequence generation task, which we solve with Amoeba, a novel reinforcement\nlearning algorithm that we design. Amoeba works by interacting with censoring\nclassifiers without any knowledge of their model structure, but by crafting\npackets and observing the classifiers' decisions, in order to guide the\nsequence generation process. Our experiments using data collected from two\npopular anti-censorship systems demonstrate that Amoeba can effectively shape\nadversarial flows that have on average 94% attack success rate against a range\nof ML algorithms. In addition, we show that these adversarial flows are robust\nin different network environments and possess transferability across various ML\nmodels, meaning that once trained against one, our agent can subvert other\ncensoring classifiers without retraining.",
            "author": [
                "Haoyu Liu",
                "Alec F. Diallo",
                "Paul Patras"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3629131",
                "http://arxiv.org/abs/2310.20469v1",
                "http://arxiv.org/pdf/2310.20469v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20463v2",
            "title": "Interpretable Neural PDE Solvers using Symbolic Frameworks",
            "updated": "2023-11-10T12:15:33Z",
            "published": "2023-10-31T13:56:25Z",
            "summary": "Partial differential equations (PDEs) are ubiquitous in the world around us,\nmodelling phenomena from heat and sound to quantum systems. Recent advances in\ndeep learning have resulted in the development of powerful neural solvers;\nhowever, while these methods have demonstrated state-of-the-art performance in\nboth accuracy and computational efficiency, a significant challenge remains in\ntheir interpretability. Most existing methodologies prioritize predictive\naccuracy over clarity in the underlying mechanisms driving the model's\ndecisions. Interpretability is crucial for trustworthiness and broader\napplicability, especially in scientific and engineering domains where neural\nPDE solvers might see the most impact. In this context, a notable gap in\ncurrent research is the integration of symbolic frameworks (such as symbolic\nregression) into these solvers. Symbolic frameworks have the potential to\ndistill complex neural operations into human-readable mathematical expressions,\nbridging the divide between black-box predictions and solutions.",
            "author": [
                "Yolanne Yi Ran Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20463v2",
                "http://arxiv.org/pdf/2310.20463v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20458v1",
            "title": "Machine learning detects terminal singularities",
            "updated": "2023-10-31T13:51:24Z",
            "published": "2023-10-31T13:51:24Z",
            "summary": "Algebraic varieties are the geometric shapes defined by systems of polynomial\nequations; they are ubiquitous across mathematics and science. Amongst these\nalgebraic varieties are Q-Fano varieties: positively curved shapes which have\nQ-factorial terminal singularities. Q-Fano varieties are of fundamental\nimportance in geometry as they are \"atomic pieces\" of more complex shapes - the\nprocess of breaking a shape into simpler pieces in this sense is called the\nMinimal Model Programme. Despite their importance, the classification of Q-Fano\nvarieties remains unknown. In this paper we demonstrate that machine learning\ncan be used to understand this classification. We focus on 8-dimensional\npositively-curved algebraic varieties that have toric symmetry and Picard rank\n2, and develop a neural network classifier that predicts with 95% accuracy\nwhether or not such an algebraic variety is Q-Fano. We use this to give a first\nsketch of the landscape of Q-Fanos in dimension 8. How the neural network is\nable to detect Q-Fano varieties with such accuracy remains mysterious, and\nhints at some deep mathematical theory waiting to be uncovered. Furthermore,\nwhen visualised using the quantum period, an invariant that has played an\nimportant role in recent theoretical developments, we observe that the\nclassification as revealed by ML appears to fall within a bounded region, and\nis stratified by the Fano index. This suggests that it may be possible to state\nand prove conjectures on completeness in the future. Inspired by the ML\nanalysis, we formulate and prove a new global combinatorial criterion for a\npositively curved toric variety of Picard rank 2 to have terminal\nsingularities. Together with the first sketch of the landscape of Q-Fanos in\nhigher dimensions, this gives new evidence that machine learning can be an\nessential tool in developing mathematical conjectures and accelerating\ntheoretical discovery.",
            "author": [
                "Tom Coates",
                "Alexander M. Kasprzyk",
                "Sara Veneziale"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20458v1",
                "http://arxiv.org/pdf/2310.20458v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "cs.LG",
                "14J45 (Primary), 68T07 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20457v2",
            "title": "FlexTrain: A Dynamic Training Framework for Heterogeneous Devices\n  Environments",
            "updated": "2023-11-23T09:58:55Z",
            "published": "2023-10-31T13:51:13Z",
            "summary": "As deep learning models become increasingly large, they pose significant\nchallenges in heterogeneous devices environments. The size of deep learning\nmodels makes it difficult to deploy them on low-power or resource-constrained\ndevices, leading to long inference times and high energy consumption. To\naddress these challenges, we propose FlexTrain, a framework that accommodates\nthe diverse storage and computational resources available on different devices\nduring the training phase. FlexTrain enables efficient deployment of deep\nlearning models, while respecting device constraints, minimizing communication\ncosts, and ensuring seamless integration with diverse devices. We demonstrate\nthe effectiveness of FlexTrain on the CIFAR-100 dataset, where a single global\nmodel trained with FlexTrain can be easily deployed on heterogeneous devices,\nsaving training time and energy consumption. We also extend FlexTrain to the\nfederated learning setting, showing that our approach outperforms standard\nfederated learning benchmarks on both CIFAR-10 and CIFAR-100 datasets.",
            "author": [
                "Mert Unsal",
                "Ali Maatouk",
                "Antonio De Domenico",
                "Nicola Piovesan",
                "Fadhel Ayed"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20457v2",
                "http://arxiv.org/pdf/2310.20457v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20453v1",
            "title": "Generate What You Prefer: Reshaping Sequential Recommendation via Guided\n  Diffusion",
            "updated": "2023-10-31T13:45:39Z",
            "published": "2023-10-31T13:45:39Z",
            "summary": "Sequential recommendation aims to recommend the next item that matches a\nuser's interest, based on the sequence of items he/she interacted with before.\nScrutinizing previous studies, we can summarize a common learning-to-classify\nparadigm -- given a positive item, a recommender model performs negative\nsampling to add negative items and learns to classify whether the user prefers\nthem or not, based on his/her historical interaction sequence. Although\neffective, we reveal two inherent limitations:(1) it may differ from human\nbehavior in that a user could imagine an oracle item in mind and select\npotential items matching the oracle; and (2) the classification is limited in\nthe candidate pool with noisy or easy supervision from negative samples, which\ndilutes the preference signals towards the oracle item. Yet, generating the\noracle item from the historical interaction sequence is mostly unexplored. To\nbridge the gap, we reshape sequential recommendation as a learning-to-generate\nparadigm, which is achieved via a guided diffusion model, termed\nDreamRec.Specifically, for a sequence of historical items, it applies a\nTransformer encoder to create guidance representations. Noising target items\nexplores the underlying distribution of item space; then, with the guidance of\nhistorical interactions, the denoising process generates an oracle item to\nrecover the positive item, so as to cast off negative sampling and depict the\ntrue preference of the user directly. We evaluate the effectiveness of DreamRec\nthrough extensive experiments and comparisons with existing methods. Codes and\ndata are open-sourced at https://github.com/YangZhengyi98/DreamRec.",
            "author": [
                "Zhengyi Yang",
                "Jiancan Wu",
                "Zhicai Wang",
                "Xiang Wang",
                "Yancheng Yuan",
                "Xiangnan He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20453v1",
                "http://arxiv.org/pdf/2310.20453v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20452v1",
            "title": "AsGrad: A Sharp Unified Analysis of Asynchronous-SGD Algorithms",
            "updated": "2023-10-31T13:44:53Z",
            "published": "2023-10-31T13:44:53Z",
            "summary": "We analyze asynchronous-type algorithms for distributed SGD in the\nheterogeneous setting, where each worker has its own computation and\ncommunication speeds, as well as data distribution. In these algorithms,\nworkers compute possibly stale and stochastic gradients associated with their\nlocal data at some iteration back in history and then return those gradients to\nthe server without synchronizing with other workers. We present a unified\nconvergence theory for non-convex smooth functions in the heterogeneous regime.\nThe proposed analysis provides convergence for pure asynchronous SGD and its\nvarious modifications. Moreover, our theory explains what affects the\nconvergence rate and what can be done to improve the performance of\nasynchronous algorithms. In particular, we introduce a novel asynchronous\nmethod based on worker shuffling. As a by-product of our analysis, we also\ndemonstrate convergence guarantees for gradient-type algorithms such as SGD\nwith random reshuffling and shuffle-once mini-batch SGD. The derived rates\nmatch the best-known results for those algorithms, highlighting the tightness\nof our approach. Finally, our numerical evaluations support theoretical\nfindings and show the good practical performance of our method.",
            "author": [
                "Rustem Islamov",
                "Mher Safaryan",
                "Dan Alistarh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20452v1",
                "http://arxiv.org/pdf/2310.20452v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20448v1",
            "title": "A Survey on Federated Unlearning: Challenges, Methods, and Future\n  Directions",
            "updated": "2023-10-31T13:32:00Z",
            "published": "2023-10-31T13:32:00Z",
            "summary": "In recent years, the notion of ``the right to be forgotten\" (RTBF) has\nevolved into a fundamental element of data privacy regulations, affording\nindividuals the ability to request the removal of their personal data from\ndigital records. Consequently, given the extensive adoption of data-intensive\nmachine learning (ML) algorithms and increasing concerns for personal data\nprivacy protection, the concept of machine unlearning (MU) has gained\nconsiderable attention. MU empowers an ML model to selectively eliminate\nsensitive or personally identifiable information it acquired during the\ntraining process. Evolving from the foundational principles of MU, federated\nunlearning (FU) has emerged to confront the challenge of data erasure within\nthe domain of federated learning (FL) settings. This empowers the FL model to\nunlearn an FL client or identifiable information pertaining to the client while\npreserving the integrity of the decentralized learning process. Nevertheless,\nunlike traditional MU, the distinctive attributes of federated learning\nintroduce specific challenges for FU techniques. These challenges lead to the\nneed for tailored design when designing FU algorithms. Therefore, this\ncomprehensive survey delves into the techniques, methodologies, and recent\nadvancements in federated unlearning. It provides an overview of fundamental\nconcepts and principles, evaluates existing federated unlearning algorithms,\nreviews optimizations tailored to federated learning, engages in discussions\nregarding practical applications, along with an assessment of their\nlimitations, and outlines promising directions for future research.",
            "author": [
                "Ziyao Liu",
                "Yu Jiang",
                "Jiyuan Shen",
                "Minyi Peng",
                "Kwok-Yan Lam",
                "Xingliang Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20448v1",
                "http://arxiv.org/pdf/2310.20448v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20447v1",
            "title": "Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted\n  Networks",
            "updated": "2023-10-31T13:30:30Z",
            "published": "2023-10-31T13:30:30Z",
            "summary": "Learning curve extrapolation aims to predict model performance in later\nepochs of training, based on the performance in earlier epochs. In this work,\nwe argue that, while the inherent uncertainty in the extrapolation of learning\ncurves warrants a Bayesian approach, existing methods are (i) overly\nrestrictive, and/or (ii) computationally expensive. We describe the first\napplication of prior-data fitted neural networks (PFNs) in this context. A PFN\nis a transformer, pre-trained on data generated from a prior, to perform\napproximate Bayesian inference in a single forward pass. We propose LC-PFN, a\nPFN trained to extrapolate 10 million artificial right-censored learning curves\ngenerated from a parametric prior proposed in prior art using MCMC. We\ndemonstrate that LC-PFN can approximate the posterior predictive distribution\nmore accurately than MCMC, while being over 10 000 times faster. We also show\nthat the same LC-PFN achieves competitive performance extrapolating a total of\n20 000 real learning curves from four learning curve benchmarks (LCBench,\nNAS-Bench-201, Taskset, and PD1) that stem from training a wide range of model\narchitectures (MLPs, CNNs, RNNs, and Transformers) on 53 different datasets\nwith varying input modalities (tabular, image, text, and protein data).\nFinally, we investigate its potential in the context of model selection and\nfind that a simple LC-PFN based predictive early stopping criterion obtains 2 -\n6x speed-ups on 45 of these datasets, at virtually no overhead.",
            "author": [
                "Steven Adriaensen",
                "Herilalaina Rakotoarison",
                "Samuel M\u00fcller",
                "Frank Hutter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20447v1",
                "http://arxiv.org/pdf/2310.20447v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20446v1",
            "title": "LAVSS: Location-Guided Audio-Visual Spatial Audio Separation",
            "updated": "2023-10-31T13:30:24Z",
            "published": "2023-10-31T13:30:24Z",
            "summary": "Existing machine learning research has achieved promising results in monaural\naudio-visual separation (MAVS). However, most MAVS methods purely consider what\nthe sound source is, not where it is located. This can be a problem in VR/AR\nscenarios, where listeners need to be able to distinguish between similar audio\nsources located in different directions. To address this limitation, we have\ngeneralized MAVS to spatial audio separation and proposed LAVSS: a\nlocation-guided audio-visual spatial audio separator. LAVSS is inspired by the\ncorrelation between spatial audio and visual location. We introduce the phase\ndifference carried by binaural audio as spatial cues, and we utilize positional\nrepresentations of sounding objects as additional modality guidance. We also\nleverage multi-level cross-modal attention to perform visual-positional\ncollaboration with audio features. In addition, we adopt a pre-trained monaural\nseparator to transfer knowledge from rich mono sounds to boost spatial audio\nseparation. This exploits the correlation between monaural and binaural\nchannels. Experiments on the FAIR-Play dataset demonstrate the superiority of\nthe proposed LAVSS over existing benchmarks of audio-visual separation. Our\nproject page: https://yyx666660.github.io/LAVSS/.",
            "author": [
                "Yuxin Ye",
                "Wenming Yang",
                "Yapeng Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20446v1",
                "http://arxiv.org/pdf/2310.20446v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20438v1",
            "title": "The Phase Transition Phenomenon of Shuffled Regression",
            "updated": "2023-10-31T13:21:14Z",
            "published": "2023-10-31T13:21:14Z",
            "summary": "We study the phase transition phenomenon inherent in the shuffled (permuted)\nregression problem, which has found numerous applications in databases,\nprivacy, data analysis, etc. In this study, we aim to precisely identify the\nlocations of the phase transition points by leveraging techniques from message\npassing (MP). In our analysis, we first transform the permutation recovery\nproblem into a probabilistic graphical model. We then leverage the analytical\ntools rooted in the message passing (MP) algorithm and derive an equation to\ntrack the convergence of the MP algorithm. By linking this equation to the\nbranching random walk process, we are able to characterize the impact of the\nsignal-to-noise-ratio ($\\snr$) on the permutation recovery. Depending on\nwhether the signal is given or not, we separately investigate the oracle case\nand the non-oracle case. The bottleneck in identifying the phase transition\nregimes lies in deriving closed-form formulas for the corresponding critical\npoints, but only in rare scenarios can one obtain such precise expressions. To\ntackle this technical challenge, this study proposes the Gaussian approximation\nmethod, which allows us to obtain the closed-form formulas in almost all\nscenarios. In the oracle case, our method can fairly accurately predict the\nphase transition $\\snr$. In the non-oracle case, our algorithm can predict the\nmaximum allowed number of permuted rows and uncover its dependency on the\nsample number.",
            "author": [
                "Hang Zhang",
                "Ping Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20438v1",
                "http://arxiv.org/pdf/2310.20438v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20434v1",
            "title": "Rapid cryogenic characterisation of 1024 integrated silicon quantum dots",
            "updated": "2023-10-31T13:14:43Z",
            "published": "2023-10-31T13:14:43Z",
            "summary": "Quantum computers are nearing the thousand qubit mark, with the current focus\non scaling to improve computational performance. As quantum processors grow in\ncomplexity, new challenges arise such as the management of device variability\nand the interface with supporting electronics. Spin qubits in silicon quantum\ndots are poised to address these challenges with their proven control\nfidelities and potential for compatibility with large-scale integration. Here,\nwe demonstrate the integration of 1024 silicon quantum dots with on-chip\ndigital and analogue electronics, all operating below 1 K. A high-frequency\nanalogue multiplexer provides fast access to all devices with minimal\nelectrical connections, enabling characteristic data across the quantum dot\narray to be acquired in just 5 minutes. We achieve this by leveraging\nradio-frequency reflectometry with state-of-the-art signal integrity, reaching\na minimum integration time of 160 ps. Key quantum dot parameters are extracted\nby fast automated machine learning routines to assess quantum dot yield and\nunderstand the impact of device design. We find correlations between quantum\ndot parameters and room temperature transistor behaviour that may be used as a\nproxy for in-line process monitoring. Our results show how rapid large-scale\nstudies of silicon quantum devices can be performed at lower temperatures and\nmeasurement rates orders of magnitude faster than current probing techniques,\nand form a platform for the future on-chip addressing of large scale qubit\narrays.",
            "author": [
                "Edward J. Thomas",
                "Virginia N. Ciriano-Tejel",
                "David F. Wise",
                "Domenic Prete",
                "Mathieu de Kruijf",
                "David J. Ibberson",
                "Grayson M. Noah",
                "Alberto Gomez-Saiz",
                "M. Fernando Gonzalez-Zalba",
                "Mark A. I. Johnson",
                "John J. L. Morton"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20434v1",
                "http://arxiv.org/pdf/2310.20434v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20435v1",
            "title": "Assessing the Sustainability and Trustworthiness of Federated Learning\n  Models",
            "updated": "2023-10-31T13:14:43Z",
            "published": "2023-10-31T13:14:43Z",
            "summary": "Artificial intelligence (AI) plays a pivotal role in various sectors,\ninfluencing critical decision-making processes in our daily lives. Within the\nAI landscape, novel AI paradigms, such as Federated Learning (FL), focus on\npreserving data privacy while collaboratively training AI models. In such a\ncontext, a group of experts from the European Commission (AI-HLEG) has\nidentified sustainable AI as one of the key elements that must be considered to\nprovide trustworthy AI. While existing literature offers several taxonomies and\nsolutions for assessing the trustworthiness of FL models, a significant gap\nexists in considering sustainability and the carbon footprint associated with\nFL. Thus, this work introduces the sustainability pillar to the most recent and\ncomprehensive trustworthy FL taxonomy, making this work the first to address\nall AI-HLEG requirements. The sustainability pillar assesses the FL system\nenvironmental impact, incorporating notions and metrics for hardware\nefficiency, federation complexity, and energy grid carbon intensity. Then, this\nwork designs and implements an algorithm for evaluating the trustworthiness of\nFL models by incorporating the sustainability pillar. Extensive evaluations\nwith the FederatedScope framework and various scenarios varying federation\nparticipants, complexities, hardware, and energy grids demonstrate the\nusefulness of the proposed solution.",
            "author": [
                "Alberto Huertas Celdran",
                "Chao Feng",
                "Pedro Miguel Sanchez Sanchez",
                "Lynn Zumtaugwald",
                "Gerome Bovet",
                "Burkhard Stiller"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20435v1",
                "http://arxiv.org/pdf/2310.20435v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20431v1",
            "title": "Raising the ClaSS of Streaming Time Series Segmentation",
            "updated": "2023-10-31T13:07:41Z",
            "published": "2023-10-31T13:07:41Z",
            "summary": "Ubiquitous sensors today emit high frequency streams of numerical\nmeasurements that reflect properties of human, animal, industrial, commercial,\nand natural processes. Shifts in such processes, e.g. caused by external events\nor internal state changes, manifest as changes in the recorded signals. The\ntask of streaming time series segmentation (STSS) is to partition the stream\ninto consecutive variable-sized segments that correspond to states of the\nobserved processes or entities. The partition operation itself must in\nperformance be able to cope with the input frequency of the signals. We\nintroduce ClaSS, a novel, efficient, and highly accurate algorithm for STSS.\nClaSS assesses the homogeneity of potential partitions using self-supervised\ntime series classification and applies statistical tests to detect significant\nchange points (CPs). In our experimental evaluation using two large benchmarks\nand six real-world data archives, we found ClaSS to be significantly more\nprecise than eight state-of-the-art competitors. Its space and time complexity\nis independent of segment sizes and linear only in the sliding window size. We\nalso provide ClaSS as a window operator with an average throughput of 538 data\npoints per second for the Apache Flink streaming engine.",
            "author": [
                "Arik Ermshaus",
                "Patrick Sch\u00e4fer",
                "Ulf Leser"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20431v1",
                "http://arxiv.org/pdf/2310.20431v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20427v1",
            "title": "Assessing and Enhancing Robustness of Deep Learning Models with\n  Corruption Emulation in Digital Pathology",
            "updated": "2023-10-31T12:59:36Z",
            "published": "2023-10-31T12:59:36Z",
            "summary": "Deep learning in digital pathology brings intelligence and automation as\nsubstantial enhancements to pathological analysis, the gold standard of\nclinical diagnosis. However, multiple steps from tissue preparation to slide\nimaging introduce various image corruptions, making it difficult for deep\nneural network (DNN) models to achieve stable diagnostic results for clinical\nuse. In order to assess and further enhance the robustness of the models, we\nanalyze the physical causes of the full-stack corruptions throughout the\npathological life-cycle and propose an Omni-Corruption Emulation (OmniCE)\nmethod to reproduce 21 types of corruptions quantified with 5-level severity.\nWe then construct three OmniCE-corrupted benchmark datasets at both patch level\nand slide level and assess the robustness of popular DNNs in classification and\nsegmentation tasks. Further, we explore to use the OmniCE-corrupted datasets as\naugmentation data for training and experiments to verify that the\ngeneralization ability of the models has been significantly enhanced.",
            "author": [
                "Peixiang Huang",
                "Songtao Zhang",
                "Yulu Gan",
                "Rui Xu",
                "Rongqi Zhu",
                "Wenkang Qin",
                "Limei Guo",
                "Shan Jiang",
                "Lin Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20427v1",
                "http://arxiv.org/pdf/2310.20427v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20426v1",
            "title": "Evolutionary Pareto Set Learning with Structure Constraints",
            "updated": "2023-10-31T12:53:56Z",
            "published": "2023-10-31T12:53:56Z",
            "summary": "The multiobjective evolutionary optimization algorithm (MOEA) is a powerful\napproach for tackling multiobjective optimization problems (MOPs), which can\nfind a finite set of approximate Pareto solutions in a single run. However,\nunder mild regularity conditions, the Pareto optimal set of a continuous MOP\ncould be a low dimensional continuous manifold that contains infinite\nsolutions. In addition, structure constraints on the whole optimal solution\nset, which characterize the patterns shared among all solutions, could be\nrequired in many real-life applications. It is very challenging for existing\nfinite population based MOEAs to handle these structure constraints properly.\nIn this work, we propose the first model-based algorithmic framework to learn\nthe whole solution set with structure constraints for multiobjective\noptimization. In our approach, the Pareto optimality can be traded off with a\npreferred structure among the whole solution set, which could be crucial for\nmany real-world problems. We also develop an efficient evolutionary learning\nmethod to train the set model with structure constraints. Experimental studies\non benchmark test suites and real-world application problems demonstrate the\npromising performance of our proposed framework.",
            "author": [
                "Xi Lin",
                "Xiaoyuan Zhang",
                "Zhiyuan Yang",
                "Qingfu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20426v1",
                "http://arxiv.org/pdf/2310.20426v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00727v1",
            "title": "Investigating Relative Performance of Transfer and Meta Learning",
            "updated": "2023-10-31T12:52:00Z",
            "published": "2023-10-31T12:52:00Z",
            "summary": "Over the past decade, the field of machine learning has experienced\nremarkable advancements. While image recognition systems have achieved\nimpressive levels of accuracy, they continue to rely on extensive training\ndatasets. Additionally, a significant challenge has emerged in the form of poor\nout-of-distribution performance, which necessitates retraining neural networks\nwhen they encounter conditions that deviate from their training data. This\nlimitation has notably contributed to the slow progress in self-driving car\ntechnology. These pressing issues have sparked considerable interest in methods\nthat enable neural networks to learn effectively from limited data. This paper\npresents the outcomes of an extensive investigation designed to compare two\ndistinct approaches, transfer learning and meta learning, as potential\nsolutions to this problem. The overarching objective was to establish a robust\ncriterion for selecting the most suitable method in diverse machine learning\nscenarios. Building upon prior research, I expanded the comparative analysis by\nintroducing a new meta learning method into the investigation. Subsequently, I\nassessed whether the findings remained consistent under varying conditions.\nFinally, I delved into the impact of altering the size of the training dataset\non the relative performance of these methods. This comprehensive exploration\nhas yielded insights into the conditions favoring each approach, thereby\nfacilitating the development of a criterion for selecting the most appropriate\nmethod in any given situation",
            "author": [
                "Benji Alwis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00727v1",
                "http://arxiv.org/pdf/2311.00727v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20425v2",
            "title": "Discussing the Spectra of Physics-Enhanced Machine Learning via a Survey\n  on Structural Mechanics Applications",
            "updated": "2023-11-01T08:21:02Z",
            "published": "2023-10-31T12:50:25Z",
            "summary": "The intersection of physics and machine learning has given rise to a paradigm\nthat we refer to here as physics-enhanced machine learning (PEML), aiming to\nimprove the capabilities and reduce the individual shortcomings of data- or\nphysics-only methods. In this paper, the spectrum of physics-enhanced machine\nlearning methods, expressed across the defining axes of physics and data, is\ndiscussed by engaging in a comprehensive exploration of its characteristics,\nusage, and motivations. In doing so, this paper offers a survey of recent\napplications and developments of PEML techniques, revealing the potency of PEML\nin addressing complex challenges. We further demonstrate application of select\nsuch schemes on the simple working example of a single-degree-of-freedom\nDuffing oscillator, which allows to highlight the individual characteristics\nand motivations of different `genres' of PEML approaches. To promote\ncollaboration and transparency, and to provide practical examples for the\nreader, the code of these working examples is provided alongside this paper. As\na foundational contribution, this paper underscores the significance of PEML in\npushing the boundaries of scientific and engineering research, underpinned by\nthe synergy of physical insights and machine learning capabilities.",
            "author": [
                "Marcus Haywood-Alexander",
                "Wei Liu",
                "Kiran Bacsa",
                "Zhilu Lai",
                "Eleni Chatzi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20425v2",
                "http://arxiv.org/pdf/2310.20425v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20424v1",
            "title": "DDC-PIM: Efficient Algorithm/Architecture Co-design for Doubling Data\n  Capacity of SRAM-based Processing-In-Memory",
            "updated": "2023-10-31T12:49:54Z",
            "published": "2023-10-31T12:49:54Z",
            "summary": "Processing-in-memory (PIM), as a novel computing paradigm, provides\nsignificant performance benefits from the aspect of effective data movement\nreduction. SRAM-based PIM has been demonstrated as one of the most promising\ncandidates due to its endurance and compatibility. However, the integration\ndensity of SRAM-based PIM is much lower than other non-volatile memory-based\nones, due to its inherent 6T structure for storing a single bit. Within\ncomparable area constraints, SRAM-based PIM exhibits notably lower capacity.\nThus, aiming to unleash its capacity potential, we propose DDC-PIM, an\nefficient algorithm/architecture co-design methodology that effectively doubles\nthe equivalent data capacity. At the algorithmic level, we propose a\nfilter-wise complementary correlation (FCC) algorithm to obtain a bitwise\ncomplementary pair. At the architecture level, we exploit the intrinsic\ncross-coupled structure of 6T SRAM to store the bitwise complementary pair in\ntheir complementary states ($Q/\\overline{Q}$), thereby maximizing the data\ncapacity of each SRAM cell. The dual-broadcast input structure and\nreconfigurable unit support both depthwise and pointwise convolution, adhering\nto the requirements of various neural networks. Evaluation results show that\nDDC-PIM yields about $2.84\\times$ speedup on MobileNetV2 and $2.69\\times$ on\nEfficientNet-B0 with negligible accuracy loss compared with PIM baseline\nimplementation. Compared with state-of-the-art SRAM-based PIM macros, DDC-PIM\nachieves up to $8.41\\times$ and $2.75\\times$ improvement in weight density and\narea efficiency, respectively.",
            "author": [
                "Cenlin Duan",
                "Jianlei Yang",
                "Xiaolin He",
                "Yingjie Qi",
                "Yikun Wang",
                "Yiou Wang",
                "Ziyan He",
                "Bonan Yan",
                "Xueyan Wang",
                "Xiaotao Jia",
                "Weitao Pan",
                "Weisheng Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20424v1",
                "http://arxiv.org/pdf/2310.20424v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20418v1",
            "title": "Multipartite entanglement sudden death and birth in randomized\n  hypergraph states",
            "updated": "2023-10-31T12:45:26Z",
            "published": "2023-10-31T12:45:26Z",
            "summary": "We introduce and analyze the entanglement properties of randomized hypergraph\nstates, as an extended notion of the randomization procedure in the quantum\nlogic gates for the usual graph states, recently proposed in the literature.\nThe probabilities of applying imperfect generalized controlled-$Z$ gates\nsimulate the noisy operations over the qubits. We obtain entanglement measures\nas negativity, concurrence, and genuine multiparticle negativity, and show that\nentanglement exhibits a non-monotonic behavior in terms of the randomness\nparameters, which is a consequence of the non-uniformity of the associated\nhypergraphs, reinforcing the claim that the entanglement of randomized graph\nstates is monotonic since they are related to $2$-uniform hypergraphs.\nMoreover, we observed the phenomena of entanglement sudden death and\nentanglement sudden birth in RH states. This work comes to unveil a connection\nbetween the non-uniformity of hypergraphs and loss of entanglement.",
            "author": [
                "Vinicius Salem",
                "Alison A. Silva",
                "Fabiano M. Andrade"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20418v1",
                "http://arxiv.org/pdf/2310.20418v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20415v1",
            "title": "Coalitional Manipulations and Immunity of the Shapley Value",
            "updated": "2023-10-31T12:43:31Z",
            "published": "2023-10-31T12:43:31Z",
            "summary": "We consider manipulations in the context of coalitional games, where a\ncoalition aims to increase the total payoff of its members. An allocation rule\nis immune to coalitional manipulation if no coalition can benefit from internal\nreallocation of worth on the level of its subcoalitions\n(reallocation-proofness), and if no coalition benefits from a lower worth while\nall else remains the same (weak coalitional monotonicity). Replacing additivity\nin Shapley's original characterization by these requirements yields a new\nfoundation of the Shapley value, i.e., it is the unique efficient and symmetric\nallocation rule that awards nothing to a null player and is immune to\ncoalitional manipulations. We further find that for efficient allocation rules,\nreallocation-proofness is equivalent to constrained marginality, a weaker\nvariant of Young's marginality axiom. Our second characterization improves upon\nYoung's characterization by weakening the independence requirement intrinsic to\nmarginality.",
            "author": [
                "Christian Basteck",
                "Frank Huettner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20415v1",
                "http://arxiv.org/pdf/2310.20415v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH",
                "cs.GT",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20414v2",
            "title": "Meta Learning for Multi-View Visuomotor Systems",
            "updated": "2023-11-03T13:58:28Z",
            "published": "2023-10-31T12:40:46Z",
            "summary": "This paper introduces a new approach for quickly adapting a multi-view\nvisuomotor system for robots to varying camera configurations from the baseline\nsetup. It utilises meta-learning to fine-tune the perceptual network while\nkeeping the policy network fixed. Experimental results demonstrate a\nsignificant reduction in the number of new training episodes needed to attain\nbaseline performance.",
            "author": [
                "Benji Alwis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20414v2",
                "http://arxiv.org/pdf/2310.20414v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20412v1",
            "title": "Thermal-Infrared Remote Target Detection System for Maritime Rescue\n  based on Data Augmentation with 3D Synthetic Data",
            "updated": "2023-10-31T12:37:49Z",
            "published": "2023-10-31T12:37:49Z",
            "summary": "This paper proposes a thermal-infrared (TIR) remote target detection system\nfor maritime rescue using deep learning and data augmentation. We established a\nself-collected TIR dataset consisting of multiple scenes imitating human rescue\nsituations using a TIR camera (FLIR). Additionally, to address dataset scarcity\nand improve model robustness, a synthetic dataset from a 3D game (ARMA3) to\naugment the data is further collected. However, a significant domain gap exists\nbetween synthetic TIR and real TIR images. Hence, a proper domain adaptation\nalgorithm is essential to overcome the gap. Therefore, we suggest a domain\nadaptation algorithm in a target-background separated manner from 3D\ngame-to-real, based on a generative model, to address this issue. Furthermore,\na segmentation network with fixed-weight kernels at the head is proposed to\nimprove the signal-to-noise ratio (SNR) and provide weak attention, as remote\nTIR targets inherently suffer from unclear boundaries. Experiment results\nreveal that the network trained on augmented data consisting of translated\nsynthetic and real TIR data outperforms that trained on only real TIR data by a\nlarge margin. Furthermore, the proposed segmentation model surpasses the\nperformance of state-of-the-art segmentation methods.",
            "author": [
                "Sungjin Cheong",
                "Wonho Jung",
                "Yoon Seop Lim",
                "Yong-Hwa Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20412v1",
                "http://arxiv.org/pdf/2310.20412v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "68T45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20403v1",
            "title": "Multi-Base Station Cooperative Sensing with AI-Aided Tracking",
            "updated": "2023-10-31T12:27:48Z",
            "published": "2023-10-31T12:27:48Z",
            "summary": "In this work, we investigate the performance of a joint sensing and\ncommunication (JSC) network consisting of multiple base stations (BSs) that\ncooperate through a fusion center (FC) to exchange information about the sensed\nenvironment while concurrently establishing communication links with a set of\nuser equipments (UEs). Each BS within the network operates as a monostatic\nradar system, enabling comprehensive scanning of the monitored area and\ngenerating range-angle maps that provide information regarding the position of\na group of heterogeneous objects. The acquired maps are subsequently fused in\nthe FC. Then, a convolutional neural network (CNN) is employed to infer the\ncategory of the targets, e.g., pedestrians or vehicles, and such information is\nexploited by an adaptive clustering algorithm to group the detections\noriginating from the same target more effectively. Finally, two multi-target\ntracking algorithms, the probability hypothesis density (PHD) filter and\nmulti-Bernoulli mixture (MBM) filter, are applied to estimate the state of the\ntargets. Numerical results demonstrated that our framework could provide\nremarkable sensing performance, achieving an optimal sub-pattern assignment\n(OSPA) less than 60 cm, while keeping communication services to UEs with a\nreduction of the communication capacity in the order of 10% to 20%. The impact\nof the number of BSs engaged in sensing is also examined, and we show that in\nthe specific case study, 3 BSs ensure a localization error below 1 m.",
            "author": [
                "Elia Favarelli",
                "Elisabetta Matricardi",
                "Lorenzo Pucci",
                "Enrico Paolini",
                "Wen Xu",
                "Andrea Giorgetti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20403v1",
                "http://arxiv.org/pdf/2310.20403v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20398v1",
            "title": "A hybrid approach for solving the gravitational N-body problem with\n  Artificial Neural Networks",
            "updated": "2023-10-31T12:20:20Z",
            "published": "2023-10-31T12:20:20Z",
            "summary": "Simulating the evolution of the gravitational N-body problem becomes\nextremely computationally expensive as N increases since the problem complexity\nscales quadratically with the number of bodies. We study the use of Artificial\nNeural Networks (ANNs) to replace expensive parts of the integration of\nplanetary systems. Neural networks that include physical knowledge have grown\nin popularity in the last few years, although few attempts have been made to\nuse them to speed up the simulation of the motion of celestial bodies. We study\nthe advantages and limitations of using Hamiltonian Neural Networks to replace\ncomputationally expensive parts of the numerical simulation. We compare the\nresults of the numerical integration of a planetary system with asteroids with\nthose obtained by a Hamiltonian Neural Network and a conventional Deep Neural\nNetwork, with special attention to understanding the challenges of this\nproblem. Due to the non-linear nature of the gravitational equations of motion,\nerrors in the integration propagate. To increase the robustness of a method\nthat uses neural networks, we propose a hybrid integrator that evaluates the\nprediction of the network and replaces it with the numerical solution if\nconsidered inaccurate. Hamiltonian Neural Networks can make predictions that\nresemble the behavior of symplectic integrators but are challenging to train\nand in our case fail when the inputs differ ~7 orders of magnitude. In\ncontrast, Deep Neural Networks are easy to train but fail to conserve energy,\nleading to fast divergence from the reference solution. The hybrid integrator\ndesigned to include the neural networks increases the reliability of the method\nand prevents large energy errors without increasing the computing cost\nsignificantly. For this problem, the use of neural networks results in faster\nsimulations when the number of asteroids is >70.",
            "author": [
                "Veronica Saz Ulibarrena",
                "Philipp Horn",
                "Simon Portegies Zwart",
                "Elena Sellentin",
                "Barry Koren",
                "Maxwell X. Cai"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.jcp.2023.112596",
                "http://arxiv.org/abs/2310.20398v1",
                "http://arxiv.org/pdf/2310.20398v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20389v1",
            "title": "High-Resolution Reference Image Assisted Volumetric Super-Resolution of\n  Cardiac Diffusion Weighted Imaging",
            "updated": "2023-10-31T12:05:27Z",
            "published": "2023-10-31T12:05:27Z",
            "summary": "Diffusion Tensor Cardiac Magnetic Resonance (DT-CMR) is the only in vivo\nmethod to non-invasively examine the microstructure of the human heart. Current\nresearch in DT-CMR aims to improve the understanding of how the cardiac\nmicrostructure relates to the macroscopic function of the healthy heart as well\nas how microstructural dysfunction contributes to disease. To get the final\nDT-CMR metrics, we need to acquire diffusion weighted images of at least 6\ndirections. However, due to DWI's low signal-to-noise ratio, the standard voxel\nsize is quite big on the scale for microstructures. In this study, we explored\nthe potential of deep-learning-based methods in improving the image quality\nvolumetrically (x4 in all dimensions). This study proposed a novel framework to\nenable volumetric super-resolution, with an additional model input of\nhigh-resolution b0 DWI. We demonstrated that the additional input could offer\nhigher super-resolved image quality. Going beyond, the model is also able to\nsuper-resolve DWIs of unseen b-values, proving the model framework's\ngeneralizability for cardiac DWI superresolution. In conclusion, we would then\nrecommend giving the model a high-resolution reference image as an additional\ninput to the low-resolution image for training and inference to guide all\nsuper-resolution frameworks for parametric imaging where a reference image is\navailable.",
            "author": [
                "Yinzhe Wu",
                "Jiahao Huang",
                "Fanwen Wang",
                "Pedro Ferreira",
                "Andrew Scott",
                "Sonia Nielles-Vallespin",
                "Guang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20389v1",
                "http://arxiv.org/pdf/2310.20389v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20384v1",
            "title": "Do large language models solve verbal analogies like children do?",
            "updated": "2023-10-31T11:49:11Z",
            "published": "2023-10-31T11:49:11Z",
            "summary": "Analogy-making lies at the heart of human cognition. Adults solve analogies\nsuch as \\textit{Horse belongs to stable like chicken belongs to ...?} by\nmapping relations (\\textit{kept in}) and answering \\textit{chicken coop}. In\ncontrast, children often use association, e.g., answering \\textit{egg}. This\npaper investigates whether large language models (LLMs) solve verbal analogies\nin A:B::C:? form using associations, similar to what children do. We use verbal\nanalogies extracted from an online adaptive learning environment, where 14,002\n7-12 year-olds from the Netherlands solved 622 analogies in Dutch. The six\ntested Dutch monolingual and multilingual LLMs performed around the same level\nas children, with MGPT performing worst, around the 7-year-old level, and XLM-V\nand GPT-3 the best, slightly above the 11-year-old level. However, when we\ncontrol for associative processes this picture changes and each model's\nperformance level drops 1-2 years. Further experiments demonstrate that\nassociative processes often underlie correctly solved analogies. We conclude\nthat the LLMs we tested indeed tend to solve verbal analogies by association\nwith C like children do.",
            "author": [
                "Claire E. Stevenson",
                "Mathilde ter Veen",
                "Rochelle Choenni",
                "Han L. J. van der Maas",
                "Ekaterina Shutova"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20384v1",
                "http://arxiv.org/pdf/2310.20384v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20380v3",
            "title": "Dropout Strategy in Reinforcement Learning: Limiting the Surrogate\n  Objective Variance in Policy Optimization Methods",
            "updated": "2023-11-03T04:12:09Z",
            "published": "2023-10-31T11:38:26Z",
            "summary": "Policy-based reinforcement learning algorithms are widely used in various\nfields. Among them, mainstream policy optimization algorithms such as TRPO and\nPPO introduce importance sampling into policy iteration, which allows the reuse\nof historical data. However, this can also lead to a high variance of the\nsurrogate objective and indirectly affects the stability and convergence of the\nalgorithm. In this paper, we first derived an upper bound of the surrogate\nobjective variance, which can grow quadratically with the increase of the\nsurrogate objective. Next, we proposed the dropout technique to avoid the\nexcessive increase of the surrogate objective variance caused by importance\nsampling. Then, we introduced a general reinforcement learning framework\napplicable to mainstream policy optimization methods, and applied the dropout\ntechnique to the PPO algorithm to obtain the D-PPO variant. Finally, we conduct\ncomparative experiments between D-PPO and PPO algorithms in the Atari 2600\nenvironment, and the results show that D-PPO achieved significant performance\nimprovements compared to PPO, and effectively limited the excessive increase of\nthe surrogate objective variance during training.",
            "author": [
                "Zhengpeng Xie",
                "Changdong Yu",
                "Weizheng Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20380v3",
                "http://arxiv.org/pdf/2310.20380v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20369v1",
            "title": "Stability and Generalization of the Decentralized Stochastic Gradient\n  Descent Ascent Algorithm",
            "updated": "2023-10-31T11:27:01Z",
            "published": "2023-10-31T11:27:01Z",
            "summary": "The growing size of available data has attracted increasing interest in\nsolving minimax problems in a decentralized manner for various machine learning\ntasks. Previous theoretical research has primarily focused on the convergence\nrate and communication complexity of decentralized minimax algorithms, with\nlittle attention given to their generalization. In this paper, we investigate\nthe primal-dual generalization bound of the decentralized stochastic gradient\ndescent ascent (D-SGDA) algorithm using the approach of algorithmic stability\nunder both convex-concave and nonconvex-nonconcave settings. Our theory refines\nthe algorithmic stability in a decentralized manner and demonstrates that the\ndecentralized structure does not destroy the stability and generalization of\nD-SGDA, implying that it can generalize as well as the vanilla SGDA in certain\nsituations. Our results analyze the impact of different topologies on the\ngeneralization bound of the D-SGDA algorithm beyond trivial factors such as\nsample sizes, learning rates, and iterations. We also evaluate the optimization\nerror and balance it with the generalization gap to obtain the optimal\npopulation risk of D-SGDA in the convex-concave setting. Additionally, we\nperform several numerical experiments which validate our theoretical findings.",
            "author": [
                "Miaoxi Zhu",
                "Li Shen",
                "Bo Du",
                "Dacheng Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20369v1",
                "http://arxiv.org/pdf/2310.20369v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20367v1",
            "title": "A Machine Learning-Based Framework for Clustering Residential\n  Electricity Load Profiles to Enhance Demand Response Programs",
            "updated": "2023-10-31T11:23:26Z",
            "published": "2023-10-31T11:23:26Z",
            "summary": "Load shapes derived from smart meter data are frequently employed to analyze\ndaily energy consumption patterns, particularly in the context of applications\nlike Demand Response (DR). Nevertheless, one of the most important challenges\nto this endeavor lies in identifying the most suitable consumer clusters with\nsimilar consumption behaviors. In this paper, we present a novel machine\nlearning based framework in order to achieve optimal load profiling through a\nreal case study, utilizing data from almost 5000 households in London. Four\nwidely used clustering algorithms are applied specifically K-means, K-medoids,\nHierarchical Agglomerative Clustering and Density-based Spatial Clustering. An\nempirical analysis as well as multiple evaluation metrics are leveraged to\nassess those algorithms. Following that, we redefine the problem as a\nprobabilistic classification one, with the classifier emulating the behavior of\na clustering algorithm,leveraging Explainable AI (xAI) to enhance the\ninterpretability of our solution. According to the clustering algorithm\nanalysis the optimal number of clusters for this case is seven. Despite that,\nour methodology shows that two of the clusters, almost 10\\% of the dataset,\nexhibit significant internal dissimilarity and thus it splits them even further\nto create nine clusters in total. The scalability and versatility of our\nsolution makes it an ideal choice for power utility companies aiming to segment\ntheir users for creating more targeted Demand Response programs.",
            "author": [
                "Vasilis Michalakopoulos",
                "Elissaios Sarmas",
                "Ioannis Papias",
                "Panagiotis Skaloumpakas",
                "Vangelis Marinakis",
                "Haris Doukas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20367v1",
                "http://arxiv.org/pdf/2310.20367v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20366v1",
            "title": "Distil the informative essence of loop detector data set: Is\n  network-level traffic forecasting hungry for more data?",
            "updated": "2023-10-31T11:23:10Z",
            "published": "2023-10-31T11:23:10Z",
            "summary": "Network-level traffic condition forecasting has been intensively studied for\ndecades. Although prediction accuracy has been continuously improved with\nemerging deep learning models and ever-expanding traffic data, traffic\nforecasting still faces many challenges in practice. These challenges include\nthe robustness of data-driven models, the inherent unpredictability of traffic\ndynamics, and whether further improvement of traffic forecasting requires more\nsensor data. In this paper, we focus on this latter question and particularly\non data from loop detectors. To answer this, we propose an uncertainty-aware\ntraffic forecasting framework to explore how many samples of loop data are\ntruly effective for training forecasting models. Firstly, the model design\ncombines traffic flow theory with graph neural networks, ensuring the\nrobustness of prediction and uncertainty quantification. Secondly, evidential\nlearning is employed to quantify different sources of uncertainty in a single\npass. The estimated uncertainty is used to \"distil\" the essence of the dataset\nthat sufficiently covers the information content. Results from a case study of\na highway network around Amsterdam show that, from 2018 to 2021, more than 80\\%\nof the data during daytime can be removed. The remaining 20\\% samples have\nequal prediction power for training models. This result suggests that indeed\nlarge traffic datasets can be subdivided into significantly smaller but equally\ninformative datasets. From these findings, we conclude that the proposed\nmethodology proves valuable in evaluating large traffic datasets' true\ninformation content. Further extensions, such as extracting smaller, spatially\nnon-redundant datasets, are possible with this method.",
            "author": [
                "Guopeng Li",
                "Victor L. Knoop",
                "J. W. C.",
                "van Lint"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20366v1",
                "http://arxiv.org/pdf/2310.20366v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20363v1",
            "title": "CAFE: Conflict-Aware Feature-wise Explanations",
            "updated": "2023-10-31T11:14:26Z",
            "published": "2023-10-31T11:14:26Z",
            "summary": "Feature attribution methods are widely used to explain neural models by\ndetermining the influence of individual input features on the models' outputs.\nWe propose a novel feature attribution method, CAFE (Conflict-Aware\nFeature-wise Explanations), that addresses three limitations of the existing\nmethods: their disregard for the impact of conflicting features, their lack of\nconsideration for the influence of bias terms, and an overly high sensitivity\nto local variations in the underpinning activation functions. Unlike other\nmethods, CAFE provides safeguards against overestimating the effects of neuron\ninputs and separately traces positive and negative influences of input features\nand biases, resulting in enhanced robustness and increased ability to surface\nfeature conflicts. We show experimentally that CAFE is better able to identify\nconflicting features on synthetic tabular data and exhibits the best overall\nfidelity on several real-world tabular datasets, while being highly\ncomputationally efficient.",
            "author": [
                "Adam Dejl",
                "Hamed Ayoobi",
                "Matthew Williams",
                "Francesca Toni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20363v1",
                "http://arxiv.org/pdf/2310.20363v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03376v1",
            "title": "Blocked Collaborative Bandits: Online Collaborative Filtering with\n  Per-Item Budget Constraints",
            "updated": "2023-10-31T11:04:21Z",
            "published": "2023-10-31T11:04:21Z",
            "summary": "We consider the problem of \\emph{blocked} collaborative bandits where there\nare multiple users, each with an associated multi-armed bandit problem. These\nusers are grouped into \\emph{latent} clusters such that the mean reward vectors\nof users within the same cluster are identical. Our goal is to design\nalgorithms that maximize the cumulative reward accrued by all the users over\ntime, under the \\emph{constraint} that no arm of a user is pulled more than\n$\\mathsf{B}$ times. This problem has been originally considered by\n\\cite{Bresler:2014}, and designing regret-optimal algorithms for it has since\nremained an open problem. In this work, we propose an algorithm called\n\\texttt{B-LATTICE} (Blocked Latent bAndiTs via maTrIx ComplEtion) that\ncollaborates across users, while simultaneously satisfying the budget\nconstraints, to maximize their cumulative rewards. Theoretically, under certain\nreasonable assumptions on the latent structure, with $\\mathsf{M}$ users,\n$\\mathsf{N}$ arms, $\\mathsf{T}$ rounds per user, and $\\mathsf{C}=O(1)$ latent\nclusters, \\texttt{B-LATTICE} achieves a per-user regret of\n$\\widetilde{O}(\\sqrt{\\mathsf{T}(1 + \\mathsf{N}\\mathsf{M}^{-1})}$ under a budget\nconstraint of $\\mathsf{B}=\\Theta(\\log \\mathsf{T})$. These are the first\nsub-linear regret bounds for this problem, and match the minimax regret bounds\nwhen $\\mathsf{B}=\\mathsf{T}$. Empirically, we demonstrate that our algorithm\nhas superior performance over baselines even when $\\mathsf{B}=1$.\n\\texttt{B-LATTICE} runs in phases where in each phase it clusters users into\ngroups and collaborates across users within a group to quickly learn their\nreward models.",
            "author": [
                "Soumyabrata Pal",
                "Arun Sai Suggala",
                "Karthikeyan Shanmugam",
                "Prateek Jain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03376v1",
                "http://arxiv.org/pdf/2311.03376v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20360v1",
            "title": "Mathematical Introduction to Deep Learning: Methods, Implementations,\n  and Theory",
            "updated": "2023-10-31T11:01:23Z",
            "published": "2023-10-31T11:01:23Z",
            "summary": "This book aims to provide an introduction to the topic of deep learning\nalgorithms. We review essential components of deep learning algorithms in full\nmathematical detail including different artificial neural network (ANN)\narchitectures (such as fully-connected feedforward ANNs, convolutional ANNs,\nrecurrent ANNs, residual ANNs, and ANNs with batch normalization) and different\noptimization algorithms (such as the basic stochastic gradient descent (SGD)\nmethod, accelerated methods, and adaptive methods). We also cover several\ntheoretical aspects of deep learning algorithms such as approximation\ncapacities of ANNs (including a calculus for ANNs), optimization theory\n(including Kurdyka-{\\L}ojasiewicz inequalities), and generalization errors. In\nthe last part of the book some deep learning approximation methods for PDEs are\nreviewed including physics-informed neural networks (PINNs) and deep Galerkin\nmethods. We hope that this book will be useful for students and scientists who\ndo not yet have any background in deep learning at all and would like to gain a\nsolid foundation as well as for practitioners who would like to obtain a firmer\nmathematical understanding of the objects and methods considered in deep\nlearning.",
            "author": [
                "Arnulf Jentzen",
                "Benno Kuckuck",
                "Philippe von Wurstemberger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20360v1",
                "http://arxiv.org/pdf/2310.20360v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NA",
                "math.NA",
                "math.PR",
                "stat.ML",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20355v1",
            "title": "Muscle volume quantification: guiding transformers with anatomical\n  priors",
            "updated": "2023-10-31T10:56:10Z",
            "published": "2023-10-31T10:56:10Z",
            "summary": "Muscle volume is a useful quantitative biomarker in sports, but also for the\nfollow-up of degenerative musculo-skelletal diseases. In addition to volume,\nother shape biomarkers can be extracted by segmenting the muscles of interest\nfrom medical images. Manual segmentation is still today the gold standard for\nsuch measurements despite being very time-consuming. We propose a method for\nautomatic segmentation of 18 muscles of the lower limb on 3D Magnetic Resonance\nImages to assist such morphometric analysis. By their nature, the tissue of\ndifferent muscles is undistinguishable when observed in MR Images. Thus, muscle\nsegmentation algorithms cannot rely on appearance but only on contour cues.\nHowever, such contours are hard to detect and their thickness varies across\nsubjects. To cope with the above challenges, we propose a segmentation approach\nbased on a hybrid architecture, combining convolutional and visual transformer\nblocks. We investigate for the first time the behaviour of such hybrid\narchitectures in the context of muscle segmentation for shape analysis.\nConsidering the consistent anatomical muscle configuration, we rely on\ntransformer blocks to capture the longrange relations between the muscles. To\nfurther exploit the anatomical priors, a second contribution of this work\nconsists in adding a regularisation loss based on an adjacency matrix of\nplausible muscle neighbourhoods estimated from the training data. Our\nexperimental results on a unique database of elite athletes show it is possible\nto train complex hybrid models from a relatively small database of large\nvolumes, while the anatomical prior regularisation favours better predictions.",
            "author": [
                "Louise Piecuch",
                "Vanessa Gonzales Duque",
                "Aur\u00e9lie Sarcher",
                "Enzo Hollville",
                "Antoine Nordez",
                "Giuseppe Rabita",
                "Ga\u00ebl Guilhem",
                "Diana Mateus"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20355v1",
                "http://arxiv.org/pdf/2310.20355v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20350v1",
            "title": "Combining Shape Completion and Grasp Prediction for Fast and Versatile\n  Grasping with a Multi-Fingered Hand",
            "updated": "2023-10-31T10:46:19Z",
            "published": "2023-10-31T10:46:19Z",
            "summary": "Grasping objects with limited or no prior knowledge about them is a highly\nrelevant skill in assistive robotics. Still, in this general setting, it has\nremained an open problem, especially when it comes to only partial\nobservability and versatile grasping with multi-fingered hands. We present a\nnovel, fast, and high fidelity deep learning pipeline consisting of a shape\ncompletion module that is based on a single depth image, and followed by a\ngrasp predictor that is based on the predicted object shape. The shape\ncompletion network is based on VQDIF and predicts spatial occupancy values at\narbitrary query points. As grasp predictor, we use our two-stage architecture\nthat first generates hand poses using an autoregressive model and then\nregresses finger joint configurations per pose. Critical factors turn out to be\nsufficient data realism and augmentation, as well as special attention to\ndifficult cases during training. Experiments on a physical robot platform\ndemonstrate successful grasping of a wide range of household objects based on a\ndepth image from a single viewpoint. The whole pipeline is fast, taking only\nabout 1 s for completing the object's shape (0.7 s) and generating 1000 grasps\n(0.3 s).",
            "author": [
                "Matthias Humt",
                "Dominik Winkelbauer",
                "Ulrich Hillenbrand",
                "Berthold B\u00e4uml"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20350v1",
                "http://arxiv.org/pdf/2310.20350v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20348v1",
            "title": "Class Incremental Learning with Pre-trained Vision-Language Models",
            "updated": "2023-10-31T10:45:03Z",
            "published": "2023-10-31T10:45:03Z",
            "summary": "With the advent of large-scale pre-trained models, interest in adapting and\nexploiting them for continual learning scenarios has grown.\n  In this paper, we propose an approach to exploiting pre-trained\nvision-language models (e.g. CLIP) that enables further adaptation instead of\nonly using zero-shot learning of new tasks. We augment a pre-trained CLIP model\nwith additional layers after the Image Encoder or before the Text Encoder. We\ninvestigate three different strategies: a Linear Adapter, a Self-attention\nAdapter, each operating on the image embedding, and Prompt Tuning which instead\nmodifies prompts input to the CLIP text encoder. We also propose a method for\nparameter retention in the adapter layers that uses a measure of parameter\nimportance to better maintain stability and plasticity during incremental\nlearning. Our experiments demonstrate that the simplest solution -- a single\nLinear Adapter layer with parameter retention -- produces the best results.\nExperiments on several conventional benchmarks consistently show a significant\nmargin of improvement over the current state-of-the-art.",
            "author": [
                "Xialei Liu",
                "Xusheng Cao",
                "Haori Lu",
                "Jia-wen Xiao",
                "Andrew D. Bagdanov",
                "Ming-Ming Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20348v1",
                "http://arxiv.org/pdf/2310.20348v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20329v1",
            "title": "InstructCoder: Empowering Language Models for Code Editing",
            "updated": "2023-10-31T10:15:35Z",
            "published": "2023-10-31T10:15:35Z",
            "summary": "Code editing encompasses a variety of pragmatic tasks that developers deal\nwith daily. Despite its relevance and practical usefulness, automatic code\nediting remains an underexplored area in the evolution of deep learning models,\npartly due to data scarcity. In this work, we explore the use of large language\nmodels (LLMs) to edit code based on user instructions, covering a broad range\nof implicit tasks such as comment insertion, code optimization, and code\nrefactoring. To facilitate this, we introduce InstructCoder, the first dataset\ndesigned to adapt LLMs for general-purpose code editing, containing\nhighdiversity code-editing tasks. It consists of over 114,000\ninstruction-input-output triplets and covers multiple distinct code editing\nscenarios. The dataset is systematically expanded through an iterative process\nthat commences with code editing data sourced from GitHub commits as seed\ntasks. Seed and generated tasks are used subsequently to prompt ChatGPT for\nmore task data. Our experiments demonstrate that open-source LLMs fine-tuned on\nInstructCoder can edit code correctly based on users' instructions most of the\ntime, exhibiting unprecedented code-editing performance levels. Such results\nsuggest that proficient instruction-finetuning can lead to significant\namelioration in code editing abilities. The dataset and the source code are\navailable at https://github.com/qishenghu/CodeInstruct.",
            "author": [
                "Qisheng Hu",
                "Kaixin Li",
                "Xu Zhao",
                "Yuxi Xie",
                "Tiedong Liu",
                "Hui Chen",
                "Qizhe Xie",
                "Junxian He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20329v1",
                "http://arxiv.org/pdf/2310.20329v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20328v1",
            "title": "ChiSCor: A Corpus of Freely Told Fantasy Stories by Dutch Children for\n  Computational Linguistics and Cognitive Science",
            "updated": "2023-10-31T10:15:20Z",
            "published": "2023-10-31T10:15:20Z",
            "summary": "In this resource paper we release ChiSCor, a new corpus containing 619\nfantasy stories, told freely by 442 Dutch children aged 4-12. ChiSCor was\ncompiled for studying how children render character perspectives, and\nunravelling language and cognition in development, with computational tools.\nUnlike existing resources, ChiSCor's stories were produced in natural contexts,\nin line with recent calls for more ecologically valid datasets. ChiSCor hosts\ntext, audio, and annotations for character complexity and linguistic\ncomplexity. Additional metadata (e.g. education of caregivers) is available for\none third of the Dutch children. ChiSCor also includes a small set of 62\nEnglish stories. This paper details how ChiSCor was compiled and shows its\npotential for future work with three brief case studies: i) we show that the\nsyntactic complexity of stories is strikingly stable across children's ages;\nii) we extend work on Zipfian distributions in free speech and show that\nChiSCor obeys Zipf's law closely, reflecting its social context; iii) we show\nthat even though ChiSCor is relatively small, the corpus is rich enough to\ntrain informative lemma vectors that allow us to analyse children's language\nuse. We end with a reflection on the value of narrative datasets in\ncomputational linguistics.",
            "author": [
                "Bram M. A. van Dijk",
                "Max J. van Duijn",
                "Suzan Verberne",
                "Marco R. Spruit"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20328v1",
                "http://arxiv.org/pdf/2310.20328v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20320v1",
            "title": "Theory of Mind in Large Language Models: Examining Performance of 11\n  State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests",
            "updated": "2023-10-31T09:55:07Z",
            "published": "2023-10-31T09:55:07Z",
            "summary": "To what degree should we ascribe cognitive capacities to Large Language\nModels (LLMs), such as the ability to reason about intentions and beliefs known\nas Theory of Mind (ToM)? Here we add to this emerging debate by (i) testing 11\nbase- and instruction-tuned LLMs on capabilities relevant to ToM beyond the\ndominant false-belief paradigm, including non-literal language usage and\nrecursive intentionality; (ii) using newly rewritten versions of standardized\ntests to gauge LLMs' robustness; (iii) prompting and scoring for open besides\nclosed questions; and (iv) benchmarking LLM performance against that of\nchildren aged 7-10 on the same tasks. We find that instruction-tuned LLMs from\nthe GPT family outperform other models, and often also children. Base-LLMs are\nmostly unable to solve ToM tasks, even with specialized prompting. We suggest\nthat the interlinked evolution and development of language and ToM may help\nexplain what instruction-tuning adds: rewarding cooperative communication that\ntakes into account interlocutor and context. We conclude by arguing for a\nnuanced perspective on ToM in LLMs.",
            "author": [
                "Max J. van Duijn",
                "Bram M. A. van Dijk",
                "Tom Kouwenhoven",
                "Werner de Valk",
                "Marco R. Spruit",
                "Peter van der Putten"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20320v1",
                "http://arxiv.org/pdf/2310.20320v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20319v1",
            "title": "GACE: Geometry Aware Confidence Enhancement for Black-Box 3D Object\n  Detectors on LiDAR-Data",
            "updated": "2023-10-31T09:55:04Z",
            "published": "2023-10-31T09:55:04Z",
            "summary": "Widely-used LiDAR-based 3D object detectors often neglect fundamental\ngeometric information readily available from the object proposals in their\nconfidence estimation. This is mostly due to architectural design choices,\nwhich were often adopted from the 2D image domain, where geometric context is\nrarely available. In 3D, however, considering the object properties and its\nsurroundings in a holistic way is important to distinguish between true and\nfalse positive detections, e.g. occluded pedestrians in a group. To address\nthis, we present GACE, an intuitive and highly efficient method to improve the\nconfidence estimation of a given black-box 3D object detector. We aggregate\ngeometric cues of detections and their spatial relationships, which enables us\nto properly assess their plausibility and consequently, improve the confidence\nestimation. This leads to consistent performance gains over a variety of\nstate-of-the-art detectors. Across all evaluated detectors, GACE proves to be\nespecially beneficial for the vulnerable road user classes, i.e. pedestrians\nand cyclists.",
            "author": [
                "David Schinagl",
                "Georg Krispel",
                "Christian Fruhwirth-Reisinger",
                "Horst Possegger",
                "Horst Bischof"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20319v1",
                "http://arxiv.org/pdf/2310.20319v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20316v1",
            "title": "HWD: A Novel Evaluation Score for Styled Handwritten Text Generation",
            "updated": "2023-10-31T09:44:27Z",
            "published": "2023-10-31T09:44:27Z",
            "summary": "Styled Handwritten Text Generation (Styled HTG) is an important task in\ndocument analysis, aiming to generate text images with the handwriting of given\nreference images. In recent years, there has been significant progress in the\ndevelopment of deep learning models for tackling this task. Being able to\nmeasure the performance of HTG models via a meaningful and representative\ncriterion is key for fostering the development of this research topic. However,\ndespite the current adoption of scores for natural image generation evaluation,\nassessing the quality of generated handwriting remains challenging. In light of\nthis, we devise the Handwriting Distance (HWD), tailored for HTG evaluation. In\nparticular, it works in the feature space of a network specifically trained to\nextract handwriting style features from the variable-lenght input images and\nexploits a perceptual distance to compare the subtle geometric features of\nhandwriting. Through extensive experimental evaluation on different word-level\nand line-level datasets of handwritten text images, we demonstrate the\nsuitability of the proposed HWD as a score for Styled HTG. The pretrained model\nused as backbone will be released to ease the adoption of the score, aiming to\nprovide a valuable tool for evaluating HTG models and thus contributing to\nadvancing this important research area.",
            "author": [
                "Vittorio Pippi",
                "Fabio Quattrini",
                "Silvia Cascianelli",
                "Rita Cucchiara"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20316v1",
                "http://arxiv.org/pdf/2310.20316v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20308v1",
            "title": "A physics-informed GAN Framework based on Model-free Data-Driven\n  Computational Mechanics",
            "updated": "2023-10-31T09:33:03Z",
            "published": "2023-10-31T09:33:03Z",
            "summary": "Model-free data-driven computational mechanics, first proposed by\nKirchdoerfer and Ortiz, replace phenomenological models with numerical\nsimulations based on sample data sets in strain-stress space. In this study, we\nintegrate this paradigm within physics-informed generative adversarial networks\n(GANs). We enhance the conventional physics-informed neural network framework\nby implementing the principles of data-driven computational mechanics into\nGANs. Specifically, the generator is informed by physical constraints, while\nthe discriminator utilizes the closest strain-stress data to discern the\nauthenticity of the generator's output. This combined approach presents a new\nformalism to harness data-driven mechanics and deep learning to simulate and\npredict mechanical behaviors.",
            "author": [
                "Kerem Ciftci",
                "Klaus Hackl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20308v1",
                "http://arxiv.org/pdf/2310.20308v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20307v1",
            "title": "Causal Interpretation of Self-Attention in Pre-Trained Transformers",
            "updated": "2023-10-31T09:27:12Z",
            "published": "2023-10-31T09:27:12Z",
            "summary": "We propose a causal interpretation of self-attention in the Transformer\nneural network architecture. We interpret self-attention as a mechanism that\nestimates a structural equation model for a given input sequence of symbols\n(tokens). The structural equation model can be interpreted, in turn, as a\ncausal structure over the input symbols under the specific context of the input\nsequence. Importantly, this interpretation remains valid in the presence of\nlatent confounders. Following this interpretation, we estimate conditional\nindependence relations between input symbols by calculating partial\ncorrelations between their corresponding representations in the deepest\nattention layer. This enables learning the causal structure over an input\nsequence using existing constraint-based algorithms. In this sense, existing\npre-trained Transformers can be utilized for zero-shot causal-discovery. We\ndemonstrate this method by providing causal explanations for the outcomes of\nTransformers in two tasks: sentiment classification (NLP) and recommendation.",
            "author": [
                "Raanan Y. Rohekar",
                "Yaniv Gurwicz",
                "Shami Nisimov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20307v1",
                "http://arxiv.org/pdf/2310.20307v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20301v1",
            "title": "Revolutionizing Global Food Security: Empowering Resilience through\n  Integrated AI Foundation Models and Data-Driven Solutions",
            "updated": "2023-10-31T09:15:35Z",
            "published": "2023-10-31T09:15:35Z",
            "summary": "Food security, a global concern, necessitates precise and diverse data-driven\nsolutions to address its multifaceted challenges. This paper explores the\nintegration of AI foundation models across various food security applications,\nleveraging distinct data types, to overcome the limitations of current deep and\nmachine learning methods. Specifically, we investigate their utilization in\ncrop type mapping, cropland mapping, field delineation and crop yield\nprediction. By capitalizing on multispectral imagery, meteorological data, soil\nproperties, historical records, and high-resolution satellite imagery, AI\nfoundation models offer a versatile approach. The study demonstrates that AI\nfoundation models enhance food security initiatives by providing accurate\npredictions, improving resource allocation, and supporting informed\ndecision-making. These models serve as a transformative force in addressing\nglobal food security limitations, marking a significant leap toward a\nsustainable and secure food future.",
            "author": [
                "Mohamed R. Shoaib",
                "Heba M. Emara",
                "Jun Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20301v1",
                "http://arxiv.org/pdf/2310.20301v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20299v1",
            "title": "Verification of Neural Networks Local Differential Classification\n  Privacy",
            "updated": "2023-10-31T09:11:12Z",
            "published": "2023-10-31T09:11:12Z",
            "summary": "Neural networks are susceptible to privacy attacks. To date, no verifier can\nreason about the privacy of individuals participating in the training set. We\npropose a new privacy property, called local differential classification\nprivacy (LDCP), extending local robustness to a differential privacy setting\nsuitable for black-box classifiers. Given a neighborhood of inputs, a\nclassifier is LDCP if it classifies all inputs the same regardless of whether\nit is trained with the full dataset or whether any single entry is omitted. A\nnaive algorithm is highly impractical because it involves training a very large\nnumber of networks and verifying local robustness of the given neighborhood\nseparately for every network. We propose Sphynx, an algorithm that computes an\nabstraction of all networks, with a high probability, from a small set of\nnetworks, and verifies LDCP directly on the abstract network. The challenge is\ntwofold: network parameters do not adhere to a known distribution probability,\nmaking it difficult to predict an abstraction, and predicting too large\nabstraction harms the verification. Our key idea is to transform the parameters\ninto a distribution given by KDE, allowing to keep the over-approximation error\nsmall. To verify LDCP, we extend a MILP verifier to analyze an abstract\nnetwork. Experimental results show that by training only 7% of the networks,\nSphynx predicts an abstract network obtaining 93% verification accuracy and\nreducing the analysis time by $1.7\\cdot10^4$x.",
            "author": [
                "Roie Reshef",
                "Anan Kabaha",
                "Olga Seleznova",
                "Dana Drachsler-Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20299v1",
                "http://arxiv.org/pdf/2310.20299v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20293v1",
            "title": "Annotator: A Generic Active Learning Baseline for LiDAR Semantic\n  Segmentation",
            "updated": "2023-10-31T09:04:39Z",
            "published": "2023-10-31T09:04:39Z",
            "summary": "Active learning, a label-efficient paradigm, empowers models to interactively\nquery an oracle for labeling new data. In the realm of LiDAR semantic\nsegmentation, the challenges stem from the sheer volume of point clouds,\nrendering annotation labor-intensive and cost-prohibitive. This paper presents\nAnnotator, a general and efficient active learning baseline, in which a\nvoxel-centric online selection strategy is tailored to efficiently probe and\nannotate the salient and exemplar voxel girds within each LiDAR scan, even\nunder distribution shift. Concretely, we first execute an in-depth analysis of\nseveral common selection strategies such as Random, Entropy, Margin, and then\ndevelop voxel confusion degree (VCD) to exploit the local topology relations\nand structures of point clouds. Annotator excels in diverse settings, with a\nparticular focus on active learning (AL), active source-free domain adaptation\n(ASFDA), and active domain adaptation (ADA). It consistently delivers\nexceptional performance across LiDAR semantic segmentation benchmarks, spanning\nboth simulation-to-real and real-to-real scenarios. Surprisingly, Annotator\nexhibits remarkable efficiency, requiring significantly fewer annotations,\ne.g., just labeling five voxels per scan in the SynLiDAR-to-SemanticKITTI task.\nThis results in impressive performance, achieving 87.8% fully-supervised\nperformance under AL, 88.5% under ASFDA, and 94.4% under ADA. We envision that\nAnnotator will offer a simple, general, and efficient solution for\nlabel-efficient 3D applications. Project page:\nhttps://binhuixie.github.io/annotator-web",
            "author": [
                "Binhui Xie",
                "Shuang Li",
                "Qingju Guo",
                "Chi Harold Liu",
                "Xinjing Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20293v1",
                "http://arxiv.org/pdf/2310.20293v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20292v1",
            "title": "IARS SegNet: Interpretable Attention Residual Skip connection SegNet for\n  melanoma segmentation",
            "updated": "2023-10-31T09:04:09Z",
            "published": "2023-10-31T09:04:09Z",
            "summary": "Skin lesion segmentation plays a crucial role in the computer-aided diagnosis\nof melanoma. Deep Learning models have shown promise in accurately segmenting\nskin lesions, but their widespread adoption in real-life clinical settings is\nhindered by their inherent black-box nature. In domains as critical as\nhealthcare, interpretability is not merely a feature but a fundamental\nrequirement for model adoption. This paper proposes IARS SegNet an advanced\nsegmentation framework built upon the SegNet baseline model. Our approach\nincorporates three critical components: Skip connections, residual\nconvolutions, and a global attention mechanism onto the baseline Segnet\narchitecture. These elements play a pivotal role in accentuating the\nsignificance of clinically relevant regions, particularly the contours of skin\nlesions. The inclusion of skip connections enhances the model's capacity to\nlearn intricate contour details, while the use of residual convolutions allows\nfor the construction of a deeper model while preserving essential image\nfeatures. The global attention mechanism further contributes by extracting\nrefined feature maps from each convolutional and deconvolutional block, thereby\nelevating the model's interpretability. This enhancement highlights critical\nregions, fosters better understanding, and leads to more accurate skin lesion\nsegmentation for melanoma diagnosis.",
            "author": [
                "Shankara Narayanan V",
                "Sikha OK",
                "Raul Benitez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20292v1",
                "http://arxiv.org/pdf/2310.20292v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20287v1",
            "title": "Sample-Efficient and Safe Deep Reinforcement Learning via Reset Deep\n  Ensemble Agents",
            "updated": "2023-10-31T08:59:39Z",
            "published": "2023-10-31T08:59:39Z",
            "summary": "Deep reinforcement learning (RL) has achieved remarkable success in solving\ncomplex tasks through its integration with deep neural networks (DNNs) as\nfunction approximators. However, the reliance on DNNs has introduced a new\nchallenge called primacy bias, whereby these function approximators tend to\nprioritize early experiences, leading to overfitting. To mitigate this primacy\nbias, a reset method has been proposed, which performs periodic resets of a\nportion or the entirety of a deep RL agent while preserving the replay buffer.\nHowever, the use of the reset method can result in performance collapses after\nexecuting the reset, which can be detrimental from the perspective of safe RL\nand regret minimization. In this paper, we propose a new reset-based method\nthat leverages deep ensemble learning to address the limitations of the vanilla\nreset method and enhance sample efficiency. The proposed method is evaluated\nthrough various experiments including those in the domain of safe RL. Numerical\nresults show its effectiveness in high sample efficiency and safety\nconsiderations.",
            "author": [
                "Woojun Kim",
                "Yongjae Shin",
                "Jongeui Park",
                "Youngchul Sung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20287v1",
                "http://arxiv.org/pdf/2310.20287v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20285v1",
            "title": "Accelerating Generalized Linear Models by Trading off Computation for\n  Uncertainty",
            "updated": "2023-10-31T08:58:16Z",
            "published": "2023-10-31T08:58:16Z",
            "summary": "Bayesian Generalized Linear Models (GLMs) define a flexible probabilistic\nframework to model categorical, ordinal and continuous data, and are widely\nused in practice. However, exact inference in GLMs is prohibitively expensive\nfor large datasets, thus requiring approximations in practice. The resulting\napproximation error adversely impacts the reliability of the model and is not\naccounted for in the uncertainty of the prediction. In this work, we introduce\na family of iterative methods that explicitly model this error. They are\nuniquely suited to parallel modern computing hardware, efficiently recycle\ncomputations, and compress information to reduce both the time and memory\nrequirements for GLMs. As we demonstrate on a realistically large\nclassification problem, our method significantly accelerates training by\nexplicitly trading off reduced computation for increased uncertainty.",
            "author": [
                "Lukas Tatzel",
                "Jonathan Wenger",
                "Frank Schneider",
                "Philipp Hennig"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20285v1",
                "http://arxiv.org/pdf/2310.20285v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20280v2",
            "title": "AutoMixer for Improved Multivariate Time-Series Forecasting on Business\n  and IT Observability Data",
            "updated": "2023-11-02T09:17:55Z",
            "published": "2023-10-31T08:50:52Z",
            "summary": "The efficiency of business processes relies on business key performance\nindicators (Biz-KPIs), that can be negatively impacted by IT failures. Business\nand IT Observability (BizITObs) data fuses both Biz-KPIs and IT event channels\ntogether as multivariate time series data. Forecasting Biz-KPIs in advance can\nenhance efficiency and revenue through proactive corrective measures. However,\nBizITObs data generally exhibit both useful and noisy inter-channel\ninteractions between Biz-KPIs and IT events that need to be effectively\ndecoupled. This leads to suboptimal forecasting performance when existing\nmultivariate forecasting models are employed. To address this, we introduce\nAutoMixer, a time-series Foundation Model (FM) approach, grounded on the novel\ntechnique of channel-compressed pretrain and finetune workflows. AutoMixer\nleverages an AutoEncoder for channel-compressed pretraining and integrates it\nwith the advanced TSMixer model for multivariate time series forecasting. This\nfusion greatly enhances the potency of TSMixer for accurate forecasts and also\ngeneralizes well across several downstream tasks. Through detailed experiments\nand dashboard analytics, we show AutoMixer's capability to consistently improve\nthe Biz-KPI's forecasting accuracy (by 11-15\\%) which directly translates to\nactionable business insights.",
            "author": [
                "Santosh Palaskar",
                "Vijay Ekambaram",
                "Arindam Jati",
                "Neelamadhav Gantayat",
                "Avirup Saha",
                "Seema Nagar",
                "Nam H. Nguyen",
                "Pankaj Dayama",
                "Renuka Sindhgatta",
                "Prateeti Mohapatra",
                "Harshit Kumar",
                "Jayant Kalagnanam",
                "Nandyala Hemachandra",
                "Narayan Rangaraj"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20280v2",
                "http://arxiv.org/pdf/2310.20280v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20279v1",
            "title": "Machine learning refinement of in situ images acquired by low electron\n  dose LC-TEM",
            "updated": "2023-10-31T08:48:59Z",
            "published": "2023-10-31T08:48:59Z",
            "summary": "We study a machine learning (ML) technique for refining images acquired\nduring in situ observation using liquid-cell transmission electron microscopy\n(LC-TEM). Our model is constructed using a U-Net architecture and a ResNet\nencoder. For training our ML model, we prepared an original image dataset that\ncontained pairs of images of samples acquired with and without a solution\npresent. The former images were used as noisy images and the latter images were\nused as corresponding ground truth images. The number of pairs of image sets\nwas $1,204$ and the image sets included images acquired at several different\nmagnifications and electron doses. The trained model converted a noisy image\ninto a clear image. The time necessary for the conversion was on the order of\n10ms, and we applied the model to in situ observations using the software Gatan\nDigitalMicrograph (DM). Even if a nanoparticle was not visible in a view window\nin the DM software because of the low electron dose, it was visible in a\nsuccessive refined image generated by our ML model.",
            "author": [
                "Hiroyasu Katsuno",
                "Yuki Kimura",
                "Tomoya Yamazaki",
                "Ichigaku Takigawa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20279v1",
                "http://arxiv.org/pdf/2310.20279v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20275v1",
            "title": "Age Optimum Sampling in Non-Stationary Environment",
            "updated": "2023-10-31T08:43:33Z",
            "published": "2023-10-31T08:43:33Z",
            "summary": "In this work, we consider a status update system with a sensor and a\nreceiver. The status update information is sampled by the sensor and then\nforwarded to the receiver through a channel with non-stationary delay\ndistribution. The data freshness at the receiver is quantified by the\nAge-of-Information (AoI). The goal is to design an online sampling strategy\nthat can minimize the average AoI when the non-stationary delay distribution is\nunknown. Assuming that channel delay distribution may change over time, to\nminimize the average AoI, we propose a joint stochastic approximation and\nnon-parametric change point detection algorithm that can: (1) learn the optimum\nupdate threshold when the delay distribution remains static; (2) detect the\nchange in transmission delay distribution quickly and then restart the learning\nprocess. Simulation results show that the proposed algorithm can quickly detect\nthe delay changes, and the average AoI obtained by the proposed policy\nconverges to the minimum AoI.",
            "author": [
                "Jinheng Zhang",
                "Haoyue Tang",
                "Jintao Wang",
                "Sastry Kompella",
                "Leandros Tassiulas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20275v1",
                "http://arxiv.org/pdf/2310.20275v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20274v1",
            "title": "Extracting Entities of Interest from Comparative Product Reviews",
            "updated": "2023-10-31T08:43:11Z",
            "published": "2023-10-31T08:43:11Z",
            "summary": "This paper presents a deep learning based approach to extract product\ncomparison information out of user reviews on various e-commerce websites. Any\ncomparative product review has three major entities of information: the names\nof the products being compared, the user opinion (predicate) and the feature or\naspect under comparison. All these informing entities are dependent on each\nother and bound by the rules of the language, in the review. We observe that\ntheir inter-dependencies can be captured well using LSTMs. We evaluate our\nsystem on existing manually labeled datasets and observe out-performance over\nthe existing Semantic Role Labeling (SRL) framework popular for this task.",
            "author": [
                "Jatin Arora",
                "Sumit Agrawal",
                "Pawan Goyal",
                "Sayan Pathak"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3132847.3133141",
                "http://arxiv.org/abs/2310.20274v1",
                "http://arxiv.org/pdf/2310.20274v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL",
                "cs.LG",
                "I.2.7; H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20271v2",
            "title": "From Denoising Training to Test-Time Adaptation: Enhancing Domain\n  Generalization for Medical Image Segmentation",
            "updated": "2023-11-03T03:48:43Z",
            "published": "2023-10-31T08:39:15Z",
            "summary": "In medical image segmentation, domain generalization poses a significant\nchallenge due to domain shifts caused by variations in data acquisition devices\nand other factors. These shifts are particularly pronounced in the most common\nscenario, which involves only single-source domain data due to privacy\nconcerns. To address this, we draw inspiration from the self-supervised\nlearning paradigm that effectively discourages overfitting to the source\ndomain. We propose the Denoising Y-Net (DeY-Net), a novel approach\nincorporating an auxiliary denoising decoder into the basic U-Net architecture.\nThe auxiliary decoder aims to perform denoising training, augmenting the\ndomain-invariant representation that facilitates domain generalization.\nFurthermore, this paradigm provides the potential to utilize unlabeled data.\nBuilding upon denoising training, we propose Denoising Test Time Adaptation\n(DeTTA) that further: (i) adapts the model to the target domain in a\nsample-wise manner, and (ii) adapts to the noise-corrupted input. Extensive\nexperiments conducted on widely-adopted liver segmentation benchmarks\ndemonstrate significant domain generalization improvements over our baseline\nand state-of-the-art results compared to other methods. Code is available at\nhttps://github.com/WenRuxue/DeTTA.",
            "author": [
                "Ruxue Wen",
                "Hangjie Yuan",
                "Dong Ni",
                "Wenbo Xiao",
                "Yaoyao Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20271v2",
                "http://arxiv.org/pdf/2310.20271v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20268v1",
            "title": "Constructing Sample-to-Class Graph for Few-Shot Class-Incremental\n  Learning",
            "updated": "2023-10-31T08:38:14Z",
            "published": "2023-10-31T08:38:14Z",
            "summary": "Few-shot class-incremental learning (FSCIL) aims to build machine learning\nmodel that can continually learn new concepts from a few data samples, without\nforgetting knowledge of old classes.\n  The challenges of FSCIL lies in the limited data of new classes, which not\nonly lead to significant overfitting issues but also exacerbates the notorious\ncatastrophic forgetting problems. As proved in early studies, building sample\nrelationships is beneficial for learning from few-shot samples. In this paper,\nwe promote the idea to the incremental scenario, and propose a Sample-to-Class\n(S2C) graph learning method for FSCIL.\n  Specifically, we propose a Sample-level Graph Network (SGN) that focuses on\nanalyzing sample relationships within a single session. This network helps\naggregate similar samples, ultimately leading to the extraction of more refined\nclass-level features.\n  Then, we present a Class-level Graph Network (CGN) that establishes\nconnections across class-level features of both new and old classes. This\nnetwork plays a crucial role in linking the knowledge between different\nsessions and helps improve overall learning in the FSCIL scenario. Moreover, we\ndesign a multi-stage strategy for training S2C model, which mitigates the\ntraining challenges posed by limited data in the incremental process.\n  The multi-stage training strategy is designed to build S2C graph from base to\nfew-shot stages, and improve the capacity via an extra pseudo-incremental\nstage. Experiments on three popular benchmark datasets show that our method\nclearly outperforms the baselines and sets new state-of-the-art results in\nFSCIL.",
            "author": [
                "Fuyuan Hu",
                "Jian Zhang",
                "Fan Lyu",
                "Linyan Li",
                "Fenglei Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20268v1",
                "http://arxiv.org/pdf/2310.20268v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20266v1",
            "title": "Beyond Average Return in Markov Decision Processes",
            "updated": "2023-10-31T08:36:41Z",
            "published": "2023-10-31T08:36:41Z",
            "summary": "What are the functionals of the reward that can be computed and optimized\nexactly in Markov Decision Processes? In the finite-horizon, undiscounted\nsetting, Dynamic Programming (DP) can only handle these operations efficiently\nfor certain classes of statistics. We summarize the characterization of these\nclasses for policy evaluation, and give a new answer for the planning problem.\nInterestingly, we prove that only generalized means can be optimized exactly,\neven in the more general framework of Distributional Reinforcement Learning\n(DistRL).DistRL permits, however, to evaluate other functionals approximately.\nWe provide error bounds on the resulting estimators, and discuss the potential\nof this approach as well as its limitations.These results contribute to\nadvancing the theory of Markov Decision Processes by examining overall\ncharacteristics of the return, and particularly risk-conscious strategies.",
            "author": [
                "Alexandre Marthe",
                "Aur\u00e9lien Garivier",
                "Claire Vernade"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20266v1",
                "http://arxiv.org/pdf/2310.20266v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "math.OC",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20265v1",
            "title": "Low-Dose CT Image Enhancement Using Deep Learning",
            "updated": "2023-10-31T08:34:33Z",
            "published": "2023-10-31T08:34:33Z",
            "summary": "The application of ionizing radiation for diagnostic imaging is common around\nthe globe. However, the process of imaging, itself, remains to be a relatively\nhazardous operation. Therefore, it is preferable to use as low a dose of\nionizing radiation as possible, particularly in computed tomography (CT)\nimaging systems, where multiple x-ray operations are performed for the\nreconstruction of slices of body tissues. A popular method for radiation dose\nreduction in CT imaging is known as the quarter-dose technique, which reduces\nthe x-ray dose but can cause a loss of image sharpness. Since CT image\nreconstruction from directional x-rays is a nonlinear process, it is\nanalytically difficult to correct the effect of dose reduction on image\nquality. Recent and popular deep-learning approaches provide an intriguing\npossibility of image enhancement for low-dose artifacts. Some recent works\npropose combinations of multiple deep-learning and classical methods for this\npurpose, which over-complicate the process. However, it is observed here that\nthe straight utilization of the well-known U-NET provides very successful\nresults for the correction of low-dose artifacts. Blind tests with actual\nradiologists reveal that the U-NET enhanced quarter-dose CT images not only\nprovide an immense visual improvement over the low-dose versions, but also\nbecome diagnostically preferable images, even when compared to their full-dose\nCT versions.",
            "author": [
                "A. Demir",
                "M. M. A. Shames",
                "O. N. Gerek",
                "S. Ergin",
                "M. Fidan",
                "M. Koc",
                "M. B. Gulmezoglu",
                "A. Barkana",
                "C. Calisir"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20265v1",
                "http://arxiv.org/pdf/2310.20265v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20260v1",
            "title": "Learning to Play Chess from Textbooks (LEAP): a Corpus for Evaluating\n  Chess Moves based on Sentiment Analysis",
            "updated": "2023-10-31T08:26:02Z",
            "published": "2023-10-31T08:26:02Z",
            "summary": "Learning chess strategies has been investigated widely, with most studies\nfocussing on learning from previous games using search algorithms. Chess\ntextbooks encapsulate grandmaster knowledge, explain playing strategies and\nrequire a smaller search space compared to traditional chess agents. This paper\nexamines chess textbooks as a new knowledge source for enabling machines to\nlearn how to play chess -- a resource that has not been explored previously. We\ndeveloped the LEAP corpus, a first and new heterogeneous dataset with\nstructured (chess move notations and board states) and unstructured data\n(textual descriptions) collected from a chess textbook containing 1164\nsentences discussing strategic moves from 91 games. We firstly labelled the\nsentences based on their relevance, i.e., whether they are discussing a move.\nEach relevant sentence was then labelled according to its sentiment towards the\ndescribed move. We performed empirical experiments that assess the performance\nof various transformer-based baseline models for sentiment analysis. Our\nresults demonstrate the feasibility of employing transformer-based sentiment\nanalysis models for evaluating chess moves, with the best performing model\nobtaining a weighted micro F_1 score of 68%. Finally, we synthesised the LEAP\ncorpus to create a larger dataset, which can be used as a solution to the\nlimited textual resource in the chess domain.",
            "author": [
                "Haifa Alrdahi",
                "Riza Batista-Navarro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20260v1",
                "http://arxiv.org/pdf/2310.20260v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20258v3",
            "title": "Advancing Bayesian Optimization via Learning Correlated Latent Space",
            "updated": "2023-11-20T03:43:31Z",
            "published": "2023-10-31T08:24:41Z",
            "summary": "Bayesian optimization is a powerful method for optimizing black-box functions\nwith limited function evaluations. Recent works have shown that optimization in\na latent space through deep generative models such as variational autoencoders\nleads to effective and efficient Bayesian optimization for structured or\ndiscrete data. However, as the optimization does not take place in the input\nspace, it leads to an inherent gap that results in potentially suboptimal\nsolutions. To alleviate the discrepancy, we propose Correlated latent space\nBayesian Optimization (CoBO), which focuses on learning correlated latent\nspaces characterized by a strong correlation between the distances in the\nlatent space and the distances within the objective function. Specifically, our\nmethod introduces Lipschitz regularization, loss weighting, and trust region\nrecoordination to minimize the inherent gap around the promising areas. We\ndemonstrate the effectiveness of our approach on several optimization tasks in\ndiscrete data, such as molecule design and arithmetic expression fitting, and\nachieve high performance within a small budget.",
            "author": [
                "Seunghun Lee",
                "Jaewon Chu",
                "Sihyeon Kim",
                "Juyeon Ko",
                "Hyunwoo J. Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20258v3",
                "http://arxiv.org/pdf/2310.20258v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20254v1",
            "title": "Artificial Intelligence for reverse engineering: application to\n  detergents using Raman spectroscopy",
            "updated": "2023-10-31T08:16:22Z",
            "published": "2023-10-31T08:16:22Z",
            "summary": "The reverse engineering of a complex mixture, regardless of its nature, has\nbecome significant today. Being able to quickly assess the potential toxicity\nof new commercial products in relation to the environment presents a genuine\nanalytical challenge. The development of digital tools (databases,\nchemometrics, machine learning, etc.) and analytical techniques (Raman\nspectroscopy, NIR spectroscopy, mass spectrometry, etc.) will allow for the\nidentification of potential toxic molecules. In this article, we use the\nexample of detergent products, whose composition can prove dangerous to humans\nor the environment, necessitating precise identification and quantification for\nquality control and regulation purposes. The combination of various digital\ntools (spectral database, mixture database, experimental design, Chemometrics /\nMachine Learning algorithm{\\ldots}) together with different sample preparation\nmethods (raw sample, or several concentrated / diluted samples) Raman\nspectroscopy, has enabled the identification of the mixture's constituents and\nan estimation of its composition. Implementing such strategies across different\nanalytical tools can result in time savings for pollutant identification and\ncontamination assessment in various matrices. This strategy is also applicable\nin the industrial sector for product or raw material control, as well as for\nquality control purposes.",
            "author": [
                "Pedro Marote",
                "Marie Martin",
                "Anne Bonhomme",
                "Pierre Lant\u00e9ri",
                "Yohann Cl\u00e9ment"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20254v1",
                "http://arxiv.org/pdf/2310.20254v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20252v1",
            "title": "Dynamic heterogeneity at the experimental glass transition predicted by\n  transferable machine learning",
            "updated": "2023-10-31T08:14:02Z",
            "published": "2023-10-31T08:14:02Z",
            "summary": "We develop a transferable machine learning model which predicts structural\nrelaxation from amorphous supercooled liquid structures. The trained networks\nare able to predict dynamic heterogeneity across a broad range of temperatures\nand time scales with excellent accuracy and transferability. We use the network\ntransferability to predict dynamic heterogeneity down to the experimental glass\ntransition temperature, $T_g$, where structural relaxation cannot be analyzed\nusing molecular dynamics simulations. The results indicate that the strength,\nthe geometry and the characteristic length scale of the dynamic heterogeneity\nevolve much more slowly near $T_g$ compared to their evolution at higher\ntemperatures. Our results show that machine learning techniques can provide\nphysical insights on the nature of the glass transition that cannot be gained\nusing conventional simulation techniques.",
            "author": [
                "Gerhard Jung",
                "Giulio Biroli",
                "Ludovic Berthier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20252v1",
                "http://arxiv.org/pdf/2310.20252v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20250v1",
            "title": "Diversified Node Sampling based Hierarchical Transformer Pooling for\n  Graph Representation Learning",
            "updated": "2023-10-31T08:13:21Z",
            "published": "2023-10-31T08:13:21Z",
            "summary": "Graph pooling methods have been widely used on downsampling graphs, achieving\nimpressive results on multiple graph-level tasks like graph classification and\ngraph generation. An important line called node dropping pooling aims at\nexploiting learnable scoring functions to drop nodes with comparatively lower\nsignificance scores. However, existing node dropping methods suffer from two\nlimitations: (1) for each pooled node, these models struggle to capture\nlong-range dependencies since they mainly take GNNs as the backbones; (2)\npooling only the highest-scoring nodes tends to preserve similar nodes, thus\ndiscarding the affluent information of low-scoring nodes. To address these\nissues, we propose a Graph Transformer Pooling method termed GTPool, which\nintroduces Transformer to node dropping pooling to efficiently capture\nlong-range pairwise interactions and meanwhile sample nodes diversely.\nSpecifically, we design a scoring module based on the self-attention mechanism\nthat takes both global context and local context into consideration, measuring\nthe importance of nodes more comprehensively. GTPool further utilizes a\ndiversified sampling method named Roulette Wheel Sampling (RWS) that is able to\nflexibly preserve nodes across different scoring intervals instead of only\nhigher scoring nodes. In this way, GTPool could effectively obtain long-range\ninformation and select more representative nodes. Extensive experiments on 11\nbenchmark datasets demonstrate the superiority of GTPool over existing popular\ngraph pooling methods.",
            "author": [
                "Gaichao Li",
                "Jinsong Chen",
                "John E. Hopcroft",
                "Kun He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20250v1",
                "http://arxiv.org/pdf/2310.20250v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20249v1",
            "title": "Pose-to-Motion: Cross-Domain Motion Retargeting with Pose Prior",
            "updated": "2023-10-31T08:13:00Z",
            "published": "2023-10-31T08:13:00Z",
            "summary": "Creating believable motions for various characters has long been a goal in\ncomputer graphics. Current learning-based motion synthesis methods depend on\nextensive motion datasets, which are often challenging, if not impossible, to\nobtain. On the other hand, pose data is more accessible, since static posed\ncharacters are easier to create and can even be extracted from images using\nrecent advancements in computer vision. In this paper, we utilize this\nalternative data source and introduce a neural motion synthesis approach\nthrough retargeting. Our method generates plausible motions for characters that\nhave only pose data by transferring motion from an existing motion capture\ndataset of another character, which can have drastically different skeletons.\nOur experiments show that our method effectively combines the motion features\nof the source character with the pose features of the target character, and\nperforms robustly with small or noisy pose data sets, ranging from a few\nartist-created poses to noisy poses estimated directly from images.\nAdditionally, a conducted user study indicated that a majority of participants\nfound our retargeted motion to be more enjoyable to watch, more lifelike in\nappearance, and exhibiting fewer artifacts. Project page:\nhttps://cyanzhao42.github.io/pose2motion",
            "author": [
                "Qingqing Zhao",
                "Peizhuo Li",
                "Wang Yifan",
                "Olga Sorkine-Hornung",
                "Gordon Wetzstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20249v1",
                "http://arxiv.org/pdf/2310.20249v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20246v4",
            "title": "Breaking Language Barriers in Multilingual Mathematical Reasoning:\n  Insights and Observations",
            "updated": "2023-11-28T05:25:14Z",
            "published": "2023-10-31T08:09:20Z",
            "summary": "Existing research predominantly focuses on developing powerful language\nlearning models (LLMs) for mathematical reasoning within monolingual languages,\nwith few explorations in preserving efficacy in a multilingual context. To\nbridge this gap, this paper pioneers exploring and training powerful\nMultilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we\nconstruct the first multilingual math reasoning instruction dataset,\nMGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue\nof training data scarcity in xMR tasks. Based on the collected dataset, we\npropose different training strategies to build powerful xMR LLMs, named\nMathOctopus, notably outperform conventional open-source LLMs and exhibit\nsuperiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B\nreaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond\nremarkable results, we unearth several pivotal observations and insights from\nextensive experiments: (1) When extending the rejection sampling strategy to\nthe multilingual context, it proves effective for model performances, albeit\nlimited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT)\nacross multiple languages not only significantly enhances model performance\nmultilingually but also elevates their monolingual performance. This indicates\nthat crafting multilingual corpora can be regarded as a vital strategy for\nenhancing model performance in a specific language, especially in mathematical\nreasoning tasks. For instance, MathOctopus-7B improves its counterparts that\ntrained on English from 42.2% to 50.8% on GSM8K testset.",
            "author": [
                "Nuo Chen",
                "Zinan Zheng",
                "Ning Wu",
                "Ming Gong",
                "Yangqiu Song",
                "Dongmei Zhang",
                "Jia Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20246v4",
                "http://arxiv.org/pdf/2310.20246v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20240v1",
            "title": "Breathing Life into Faces: Speech-driven 3D Facial Animation with\n  Natural Head Pose and Detailed Shape",
            "updated": "2023-10-31T07:47:19Z",
            "published": "2023-10-31T07:47:19Z",
            "summary": "The creation of lifelike speech-driven 3D facial animation requires a natural\nand precise synchronization between audio input and facial expressions.\nHowever, existing works still fail to render shapes with flexible head poses\nand natural facial details (e.g., wrinkles). This limitation is mainly due to\ntwo aspects: 1) Collecting training set with detailed 3D facial shapes is\nhighly expensive. This scarcity of detailed shape annotations hinders the\ntraining of models with expressive facial animation. 2) Compared to mouth\nmovement, the head pose is much less correlated to speech content.\nConsequently, concurrent modeling of both mouth movement and head pose yields\nthe lack of facial movement controllability. To address these challenges, we\nintroduce VividTalker, a new framework designed to facilitate speech-driven 3D\nfacial animation characterized by flexible head pose and natural facial\ndetails. Specifically, we explicitly disentangle facial animation into head\npose and mouth movement and encode them separately into discrete latent spaces.\nThen, these attributes are generated through an autoregressive process\nleveraging a window-based Transformer architecture. To augment the richness of\n3D facial animation, we construct a new 3D dataset with detailed shapes and\nlearn to synthesize facial details in line with speech content. Extensive\nquantitative and qualitative experiments demonstrate that VividTalker\noutperforms state-of-the-art methods, resulting in vivid and realistic\nspeech-driven 3D facial animation.",
            "author": [
                "Wei Zhao",
                "Yijun Wang",
                "Tianyu He",
                "Lianying Yin",
                "Jianxin Lin",
                "Xin Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20240v1",
                "http://arxiv.org/pdf/2310.20240v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20236v1",
            "title": "Dynamically Updating Event Representations for Temporal Relation\n  Classification with Multi-category Learning",
            "updated": "2023-10-31T07:41:24Z",
            "published": "2023-10-31T07:41:24Z",
            "summary": "Temporal relation classification is a pair-wise task for identifying the\nrelation of a temporal link (TLINK) between two mentions, i.e. event, time, and\ndocument creation time (DCT). It leads to two crucial limits: 1) Two TLINKs\ninvolving a common mention do not share information. 2) Existing models with\nindependent classifiers for each TLINK category (E2E, E2T, and E2D) hinder from\nusing the whole data. This paper presents an event centric model that allows to\nmanage dynamic event representations across multiple TLINKs. Our model deals\nwith three TLINK categories with multi-task learning to leverage the full size\nof data. The experimental results show that our proposal outperforms\nstate-of-the-art models and two transfer learning baselines on both the English\nand Japanese data.",
            "author": [
                "Fei Cheng",
                "Masayuki Asahara",
                "Ichiro Kobayashi",
                "Sadao Kurohashi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20236v1",
                "http://arxiv.org/pdf/2310.20236v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04225v1",
            "title": "Fast, accurate, and interpretable decoding of electrocorticographic\n  signals using dynamic mode decomposition",
            "updated": "2023-10-31T07:13:43Z",
            "published": "2023-10-31T07:13:43Z",
            "summary": "Dynamic mode (DM) decomposition decomposes spatiotemporal signals into basic\noscillatory components (DMs). DMs can improve the accuracy of neural decoding\nwhen used with the nonlinear Grassmann kernel, compared to conventional power\nfeatures. However, such kernel-based machine learning algorithms have three\nlimitations: large computational time preventing real-time application,\nincompatibility with non-kernel algorithms, and low interpretability. Here, we\npropose a mapping function corresponding to the Grassmann kernel that\nexplicitly transforms DMs into spatial DM (sDM) features, which can be used in\nany machine learning algorithm. Using electrocorticographic signals recorded\nduring various movement and visual perception tasks, the sDM features were\nshown to improve the decoding accuracy and computational time compared to\nconventional methods. Furthermore, the components of the sDM features\ninformative for decoding showed similar characteristics to the high-$\\gamma$\npower of the signals, but with higher trial-to-trial reproducibility. The\nproposed sDM features enable fast, accurate, and interpretable neural decoding.",
            "author": [
                "Ryohei Fukuma",
                "Kei Majima",
                "Yoshinobu Kawahara",
                "Okito Yamashita",
                "Yoshiyuki Shiraishi",
                "Haruhiko Kishima",
                "Takufumi Yanagisawa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04225v1",
                "http://arxiv.org/pdf/2311.04225v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10746v1",
            "title": "EIT: Earnest Insight Toolkit for Evaluating Students' Earnestness in\n  Interactive Lecture Participation Exercises",
            "updated": "2023-10-31T07:05:00Z",
            "published": "2023-10-31T07:05:00Z",
            "summary": "In today's rapidly evolving educational landscape, traditional modes of\npassive information delivery are giving way to transformative pedagogical\napproaches that prioritize active student engagement. Within the context of\nlarge-scale hybrid classrooms, the challenge lies in fostering meaningful and\nactive interaction between students and course content. This study delves into\nthe significance of measuring students' earnestness during interactive lecture\nparticipation exercises. By analyzing students' responses to interactive\nlecture poll questions, establishing a clear rubric for evaluating earnestness,\nand conducting a comprehensive assessment, we introduce EIT (Earnest Insight\nToolkit), a tool designed to assess students' engagement within interactive\nlecture participation exercises - particularly in the context of large-scale\nhybrid classrooms. Through the utilization of EIT, our objective is to equip\neducators with valuable means of identifying at-risk students for enhancing\nintervention and support strategies, as well as measuring students' levels of\nengagement with course content.",
            "author": [
                "Mihran Miroyan",
                "Shiny Weng",
                "Rahul Shah",
                "Lisa Yan",
                "Narges Norouzi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10746v1",
                "http://arxiv.org/pdf/2311.10746v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20224v1",
            "title": "Choose A Table: Tensor Dirichlet Process Multinomial Mixture Model with\n  Graphs for Passenger Trajectory Clustering",
            "updated": "2023-10-31T06:53:04Z",
            "published": "2023-10-31T06:53:04Z",
            "summary": "Passenger clustering based on trajectory records is essential for\ntransportation operators. However, existing methods cannot easily cluster the\npassengers due to the hierarchical structure of the passenger trip information,\nincluding multiple trips within each passenger and multi-dimensional\ninformation about each trip. Furthermore, existing approaches rely on an\naccurate specification of the clustering number to start. Finally, existing\nmethods do not consider spatial semantic graphs such as geographical proximity\nand functional similarity between the locations. In this paper, we propose a\nnovel tensor Dirichlet Process Multinomial Mixture model with graphs, which can\npreserve the hierarchical structure of the multi-dimensional trip information\nand cluster them in a unified one-step manner with the ability to determine the\nnumber of clusters automatically. The spatial graphs are utilized in community\ndetection to link the semantic neighbors. We further propose a tensor version\nof Collapsed Gibbs Sampling method with a minimum cluster size requirement. A\ncase study based on Hong Kong metro passenger data is conducted to demonstrate\nthe automatic process of cluster amount evolution and better cluster quality\nmeasured by within-cluster compactness and cross-cluster separateness. The code\nis available at https://github.com/bonaldli/TensorDPMM-G.",
            "author": [
                "Ziyue Li",
                "Hao Yan",
                "Chen Zhang",
                "Lijun Sun",
                "Wolfgang Ketter",
                "Fugee Tsung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20224v1",
                "http://arxiv.org/pdf/2310.20224v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20223v1",
            "title": "STDA-Meta: A Meta-Learning Framework for Few-Shot Traffic Prediction",
            "updated": "2023-10-31T06:52:56Z",
            "published": "2023-10-31T06:52:56Z",
            "summary": "As the development of cities, traffic congestion becomes an increasingly\npressing issue, and traffic prediction is a classic method to relieve that\nissue. Traffic prediction is one specific application of spatio-temporal\nprediction learning, like taxi scheduling, weather prediction, and ship\ntrajectory prediction. Against these problems, classical spatio-temporal\nprediction learning methods including deep learning, require large amounts of\ntraining data. In reality, some newly developed cities with insufficient\nsensors would not hold that assumption, and the data scarcity makes predictive\nperformance worse. In such situation, the learning method on insufficient data\nis known as few-shot learning (FSL), and the FSL of traffic prediction remains\nchallenges. On the one hand, graph structures' irregularity and dynamic nature\nof graphs cannot hold the performance of spatio-temporal learning method. On\nthe other hand, conventional domain adaptation methods cannot work well on\ninsufficient training data, when transferring knowledge from different domains\nto the intended target domain.To address these challenges, we propose a novel\nspatio-temporal domain adaptation (STDA) method that learns transferable\nspatio-temporal meta-knowledge from data-sufficient cities in an adversarial\nmanner. This learned meta-knowledge can improve the prediction performance of\ndata-scarce cities. Specifically, we train the STDA model using a\nModel-Agnostic Meta-Learning (MAML) based episode learning process, which is a\nmodel-agnostic meta-learning framework that enables the model to solve new\nlearning tasks using only a small number of training samples. We conduct\nnumerous experiments on four traffic prediction datasets, and our results show\nthat the prediction performance of our model has improved by 7\\% compared to\nbaseline models on the two metrics of MAE and RMSE.",
            "author": [
                "Maoxiang Sun",
                "Weilong Ding",
                "Tianpu Zhang",
                "Zijian Liu",
                "Mengda Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20223v1",
                "http://arxiv.org/pdf/2310.20223v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20218v1",
            "title": "A Systematic Review for Transformer-based Long-term Series Forecasting",
            "updated": "2023-10-31T06:37:51Z",
            "published": "2023-10-31T06:37:51Z",
            "summary": "The emergence of deep learning has yielded noteworthy advancements in time\nseries forecasting (TSF). Transformer architectures, in particular, have\nwitnessed broad utilization and adoption in TSF tasks. Transformers have proven\nto be the most successful solution to extract the semantic correlations among\nthe elements within a long sequence. Various variants have enabled transformer\narchitecture to effectively handle long-term time series forecasting (LTSF)\ntasks. In this article, we first present a comprehensive overview of\ntransformer architectures and their subsequent enhancements developed to\naddress various LTSF tasks. Then, we summarize the publicly available LTSF\ndatasets and relevant evaluation metrics. Furthermore, we provide valuable\ninsights into the best practices and techniques for effectively training\ntransformers in the context of time-series analysis. Lastly, we propose\npotential research directions in this rapidly evolving field.",
            "author": [
                "Liyilei Su",
                "Xumin Zuo",
                "Rui Li",
                "Xin Wang",
                "Heng Zhao",
                "Bingding Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20218v1",
                "http://arxiv.org/pdf/2310.20218v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20215v1",
            "title": "Handover Protocol Learning for LEO Satellite Networks: Access Delay and\n  Collision Minimization",
            "updated": "2023-10-31T06:26:38Z",
            "published": "2023-10-31T06:26:38Z",
            "summary": "This study presents a novel deep reinforcement learning (DRL)-based handover\n(HO) protocol, called DHO, specifically designed to address the persistent\nchallenge of long propagation delays in low-Earth orbit (LEO) satellite\nnetworks' HO procedures. DHO skips the Measurement Report (MR) in the HO\nprocedure by leveraging its predictive capabilities after being trained with a\npre-determined LEO satellite orbital pattern. This simplification eliminates\nthe propagation delay incurred during the MR phase, while still providing\neffective HO decisions. The proposed DHO outperforms the legacy HO protocol\nacross diverse network conditions in terms of access delay, collision rate, and\nhandover success rate, demonstrating the practical applicability of DHO in\nreal-world networks. Furthermore, the study examines the trade-off between\naccess delay and collision rate and also evaluates the training performance and\nconvergence of DHO using various DRL algorithms.",
            "author": [
                "Ju-Hyung Lee",
                "Chanyoung Park",
                "Soohyun Park",
                "Andreas F. Molisch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20215v1",
                "http://arxiv.org/pdf/2310.20215v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20211v1",
            "title": "Calibration by Distribution Matching: Trainable Kernel Calibration\n  Metrics",
            "updated": "2023-10-31T06:19:40Z",
            "published": "2023-10-31T06:19:40Z",
            "summary": "Calibration ensures that probabilistic forecasts meaningfully capture\nuncertainty by requiring that predicted probabilities align with empirical\nfrequencies. However, many existing calibration methods are specialized for\npost-hoc recalibration, which can worsen the sharpness of forecasts. Drawing on\nthe insight that calibration can be viewed as a distribution matching task, we\nintroduce kernel-based calibration metrics that unify and generalize popular\nforms of calibration for both classification and regression. These metrics\nadmit differentiable sample estimates, making it easy to incorporate a\ncalibration objective into empirical risk minimization. Furthermore, we provide\nintuitive mechanisms to tailor calibration metrics to a decision task, and\nenforce accurate loss estimation and no regret decisions. Our empirical\nevaluation demonstrates that employing these metrics as regularizers enhances\ncalibration, sharpness, and decision-making across a range of regression and\nclassification tasks, outperforming methods relying solely on post-hoc\nrecalibration.",
            "author": [
                "Charles Marx",
                "Sofian Zalouk",
                "Stefano Ermon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20211v1",
                "http://arxiv.org/pdf/2310.20211v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20210v1",
            "title": "UWFormer: Underwater Image Enhancement via a Semi-Supervised Multi-Scale\n  Transformer",
            "updated": "2023-10-31T06:19:09Z",
            "published": "2023-10-31T06:19:09Z",
            "summary": "Underwater images often exhibit poor quality, imbalanced coloration, and low\ncontrast due to the complex and intricate interaction of light, water, and\nobjects. Despite the significant contributions of previous underwater\nenhancement techniques, there exist several problems that demand further\nimprovement: (i) Current deep learning methodologies depend on Convolutional\nNeural Networks (CNNs) that lack multi-scale enhancement and also have limited\nglobal perception fields. (ii) The scarcity of paired real-world underwater\ndatasets poses a considerable challenge, and the utilization of synthetic image\npairs risks overfitting. To address the aforementioned issues, this paper\npresents a Multi-scale Transformer-based Network called UWFormer for enhancing\nimages at multiple frequencies via semi-supervised learning, in which we\npropose a Nonlinear Frequency-aware Attention mechanism and a Multi-Scale\nFusion Feed-forward Network for low-frequency enhancement. Additionally, we\nintroduce a specialized underwater semi-supervised training strategy, proposing\na Subaqueous Perceptual Loss function to generate reliable pseudo labels.\nExperiments using full-reference and non-reference underwater benchmarks\ndemonstrate that our method outperforms state-of-the-art methods in terms of\nboth quantity and visual quality.",
            "author": [
                "Xuhang Chen",
                "Zinuo Li",
                "Shenghong Luo",
                "Weiwen Chen",
                "Shuqiang Wang",
                "Chi-Man Pun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20210v1",
                "http://arxiv.org/pdf/2310.20210v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20209v1",
            "title": "Network Contention-Aware Cluster Scheduling with Reinforcement Learning",
            "updated": "2023-10-31T06:17:23Z",
            "published": "2023-10-31T06:17:23Z",
            "summary": "With continuous advances in deep learning, distributed training is becoming\ncommon in GPU clusters. Specifically, for emerging workloads with diverse\namounts, ratios, and patterns of communication, we observe that network\ncontention can significantly degrade training throughput. However, widely used\nscheduling policies often face limitations as they are agnostic to network\ncontention between jobs. In this paper, we present a new approach to mitigate\nnetwork contention in GPU clusters using reinforcement learning. We formulate\nGPU cluster scheduling as a reinforcement learning problem and opt to learn a\nnetwork contention-aware scheduling policy that efficiently captures contention\nsensitivities and dynamically adapts scheduling decisions through continuous\nevaluation and improvement. We show that compared to widely used scheduling\npolicies, our approach reduces average job completion time by up to 18.2\\% and\neffectively cuts the tail job completion time by up to 20.7\\% while allowing a\npreferable trade-off between average job completion time and resource\nutilization.",
            "author": [
                "Junyeol Ryu",
                "Jeongyoon Eo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20209v1",
                "http://arxiv.org/pdf/2310.20209v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20208v2",
            "title": "ZoomNeXt: A Unified Collaborative Pyramid Network for Camouflaged Object\n  Detection",
            "updated": "2023-11-29T08:33:30Z",
            "published": "2023-10-31T06:11:23Z",
            "summary": "Recent camouflaged object detection (COD) attempts to segment objects\nvisually blended into their surroundings, which is extremely complex and\ndifficult in real-world scenarios. Apart from the high intrinsic similarity\nbetween camouflaged objects and their background, objects are usually diverse\nin scale, fuzzy in appearance, and even severely occluded. To this end, we\npropose an effective unified collaborative pyramid network which mimics human\nbehavior when observing vague images and videos, \\textit{i.e.}, zooming in and\nout. Specifically, our approach employs the zooming strategy to learn\ndiscriminative mixed-scale semantics by the multi-head scale integration and\nrich granularity perception units, which are designed to fully explore\nimperceptible clues between candidate objects and background surroundings. The\nformer's intrinsic multi-head aggregation provides more diverse visual\npatterns. The latter's routing mechanism can effectively propagate inter-frame\ndifference in spatiotemporal scenarios and adaptively ignore static\nrepresentations. They provides a solid foundation for realizing a unified\narchitecture for static and dynamic COD. Moreover, considering the uncertainty\nand ambiguity derived from indistinguishable textures, we construct a simple\nyet effective regularization, uncertainty awareness loss, to encourage\npredictions with higher confidence in candidate regions. Our highly\ntask-friendly framework consistently outperforms existing state-of-the-art\nmethods in image and video COD benchmarks. The code will be available at\n\\url{https://github.com/lartpang/ZoomNeXt}.",
            "author": [
                "Youwei Pang",
                "Xiaoqi Zhao",
                "Tian-Zhu Xiang",
                "Lihe Zhang",
                "Huchuan Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20208v2",
                "http://arxiv.org/pdf/2310.20208v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20204v2",
            "title": "General-Purpose Retrieval-Enhanced Medical Prediction Model Using\n  Near-Infinite History",
            "updated": "2023-12-05T10:20:11Z",
            "published": "2023-10-31T06:04:18Z",
            "summary": "Developing clinical prediction models (e.g., mortality prediction) based on\nelectronic health records (EHRs) typically relies on expert opinion for feature\nselection and adjusting observation window size. This burdens experts and\ncreates a bottleneck in the development process. We propose Retrieval-Enhanced\nMedical prediction model (REMed) to address such challenges. REMed can\nessentially evaluate an unlimited number of clinical events, select the\nrelevant ones, and make predictions. This approach effectively eliminates the\nneed for manual feature selection and enables an unrestricted observation\nwindow. We verified these properties through experiments on 27 clinical tasks\nand two independent cohorts from publicly available EHR datasets, where REMed\noutperformed other contemporary architectures that aim to handle as many events\nas possible. Notably, we found that the preferences of REMed align closely with\nthose of medical experts. We expect our approach to significantly expedite the\ndevelopment of EHR prediction models by minimizing clinicians' need for manual\ninvolvement.",
            "author": [
                "Junu Kim",
                "Chaeeun Shim",
                "Bosco Seong Kyu Yang",
                "Chami Im",
                "Sung Yoon Lim",
                "Han-Gil Jeong",
                "Edward Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20204v2",
                "http://arxiv.org/pdf/2310.20204v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20203v1",
            "title": "Importance Estimation with Random Gradient for Neural Network Pruning",
            "updated": "2023-10-31T06:00:17Z",
            "published": "2023-10-31T06:00:17Z",
            "summary": "Global Neuron Importance Estimation is used to prune neural networks for\nefficiency reasons. To determine the global importance of each neuron or\nconvolutional kernel, most of the existing methods either use activation or\ngradient information or both, which demands abundant labelled examples. In this\nwork, we use heuristics to derive importance estimation similar to Taylor First\nOrder (TaylorFO) approximation based methods. We name our methods TaylorFO-abs\nand TaylorFO-sq. We propose two additional methods to improve these importance\nestimation methods. Firstly, we propagate random gradients from the last layer\nof a network, thus avoiding the need for labelled examples. Secondly, we\nnormalize the gradient magnitude of the last layer output before propagating,\nwhich allows all examples to contribute similarly to the importance score. Our\nmethods with additional techniques perform better than previous methods when\ntested on ResNet and VGG architectures on CIFAR-100 and STL-10 datasets.\nFurthermore, our method also complements the existing methods and improves\ntheir performances when combined with them.",
            "author": [
                "Suman Sapkota",
                "Binod Bhattarai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20203v1",
                "http://arxiv.org/pdf/2310.20203v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00724v1",
            "title": "Fraud Analytics Using Machine-learning & Engineering on Big Data (FAME)\n  for Telecom",
            "updated": "2023-10-31T05:47:35Z",
            "published": "2023-10-31T05:47:35Z",
            "summary": "Telecom industries lose globally 46.3 Billion USD due to fraud. Data mining\nand machine learning techniques (apart from rules oriented approach) have been\nused in past, but efficiency has been low as fraud pattern changes very\nrapidly. This paper presents an industrialized solution approach with self\nadaptive data mining technique and application of big data technologies to\ndetect fraud and discover novel fraud patterns in accurate, efficient and cost\neffective manner. Solution has been successfully demonstrated to detect\nInternational Revenue Share Fraud with <5% false positive. More than 1 Terra\nBytes of Call Detail Record from a reputed wholesale carrier and overseas\ntelecom transit carrier has been used to conduct this study.",
            "author": [
                "Sudarson Roy Pratihar",
                "Subhadip Paul",
                "Pranab Kumar Dash",
                "Amartya Kumar Das"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00724v1",
                "http://arxiv.org/pdf/2311.00724v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20199v1",
            "title": "In Search of Lost Online Test-time Adaptation: A Survey",
            "updated": "2023-10-31T05:47:33Z",
            "published": "2023-10-31T05:47:33Z",
            "summary": "In this paper, we present a comprehensive survey on online test-time\nadaptation (OTTA), a paradigm focused on adapting machine learning models to\nnovel data distributions upon batch arrival. Despite the proliferation of OTTA\nmethods recently, the field is mired in issues like ambiguous settings,\nantiquated backbones, and inconsistent hyperparameter tuning, obfuscating the\nreal challenges and making reproducibility elusive. For clarity and a rigorous\ncomparison, we classify OTTA techniques into three primary categories and\nsubject them to benchmarks using the potent Vision Transformer (ViT) backbone\nto discover genuinely effective strategies. Our benchmarks span not only\nconventional corrupted datasets such as CIFAR-10/100-C and ImageNet-C but also\nreal-world shifts embodied in CIFAR-10.1 and CIFAR-10-Warehouse, encapsulating\nvariations across search engines and synthesized data by diffusion models. To\ngauge efficiency in online scenarios, we introduce novel evaluation metrics,\ninclusive of FLOPs, shedding light on the trade-offs between adaptation\naccuracy and computational overhead. Our findings diverge from existing\nliterature, indicating: (1) transformers exhibit heightened resilience to\ndiverse domain shifts, (2) the efficacy of many OTTA methods hinges on ample\nbatch sizes, and (3) stability in optimization and resistance to perturbations\nare critical during adaptation, especially when the batch size is 1. Motivated\nby these insights, we pointed out promising directions for future research. The\nsource code will be made available.",
            "author": [
                "Zixin Wang",
                "Yadan Luo",
                "Liang Zheng",
                "Zhuoxiao Chen",
                "Sen Wang",
                "Zi Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20199v1",
                "http://arxiv.org/pdf/2310.20199v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20193v1",
            "title": "FedRec+: Enhancing Privacy and Addressing Heterogeneity in Federated\n  Recommendation Systems",
            "updated": "2023-10-31T05:36:53Z",
            "published": "2023-10-31T05:36:53Z",
            "summary": "Preserving privacy and reducing communication costs for edge users pose\nsignificant challenges in recommendation systems. Although federated learning\nhas proven effective in protecting privacy by avoiding data exchange between\nclients and servers, it has been shown that the server can infer user ratings\nbased on updated non-zero gradients obtained from two consecutive rounds of\nuser-uploaded gradients. Moreover, federated recommendation systems (FRS) face\nthe challenge of heterogeneity, leading to decreased recommendation\nperformance. In this paper, we propose FedRec+, an ensemble framework for FRS\nthat enhances privacy while addressing the heterogeneity challenge. FedRec+\nemploys optimal subset selection based on feature similarity to generate\nnear-optimal virtual ratings for pseudo items, utilizing only the user's local\ninformation. This approach reduces noise without incurring additional\ncommunication costs. Furthermore, we utilize the Wasserstein distance to\nestimate the heterogeneity and contribution of each client, and derive optimal\naggregation weights by solving a defined optimization problem. Experimental\nresults demonstrate the state-of-the-art performance of FedRec+ across various\nreference datasets.",
            "author": [
                "Lin Wang",
                "Zhichao Wang",
                "Xi Leng",
                "Xiaoying Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20193v1",
                "http://arxiv.org/pdf/2310.20193v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20190v2",
            "title": "Visible to Thermal image Translation for improving visual task in low\n  light conditions",
            "updated": "2023-11-09T02:42:20Z",
            "published": "2023-10-31T05:18:53Z",
            "summary": "Several visual tasks, such as pedestrian detection and image-to-image\ntranslation, are challenging to accomplish in low light using RGB images. Heat\nvariation of objects in thermal images can be used to overcome this. In this\nwork, an end-to-end framework, which consists of a generative network and a\ndetector network, is proposed to translate RGB image into Thermal ones and\ncompare generated thermal images with real data. We have collected images from\ntwo different locations using the Parrot Anafi Thermal drone. After that, we\ncreated a two-stream network, preprocessed, augmented, the image data, and\ntrained the generator and discriminator models from scratch. The findings\ndemonstrate that it is feasible to translate RGB training data to thermal data\nusing GAN. As a result, thermal data can now be produced more quickly and\naffordably, which is useful for security and surveillance applications.",
            "author": [
                "Md Azim Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20190v2",
                "http://arxiv.org/pdf/2310.20190v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20189v2",
            "title": "LFG: A Generative Network for Real-Time Recommendation",
            "updated": "2023-11-25T11:46:49Z",
            "published": "2023-10-31T05:16:54Z",
            "summary": "Recommender systems are essential information technologies today, and\nrecommendation algorithms combined with deep learning have become a research\nhotspot in this field. The recommendation model known as LFM (Latent Factor\nModel), which captures latent features through matrix factorization and\ngradient descent to fit user preferences, has given rise to various\nrecommendation algorithms that bring new improvements in recommendation\naccuracy. However, collaborative filtering recommendation models based on LFM\nlack flexibility and has shortcomings for real-time recommendations, as they\nneed to redo the matrix factorization and retrain using gradient descent when\nnew users arrive. In response to this, this paper innovatively proposes a\nLatent Factor Generator (LFG) network, and set the movie recommendation as\nresearch theme. The LFG dynamically generates user latent factors through deep\nneural networks without the need for re-factorization or retrain. Experimental\nresults indicate that the LFG recommendation model outperforms traditional\nmatrix factorization algorithms in recommendation accuracy, providing an\neffective solution to the challenges of real-time recommendations with LFM.",
            "author": [
                "Junyi Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20189v2",
                "http://arxiv.org/pdf/2310.20189v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20187v1",
            "title": "Self-supervised Pre-training for Precipitation Post-processor",
            "updated": "2023-10-31T05:13:10Z",
            "published": "2023-10-31T05:13:10Z",
            "summary": "Securing sufficient forecast lead time for local precipitation is essential\nfor preventing hazardous weather events. Nonetheless, global warming-induced\nclimate change is adding to the challenge of accurately predicting severe\nprecipitation events, such as heavy rainfall. In this work, we propose a deep\nlearning-based precipitation post-processor approach to numerical weather\nprediction (NWP) models. The precipitation post-processor consists of (i)\nself-supervised pre-training, where parameters of encoder are pre-trained on\nthe reconstruction of masked variables of the atmospheric physics domain, and\n(ii) transfer learning on precipitation segmentation tasks (target domain) from\nthe pre-trained encoder. We also introduce a heuristic labeling approach for\neffectively training class-imbalanced datasets. Our experiment results in\nprecipitation correction for regional NWP show that the proposed method\noutperforms other approaches.",
            "author": [
                "Sojung An",
                "Junha Lee",
                "Jiyeon Jang",
                "Inchae Na",
                "Wooyeon Park",
                "Sujeong You"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20187v1",
                "http://arxiv.org/pdf/2310.20187v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20183v1",
            "title": "Thriving in a Pandemic: Lessons Learned from a Resilient University\n  Program Seen Through the CoI Lens",
            "updated": "2023-10-31T05:09:17Z",
            "published": "2023-10-31T05:09:17Z",
            "summary": "In March 2020, college campuses underwent a sudden transformation to online\nlearning due to the COVID-19 outbreak. To understand the impact of COVID-19 on\nstudents' expectations, this study conducted a three-year survey from ten core\ncourses within the Project Management Center for Excellence at the University\nof Maryland. The study involved two main steps: 1) a statistical analysis to\nevaluate students' expectations regarding \"student,\" \"class,\" \"instructor,\" and\n\"effort;\" and 2) a lexical salience-valence analysis (LSVA) through the lens of\nthe Community of Inquiry (CoI) framework to show the changes of students'\nexpectations. The results revealed that students' overall evaluations\nmaintained relatively consistent amid the COVID-19 teaching period. However,\nthere were significant shifts of the student expectations toward Cognitive,\nSocial and Teaching Presence course elements based on LSVA results. Also, clear\ndifferences emerged between under-graduates and graduates in their expectations\nand preferences in course design and delivery. These insights provide practical\nrecommendations for course instructors in designing effective online courses.",
            "author": [
                "Zihui Ma",
                "Lingyao Li",
                "John C. E. Johnson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20183v1",
                "http://arxiv.org/pdf/2310.20183v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20178v2",
            "title": "Learning to Discover Skills through Guidance",
            "updated": "2023-11-01T13:55:57Z",
            "published": "2023-10-31T05:01:02Z",
            "summary": "In the field of unsupervised skill discovery (USD), a major challenge is\nlimited exploration, primarily due to substantial penalties when skills deviate\nfrom their initial trajectories. To enhance exploration, recent methodologies\nemploy auxiliary rewards to maximize the epistemic uncertainty or entropy of\nstates. However, we have identified that the effectiveness of these rewards\ndeclines as the environmental complexity rises. Therefore, we present a novel\nUSD algorithm, skill discovery with guidance (DISCO-DANCE), which (1) selects\nthe guide skill that possesses the highest potential to reach unexplored\nstates, (2) guides other skills to follow guide skill, then (3) the guided\nskills are dispersed to maximize their discriminability in unexplored states.\nEmpirical evaluation demonstrates that DISCO-DANCE outperforms other USD\nbaselines in challenging environments, including two navigation benchmarks and\na continuous control benchmark. Qualitative visualizations and code of\nDISCO-DANCE are available at https://mynsng.github.io/discodance.",
            "author": [
                "Hyunseung Kim",
                "Byungkun Lee",
                "Hojoon Lee",
                "Dongyoon Hwang",
                "Sejik Park",
                "Kyushik Min",
                "Jaegul Choo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20178v2",
                "http://arxiv.org/pdf/2310.20178v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20172v1",
            "title": "Compact Binary Systems Waveform Generation with Generative Pre-trained\n  Transformer",
            "updated": "2023-10-31T04:40:20Z",
            "published": "2023-10-31T04:40:20Z",
            "summary": "Space-based gravitational wave detection is one of the most anticipated\ngravitational wave (GW) detection projects in the next decade, which will\ndetect abundant compact binary systems. However, the precise prediction of\nspace GW waveforms remains unexplored. To solve the data processing difficulty\nin the increasing waveform complexity caused by detectors' response and\nsecond-generation time-delay interferometry (TDI 2.0), an interpretable\npre-trained large model named CBS-GPT (Compact Binary Systems Waveform\nGeneration with Generative Pre-trained Transformer) is proposed. For compact\nbinary system waveforms, three models were trained to predict the waveforms of\nmassive black hole binary (MBHB), extreme mass-ratio inspirals (EMRIs), and\ngalactic binary (GB), achieving prediction accuracies of 98%, 91%, and 99%,\nrespectively. The CBS-GPT model exhibits notable interpretability, with its\nhidden parameters effectively capturing the intricate information of waveforms,\neven with complex instrument response and a wide parameter range. Our research\ndemonstrates the potential of large pre-trained models in gravitational wave\ndata processing, opening up new opportunities for future tasks such as gap\ncompletion, GW signal detection, and signal noise reduction.",
            "author": [
                "Ruijun Shi",
                "Yue Zhou",
                "Tianyu Zhao",
                "Zhoujian Cao",
                "Zhixiang Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20172v1",
                "http://arxiv.org/pdf/2310.20172v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20168v1",
            "title": "Understanding and Visualizing Droplet Distributions in Simulations of\n  Shallow Clouds",
            "updated": "2023-10-31T04:25:00Z",
            "published": "2023-10-31T04:25:00Z",
            "summary": "Thorough analysis of local droplet-level interactions is crucial to better\nunderstand the microphysical processes in clouds and their effect on the global\nclimate. High-accuracy simulations of relevant droplet size distributions from\nLarge Eddy Simulations (LES) of bin microphysics challenge current analysis\ntechniques due to their high dimensionality involving three spatial dimensions,\ntime, and a continuous range of droplet sizes. Utilizing the compact latent\nrepresentations from Variational Autoencoders (VAEs), we produce novel and\nintuitive visualizations for the organization of droplet sizes and their\nevolution over time beyond what is possible with clustering techniques. This\ngreatly improves interpretation and allows us to examine aerosol-cloud\ninteractions by contrasting simulations with different aerosol concentrations.\nWe find that the evolution of the droplet spectrum is similar across aerosol\nlevels but occurs at different paces. This similarity suggests that\nprecipitation initiation processes are alike despite variations in onset times.",
            "author": [
                "Justus C. Will",
                "Andrea M. Jenney",
                "Kara D. Lamb",
                "Michael S. Pritchard",
                "Colleen Kaul",
                "Po-Lun Ma",
                "Kyle Pressel",
                "Jacob Shpund",
                "Marcus van Lier-Walqui",
                "Stephan Mandt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20168v1",
                "http://arxiv.org/pdf/2310.20168v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.ao-ph",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20155v1",
            "title": "MLatom 3: Platform for machine learning-enhanced computational chemistry\n  simulations and workflows",
            "updated": "2023-10-31T03:41:39Z",
            "published": "2023-10-31T03:41:39Z",
            "summary": "Machine learning (ML) is increasingly becoming a common tool in computational\nchemistry. At the same time, the rapid development of ML methods requires a\nflexible software framework for designing custom workflows. MLatom 3 is a\nprogram package designed to leverage the power of ML to enhance typical\ncomputational chemistry simulations and to create complex workflows. This\nopen-source package provides plenty of choice to the users who can run\nsimulations with the command line options, input files, or with scripts using\nMLatom as a Python package, both on their computers and on the online XACS\ncloud computing at XACScloud.com. Computational chemists can calculate energies\nand thermochemical properties, optimize geometries, run molecular and quantum\ndynamics, and simulate (ro)vibrational, one-photon UV/vis absorption, and\ntwo-photon absorption spectra with ML, quantum mechanical, and combined models.\nThe users can choose from an extensive library of methods containing\npre-trained ML models and quantum mechanical approximations such as AIQM1\napproaching coupled-cluster accuracy. The developers can build their own models\nusing various ML algorithms. The great flexibility of MLatom is largely due to\nthe extensive use of the interfaces to many state-of-the-art software packages\nand libraries.",
            "author": [
                "Pavlo O. Dral",
                "Fuchun Ge",
                "Yi-Fan Hou",
                "Peikun Zheng",
                "Yuxinxin Chen",
                "Mario Barbatti",
                "Olexandr Isayev",
                "Cheng Wang",
                "Bao-Xin Xue",
                "Max Pinheiro Jr",
                "Yuming Su",
                "Yiheng Dai",
                "Yangtao Chen",
                "Lina Zhang",
                "Shuang Zhang",
                "Arif Ullah",
                "Quanhao Zhang",
                "Yanchi Ou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20155v1",
                "http://arxiv.org/pdf/2310.20155v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20153v1",
            "title": "Interactive Multi-fidelity Learning for Cost-effective Adaptation of\n  Language Model with Sparse Human Supervision",
            "updated": "2023-10-31T03:39:23Z",
            "published": "2023-10-31T03:39:23Z",
            "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious tasks. However, their suitability for domain-specific tasks, is limited\ndue to their immense scale at deployment, susceptibility to misinformation, and\nmore importantly, high data annotation costs. We propose a novel Interactive\nMulti-Fidelity Learning (IMFL) framework for the cost-effective development of\nsmall domain-specific LMs under limited annotation budgets. Our approach\nformulates the domain-specific fine-tuning process as a multi-fidelity learning\nproblem, focusing on identifying the optimal acquisition strategy that balances\nbetween low-fidelity automatic LLM annotations and high-fidelity human\nannotations to maximize model performance. We further propose an\nexploration-exploitation query strategy that enhances annotation diversity and\ninformativeness, incorporating two innovative designs: 1) prompt retrieval that\nselects in-context examples from human-annotated samples to improve LLM\nannotation, and 2) variable batch size that controls the order for choosing\neach fidelity to facilitate knowledge distillation, ultimately enhancing\nannotation quality. Extensive experiments on financial and medical tasks\ndemonstrate that IMFL achieves superior performance compared with single\nfidelity annotations. Given a limited budget of human annotation, IMFL\nsignificantly outperforms the human annotation baselines in all four tasks and\nachieves very close performance as human annotations on two of the tasks. These\npromising results suggest that the high human annotation costs in\ndomain-specific tasks can be significantly reduced by employing IMFL, which\nutilizes fewer human annotations, supplemented with cheaper and faster LLM\n(e.g., GPT-3.5) annotations to achieve comparable performance.",
            "author": [
                "Jiaxin Zhang",
                "Zhuohang Li",
                "Kamalika Das",
                "Sricharan Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20153v1",
                "http://arxiv.org/pdf/2310.20153v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20150v1",
            "title": "Unlearn What You Want to Forget: Efficient Unlearning for LLMs",
            "updated": "2023-10-31T03:35:59Z",
            "published": "2023-10-31T03:35:59Z",
            "summary": "Large language models (LLMs) have achieved significant progress from\npre-training on and memorizing a wide range of textual data, however, this\nprocess might suffer from privacy issues and violations of data protection\nregulations. As a result, the ability to easily remove data related to\nindividual users from such models while not deteriorating their predictive\nquality after the removal becomes increasingly important. To address these\nissues, in this work, we propose an efficient unlearning framework that could\nefficiently update LLMs without having to retrain the whole model after data\nremovals, by introducing lightweight unlearning layers learned with a selective\nteacher-student objective into the transformers. In addition, we introduce a\nfusion mechanism to effectively combine different unlearning layers that learns\nto forget different sets of data to handle a sequence of forgetting operations.\nExperiments on classification and generation tasks demonstrate the\neffectiveness of our proposed methods compared to the state-of-the-art\nbaselines.",
            "author": [
                "Jiaao Chen",
                "Diyi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20150v1",
                "http://arxiv.org/pdf/2310.20150v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20145v2",
            "title": "Efficient Robust Bayesian Optimization for Arbitrary Uncertain Inputs",
            "updated": "2023-11-03T23:52:57Z",
            "published": "2023-10-31T03:29:31Z",
            "summary": "Bayesian Optimization (BO) is a sample-efficient optimization algorithm\nwidely employed across various applications. In some challenging BO tasks,\ninput uncertainty arises due to the inevitable randomness in the optimization\nprocess, such as machining errors, execution noise, or contextual variability.\nThis uncertainty deviates the input from the intended value before evaluation,\nresulting in significant performance fluctuations in the final result. In this\npaper, we introduce a novel robust Bayesian Optimization algorithm, AIRBO,\nwhich can effectively identify a robust optimum that performs consistently well\nunder arbitrary input uncertainty. Our method directly models the uncertain\ninputs of arbitrary distributions by empowering the Gaussian Process with the\nMaximum Mean Discrepancy (MMD) and further accelerates the posterior inference\nvia Nystrom approximation. Rigorous theoretical regret bound is established\nunder MMD estimation error and extensive experiments on synthetic functions and\nreal problems demonstrate that our approach can handle various input\nuncertainties and achieve state-of-the-art performance.",
            "author": [
                "Lin Yang",
                "Junlong Lyu",
                "Wenlong Lyu",
                "Zhitang Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20145v2",
                "http://arxiv.org/pdf/2310.20145v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20144v1",
            "title": "EELBERT: Tiny Models through Dynamic Embeddings",
            "updated": "2023-10-31T03:28:08Z",
            "published": "2023-10-31T03:28:08Z",
            "summary": "We introduce EELBERT, an approach for compression of transformer-based models\n(e.g., BERT), with minimal impact on the accuracy of downstream tasks. This is\nachieved by replacing the input embedding layer of the model with dynamic, i.e.\non-the-fly, embedding computations. Since the input embedding layer accounts\nfor a significant fraction of the model size, especially for the smaller BERT\nvariants, replacing this layer with an embedding computation function helps us\nreduce the model size significantly. Empirical evaluation on the GLUE benchmark\nshows that our BERT variants (EELBERT) suffer minimal regression compared to\nthe traditional BERT models. Through this approach, we are able to develop our\nsmallest model UNO-EELBERT, which achieves a GLUE score within 4% of fully\ntrained BERT-tiny, while being 15x smaller (1.2 MB) in size.",
            "author": [
                "Gabrielle Cohn",
                "Rishika Agarwal",
                "Deepanshu Gupta",
                "Siddharth Patwardhan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20144v1",
                "http://arxiv.org/pdf/2310.20144v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "68T07",
                "I.2.7; I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20141v1",
            "title": "Contrastive Difference Predictive Coding",
            "updated": "2023-10-31T03:16:32Z",
            "published": "2023-10-31T03:16:32Z",
            "summary": "Predicting and reasoning about the future lie at the heart of many\ntime-series questions. For example, goal-conditioned reinforcement learning can\nbe viewed as learning representations to predict which states are likely to be\nvisited in the future. While prior methods have used contrastive predictive\ncoding to model time series data, learning representations that encode\nlong-term dependencies usually requires large amounts of data. In this paper,\nwe introduce a temporal difference version of contrastive predictive coding\nthat stitches together pieces of different time series data to decrease the\namount of data required to learn predictions of future events. We apply this\nrepresentation learning method to derive an off-policy algorithm for\ngoal-conditioned RL. Experiments demonstrate that, compared with prior RL\nmethods, ours achieves $2 \\times$ median improvement in success rates and can\nbetter cope with stochastic environments. In tabular settings, we show that our\nmethod is about $20 \\times$ more sample efficient than the successor\nrepresentation and $1500 \\times$ more sample efficient than the standard (Monte\nCarlo) version of contrastive predictive coding.",
            "author": [
                "Chongyi Zheng",
                "Ruslan Salakhutdinov",
                "Benjamin Eysenbach"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20141v1",
                "http://arxiv.org/pdf/2310.20141v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20140v1",
            "title": "Synthesizing Diabetic Foot Ulcer Images with Diffusion Model",
            "updated": "2023-10-31T03:15:30Z",
            "published": "2023-10-31T03:15:30Z",
            "summary": "Diabetic Foot Ulcer (DFU) is a serious skin wound requiring specialized care.\nHowever, real DFU datasets are limited, hindering clinical training and\nresearch activities. In recent years, generative adversarial networks and\ndiffusion models have emerged as powerful tools for generating synthetic images\nwith remarkable realism and diversity in many applications. This paper explores\nthe potential of diffusion models for synthesizing DFU images and evaluates\ntheir authenticity through expert clinician assessments. Additionally,\nevaluation metrics such as Frechet Inception Distance (FID) and Kernel\nInception Distance (KID) are examined to assess the quality of the synthetic\nDFU images. A dataset of 2,000 DFU images is used for training the diffusion\nmodel, and the synthetic images are generated by applying diffusion processes.\nThe results indicate that the diffusion model successfully synthesizes visually\nindistinguishable DFU images. 70% of the time, clinicians marked synthetic DFU\nimages as real DFUs. However, clinicians demonstrate higher unanimous\nconfidence in rating real images than synthetic ones. The study also reveals\nthat FID and KID metrics do not significantly align with clinicians'\nassessments, suggesting alternative evaluation approaches are needed. The\nfindings highlight the potential of diffusion models for generating synthetic\nDFU images and their impact on medical training programs and research in wound\ndetection and classification.",
            "author": [
                "Reza Basiri",
                "Karim Manji",
                "Francois Harton",
                "Alisha Poonja",
                "Milos R. Popovic",
                "Shehroz S. Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20140v1",
                "http://arxiv.org/pdf/2310.20140v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20129v1",
            "title": "Gibbs state sampling via cluster expansions",
            "updated": "2023-10-31T02:36:24Z",
            "published": "2023-10-31T02:36:24Z",
            "summary": "Gibbs states (i.e., thermal states) can be used for several applications such\nas quantum simulation, quantum machine learning, quantum optimization, and the\nstudy of open quantum systems. Moreover, semi-definite programming,\ncombinatorial optimization problems, and training quantum Boltzmann machines\ncan all be addressed by sampling from well-prepared Gibbs states. With that,\nhowever, comes the fact that preparing and sampling from Gibbs states on a\nquantum computer are notoriously difficult tasks. Such tasks can require large\noverhead in resources and/or calibration even in the simplest of cases, as well\nas the fact that the implementation might be limited to only a specific set of\nsystems. We propose a method based on sampling from a quasi-distribution\nconsisting of tensor products of mixed states on local clusters, i.e.,\nexpanding the full Gibbs state into a sum of products of local \"Gibbs-cumulant\"\ntype states easier to implement and sample from on quantum hardware. We begin\nwith presenting results for 4-spin linear chains with XY spin interactions, for\nwhich we obtain the $ZZ$ dynamical spin-spin correlation functions. We also\npresent the results of measuring the specific heat of the 8-spin chain Gibbs\nstate $\\rho_8$.",
            "author": [
                "Norhan M. Eassa",
                "Mahmoud M. Moustafa",
                "Arnab Banerjee",
                "Jeffrey Cohn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20129v1",
                "http://arxiv.org/pdf/2310.20129v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.other"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20127v1",
            "title": "Improving Prompt Tuning with Learned Prompting Layers",
            "updated": "2023-10-31T02:07:51Z",
            "published": "2023-10-31T02:07:51Z",
            "summary": "Prompt tuning prepends a soft prompt to the input embeddings or hidden states\nand only optimizes the prompt to adapt pretrained models (PTMs) to downstream\ntasks. The previous work manually selects prompt layers which are far from\noptimal and failed to exploit the potential of prompt tuning. In this work, we\npropose a novel framework, \\underline{S}elective \\underline{P}rompt\n\\underline{T}uning (SPT), that learns to select the proper prompt layers by\ninserting a prompt controlled by a learnable probabilistic gate at each\nintermediate layer. We further propose a novel bi-level optimization framework,\nSPT-DARTS, that can better optimize the learnable gates and improve the final\nprompt tuning performances of the learned prompt layer settings. We conduct\nextensive experiments with ten benchmark datasets under the full-data and\nfew-shot scenarios. The results demonstrate that our SPT framework can perform\nbetter than the previous state-of-the-art PETuning baselines with comparable or\nfewer tunable parameters.",
            "author": [
                "Wei Zhu",
                "Ming Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20127v1",
                "http://arxiv.org/pdf/2310.20127v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20125v1",
            "title": "Zephyr : Stitching Heterogeneous Training Data with Normalizing Flows\n  for Photometric Redshift Inference",
            "updated": "2023-10-31T01:58:39Z",
            "published": "2023-10-31T01:58:39Z",
            "summary": "We present zephyr, a novel method that integrates cutting-edge normalizing\nflow techniques into a mixture density estimation framework, enabling the\neffective use of heterogeneous training data for photometric redshift\ninference. Compared to previous methods, zephyr demonstrates enhanced\nrobustness for both point estimation and distribution reconstruction by\nleveraging normalizing flows for density estimation and incorporating careful\nuncertainty quantification. Moreover, zephyr offers unique interpretability by\nexplicitly disentangling contributions from multi-source training data, which\ncan facilitate future weak lensing analysis by providing an additional quality\nassessment. As probabilistic generative deep learning techniques gain\nincreasing prominence in astronomy, zephyr should become an inspiration for\nhandling heterogeneous training data while remaining interpretable and robustly\naccounting for observational uncertainties.",
            "author": [
                "Zechang Sun",
                "Joshua S. Speagle",
                "Song Huang",
                "Yuan-Sen Ting",
                "Zheng Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20125v1",
                "http://arxiv.org/pdf/2310.20125v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20121v1",
            "title": "Ling-CL: Understanding NLP Models through Linguistic Curricula",
            "updated": "2023-10-31T01:44:33Z",
            "published": "2023-10-31T01:44:33Z",
            "summary": "We employ a characterization of linguistic complexity from psycholinguistic\nand language acquisition research to develop data-driven curricula to\nunderstand the underlying linguistic knowledge that models learn to address NLP\ntasks. The novelty of our approach is in the development of linguistic\ncurricula derived from data, existing knowledge about linguistic complexity,\nand model behavior during training. By analyzing several benchmark NLP\ndatasets, our curriculum learning approaches identify sets of linguistic\nmetrics (indices) that inform the challenges and reasoning required to address\neach task. Our work will inform future research in all NLP areas, allowing\nlinguistic complexity to be considered early in the research and development\nprocess. In addition, our work prompts an examination of gold standards and\nfair evaluation in NLP.",
            "author": [
                "Mohamed Elgaar",
                "Hadi Amiri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20121v1",
                "http://arxiv.org/pdf/2310.20121v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20117v1",
            "title": "Refined Equivalent Pinhole Model for Large-scale 3D Reconstruction from\n  Spaceborne CCD Imagery",
            "updated": "2023-10-31T01:30:57Z",
            "published": "2023-10-31T01:30:57Z",
            "summary": "In this study, we present a large-scale earth surface reconstruction pipeline\nfor linear-array charge-coupled device (CCD) satellite imagery. While\nmainstream satellite image-based reconstruction approaches perform\nexceptionally well, the rational functional model (RFM) is subject to several\nlimitations. For example, the RFM has no rigorous physical interpretation and\ndiffers significantly from the pinhole imaging model; hence, it cannot be\ndirectly applied to learning-based 3D reconstruction networks and to more novel\nreconstruction pipelines in computer vision. Hence, in this study, we introduce\na method in which the RFM is equivalent to the pinhole camera model (PCM),\nmeaning that the internal and external parameters of the pinhole camera are\nused instead of the rational polynomial coefficient parameters. We then derive\nan error formula for this equivalent pinhole model for the first time,\ndemonstrating the influence of the image size on the accuracy of the\nreconstruction. In addition, we propose a polynomial image refinement model\nthat minimizes equivalent errors via the least squares method. The experiments\nwere conducted using four image datasets: WHU-TLC, DFC2019, ISPRS-ZY3, and GF7.\nThe results demonstrated that the reconstruction accuracy was proportional to\nthe image size. Our polynomial image refinement model significantly enhanced\nthe accuracy and completeness of the reconstruction, and achieved more\nsignificant improvements for larger-scale images.",
            "author": [
                "Hong Danyang",
                "Yu Anzhu",
                "Ji Song",
                "Cao Xuefeng",
                "Quan Yujun",
                "Guo Wenyue",
                "Qiu Chunping"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20117v1",
                "http://arxiv.org/pdf/2310.20117v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20109v1",
            "title": "Multi-Objective Intrinsic Reward Learning for Conversational Recommender\n  Systems",
            "updated": "2023-10-31T01:07:30Z",
            "published": "2023-10-31T01:07:30Z",
            "summary": "Conversational Recommender Systems (CRS) actively elicit user preferences to\ngenerate adaptive recommendations. Mainstream reinforcement learning-based CRS\nsolutions heavily rely on handcrafted reward functions, which may not be\naligned with user intent in CRS tasks. Therefore, the design of task-specific\nrewards is critical to facilitate CRS policy learning, which remains largely\nunder-explored in the literature. In this work, we propose a novel approach to\naddress this challenge by learning intrinsic rewards from interactions with\nusers. Specifically, we formulate intrinsic reward learning as a\nmulti-objective bi-level optimization problem. The inner level optimizes the\nCRS policy augmented by the learned intrinsic rewards, while the outer level\ndrives the intrinsic rewards to optimize two CRS-specific objectives:\nmaximizing the success rate and minimizing the number of turns to reach a\nsuccessful recommendation in conversations. To evaluate the effectiveness of\nour approach, we conduct extensive experiments on three public CRS benchmarks.\nThe results show that our algorithm significantly improves CRS performance by\nexploiting informative learned intrinsic rewards.",
            "author": [
                "Zhendong Chu",
                "Nan Wang",
                "Hongning Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20109v1",
                "http://arxiv.org/pdf/2310.20109v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20106v1",
            "title": "Progress and outlook on advanced fly scans based on Mamba",
            "updated": "2023-10-31T00:57:58Z",
            "published": "2023-10-31T00:57:58Z",
            "summary": "Development related to PandABox-based fly scans is an important part of the\nactive work on Mamba, the software framework for beamline experiments at the\nHigh Energy Photon Source (HEPS); presented in this paper is the progress of\nour development, and some outlook for advanced fly scans based on knowledge\nlearned during the process. By treating fly scans as a collaboration between a\nfew loosely coupled subsystems - motors / mechanics, detectors / data\nprocessing, sequencer devices like PandABox - systematic analyses of issues in\nfly scans are conducted. Interesting products of these analyses include a\ngeneral-purpose software-based fly-scan mechanism, a general way to design\nundulator-monochromator fly scans, a sketch of how to practically implement\nonline tuning of fly-scan behaviours based on processing of the data acquired,\nand many more. Based on the results above, an architectural discussion on\n>=10kHz fly scans is given.",
            "author": [
                "Peng-Cheng Li",
                "Cheng-Long Zhang",
                "Zong-Yang Yue",
                "Xiao-Bao Deng",
                "Chun Li",
                "Ai-Yu Zhou",
                "Gang Li",
                "Yu Liu",
                "Yi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20106v1",
                "http://arxiv.org/pdf/2310.20106v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20102v1",
            "title": "Sample-Conditioned Hypothesis Stability Sharpens Information-Theoretic\n  Generalization Bounds",
            "updated": "2023-10-31T00:44:20Z",
            "published": "2023-10-31T00:44:20Z",
            "summary": "We present new information-theoretic generalization guarantees through the a\nnovel construction of the \"neighboring-hypothesis\" matrix and a new family of\nstability notions termed sample-conditioned hypothesis (SCH) stability. Our\napproach yields sharper bounds that improve upon previous information-theoretic\nbounds in various learning scenarios. Notably, these bounds address the\nlimitations of existing information-theoretic bounds in the context of\nstochastic convex optimization (SCO) problems, as explored in the recent work\nby Haghifam et al. (2023).",
            "author": [
                "Ziqiao Wang",
                "Yongyi Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20102v1",
                "http://arxiv.org/pdf/2310.20102v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20098v1",
            "title": "Robust Learning for Smoothed Online Convex Optimization with Feedback\n  Delay",
            "updated": "2023-10-31T00:22:55Z",
            "published": "2023-10-31T00:22:55Z",
            "summary": "We study a challenging form of Smoothed Online Convex Optimization, a.k.a.\nSOCO, including multi-step nonlinear switching costs and feedback delay. We\npropose a novel machine learning (ML) augmented online algorithm,\nRobustness-Constrained Learning (RCL), which combines untrusted ML predictions\nwith a trusted expert online algorithm via constrained projection to robustify\nthe ML prediction. Specifically,we prove that RCL is able to\nguarantee$(1+\\lambda)$-competitiveness against any given expert for\nany$\\lambda>0$, while also explicitly training the ML model in a\nrobustification-aware manner to improve the average-case performance.\nImportantly,RCL is the first ML-augmented algorithm with a provable robustness\nguarantee in the case of multi-step switching cost and feedback delay.We\ndemonstrate the improvement of RCL in both robustness and average performance\nusing battery management for electrifying transportationas a case study.",
            "author": [
                "Pengfei Li",
                "Jianyi Yang",
                "Adam Wierman",
                "Shaolei Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20098v1",
                "http://arxiv.org/pdf/2310.20098v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20096v1",
            "title": "Data Market Design through Deep Learning",
            "updated": "2023-10-31T00:21:09Z",
            "published": "2023-10-31T00:21:09Z",
            "summary": "The $\\textit{data market design}$ problem is a problem in economic theory to\nfind a set of signaling schemes (statistical experiments) to maximize expected\nrevenue to the information seller, where each experiment reveals some of the\ninformation known to a seller and has a corresponding price [Bergemann et al.,\n2018]. Each buyer has their own decision to make in a world environment, and\ntheir subjective expected value for the information associated with a\nparticular experiment comes from the improvement in this decision and depends\non their prior and value for different outcomes. In a setting with multiple\nbuyers, a buyer's expected value for an experiment may also depend on the\ninformation sold to others [Bonatti et al., 2022]. We introduce the application\nof deep learning for the design of revenue-optimal data markets, looking to\nexpand the frontiers of what can be understood and achieved. Relative to\nearlier work on deep learning for auction design [D\\\"utting et al., 2023], we\nmust learn signaling schemes rather than allocation rules and handle\n$\\textit{obedience constraints}$ $-$ these arising from modeling the downstream\nactions of buyers $-$ in addition to incentive constraints on bids. Our\nexperiments demonstrate that this new deep learning framework can almost\nprecisely replicate all known solutions from theory, expand to more complex\nsettings, and be used to establish the optimality of new designs for data\nmarkets and make conjectures in regard to the structure of optimal designs.",
            "author": [
                "Sai Srivatsa Ravindranath",
                "Yanchen Jiang",
                "David C. Parkes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20096v1",
                "http://arxiv.org/pdf/2310.20096v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20095v1",
            "title": "$p$-Poisson surface reconstruction in curl-free flow from point clouds",
            "updated": "2023-10-31T00:20:24Z",
            "published": "2023-10-31T00:20:24Z",
            "summary": "The aim of this paper is the reconstruction of a smooth surface from an\nunorganized point cloud sampled by a closed surface, with the preservation of\ngeometric shapes, without any further information other than the point cloud.\nImplicit neural representations (INRs) have recently emerged as a promising\napproach to surface reconstruction. However, the reconstruction quality of\nexisting methods relies on ground truth implicit function values or surface\nnormal vectors. In this paper, we show that proper supervision of partial\ndifferential equations and fundamental properties of differential vector fields\nare sufficient to robustly reconstruct high-quality surfaces. We cast the\n$p$-Poisson equation to learn a signed distance function (SDF) and the\nreconstructed surface is implicitly represented by the zero-level set of the\nSDF. For efficient training, we develop a variable splitting structure by\nintroducing a gradient of the SDF as an auxiliary variable and impose the\n$p$-Poisson equation directly on the auxiliary variable as a hard constraint.\nBased on the curl-free property of the gradient field, we impose a curl-free\nconstraint on the auxiliary variable, which leads to a more faithful\nreconstruction. Experiments on standard benchmark datasets show that the\nproposed INR provides a superior and robust reconstruction. The code is\navailable at \\url{https://github.com/Yebbi/PINC}.",
            "author": [
                "Yesom Park",
                "Taekyung Lee",
                "Jooyoung Hahn",
                "Myungjoo Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20095v1",
                "http://arxiv.org/pdf/2310.20095v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20092v1",
            "title": "Beyond U: Making Diffusion Models Faster & Lighter",
            "updated": "2023-10-31T00:12:14Z",
            "published": "2023-10-31T00:12:14Z",
            "summary": "Diffusion models are a family of generative models that yield record-breaking\nperformance in tasks such as image synthesis, video generation, and molecule\ndesign. Despite their capabilities, their efficiency, especially in the reverse\ndenoising process, remains a challenge due to slow convergence rates and high\ncomputational costs. In this work, we introduce an approach that leverages\ncontinuous dynamical systems to design a novel denoising network for diffusion\nmodels that is more parameter-efficient, exhibits faster convergence, and\ndemonstrates increased noise robustness. Experimenting with denoising\nprobabilistic diffusion models, our framework operates with approximately a\nquarter of the parameters and 30% of the Floating Point Operations (FLOPs)\ncompared to standard U-Nets in Denoising Diffusion Probabilistic Models\n(DDPMs). Furthermore, our model is up to 70% faster in inference than the\nbaseline models when measured in equal conditions while converging to better\nquality solutions.",
            "author": [
                "Sergio Calvo-Ordonez",
                "Jiahao Huang",
                "Lipei Zhang",
                "Guang Yang",
                "Carola-Bibiane Schonlieb",
                "Angelica I Aviles-Rivero"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20092v1",
                "http://arxiv.org/pdf/2310.20092v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20090v1",
            "title": "Bridging the Gap Between Variational Inference and Wasserstein Gradient\n  Flows",
            "updated": "2023-10-31T00:10:19Z",
            "published": "2023-10-31T00:10:19Z",
            "summary": "Variational inference is a technique that approximates a target distribution\nby optimizing within the parameter space of variational families. On the other\nhand, Wasserstein gradient flows describe optimization within the space of\nprobability measures where they do not necessarily admit a parametric density\nfunction. In this paper, we bridge the gap between these two methods. We\ndemonstrate that, under certain conditions, the Bures-Wasserstein gradient flow\ncan be recast as the Euclidean gradient flow where its forward Euler scheme is\nthe standard black-box variational inference algorithm. Specifically, the\nvector field of the gradient flow is generated via the path-derivative gradient\nestimator. We also offer an alternative perspective on the path-derivative\ngradient, framing it as a distillation procedure to the Wasserstein gradient\nflow. Distillations can be extended to encompass $f$-divergences and\nnon-Gaussian variational families. This extension yields a new gradient\nestimator for $f$-divergences, readily implementable using contemporary machine\nlearning libraries like PyTorch or TensorFlow.",
            "author": [
                "Mingxuan Yi",
                "Song Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20090v1",
                "http://arxiv.org/pdf/2310.20090v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20089v1",
            "title": "Keyword-optimized Template Insertion for Clinical Information Extraction\n  via Prompt-based Learning",
            "updated": "2023-10-31T00:07:11Z",
            "published": "2023-10-31T00:07:11Z",
            "summary": "Clinical note classification is a common clinical NLP task. However,\nannotated data-sets are scarse. Prompt-based learning has recently emerged as\nan effective method to adapt pre-trained models for text classification using\nonly few training examples. A critical component of prompt design is the\ndefinition of the template (i.e. prompt text). The effect of template position,\nhowever, has been insufficiently investigated. This seems particularly\nimportant in the clinical setting, where task-relevant information is usually\nsparse in clinical notes. In this study we develop a keyword-optimized template\ninsertion method (KOTI) and show how optimizing position can improve\nperformance on several clinical tasks in a zero-shot and few-shot training\nsetting.",
            "author": [
                "Eugenia Alleva",
                "Isotta Landi",
                "Leslee J Shaw",
                "Erwin B\u00f6ttinger",
                "Thomas J Fuchs",
                "Ipek Ensari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20089v1",
                "http://arxiv.org/pdf/2310.20089v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20082v1",
            "title": "Efficient Subgraph GNNs by Learning Effective Selection Policies",
            "updated": "2023-10-30T23:41:05Z",
            "published": "2023-10-30T23:41:05Z",
            "summary": "Subgraph GNNs are provably expressive neural architectures that learn graph\nrepresentations from sets of subgraphs. Unfortunately, their applicability is\nhampered by the computational complexity associated with performing message\npassing on many subgraphs. In this paper, we consider the problem of learning\nto select a small subset of the large set of possible subgraphs in a\ndata-driven fashion. We first motivate the problem by proving that there are\nfamilies of WL-indistinguishable graphs for which there exist efficient\nsubgraph selection policies: small subsets of subgraphs that can already\nidentify all the graphs within the family. We then propose a new approach,\ncalled Policy-Learn, that learns how to select subgraphs in an iterative\nmanner. We prove that, unlike popular random policies and prior work addressing\nthe same problem, our architecture is able to learn the efficient policies\nmentioned above. Our experimental results demonstrate that Policy-Learn\noutperforms existing baselines across a wide range of datasets.",
            "author": [
                "Beatrice Bevilacqua",
                "Moshe Eliasof",
                "Eli Meirom",
                "Bruno Ribeiro",
                "Haggai Maron"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20082v1",
                "http://arxiv.org/pdf/2310.20082v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20079v1",
            "title": "Hybridizing Physics and Neural ODEs for Predicting Plasma Inductance\n  Dynamics in Tokamak Fusion Reactors",
            "updated": "2023-10-30T23:25:54Z",
            "published": "2023-10-30T23:25:54Z",
            "summary": "While fusion reactors known as tokamaks hold promise as a firm energy source,\nadvances in plasma control, and handling of events where control of plasmas is\nlost, are needed for them to be economical. A significant bottleneck towards\napplying more advanced control algorithms is the need for better plasma\nsimulation, where both physics-based and data-driven approaches currently fall\nshort. The former is bottle-necked by both computational cost and the\ndifficulty of modelling plasmas, and the latter is bottle-necked by the\nrelative paucity of data. To address this issue, this work applies the neural\nordinary differential equations (ODE) framework to the problem of predicting a\nsubset of plasma dynamics, namely the coupled plasma current and internal\ninductance dynamics. As the neural ODE framework allows for the natural\ninclusion of physics-based inductive biases, we train both physics-based and\nneural network models on data from the Alcator C-Mod fusion reactor and find\nthat a model that combines physics-based equations with a neural ODE performs\nbetter than both existing physics-motivated ODEs and a pure neural ODE model.",
            "author": [
                "Allen M. Wang",
                "Darren T. Garnier",
                "Cristina Rea"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20079v1",
                "http://arxiv.org/pdf/2310.20079v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20078v1",
            "title": "TorchProbe: Fuzzing Dynamic Deep Learning Compilers",
            "updated": "2023-10-30T23:20:47Z",
            "published": "2023-10-30T23:20:47Z",
            "summary": "Static and dynamic computational graphs represent two distinct approaches to\nconstructing deep learning frameworks. The former prioritizes compiler-based\noptimizations, while the latter focuses on programmability and\nuser-friendliness. The recent release of PyTorch 2.0, which supports compiling\narbitrary deep learning programs in Python, signifies a new direction in the\nevolution of deep learning infrastructure to incorporate compiler techniques in\na more dynamic manner and support more dynamic language features like dynamic\ncontrol flows and closures. Given PyTorch's seamless integration with Python,\nits compiler aims to support arbitrary deep learning code written in Python.\nHowever, the inherent dynamism of Python poses challenges to the completeness\nand robustness of the compiler. While recent research has introduced fuzzing to\ntest deep learning compilers, there is still a lack of comprehensive analysis\non how to test dynamic features. To address this issue, we propose several code\ntransformations to generate test cases involving dynamic features. These\ntransformations preserve the program's semantics, ensuring that any discrepancy\nbetween the transformed and original programs indicates the presence of a bug.\nThrough our approach, we have successfully identified twenty previously unknown\nbugs in the PyTorch compiler and its underlying tensor compiler Triton.",
            "author": [
                "Qidong Su",
                "Chuqin Geng",
                "Gennady Pekhimenko",
                "Xujie Si"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20078v1",
                "http://arxiv.org/pdf/2310.20078v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20077v1",
            "title": "Partial Tensorized Transformers for Natural Language Processing",
            "updated": "2023-10-30T23:19:06Z",
            "published": "2023-10-30T23:19:06Z",
            "summary": "The transformer architecture has revolutionized Natural Language Processing\n(NLP) and other machine-learning tasks, due to its unprecedented accuracy.\nHowever, their extensive memory and parameter requirements often hinder their\npractical applications. In this work, we study the effect of tensor-train\ndecomposition to improve the accuracy and compress transformer vision-language\nneural networks, namely BERT and ViT. We focus both on embedding-layer\ncompression and partial tensorization of neural networks (PTNN) through an\nalgorithmic approach. Our novel PTNN approach significantly improves the\naccuracy of existing models by up to 5%, all without the need for post-training\nadjustments, breaking new ground in the field of tensor decomposition.",
            "author": [
                "Subhadra Vadlamannati",
                "Ryan Solgi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20077v1",
                "http://arxiv.org/pdf/2310.20077v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20075v1",
            "title": "Meek Separators and Their Applications in Targeted Causal Discovery",
            "updated": "2023-10-30T23:15:27Z",
            "published": "2023-10-30T23:15:27Z",
            "summary": "Learning causal structures from interventional data is a fundamental problem\nwith broad applications across various fields. While many previous works have\nfocused on recovering the entire causal graph, in practice, there are scenarios\nwhere learning only part of the causal graph suffices. This is called\n$targeted$ causal discovery. In our work, we focus on two such well-motivated\nproblems: subset search and causal matching. We aim to minimize the number of\ninterventions in both cases.\n  Towards this, we introduce the $Meek~separator$, which is a subset of\nvertices that, when intervened, decomposes the remaining unoriented edges into\nsmaller connected components. We then present an efficient algorithm to find\nMeek separators that are of small sizes. Such a procedure is helpful in\ndesigning various divide-and-conquer-based approaches. In particular, we\npropose two randomized algorithms that achieve logarithmic approximation for\nsubset search and causal matching, respectively. Our results provide the first\nknown average-case provable guarantees for both problems. We believe that this\nopens up possibilities to design near-optimal methods for many other targeted\ncausal structure learning problems arising from various applications.",
            "author": [
                "Kirankumar Shiragur",
                "Jiaqi Zhang",
                "Caroline Uhler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20075v1",
                "http://arxiv.org/pdf/2310.20075v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DM",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20072v1",
            "title": "Automatic Evaluation of Generative Models with Instruction Tuning",
            "updated": "2023-10-30T23:00:52Z",
            "published": "2023-10-30T23:00:52Z",
            "summary": "Automatic evaluation of natural language generation has long been an elusive\ngoal in NLP.A recent paradigm fine-tunes pre-trained language models to emulate\nhuman judgements for a particular task and evaluation criterion. Inspired by\nthe generalization ability of instruction-tuned models, we propose a learned\nmetric based on instruction tuning. To test our approach, we collected HEAP, a\ndataset of human judgements across various NLG tasks and evaluation criteria.\nOur findings demonstrate that instruction tuning language models on HEAP yields\ngood performance on many evaluation tasks, though some criteria are less\ntrivial to learn than others. Further, jointly training on multiple tasks can\nyield additional performance improvements, which can be beneficial for future\ntasks with little to no human annotated data.",
            "author": [
                "Shuhaib Mehri",
                "Vered Shwartz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20072v1",
                "http://arxiv.org/pdf/2310.20072v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20071v1",
            "title": "FOCAL: Contrastive Learning for Multimodal Time-Series Sensing Signals\n  in Factorized Orthogonal Latent Space",
            "updated": "2023-10-30T22:55:29Z",
            "published": "2023-10-30T22:55:29Z",
            "summary": "This paper proposes a novel contrastive learning framework, called FOCAL, for\nextracting comprehensive features from multimodal time-series sensing signals\nthrough self-supervised training. Existing multimodal contrastive frameworks\nmostly rely on the shared information between sensory modalities, but do not\nexplicitly consider the exclusive modality information that could be critical\nto understanding the underlying sensing physics. Besides, contrastive\nframeworks for time series have not handled the temporal information locality\nappropriately. FOCAL solves these challenges by making the following\ncontributions: First, given multimodal time series, it encodes each modality\ninto a factorized latent space consisting of shared features and private\nfeatures that are orthogonal to each other. The shared space emphasizes feature\npatterns consistent across sensory modalities through a modal-matching\nobjective. In contrast, the private space extracts modality-exclusive\ninformation through a transformation-invariant objective. Second, we propose a\ntemporal structural constraint for modality features, such that the average\ndistance between temporally neighboring samples is no larger than that of\ntemporally distant samples. Extensive evaluations are performed on four\nmultimodal sensing datasets with two backbone encoders and two classifiers to\ndemonstrate the superiority of FOCAL. It consistently outperforms the\nstate-of-the-art baselines in downstream tasks with a clear margin, under\ndifferent ratios of available labels. The code and self-collected dataset are\navailable at https://github.com/tomoyoshki/focal.",
            "author": [
                "Shengzhong Liu",
                "Tomoyoshi Kimura",
                "Dongxin Liu",
                "Ruijie Wang",
                "Jinyang Li",
                "Suhas Diggavi",
                "Mani Srivastava",
                "Tarek Abdelzaher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20071v1",
                "http://arxiv.org/pdf/2310.20071v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20067v1",
            "title": "Vignat: Vulnerability identification by learning code semantics via\n  graph attention networks",
            "updated": "2023-10-30T22:31:38Z",
            "published": "2023-10-30T22:31:38Z",
            "summary": "Vulnerability identification is crucial to protect software systems from\nattacks for cyber-security. However, huge projects have more than millions of\nlines of code, and the complex dependencies make it hard to carry out\ntraditional static and dynamic methods. Furthermore, the semantic structure of\nvarious types of vulnerabilities differs greatly and may occur simultaneously,\nmaking general rule-based methods difficult to extend. In this paper, we\npropose \\textit{Vignat}, a novel attention-based framework for identifying\nvulnerabilities by learning graph-level semantic representations of code. We\nrepresent codes with code property graphs (CPGs) in fine grain and use graph\nattention networks (GATs) for vulnerability detection. The results show that\nVignat is able to achieve $57.38\\%$ accuracy on reliable datasets derived from\npopular C libraries. Furthermore, the interpretability of our GATs provides\nvaluable insights into vulnerability patterns.",
            "author": [
                "Shuo Liu",
                "Gail Kaiser"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20067v1",
                "http://arxiv.org/pdf/2310.20067v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20065v1",
            "title": "LinFlo-Net: A two-stage deep learning method to generate simulation\n  ready meshes of the heart",
            "updated": "2023-10-30T22:29:50Z",
            "published": "2023-10-30T22:29:50Z",
            "summary": "We present a deep learning model to automatically generate computer models of\nthe human heart from patient imaging data with an emphasis on its capability to\ngenerate thin-walled cardiac structures. Our method works by deforming a\ntemplate mesh to fit the cardiac structures to the given image. Compared with\nprior deep learning methods that adopted this approach, our framework is\ndesigned to minimize mesh self-penetration, which typically arises when\ndeforming surface meshes separated by small distances. We achieve this by using\na two-stage diffeomorphic deformation process along with a novel loss function\nderived from the kinematics of motion that penalizes surface contact and\ninterpenetration. Our model demonstrates comparable accuracy with\nstate-of-the-art methods while additionally producing meshes free of\nself-intersections. The resultant meshes are readily usable in physics based\nsimulation, minimizing the need for post-processing and cleanup.",
            "author": [
                "Arjun Narayanan",
                "Fanwei Kong",
                "Shawn Shadden"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20065v1",
                "http://arxiv.org/pdf/2310.20065v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20064v1",
            "title": "A Scalable Training Strategy for Blind Multi-Distribution Noise Removal",
            "updated": "2023-10-30T22:29:07Z",
            "published": "2023-10-30T22:29:07Z",
            "summary": "Despite recent advances, developing general-purpose universal denoising and\nartifact-removal networks remains largely an open problem: Given fixed network\nweights, one inherently trades-off specialization at one task (e.g.,~removing\nPoisson noise) for performance at another (e.g.,~removing speckle noise). In\naddition, training such a network is challenging due to the curse of\ndimensionality: As one increases the dimensions of the specification-space\n(i.e.,~the number of parameters needed to describe the noise distribution) the\nnumber of unique specifications one needs to train for grows exponentially.\nUniformly sampling this space will result in a network that does well at very\nchallenging problem specifications but poorly at easy problem specifications,\nwhere even large errors will have a small effect on the overall mean squared\nerror.\n  In this work we propose training denoising networks using an\nadaptive-sampling/active-learning strategy. Our work improves upon a recently\nproposed universal denoiser training strategy by extending these results to\nhigher dimensions and by incorporating a polynomial approximation of the true\nspecification-loss landscape. This approximation allows us to reduce training\ntimes by almost two orders of magnitude. We test our method on simulated joint\nPoisson-Gaussian-Speckle noise and demonstrate that with our proposed training\nstrategy, a single blind, generalist denoiser network can achieve peak\nsignal-to-noise ratios within a uniform bound of specialized denoiser networks\nacross a large range of operating conditions. We also capture a small dataset\nof images with varying amounts of joint Poisson-Gaussian-Speckle noise and\ndemonstrate that a universal denoiser trained using our adaptive-sampling\nstrategy outperforms uniformly trained baselines.",
            "author": [
                "Kevin Zhang",
                "Sakshum Kulshrestha",
                "Christopher Metzler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20064v1",
                "http://arxiv.org/pdf/2310.20064v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20062v1",
            "title": "Decentralised, Scalable and Privacy-Preserving Synthetic Data Generation",
            "updated": "2023-10-30T22:27:32Z",
            "published": "2023-10-30T22:27:32Z",
            "summary": "Synthetic data is emerging as a promising way to harness the value of data,\nwhile reducing privacy risks. The potential of synthetic data is not limited to\nprivacy-friendly data release, but also includes complementing real data in\nuse-cases such as training machine learning algorithms that are more fair and\nrobust to distribution shifts etc. There is a lot of interest in algorithmic\nadvances in synthetic data generation for providing better privacy and\nstatistical guarantees and for its better utilisation in machine learning\npipelines. However, for responsible and trustworthy synthetic data generation,\nit is not sufficient to focus only on these algorithmic aspects and instead, a\nholistic view of the synthetic data generation pipeline must be considered. We\nbuild a novel system that allows the contributors of real data to autonomously\nparticipate in differentially private synthetic data generation without relying\non a trusted centre. Our modular, general and scalable solution is based on\nthree building blocks namely: Solid (Social Linked Data), MPC (Secure\nMulti-Party Computation) and Trusted Execution Environments (TEEs). Solid is a\nspecification that lets people store their data securely in decentralised data\nstores called Pods and control access to their data. MPC refers to the set of\ncryptographic methods for different parties to jointly compute a function over\ntheir inputs while keeping those inputs private. TEEs such as Intel SGX rely on\nhardware based features for confidentiality and integrity of code and data. We\nshow how these three technologies can be effectively used to address various\nchallenges in responsible and trustworthy synthetic data generation by\nensuring: 1) contributor autonomy, 2) decentralisation, 3) privacy and 4)\nscalability. We support our claims with rigorous empirical results on simulated\nand real datasets and different synthetic data generation algorithms.",
            "author": [
                "Vishal Ramesh",
                "Rui Zhao",
                "Naman Goel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20062v1",
                "http://arxiv.org/pdf/2310.20062v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20061v1",
            "title": "Evaluation Framework for Understanding Sensitive Attribute Association\n  Bias in Latent Factor Recommendation Algorithms",
            "updated": "2023-10-30T22:26:45Z",
            "published": "2023-10-30T22:26:45Z",
            "summary": "We present a novel evaluation framework for representation bias in latent\nfactor recommendation (LFR) algorithms. Our framework introduces the concept of\nattribute association bias in recommendations allowing practitioners to explore\nhow recommendation systems can introduce or amplify stakeholder representation\nharm. Attribute association bias (AAB) occurs when sensitive attributes become\nsemantically captured or entangled in the trained recommendation latent space.\nThis bias can result in the recommender reinforcing harmful stereotypes, which\nmay result in downstream representation harms to system consumer and provider\nstakeholders. LFR models are at risk of experiencing AAB due to their ability\nto entangle explicit and implicit attributes into the trained latent space.\nUnderstanding this phenomenon is essential due to the increasingly common use\nof entity vectors as attributes in downstream components in hybrid industry\nrecommendation systems. We provide practitioners with a framework for executing\ndisaggregated evaluations of AAB within broader algorithmic auditing\nframeworks. Inspired by research in natural language processing (NLP) observing\ngender bias in word embeddings, our framework introduces AAB evaluation methods\nspecifically for recommendation entity vectors. We present four evaluation\nstrategies for sensitive AAB in LFR models: attribute bias directions,\nattribute association bias metrics, classification for explaining bias, and\nlatent space visualization. We demonstrate the utility of our framework by\nevaluating user gender AAB regarding podcast genres with an industry case study\nof a production-level DNN recommendation model. We uncover significant levels\nof user gender AAB when user gender is used and removed as a model feature\nduring training, pointing to the potential for systematic bias in LFR model\noutputs.",
            "author": [
                "Lex Beattie",
                "Isabel Corpus",
                "Lucy H. Lin",
                "Praveen Ravichandran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20061v1",
                "http://arxiv.org/pdf/2310.20061v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20060v2",
            "title": "AdaSub: Stochastic Optimization Using Second-Order Information in\n  Low-Dimensional Subspaces",
            "updated": "2023-11-06T21:37:33Z",
            "published": "2023-10-30T22:24:23Z",
            "summary": "We introduce AdaSub, a stochastic optimization algorithm that computes a\nsearch direction based on second-order information in a low-dimensional\nsubspace that is defined adaptively based on available current and past\ninformation. Compared to first-order methods, second-order methods exhibit\nbetter convergence characteristics, but the need to compute the Hessian matrix\nat each iteration results in excessive computational expenses, making them\nimpractical. To address this issue, our approach enables the management of\ncomputational expenses and algorithm efficiency by enabling the selection of\nthe subspace dimension for the search. Our code is freely available on GitHub,\nand our preliminary numerical results demonstrate that AdaSub surpasses popular\nstochastic optimizers in terms of time and number of iterations required to\nreach a given accuracy.",
            "author": [
                "Jo\u00e3o Victor Galv\u00e3o da Mata",
                "Martin S. Andersen"
            ],
            "link": [
                "http://dx.doi.org/10.1109/DSAA60987.2023.10302473",
                "http://arxiv.org/abs/2310.20060v2",
                "http://arxiv.org/pdf/2310.20060v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20059v1",
            "title": "Concept Alignment as a Prerequisite for Value Alignment",
            "updated": "2023-10-30T22:23:15Z",
            "published": "2023-10-30T22:23:15Z",
            "summary": "Value alignment is essential for building AI systems that can safely and\nreliably interact with people. However, what a person values -- and is even\ncapable of valuing -- depends on the concepts that they are currently using to\nunderstand and evaluate what happens in the world. The dependence of values on\nconcepts means that concept alignment is a prerequisite for value alignment --\nagents need to align their representation of a situation with that of humans in\norder to successfully align their values. Here, we formally analyze the concept\nalignment problem in the inverse reinforcement learning setting, show how\nneglecting concept alignment can lead to systematic value mis-alignment, and\ndescribe an approach that helps minimize such failure modes by jointly\nreasoning about a person's concepts and values. Additionally, we report\nexperimental results with human participants showing that humans reason about\nthe concepts used by an agent when acting intentionally, in line with our joint\nreasoning model.",
            "author": [
                "Sunayana Rane",
                "Mark Ho",
                "Ilia Sucholutsky",
                "Thomas L. Griffiths"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20059v1",
                "http://arxiv.org/pdf/2310.20059v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20056v1",
            "title": "On the data-driven description of lattice materials mechanics",
            "updated": "2023-10-30T22:21:08Z",
            "published": "2023-10-30T22:21:08Z",
            "summary": "In the emerging field of mechanical metamaterials, using periodic lattice\nstructures as a primary ingredient is relatively frequent. However, the choice\nof aperiodic lattices in these structures presents unique advantages regarding\nfailure, e.g., buckling or fracture, because avoiding repeated patterns\nprevents global failures, with local failures occurring in turn that can\nbeneficially delay structural collapse. Therefore, it is expedient to develop\nmodels for computing efficiently the effective mechanical properties in\nlattices from different general features while addressing the challenge of\npresenting topologies (or graphs) of different sizes. In this paper, we develop\na deep learning model to predict energetically-equivalent mechanical properties\nof linear elastic lattices effectively. Considering the lattice as a graph and\ndefining material and geometrical features on such, we show that Graph Neural\nNetworks provide more accurate predictions than a dense, fully connected\nstrategy, thanks to the geometrically induced bias through graph\nrepresentation, closer to the underlying equilibrium laws from mechanics solved\nin the direct problem. Leveraging the efficient forward-evaluation of a vast\nnumber of lattices using this surrogate enables the inverse problem, i.e., to\nobtain a structure having prescribed specific behavior, which is ultimately\nsuitable for multiscale structural optimization problems.",
            "author": [
                "Ismael Ben-Yelun",
                "Luis Irastorza-Valera",
                "Luis Saucedo-Mora",
                "Francisco Javier Mont\u00e1ns",
                "Francisco Chinesta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20056v1",
                "http://arxiv.org/pdf/2310.20056v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20053v1",
            "title": "Estimating optimal PAC-Bayes bounds with Hamiltonian Monte Carlo",
            "updated": "2023-10-30T22:16:51Z",
            "published": "2023-10-30T22:16:51Z",
            "summary": "An important yet underexplored question in the PAC-Bayes literature is how\nmuch tightness we lose by restricting the posterior family to factorized\nGaussian distributions when optimizing a PAC-Bayes bound. We investigate this\nissue by estimating data-independent PAC-Bayes bounds using the optimal\nposteriors, comparing them to bounds obtained using MFVI. Concretely, we (1)\nsample from the optimal Gibbs posterior using Hamiltonian Monte Carlo, (2)\nestimate its KL divergence from the prior with thermodynamic integration, and\n(3) propose three methods to obtain high-probability bounds under different\nassumptions. Our experiments on the MNIST dataset reveal significant tightness\ngaps, as much as 5-6\\% in some cases.",
            "author": [
                "Szilvia Ujv\u00e1ry",
                "Gergely Flamich",
                "Vincent Fortuin",
                "Jos\u00e9 Miguel Hern\u00e1ndez Lobato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20053v1",
                "http://arxiv.org/pdf/2310.20053v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20052v1",
            "title": "Look At Me, No Replay! SurpriseNet: Anomaly Detection Inspired Class\n  Incremental Learning",
            "updated": "2023-10-30T22:16:26Z",
            "published": "2023-10-30T22:16:26Z",
            "summary": "Continual learning aims to create artificial neural networks capable of\naccumulating knowledge and skills through incremental training on a sequence of\ntasks. The main challenge of continual learning is catastrophic interference,\nwherein new knowledge overrides or interferes with past knowledge, leading to\nforgetting. An associated issue is the problem of learning \"cross-task\nknowledge,\" where models fail to acquire and retain knowledge that helps\ndifferentiate classes across task boundaries. A common solution to both\nproblems is \"replay,\" where a limited buffer of past instances is utilized to\nlearn cross-task knowledge and mitigate catastrophic interference. However, a\nnotable drawback of these methods is their tendency to overfit the limited\nreplay buffer. In contrast, our proposed solution, SurpriseNet, addresses\ncatastrophic interference by employing a parameter isolation method and\nlearning cross-task knowledge using an auto-encoder inspired by anomaly\ndetection. SurpriseNet is applicable to both structured and unstructured data,\nas it does not rely on image-specific inductive biases. We have conducted\nempirical experiments demonstrating the strengths of SurpriseNet on various\ntraditional vision continual-learning benchmarks, as well as on structured data\ndatasets. Source code made available at https://doi.org/10.5281/zenodo.8247906\nand https://github.com/tachyonicClock/SurpriseNet-CIKM-23",
            "author": [
                "Anton Lee",
                "Yaqian Zhang",
                "Heitor Murilo Gomes",
                "Albert Bifet",
                "Bernhard Pfahringer"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615236",
                "http://arxiv.org/abs/2310.20052v1",
                "http://arxiv.org/pdf/2310.20052v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20051v1",
            "title": "The Expressibility of Polynomial based Attention Scheme",
            "updated": "2023-10-30T22:16:18Z",
            "published": "2023-10-30T22:16:18Z",
            "summary": "Large language models (LLMs) have significantly improved various aspects of\nour daily lives. These models have impacted numerous domains, from healthcare\nto education, enhancing productivity, decision-making processes, and\naccessibility. As a result, they have influenced and, to some extent, reshaped\npeople's lifestyles. However, the quadratic complexity of attention in\ntransformer architectures poses a challenge when scaling up these models for\nprocessing long textual contexts. This issue makes it impractical to train very\nlarge models on lengthy texts or use them efficiently during inference. While a\nrecent study by [KMZ23] introduced a technique that replaces the softmax with a\npolynomial function and polynomial sketching to speed up attention mechanisms,\nthe theoretical understandings of this new approach are not yet well\nunderstood.\n  In this paper, we offer a theoretical analysis of the expressive capabilities\nof polynomial attention. Our study reveals a disparity in the ability of\nhigh-degree and low-degree polynomial attention. Specifically, we construct two\ncarefully designed datasets, namely $\\mathcal{D}_0$ and $\\mathcal{D}_1$, where\n$\\mathcal{D}_1$ includes a feature with a significantly larger value compared\nto $\\mathcal{D}_0$. We demonstrate that with a sufficiently high degree\n$\\beta$, a single-layer polynomial attention network can distinguish between\n$\\mathcal{D}_0$ and $\\mathcal{D}_1$. However, with a low degree $\\beta$, the\nnetwork cannot effectively separate the two datasets. This analysis underscores\nthe greater effectiveness of high-degree polynomials in amplifying large values\nand distinguishing between datasets. Our analysis offers insight into the\nrepresentational capacity of polynomial attention and provides a rationale for\nincorporating higher-degree polynomials in attention mechanisms to capture\nintricate linguistic correlations.",
            "author": [
                "Zhao Song",
                "Guangyi Xu",
                "Junze Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20051v1",
                "http://arxiv.org/pdf/2310.20051v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20049v3",
            "title": "SURF: A Generalization Benchmark for GNNs Predicting Fluid Dynamics",
            "updated": "2023-11-20T15:16:59Z",
            "published": "2023-10-30T22:12:35Z",
            "summary": "Simulating fluid dynamics is crucial for the design and development process,\nranging from simple valves to complex turbomachinery. Accurately solving the\nunderlying physical equations is computationally expensive. Therefore,\nlearning-based solvers that model interactions on meshes have gained interest\ndue to their promising speed-ups. However, it is unknown to what extent these\nmodels truly understand the underlying physical principles and can generalize\nrather than interpolate. Generalization is a key requirement for a\ngeneral-purpose fluid simulator, which should adapt to different topologies,\nresolutions, or thermodynamic ranges. We propose SURF, a benchmark designed to\ntest the $\\textit{generalization}$ of learned graph-based fluid simulators.\nSURF comprises individual datasets and provides specific performance and\ngeneralization metrics for evaluating and comparing different models. We\nempirically demonstrate the applicability of SURF by thoroughly investigating\nthe two state-of-the-art graph-based models, yielding new insights into their\ngeneralization.",
            "author": [
                "Stefan K\u00fcnzli",
                "Florian Gr\u00f6tschla",
                "Jo\u00ebl Mathys",
                "Roger Wattenhofer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20049v3",
                "http://arxiv.org/pdf/2310.20049v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20046v1",
            "title": "Which Examples to Annotate for In-Context Learning? Towards Effective\n  and Efficient Selection",
            "updated": "2023-10-30T22:03:55Z",
            "published": "2023-10-30T22:03:55Z",
            "summary": "Large Language Models (LLMs) can adapt to new tasks via in-context learning\n(ICL). ICL is efficient as it does not require any parameter updates to the\ntrained LLM, but only few annotated examples as input for the LLM. In this\nwork, we investigate an active learning approach for ICL, where there is a\nlimited budget for annotating examples. We propose a model-adaptive\noptimization-free algorithm, termed AdaICL, which identifies examples that the\nmodel is uncertain about, and performs semantic diversity-based example\nselection. Diversity-based sampling improves overall effectiveness, while\nuncertainty sampling improves budget efficiency and helps the LLM learn new\ninformation. Moreover, AdaICL poses its sampling strategy as a Maximum Coverage\nproblem, that dynamically adapts based on the model's feedback and can be\napproximately solved via greedy algorithms. Extensive experiments on nine\ndatasets and seven LLMs show that AdaICL improves performance by 4.4% accuracy\npoints over SOTA (7.7% relative improvement), is up to 3x more budget-efficient\nthan performing annotations uniformly at random, while it outperforms SOTA with\n2x fewer ICL examples.",
            "author": [
                "Costas Mavromatis",
                "Balasubramaniam Srinivasan",
                "Zhengyuan Shen",
                "Jiani Zhang",
                "Huzefa Rangwala",
                "Christos Faloutsos",
                "George Karypis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20046v1",
                "http://arxiv.org/pdf/2310.20046v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02099v1",
            "title": "A Preference Learning Approach to Develop Safe and Personalizable\n  Autonomous Vehicles",
            "updated": "2023-10-30T21:52:37Z",
            "published": "2023-10-30T21:52:37Z",
            "summary": "This work introduces a preference learning method that ensures adherence to\ntraffic rules for autonomous vehicles. Our approach incorporates priority\nordering of signal temporal logic (STL) formulas, describing traffic rules,\ninto a learning framework. By leveraging the parametric weighted signal\ntemporal logic (PWSTL), we formulate the problem of safety-guaranteed\npreference learning based on pairwise comparisons, and propose an approach to\nsolve this learning problem. Our approach finds a feasible valuation for the\nweights of the given PWSTL formula such that, with these weights, preferred\nsignals have weighted quantitative satisfaction measures greater than their\nnon-preferred counterparts. The feasible valuation of weights given by our\napproach leads to a weighted STL formula which can be used in\ncorrect-and-custom-by-construction controller synthesis. We demonstrate the\nperformance of our method with human subject studies in two different simulated\ndriving scenarios involving a stop sign and a pedestrian crossing. Our approach\nyields competitive results compared to existing preference learning methods in\nterms of capturing preferences, and notably outperforms them when safety is\nconsidered.",
            "author": [
                "Ruya Karagulle",
                "Nikos Arechiga",
                "Andrew Best",
                "Jonathan DeCastro",
                "Necmiye Ozay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02099v1",
                "http://arxiv.org/pdf/2311.02099v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01469v1",
            "title": "Leveraging Language Models to Detect Greenwashing",
            "updated": "2023-10-30T21:41:49Z",
            "published": "2023-10-30T21:41:49Z",
            "summary": "In recent years, climate change repercussions have increasingly captured\npublic interest. Consequently, corporations are emphasizing their environmental\nefforts in sustainability reports to bolster their public image. Yet, the\nabsence of stringent regulations in review of such reports allows potential\ngreenwashing. In this study, we introduce a novel methodology to train a\nlanguage model on generated labels for greenwashing risk. Our primary\ncontributions encompass: developing a mathematical formulation to quantify\ngreenwashing risk, a fine-tuned ClimateBERT model for this problem, and a\ncomparative analysis of results. On a test set comprising of sustainability\nreports, our best model achieved an average accuracy score of 86.34% and F1\nscore of 0.67, demonstrating that our methods show a promising direction of\nexploration for this task.",
            "author": [
                "Avalon Vinella",
                "Margaret Capetz",
                "Rebecca Pattichis",
                "Christina Chance",
                "Reshmi Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01469v1",
                "http://arxiv.org/pdf/2311.01469v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20030v1",
            "title": "Scaling Riemannian Diffusion Models",
            "updated": "2023-10-30T21:27:53Z",
            "published": "2023-10-30T21:27:53Z",
            "summary": "Riemannian diffusion models draw inspiration from standard Euclidean space\ndiffusion models to learn distributions on general manifolds. Unfortunately,\nthe additional geometric complexity renders the diffusion transition term\ninexpressible in closed form, so prior methods resort to imprecise\napproximations of the score matching training objective that degrade\nperformance and preclude applications in high dimensions. In this work, we\nreexamine these approximations and propose several practical improvements. Our\nkey observation is that most relevant manifolds are symmetric spaces, which are\nmuch more amenable to computation. By leveraging and combining various\nans\\\"{a}tze, we can quickly compute relevant quantities to high precision. On\nlow dimensional datasets, our correction produces a noticeable improvement,\nallowing diffusion to compete with other methods. Additionally, we show that\nour method enables us to scale to high dimensional tasks on nontrivial\nmanifolds. In particular, we model QCD densities on $SU(n)$ lattices and\ncontrastively learned embeddings on high dimensional hyperspheres.",
            "author": [
                "Aaron Lou",
                "Minkai Xu",
                "Stefano Ermon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20030v1",
                "http://arxiv.org/pdf/2310.20030v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.DG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20025v1",
            "title": "GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with\n  Learned Models",
            "updated": "2023-10-30T21:19:52Z",
            "published": "2023-10-30T21:19:52Z",
            "summary": "Offline goal-conditioned RL (GCRL) offers a feasible paradigm to learn\ngeneral-purpose policies from diverse and multi-task offline datasets. Despite\nnotable recent progress, the predominant offline GCRL methods have been\nrestricted to model-free approaches, constraining their capacity to tackle\nlimited data budgets and unseen goal generalization. In this work, we propose a\nnovel two-stage model-based framework, Goal-conditioned Offline Planning\n(GOPlan), including (1) pretraining a prior policy capable of capturing\nmulti-modal action distribution within the multi-goal dataset; (2) employing\nthe reanalysis method with planning to generate imagined trajectories for\nfunetuning policies. Specifically, the prior policy is based on an\nadvantage-weighted Conditioned Generative Adversarial Networks that exhibits\ndistinct mode separation to overcome the pitfalls of out-of-distribution (OOD)\nactions. For further policy optimization, the reanalysis method generates\nhigh-quality imaginary data by planning with learned models for both\nintra-trajectory and inter-trajectory goals. Through experimental evaluations,\nwe demonstrate that GOPlan achieves state-of-the-art performance on various\noffline multi-goal manipulation tasks. Moreover, our results highlight the\nsuperior ability of GOPlan to handle small data budgets and generalize to OOD\ngoals.",
            "author": [
                "Mianchu Wang",
                "Rui Yang",
                "Xi Chen",
                "Meng Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20025v1",
                "http://arxiv.org/pdf/2310.20025v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20024v1",
            "title": "Topology Recoverability Prediction for Ad-Hoc Robot Networks: A\n  Data-Driven Fault-Tolerant Approach",
            "updated": "2023-10-30T21:16:46Z",
            "published": "2023-10-30T21:16:46Z",
            "summary": "Faults occurring in ad-hoc robot networks may fatally perturb their\ntopologies leading to disconnection of subsets of those networks. Optimal\ntopology synthesis is generally resource-intensive and time-consuming to be\ndone in real time for large ad-hoc robot networks. One should only perform\ntopology re-computations if the probability of topology recoverability after\nthe occurrence of any fault surpasses that of its irrecoverability. We\nformulate this problem as a binary classification problem. Then, we develop a\ntwo-pathway data-driven model based on Bayesian Gaussian mixture models that\npredicts the solution to a typical problem by two different pre-fault and\npost-fault prediction pathways. The results, obtained by the integration of the\npredictions of those pathways, clearly indicate the success of our model in\nsolving the topology (ir)recoverability prediction problem compared to the best\nof current strategies found in the literature.",
            "author": [
                "Matin Macktoobian",
                "Zhan Shu",
                "Qing Zhao"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TSIPN.2023.3328275",
                "http://arxiv.org/abs/2310.20024v1",
                "http://arxiv.org/pdf/2310.20024v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20012v1",
            "title": "Multiscale Feature Attribution for Outliers",
            "updated": "2023-10-30T20:58:28Z",
            "published": "2023-10-30T20:58:28Z",
            "summary": "Machine learning techniques can automatically identify outliers in massive\ndatasets, much faster and more reproducible than human inspection ever could.\nBut finding such outliers immediately leads to the question: which features\nrender this input anomalous? We propose a new feature attribution method,\nInverse Multiscale Occlusion, that is specifically designed for outliers, for\nwhich we have little knowledge of the type of features we want to identify and\nexpect that the model performance is questionable because anomalous test data\nlikely exceed the limits of the training data. We demonstrate our method on\noutliers detected in galaxy spectra from the Dark Energy Survey Instrument and\nfind its results to be much more interpretable than alternative attribution\napproaches.",
            "author": [
                "Jeff Shen",
                "Peter Melchior"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20012v1",
                "http://arxiv.org/pdf/2310.20012v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "astro-ph.IM",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.20007v1",
            "title": "Improved Bayesian Regret Bounds for Thompson Sampling in Reinforcement\n  Learning",
            "updated": "2023-10-30T20:53:02Z",
            "published": "2023-10-30T20:53:02Z",
            "summary": "In this paper, we prove the first Bayesian regret bounds for Thompson\nSampling in reinforcement learning in a multitude of settings. We simplify the\nlearning problem using a discrete set of surrogate environments, and present a\nrefined analysis of the information ratio using posterior consistency. This\nleads to an upper bound of order $\\widetilde{O}(H\\sqrt{d_{l_1}T})$ in the time\ninhomogeneous reinforcement learning problem where $H$ is the episode length\nand $d_{l_1}$ is the Kolmogorov $l_1-$dimension of the space of environments.\nWe then find concrete bounds of $d_{l_1}$ in a variety of settings, such as\ntabular, linear and finite mixtures, and discuss how how our results are either\nthe first of their kind or improve the state-of-the-art.",
            "author": [
                "Ahmadreza Moradipari",
                "Mohammad Pedramfar",
                "Modjtaba Shokrian Zini",
                "Vaneet Aggarwal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20007v1",
                "http://arxiv.org/pdf/2310.20007v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19998v1",
            "title": "Generative retrieval-augmented ontologic graph and multi-agent\n  strategies for interpretive large language model-based materials design",
            "updated": "2023-10-30T20:31:50Z",
            "published": "2023-10-30T20:31:50Z",
            "summary": "Transformer neural networks show promising capabilities, in particular for\nuses in materials analysis, design and manufacturing, including their capacity\nto work effectively with both human language, symbols, code, and numerical\ndata. Here we explore the use of large language models (LLMs) as a tool that\ncan support engineering analysis of materials, applied to retrieving key\ninformation about subject areas, developing research hypotheses, discovery of\nmechanistic relationships across disparate areas of knowledge, and writing and\nexecuting simulation codes for active knowledge generation based on physical\nground truths. When used as sets of AI agents with specific features,\ncapabilities, and instructions, LLMs can provide powerful problem solution\nstrategies for applications in analysis and design problems. Our experiments\nfocus on using a fine-tuned model, MechGPT, developed based on training data in\nthe mechanics of materials domain. We first affirm how finetuning endows LLMs\nwith reasonable understanding of domain knowledge. However, when queried\noutside the context of learned matter, LLMs can have difficulty to recall\ncorrect information. We show how this can be addressed using\nretrieval-augmented Ontological Knowledge Graph strategies that discern how the\nmodel understands what concepts are important and how they are related.\nIllustrated for a use case of relating distinct areas of knowledge - here,\nmusic and proteins - such strategies can also provide an interpretable graph\nstructure with rich information at the node, edge and subgraph level. We\ndiscuss nonlinear sampling strategies and agent-based modeling applied to\ncomplex question answering, code generation and execution in the context of\nautomated force field development from actively learned Density Functional\nTheory (DFT) modeling, and data analysis.",
            "author": [
                "Markus J. Buehler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19998v1",
                "http://arxiv.org/pdf/2310.19998v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cond-mat.dis-nn",
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19997v1",
            "title": "State-Dependent Dynamic Tube MPC: A Novel Tube MPC Method with a Fuzzy\n  Model of Disturbances",
            "updated": "2023-10-30T20:30:12Z",
            "published": "2023-10-30T20:30:12Z",
            "summary": "Most real-world systems are affected by external disturbances, which may be\nimpossible or costly to measure. For instance, when autonomous robots move in\ndusty environments, the perception of their sensors is disturbed. Moreover,\nuneven terrains can cause ground robots to deviate from their planned\ntrajectories. Thus, learning the external disturbances and incorporating this\nknowledge into the future predictions in decision-making can significantly\ncontribute to improved performance. Our core idea is to learn the external\ndisturbances that vary with the states of the system, and to incorporate this\nknowledge into a novel formulation for robust tube model predictive control\n(TMPC). Robust TMPC provides robustness to bounded disturbances considering the\nknown (fixed) upper bound of the disturbances, but it does not consider the\ndynamics of the disturbances. This can lead to highly conservative solutions.\nWe propose a new dynamic version of robust TMPC (with proven robust stability),\ncalled state-dependent dynamic TMPC (SDD-TMPC), which incorporates the dynamics\nof the disturbances into the decision-making of TMPC. In order to learn the\ndynamics of the disturbances as a function of the system states, a fuzzy model\nis proposed. We compare the performance of SDD-TMPC, MPC, and TMPC via\nsimulations, in designed search-and-rescue scenarios. The results show that,\nwhile remaining robust to bounded external disturbances, SDD-TMPC generates\nless conservative solutions and remains feasible in more cases, compared to\nTMPC.",
            "author": [
                "Filip Surma",
                "Anahita Jamshidnejad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19997v1",
                "http://arxiv.org/pdf/2310.19997v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "93B45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19996v1",
            "title": "Adaptive Anchor Label Propagation for Transductive Few-Shot Learning",
            "updated": "2023-10-30T20:29:31Z",
            "published": "2023-10-30T20:29:31Z",
            "summary": "Few-shot learning addresses the issue of classifying images using limited\nlabeled data. Exploiting unlabeled data through the use of transductive\ninference methods such as label propagation has been shown to improve the\nperformance of few-shot learning significantly. Label propagation infers\npseudo-labels for unlabeled data by utilizing a constructed graph that exploits\nthe underlying manifold structure of the data. However, a limitation of the\nexisting label propagation approaches is that the positions of all data points\nare fixed and might be sub-optimal so that the algorithm is not as effective as\npossible. In this work, we propose a novel algorithm that adapts the feature\nembeddings of the labeled data by minimizing a differentiable loss function\noptimizing their positions in the manifold in the process. Our novel algorithm,\nAdaptive Anchor Label Propagation}, outperforms the standard label propagation\nalgorithm by as much as 7% and 2% in the 1-shot and 5-shot settings\nrespectively. We provide experimental results highlighting the merits of our\nalgorithm on four widely used few-shot benchmark datasets, namely miniImageNet,\ntieredImageNet, CUB and CIFAR-FS and two commonly used backbones, ResNet12 and\nWideResNet-28-10. The source code can be found at\nhttps://github.com/MichalisLazarou/A2LP.",
            "author": [
                "Michalis Lazarou",
                "Yannis Avrithis",
                "Guangyu Ren",
                "Tania Stathaki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19996v1",
                "http://arxiv.org/pdf/2310.19996v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01605v1",
            "title": "Faithful and Robust Local Interpretability for Textual Predictions",
            "updated": "2023-10-30T20:27:36Z",
            "published": "2023-10-30T20:27:36Z",
            "summary": "Interpretability is essential for machine learning models to be trusted and\ndeployed in critical domains. However, existing methods for interpreting text\nmodels are often complex, lack solid mathematical foundations, and their\nperformance is not guaranteed. In this paper, we propose FRED (Faithful and\nRobust Explainer for textual Documents), a novel method for interpreting\npredictions over text. FRED identifies key words in a document that\nsignificantly impact the prediction when removed. We establish the reliability\nof FRED through formal definitions and theoretical analyses on interpretable\nclassifiers. Additionally, our empirical evaluation against state-of-the-art\nmethods demonstrates the effectiveness of FRED in providing insights into text\nmodels.",
            "author": [
                "Gianluigi Lopardo",
                "Frederic Precioso",
                "Damien Garreau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01605v1",
                "http://arxiv.org/pdf/2311.01605v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19991v1",
            "title": "PolyThrottle: Energy-efficient Neural Network Inference on Edge Devices",
            "updated": "2023-10-30T20:19:41Z",
            "published": "2023-10-30T20:19:41Z",
            "summary": "As neural networks (NN) are deployed across diverse sectors, their energy\ndemand correspondingly grows. While several prior works have focused on\nreducing energy consumption during training, the continuous operation of\nML-powered systems leads to significant energy use during inference. This paper\ninvestigates how the configuration of on-device hardware-elements such as GPU,\nmemory, and CPU frequency, often neglected in prior studies, affects energy\nconsumption for NN inference with regular fine-tuning. We propose PolyThrottle,\na solution that optimizes configurations across individual hardware components\nusing Constrained Bayesian Optimization in an energy-conserving manner. Our\nempirical evaluation uncovers novel facets of the energy-performance\nequilibrium showing that we can save up to 36 percent of energy for popular\nmodels. We also validate that PolyThrottle can quickly converge towards\nnear-optimal settings while satisfying application constraints.",
            "author": [
                "Minghao Yan",
                "Hongyi Wang",
                "Shivaram Venkataraman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19991v1",
                "http://arxiv.org/pdf/2310.19991v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19990v1",
            "title": "Unveiling the Limits of Learned Local Search Heuristics: Are You the\n  Mightiest of the Meek?",
            "updated": "2023-10-30T20:16:42Z",
            "published": "2023-10-30T20:16:42Z",
            "summary": "In recent years, combining neural networks with local search heuristics has\nbecome popular in the field of combinatorial optimization. Despite its\nconsiderable computational demands, this approach has exhibited promising\noutcomes with minimal manual engineering. However, we have identified three\ncritical limitations in the empirical evaluation of these integration attempts.\nFirstly, instances with moderate complexity and weak baselines pose a challenge\nin accurately evaluating the effectiveness of learning-based approaches.\nSecondly, the absence of an ablation study makes it difficult to quantify and\nattribute improvements accurately to the deep learning architecture. Lastly,\nthe generalization of learned heuristics across diverse distributions remains\nunderexplored. In this study, we conduct a comprehensive investigation into\nthese identified limitations. Surprisingly, we demonstrate that a simple\nlearned heuristic based on Tabu Search surpasses state-of-the-art (SOTA)\nlearned heuristics in terms of performance and generalizability. Our findings\nchallenge prevailing assumptions and open up exciting avenues for future\nresearch and innovation in combinatorial optimization.",
            "author": [
                "Ankur Nath",
                "Alan Kuhnle"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19990v1",
                "http://arxiv.org/pdf/2310.19990v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19986v1",
            "title": "Addressing Weak Decision Boundaries in Image Classification by\n  Leveraging Web Search and Generative Models",
            "updated": "2023-10-30T20:04:50Z",
            "published": "2023-10-30T20:04:50Z",
            "summary": "Machine learning (ML) technologies are known to be riddled with ethical and\noperational problems, however, we are witnessing an increasing thrust by\nbusinesses to deploy them in sensitive applications. One major issue among many\nis that ML models do not perform equally well for underrepresented groups. This\nputs vulnerable populations in an even disadvantaged and unfavorable position.\nWe propose an approach that leverages the power of web search and generative\nmodels to alleviate some of the shortcomings of discriminative models. We\ndemonstrate our method on an image classification problem using ImageNet's\nPeople Subtree subset, and show that it is effective in enhancing robustness\nand mitigating bias in certain classes that represent vulnerable populations\n(e.g., female doctor of color). Our new method is able to (1) identify weak\ndecision boundaries for such classes; (2) construct search queries for Google\nas well as text for generating images through DALL-E 2 and Stable Diffusion;\nand (3) show how these newly captured training samples could alleviate\npopulation bias issue. While still improving the model's overall performance\nconsiderably, we achieve a significant reduction (77.30\\%) in the model's\ngender accuracy disparity. In addition to these improvements, we observed a\nnotable enhancement in the classifier's decision boundary, as it is\ncharacterized by fewer weakspots and an increased separation between classes.\nAlthough we showcase our method on vulnerable populations in this study, the\nproposed technique is extendable to a wide range of problems and domains.",
            "author": [
                "Preetam Prabhu Srikar Dammu",
                "Yunhe Feng",
                "Chirag Shah"
            ],
            "link": [
                "http://dx.doi.org/10.24963/ijcai.2023/659",
                "http://arxiv.org/abs/2310.19986v1",
                "http://arxiv.org/pdf/2310.19986v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14675v2",
            "title": "Fast and Expressive Gesture Recognition using a Combination-Homomorphic\n  Electromyogram Encoder",
            "updated": "2023-11-29T16:19:16Z",
            "published": "2023-10-30T20:03:34Z",
            "summary": "We study the task of gesture recognition from electromyography (EMG), with\nthe goal of enabling expressive human-computer interaction at high accuracy,\nwhile minimizing the time required for new subjects to provide calibration\ndata. To fulfill these goals, we define combination gestures consisting of a\ndirection component and a modifier component. New subjects only demonstrate the\nsingle component gestures and we seek to extrapolate from these to all possible\nsingle or combination gestures. We extrapolate to unseen combination gestures\nby combining the feature vectors of real single gestures to produce synthetic\ntraining data. This strategy allows us to provide a large and flexible gesture\nvocabulary, while not requiring new subjects to demonstrate combinatorially\nmany example gestures. We pre-train an encoder and a combination operator using\nself-supervision, so that we can produce useful synthetic training data for\nunseen test subjects. To evaluate the proposed method, we collect a real-world\nEMG dataset, and measure the effect of augmented supervision against two\nbaselines: a partially-supervised model trained with only single gesture data\nfrom the unseen subject, and a fully-supervised model trained with real single\nand real combination gesture data from the unseen subject. We find that the\nproposed method provides a dramatic improvement over the partially-supervised\nmodel, and achieves a useful classification accuracy that in some cases\napproaches the performance of the fully-supervised model.",
            "author": [
                "Niklas Smedemark-Margulies",
                "Yunus Bicer",
                "Elifnur Sunger",
                "Tales Imbiriba",
                "Eugene Tunik",
                "Deniz Erdogmus",
                "Mathew Yarossi",
                "Robin Walters"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14675v2",
                "http://arxiv.org/pdf/2311.14675v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19985v1",
            "title": "Modeling random directions of changes in simplex-valued data",
            "updated": "2023-10-30T20:01:38Z",
            "published": "2023-10-30T20:01:38Z",
            "summary": "We propose models and algorithms for learning about random directions in\nsimplex-valued data. The models are applied to the study of income level\nproportions and their changes over time in a geostatistical area. There are\nseveral notable challenges in the analysis of simplex-valued data: the\nmeasurements must respect the simplex constraint and the changes exhibit\nspatiotemporal smoothness and may be heterogeneous. To that end, we propose\nBayesian models that draw from and expand upon building blocks in circular and\nspatial statistics by exploiting a suitable transformation for the\nsimplex-valued data. Our models also account for spatial correlation across\nlocations in the simplex and the heterogeneous patterns via mixture modeling.\nWe describe some properties of the models and model fitting via MCMC\ntechniques. Our models and methods are applied to an analysis of movements and\ntrends of income categories using the Home Mortgage Disclosure Act data.",
            "author": [
                "Rayleigh Lei",
                "XuanLong Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19985v1",
                "http://arxiv.org/pdf/2310.19985v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10745v1",
            "title": "\"Just a little bit on the outside for the whole time\": Social belonging\n  confidence and the persistence of Machine Learning and Artificial\n  Intelligence students",
            "updated": "2023-10-30T19:59:38Z",
            "published": "2023-10-30T19:59:38Z",
            "summary": "The growing field of machine learning (ML) and artificial intelligence (AI)\npresents a unique and unexplored case within persistence research, meaning it\nis unclear how past findings from engineering will apply to this developing\nfield. We conduct an exploratory study to gain an initial understanding of\npersistence in this field and identify fruitful directions for future work. One\nfactor that has been shown to predict persistence in engineering is belonging;\nwe study belonging through the lens of confidence, and discuss how attention to\nsocial belonging confidence may help to increase diversity in the profession.\nIn this research paper, we conduct a small set of interviews with students in\nML/AI courses. Thematic analysis of these interviews revealed initial\ndifferences in how students see a career in ML/AI, which diverge based on\ninterest and programming confidence. We identified how exposure and initiation,\nthe interpretation of ML and AI field boundaries, and beliefs of the skills\nrequired to succeed might influence students' intentions to persist. We discuss\ndifferences in how students describe being motivated by social belonging and\nthe importance of close mentorship. We motivate further persistence research in\nML/AI with particular focus on social belonging and close mentorship, the role\nof intersectional identity, and introductory ML/AI courses.",
            "author": [
                "Katherine Mao",
                "Sharon Ferguson",
                "James Magarian",
                "Alison Olechowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10745v1",
                "http://arxiv.org/pdf/2311.10745v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.OH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10744v1",
            "title": "Advancing a Model of Students' Intentional Persistence in Machine\n  Learning and Artificial Intelligence",
            "updated": "2023-10-30T19:57:40Z",
            "published": "2023-10-30T19:57:40Z",
            "summary": "Machine Learning (ML) and Artificial Intelligence (AI) are powering the\napplications we use, the decisions we make, and the decisions made about us. We\nhave seen numerous examples of non-equitable outcomes, from facial recognition\nalgorithms to recidivism algorithms, when they are designed without diversity\nin mind. Thus, we must take action to promote diversity among those in this\nfield. A critical step in this work is understanding why some students who\nchoose to study ML/AI later leave the field. While the persistence of diverse\npopulations has been studied in engineering, there is a lack of research\ninvestigating factors that influence persistence in ML/AI. In this work, we\npresent the advancement of a model of intentional persistence in ML/AI by\nsurveying students in ML/AI courses. We examine persistence across demographic\ngroups, such as gender, international student status, student loan status, and\nvisible minority status. We investigate independent variables that distinguish\nML/AI from other STEM fields, such as the varying emphasis on non-technical\nskills, the ambiguous ethical implications of the work, and the highly\ncompetitive and lucrative nature of the field. Our findings suggest that\nshort-term intentional persistence is associated with academic enrollment\nfactors such as major and level of study. Long-term intentional persistence is\ncorrelated with measures of professional role confidence. Unique to our study,\nwe show that wanting your work to have a positive social benefit is a negative\npredictor of long-term intentional persistence, and women generally care more\nabout this. We provide recommendations to educators to meaningfully discuss\nML/AI ethics in classes and encourage the development of interpersonal skills\nto help increase diversity in the field.",
            "author": [
                "Sharon Ferguson",
                "Katherine Mao",
                "James Magarian",
                "Alison Olechowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10744v1",
                "http://arxiv.org/pdf/2311.10744v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19978v1",
            "title": "Scaling Up Differentially Private LASSO Regularized Logistic Regression\n  via Faster Frank-Wolfe Iterations",
            "updated": "2023-10-30T19:52:43Z",
            "published": "2023-10-30T19:52:43Z",
            "summary": "To the best of our knowledge, there are no methods today for training\ndifferentially private regression models on sparse input data. To remedy this,\nwe adapt the Frank-Wolfe algorithm for $L_1$ penalized linear regression to be\naware of sparse inputs and to use them effectively. In doing so, we reduce the\ntraining time of the algorithm from $\\mathcal{O}( T D S + T N S)$ to\n$\\mathcal{O}(N S + T \\sqrt{D} \\log{D} + T S^2)$, where $T$ is the number of\niterations and a sparsity rate $S$ of a dataset with $N$ rows and $D$ features.\nOur results demonstrate that this procedure can reduce runtime by a factor of\nup to $2,200\\times$, depending on the value of the privacy parameter $\\epsilon$\nand the sparsity of the dataset.",
            "author": [
                "Edward Raff",
                "Amol Khanna",
                "Fred Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19978v1",
                "http://arxiv.org/pdf/2310.19978v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19975v2",
            "title": "BioInstruct: Instruction Tuning of Large Language Models for Biomedical\n  Natural Language Processing",
            "updated": "2023-11-06T15:05:34Z",
            "published": "2023-10-30T19:38:50Z",
            "summary": "To enhance the performance of large language models (LLMs) in biomedical\nnatural language processing (BioNLP) by introducing a domain-specific\ninstruction dataset and examining its impact when combined with multi-task\nlearning principles. We created the BioInstruct, comprising 25,005 instructions\nto instruction-tune LLMs(LLaMA 1 & 2, 7B & 13B version). The instructions were\ncreated by prompting the GPT-4 language model with three-seed samples randomly\ndrawn from an 80 human curated instructions. We employed Low-Rank\nAdaptation(LoRA) for parameter-efficient fine-tuning. We then evaluated these\ninstruction-tuned LLMs on several BioNLP tasks, which can be grouped into three\nmajor categories: question answering(QA), information extraction(IE), and text\ngeneration(GEN). We also examined whether categories(e.g., QA, IE, and\ngeneration) of instructions impact model performance. Comparing with LLMs\nwithout instruction-tuned, our instruction-tuned LLMs demonstrated marked\nperformance gains: 17.3% in QA, 5.7% in IE, and 96% in Generation tasks. Our\n7B-parameter instruction-tuned LLaMA 1 model was competitive or even surpassed\nother LLMs in the biomedical domain that were also fine-tuned from LLaMA 1 with\nvast domain-specific data or a variety of tasks. Our results also show that the\nperformance gain is significantly higher when instruction fine-tuning is\nconducted with closely related tasks. Our findings align with the observations\nof multi-task learning, suggesting the synergies between two tasks. The\nBioInstruct dataset serves as a valuable resource and instruction tuned LLMs\nlead to the best performing BioNLP applications.",
            "author": [
                "Hieu Tran",
                "Zhichao Yang",
                "Zonghai Yao",
                "Hong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19975v2",
                "http://arxiv.org/pdf/2310.19975v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19974v1",
            "title": "Deep Learning-Enabled Text Semantic Communication under Interference: An\n  Empirical Study",
            "updated": "2023-10-30T19:38:47Z",
            "published": "2023-10-30T19:38:47Z",
            "summary": "At the confluence of 6G, deep learning (DL), and natural language processing\n(NLP), DL-enabled text semantic communication (SemCom) has emerged as a 6G\nenabler by promising to minimize bandwidth consumption, transmission delay, and\npower usage. Among text SemCom techniques, \\textit{DeepSC} is a popular scheme\nthat leverages advancements in DL and NLP to reliably transmit semantic\ninformation in low signal-to-noise ratio (SNR) regimes. To understand the\nfundamental limits of such a transmission paradigm, our recently developed\ntheory \\cite{Getu'23_Performance_Limits} predicted the performance limits of\nDeepSC under radio frequency interference (RFI). Although these limits were\ncorroborated by simulations, trained deep networks can defy classical\nstatistical wisdom, and hence extensive computer experiments are needed to\nvalidate our theory. Accordingly, this empirical work follows concerning the\ntraining and testing of DeepSC using the proceedings of the European Parliament\n(Europarl) dataset. Employing training, validation, and testing sets\n\\textit{tokenized and vectorized} from Europarl, we train the DeepSC\narchitecture in Keras 2.9 with TensorFlow 2.9 as a backend and test it under\nGaussian multi-interferer RFI received over Rayleigh fading channels.\nValidating our theory, the testing results corroborate that DeepSC produces\nsemantically irrelevant sentences as the number of Gaussian RFI emitters gets\nvery large. Therefore, a fundamental 6G design paradigm for\n\\textit{interference-resistant and robust SemCom} (IR$^2$ SemCom) is needed.",
            "author": [
                "Tilahun M. Getu",
                "Georges Kaddoum",
                "Mehdi Bennis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19974v1",
                "http://arxiv.org/pdf/2310.19974v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19973v2",
            "title": "Unified Enhancement of Privacy Bounds for Mixture Mechanisms via\n  $f$-Differential Privacy",
            "updated": "2023-11-01T14:43:16Z",
            "published": "2023-10-30T19:37:51Z",
            "summary": "Differentially private (DP) machine learning algorithms incur many sources of\nrandomness, such as random initialization, random batch subsampling, and\nshuffling. However, such randomness is difficult to take into account when\nproving differential privacy bounds because it induces mixture distributions\nfor the algorithm's output that are difficult to analyze. This paper focuses on\nimproving privacy bounds for shuffling models and one-iteration differentially\nprivate gradient descent (DP-GD) with random initializations using $f$-DP. We\nderive a closed-form expression of the trade-off function for shuffling models\nthat outperforms the most up-to-date results based on $(\\epsilon,\\delta)$-DP.\nMoreover, we investigate the effects of random initialization on the privacy of\none-iteration DP-GD. Our numerical computations of the trade-off function\nindicate that random initialization can enhance the privacy of DP-GD. Our\nanalysis of $f$-DP guarantees for these mixture mechanisms relies on an\ninequality for trade-off functions introduced in this paper. This inequality\nimplies the joint convexity of $F$-divergences. Finally, we study an $f$-DP\nanalog of the advanced joint convexity of the hockey-stick divergence related\nto $(\\epsilon,\\delta)$-DP and apply it to analyze the privacy of mixture\nmechanisms.",
            "author": [
                "Chendi Wang",
                "Buxin Su",
                "Jiayuan Ye",
                "Reza Shokri",
                "Weijie J. Su"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19973v2",
                "http://arxiv.org/pdf/2310.19973v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CR",
                "cs.LG",
                "math.ST",
                "stat.ME",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19970v1",
            "title": "Strategies to Harness the Transformers' Potential: UNSL at eRisk 2023",
            "updated": "2023-10-30T19:34:33Z",
            "published": "2023-10-30T19:34:33Z",
            "summary": "The CLEF eRisk Laboratory explores solutions to different tasks related to\nrisk detection on the Internet. In the 2023 edition, Task 1 consisted of\nsearching for symptoms of depression, the objective of which was to extract\nuser writings according to their relevance to the BDI Questionnaire symptoms.\nTask 2 was related to the problem of early detection of pathological gambling\nrisks, where the participants had to detect users at risk as quickly as\npossible. Finally, Task 3 consisted of estimating the severity levels of signs\nof eating disorders. Our research group participated in the first two tasks,\nproposing solutions based on Transformers. For Task 1, we applied different\napproaches that can be interesting in information retrieval tasks. Two\nproposals were based on the similarity of contextualized embedding vectors, and\nthe other one was based on prompting, an attractive current technique of\nmachine learning. For Task 2, we proposed three fine-tuned models followed by\ndecision policy according to criteria defined by an early detection framework.\nOne model presented extended vocabulary with important words to the addressed\ndomain. In the last task, we obtained good performances considering the\ndecision-based metrics, ranking-based metrics, and runtime. In this work, we\nexplore different ways to deploy the predictive potential of Transformers in\neRisk tasks.",
            "author": [
                "Horacio Thompson",
                "Leticia Cagnina",
                "Marcelo Errecalde"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19970v1",
                "http://arxiv.org/pdf/2310.19970v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00862v1",
            "title": "Role of Structural and Conformational Diversity for Machine Learning\n  Potentials",
            "updated": "2023-10-30T19:33:12Z",
            "published": "2023-10-30T19:33:12Z",
            "summary": "In the field of Machine Learning Interatomic Potentials (MLIPs),\nunderstanding the intricate relationship between data biases, specifically\nconformational and structural diversity, and model generalization is critical\nin improving the quality of Quantum Mechanics (QM) data generation efforts. We\ninvestigate these dynamics through two distinct experiments: a fixed budget\none, where the dataset size remains constant, and a fixed molecular set one,\nwhich focuses on fixed structural diversity while varying conformational\ndiversity. Our results reveal nuanced patterns in generalization metrics.\nNotably, for optimal structural and conformational generalization, a careful\nbalance between structural and conformational diversity is required, but\nexisting QM datasets do not meet that trade-off. Additionally, our results\nhighlight the limitation of the MLIP models at generalizing beyond their\ntraining distribution, emphasizing the importance of defining applicability\ndomain during model deployment. These findings provide valuable insights and\nguidelines for QM data generation efforts.",
            "author": [
                "Nikhil Shenoy",
                "Prudencio Tossou",
                "Emmanuel Noutahi",
                "Hadrien Mary",
                "Dominique Beaini",
                "Jiarui Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00862v1",
                "http://arxiv.org/pdf/2311.00862v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19967v2",
            "title": "Early detection of inflammatory arthritis to improve referrals using\n  multimodal machine learning from blood testing, semi-structured and\n  unstructured patient records",
            "updated": "2023-11-03T19:32:02Z",
            "published": "2023-10-30T19:30:00Z",
            "summary": "Early detection of inflammatory arthritis (IA) is critical to efficient and\naccurate hospital referral triage for timely treatment and preventing the\ndeterioration of the IA disease course, especially under limited healthcare\nresources. The manual assessment process is the most common approach in\npractice for the early detection of IA, but it is extremely labor-intensive and\ninefficient. A large amount of clinical information needs to be assessed for\nevery referral from General Practice (GP) to the hospitals. Machine learning\nshows great potential in automating repetitive assessment tasks and providing\ndecision support for the early detection of IA. However, most machine\nlearning-based methods for IA detection rely on blood testing results. But in\npractice, blood testing data is not always available at the point of referrals,\nso we need methods to leverage multimodal data such as semi-structured and\nunstructured data for early detection of IA. In this research, we present\nfusion and ensemble learning-based methods using multimodal data to assist\ndecision-making in the early detection of IA, and a conformal prediction-based\nmethod to quantify the uncertainty of the prediction and detect any unreliable\npredictions. To the best of our knowledge, our study is the first attempt to\nutilize multimodal data to support the early detection of IA from GP referrals.",
            "author": [
                "Bing Wang",
                "Weizi Li",
                "Anthony Bradlow",
                "Antoni T. Y. Chan",
                "Eghosa Bazuaye"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19967v2",
                "http://arxiv.org/pdf/2310.19967v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01468v1",
            "title": "Remember what you did so you know what to do next",
            "updated": "2023-10-30T19:29:00Z",
            "published": "2023-10-30T19:29:00Z",
            "summary": "We explore using a moderately sized large language model (GPT-J 6B\nparameters) to create a plan for a simulated robot to achieve 30 classes of\ngoals in ScienceWorld, a text game simulator for elementary science\nexperiments. Previously published empirical work claimed that large language\nmodels (LLMs) are a poor fit (Wang et al., 2022) compared to reinforcement\nlearning. Using the Markov assumption (a single previous step), the LLM\noutperforms the reinforcement learning-based approach by a factor of 1.4. When\nwe fill the LLM's input buffer with as many prior steps as possible,\nimprovement rises to 3.5x. Even when training on only 6.5% of the training\ndata, we observe a 2.2x improvement over the reinforcement-learning-based\napproach. Our experiments show that performance varies widely across the 30\nclasses of actions, indicating that averaging over tasks can hide significant\nperformance issues. In work contemporaneous with ours, Lin et al. (2023)\ndemonstrated a two-part approach (SwiftSage) that uses a small LLM (T5-large)\ncomplemented by OpenAI's massive LLMs to achieve outstanding results in\nScienceWorld. Our 6-B parameter, single-stage GPT-J matches the performance of\nSwiftSage's two-stage architecture when it incorporates GPT-3.5 turbo which has\n29-times more parameters than GPT-J.",
            "author": [
                "Manuel R. Ciosici",
                "Alex Hedges",
                "Yash Kankanampati",
                "Justin Martin",
                "Marjorie Freedman",
                "Ralph Weischedel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01468v1",
                "http://arxiv.org/pdf/2311.01468v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19961v1",
            "title": "ExPT: Synthetic Pretraining for Few-Shot Experimental Design",
            "updated": "2023-10-30T19:25:43Z",
            "published": "2023-10-30T19:25:43Z",
            "summary": "Experimental design is a fundamental problem in many science and engineering\nfields. In this problem, sample efficiency is crucial due to the time, money,\nand safety costs of real-world design evaluations. Existing approaches either\nrely on active data collection or access to large, labeled datasets of past\nexperiments, making them impractical in many real-world scenarios. In this\nwork, we address the more challenging yet realistic setting of few-shot\nexperimental design, where only a few labeled data points of input designs and\ntheir corresponding values are available. We approach this problem as a\nconditional generation task, where a model conditions on a few labeled examples\nand the desired output to generate an optimal input design. To this end, we\nintroduce Experiment Pretrained Transformers (ExPT), a foundation model for\nfew-shot experimental design that employs a novel combination of synthetic\npretraining with in-context learning. In ExPT, we only assume knowledge of a\nfinite collection of unlabelled data points from the input domain and pretrain\na transformer neural network to optimize diverse synthetic functions defined\nover this domain. Unsupervised pretraining allows ExPT to adapt to any design\ntask at test time in an in-context fashion by conditioning on a few labeled\ndata points from the target task and generating the candidate optima. We\nevaluate ExPT on few-shot experimental design in challenging domains and\ndemonstrate its superior generality and performance compared to existing\nmethods. The source code is available at https://github.com/tung-nd/ExPT.git.",
            "author": [
                "Tung Nguyen",
                "Sudhanshu Agrawal",
                "Aditya Grover"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19961v1",
                "http://arxiv.org/pdf/2310.19961v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19960v1",
            "title": "Topological Learning for Motion Data via Mixed Coordinates",
            "updated": "2023-10-30T19:20:48Z",
            "published": "2023-10-30T19:20:48Z",
            "summary": "Topology can extract the structural information in a dataset efficiently. In\nthis paper, we attempt to incorporate topological information into a multiple\noutput Gaussian process model for transfer learning purposes. To achieve this\ngoal, we extend the framework of circular coordinates into a novel framework of\nmixed valued coordinates to take linear trends in the time series into\nconsideration.\n  One of the major challenges to learn from multiple time series effectively\nvia a multiple output Gaussian process model is constructing a functional\nkernel. We propose to use topologically induced clustering to construct a\ncluster based kernel in a multiple output Gaussian process model. This kernel\nnot only incorporates the topological structural information, but also allows\nus to put forward a unified framework using topological information in time and\nmotion series.",
            "author": [
                "Hengrui Luo",
                "Jisu Kim",
                "Alice Patania",
                "Mikael Vejdemo-Johansson"
            ],
            "link": [
                "http://dx.doi.org/10.1109/BigData52589.2021.9671525",
                "http://arxiv.org/abs/2310.19960v1",
                "http://arxiv.org/pdf/2310.19960v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.AT",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19958v1",
            "title": "PriPrune: Quantifying and Preserving Privacy in Pruned Federated\n  Learning",
            "updated": "2023-10-30T19:18:09Z",
            "published": "2023-10-30T19:18:09Z",
            "summary": "Federated learning (FL) is a paradigm that allows several client devices and\na server to collaboratively train a global model, by exchanging only model\nupdates, without the devices sharing their local training data. These devices\nare often constrained in terms of communication and computation resources, and\ncan further benefit from model pruning -- a paradigm that is widely used to\nreduce the size and complexity of models. Intuitively, by making local models\ncoarser, pruning is expected to also provide some protection against privacy\nattacks in the context of FL. However this protection has not been previously\ncharacterized, formally or experimentally, and it is unclear if it is\nsufficient against state-of-the-art attacks.\n  In this paper, we perform the first investigation of privacy guarantees for\nmodel pruning in FL. We derive information-theoretic upper bounds on the amount\nof information leaked by pruned FL models. We complement and validate these\ntheoretical findings, with comprehensive experiments that involve\nstate-of-the-art privacy attacks, on several state-of-the-art FL pruning\nschemes, using benchmark datasets. This evaluation provides valuable insights\ninto the choices and parameters that can affect the privacy protection provided\nby pruning. Based on these insights, we introduce PriPrune -- a privacy-aware\nalgorithm for local model pruning, which uses a personalized per-client defense\nmask and adapts the defense pruning rate so as to jointly optimize privacy and\nmodel performance. PriPrune is universal in that can be applied after any\npruned FL scheme on the client, without modification, and protects against any\ninversion attack by the server. Our empirical evaluation demonstrates that\nPriPrune significantly improves the privacy-accuracy tradeoff compared to\nstate-of-the-art pruned FL schemes that do not take privacy into account.",
            "author": [
                "Tianyue Chu",
                "Mengwei Yang",
                "Nikolaos Laoutaris",
                "Athina Markopoulou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19958v1",
                "http://arxiv.org/pdf/2310.19958v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19957v1",
            "title": "Deep Learning for Spatiotemporal Big Data: A Vision on Opportunities and\n  Challenges",
            "updated": "2023-10-30T19:12:51Z",
            "published": "2023-10-30T19:12:51Z",
            "summary": "With advancements in GPS, remote sensing, and computational simulation, an\nenormous volume of spatiotemporal data is being collected at an increasing\nspeed from various application domains, spanning Earth sciences, agriculture,\nsmart cities, and public safety. Such emerging geospatial and spatiotemporal\nbig data, coupled with recent advances in deep learning technologies, foster\nnew opportunities to solve problems that have not been possible before. For\ninstance, remote sensing researchers can potentially train a foundation model\nusing Earth imagery big data for numerous land cover and land use modeling\ntasks. Coastal modelers can train AI surrogates to speed up numerical\nsimulations. However, the distinctive characteristics of spatiotemporal big\ndata pose new challenges for deep learning technologies. This vision paper\nintroduces various types of spatiotemporal big data, discusses new research\nopportunities in the realm of deep learning applied to spatiotemporal big data,\nlists the unique challenges, and identifies several future research needs.",
            "author": [
                "Zhe Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19957v1",
                "http://arxiv.org/pdf/2310.19957v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19944v1",
            "title": "Conditional Unscented Autoencoders for Trajectory Prediction",
            "updated": "2023-10-30T18:59:32Z",
            "published": "2023-10-30T18:59:32Z",
            "summary": "The \\ac{CVAE} is one of the most widely-used models in trajectory prediction\nfor \\ac{AD}. It captures the interplay between a driving context and its\nground-truth future into a probabilistic latent space and uses it to produce\npredictions. In this paper, we challenge key components of the CVAE. We\nleverage recent advances in the space of the VAE, the foundation of the CVAE,\nwhich show that a simple change in the sampling procedure can greatly benefit\nperformance. We find that unscented sampling, which draws samples from any\nlearned distribution in a deterministic manner, can naturally be better suited\nto trajectory prediction than potentially dangerous random sampling. We go\nfurther and offer additional improvements, including a more structured mixture\nlatent space, as well as a novel, potentially more expressive way to do\ninference with CVAEs. We show wide applicability of our models by evaluating\nthem on the INTERACTION prediction dataset, outperforming the state of the art,\nas well as at the task of image modeling on the CelebA dataset, outperforming\nthe baseline vanilla CVAE. Code is available at\nhttps://github.com/boschresearch/cuae-prediction.",
            "author": [
                "Faris Janjo\u0161",
                "Marcel Hallgarten",
                "Anthony Knittel",
                "Maxim Dolgov",
                "Andreas Zell",
                "J. Marius Z\u00f6llner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19944v1",
                "http://arxiv.org/pdf/2310.19944v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19943v1",
            "title": "The Acquisition of Physical Knowledge in Generative Neural Networks",
            "updated": "2023-10-30T18:58:03Z",
            "published": "2023-10-30T18:58:03Z",
            "summary": "As children grow older, they develop an intuitive understanding of the\nphysical processes around them. Their physical understanding develops in\nstages, moving along developmental trajectories which have been mapped out\nextensively in previous empirical research. Here, we investigate how the\nlearning trajectories of deep generative neural networks compare to children's\ndevelopmental trajectories using physical understanding as a testbed. We\noutline an approach that allows us to examine two distinct hypotheses of human\ndevelopment - stochastic optimization and complexity increase. We find that\nwhile our models are able to accurately predict a number of physical processes,\ntheir learning trajectories under both hypotheses do not follow the\ndevelopmental trajectories of children.",
            "author": [
                "Luca M. Schulze Buschoff",
                "Eric Schulz",
                "Marcel Binz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19943v1",
                "http://arxiv.org/pdf/2310.19943v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19942v1",
            "title": "Split-NER: Named Entity Recognition via Two Question-Answering-based\n  Classifications",
            "updated": "2023-10-30T18:57:28Z",
            "published": "2023-10-30T18:57:28Z",
            "summary": "In this work, we address the NER problem by splitting it into two logical\nsub-tasks: (1) Span Detection which simply extracts entity mention spans\nirrespective of entity type; (2) Span Classification which classifies the spans\ninto their entity types. Further, we formulate both sub-tasks as\nquestion-answering (QA) problems and produce two leaner models which can be\noptimized separately for each sub-task. Experiments with four cross-domain\ndatasets demonstrate that this two-step approach is both effective and time\nefficient. Our system, SplitNER outperforms baselines on OntoNotes5.0, WNUT17\nand a cybersecurity dataset and gives on-par performance on BioNLP13CG. In all\ncases, it achieves a significant reduction in training time compared to its QA\nbaseline counterpart. The effectiveness of our system stems from fine-tuning\nthe BERT model twice, separately for span detection and classification. The\nsource code can be found at https://github.com/c3sr/split-ner.",
            "author": [
                "Jatin Arora",
                "Youngja Park"
            ],
            "link": [
                "http://dx.doi.org/10.18653/v1/2023.acl-short.36",
                "http://arxiv.org/abs/2310.19942v1",
                "http://arxiv.org/pdf/2310.19942v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.LG",
                "I.2.7; H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19938v1",
            "title": "Lyapunov-Based Dropout Deep Neural Network (Lb-DDNN) Controller",
            "updated": "2023-10-30T18:54:08Z",
            "published": "2023-10-30T18:54:08Z",
            "summary": "Deep neural network (DNN)-based adaptive controllers can be used to\ncompensate for unstructured uncertainties in nonlinear dynamic systems.\nHowever, DNNs are also very susceptible to overfitting and co-adaptation.\nDropout regularization is an approach where nodes are randomly dropped during\ntraining to alleviate issues such as overfitting and co-adaptation. In this\npaper, a dropout DNN-based adaptive controller is developed. The developed\ndropout technique allows the deactivation of weights that are stochastically\nselected for each individual layer within the DNN. Simultaneously, a\nLyapunov-based real-time weight adaptation law is introduced to update the\nweights of all layers of the DNN for online unsupervised learning. A non-smooth\nLyapunov-based stability analysis is performed to ensure asymptotic convergence\nof the tracking error. Simulation results of the developed dropout DNN-based\nadaptive controller indicate a 38.32% improvement in the tracking error, a\n53.67% improvement in the function approximation error, and 50.44% lower\ncontrol effort when compared to a baseline adaptive DNN-based controller\nwithout dropout regularization.",
            "author": [
                "Saiedeh Akbari",
                "Emily J. Griffis",
                "Omkar Sudhir Patil",
                "Warren E. Dixon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19938v1",
                "http://arxiv.org/pdf/2310.19938v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19936v1",
            "title": "Towards Few-Annotation Learning for Object Detection: Are\n  Transformer-based Models More Efficient ?",
            "updated": "2023-10-30T18:51:25Z",
            "published": "2023-10-30T18:51:25Z",
            "summary": "For specialized and dense downstream tasks such as object detection, labeling\ndata requires expertise and can be very expensive, making few-shot and\nsemi-supervised models much more attractive alternatives. While in the few-shot\nsetup we observe that transformer-based object detectors perform better than\nconvolution-based two-stage models for a similar amount of parameters, they are\nnot as effective when used with recent approaches in the semi-supervised\nsetting. In this paper, we propose a semi-supervised method tailored for the\ncurrent state-of-the-art object detector Deformable DETR in the few-annotation\nlearning setup using a student-teacher architecture, which avoids relying on a\nsensitive post-processing of the pseudo-labels generated by the teacher model.\nWe evaluate our method on the semi-supervised object detection benchmarks COCO\nand Pascal VOC, and it outperforms previous methods, especially when\nannotations are scarce. We believe that our contributions open new\npossibilities to adapt similar object detection methods in this setup as well.",
            "author": [
                "Quentin Bouniot",
                "Ang\u00e9lique Loesch",
                "Romaric Audigier",
                "Amaury Habrard"
            ],
            "link": [
                "http://dx.doi.org/10.1109/WACV56688.2023.00016",
                "http://arxiv.org/abs/2310.19936v1",
                "http://arxiv.org/pdf/2310.19936v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19932v1",
            "title": "Sim2Real for Environmental Neural Processes",
            "updated": "2023-10-30T18:49:06Z",
            "published": "2023-10-30T18:49:06Z",
            "summary": "Machine learning (ML)-based weather models have recently undergone rapid\nimprovements. These models are typically trained on gridded reanalysis data\nfrom numerical data assimilation systems. However, reanalysis data comes with\nlimitations, such as assumptions about physical laws and low spatiotemporal\nresolution. The gap between reanalysis and reality has sparked growing interest\nin training ML models directly on observations such as weather stations.\nModelling scattered and sparse environmental observations requires scalable and\nflexible ML architectures, one of which is the convolutional conditional neural\nprocess (ConvCNP). ConvCNPs can learn to condition on both gridded and\noff-the-grid context data to make uncertainty-aware predictions at target\nlocations. However, the sparsity of real observations presents a challenge for\ndata-hungry deep learning models like the ConvCNP. One potential solution is\n'Sim2Real': pre-training on reanalysis and fine-tuning on observational data.\nWe analyse Sim2Real with a ConvCNP trained to interpolate surface air\ntemperature over Germany, using varying numbers of weather stations for\nfine-tuning. On held-out weather stations, Sim2Real training substantially\noutperforms the same model architecture trained only with reanalysis data or\nonly with station data, showing that reanalysis data can serve as a stepping\nstone for learning from real observations. Sim2Real could thus enable more\naccurate models for weather prediction and climate monitoring.",
            "author": [
                "Jonas Scholz",
                "Tom R. Andersson",
                "Anna Vaughan",
                "James Requeima",
                "Richard E. Turner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19932v1",
                "http://arxiv.org/pdf/2310.19932v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19927v1",
            "title": "Model-Based Reparameterization Policy Gradient Methods: Theory and\n  Practical Algorithms",
            "updated": "2023-10-30T18:43:21Z",
            "published": "2023-10-30T18:43:21Z",
            "summary": "ReParameterization (RP) Policy Gradient Methods (PGMs) have been widely\nadopted for continuous control tasks in robotics and computer graphics.\nHowever, recent studies have revealed that, when applied to long-term\nreinforcement learning problems, model-based RP PGMs may experience chaotic and\nnon-smooth optimization landscapes with exploding gradient variance, which\nleads to slow convergence. This is in contrast to the conventional belief that\nreparameterization methods have low gradient estimation variance in problems\nsuch as training deep generative models. To comprehend this phenomenon, we\nconduct a theoretical examination of model-based RP PGMs and search for\nsolutions to the optimization difficulties. Specifically, we analyze the\nconvergence of the model-based RP PGMs and pinpoint the smoothness of function\napproximators as a major factor that affects the quality of gradient\nestimation. Based on our analysis, we propose a spectral normalization method\nto mitigate the exploding variance issue caused by long model unrolls. Our\nexperimental results demonstrate that proper normalization significantly\nreduces the gradient variance of model-based RP PGMs. As a result, the\nperformance of the proposed method is comparable or superior to other gradient\nestimators, such as the Likelihood Ratio (LR) gradient estimator. Our code is\navailable at https://github.com/agentification/RP_PGM.",
            "author": [
                "Shenao Zhang",
                "Boyi Liu",
                "Zhaoran Wang",
                "Tuo Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19927v1",
                "http://arxiv.org/pdf/2310.19927v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19923v1",
            "title": "Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long\n  Documents",
            "updated": "2023-10-30T18:35:30Z",
            "published": "2023-10-30T18:35:30Z",
            "summary": "Text embedding models have emerged as powerful tools for transforming\nsentences into fixed-sized feature vectors that encapsulate semantic\ninformation. While these models are essential for tasks like information\nretrieval, semantic clustering, and text re-ranking, most existing open-source\nmodels, especially those built on architectures like BERT, struggle to\nrepresent lengthy documents and often resort to truncation. One common approach\nto mitigate this challenge involves splitting documents into smaller paragraphs\nfor embedding. However, this strategy results in a much larger set of vectors,\nconsequently leading to increased memory consumption and computationally\nintensive vector searches with elevated latency.\n  To address these challenges, we introduce Jina Embeddings 2, an open-source\ntext embedding model capable of accommodating up to 8192 tokens. This model is\ndesigned to transcend the conventional 512-token limit and adeptly process long\ndocuments. Jina Embeddings 2 not only achieves state-of-the-art performance on\na range of embedding-related tasks in the MTEB benchmark but also matches the\nperformance of OpenAI's proprietary ada-002 model. Additionally, our\nexperiments indicate that an extended context can enhance performance in tasks\nsuch as NarrativeQA.",
            "author": [
                "Michael G\u00fcnther",
                "Jackmin Ong",
                "Isabelle Mohr",
                "Alaeddine Abdessalem",
                "Tanguy Abel",
                "Mohammad Kalim Akram",
                "Susana Guzman",
                "Georgios Mastrapas",
                "Saba Sturua",
                "Bo Wang",
                "Maximilian Werk",
                "Nan Wang",
                "Han Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19923v1",
                "http://arxiv.org/pdf/2310.19923v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "68T50",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19920v1",
            "title": "Solving a Class of Cut-Generating Linear Programs via Machine Learning",
            "updated": "2023-10-30T18:31:52Z",
            "published": "2023-10-30T18:31:52Z",
            "summary": "Cut-generating linear programs (CGLPs) play a key role as a separation oracle\nto produce valid inequalities for the feasible region of mixed-integer\nprograms. When incorporated inside branch-and-bound, the cutting planes\nobtained from CGLPs help to tighten relaxations and improve dual bounds.\nHowever, running the CGLPs at the nodes of the branch-and-bound tree is\ncomputationally cumbersome due to the large number of node candidates and the\nlack of a priori knowledge on which nodes admit useful cutting planes. As a\nresult, CGLPs are often avoided at default settings of branch-and-cut\nalgorithms despite their potential impact on improving dual bounds. In this\npaper, we propose a novel framework based on machine learning to approximate\nthe optimal value of a CGLP class that determines whether a cutting plane can\nbe generated at a node of the branch-and-bound tree. Translating the CGLP as an\nindicator function of the objective function vector, we show that it can be\napproximated through conventional data classification techniques. We provide a\nsystematic procedure to efficiently generate training data sets for the\ncorresponding classification problem based on the CGLP structure. We conduct\ncomputational experiments on benchmark instances using classification methods\nsuch as logistic regression. These results suggest that the approximate CGLP\nobtained from classification can improve the solution time compared to that of\nconventional cutting plane methods. Our proposed framework can be efficiently\napplied to a large number of nodes in the branch-and-bound tree to identify the\nbest candidates for adding a cut.",
            "author": [
                "Atefeh Rajabalizadeh",
                "Danial Davarnia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19920v1",
                "http://arxiv.org/pdf/2310.19920v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19919v1",
            "title": "Meta-Learning Strategies through Value Maximization in Neural Networks",
            "updated": "2023-10-30T18:29:26Z",
            "published": "2023-10-30T18:29:26Z",
            "summary": "Biological and artificial learning agents face numerous choices about how to\nlearn, ranging from hyperparameter selection to aspects of task distributions\nlike curricula. Understanding how to make these meta-learning choices could\noffer normative accounts of cognitive control functions in biological learners\nand improve engineered systems. Yet optimal strategies remain challenging to\ncompute in modern deep networks due to the complexity of optimizing through the\nentire learning process. Here we theoretically investigate optimal strategies\nin a tractable setting. We present a learning effort framework capable of\nefficiently optimizing control signals on a fully normative objective:\ndiscounted cumulative performance throughout learning. We obtain computational\ntractability by using average dynamical equations for gradient descent,\navailable for simple neural network architectures. Our framework accommodates a\nrange of meta-learning and automatic curriculum learning methods in a unified\nnormative setting. We apply this framework to investigate the effect of\napproximations in common meta-learning algorithms; infer aspects of optimal\ncurricula; and compute optimal neuronal resource allocation in a continual\nlearning setting. Across settings, we find that control effort is most\nbeneficial when applied to easier aspects of a task early in learning; followed\nby sustained effort on harder aspects. Overall, the learning effort framework\nprovides a tractable theoretical test bed to study normative benefits of\ninterventions in a variety of learning systems, as well as a formal account of\noptimal cognitive control strategies over learning trajectories posited by\nestablished theories in cognitive neuroscience.",
            "author": [
                "Rodrigo Carrasco-Davis",
                "Javier Mas\u00eds",
                "Andrew M. Saxe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19919v1",
                "http://arxiv.org/pdf/2310.19919v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19917v1",
            "title": "Unmasking Bias and Inequities: A Systematic Review of Bias Detection and\n  Mitigation in Healthcare Artificial Intelligence Using Electronic Health\n  Records",
            "updated": "2023-10-30T18:29:15Z",
            "published": "2023-10-30T18:29:15Z",
            "summary": "Objectives: Artificial intelligence (AI) applications utilizing electronic\nhealth records (EHRs) have gained popularity, but they also introduce various\ntypes of bias. This study aims to systematically review the literature that\naddress bias in AI research utilizing EHR data. Methods: A systematic review\nwas conducted following the Preferred Reporting Items for Systematic Reviews\nand Meta-analyses (PRISMA) guideline. We retrieved articles published between\nJanuary 1, 2010, and October 31, 2022, from PubMed, Web of Science, and the\nInstitute of Electrical and Electronics Engineers. We defined six major types\nof bias and summarized the existing approaches in bias handling. Results: Out\nof the 252 retrieved articles, 20 met the inclusion criteria for the final\nreview. Five out of six bias were covered in this review: eight studies\nanalyzed selection bias; six on implicit bias; five on confounding bias; four\non measurement bias; two on algorithmic bias. For bias handling approaches, ten\nstudies identified bias during model development, while seventeen presented\nmethods to mitigate the bias. Discussion: Bias may infiltrate the AI\napplication development process at various stages. Although this review\ndiscusses methods for addressing bias at different development stages, there is\nroom for implementing additional effective approaches. Conclusion: Despite\ngrowing attention to bias in healthcare AI, research using EHR data on this\ntopic is still limited. Detecting and mitigating AI bias with EHR data\ncontinues to pose challenges. Further research is needed to raise a\nstandardized method that is generalizable and interpretable to detect, mitigate\nand evaluate bias in medical AI.",
            "author": [
                "Feng Chen",
                "Liqin Wang",
                "Julie Hong",
                "Jiaqi Jiang",
                "Li Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19917v1",
                "http://arxiv.org/pdf/2310.19917v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19915v1",
            "title": "GPCR-BERT: Interpreting Sequential Design of G Protein Coupled Receptors\n  Using Protein Language Models",
            "updated": "2023-10-30T18:28:50Z",
            "published": "2023-10-30T18:28:50Z",
            "summary": "With the rise of Transformers and Large Language Models (LLMs) in Chemistry\nand Biology, new avenues for the design and understanding of therapeutics have\nopened up to the scientific community. Protein sequences can be modeled as\nlanguage and can take advantage of recent advances in LLMs, specifically with\nthe abundance of our access to the protein sequence datasets. In this paper, we\ndeveloped the GPCR-BERT model for understanding the sequential design of G\nProtein-Coupled Receptors (GPCRs). GPCRs are the target of over one-third of\nFDA-approved pharmaceuticals. However, there is a lack of comprehensive\nunderstanding regarding the relationship between amino acid sequence, ligand\nselectivity, and conformational motifs (such as NPxxY, CWxP, E/DRY). By\nutilizing the pre-trained protein model (Prot-Bert) and fine-tuning with\nprediction tasks of variations in the motifs, we were able to shed light on\nseveral relationships between residues in the binding pocket and some of the\nconserved motifs. To achieve this, we took advantage of attention weights, and\nhidden states of the model that are interpreted to extract the extent of\ncontributions of amino acids in dictating the type of masked ones. The\nfine-tuned models demonstrated high accuracy in predicting hidden residues\nwithin the motifs. In addition, the analysis of embedding was performed over 3D\nstructures to elucidate the higher-order interactions within the conformations\nof the receptors.",
            "author": [
                "Seongwon Kim",
                "Parisa Mollaei",
                "Akshay Antony",
                "Rishikesh Magar",
                "Amir Barati Farimani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19915v1",
                "http://arxiv.org/pdf/2310.19915v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19910v1",
            "title": "Bayesian Simulation-based Inference for Cosmological Initial Conditions",
            "updated": "2023-10-30T18:24:25Z",
            "published": "2023-10-30T18:24:25Z",
            "summary": "Reconstructing astrophysical and cosmological fields from observations is\nchallenging. It requires accounting for non-linear transformations, mixing of\nspatial structure, and noise. In contrast, forward simulators that map fields\nto observations are readily available for many applications. We present a\nversatile Bayesian field reconstruction algorithm rooted in simulation-based\ninference and enhanced by autoregressive modeling. The proposed technique is\napplicable to generic (non-differentiable) forward simulators and allows\nsampling from the posterior for the underlying field. We show first promising\nresults on a proof-of-concept application: the recovery of cosmological initial\nconditions from late-time density fields.",
            "author": [
                "Florian List",
                "Noemi Anau Montel",
                "Christoph Weniger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19910v1",
                "http://arxiv.org/pdf/2310.19910v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19909v2",
            "title": "Battle of the Backbones: A Large-Scale Comparison of Pretrained Models\n  across Computer Vision Tasks",
            "updated": "2023-11-20T03:05:50Z",
            "published": "2023-10-30T18:23:58Z",
            "summary": "Neural network based computer vision systems are typically built on a\nbackbone, a pretrained or randomly initialized feature extractor. Several years\nago, the default option was an ImageNet-trained convolutional neural network.\nHowever, the recent past has seen the emergence of countless backbones\npretrained using various algorithms and datasets. While this abundance of\nchoice has led to performance increases for a range of systems, it is difficult\nfor practitioners to make informed decisions about which backbone to choose.\nBattle of the Backbones (BoB) makes this choice easier by benchmarking a\ndiverse suite of pretrained models, including vision-language models, those\ntrained via self-supervised learning, and the Stable Diffusion backbone, across\na diverse set of computer vision tasks ranging from classification to object\ndetection to OOD generalization and more. Furthermore, BoB sheds light on\npromising directions for the research community to advance computer vision by\nilluminating strengths and weakness of existing approaches through a\ncomprehensive analysis conducted on more than 1500 training runs. While vision\ntransformers (ViTs) and self-supervised learning (SSL) are increasingly\npopular, we find that convolutional neural networks pretrained in a supervised\nfashion on large training sets still perform best on most tasks among the\nmodels we consider. Moreover, in apples-to-apples comparisons on the same\narchitectures and similarly sized pretraining datasets, we find that SSL\nbackbones are highly competitive, indicating that future works should perform\nSSL pretraining with advanced architectures and larger pretraining datasets. We\nrelease the raw results of our experiments along with code that allows\nresearchers to put their own backbones through the gauntlet here:\nhttps://github.com/hsouri/Battle-of-the-Backbones",
            "author": [
                "Micah Goldblum",
                "Hossein Souri",
                "Renkun Ni",
                "Manli Shu",
                "Viraj Prabhu",
                "Gowthami Somepalli",
                "Prithvijit Chattopadhyay",
                "Mark Ibrahim",
                "Adrien Bardes",
                "Judy Hoffman",
                "Rama Chellappa",
                "Andrew Gordon Wilson",
                "Tom Goldstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19909v2",
                "http://arxiv.org/pdf/2310.19909v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19906v1",
            "title": "Interpretable Prototype-based Graph Information Bottleneck",
            "updated": "2023-10-30T18:16:19Z",
            "published": "2023-10-30T18:16:19Z",
            "summary": "The success of Graph Neural Networks (GNNs) has led to a need for\nunderstanding their decision-making process and providing explanations for\ntheir predictions, which has given rise to explainable AI (XAI) that offers\ntransparent explanations for black-box models. Recently, the use of prototypes\nhas successfully improved the explainability of models by learning prototypes\nto imply training graphs that affect the prediction. However, these approaches\ntend to provide prototypes with excessive information from the entire graph,\nleading to the exclusion of key substructures or the inclusion of irrelevant\nsubstructures, which can limit both the interpretability and the performance of\nthe model in downstream tasks. In this work, we propose a novel framework of\nexplainable GNNs, called interpretable Prototype-based Graph Information\nBottleneck (PGIB) that incorporates prototype learning within the information\nbottleneck framework to provide prototypes with the key subgraph from the input\ngraph that is important for the model prediction. This is the first work that\nincorporates prototype learning into the process of identifying the key\nsubgraphs that have a critical impact on the prediction performance. Extensive\nexperiments, including qualitative analysis, demonstrate that PGIB outperforms\nstate-of-the-art methods in terms of both prediction performance and\nexplainability.",
            "author": [
                "Sangwoo Seo",
                "Sungwon Kim",
                "Chanyoung Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19906v1",
                "http://arxiv.org/pdf/2310.19906v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19904v1",
            "title": "ERGO-ML -- Comparing IllustrisTNG and HSC galaxy images via contrastive\n  learning",
            "updated": "2023-10-30T18:11:29Z",
            "published": "2023-10-30T18:11:29Z",
            "summary": "Modern cosmological hydrodynamical galaxy simulations provide tens of\nthousands of reasonably realistic synthetic galaxies across cosmic time.\nHowever, quantitatively assessing the level of realism of simulated universes\nin comparison to the real one is difficult. In this paper of the ERGO-ML series\n(Extracting Reality from Galaxy Observables with Machine Learning), we utilize\ncontrastive learning to directly compare a large sample of simulated and\nobserved galaxies based on their stellar-light images. This eliminates the need\nto specify summary statistics and allows to exploit the whole information\ncontent of the observations. We produce survey-realistic galaxy mock datasets\nresembling real Hyper Suprime-Cam (HSC) observations using the cosmological\nsimulations TNG50 and TNG100. Our focus is on galaxies with stellar masses\nbetween $10^9$ and $10^{12} M_\\odot$ at $z=0.1-0.4$. This allows us to evaluate\nthe realism of the simulated TNG galaxies in comparison to actual HSC\nobservations. We apply the self-supervised contrastive learning method NNCLR to\nthe images from both simulated and observed datasets (g, r, i - bands). This\nresults in a 256-dimensional representation space, encoding all relevant\nobservable galaxy properties. Firstly, this allows us to identify simulated\ngalaxies that closely resemble real ones by seeking similar images in this\nmulti-dimensional space. Even more powerful, we quantify the alignment between\nthe representations of these two image sets, finding that the majority\n($\\gtrsim 70$ per cent) of the TNG galaxies align well with observed HSC\nimages. However, a subset of simulated galaxies with larger sizes, steeper\nSersic profiles, smaller Sersic ellipticities, and larger asymmetries appears\nunrealistic. We also demonstrate the utility of our derived image\nrepresentations by inferring properties of real HSC galaxies using simulated\nTNG galaxies as the ground truth.",
            "author": [
                "Lukas Eisert",
                "Connor Bottrell",
                "Annalisa Pillepich",
                "Rhythm Shimakawa",
                "Vicente Rodriguez-Gomez",
                "Dylan Nelson",
                "Eirini Angeloudi",
                "Marc Huertas-Company"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19904v1",
                "http://arxiv.org/pdf/2310.19904v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19898v1",
            "title": "MIST: Medical Image Segmentation Transformer with Convolutional\n  Attention Mixing (CAM) Decoder",
            "updated": "2023-10-30T18:07:57Z",
            "published": "2023-10-30T18:07:57Z",
            "summary": "One of the common and promising deep learning approaches used for medical\nimage segmentation is transformers, as they can capture long-range dependencies\namong the pixels by utilizing self-attention. Despite being successful in\nmedical image segmentation, transformers face limitations in capturing local\ncontexts of pixels in multimodal dimensions. We propose a Medical Image\nSegmentation Transformer (MIST) incorporating a novel Convolutional Attention\nMixing (CAM) decoder to address this issue. MIST has two parts: a pre-trained\nmulti-axis vision transformer (MaxViT) is used as an encoder, and the encoded\nfeature representation is passed through the CAM decoder for segmenting the\nimages. In the CAM decoder, an attention-mixer combining multi-head\nself-attention, spatial attention, and squeeze and excitation attention modules\nis introduced to capture long-range dependencies in all spatial dimensions.\nMoreover, to enhance spatial information gain, deep and shallow convolutions\nare used for feature extraction and receptive field expansion, respectively.\nThe integration of low-level and high-level features from different network\nstages is enabled by skip connections, allowing MIST to suppress unnecessary\ninformation. The experiments show that our MIST transformer with CAM decoder\noutperforms the state-of-the-art models specifically designed for medical image\nsegmentation on the ACDC and Synapse datasets. Our results also demonstrate\nthat adding the CAM decoder with a hierarchical transformer improves\nsegmentation performance significantly. Our model with data and code is\npublicly available on GitHub.",
            "author": [
                "Md Motiur Rahman",
                "Shiva Shokouhmand",
                "Smriti Bhatt",
                "Miad Faezipour"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19898v1",
                "http://arxiv.org/pdf/2310.19898v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19889v1",
            "title": "Exploring Geometry of Blind Spots in Vision Models",
            "updated": "2023-10-30T18:00:33Z",
            "published": "2023-10-30T18:00:33Z",
            "summary": "Despite the remarkable success of deep neural networks in a myriad of\nsettings, several works have demonstrated their overwhelming sensitivity to\nnear-imperceptible perturbations, known as adversarial attacks. On the other\nhand, prior works have also observed that deep networks can be under-sensitive,\nwherein large-magnitude perturbations in input space do not induce appreciable\nchanges to network activations. In this work, we study in detail the phenomenon\nof under-sensitivity in vision models such as CNNs and Transformers, and\npresent techniques to study the geometry and extent of \"equi-confidence\" level\nsets of such networks. We propose a Level Set Traversal algorithm that\niteratively explores regions of high confidence with respect to the input space\nusing orthogonal components of the local gradients. Given a source image, we\nuse this algorithm to identify inputs that lie in the same equi-confidence\nlevel set as the source image despite being perceptually similar to arbitrary\nimages from other classes. We further observe that the source image is linearly\nconnected by a high-confidence path to these inputs, uncovering a star-like\nstructure for level sets of deep networks. Furthermore, we attempt to identify\nand estimate the extent of these connected higher-dimensional regions over\nwhich the model maintains a high degree of confidence. The code for this\nproject is publicly available at\nhttps://github.com/SriramB-98/blindspots-neurips-sub",
            "author": [
                "Sriram Balasubramanian",
                "Gaurang Sriramanan",
                "Vinu Sankar Sadasivan",
                "Soheil Feizi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19889v1",
                "http://arxiv.org/pdf/2310.19889v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "I.2.6; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19886v1",
            "title": "BTRec: BERT-Based Trajectory Recommendation for Personalized Tours",
            "updated": "2023-10-30T18:00:26Z",
            "published": "2023-10-30T18:00:26Z",
            "summary": "An essential task for tourists having a pleasant holiday is to have a\nwell-planned itinerary with relevant recommendations, especially when visiting\nunfamiliar cities. Many tour recommendation tools only take into account a\nlimited number of factors, such as popular Points of Interest (POIs) and\nrouting constraints. Consequently, the solutions they provide may not always\nalign with the individual users of the system. We propose an iterative\nalgorithm in this paper, namely: BTREC (BERT-based Trajectory Recommendation),\nthat extends from the POIBERT embedding algorithm to recommend personalized\nitineraries on POIs using the BERT framework. Our BTREC algorithm incorporates\nusers' demographic information alongside past POI visits into a modified BERT\nlanguage model to recommend a personalized POI itinerary prediction given a\npair of source and destination POIs. Our recommendation system can create a\ntravel itinerary that maximizes POIs visited, while also taking into account\nuser preferences for categories of POIs and time availability. Our\nrecommendation algorithm is largely inspired by the problem of sentence\ncompletion in natural language processing (NLP). Using a dataset of eight\ncities of different sizes, our experimental results demonstrate that our\nproposed algorithm is stable and outperforms many other sequence prediction\nalgorithms, measured by recall, precision, and F1-scores.",
            "author": [
                "Ngai Lam Ho",
                "Roy Ka-Wei Lee",
                "Kwan Hui Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19886v1",
                "http://arxiv.org/pdf/2310.19886v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19882v1",
            "title": "Learning quantum states and unitaries of bounded gate complexity",
            "updated": "2023-10-30T18:00:03Z",
            "published": "2023-10-30T18:00:03Z",
            "summary": "While quantum state tomography is notoriously hard, most states hold little\ninterest to practically-minded tomographers. Given that states and unitaries\nappearing in Nature are of bounded gate complexity, it is natural to ask if\nefficient learning becomes possible. In this work, we prove that to learn a\nstate generated by a quantum circuit with $G$ two-qubit gates to a small trace\ndistance, a sample complexity scaling linearly in $G$ is necessary and\nsufficient. We also prove that the optimal query complexity to learn a unitary\ngenerated by $G$ gates to a small average-case error scales linearly in $G$.\nWhile sample-efficient learning can be achieved, we show that under reasonable\ncryptographic conjectures, the computational complexity for learning states and\nunitaries of gate complexity $G$ must scale exponentially in $G$. We illustrate\nhow these results establish fundamental limitations on the expressivity of\nquantum machine learning models and provide new perspectives on no-free-lunch\ntheorems in unitary learning. Together, our results answer how the complexity\nof learning quantum states and unitaries relate to the complexity of creating\nthese states and unitaries.",
            "author": [
                "Haimeng Zhao",
                "Laura Lewis",
                "Ishaan Kannan",
                "Yihui Quek",
                "Hsin-Yuan Huang",
                "Matthias C. Caro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19882v1",
                "http://arxiv.org/pdf/2310.19882v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19870v1",
            "title": "Metric Flows with Neural Networks",
            "updated": "2023-10-30T18:00:01Z",
            "published": "2023-10-30T18:00:01Z",
            "summary": "We develop a theory of flows in the space of Riemannian metrics induced by\nneural network gradient descent. This is motivated in part by recent advances\nin approximating Calabi-Yau metrics with neural networks and is enabled by\nrecent advances in understanding flows in the space of neural networks. We\nderive the corresponding metric flow equations, which are governed by a metric\nneural tangent kernel, a complicated, non-local object that evolves in time.\nHowever, many architectures admit an infinite-width limit in which the kernel\nbecomes fixed and the dynamics simplify. Additional assumptions can induce\nlocality in the flow, which allows for the realization of Perelman's\nformulation of Ricci flow that was used to resolve the 3d Poincar\\'e\nconjecture. We apply these ideas to numerical Calabi-Yau metrics, including a\ndiscussion on the importance of feature learning.",
            "author": [
                "James Halverson",
                "Fabian Ruehle"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19870v1",
                "http://arxiv.org/pdf/2310.19870v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cs.LG",
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19797v1",
            "title": "DEFT: Dexterous Fine-Tuning for Real-World Hand Policies",
            "updated": "2023-10-30T17:59:35Z",
            "published": "2023-10-30T17:59:35Z",
            "summary": "Dexterity is often seen as a cornerstone of complex manipulation. Humans are\nable to perform a host of skills with their hands, from making food to\noperating tools. In this paper, we investigate these challenges, especially in\nthe case of soft, deformable objects as well as complex, relatively\nlong-horizon tasks. However, learning such behaviors from scratch can be data\ninefficient. To circumvent this, we propose a novel approach, DEFT (DExterous\nFine-Tuning for Hand Policies), that leverages human-driven priors, which are\nexecuted directly in the real world. In order to improve upon these priors,\nDEFT involves an efficient online optimization procedure. With the integration\nof human-based learning and online fine-tuning, coupled with a soft robotic\nhand, DEFT demonstrates success across various tasks, establishing a robust,\ndata-efficient pathway toward general dexterous manipulation. Please see our\nwebsite at https://dexterous-finetuning.github.io for video results.",
            "author": [
                "Aditya Kannan",
                "Kenneth Shaw",
                "Shikhar Bahl",
                "Pragna Mannam",
                "Deepak Pathak"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19797v1",
                "http://arxiv.org/pdf/2310.19797v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19861v1",
            "title": "Posterior Sampling for Competitive RL: Function Approximation and\n  Partial Observation",
            "updated": "2023-10-30T17:59:26Z",
            "published": "2023-10-30T17:59:26Z",
            "summary": "This paper investigates posterior sampling algorithms for competitive\nreinforcement learning (RL) in the context of general function approximations.\nFocusing on zero-sum Markov games (MGs) under two critical settings, namely\nself-play and adversarial learning, we first propose the self-play and\nadversarial generalized eluder coefficient (GEC) as complexity measures for\nfunction approximation, capturing the exploration-exploitation trade-off in\nMGs. Based on self-play GEC, we propose a model-based self-play posterior\nsampling method to control both players to learn Nash equilibrium, which can\nsuccessfully handle the partial observability of states. Furthermore, we\nidentify a set of partially observable MG models fitting MG learning with the\nadversarial policies of the opponent. Incorporating the adversarial GEC, we\npropose a model-based posterior sampling method for learning adversarial MG\nwith potential partial observability. We further provide low regret bounds for\nproposed algorithms that can scale sublinearly with the proposed GEC and the\nnumber of episodes $T$. To the best of our knowledge, we for the first time\ndevelop generic model-based posterior sampling algorithms for competitive RL\nthat can be applied to a majority of tractable zero-sum MG classes in both\nfully observable and partially observable MGs with self-play and adversarial\nlearning.",
            "author": [
                "Shuang Qiu",
                "Ziyu Dai",
                "Han Zhong",
                "Zhaoran Wang",
                "Zhuoran Yang",
                "Tong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19861v1",
                "http://arxiv.org/pdf/2310.19861v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19796v1",
            "title": "Re-evaluating Retrosynthesis Algorithms with Syntheseus",
            "updated": "2023-10-30T17:59:04Z",
            "published": "2023-10-30T17:59:04Z",
            "summary": "The planning of how to synthesize molecules, also known as retrosynthesis,\nhas been a growing focus of the machine learning and chemistry communities in\nrecent years. Despite the appearance of steady progress, we argue that\nimperfect benchmarks and inconsistent comparisons mask systematic shortcomings\nof existing techniques. To remedy this, we present a benchmarking library\ncalled syntheseus which promotes best practice by default, enabling consistent\nmeaningful evaluation of single-step and multi-step retrosynthesis algorithms.\nWe use syntheseus to re-evaluate a number of previous retrosynthesis\nalgorithms, and find that the ranking of state-of-the-art models changes when\nevaluated carefully. We end with guidance for future works in this area.",
            "author": [
                "Krzysztof Maziarz",
                "Austin Tripp",
                "Guoqing Liu",
                "Megan Stanley",
                "Shufang Xie",
                "Piotr Gai\u0144ski",
                "Philipp Seidl",
                "Marwin Segler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19796v1",
                "http://arxiv.org/pdf/2310.19796v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19859v1",
            "title": "Res-Tuning: A Flexible and Efficient Tuning Paradigm via Unbinding Tuner\n  from Backbone",
            "updated": "2023-10-30T17:58:19Z",
            "published": "2023-10-30T17:58:19Z",
            "summary": "Parameter-efficient tuning has become a trend in transferring large-scale\nfoundation models to downstream applications. Existing methods typically embed\nsome light-weight tuners into the backbone, where both the design and the\nlearning of the tuners are highly dependent on the base model. This work offers\na new tuning paradigm, dubbed Res-Tuning, which intentionally unbinds tuners\nfrom the backbone. With both theoretical and empirical evidence, we show that\npopular tuning approaches have their equivalent counterparts under our\nunbinding formulation, and hence can be integrated into our framework\neffortlessly. Thanks to the structural disentanglement, we manage to free the\ndesign of tuners from the network architecture, facilitating flexible\ncombination of various tuning strategies. We further propose a memory-efficient\nvariant of Res-Tuning, where the bypass i.e., formed by a sequence of tuners)\nis effectively detached from the main branch, such that the gradients are\nback-propagated only to the tuners but not to the backbone. Such a detachment\nalso allows one-time backbone forward for multi-task inference. Extensive\nexperiments on both discriminative and generative tasks demonstrate the\nsuperiority of our method over existing alternatives from the perspectives of\nefficacy and efficiency. Project page:\n$\\href{https://res-tuning.github.io/}{\\textit{https://res-tuning.github.io/}}$.",
            "author": [
                "Zeyinzi Jiang",
                "Chaojie Mao",
                "Ziyuan Huang",
                "Ao Ma",
                "Yiliang Lv",
                "Yujun Shen",
                "Deli Zhao",
                "Jingren Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19859v1",
                "http://arxiv.org/pdf/2310.19859v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19795v1",
            "title": "SimMMDG: A Simple and Effective Framework for Multi-modal Domain\n  Generalization",
            "updated": "2023-10-30T17:58:09Z",
            "published": "2023-10-30T17:58:09Z",
            "summary": "In real-world scenarios, achieving domain generalization (DG) presents\nsignificant challenges as models are required to generalize to unknown target\ndistributions. Generalizing to unseen multi-modal distributions poses even\ngreater difficulties due to the distinct properties exhibited by different\nmodalities. To overcome the challenges of achieving domain generalization in\nmulti-modal scenarios, we propose SimMMDG, a simple yet effective multi-modal\nDG framework. We argue that mapping features from different modalities into the\nsame embedding space impedes model generalization. To address this, we propose\nsplitting the features within each modality into modality-specific and\nmodality-shared components. We employ supervised contrastive learning on the\nmodality-shared features to ensure they possess joint properties and impose\ndistance constraints on modality-specific features to promote diversity. In\naddition, we introduce a cross-modal translation module to regularize the\nlearned features, which can also be used for missing-modality generalization.\nWe demonstrate that our framework is theoretically well-supported and achieves\nstrong performance in multi-modal DG on the EPIC-Kitchens dataset and the novel\nHuman-Animal-Cartoon (HAC) dataset introduced in this paper. Our source code\nand HAC dataset are available at https://github.com/donghao51/SimMMDG.",
            "author": [
                "Hao Dong",
                "Ismail Nejjar",
                "Han Sun",
                "Eleni Chatzi",
                "Olga Fink"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19795v1",
                "http://arxiv.org/pdf/2310.19795v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19794v1",
            "title": "Robust Causal Bandits for Linear Models",
            "updated": "2023-10-30T17:58:01Z",
            "published": "2023-10-30T17:58:01Z",
            "summary": "Sequential design of experiments for optimizing a reward function in causal\nsystems can be effectively modeled by the sequential design of interventions in\ncausal bandits (CBs). In the existing literature on CBs, a critical assumption\nis that the causal models remain constant over time. However, this assumption\ndoes not necessarily hold in complex systems, which constantly undergo temporal\nmodel fluctuations. This paper addresses the robustness of CBs to such model\nfluctuations. The focus is on causal systems with linear structural equation\nmodels (SEMs). The SEMs and the time-varying pre- and post-interventional\nstatistical models are all unknown. Cumulative regret is adopted as the design\ncriteria, based on which the objective is to design a sequence of interventions\nthat incur the smallest cumulative regret with respect to an oracle aware of\nthe entire causal model and its fluctuations. First, it is established that the\nexisting approaches fail to maintain regret sub-linearity with even a few\ninstances of model deviation. Specifically, when the number of instances with\nmodel deviation is as few as $T^\\frac{1}{2L}$, where $T$ is the time horizon\nand $L$ is the longest causal path in the graph, the existing algorithms will\nhave linear regret in $T$. Next, a robust CB algorithm is designed, and its\nregret is analyzed, where upper and information-theoretic lower bounds on the\nregret are established. Specifically, in a graph with $N$ nodes and maximum\ndegree $d$, under a general measure of model deviation $C$, the cumulative\nregret is upper bounded by $\\tilde{\\mathcal{O}}(d^{L-\\frac{1}{2}}(\\sqrt{NT} +\nNC))$ and lower bounded by $\\Omega(d^{\\frac{L}{2}-2}\\max\\{\\sqrt{T},d^2C\\})$.\nComparing these bounds establishes that the proposed algorithm achieves nearly\noptimal $\\tilde{\\mathcal{O}}(\\sqrt{T})$ regret when $C$ is $o(\\sqrt{T})$ and\nmaintains sub-linear regret for a broader range of $C$.",
            "author": [
                "Zirui Yan",
                "Arpan Mukherjee",
                "Burak Var\u0131c\u0131",
                "Ali Tajer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19794v1",
                "http://arxiv.org/pdf/2310.19794v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19793v2",
            "title": "On Learning Gaussian Multi-index Models with Gradient Flow",
            "updated": "2023-11-02T17:33:13Z",
            "published": "2023-10-30T17:55:28Z",
            "summary": "We study gradient flow on the multi-index regression problem for\nhigh-dimensional Gaussian data. Multi-index functions consist of a composition\nof an unknown low-rank linear projection and an arbitrary unknown,\nlow-dimensional link function. As such, they constitute a natural template for\nfeature learning in neural networks.\n  We consider a two-timescale algorithm, whereby the low-dimensional link\nfunction is learnt with a non-parametric model infinitely faster than the\nsubspace parametrizing the low-rank projection. By appropriately exploiting the\nmatrix semigroup structure arising over the subspace correlation matrices, we\nestablish global convergence of the resulting Grassmannian population gradient\nflow dynamics, and provide a quantitative description of its associated\n`saddle-to-saddle' dynamics. Notably, the timescales associated with each\nsaddle can be explicitly characterized in terms of an appropriate Hermite\ndecomposition of the target link function. In contrast with these positive\nresults, we also show that the related \\emph{planted} problem, where the link\nfunction is known and fixed, in fact has a rough optimization landscape, in\nwhich gradient flow dynamics might get trapped with high probability.",
            "author": [
                "Alberto Bietti",
                "Joan Bruna",
                "Loucas Pillaud-Vivien"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19793v2",
                "http://arxiv.org/pdf/2310.19793v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19790v1",
            "title": "Detection and Preliminary Characterisation of Polluted White Dwarfs from\n  Gaia EDR3 and LAMOST",
            "updated": "2023-10-30T17:55:02Z",
            "published": "2023-10-30T17:55:02Z",
            "summary": "We present a catalogue of 62 polluted white dwarfs observed by the 9th\nLow-Resolution Data Release of the Large Sky Area Multi-Object Fiber\nSpectroscopic Telescope (LAMOST LRS DR9v1; R$\\approx$1,800) and the Early Data\nRelease 3 (EDR3) of the Gaia Mission. Among these stellar remnants, 30 are new\ndiscoveries with previously unknown traces of calcium pollution. To generate\nour catalogue, we used a database of 4,324 unique Gaia EDR3 white dwarf\ncandidates with LAMOST LRS DR9v1 observations, many of which have been\nspectroscopically confirmed by other telescopes. For these stars, we developed\na quantitative method to detect calcium absorption in their spectra between\n3,900-4,000$\\mathring {\\mathrm A}$, which we then validated through visual\ninspection and multiple literature cross-checks. Our catalogue provides the\nastrometric and photometric properties of the white dwarf candidates,\nincorporates supplementary data (e.g. Montreal White Dwarf Database, MWDD;\nPanSTARRS; the Hubble Space Telescope), and indicates the possibility of\ncalcium pollution in their atmospheres. For our final sample of polluted white\ndwarfs, we also determine the main atmospheric properties of 23 sources with\neffective temperatures $T_{\\rm eff}$$\\leq$25,000K and no existing calcium\nabundances in the MWDD. Our analysis represents a first step towards measuring\nthe full atmospheric composition of these stars and learning about the bulk\nproperties of their accreted material. As we venture into the era of wide-field\nspectroscopic surveys, our work highlights the importance of combining\nlarge-scale databases for identifying and characterising new polluted white\ndwarfs.",
            "author": [
                "Mariona Badenas-Agusti",
                "Andrew Vanderburg",
                "Simon Blouin",
                "Patrick Dufour",
                "Javier Via\u00f1a",
                "Sara Seager",
                "Sharon X. Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19790v1",
                "http://arxiv.org/pdf/2310.19790v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19791v1",
            "title": "LILO: Learning Interpretable Libraries by Compressing and Documenting\n  Code",
            "updated": "2023-10-30T17:55:02Z",
            "published": "2023-10-30T17:55:02Z",
            "summary": "While large language models (LLMs) now excel at code generation, a key aspect\nof software development is the art of refactoring: consolidating code into\nlibraries of reusable and readable programs. In this paper, we introduce LILO,\na neurosymbolic framework that iteratively synthesizes, compresses, and\ndocuments code to build libraries tailored to particular problem domains. LILO\ncombines LLM-guided program synthesis with recent algorithmic advances in\nautomated refactoring from Stitch: a symbolic compression system that\nefficiently identifies optimal lambda abstractions across large code corpora.\nTo make these abstractions interpretable, we introduce an auto-documentation\n(AutoDoc) procedure that infers natural language names and docstrings based on\ncontextual examples of usage. In addition to improving human readability, we\nfind that AutoDoc boosts performance by helping LILO's synthesizer to interpret\nand deploy learned abstractions. We evaluate LILO on three inductive program\nsynthesis benchmarks for string editing, scene reasoning, and graphics\ncomposition. Compared to existing neural and symbolic methods - including the\nstate-of-the-art library learning algorithm DreamCoder - LILO solves more\ncomplex tasks and learns richer libraries that are grounded in linguistic\nknowledge.",
            "author": [
                "Gabriel Grand",
                "Lionel Wong",
                "Matthew Bowers",
                "Theo X. Olausson",
                "Muxin Liu",
                "Joshua B. Tenenbaum",
                "Jacob Andreas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19791v1",
                "http://arxiv.org/pdf/2310.19791v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19789v1",
            "title": "DiffEnc: Variational Diffusion with a Learned Encoder",
            "updated": "2023-10-30T17:54:36Z",
            "published": "2023-10-30T17:54:36Z",
            "summary": "Diffusion models may be viewed as hierarchical variational autoencoders\n(VAEs) with two improvements: parameter sharing for the conditional\ndistributions in the generative process and efficient computation of the loss\nas independent terms over the hierarchy. We consider two changes to the\ndiffusion model that retain these advantages while adding flexibility to the\nmodel. Firstly, we introduce a data- and depth-dependent mean function in the\ndiffusion process, which leads to a modified diffusion loss. Our proposed\nframework, DiffEnc, achieves state-of-the-art likelihood on CIFAR-10. Secondly,\nwe let the ratio of the noise variance of the reverse encoder process and the\ngenerative process be a free weight parameter rather than being fixed to 1.\nThis leads to theoretical insights: For a finite depth hierarchy, the evidence\nlower bound (ELBO) can be used as an objective for a weighted diffusion loss\napproach and for optimizing the noise schedule specifically for inference. For\nthe infinite-depth hierarchy, on the other hand, the weight parameter has to be\n1 to have a well-defined ELBO.",
            "author": [
                "Beatrix M. G. Nielsen",
                "Anders Christensen",
                "Andrea Dittadi",
                "Ole Winther"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19789v1",
                "http://arxiv.org/pdf/2310.19789v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19788v2",
            "title": "Worst-Case Optimal Multi-Armed Gaussian Best Arm Identification with a\n  Fixed Budget",
            "updated": "2023-12-02T14:36:15Z",
            "published": "2023-10-30T17:52:46Z",
            "summary": "Experimental design is crucial in evidence-based decision-making with\nmultiple treatment arms, such as online advertisements and medical treatments.\nThis study investigates the problem of identifying the treatment arm with the\nhighest expected outcome, referred to as the best treatment arm, while\nminimizing the probability of misidentification. This problem has been studied\nacross numerous research fields, including best arm identification (BAI) and\nordinal optimization. In our experiments, the number of treatment-allocation\nrounds is fixed. During each round, a decision-maker allocates a treatment arm\nto an experimental unit and observes a corresponding outcome, which follows a\nGaussian distribution with variances that can differ among the treatment arms.\nAt the end of the experiment, we recommend one of the treatment arms as an\nestimate of the best treatment arm based on the observations. To design an\nexperiment, we first discuss the worst-case lower bound for the probability of\nmisidentification through an information-theoretic approach. Then, under the\nassumption that the variances are known, we propose the\nGeneralized-Neyman-Allocation (GNA)-empirical-best-arm (EBA) strategy, an\nextension of the Neyman allocation proposed by Neyman (1934). We show that the\nGNA-EBA strategy is asymptotically optimal in the sense that its probability of\nmisidentification aligns with the lower bounds as the sample size increases\nindefinitely and the differences between the expected outcomes of the best and\nother suboptimal arms converge to a uniform value. We refer to such strategies\nas asymptotically worst-case optimal.",
            "author": [
                "Masahiro Kato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19788v2",
                "http://arxiv.org/pdf/2310.19788v2"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.LG",
                "econ.EM",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19787v1",
            "title": "$e^{\\text{RPCA}}$: Robust Principal Component Analysis for Exponential\n  Family Distributions",
            "updated": "2023-10-30T17:51:30Z",
            "published": "2023-10-30T17:51:30Z",
            "summary": "Robust Principal Component Analysis (RPCA) is a widely used method for\nrecovering low-rank structure from data matrices corrupted by significant and\nsparse outliers. These corruptions may arise from occlusions, malicious\ntampering, or other causes for anomalies, and the joint identification of such\ncorruptions with low-rank background is critical for process monitoring and\ndiagnosis. However, existing RPCA methods and their extensions largely do not\naccount for the underlying probabilistic distribution for the data matrices,\nwhich in many applications are known and can be highly non-Gaussian. We thus\npropose a new method called Robust Principal Component Analysis for Exponential\nFamily distributions ($e^{\\text{RPCA}}$), which can perform the desired\ndecomposition into low-rank and sparse matrices when such a distribution falls\nwithin the exponential family. We present a novel alternating direction method\nof multiplier optimization algorithm for efficient $e^{\\text{RPCA}}$\ndecomposition. The effectiveness of $e^{\\text{RPCA}}$ is then demonstrated in\ntwo applications: the first for steel sheet defect detection, and the second\nfor crime activity monitoring in the Atlanta metropolitan area.",
            "author": [
                "Xiaojun Zheng",
                "Simon Mak",
                "Liyan Xie",
                "Yao Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19787v1",
                "http://arxiv.org/pdf/2310.19787v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19786v3",
            "title": "From External to Swap Regret 2.0: An Efficient Reduction and Oblivious\n  Adversary for Large Action Spaces",
            "updated": "2023-12-06T07:34:24Z",
            "published": "2023-10-30T17:50:29Z",
            "summary": "We provide a novel reduction from swap-regret minimization to external-regret\nminimization, which improves upon the classical reductions of Blum-Mansour\n[BM07] and Stolz-Lugosi [SL05] in that it does not require finiteness of the\nspace of actions. We show that, whenever there exists a no-external-regret\nalgorithm for some hypothesis class, there must also exist a no-swap-regret\nalgorithm for that same class. For the problem of learning with expert advice,\nour result implies that it is possible to guarantee that the swap regret is\nbounded by {\\epsilon} after $\\log(N)^{O(1/\\epsilon)}$ rounds and with $O(N)$\nper iteration complexity, where $N$ is the number of experts, while the\nclassical reductions of Blum-Mansour and Stolz-Lugosi require $O(N/\\epsilon^2)$\nrounds and at least $\\Omega(N^2)$ per iteration complexity. Our result comes\nwith an associated lower bound, which -- in contrast to that in [BM07] -- holds\nfor oblivious and $\\ell_1$-constrained adversaries and learners that can employ\ndistributions over experts, showing that the number of rounds must be\n$\\tilde\\Omega(N/\\epsilon^2)$ or exponential in $1/\\epsilon$.\n  Our reduction implies that, if no-regret learning is possible in some game,\nthen this game must have approximate correlated equilibria, of arbitrarily good\napproximation. This strengthens the folklore implication of no-regret learning\nthat approximate coarse correlated equilibria exist. Importantly, it provides a\nsufficient condition for the existence of correlated equilibrium which vastly\nextends the requirement that the action set is finite, thus answering a\nquestion left open by [DG22; Ass+23]. Moreover, it answers several outstanding\nquestions about equilibrium computation and learning in games.",
            "author": [
                "Yuval Dagan",
                "Constantinos Daskalakis",
                "Maxwell Fishelson",
                "Noah Golowich"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19786v3",
                "http://arxiv.org/pdf/2310.19786v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19785v1",
            "title": "What's \"up\" with vision-language models? Investigating their struggle\n  with spatial reasoning",
            "updated": "2023-10-30T17:50:15Z",
            "published": "2023-10-30T17:50:15Z",
            "summary": "Recent vision-language (VL) models are powerful, but can they reliably\ndistinguish \"right\" from \"left\"? We curate three new corpora to quantify model\ncomprehension of such basic spatial relations. These tests isolate spatial\nreasoning more precisely than existing datasets like VQAv2, e.g., our What'sUp\nbenchmark contains sets of photographs varying only the spatial relations of\nobjects, keeping their identity fixed (see Figure 1: models must comprehend not\nonly the usual case of a dog under a table, but also, the same dog on top of\nthe same table). We evaluate 18 VL models, finding that all perform poorly,\ne.g., BLIP finetuned on VQAv2, which nears human parity on VQAv2, achieves 56%\naccuracy on our benchmarks vs. humans at 99%. We conclude by studying causes of\nthis surprising behavior, finding: 1) that popular vision-language pretraining\ncorpora like LAION-2B contain little reliable data for learning spatial\nrelationships; and 2) that basic modeling interventions like up-weighting\npreposition-containing instances or fine-tuning on our corpora are not\nsufficient to address the challenges our benchmarks pose. We are hopeful that\nthese corpora will facilitate further research, and we release our data and\ncode at https://github.com/amitakamath/whatsup_vlms.",
            "author": [
                "Amita Kamath",
                "Jack Hessel",
                "Kai-Wei Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19785v1",
                "http://arxiv.org/pdf/2310.19785v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19776v2",
            "title": "Learn to Categorize or Categorize to Learn? Self-Coding for Generalized\n  Category Discovery",
            "updated": "2023-11-06T14:00:11Z",
            "published": "2023-10-30T17:45:32Z",
            "summary": "In the quest for unveiling novel categories at test time, we confront the\ninherent limitations of traditional supervised recognition models that are\nrestricted by a predefined category set. While strides have been made in the\nrealms of self-supervised and open-world learning towards test-time category\ndiscovery, a crucial yet often overlooked question persists: what exactly\ndelineates a category? In this paper, we conceptualize a category through the\nlens of optimization, viewing it as an optimal solution to a well-defined\nproblem. Harnessing this unique conceptualization, we propose a novel,\nefficient and self-supervised method capable of discovering previously unknown\ncategories at test time. A salient feature of our approach is the assignment of\nminimum length category codes to individual data instances, which encapsulates\nthe implicit category hierarchy prevalent in real-world datasets. This\nmechanism affords us enhanced control over category granularity, thereby\nequipping our model to handle fine-grained categories adeptly. Experimental\nevaluations, bolstered by state-of-the-art benchmark comparisons, testify to\nthe efficacy of our solution in managing unknown categories at test time.\nFurthermore, we fortify our proposition with a theoretical foundation,\nproviding proof of its optimality. Our code is available at\nhttps://github.com/SarahRastegar/InfoSieve.",
            "author": [
                "Sarah Rastegar",
                "Hazel Doughty",
                "Cees G. M. Snoek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19776v2",
                "http://arxiv.org/pdf/2310.19776v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "I.2.1.b; I.2.6.g; I.5.4.b; I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19767v1",
            "title": "Autoregressive Attention Neural Networks for Non-Line-of-Sight User\n  Tracking with Dynamic Metasurface Antennas",
            "updated": "2023-10-30T17:38:16Z",
            "published": "2023-10-30T17:38:16Z",
            "summary": "User localization and tracking in the upcoming generation of wireless\nnetworks have the potential to be revolutionized by technologies such as the\nDynamic Metasurface Antennas (DMAs). Commonly proposed algorithmic approaches\nrely on assumptions about relatively dominant Line-of-Sight (LoS) paths, or\nrequire pilot transmission sequences whose length is comparable to the number\nof DMA elements, thus, leading to limited effectiveness and considerable\nmeasurement overheads in blocked LoS and dynamic multipath environments. In\nthis paper, we present a two-stage machine-learning-based approach for user\ntracking, specifically designed for non-LoS multipath settings. A newly\nproposed attention-based Neural Network (NN) is first trained to map noisy\nchannel responses to potential user positions, regardless of user mobility\npatterns. This architecture constitutes a modification of the prominent vision\ntransformer, specifically modified for extracting information from\nhigh-dimensional frequency response signals. As a second stage, the NN's\npredictions for the past user positions are passed through a learnable\nautoregressive model to exploit the time-correlated channel information and\nobtain the final position predictions. The channel estimation procedure\nleverages a DMA receive architecture with partially-connected radio frequency\nchains, which results to reduced numbers of pilots. The numerical evaluation\nover an outdoor ray-tracing scenario illustrates that despite LoS blockage,\nthis methodology is capable of achieving high position accuracy across various\nmultipath settings.",
            "author": [
                "Kyriakos Stylianopoulos",
                "Murat Bayraktar",
                "Nuria Gonz\u00e1lez Prelcic",
                "George C. Alexandropoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19767v1",
                "http://arxiv.org/pdf/2310.19767v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19763v1",
            "title": "Autoregressive Renaissance in Neural PDE Solvers",
            "updated": "2023-10-30T17:35:26Z",
            "published": "2023-10-30T17:35:26Z",
            "summary": "Recent developments in the field of neural partial differential equation\n(PDE) solvers have placed a strong emphasis on neural operators. However, the\npaper \"Message Passing Neural PDE Solver\" by Brandstetter et al. published in\nICLR 2022 revisits autoregressive models and designs a message passing graph\nneural network that is comparable with or outperforms both the state-of-the-art\nFourier Neural Operator and traditional classical PDE solvers in its\ngeneralization capabilities and performance. This blog post delves into the key\ncontributions of this work, exploring the strategies used to address the common\nproblem of instability in autoregressive models and the design choices of the\nmessage passing graph neural network architecture.",
            "author": [
                "Yolanne Yi Ran Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19763v1",
                "http://arxiv.org/pdf/2310.19763v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19760v1",
            "title": "Epidemic outbreak prediction using machine learning models",
            "updated": "2023-10-30T17:28:44Z",
            "published": "2023-10-30T17:28:44Z",
            "summary": "In today's world,the risk of emerging and re-emerging epidemics have\nincreased.The recent advancement in healthcare technology has made it possible\nto predict an epidemic outbreak in a region.Early prediction of an epidemic\noutbreak greatly helps the authorities to be prepared with the necessary\nmedications and logistics required to keep things in control. In this article,\nwe try to predict the epidemic outbreak (influenza, hepatitis and malaria) for\nthe state of New York, USA using machine and deep learning algorithms, and a\nportal has been created for the same which can alert the authorities and health\ncare organizations of the region in case of an outbreak. The algorithm takes\nhistorical data to predict the possible number of cases for 5 weeks into the\nfuture. Non-clinical factors like google search trends,social media data and\nweather data have also been used to predict the probability of an outbreak.",
            "author": [
                "Akshara Pramod",
                "JS Abhishek",
                "Dr. Suganthi K"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19760v1",
                "http://arxiv.org/pdf/2310.19760v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19756v2",
            "title": "Transmission line condition prediction based on semi-supervised learning",
            "updated": "2023-12-07T00:38:51Z",
            "published": "2023-10-30T17:25:39Z",
            "summary": "Transmission line state assessment and prediction are of great significance\nfor the rational formulation of operation and maintenance strategy and\nimprovement of operation and maintenance level. Aiming at the problem that\nexisting models cannot take into account the robustness and data demand, this\npaper proposes a state prediction method based on semi-supervised learning.\nFirstly, for the expanded feature vector, the regular matrix is used to fill in\nthe missing data, and the sparse coding problem is solved by representation\nlearning. Then, with the help of a small number of labelled samples to\ninitially determine the category centers of line segments in different\ndefective states. Finally, the estimated parameters of the model are corrected\nusing unlabeled samples. Example analysis shows that this method can improve\nthe recognition accuracy and use data more efficiently than the existing\nmodels.",
            "author": [
                "Sizhe Li",
                "Xun Ma",
                "Nan Liu",
                "Yi Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19756v2",
                "http://arxiv.org/pdf/2310.19756v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19752v1",
            "title": "Intra-Modal Proxy Learning for Zero-Shot Visual Categorization with CLIP",
            "updated": "2023-10-30T17:22:02Z",
            "published": "2023-10-30T17:22:02Z",
            "summary": "Vision-language pre-training methods, e.g., CLIP, demonstrate an impressive\nzero-shot performance on visual categorizations with the class proxy from the\ntext embedding of the class name. However, the modality gap between the text\nand vision space can result in a sub-optimal performance. We theoretically show\nthat the gap cannot be reduced sufficiently by minimizing the contrastive loss\nin CLIP and the optimal proxy for vision tasks may reside only in the vision\nspace. Therefore, given unlabeled target vision data, we propose to learn the\nvision proxy directly with the help from the text proxy for zero-shot transfer.\nMoreover, according to our theoretical analysis, strategies are developed to\nfurther refine the pseudo label obtained by the text proxy to facilitate the\nintra-modal proxy learning (InMaP) for vision. Experiments on extensive\ndownstream tasks confirm the effectiveness and efficiency of our proposal.\nConcretely, InMaP can obtain the vision proxy within one minute on a single GPU\nwhile improving the zero-shot accuracy from $77.02\\%$ to $80.21\\%$ on ImageNet\nwith ViT-L/14@336 pre-trained by CLIP. Code is available at\n\\url{https://github.com/idstcv/InMaP}.",
            "author": [
                "Qi Qian",
                "Yuanhong Xu",
                "Juhua Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19752v1",
                "http://arxiv.org/pdf/2310.19752v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19748v2",
            "title": "Efficient learning of arbitrary single-copy quantum states",
            "updated": "2023-11-13T04:55:28Z",
            "published": "2023-10-30T17:15:19Z",
            "summary": "Quantum state tomography is the problem of estimating a given quantum state.\nUsually, it is required to run the quantum experiment - state preparation,\nstate evolution, measurement - several times to be able to estimate the output\nquantum state of the experiment, because an exponentially high number of copies\nof the state is required. In this work, we present an efficient algorithm to\nestimate with a small but non-zero probability of error the output state of the\nexperiment using a single copy of the state, without knowing the evolution\ndynamics of the state. It also does not destroy the original state, which can\nbe recovered easily for any further quantum processing. As an example, it is\nusually required to repeat a quantum image processing experiment many times,\nsince many copies of the state of the output image are needed to extract the\ninformation from all its pixels. The information from $\\mathcal{N}$ pixels of\nthe image can be inferred from a single run of the image processing experiment\nin our algorithm, to efficiently estimate the density matrix of the image\nstate.",
            "author": [
                "Shibdas Roy",
                "Filippo Caruso",
                "Srushti Patil"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19748v2",
                "http://arxiv.org/pdf/2310.19748v2"
            ],
            "primary_category": "physics.gen-ph",
            "category": [
                "physics.gen-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19743v1",
            "title": "Tell Me What Is Good About This Property: Leveraging Reviews For\n  Segment-Personalized Image Collection Summarization",
            "updated": "2023-10-30T17:06:49Z",
            "published": "2023-10-30T17:06:49Z",
            "summary": "Image collection summarization techniques aim to present a compact\nrepresentation of an image gallery through a carefully selected subset of\nimages that captures its semantic content. When it comes to web content,\nhowever, the ideal selection can vary based on the user's specific intentions\nand preferences. This is particularly relevant at Booking.com, where presenting\nproperties and their visual summaries that align with users' expectations is\ncrucial. To address this challenge, we consider user intentions in the\nsummarization of property visuals by analyzing property reviews and extracting\nthe most significant aspects mentioned by users. By incorporating the insights\nfrom reviews in our visual summaries, we enhance the summaries by presenting\nthe relevant content to a user. Moreover, we achieve it without the need for\ncostly annotations. Our experiments, including human perceptual studies,\ndemonstrate the superiority of our cross-modal approach, which we coin as\nCrossSummarizer over the no-personalization and image-based clustering\nbaselines.",
            "author": [
                "Monika Wysoczanska",
                "Moran Beladev",
                "Karen Lastmann Assaraf",
                "Fengjun Wang",
                "Ofri Kleinfeld",
                "Gil Amsalem",
                "Hadas Harush Boker"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19743v1",
                "http://arxiv.org/pdf/2310.19743v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19733v1",
            "title": "Differentially Private Reward Estimation with Preference Feedback",
            "updated": "2023-10-30T16:58:30Z",
            "published": "2023-10-30T16:58:30Z",
            "summary": "Learning from preference-based feedback has recently gained considerable\ntraction as a promising approach to align generative models with human\ninterests. Instead of relying on numerical rewards, the generative models are\ntrained using reinforcement learning with human feedback (RLHF). These\napproaches first solicit feedback from human labelers typically in the form of\npairwise comparisons between two possible actions, then estimate a reward model\nusing these comparisons, and finally employ a policy based on the estimated\nreward model. An adversarial attack in any step of the above pipeline might\nreveal private and sensitive information of human labelers. In this work, we\nadopt the notion of label differential privacy (DP) and focus on the problem of\nreward estimation from preference-based feedback while protecting privacy of\neach individual labelers. Specifically, we consider the parametric\nBradley-Terry-Luce (BTL) model for such pairwise comparison feedback involving\na latent reward parameter $\\theta^* \\in \\mathbb{R}^d$. Within a standard\nminimax estimation framework, we provide tight upper and lower bounds on the\nerror in estimating $\\theta^*$ under both local and central models of DP. We\nshow, for a given privacy budget $\\epsilon$ and number of samples $n$, that the\nadditional cost to ensure label-DP under local model is $\\Theta \\big(\\frac{1}{\ne^\\epsilon-1}\\sqrt{\\frac{d}{n}}\\big)$, while it is\n$\\Theta\\big(\\frac{\\text{poly}(d)}{\\epsilon n} \\big)$ under the weaker central\nmodel. We perform simulations on synthetic data that corroborate these\ntheoretical results.",
            "author": [
                "Sayak Ray Chowdhury",
                "Xingyu Zhou",
                "Nagarajan Natarajan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19733v1",
                "http://arxiv.org/pdf/2310.19733v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19731v1",
            "title": "ViR: Vision Retention Networks",
            "updated": "2023-10-30T16:55:50Z",
            "published": "2023-10-30T16:55:50Z",
            "summary": "Vision Transformers (ViTs) have attracted a lot of popularity in recent\nyears, due to their exceptional capabilities in modeling long-range spatial\ndependencies and scalability for large scale training. Although the training\nparallelism of self-attention mechanism plays an important role in retaining\ngreat performance, its quadratic complexity baffles the application of ViTs in\nmany scenarios which demand fast inference. This effect is even more pronounced\nin applications in which autoregressive modeling of input features is required.\nIn Natural Language Processing (NLP), a new stream of efforts have proposed\nparallelizable models with recurrent formulation that allows for efficient\ninference in generative applications. Inspired by this trend, we propose a new\nclass of computer vision models, dubbed Vision Retention Networks (ViR), with\ndual parallel and recurrent formulations, which strike an optimal balance\nbetween fast inference and parallel training with competitive performance. In\nparticular, ViR scales favorably for image throughput and memory consumption in\ntasks that require higher-resolution images due to its flexible formulation in\nprocessing large sequence lengths. The ViR is the first attempt to realize dual\nparallel and recurrent equivalency in a general vision backbone for recognition\ntasks. We have validated the effectiveness of ViR through extensive experiments\nwith different dataset sizes and various image resolutions and achieved\ncompetitive performance. Our code and pretrained models will be made publicly\navailable.",
            "author": [
                "Ali Hatamizadeh",
                "Michael Ranzinger",
                "Jan Kautz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19731v1",
                "http://arxiv.org/pdf/2310.19731v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19727v2",
            "title": "Generating Medical Prescriptions with Conditional Transformer",
            "updated": "2023-11-18T17:10:29Z",
            "published": "2023-10-30T16:53:11Z",
            "summary": "Access to real-world medication prescriptions is essential for medical\nresearch and healthcare quality improvement. However, access to real medication\nprescriptions is often limited due to the sensitive nature of the information\nexpressed. Additionally, manually labelling these instructions for training and\nfine-tuning Natural Language Processing (NLP) models can be tedious and\nexpensive. We introduce a novel task-specific model architecture,\nLabel-To-Text-Transformer (\\textbf{LT3}), tailored to generate synthetic\nmedication prescriptions based on provided labels, such as a vocabulary list of\nmedications and their attributes. LT3 is trained on a set of around 2K lines of\nmedication prescriptions extracted from the MIMIC-III database, allowing the\nmodel to produce valuable synthetic medication prescriptions. We evaluate LT3's\nperformance by contrasting it with a state-of-the-art Pre-trained Language\nModel (PLM), T5, analysing the quality and diversity of generated texts. We\ndeploy the generated synthetic data to train the SpacyNER model for the Named\nEntity Recognition (NER) task over the n2c2-2018 dataset. The experiments show\nthat the model trained on synthetic data can achieve a 96-98\\% F1 score at\nLabel Recognition on Drug, Frequency, Route, Strength, and Form. LT3 codes and\ndata will be shared at\n\\url{https://github.com/HECTA-UoM/Label-To-Text-Transformer}",
            "author": [
                "Samuel Belkadi",
                "Nicolo Micheletti",
                "Lifeng Han",
                "Warren Del-Pinto",
                "Goran Nenadic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19727v2",
                "http://arxiv.org/pdf/2310.19727v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19726v1",
            "title": "A Path to Simpler Models Starts With Noise",
            "updated": "2023-10-30T16:52:57Z",
            "published": "2023-10-30T16:52:57Z",
            "summary": "The Rashomon set is the set of models that perform approximately equally well\non a given dataset, and the Rashomon ratio is the fraction of all models in a\ngiven hypothesis space that are in the Rashomon set. Rashomon ratios are often\nlarge for tabular datasets in criminal justice, healthcare, lending, education,\nand in other areas, which has practical implications about whether simpler\nmodels can attain the same level of accuracy as more complex models. An open\nquestion is why Rashomon ratios often tend to be large. In this work, we\npropose and study a mechanism of the data generation process, coupled with\nchoices usually made by the analyst during the learning process, that\ndetermines the size of the Rashomon ratio. Specifically, we demonstrate that\nnoisier datasets lead to larger Rashomon ratios through the way that\npractitioners train models. Additionally, we introduce a measure called pattern\ndiversity, which captures the average difference in predictions between\ndistinct classification patterns in the Rashomon set, and motivate why it tends\nto increase with label noise. Our results explain a key aspect of why simpler\nmodels often tend to perform as well as black box models on complex, noisier\ndatasets.",
            "author": [
                "Lesia Semenova",
                "Harry Chen",
                "Ronald Parr",
                "Cynthia Rudin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19726v1",
                "http://arxiv.org/pdf/2310.19726v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19721v3",
            "title": "Promise:Prompt-driven 3D Medical Image Segmentation Using Pretrained\n  Image Foundation Models",
            "updated": "2023-11-13T21:28:24Z",
            "published": "2023-10-30T16:49:03Z",
            "summary": "To address prevalent issues in medical imaging, such as data acquisition\nchallenges and label availability, transfer learning from natural to medical\nimage domains serves as a viable strategy to produce reliable segmentation\nresults. However, several existing barriers between domains need to be broken\ndown, including addressing contrast discrepancies, managing anatomical\nvariability, and adapting 2D pretrained models for 3D segmentation tasks. In\nthis paper, we propose ProMISe,a prompt-driven 3D medical image segmentation\nmodel using only a single point prompt to leverage knowledge from a pretrained\n2D image foundation model. In particular, we use the pretrained vision\ntransformer from the Segment Anything Model (SAM) and integrate lightweight\nadapters to extract depth-related (3D) spatial context without updating the\npretrained weights. For robust results, a hybrid network with complementary\nencoders is designed, and a boundary-aware loss is proposed to achieve precise\nboundaries. We evaluate our model on two public datasets for colon and pancreas\ntumor segmentations, respectively. Compared to the state-of-the-art\nsegmentation methods with and without prompt engineering, our proposed method\nachieves superior performance. The code is publicly available at\nhttps://github.com/MedICL-VU/ProMISe.",
            "author": [
                "Hao Li",
                "Han Liu",
                "Dewei Hu",
                "Jiacheng Wang",
                "Ipek Oguz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19721v3",
                "http://arxiv.org/pdf/2310.19721v3"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19717v1",
            "title": "Support matrix machine: A review",
            "updated": "2023-10-30T16:46:23Z",
            "published": "2023-10-30T16:46:23Z",
            "summary": "Support vector machine (SVM) is one of the most studied paradigms in the\nrealm of machine learning for classification and regression problems. It relies\non vectorized input data. However, a significant portion of the real-world data\nexists in matrix format, which is given as input to SVM by reshaping the\nmatrices into vectors. The process of reshaping disrupts the spatial\ncorrelations inherent in the matrix data. Also, converting matrices into\nvectors results in input data with a high dimensionality, which introduces\nsignificant computational complexity. To overcome these issues in classifying\nmatrix input data, support matrix machine (SMM) is proposed. It represents one\nof the emerging methodologies tailored for handling matrix input data. The SMM\nmethod preserves the structural information of the matrix data by using the\nspectral elastic net property which is a combination of the nuclear norm and\nFrobenius norm. This article provides the first in-depth analysis of the\ndevelopment of the SMM model, which can be used as a thorough summary by both\nnovices and experts. We discuss numerous SMM variants, such as robust, sparse,\nclass imbalance, and multi-class classification models. We also analyze the\napplications of the SMM model and conclude the article by outlining potential\nfuture research avenues and possibilities that may motivate academics to\nadvance the SMM algorithm.",
            "author": [
                "Anuradha Kumari",
                "Mushir Akhtar",
                "Rupal Shah",
                "M. Tanveer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19717v1",
                "http://arxiv.org/pdf/2310.19717v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19854v1",
            "title": "Exact Recovery and Bregman Hard Clustering of Node-Attributed Stochastic\n  Block Model",
            "updated": "2023-10-30T16:46:05Z",
            "published": "2023-10-30T16:46:05Z",
            "summary": "Network clustering tackles the problem of identifying sets of nodes\n(communities) that have similar connection patterns. However, in many\nscenarios, nodes also have attributes that are correlated with the clustering\nstructure. Thus, network information (edges) and node information (attributes)\ncan be jointly leveraged to design high-performance clustering algorithms.\nUnder a general model for the network and node attributes, this work\nestablishes an information-theoretic criterion for the exact recovery of\ncommunity labels and characterizes a phase transition determined by the\nChernoff-Hellinger divergence of the model. The criterion shows how network and\nattribute information can be exchanged in order to have exact recovery (e.g.,\nmore reliable network information requires less reliable attribute\ninformation). This work also presents an iterative clustering algorithm that\nmaximizes the joint likelihood, assuming that the probability distribution of\nnetwork interactions and node attributes belong to exponential families. This\ncovers a broad range of possible interactions (e.g., edges with weights) and\nattributes (e.g., non-Gaussian models), as well as sparse networks, while also\nexploring the connection between exponential families and Bregman divergences.\nExtensive numerical experiments using synthetic data indicate that the proposed\nalgorithm outperforms classic algorithms that leverage only network or only\nattribute information as well as state-of-the-art algorithms that also leverage\nboth sources of information. The contributions of this work provide insights\ninto the fundamental limits and practical techniques for inferring community\nlabels on node-attributed networks.",
            "author": [
                "Maximilien Dreveton",
                "Felipe S. Fernandes",
                "Daniel R. Figueiredo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19854v1",
                "http://arxiv.org/pdf/2310.19854v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG",
                "stat.ML",
                "62H30, 62F12"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19708v3",
            "title": "Combining Language Models For Specialized Domains: A Colorful Approach",
            "updated": "2023-11-01T07:55:28Z",
            "published": "2023-10-30T16:35:55Z",
            "summary": "General purpose language models (LMs) encounter difficulties when processing\ndomain-specific jargon and terminology, which are frequently utilized in\nspecialized fields such as medicine or industrial settings. Moreover, they\noften find it challenging to interpret mixed speech that blends general\nlanguage with specialized jargon. This poses a challenge for automatic speech\nrecognition systems operating within these specific domains. In this work, we\nintroduce a novel approach that integrates domain-specific or secondary LM into\ngeneral-purpose LM. This strategy involves labeling, or \"coloring\", each word\nto indicate its association with either the general or the domain-specific LM.\nWe develop an optimized algorithm that enhances the beam search algorithm to\neffectively handle inferences involving colored words. Our evaluations indicate\nthat this approach is highly effective in integrating jargon into language\ntasks. Notably, our method substantially lowers the error rate for\ndomain-specific words without compromising performance in the general domain.",
            "author": [
                "Daniel Eitan",
                "Menachem Pirchi",
                "Neta Glazer",
                "Shai Meital",
                "Gil Ayach",
                "Gidon Krendel",
                "Aviv Shamsian",
                "Aviv Navon",
                "Gil Hetz",
                "Joseph Keshet"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19708v3",
                "http://arxiv.org/pdf/2310.19708v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19704v1",
            "title": "A Survey on Knowledge Editing of Neural Networks",
            "updated": "2023-10-30T16:29:47Z",
            "published": "2023-10-30T16:29:47Z",
            "summary": "Deep neural networks are becoming increasingly pervasive in academia and\nindustry, matching and surpassing human performance on a wide variety of fields\nand related tasks. However, just as humans, even the largest artificial neural\nnetworks make mistakes, and once-correct predictions can become invalid as the\nworld progresses in time. Augmenting datasets with samples that account for\nmistakes or up-to-date information has become a common workaround in practical\napplications. However, the well-known phenomenon of catastrophic forgetting\nposes a challenge in achieving precise changes in the implicitly memorized\nknowledge of neural network parameters, often requiring a full model\nre-training to achieve desired behaviors. That is expensive, unreliable, and\nincompatible with the current trend of large self-supervised pre-training,\nmaking it necessary to find more efficient and effective methods for adapting\nneural network models to changing data. To address this need, knowledge editing\nis emerging as a novel area of research that aims to enable reliable,\ndata-efficient, and fast changes to a pre-trained target model, without\naffecting model behaviors on previously learned tasks. In this survey, we\nprovide a brief review of this recent artificial intelligence field of\nresearch. We first introduce the problem of editing neural networks, formalize\nit in a common framework and differentiate it from more notorious branches of\nresearch such as continuous learning. Next, we provide a review of the most\nrelevant knowledge editing approaches and datasets proposed so far, grouping\nworks under four different families: regularization techniques, meta-learning,\ndirect model editing, and architectural strategies. Finally, we outline some\nintersections with other fields of research and potential directions for future\nworks.",
            "author": [
                "Vittorio Mazzia",
                "Alessandro Pedrani",
                "Andrea Caciolai",
                "Kay Rottmann",
                "Davide Bernardi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19704v1",
                "http://arxiv.org/pdf/2310.19704v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19698v1",
            "title": "When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and\n  Limitations",
            "updated": "2023-10-30T16:19:34Z",
            "published": "2023-10-30T16:19:34Z",
            "summary": "Context-based fine-tuning methods, including prompting, in-context learning,\nsoft prompting (also known as prompt tuning), and prefix-tuning, have gained\npopularity due to their ability to often match the performance of full\nfine-tuning with a fraction of the parameters. Despite their empirical\nsuccesses, there is little theoretical understanding of how these techniques\ninfluence the internal computation of the model and their expressiveness\nlimitations. We show that despite the continuous embedding space being more\nexpressive than the discrete token space, soft-prompting and prefix-tuning are\nstrictly less expressive than full fine-tuning, even with the same number of\nlearnable parameters. Concretely, context-based fine-tuning cannot change the\nrelative attention pattern over the content and can only bias the outputs of an\nattention layer in a fixed direction. This suggests that while techniques like\nprompting, in-context learning, soft prompting, and prefix-tuning can\neffectively elicit skills present in the pretrained model, they cannot learn\nnovel tasks that require new attention patterns.",
            "author": [
                "Aleksandar Petrov",
                "Philip H. S. Torr",
                "Adel Bibi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19698v1",
                "http://arxiv.org/pdf/2310.19698v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19695v2",
            "title": "Deep-learning-based decomposition of overlapping-sparse images:\n  application at the vertex of neutrino interactions",
            "updated": "2023-11-06T21:46:56Z",
            "published": "2023-10-30T16:12:25Z",
            "summary": "Image decomposition plays a crucial role in various computer vision tasks,\nenabling the analysis and manipulation of visual content at a fundamental\nlevel. Overlapping images, which occur when multiple objects or scenes\npartially occlude each other, pose unique challenges for decomposition\nalgorithms. The task intensifies when working with sparse images, where the\nscarcity of meaningful information complicates the precise extraction of\ncomponents. This paper presents a solution that leverages the power of deep\nlearning to accurately extract individual objects within multi-dimensional\noverlapping-sparse images, with a direct application in high-energy physics\nwith decomposition of overlaid elementary particles obtained from imaging\ndetectors. In particular, the proposed approach tackles a highly complex yet\nunsolved problem: identifying and measuring independent particles at the vertex\nof neutrino interactions, where one expects to observe detector images with\nmultiple indiscernible overlapping charged particles. By decomposing the image\nof the detector activity at the vertex through deep learning, it is possible to\ninfer the kinematic parameters of the identified low-momentum particles - which\notherwise would remain neglected - and enhance the reconstructed energy\nresolution of the neutrino event. We also present an additional step - that can\nbe tuned directly on detector data - combining the above method with a\nfully-differentiable generative model to improve the image decomposition\nfurther and, consequently, the resolution of the measured parameters, achieving\nunprecedented results. This improvement is crucial for precisely measuring the\nparameters that govern neutrino flavour oscillations and searching for\nasymmetries between matter and antimatter.",
            "author": [
                "Sa\u00fal Alonso-Monsalve",
                "Davide Sgalaberna",
                "Xingyu Zhao",
                "Adrien Molines",
                "Clark McGrew",
                "Andr\u00e9 Rubbia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19695v2",
                "http://arxiv.org/pdf/2310.19695v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19694v1",
            "title": "Convolutional State Space Models for Long-Range Spatiotemporal Modeling",
            "updated": "2023-10-30T16:11:06Z",
            "published": "2023-10-30T16:11:06Z",
            "summary": "Effectively modeling long spatiotemporal sequences is challenging due to the\nneed to model complex spatial correlations and long-range temporal dependencies\nsimultaneously. ConvLSTMs attempt to address this by updating tensor-valued\nstates with recurrent neural networks, but their sequential computation makes\nthem slow to train. In contrast, Transformers can process an entire\nspatiotemporal sequence, compressed into tokens, in parallel. However, the cost\nof attention scales quadratically in length, limiting their scalability to\nlonger sequences. Here, we address the challenges of prior methods and\nintroduce convolutional state space models (ConvSSM) that combine the tensor\nmodeling ideas of ConvLSTM with the long sequence modeling approaches of state\nspace methods such as S4 and S5. First, we demonstrate how parallel scans can\nbe applied to convolutional recurrences to achieve subquadratic parallelization\nand fast autoregressive generation. We then establish an equivalence between\nthe dynamics of ConvSSMs and SSMs, which motivates parameterization and\ninitialization strategies for modeling long-range dependencies. The result is\nConvS5, an efficient ConvSSM variant for long-range spatiotemporal modeling.\nConvS5 significantly outperforms Transformers and ConvLSTM on a long horizon\nMoving-MNIST experiment while training 3X faster than ConvLSTM and generating\nsamples 400X faster than Transformers. In addition, ConvS5 matches or exceeds\nthe performance of state-of-the-art methods on challenging DMLab, Minecraft and\nHabitat prediction benchmarks and enables new directions for modeling long\nspatiotemporal sequences.",
            "author": [
                "Jimmy T. H. Smith",
                "Shalini De Mello",
                "Jan Kautz",
                "Scott W. Linderman",
                "Wonmin Byeon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19694v1",
                "http://arxiv.org/pdf/2310.19694v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19693v1",
            "title": "The Effect of Structural Phase Changes on Fermi Level Shifts and\n  Optoelectronic Properties of Lead-Free CsSnI3 Perovskites",
            "updated": "2023-10-30T16:09:35Z",
            "published": "2023-10-30T16:09:35Z",
            "summary": "The work carried out first-principles calculations within the framework of\ndensity functional theory to study the structural stability of the CsSnI3\ncompound and the influence of phase transitions on their electronic and optical\nproperties. Using the GGA and SCAN functionals, the relaxed structures of the\nCsSnI3 phases were obtained and their geometric characteristics were assessed.\nUsing the Phonopy code based on VASP, calculations of phonon and thermodynamic\nproperties were performed, and the temperatures of phase transitions of CsSnI3\nwere determined. Electronic properties and Fermi level shifts as a result of\nphase transformations of CsSnI3 were assessed using the HSE06 functional and\nmachine learning prediction. The values of the complex dielectric constant and\nthe refractive index of all phases of the CsSnI3 were determined.",
            "author": [
                "Dilshod D. Nematov",
                "Amondulloi S. Burhonzoda",
                "Mekhrdod S. Kurboniyon",
                "Umar Zafari",
                "Kholmirzo T. Kholmurodov",
                "Tomoyuki Yamamoto",
                "Farhod Shokir"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19693v1",
                "http://arxiv.org/pdf/2310.19693v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "00A79",
                "J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19691v1",
            "title": "Causal Context Connects Counterfactual Fairness to Robust Prediction and\n  Group Fairness",
            "updated": "2023-10-30T16:07:57Z",
            "published": "2023-10-30T16:07:57Z",
            "summary": "Counterfactual fairness requires that a person would have been classified in\nthe same way by an AI or other algorithmic system if they had a different\nprotected class, such as a different race or gender. This is an intuitive\nstandard, as reflected in the U.S. legal system, but its use is limited because\ncounterfactuals cannot be directly observed in real-world data. On the other\nhand, group fairness metrics (e.g., demographic parity or equalized odds) are\nless intuitive but more readily observed. In this paper, we use $\\textit{causal\ncontext}$ to bridge the gaps between counterfactual fairness, robust\nprediction, and group fairness. First, we motivate counterfactual fairness by\nshowing that there is not necessarily a fundamental trade-off between fairness\nand accuracy because, under plausible conditions, the counterfactually fair\npredictor is in fact accuracy-optimal in an unbiased target distribution.\nSecond, we develop a correspondence between the causal graph of the\ndata-generating process and which, if any, group fairness metrics are\nequivalent to counterfactual fairness. Third, we show that in three common\nfairness contexts$\\unicode{x2013}$measurement error, selection on label, and\nselection on predictors$\\unicode{x2013}$counterfactual fairness is equivalent\nto demographic parity, equalized odds, and calibration, respectively.\nCounterfactual fairness can sometimes be tested by measuring relatively simple\ngroup fairness metrics.",
            "author": [
                "Jacy Reese Anthis",
                "Victor Veitch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19691v1",
                "http://arxiv.org/pdf/2310.19691v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19690v1",
            "title": "Towards Practical Non-Adversarial Distribution Alignment via Variational\n  Bounds",
            "updated": "2023-10-30T16:05:46Z",
            "published": "2023-10-30T16:05:46Z",
            "summary": "Distribution alignment can be used to learn invariant representations with\napplications in fairness and robustness. Most prior works resort to adversarial\nalignment methods but the resulting minimax problems are unstable and\nchallenging to optimize. Non-adversarial likelihood-based approaches either\nrequire model invertibility, impose constraints on the latent prior, or lack a\ngeneric framework for alignment. To overcome these limitations, we propose a\nnon-adversarial VAE-based alignment method that can be applied to any model\npipeline. We develop a set of alignment upper bounds (including a noisy bound)\nthat have VAE-like objectives but with a different perspective. We carefully\ncompare our method to prior VAE-based alignment approaches both theoretically\nand empirically. Finally, we demonstrate that our novel alignment losses can\nreplace adversarial losses in standard invariant representation learning\npipelines without modifying the original architectures -- thereby significantly\nbroadening the applicability of non-adversarial alignment methods.",
            "author": [
                "Ziyu Gong",
                "Ben Usman",
                "Han Zhao",
                "David I. Inouye"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19690v1",
                "http://arxiv.org/pdf/2310.19690v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19686v1",
            "title": "Can input reconstruction be used to directly estimate uncertainty of a\n  regression U-Net model? -- Application to proton therapy dose prediction for\n  head and neck cancer patients",
            "updated": "2023-10-30T16:04:34Z",
            "published": "2023-10-30T16:04:34Z",
            "summary": "Estimating the uncertainty of deep learning models in a reliable and\nefficient way has remained an open problem, where many different solutions have\nbeen proposed in the literature. Most common methods are based on Bayesian\napproximations, like Monte Carlo dropout (MCDO) or Deep ensembling (DE), but\nthey have a high inference time (i.e. require multiple inference passes) and\nmight not work for out-of-distribution detection (OOD) data (i.e. similar\nuncertainty for in-distribution (ID) and OOD). In safety critical environments,\nlike medical applications, accurate and fast uncertainty estimation methods,\nable to detect OOD data, are crucial, since wrong predictions can jeopardize\npatients safety. In this study, we present an alternative direct uncertainty\nestimation method and apply it for a regression U-Net architecture. The method\nconsists in the addition of a branch from the bottleneck which reconstructs the\ninput. The input reconstruction error can be used as a surrogate of the model\nuncertainty. For the proof-of-concept, our method is applied to proton therapy\ndose prediction in head and neck cancer patients. Accuracy, time-gain, and OOD\ndetection are analyzed for our method in this particular application and\ncompared with the popular MCDO and DE. The input reconstruction method showed a\nhigher Pearson correlation coefficient with the prediction error (0.620) than\nDE and MCDO (between 0.447 and 0.612). Moreover, our method allows an easier\nidentification of OOD (Z-score of 34.05). It estimates the uncertainty\nsimultaneously to the regression task, therefore requires less time or\ncomputational resources.",
            "author": [
                "Margerie Huet-Dastarac",
                "Dan Nguyen",
                "Steve Jiang",
                "John Lee",
                "Ana Barragan Montero"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19686v1",
                "http://arxiv.org/pdf/2310.19686v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19685v3",
            "title": "DGFN: Double Generative Flow Networks",
            "updated": "2023-11-06T19:23:27Z",
            "published": "2023-10-30T16:04:02Z",
            "summary": "Deep learning is emerging as an effective tool in drug discovery, with\npotential applications in both predictive and generative models. Generative\nFlow Networks (GFlowNets/GFNs) are a recently introduced method recognized for\nthe ability to generate diverse candidates, in particular in small molecule\ngeneration tasks. In this work, we introduce double GFlowNets (DGFNs). Drawing\ninspiration from reinforcement learning and Double Deep Q-Learning, we\nintroduce a target network used to sample trajectories, while updating the main\nnetwork with these sampled trajectories. Empirical results confirm that DGFNs\neffectively enhance exploration in sparse reward domains and high-dimensional\nstate spaces, both challenging aspects of de-novo design in drug discovery.",
            "author": [
                "Elaine Lau",
                "Nikhil Vemgal",
                "Doina Precup",
                "Emmanuel Bengio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19685v3",
                "http://arxiv.org/pdf/2310.19685v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19684v1",
            "title": "Density Estimation for Entry Guidance Problems using Deep Learning",
            "updated": "2023-10-30T16:03:37Z",
            "published": "2023-10-30T16:03:37Z",
            "summary": "This work presents a deep-learning approach to estimate atmospheric density\nprofiles for use in planetary entry guidance problems. A long short-term memory\n(LSTM) neural network is trained to learn the mapping between measurements\navailable onboard an entry vehicle and the density profile through which it is\nflying. Measurements include the spherical state representation, Cartesian\nsensed acceleration components, and a surface-pressure measurement. Training\ndata for the network is initially generated by performing a Monte Carlo\nanalysis of an entry mission at Mars using the fully numerical\npredictor-corrector guidance (FNPEG) algorithm that utilizes an exponential\ndensity model, while the truth density profiles are sampled from MarsGRAM. A\ncurriculum learning procedure is developed to refine the LSTM network's\npredictions for integration within the FNPEG algorithm. The trained LSTM is\ncapable of both predicting the density profile through which the vehicle will\nfly and reconstructing the density profile through which it has already flown.\nThe performance of the FNPEG algorithm is assessed for three different density\nestimation techniques: an exponential model, an exponential model augmented\nwith a first-order fading-memory filter, and the LSTM network. Results\ndemonstrate that using the LSTM model results in superior terminal accuracy\ncompared to the other two techniques when considering both noisy and noiseless\nmeasurements.",
            "author": [
                "Jens A. Rataczak",
                "Davide Amato",
                "Jay W. McMahon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19684v1",
                "http://arxiv.org/pdf/2310.19684v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19683v1",
            "title": "An Online Bootstrap for Time Series",
            "updated": "2023-10-30T16:03:11Z",
            "published": "2023-10-30T16:03:11Z",
            "summary": "Resampling methods such as the bootstrap have proven invaluable in the field\nof machine learning. However, the applicability of traditional bootstrap\nmethods is limited when dealing with large streams of dependent data, such as\ntime series or spatially correlated observations. In this paper, we propose a\nnovel bootstrap method that is designed to account for data dependencies and\ncan be executed online, making it particularly suitable for real-time\napplications. This method is based on an autoregressive sequence of\nincreasingly dependent resampling weights. We prove the theoretical validity of\nthe proposed bootstrap scheme under general conditions. We demonstrate the\neffectiveness of our approach through extensive simulations and show that it\nprovides reliable uncertainty quantification even in the presence of complex\ndata dependencies. Our work bridges the gap between classical resampling\ntechniques and the demands of modern data analysis, providing a valuable tool\nfor researchers and practitioners in dynamic, data-rich environments.",
            "author": [
                "Nicolai Palm",
                "Thomas Nagler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19683v1",
                "http://arxiv.org/pdf/2310.19683v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.CO",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19680v3",
            "title": "Integrating Pre-trained Language Model into Neural Machine Translation",
            "updated": "2023-11-22T16:12:39Z",
            "published": "2023-10-30T16:00:13Z",
            "summary": "Neural Machine Translation (NMT) has become a significant technology in\nnatural language processing through extensive research and development.\nHowever, the deficiency of high-quality bilingual language pair data still\nposes a major challenge to improving NMT performance. Recent studies have been\nexploring the use of contextual information from pre-trained language model\n(PLM) to address this problem. Yet, the issue of incompatibility between PLM\nand NMT model remains unresolved. This study proposes PLM-integrated NMT\n(PiNMT) model to overcome the identified problems. PiNMT model consists of\nthree critical components, PLM Multi Layer Converter, Embedding Fusion, and\nCosine Alignment, each playing a vital role in providing effective PLM\ninformation to NMT. Furthermore, two training strategies, Separate Learning\nRates and Dual Step Training, are also introduced in this paper. By\nimplementing the proposed PiNMT model and training strategy, we achieve\nstate-of-the-art performance on the IWSLT'14 En$\\leftrightarrow$De dataset.\nThis study's outcomes are noteworthy as they demonstrate a novel approach for\nefficiently integrating PLM with NMT to overcome incompatibility and enhance\nperformance.",
            "author": [
                "Soon-Jae Hwang",
                "Chang-Sung Jeong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19680v3",
                "http://arxiv.org/pdf/2310.19680v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19676v1",
            "title": "HyPE: Attention with Hyperbolic Biases for Relative Positional Encoding",
            "updated": "2023-10-30T15:54:32Z",
            "published": "2023-10-30T15:54:32Z",
            "summary": "In Transformer-based architectures, the attention mechanism is inherently\npermutation-invariant with respect to the input sequence's tokens. To impose\nsequential order, token positions are typically encoded using a scheme with\neither fixed or learnable parameters. We introduce Hyperbolic Positional\nEncoding (HyPE), a novel method that utilizes hyperbolic functions' properties\nto encode tokens' relative positions. This approach biases the attention\nmechanism without the necessity of storing the $O(L^2)$ values of the mask,\nwith $L$ being the length of the input sequence. HyPE leverages preliminary\nconcatenation operations and matrix multiplications, facilitating the encoding\nof relative distances indirectly incorporating biases into the softmax\ncomputation. This design ensures compatibility with FlashAttention-2 and\nsupports the gradient backpropagation for any potential learnable parameters\nwithin the encoding. We analytically demonstrate that, by careful\nhyperparameter selection, HyPE can approximate the attention bias of ALiBi,\nthereby offering promising generalization capabilities for contexts extending\nbeyond the lengths encountered during pretraining. The experimental evaluation\nof HyPE is proposed as a direction for future research.",
            "author": [
                "Giorgio Angelotti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19676v1",
                "http://arxiv.org/pdf/2310.19676v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19675v1",
            "title": "A Principled Hierarchical Deep Learning Approach to Joint Image\n  Compression and Classification",
            "updated": "2023-10-30T15:52:18Z",
            "published": "2023-10-30T15:52:18Z",
            "summary": "Among applications of deep learning (DL) involving low cost sensors, remote\nimage classification involves a physical channel that separates edge sensors\nand cloud classifiers. Traditional DL models must be divided between an encoder\nfor the sensor and the decoder + classifier at the edge server. An important\nchallenge is to effectively train such distributed models when the connecting\nchannels have limited rate/capacity. Our goal is to optimize DL models such\nthat the encoder latent requires low channel bandwidth while still delivers\nfeature information for high classification accuracy. This work proposes a\nthree-step joint learning strategy to guide encoders to extract features that\nare compact, discriminative, and amenable to common\naugmentations/transformations. We optimize latent dimension through an initial\nscreening phase before end-to-end (E2E) training. To obtain an adjustable bit\nrate via a single pre-deployed encoder, we apply entropy-based quantization\nand/or manual truncation on the latent representations. Tests show that our\nproposed method achieves accuracy improvement of up to 1.5% on CIFAR-10 and 3%\non CIFAR-100 over conventional E2E cross-entropy training.",
            "author": [
                "Siyu Qi",
                "Achintha Wijesinghe",
                "Lahiru D. Chamain",
                "Zhi Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19675v1",
                "http://arxiv.org/pdf/2310.19675v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19852v2",
            "title": "AI Alignment: A Comprehensive Survey",
            "updated": "2023-11-01T14:18:52Z",
            "published": "2023-10-30T15:52:15Z",
            "summary": "AI alignment aims to make AI systems behave in line with human intentions and\nvalues. As AI systems grow more capable, the potential large-scale risks\nassociated with misaligned AI systems become salient. Hundreds of AI experts\nand public figures have expressed concerns about AI risks, arguing that\n\"mitigating the risk of extinction from AI should be a global priority,\nalongside other societal-scale risks such as pandemics and nuclear war\". To\nprovide a comprehensive and up-to-date overview of the alignment field, in this\nsurvey paper, we delve into the core concepts, methodology, and practice of\nalignment. We identify the RICE principles as the key objectives of AI\nalignment: Robustness, Interpretability, Controllability, and Ethicality.\nGuided by these four principles, we outline the landscape of current alignment\nresearch and decompose them into two key components: forward alignment and\nbackward alignment. The former aims to make AI systems aligned via alignment\ntraining, while the latter aims to gain evidence about the systems' alignment\nand govern them appropriately to avoid exacerbating misalignment risks. Forward\nalignment and backward alignment form a recurrent process where the alignment\nof AI systems from the forward process is verified in the backward process,\nmeanwhile providing updated objectives for forward alignment in the next round.\nOn forward alignment, we discuss learning from feedback and learning under\ndistribution shift. On backward alignment, we discuss assurance techniques and\ngovernance practices that apply to every stage of AI systems' lifecycle.\n  We also release and continually update the website (www.alignmentsurvey.com)\nwhich features tutorials, collections of papers, blog posts, and other\nresources.",
            "author": [
                "Jiaming Ji",
                "Tianyi Qiu",
                "Boyuan Chen",
                "Borong Zhang",
                "Hantao Lou",
                "Kaile Wang",
                "Yawen Duan",
                "Zhonghao He",
                "Jiayi Zhou",
                "Zhaowei Zhang",
                "Fanzhi Zeng",
                "Kwan Yee Ng",
                "Juntao Dai",
                "Xuehai Pan",
                "Aidan O'Gara",
                "Yingshan Lei",
                "Hua Xu",
                "Brian Tse",
                "Jie Fu",
                "Stephen McAleer",
                "Yaodong Yang",
                "Yizhou Wang",
                "Song-Chun Zhu",
                "Yike Guo",
                "Wen Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19852v2",
                "http://arxiv.org/pdf/2310.19852v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19671v2",
            "title": "Large Language Models: The Need for Nuance in Current Debates and a\n  Pragmatic Perspective on Understanding",
            "updated": "2023-10-31T08:17:29Z",
            "published": "2023-10-30T15:51:04Z",
            "summary": "Current Large Language Models (LLMs) are unparalleled in their ability to\ngenerate grammatically correct, fluent text. LLMs are appearing rapidly, and\ndebates on LLM capacities have taken off, but reflection is lagging behind.\nThus, in this position paper, we first zoom in on the debate and critically\nassess three points recurring in critiques of LLM capacities: i) that LLMs only\nparrot statistical patterns in the training data; ii) that LLMs master formal\nbut not functional language competence; and iii) that language learning in LLMs\ncannot inform human language learning. Drawing on empirical and theoretical\narguments, we show that these points need more nuance. Second, we outline a\npragmatic perspective on the issue of `real' understanding and intentionality\nin LLMs. Understanding and intentionality pertain to unobservable mental states\nwe attribute to other humans because they have pragmatic value: they allow us\nto abstract away from complex underlying mechanics and predict behaviour\neffectively. We reflect on the circumstances under which it would make sense\nfor humans to similarly attribute mental states to LLMs, thereby outlining a\npragmatic philosophical context for LLMs as an increasingly prominent\ntechnology in society.",
            "author": [
                "Bram M. A. van Dijk",
                "Tom Kouwenhoven",
                "Marco R. Spruit",
                "Max J. van Duijn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19671v2",
                "http://arxiv.org/pdf/2310.19671v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19670v1",
            "title": "Spatiotemporal Attention Enhances Lidar-Based Robot Navigation in\n  Dynamic Environments",
            "updated": "2023-10-30T15:50:59Z",
            "published": "2023-10-30T15:50:59Z",
            "summary": "Foresighted robot navigation in dynamic indoor environments with\ncost-efficient hardware necessitates the use of a lightweight yet dependable\ncontroller. So inferring the scene dynamics from sensor readings without\nexplicit object tracking is a pivotal aspect of foresighted navigation among\npedestrians. In this paper, we introduce a spatiotemporal attention pipeline\nfor enhanced navigation based on 2D lidar sensor readings. This pipeline is\ncomplemented by a novel lidar-state representation that emphasizes dynamic\nobstacles over static ones. Subsequently, the attention mechanism enables\nselective scene perception across both space and time, resulting in improved\noverall navigation performance within dynamic scenarios. We thoroughly\nevaluated the approach in different scenarios and simulators, finding good\ngeneralization to unseen environments. The results demonstrate outstanding\nperformance compared to state-of-the-art methods, thereby enabling the seamless\ndeployment of the learned controller on a real robot.",
            "author": [
                "Jorge de Heuvel",
                "Xiangyu Zeng",
                "Weixian Shi",
                "Tharun Sethuraman",
                "Maren Bennewitz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19670v1",
                "http://arxiv.org/pdf/2310.19670v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19668v1",
            "title": "DrM: Mastering Visual Reinforcement Learning through Dormant Ratio\n  Minimization",
            "updated": "2023-10-30T15:50:56Z",
            "published": "2023-10-30T15:50:56Z",
            "summary": "Visual reinforcement learning (RL) has shown promise in continuous control\ntasks. Despite its progress, current algorithms are still unsatisfactory in\nvirtually every aspect of the performance such as sample efficiency, asymptotic\nperformance, and their robustness to the choice of random seeds. In this paper,\nwe identify a major shortcoming in existing visual RL methods that is the\nagents often exhibit sustained inactivity during early training, thereby\nlimiting their ability to explore effectively. Expanding upon this crucial\nobservation, we additionally unveil a significant correlation between the\nagents' inclination towards motorically inactive exploration and the absence of\nneuronal activity within their policy networks. To quantify this inactivity, we\nadopt dormant ratio as a metric to measure inactivity in the RL agent's\nnetwork. Empirically, we also recognize that the dormant ratio can act as a\nstandalone indicator of an agent's activity level, regardless of the received\nreward signals. Leveraging the aforementioned insights, we introduce DrM, a\nmethod that uses three core mechanisms to guide agents'\nexploration-exploitation trade-offs by actively minimizing the dormant ratio.\nExperiments demonstrate that DrM achieves significant improvements in sample\nefficiency and asymptotic performance with no broken seeds (76 seeds in total)\nacross three continuous control benchmark environments, including DeepMind\nControl Suite, MetaWorld, and Adroit. Most importantly, DrM is the first\nmodel-free algorithm that consistently solves tasks in both the Dog and\nManipulator domains from the DeepMind Control Suite as well as three dexterous\nhand manipulation tasks without demonstrations in Adroit, all based on pixel\nobservations.",
            "author": [
                "Guowei Xu",
                "Ruijie Zheng",
                "Yongyuan Liang",
                "Xiyao Wang",
                "Zhecheng Yuan",
                "Tianying Ji",
                "Yu Luo",
                "Xiaoyu Liu",
                "Jiaxin Yuan",
                "Pu Hua",
                "Shuzhen Li",
                "Yanjie Ze",
                "Hal Daum\u00e9 III",
                "Furong Huang",
                "Huazhe Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19668v1",
                "http://arxiv.org/pdf/2310.19668v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19666v1",
            "title": "Dynamic Tensor Decomposition via Neural Diffusion-Reaction Processes",
            "updated": "2023-10-30T15:49:45Z",
            "published": "2023-10-30T15:49:45Z",
            "summary": "Tensor decomposition is an important tool for multiway data analysis. In\npractice, the data is often sparse yet associated with rich temporal\ninformation. Existing methods, however, often under-use the time information\nand ignore the structural knowledge within the sparsely observed tensor\nentries. To overcome these limitations and to better capture the underlying\ntemporal structure, we propose Dynamic EMbedIngs fOr dynamic Tensor\ndEcomposition (DEMOTE). We develop a neural diffusion-reaction process to\nestimate dynamic embeddings for the entities in each tensor mode. Specifically,\nbased on the observed tensor entries, we build a multi-partite graph to encode\nthe correlation between the entities. We construct a graph diffusion process to\nco-evolve the embedding trajectories of the correlated entities and use a\nneural network to construct a reaction process for each individual entity. In\nthis way, our model can capture both the commonalities and personalities during\nthe evolution of the embeddings for different entities. We then use a neural\nnetwork to model the entry value as a nonlinear function of the embedding\ntrajectories. For model estimation, we combine ODE solvers to develop a\nstochastic mini-batch learning algorithm. We propose a stratified sampling\nmethod to balance the cost of processing each mini-batch so as to improve the\noverall efficiency. We show the advantage of our approach in both simulation\nstudy and real-world applications. The code is available at\nhttps://github.com/wzhut/Dynamic-Tensor-Decomposition-via-Neural-Diffusion-Reaction-Processes.",
            "author": [
                "Zheng Wang",
                "Shikai Fang",
                "Shibo Li",
                "Shandian Zhe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19666v1",
                "http://arxiv.org/pdf/2310.19666v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19658v1",
            "title": "Explaining Tree Model Decisions in Natural Language for Network\n  Intrusion Detection",
            "updated": "2023-10-30T15:40:34Z",
            "published": "2023-10-30T15:40:34Z",
            "summary": "Network intrusion detection (NID) systems which leverage machine learning\nhave been shown to have strong performance in practice when used to detect\nmalicious network traffic. Decision trees in particular offer a strong balance\nbetween performance and simplicity, but require users of NID systems to have\nbackground knowledge in machine learning to interpret. In addition, they are\nunable to provide additional outside information as to why certain features may\nbe important for classification.\n  In this work, we explore the use of large language models (LLMs) to provide\nexplanations and additional background knowledge for decision tree NID systems.\nFurther, we introduce a new human evaluation framework for decision tree\nexplanations, which leverages automatically generated quiz questions that\nmeasure human evaluators' understanding of decision tree inference. Finally, we\nshow LLM generated decision tree explanations correlate highly with human\nratings of readability, quality, and use of background knowledge while\nsimultaneously providing better understanding of decision boundaries.",
            "author": [
                "Noah Ziems",
                "Gang Liu",
                "John Flanagan",
                "Meng Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19658v1",
                "http://arxiv.org/pdf/2310.19658v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19656v1",
            "title": "Domain Generalization in Computational Pathology: Survey and Guidelines",
            "updated": "2023-10-30T15:39:19Z",
            "published": "2023-10-30T15:39:19Z",
            "summary": "Deep learning models have exhibited exceptional effectiveness in\nComputational Pathology (CPath) by tackling intricate tasks across an array of\nhistology image analysis applications. Nevertheless, the presence of\nout-of-distribution data (stemming from a multitude of sources such as\ndisparate imaging devices and diverse tissue preparation methods) can cause\n\\emph{domain shift} (DS). DS decreases the generalization of trained models to\nunseen datasets with slightly different data distributions, prompting the need\nfor innovative \\emph{domain generalization} (DG) solutions. Recognizing the\npotential of DG methods to significantly influence diagnostic and prognostic\nmodels in cancer studies and clinical practice, we present this survey along\nwith guidelines on achieving DG in CPath. We rigorously define various DS\ntypes, systematically review and categorize existing DG approaches and\nresources in CPath, and provide insights into their advantages, limitations,\nand applicability. We also conduct thorough benchmarking experiments with 28\ncutting-edge DG algorithms to address a complex DG problem. Our findings\nsuggest that careful experiment design and CPath-specific Stain Augmentation\ntechnique can be very effective. However, there is no one-size-fits-all\nsolution for DG in CPath. Therefore, we establish clear guidelines for\ndetecting and managing DS depending on different scenarios. While most of the\nconcepts, guidelines, and recommendations are given for applications in CPath,\nwe believe that they are applicable to most medical image analysis tasks as\nwell.",
            "author": [
                "Mostafa Jahanifar",
                "Manahil Raza",
                "Kesi Xu",
                "Trinh Vuong",
                "Rob Jewsbury",
                "Adam Shephard",
                "Neda Zamanitajeddin",
                "Jin Tae Kwak",
                "Shan E Ahmed Raza",
                "Fayyaz Minhas",
                "Nasir Rajpoot"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19656v1",
                "http://arxiv.org/pdf/2310.19656v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19653v2",
            "title": "Upgrading VAE Training With Unlimited Data Plans Provided by Diffusion\n  Models",
            "updated": "2023-11-24T13:02:55Z",
            "published": "2023-10-30T15:38:39Z",
            "summary": "Variational autoencoders (VAEs) are popular models for representation\nlearning but their encoders are susceptible to overfitting (Cremer et al.,\n2018) because they are trained on a finite training set instead of the true\n(continuous) data distribution $p_{\\mathrm{data}}(\\mathbf{x})$. Diffusion\nmodels, on the other hand, avoid this issue by keeping the encoder fixed. This\nmakes their representations less interpretable, but it simplifies training,\nenabling accurate and continuous approximations of\n$p_{\\mathrm{data}}(\\mathbf{x})$. In this paper, we show that overfitting\nencoders in VAEs can be effectively mitigated by training on samples from a\npre-trained diffusion model. These results are somewhat unexpected as recent\nfindings (Alemohammad et al., 2023; Shumailov et al., 2023) observe a decay in\ngenerative performance when models are trained on data generated by another\ngenerative model. We analyze generalization performance, amortization gap, and\nrobustness of VAEs trained with our proposed method on three different data\nsets. We find improvements in all metrics compared to both normal training and\nconventional data augmentation methods, and we show that a modest amount of\nsamples from the diffusion model suffices to obtain these gains.",
            "author": [
                "Tim Z. Xiao",
                "Johannes Zenn",
                "Robert Bamler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19653v2",
                "http://arxiv.org/pdf/2310.19653v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02168v2",
            "title": "The SVHN Dataset Is Deceptive for Probabilistic Generative Models Due to\n  a Distribution Mismatch",
            "updated": "2023-12-06T05:16:37Z",
            "published": "2023-10-30T15:38:31Z",
            "summary": "The Street View House Numbers (SVHN) dataset is a popular benchmark dataset\nin deep learning. Originally designed for digit classification tasks, the SVHN\ndataset has been widely used as a benchmark for various other tasks including\ngenerative modeling. However, with this work, we aim to warn the community\nabout an issue of the SVHN dataset as a benchmark for generative modeling\ntasks: we discover that the official split into training set and test set of\nthe SVHN dataset are not drawn from the same distribution. We empirically show\nthat this distribution mismatch has little impact on the classification task\n(which may explain why this issue has not been detected before), but it\nseverely affects the evaluation of probabilistic generative models, such as\nVariational Autoencoders and diffusion models. As a workaround, we propose to\nmix and re-split the official training and test set when SVHN is used for tasks\nother than classification. We publish a new split and the indices we used to\ncreate it at https://jzenn.github.io/svhn-remix/ .",
            "author": [
                "Tim Z. Xiao",
                "Johannes Zenn",
                "Robert Bamler"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02168v2",
                "http://arxiv.org/pdf/2312.02168v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19650v1",
            "title": "KeyGen2Vec: Learning Document Embedding via Multi-label Keyword\n  Generation in Question-Answering",
            "updated": "2023-10-30T15:35:45Z",
            "published": "2023-10-30T15:35:45Z",
            "summary": "Representing documents into high dimensional embedding space while preserving\nthe structural similarity between document sources has been an ultimate goal\nfor many works on text representation learning. Current embedding models,\nhowever, mainly rely on the availability of label supervision to increase the\nexpressiveness of the resulting embeddings. In contrast, unsupervised\nembeddings are cheap, but they often cannot capture implicit structure in\ntarget corpus, particularly for samples that come from different distribution\nwith the pretraining source.\n  Our study aims to loosen up the dependency on label supervision by learning\ndocument embeddings via Sequence-to-Sequence (Seq2Seq) text generator.\nSpecifically, we reformulate keyphrase generation task into multi-label keyword\ngeneration in community-based Question Answering (cQA). Our empirical results\nshow that KeyGen2Vec in general is superior than multi-label keyword classifier\nby up to 14.7% based on Purity, Normalized Mutual Information (NMI), and\nF1-Score metrics. Interestingly, although in general the absolute advantage of\nlearning embeddings through label supervision is highly positive across\nevaluation datasets, KeyGen2Vec is shown to be competitive with classifier that\nexploits topic label supervision in Yahoo! cQA with larger number of latent\ntopic labels.",
            "author": [
                "Iftitahu Ni'mah",
                "Samaneh Khoshrou",
                "Vlado Menkovski",
                "Mykola Pechenizkiy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19650v1",
                "http://arxiv.org/pdf/2310.19650v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19647v2",
            "title": "Fast swap regret minimization and applications to approximate correlated\n  equilibria",
            "updated": "2023-11-14T17:39:27Z",
            "published": "2023-10-30T15:35:24Z",
            "summary": "We give a simple and computationally efficient algorithm that, for any\nconstant $\\varepsilon>0$, obtains $\\varepsilon T$-swap regret within only $T =\n\\mathsf{polylog}(n)$ rounds; this is an exponential improvement compared to the\nsuper-linear number of rounds required by the state-of-the-art algorithm, and\nresolves the main open problem of [Blum and Mansour 2007]. Our algorithm has an\nexponential dependence on $\\varepsilon$, but we prove a new, matching lower\nbound.\n  Our algorithm for swap regret implies faster convergence to\n$\\varepsilon$-Correlated Equilibrium ($\\varepsilon$-CE) in several regimes: For\nnormal form two-player games with $n$ actions, it implies the first uncoupled\ndynamics that converges to the set of $\\varepsilon$-CE in polylogarithmic\nrounds; a $\\mathsf{polylog}(n)$-bit communication protocol for $\\varepsilon$-CE\nin two-player games (resolving an open problem mentioned by\n[Babichenko-Rubinstein'2017, Goos-Rubinstein'2018, Ganor-CS'2018]); and an\n$\\tilde{O}(n)$-query algorithm for $\\varepsilon$-CE (resolving an open problem\nof [Babichenko'2020] and obtaining the first separation between\n$\\varepsilon$-CE and $\\varepsilon$-Nash equilibrium in the query complexity\nmodel).\n  For extensive-form games, our algorithm implies a PTAS for $\\mathit{normal}$\n$\\mathit{form}$ $\\mathit{correlated}$ $\\mathit{equilibria}$, a solution concept\noften conjectured to be computationally intractable (e.g. [Stengel-Forges'08,\nFujii'23]).",
            "author": [
                "Binghui Peng",
                "Aviad Rubinstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19647v2",
                "http://arxiv.org/pdf/2310.19647v2"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.AI",
                "cs.DS",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19636v1",
            "title": "Leave No Stone Unturned: Mine Extra Knowledge for Imbalanced Facial\n  Expression Recognition",
            "updated": "2023-10-30T15:26:26Z",
            "published": "2023-10-30T15:26:26Z",
            "summary": "Facial expression data is characterized by a significant imbalance, with most\ncollected data showing happy or neutral expressions and fewer instances of fear\nor disgust. This imbalance poses challenges to facial expression recognition\n(FER) models, hindering their ability to fully understand various human\nemotional states. Existing FER methods typically report overall accuracy on\nhighly imbalanced test sets but exhibit low performance in terms of the mean\naccuracy across all expression classes. In this paper, our aim is to address\nthe imbalanced FER problem. Existing methods primarily focus on learning\nknowledge of minor classes solely from minor-class samples. However, we propose\na novel approach to extract extra knowledge related to the minor classes from\nboth major and minor class samples. Our motivation stems from the belief that\nFER resembles a distribution learning task, wherein a sample may contain\ninformation about multiple classes. For instance, a sample from the major class\nsurprise might also contain useful features of the minor class fear. Inspired\nby that, we propose a novel method that leverages re-balanced attention maps to\nregularize the model, enabling it to extract transformation invariant\ninformation about the minor classes from all training samples. Additionally, we\nintroduce re-balanced smooth labels to regulate the cross-entropy loss, guiding\nthe model to pay more attention to the minor classes by utilizing the extra\ninformation regarding the label distribution of the imbalanced training data.\nExtensive experiments on different datasets and backbones show that the two\nproposed modules work together to regularize the model and achieve\nstate-of-the-art performance under the imbalanced FER task. Code is available\nat https://github.com/zyh-uaiaaaa.",
            "author": [
                "Yuhang Zhang",
                "Yaqi Li",
                "Lixiong Qin",
                "Xuannan Liu",
                "Weihong Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19636v1",
                "http://arxiv.org/pdf/2310.19636v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19635v1",
            "title": "Bidirectional Captioning for Clinically Accurate and Interpretable\n  Models",
            "updated": "2023-10-30T15:25:29Z",
            "published": "2023-10-30T15:25:29Z",
            "summary": "Vision-language pretraining has been shown to produce high-quality visual\nencoders which transfer efficiently to downstream computer vision tasks. While\ngenerative language models have gained widespread attention, image captioning\nhas thus far been mostly overlooked as a form of cross-modal pretraining in\nfavor of contrastive learning, especially in medical image analysis. In this\npaper, we experiment with bidirectional captioning of radiology reports as a\nform of pretraining and compare the quality and utility of learned embeddings\nwith those from contrastive pretraining methods. We optimize a CNN encoder,\ntransformer decoder architecture named RadTex for the radiology domain. Results\nshow that not only does captioning pretraining yield visual encoders that are\ncompetitive with contrastive pretraining (CheXpert competition multi-label AUC\nof 89.4%), but also that our transformer decoder is capable of generating\nclinically relevant reports (captioning macro-F1 score of 0.349 using CheXpert\nlabeler) and responding to prompts with targeted, interactive outputs.",
            "author": [
                "Keegan Quigley",
                "Miriam Cha",
                "Josh Barua",
                "Geeticka Chauhan",
                "Seth Berkowitz",
                "Steven Horng",
                "Polina Golland"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19635v1",
                "http://arxiv.org/pdf/2310.19635v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19849v1",
            "title": "Predicting mutational effects on protein-protein binding via a\n  side-chain diffusion probabilistic model",
            "updated": "2023-10-30T15:23:42Z",
            "published": "2023-10-30T15:23:42Z",
            "summary": "Many crucial biological processes rely on networks of protein-protein\ninteractions. Predicting the effect of amino acid mutations on protein-protein\nbinding is vital in protein engineering and therapeutic discovery. However, the\nscarcity of annotated experimental data on binding energy poses a significant\nchallenge for developing computational approaches, particularly deep\nlearning-based methods. In this work, we propose SidechainDiff, a\nrepresentation learning-based approach that leverages unlabelled experimental\nprotein structures. SidechainDiff utilizes a Riemannian diffusion model to\nlearn the generative process of side-chain conformations and can also give the\nstructural context representations of mutations on the protein-protein\ninterface. Leveraging the learned representations, we achieve state-of-the-art\nperformance in predicting the mutational effects on protein-protein binding.\nFurthermore, SidechainDiff is the first diffusion-based generative model for\nside-chains, distinguishing it from prior efforts that have predominantly\nfocused on generating protein backbone structures.",
            "author": [
                "Shiwei Liu",
                "Tian Zhu",
                "Milong Ren",
                "Chungong Yu",
                "Dongbo Bu",
                "Haicang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19849v1",
                "http://arxiv.org/pdf/2310.19849v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19629v1",
            "title": "RayDF: Neural Ray-surface Distance Fields with Multi-view Consistency",
            "updated": "2023-10-30T15:22:50Z",
            "published": "2023-10-30T15:22:50Z",
            "summary": "In this paper, we study the problem of continuous 3D shape representations.\nThe majority of existing successful methods are coordinate-based implicit\nneural representations. However, they are inefficient to render novel views or\nrecover explicit surface points. A few works start to formulate 3D shapes as\nray-based neural functions, but the learned structures are inferior due to the\nlack of multi-view geometry consistency. To tackle these challenges, we propose\na new framework called RayDF. It consists of three major components: 1) the\nsimple ray-surface distance field, 2) the novel dual-ray visibility classifier,\nand 3) a multi-view consistency optimization module to drive the learned\nray-surface distances to be multi-view geometry consistent. We extensively\nevaluate our method on three public datasets, demonstrating remarkable\nperformance in 3D surface point reconstruction on both synthetic and\nchallenging real-world 3D scenes, clearly surpassing existing coordinate-based\nand ray-based baselines. Most notably, our method achieves a 1000x faster speed\nthan coordinate-based methods to render an 800x800 depth image, showing the\nsuperiority of our method for 3D shape representation. Our code and data are\navailable at https://github.com/vLAR-group/RayDF",
            "author": [
                "Zhuoman Liu",
                "Bo Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19629v1",
                "http://arxiv.org/pdf/2310.19629v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19624v1",
            "title": "Exploring Post-Training Quantization of Protein Language Models",
            "updated": "2023-10-30T15:18:06Z",
            "published": "2023-10-30T15:18:06Z",
            "summary": "Recent advancements in unsupervised protein language models (ProteinLMs),\nlike ESM-1b and ESM-2, have shown promise in different protein prediction\ntasks. However, these models face challenges due to their high computational\ndemands, significant memory needs, and latency, restricting their usage on\ndevices with limited resources. To tackle this, we explore post-training\nquantization (PTQ) for ProteinLMs, focusing on ESMFold, a simplified version of\nAlphaFold based on ESM-2 ProteinLM. Our study is the first attempt to quantize\nall weights and activations of ProteinLMs. We observed that the typical uniform\nquantization method performs poorly on ESMFold, causing a significant drop in\nTM-Score when using 8-bit quantization. We conducted extensive quantization\nexperiments, uncovering unique challenges associated with ESMFold, particularly\nhighly asymmetric activation ranges before Layer Normalization, making\nrepresentation difficult using low-bit fixed-point formats. To address these\nchallenges, we propose a new PTQ method for ProteinLMs, utilizing piecewise\nlinear quantization for asymmetric activation values to ensure accurate\napproximation. We demonstrated the effectiveness of our method in protein\nstructure prediction tasks, demonstrating that ESMFold can be accurately\nquantized to low-bit widths without compromising accuracy. Additionally, we\napplied our method to the contact prediction task, showcasing its versatility.\nIn summary, our study introduces an innovative PTQ method for ProteinLMs,\naddressing specific quantization challenges and potentially leading to the\ndevelopment of more efficient ProteinLMs with significant implications for\nvarious protein-related applications.",
            "author": [
                "Shuang Peng",
                "Fei Yang",
                "Ning Sun",
                "Sheng Chen",
                "Yanfeng Jiang",
                "Aimin Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19624v1",
                "http://arxiv.org/pdf/2310.19624v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19621v1",
            "title": "A Bayesian Methodology for Estimation for Sparse Canonical Correlation",
            "updated": "2023-10-30T15:14:25Z",
            "published": "2023-10-30T15:14:25Z",
            "summary": "It can be challenging to perform an integrative statistical analysis of\nmulti-view high-dimensional data acquired from different experiments on each\nsubject who participated in a joint study. Canonical Correlation Analysis (CCA)\nis a statistical procedure for identifying relationships between such data\nsets. In that context, Structured Sparse CCA (ScSCCA) is a rapidly emerging\nmethodological area that aims for robust modeling of the interrelations between\nthe different data modalities by assuming the corresponding CCA directional\nvectors to be sparse. Although it is a rapidly growing area of statistical\nmethodology development, there is a need for developing related methodologies\nin the Bayesian paradigm. In this manuscript, we propose a novel ScSCCA\napproach where we employ a Bayesian infinite factor model and aim to achieve\nrobust estimation by encouraging sparsity in two different levels of the\nmodeling framework. Firstly, we utilize a multiplicative Half-Cauchy process\nprior to encourage sparsity at the level of the latent variable loading\nmatrices. Additionally, we promote further sparsity in the covariance matrix by\nusing graphical horseshoe prior or diagonal structure. We conduct multiple\nsimulations to compare the performance of the proposed method with that of\nother frequently used CCA procedures, and we apply the developed procedures to\nanalyze multi-omics data arising from a breast cancer study.",
            "author": [
                "Siddhesh Kulkarni",
                "Subhadip Pal",
                "Jeremy T. Gaskins"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19621v1",
                "http://arxiv.org/pdf/2310.19621v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML",
                "62, 60"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19620v1",
            "title": "Large Trajectory Models are Scalable Motion Predictors and Planners",
            "updated": "2023-10-30T15:12:41Z",
            "published": "2023-10-30T15:12:41Z",
            "summary": "Motion prediction and planning are vital tasks in autonomous driving, and\nrecent efforts have shifted to machine learning-based approaches. The\nchallenges include understanding diverse road topologies, reasoning traffic\ndynamics over a long time horizon, interpreting heterogeneous behaviors, and\ngenerating policies in a large continuous state space. Inspired by the success\nof large language models in addressing similar complexities through model\nscaling, we introduce a scalable trajectory model called State Transformer\n(STR). STR reformulates the motion prediction and motion planning problems by\narranging observations, states, and actions into one unified sequence modeling\ntask. With a simple model design, STR consistently outperforms baseline\napproaches in both problems. Remarkably, experimental results reveal that large\ntrajectory models (LTMs), such as STR, adhere to the scaling laws by presenting\noutstanding adaptability and learning efficiency. Qualitative results further\ndemonstrate that LTMs are capable of making plausible predictions in scenarios\nthat diverge significantly from the training data distribution. LTMs also learn\nto make complex reasonings for long-term planning, without explicit loss\ndesigns or costly high-level annotations.",
            "author": [
                "Qiao Sun",
                "Shiduo Zhang",
                "Danjiao Ma",
                "Jingzhe Shi",
                "Derun Li",
                "Simian Luo",
                "Yu Wang",
                "Ningyi Xu",
                "Guangzhi Cao",
                "Hang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19620v1",
                "http://arxiv.org/pdf/2310.19620v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19614v1",
            "title": "Dis-inhibitory neuronal circuits can control the sign of synaptic\n  plasticity",
            "updated": "2023-10-30T15:06:19Z",
            "published": "2023-10-30T15:06:19Z",
            "summary": "How neuronal circuits achieve credit assignment remains a central unsolved\nquestion in systems neuroscience. Various studies have suggested plausible\nsolutions for back-propagating error signals through multi-layer networks.\nThese purely functionally motivated models assume distinct neuronal\ncompartments to represent local error signals that determine the sign of\nsynaptic plasticity. However, this explicit error modulation is inconsistent\nwith phenomenological plasticity models in which the sign depends primarily on\npostsynaptic activity. Here we show how a plausible microcircuit model and\nHebbian learning rule derived within an adaptive control theory framework can\nresolve this discrepancy. Assuming errors are encoded in top-down\ndis-inhibitory synaptic afferents, we show that error-modulated learning\nemerges naturally at the circuit level when recurrent inhibition explicitly\ninfluences Hebbian plasticity. The same learning rule accounts for\nexperimentally observed plasticity in the absence of inhibition and performs\ncomparably to back-propagation of error (BP) on several non-linearly separable\nbenchmarks. Our findings bridge the gap between functional and experimentally\nobserved plasticity rules and make concrete predictions on inhibitory\nmodulation of excitatory plasticity.",
            "author": [
                "Julian Rossbroich",
                "Friedemann Zenke"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19614v1",
                "http://arxiv.org/pdf/2310.19614v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19848v1",
            "title": "Efficient Exploration in Continuous-time Model-based Reinforcement\n  Learning",
            "updated": "2023-10-30T15:04:40Z",
            "published": "2023-10-30T15:04:40Z",
            "summary": "Reinforcement learning algorithms typically consider discrete-time dynamics,\neven though the underlying systems are often continuous in time. In this paper,\nwe introduce a model-based reinforcement learning algorithm that represents\ncontinuous-time dynamics using nonlinear ordinary differential equations\n(ODEs). We capture epistemic uncertainty using well-calibrated probabilistic\nmodels, and use the optimistic principle for exploration. Our regret bounds\nsurface the importance of the measurement selection strategy(MSS), since in\ncontinuous time we not only must decide how to explore, but also when to\nobserve the underlying system. Our analysis demonstrates that the regret is\nsublinear when modeling ODEs with Gaussian Processes (GP) for common choices of\nMSS, such as equidistant sampling. Additionally, we propose an adaptive,\ndata-dependent, practical MSS that, when combined with GP dynamics, also\nachieves sublinear regret with significantly fewer samples. We showcase the\nbenefits of continuous-time modeling over its discrete-time counterpart, as\nwell as our proposed adaptive MSS over standard baselines, on several\napplications.",
            "author": [
                "Lenart Treven",
                "Jonas H\u00fcbotter",
                "Bhavya Sukhija",
                "Florian D\u00f6rfler",
                "Andreas Krause"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19848v1",
                "http://arxiv.org/pdf/2310.19848v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19608v1",
            "title": "On Feynman--Kac training of partial Bayesian neural networks",
            "updated": "2023-10-30T15:03:15Z",
            "published": "2023-10-30T15:03:15Z",
            "summary": "Recently, partial Bayesian neural networks (pBNNs), which only consider a\nsubset of the parameters to be stochastic, were shown to perform competitively\nwith full Bayesian neural networks. However, pBNNs are often multi-modal in the\nlatent-variable space and thus challenging to approximate with parametric\nmodels. To address this problem, we propose an efficient sampling-based\ntraining strategy, wherein the training of a pBNN is formulated as simulating a\nFeynman--Kac model. We then describe variations of sequential Monte Carlo\nsamplers that allow us to simultaneously estimate the parameters and the latent\nposterior distribution of this model at a tractable computational cost. We show\non various synthetic and real-world datasets that our proposed training scheme\noutperforms the state of the art in terms of predictive performance.",
            "author": [
                "Zheng Zhao",
                "Sebastian Mair",
                "Thomas B. Sch\u00f6n",
                "Jens Sj\u00f6lund"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19608v1",
                "http://arxiv.org/pdf/2310.19608v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19607v1",
            "title": "Technical Report on the Learning of Case Relevance in Case-Based\n  Reasoning with Abstract Argumentation",
            "updated": "2023-10-30T15:01:41Z",
            "published": "2023-10-30T15:01:41Z",
            "summary": "Case-based reasoning is known to play an important role in several legal\nsettings. In this paper we focus on a recent approach to case-based reasoning,\nsupported by an instantiation of abstract argumentation whereby arguments\nrepresent cases and attack between arguments results from outcome disagreement\nbetween cases and a notion of relevance. In this context, relevance is\nconnected to a form of specificity among cases. We explore how relevance can be\nlearnt automatically in practice with the help of decision trees, and explore\nthe combination of case-based reasoning with abstract argumentation (AA-CBR)\nand learning of case relevance for prediction in legal settings. Specifically,\nwe show that, for two legal datasets, AA-CBR and decision-tree-based learning\nof case relevance perform competitively in comparison with decision trees. We\nalso show that AA-CBR with decision-tree-based learning of case relevance\nresults in a more compact representation than their decision tree counterparts,\nwhich could be beneficial for obtaining cognitively tractable explanations.",
            "author": [
                "Guilherme Paulino-Passos",
                "Francesca Toni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19607v1",
                "http://arxiv.org/pdf/2310.19607v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19603v1",
            "title": "Deep Kalman Filters Can Filter",
            "updated": "2023-10-30T14:58:12Z",
            "published": "2023-10-30T14:58:12Z",
            "summary": "Deep Kalman filters (DKFs) are a class of neural network models that generate\nGaussian probability measures from sequential data. Though DKFs are inspired by\nthe Kalman filter, they lack concrete theoretical ties to the stochastic\nfiltering problem, thus limiting their applicability to areas where traditional\nmodel-based filters have been used, e.g.\\ model calibration for bond and option\nprices in mathematical finance. We address this issue in the mathematical\nfoundations of deep learning by exhibiting a class of continuous-time DKFs\nwhich can approximately implement the conditional law of a broad class of\nnon-Markovian and conditionally Gaussian signal processes given noisy\ncontinuous-times measurements. Our approximation results hold uniformly over\nsufficiently regular compact subsets of paths, where the approximation error is\nquantified by the worst-case 2-Wasserstein distance computed uniformly over the\ngiven compact set of paths.",
            "author": [
                "Blanka Hovart",
                "Anastasis Kratsios",
                "Yannick Limmer",
                "Xuwei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19603v1",
                "http://arxiv.org/pdf/2310.19603v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "cs.NE",
                "math.NA",
                "math.PR",
                "stat.ML",
                "60G35, 62M20, 68T07, 41A65"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19602v1",
            "title": "DCHT: Deep Complex Hybrid Transformer for Speech Enhancement",
            "updated": "2023-10-30T14:58:11Z",
            "published": "2023-10-30T14:58:11Z",
            "summary": "Most of the current deep learning-based approaches for speech enhancement\nonly operate in the spectrogram or waveform domain. Although a cross-domain\ntransformer combining waveform- and spectrogram-domain inputs has been\nproposed, its performance can be further improved. In this paper, we present a\nnovel deep complex hybrid transformer that integrates both spectrogram and\nwaveform domains approaches to improve the performance of speech enhancement.\nThe proposed model consists of two parts: a complex Swin-Unet in the\nspectrogram domain and a dual-path transformer network (DPTnet) in the waveform\ndomain. We first construct a complex Swin-Unet network in the spectrogram\ndomain and perform speech enhancement in the complex audio spectrum. We then\nintroduce improved DPT by adding memory-compressed attention. Our model is\ncapable of learning multi-domain features to reduce existing noise on different\ndomains in a complementary way. The experimental results on the\nBirdSoundsDenoising dataset and the VCTK+DEMAND dataset indicate that our\nmethod can achieve better performance compared to state-of-the-art methods.",
            "author": [
                "Jialu Li",
                "Junhui Li",
                "Pu Wang",
                "Youshan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19602v1",
                "http://arxiv.org/pdf/2310.19602v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19596v2",
            "title": "LLMaAA: Making Large Language Models as Active Annotators",
            "updated": "2023-10-31T08:19:52Z",
            "published": "2023-10-30T14:54:15Z",
            "summary": "Prevalent supervised learning methods in natural language processing (NLP)\nare notoriously data-hungry, which demand large amounts of high-quality\nannotated data. In practice, acquiring such data is a costly endeavor.\nRecently, the superior few-shot performance of large language models (LLMs) has\npropelled the development of dataset generation, where the training data are\nsolely synthesized from LLMs. However, such an approach usually suffers from\nlow-quality issues, and requires orders of magnitude more labeled data to\nachieve satisfactory performance. To fully exploit the potential of LLMs and\nmake use of massive unlabeled data, we propose LLMaAA, which takes LLMs as\nannotators and puts them into an active learning loop to determine what to\nannotate efficiently. To learn robustly with pseudo labels, we optimize both\nthe annotation and training processes: (1) we draw k-NN examples from a small\ndemonstration pool as in-context examples, and (2) we adopt the example\nreweighting technique to assign training samples with learnable weights.\nCompared with previous approaches, LLMaAA features both efficiency and\nreliability. We conduct experiments and analysis on two classic NLP tasks,\nnamed entity recognition and relation extraction. With LLMaAA, task-specific\nmodels trained from LLM-generated labels can outperform the teacher within only\nhundreds of annotated examples, which is much more cost-effective than other\nbaselines.",
            "author": [
                "Ruoyu Zhang",
                "Yanzeng Li",
                "Yongliang Ma",
                "Ming Zhou",
                "Lei Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19596v2",
                "http://arxiv.org/pdf/2310.19596v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19591v1",
            "title": "Prediction of Locally Stationary Data Using Expert Advice",
            "updated": "2023-10-30T14:48:01Z",
            "published": "2023-10-30T14:48:01Z",
            "summary": "The problem of continuous machine learning is studied. Within the framework\nof the game-theoretic approach, when for calculating the next forecast, no\nassumptions about the stochastic nature of the source that generates the data\nflow are used -- the source can be analog, algorithmic or probabilistic, its\nparameters can change at random times, when building a prognostic model, only\nstructural assumptions are used about the nature of data generation. An online\nforecasting algorithm for a locally stationary time series is presented. An\nestimate of the efficiency of the proposed algorithm is obtained.",
            "author": [
                "Vladimir V'yugin",
                "Vladimir Trunov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19591v1",
                "http://arxiv.org/pdf/2310.19591v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19590v1",
            "title": "Operator Learning Enhanced Physics-informed Neural Networks for Solving\n  Partial Differential Equations Characterized by Sharp Solutions",
            "updated": "2023-10-30T14:47:55Z",
            "published": "2023-10-30T14:47:55Z",
            "summary": "Physics-informed Neural Networks (PINNs) have been shown as a promising\napproach for solving both forward and inverse problems of partial differential\nequations (PDEs). Meanwhile, the neural operator approach, including methods\nsuch as Deep Operator Network (DeepONet) and Fourier neural operator (FNO), has\nbeen introduced and extensively employed in approximating solution of PDEs.\nNevertheless, to solve problems consisting of sharp solutions poses a\nsignificant challenge when employing these two approaches. To address this\nissue, we propose in this work a novel framework termed Operator Learning\nEnhanced Physics-informed Neural Networks (OL-PINN). Initially, we utilize\nDeepONet to learn the solution operator for a set of smooth problems relevant\nto the PDEs characterized by sharp solutions. Subsequently, we integrate the\npre-trained DeepONet with PINN to resolve the target sharp solution problem. We\nshowcase the efficacy of OL-PINN by successfully addressing various problems,\nsuch as the nonlinear diffusion-reaction equation, the Burgers equation and the\nincompressible Navier-Stokes equation at high Reynolds number. Compared with\nthe vanilla PINN, the proposed method requires only a small number of residual\npoints to achieve a strong generalization capability. Moreover, it\nsubstantially enhances accuracy, while also ensuring a robust training process.\nFurthermore, OL-PINN inherits the advantage of PINN for solving inverse\nproblems. To this end, we apply the OL-PINN approach for solving problems with\nonly partial boundary conditions, which usually cannot be solved by the\nclassical numerical methods, showing its capacity in solving ill-posed problems\nand consequently more complex inverse problems.",
            "author": [
                "Bin Lin",
                "Zhiping Mao",
                "Zhicheng Wang",
                "George Em Karniadakis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19590v1",
                "http://arxiv.org/pdf/2310.19590v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19589v2",
            "title": "Modeling Dynamics over Meshes with Gauge Equivariant Nonlinear Message\n  Passing",
            "updated": "2023-11-03T02:20:30Z",
            "published": "2023-10-30T14:45:59Z",
            "summary": "Data over non-Euclidean manifolds, often discretized as surface meshes,\nnaturally arise in computer graphics and biological and physical systems. In\nparticular, solutions to partial differential equations (PDEs) over manifolds\ndepend critically on the underlying geometry. While graph neural networks have\nbeen successfully applied to PDEs, they do not incorporate surface geometry and\ndo not consider local gauge symmetries of the manifold. Alternatively, recent\nworks on gauge equivariant convolutional and attentional architectures on\nmeshes leverage the underlying geometry but underperform in modeling surface\nPDEs with complex nonlinear dynamics. To address these issues, we introduce a\nnew gauge equivariant architecture using nonlinear message passing. Our novel\narchitecture achieves higher performance than either convolutional or\nattentional networks on domains with highly complex and nonlinear dynamics.\nHowever, similar to the non-mesh case, design trade-offs favor convolutional,\nattentional, or message passing networks for different tasks; we investigate in\nwhich circumstances our message passing method provides the most benefit.",
            "author": [
                "Jung Yeon Park",
                "Lawson L. S. Wong",
                "Robin Walters"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19589v2",
                "http://arxiv.org/pdf/2310.19589v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19588v1",
            "title": "DPATD: Dual-Phase Audio Transformer for Denoising",
            "updated": "2023-10-30T14:44:59Z",
            "published": "2023-10-30T14:44:59Z",
            "summary": "Recent high-performance transformer-based speech enhancement models\ndemonstrate that time domain methods could achieve similar performance as\ntime-frequency domain methods. However, time-domain speech enhancement systems\ntypically receive input audio sequences consisting of a large number of time\nsteps, making it challenging to model extremely long sequences and train models\nto perform adequately. In this paper, we utilize smaller audio chunks as input\nto achieve efficient utilization of audio information to address the above\nchallenges. We propose a dual-phase audio transformer for denoising (DPATD), a\nnovel model to organize transformer layers in a deep structure to learn clean\naudio sequences for denoising. DPATD splits the audio input into smaller\nchunks, where the input length can be proportional to the square root of the\noriginal sequence length. Our memory-compressed explainable attention is\nefficient and converges faster compared to the frequently used self-attention\nmodule. Extensive experiments demonstrate that our model outperforms\nstate-of-the-art methods.",
            "author": [
                "Junhui Li",
                "Pu Wang",
                "Jialu Li",
                "Xinzhe Wang",
                "Youshan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19588v1",
                "http://arxiv.org/pdf/2310.19588v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19583v2",
            "title": "GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View\n  Stereo",
            "updated": "2023-11-29T14:33:09Z",
            "published": "2023-10-30T14:41:53Z",
            "summary": "Traditional multi-view stereo (MVS) methods rely heavily on photometric and\ngeometric consistency constraints, but newer machine learning-based MVS methods\ncheck geometric consistency across multiple source views only as a\npost-processing step. In this paper, we present a novel approach that\nexplicitly encourages geometric consistency of reference view depth maps across\nmultiple source views at different scales during learning (see Fig. 1). We find\nthat adding this geometric consistency loss significantly accelerates learning\nby explicitly penalizing geometrically inconsistent pixels, reducing the\ntraining iteration requirements to nearly half that of other MVS methods. Our\nextensive experiments show that our approach achieves a new state-of-the-art on\nthe DTU and BlendedMVS datasets, and competitive results on the Tanks and\nTemples benchmark. To the best of our knowledge, GC-MVSNet is the first attempt\nto enforce multi-view, multi-scale geometric consistency during learning.",
            "author": [
                "Vibhas K. Vats",
                "Sripad Joshi",
                "David J. Crandall",
                "Md. Alimoor Reza",
                "Soon-heung Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19583v2",
                "http://arxiv.org/pdf/2310.19583v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19582v2",
            "title": "Human-interpretable and deep features for image privacy classification",
            "updated": "2023-10-31T10:44:15Z",
            "published": "2023-10-30T14:39:43Z",
            "summary": "Privacy is a complex, subjective and contextual concept that is difficult to\ndefine. Therefore, the annotation of images to train privacy classifiers is a\nchallenging task. In this paper, we analyse privacy classification datasets and\nthe properties of controversial images that are annotated with contrasting\nprivacy labels by different assessors. We discuss suitable features for image\nprivacy classification and propose eight privacy-specific and\nhuman-interpretable features. These features increase the performance of deep\nlearning models and, on their own, improve the image representation for privacy\nclassification compared with much higher dimensional deep features.",
            "author": [
                "Darya Baranouskaya",
                "Andrea Cavallaro"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICIP49359.2023.10222833",
                "http://arxiv.org/abs/2310.19582v2",
                "http://arxiv.org/pdf/2310.19582v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19574v1",
            "title": "Skip-WaveNet: A Wavelet based Multi-scale Architecture to Trace Firn\n  Layers in Radar Echograms",
            "updated": "2023-10-30T14:30:27Z",
            "published": "2023-10-30T14:30:27Z",
            "summary": "Echograms created from airborne radar sensors capture the profile of firn\nlayers present on top of an ice sheet. Accurate tracking of these layers is\nessential to calculate the snow accumulation rates, which are required to\ninvestigate the contribution of polar ice cap melt to sea level rise. However,\nautomatically processing the radar echograms to detect the underlying firn\nlayers is a challenging problem. In our work, we develop wavelet-based\nmulti-scale deep learning architectures for these radar echograms to improve\nfirn layer detection. We show that wavelet based architectures improve the\noptimal dataset scale (ODS) and optimal image scale (OIS) F-scores by 3.99% and\n3.7%, respectively, over the non-wavelet architecture. Further, our proposed\nSkip-WaveNet architecture generates new wavelets in each iteration, achieves\nhigher generalizability as compared to state-of-the-art firn layer detection\nnetworks, and estimates layer depths with a mean absolute error of 3.31 pixels\nand 94.3% average precision. Such a network can be used by scientists to trace\nfirn layers, calculate the annual snow accumulation rates, estimate the\nresulting surface mass balance of the ice sheet, and help project global sea\nlevel rise.",
            "author": [
                "Debvrat Varshney",
                "Masoud Yari",
                "Oluwanisola Ibikunle",
                "Jilu Li",
                "John Paden",
                "Maryam Rahnemoonfar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19574v1",
                "http://arxiv.org/pdf/2310.19574v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19573v1",
            "title": "Model Uncertainty based Active Learning on Tabular Data using Boosted\n  Trees",
            "updated": "2023-10-30T14:29:53Z",
            "published": "2023-10-30T14:29:53Z",
            "summary": "Supervised machine learning relies on the availability of good labelled data\nfor model training. Labelled data is acquired by human annotation, which is a\ncumbersome and costly process, often requiring subject matter experts. Active\nlearning is a sub-field of machine learning which helps in obtaining the\nlabelled data efficiently by selecting the most valuable data instances for\nmodel training and querying the labels only for those instances from the human\nannotator. Recently, a lot of research has been done in the field of active\nlearning, especially for deep neural network based models. Although deep\nlearning shines when dealing with image\\textual\\multimodal data, gradient\nboosting methods still tend to achieve much better results on tabular data. In\nthis work, we explore active learning for tabular data using boosted trees.\nUncertainty based sampling in active learning is the most commonly used\nquerying strategy, wherein the labels of those instances are sequentially\nqueried for which the current model prediction is maximally uncertain. Entropy\nis often the choice for measuring uncertainty. However, entropy is not exactly\na measure of model uncertainty. Although there has been a lot of work in deep\nlearning for measuring model uncertainty and employing it in active learning,\nit is yet to be explored for non-neural network models. To this end, we explore\nthe effectiveness of boosted trees based model uncertainty methods in active\nlearning. Leveraging this model uncertainty, we propose an uncertainty based\nsampling in active learning for regression tasks on tabular data. Additionally,\nwe also propose a novel cost-effective active learning method for regression\ntasks along with an improved cost-effective active learning method for\nclassification tasks.",
            "author": [
                "Sharath M Shankaranarayana"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19573v1",
                "http://arxiv.org/pdf/2310.19573v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19572v1",
            "title": "Improving Input-label Mapping with Demonstration Replay for In-context\n  Learning",
            "updated": "2023-10-30T14:29:41Z",
            "published": "2023-10-30T14:29:41Z",
            "summary": "In-context learning (ICL) is an emerging capability of large autoregressive\nlanguage models where a few input-label demonstrations are appended to the\ninput to enhance the model's understanding of downstream NLP tasks, without\ndirectly adjusting the model parameters. The effectiveness of ICL can be\nattributed to the strong language modeling capabilities of large language\nmodels (LLMs), which enable them to learn the mapping between input and labels\nbased on in-context demonstrations. Despite achieving promising results, the\ncausal nature of language modeling in ICL restricts the attention to be\nbackward only, i.e., a token only attends to its previous tokens, failing to\ncapture the full input-label information and limiting the model's performance.\nIn this paper, we propose a novel ICL method called Repeated Demonstration with\nSliding Causal Attention, (RdSca). Specifically, we duplicate later\ndemonstrations and concatenate them to the front, allowing the model to\n`observe' the later information even under the causal restriction. Besides, we\nintroduce sliding causal attention, which customizes causal attention to avoid\ninformation leakage. Experimental results show that our method significantly\nimproves the input-label mapping in ICL demonstrations. We also conduct an\nin-depth analysis of how to customize the causal attention without training,\nwhich has been an unexplored area in previous research.",
            "author": [
                "Zhuocheng Gong",
                "Jiahao Liu",
                "Qifan Wang",
                "Jingang Wang",
                "Xunliang Cai",
                "Dongyan Zhao",
                "Rui Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19572v1",
                "http://arxiv.org/pdf/2310.19572v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19568v1",
            "title": "DataZoo: Streamlining Traffic Classification Experiments",
            "updated": "2023-10-30T14:24:25Z",
            "published": "2023-10-30T14:24:25Z",
            "summary": "The machine learning communities, such as those around computer vision or\nnatural language processing, have developed numerous supportive tools and\nbenchmark datasets to accelerate the development. In contrast, the network\ntraffic classification field lacks standard benchmark datasets for most tasks,\nand the available supportive software is rather limited in scope. This paper\naims to address the gap and introduces DataZoo, a toolset designed to\nstreamline dataset management in network traffic classification and to reduce\nthe space for potential mistakes in the evaluation setup. DataZoo provides a\nstandardized API for accessing three extensive datasets -- CESNET-QUIC22,\nCESNET-TLS22, and CESNET-TLS-Year22. Moreover, it includes methods for feature\nscaling and realistic dataset partitioning, taking into consideration temporal\nand service-related factors. The DataZoo toolset simplifies the creation of\nrealistic evaluation scenarios, making it easier to cross-compare\nclassification methods and reproduce results.",
            "author": [
                "Jan Luxemburk",
                "Karel Hynek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19568v1",
                "http://arxiv.org/pdf/2310.19568v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19567v1",
            "title": "CreoleVal: Multilingual Multitask Benchmarks for Creoles",
            "updated": "2023-10-30T14:24:20Z",
            "published": "2023-10-30T14:24:20Z",
            "summary": "Creoles represent an under-explored and marginalized group of languages, with\nfew available resources for NLP research. While the genealogical ties between\nCreoles and other highly-resourced languages imply a significant potential for\ntransfer learning, this potential is hampered due to this lack of annotated\ndata. In this work we present CreoleVal, a collection of benchmark datasets\nspanning 8 different NLP tasks, covering up to 28 Creole languages; it is an\naggregate of brand new development datasets for machine comprehension, relation\nclassification, and machine translation for Creoles, in addition to a practical\ngateway to a handful of preexisting benchmarks. For each benchmark, we conduct\nbaseline experiments in a zero-shot setting in order to further ascertain the\ncapabilities and limitations of transfer learning for Creoles. Ultimately, the\ngoal of CreoleVal is to empower research on Creoles in NLP and computational\nlinguistics. We hope this resource will contribute to technological inclusion\nfor Creole language users around the globe.",
            "author": [
                "Heather Lent",
                "Kushal Tatariya",
                "Raj Dabre",
                "Yiyi Chen",
                "Marcell Fekete",
                "Esther Ploeger",
                "Li Zhou",
                "Hans Erik Heje",
                "Diptesh Kanojia",
                "Paul Belony",
                "Marcel Bollmann",
                "Lo\u00efc Grobol",
                "Miryam de Lhoneux",
                "Daniel Hershcovich",
                "Michel DeGraff",
                "Anders S\u00f8gaard",
                "Johannes Bjerva"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19567v1",
                "http://arxiv.org/pdf/2310.19567v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19561v1",
            "title": "Non-parametric regression for robot learning on manifolds",
            "updated": "2023-10-30T14:17:32Z",
            "published": "2023-10-30T14:17:32Z",
            "summary": "Many of the tools available for robot learning were designed for Euclidean\ndata. However, many applications in robotics involve manifold-valued data. A\ncommon example is orientation; this can be represented as a 3-by-3 rotation\nmatrix or a quaternion, the spaces of which are non-Euclidean manifolds. In\nrobot learning, manifold-valued data are often handled by relating the manifold\nto a suitable Euclidean space, either by embedding the manifold or by\nprojecting the data onto one or several tangent spaces. These approaches can\nresult in poor predictive accuracy, and convoluted algorithms. In this paper,\nwe propose an \"intrinsic\" approach to regression that works directly within the\nmanifold. It involves taking a suitable probability distribution on the\nmanifold, letting its parameter be a function of a predictor variable, such as\ntime, then estimating that function non-parametrically via a \"local likelihood\"\nmethod that incorporates a kernel. We name the method kernelised likelihood\nestimation. The approach is conceptually simple, and generally applicable to\ndifferent manifolds. We implement it with three different types of\nmanifold-valued data that commonly appear in robotics applications. The results\nof these experiments show better predictive accuracy than projection-based\nalgorithms.",
            "author": [
                "P. C. Lopez-Custodio",
                "K. Bharath",
                "A. Kucukyilmaz",
                "S. P. Preston"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19561v1",
                "http://arxiv.org/pdf/2310.19561v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19559v2",
            "title": "Disentangled Counterfactual Learning for Physical Audiovisual\n  Commonsense Reasoning",
            "updated": "2023-11-02T02:36:12Z",
            "published": "2023-10-30T14:16:34Z",
            "summary": "In this paper, we propose a Disentangled Counterfactual Learning~(DCL)\napproach for physical audiovisual commonsense reasoning. The task aims to infer\nobjects' physics commonsense based on both video and audio input, with the main\nchallenge is how to imitate the reasoning ability of humans. Most of the\ncurrent methods fail to take full advantage of different characteristics in\nmulti-modal data, and lacking causal reasoning ability in models impedes the\nprogress of implicit physical knowledge inferring. To address these issues, our\nproposed DCL method decouples videos into static (time-invariant) and dynamic\n(time-varying) factors in the latent space by the disentangled sequential\nencoder, which adopts a variational autoencoder (VAE) to maximize the mutual\ninformation with a contrastive loss function. Furthermore, we introduce a\ncounterfactual learning module to augment the model's reasoning ability by\nmodeling physical knowledge relationships among different objects under\ncounterfactual intervention. Our proposed method is a plug-and-play module that\ncan be incorporated into any baseline. In experiments, we show that our\nproposed method improves baseline methods and achieves state-of-the-art\nperformance. Our source code is available at https://github.com/Andy20178/DCL.",
            "author": [
                "Changsheng Lv",
                "Shuai Zhang",
                "Yapeng Tian",
                "Mengshi Qi",
                "Huadong Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19559v2",
                "http://arxiv.org/pdf/2310.19559v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19558v1",
            "title": "Privacy-preserving Federated Primal-dual Learning for Non-convex and\n  Non-smooth Problems with Model Sparsification",
            "updated": "2023-10-30T14:15:47Z",
            "published": "2023-10-30T14:15:47Z",
            "summary": "Federated learning (FL) has been recognized as a rapidly growing research\narea, where the model is trained over massively distributed clients under the\norchestration of a parameter server (PS) without sharing clients' data. This\npaper delves into a class of federated problems characterized by non-convex and\nnon-smooth loss functions, that are prevalent in FL applications but\nchallenging to handle due to their intricate non-convexity and non-smoothness\nnature and the conflicting requirements on communication efficiency and privacy\nprotection. In this paper, we propose a novel federated primal-dual algorithm\nwith bidirectional model sparsification tailored for non-convex and non-smooth\nFL problems, and differential privacy is applied for strong privacy guarantee.\nIts unique insightful properties and some privacy and convergence analyses are\nalso presented for the FL algorithm design guidelines. Extensive experiments on\nreal-world data are conducted to demonstrate the effectiveness of the proposed\nalgorithm and much superior performance than some state-of-the-art FL\nalgorithms, together with the validation of all the analytical results and\nproperties.",
            "author": [
                "Yiwei Li",
                "Chien-Wei Huang",
                "Shuai Wang",
                "Chong-Yung Chi",
                "Tony Q. S. Quek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19558v1",
                "http://arxiv.org/pdf/2310.19558v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19554v1",
            "title": "Harvest Video Foundation Models via Efficient Post-Pretraining",
            "updated": "2023-10-30T14:06:16Z",
            "published": "2023-10-30T14:06:16Z",
            "summary": "Building video-language foundation models is costly and difficult due to the\nredundant nature of video data and the lack of high-quality video-language\ndatasets. In this paper, we propose an efficient framework to harvest video\nfoundation models from image ones. Our method is intuitively simple by randomly\ndropping input video patches and masking out input text during the\npost-pretraining procedure. The patch dropping boosts the training efficiency\nsignificantly and text masking enforces the learning of cross-modal fusion. We\nconduct extensive experiments to validate the effectiveness of our method on a\nwide range of video-language downstream tasks including various zero-shot\ntasks, video question answering, and video-text retrieval. Despite its\nsimplicity, our method achieves state-of-the-art performances, which are\ncomparable to some heavily pretrained video foundation models. Our method is\nextremely efficient and can be trained in less than one day on 8 GPUs,\nrequiring only WebVid-10M as pretraining data. We hope our method can serve as\na simple yet strong counterpart for prevalent video foundation models, provide\nuseful insights when building them, and make large pretrained models more\naccessible and sustainable. This is part of the InternVideo project\n\\url{https://github.com/OpenGVLab/InternVideo}.",
            "author": [
                "Yizhuo Li",
                "Kunchang Li",
                "Yinan He",
                "Yi Wang",
                "Yali Wang",
                "Limin Wang",
                "Yu Qiao",
                "Ping Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19554v1",
                "http://arxiv.org/pdf/2310.19554v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19548v2",
            "title": "Approximation Theory, Computing, and Deep Learning on the Wasserstein\n  Space",
            "updated": "2023-11-16T17:57:02Z",
            "published": "2023-10-30T13:59:47Z",
            "summary": "The challenge of approximating functions in infinite-dimensional spaces from\nfinite samples is widely regarded as formidable. In this study, we delve into\nthe challenging problem of the numerical approximation of Sobolev-smooth\nfunctions defined on probability spaces. Our particular focus centers on the\nWasserstein distance function, which serves as a relevant example. In contrast\nto the existing body of literature focused on approximating efficiently\npointwise evaluations, we chart a new course to define functional approximants\nby adopting three machine learning-based approaches: 1. Solving a finite number\nof optimal transport problems and computing the corresponding Wasserstein\npotentials. 2. Employing empirical risk minimization with Tikhonov\nregularization in Wasserstein Sobolev spaces. 3. Addressing the problem through\nthe saddle point formulation that characterizes the weak form of the Tikhonov\nfunctional's Euler-Lagrange equation. As a theoretical contribution, we furnish\nexplicit and quantitative bounds on generalization errors for each of these\nsolutions. In the proofs, we leverage the theory of metric Sobolev spaces and\nwe combine it with techniques of optimal transport, variational calculus, and\nlarge deviation bounds. In our numerical implementation, we harness\nappropriately designed neural networks to serve as basis functions. These\nnetworks undergo training using diverse methodologies. This approach allows us\nto obtain approximating functions that can be rapidly evaluated after training.\nConsequently, our constructive solutions significantly enhance at equal\naccuracy the evaluation speed, surpassing that of state-of-the-art methods by\nseveral orders of magnitude.",
            "author": [
                "Massimo Fornasier",
                "Pascal Heid",
                "Giacomo Enrico Sodini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19548v2",
                "http://arxiv.org/pdf/2310.19548v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "math.FA",
                "49Q22, 33F05, 46E36, 28A33, 68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19545v1",
            "title": "MENTOR: Human Perception-Guided Pretraining for Iris Presentation\n  Detection",
            "updated": "2023-10-30T13:50:44Z",
            "published": "2023-10-30T13:50:44Z",
            "summary": "Incorporating human salience into the training of CNNs has boosted\nperformance in difficult tasks such as biometric presentation attack detection.\nHowever, collecting human annotations is a laborious task, not to mention the\nquestions of how and where (in the model architecture) to efficiently\nincorporate this information into model's training once annotations are\nobtained. In this paper, we introduce MENTOR (huMan pErceptioN-guided\npreTraining fOr iris pResentation attack detection), which addresses both of\nthese issues through two unique rounds of training. First, we train an\nautoencoder to learn human saliency maps given an input iris image (both real\nand fake examples). Once this representation is learned, we utilize the trained\nautoencoder in two different ways: (a) as a pre-trained backbone for an iris\npresentation attack detector, and (b) as a human-inspired annotator of salient\nfeatures on unknown data. We show that MENTOR's benefits are threefold: (a)\nsignificant boost in iris PAD performance when using the human\nperception-trained encoder's weights compared to general-purpose weights (e.g.\nImageNet-sourced, or random), (b) capability of generating infinite number of\nhuman-like saliency maps for unseen iris PAD samples to be used in any human\nsaliency-guided training paradigm, and (c) increase in efficiency of iris PAD\nmodel training. Sources codes and weights are offered along with the paper.",
            "author": [
                "Colton R. Crum",
                "Adam Czajka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19545v1",
                "http://arxiv.org/pdf/2310.19545v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02167v1",
            "title": "Uncertainty Quantification in Machine Learning Based Segmentation: A\n  Post-Hoc Approach for Left Ventricle Volume Estimation in MRI",
            "updated": "2023-10-30T13:44:55Z",
            "published": "2023-10-30T13:44:55Z",
            "summary": "Recent studies have confirmed cardiovascular diseases remain responsible for\nhighest death toll amongst non-communicable diseases. Accurate left ventricular\n(LV) volume estimation is critical for valid diagnosis and management of\nvarious cardiovascular conditions, but poses significant challenge due to\ninherent uncertainties associated with segmentation algorithms in magnetic\nresonance imaging (MRI). Recent machine learning advancements, particularly\nU-Net-like convolutional networks, have facilitated automated segmentation for\nmedical images, but struggles under certain pathologies and/or different\nscanner vendors and imaging protocols. This study proposes a novel methodology\nfor post-hoc uncertainty estimation in LV volume prediction using It\\^{o}\nstochastic differential equations (SDEs) to model path-wise behavior for the\nprediction error. The model describes the area of the left ventricle along the\nheart's long axis. The method is agnostic to the underlying segmentation\nalgorithm, facilitating its use with various existing and future segmentation\ntechnologies. The proposed approach provides a mechanism for quantifying\nuncertainty, enabling medical professionals to intervene for unreliable\npredictions. This is of utmost importance in critical applications such as\nmedical diagnosis, where prediction accuracy and reliability can directly\nimpact patient outcomes. The method is also robust to dataset changes, enabling\napplication for medical centers with limited access to labeled data. Our\nfindings highlight the proposed uncertainty estimation methodology's potential\nto enhance automated segmentation robustness and generalizability, paving the\nway for more reliable and accurate LV volume estimation in clinical settings as\nwell as opening new avenues for uncertainty quantification in biomedical image\nsegmentation, providing promising directions for future research.",
            "author": [
                "F. Terhag",
                "P. Knechtges",
                "A. Basermann",
                "R. Tempone"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02167v1",
                "http://arxiv.org/pdf/2312.02167v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ME",
                "68T07, 62P10, 92C55, 68T05, 65C20, 62M45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19537v2",
            "title": "On consequences of finetuning on data with highly discriminative\n  features",
            "updated": "2023-11-15T22:09:08Z",
            "published": "2023-10-30T13:43:50Z",
            "summary": "In the era of transfer learning, training neural networks from scratch is\nbecoming obsolete. Transfer learning leverages prior knowledge for new tasks,\nconserving computational resources. While its advantages are well-documented,\nwe uncover a notable drawback: networks tend to prioritize basic data patterns,\nforsaking valuable pre-learned features. We term this behavior \"feature\nerosion\" and analyze its impact on network performance and internal\nrepresentations.",
            "author": [
                "Wojciech Masarczyk",
                "Tomasz Trzci\u0144ski",
                "Mateusz Ostaszewski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19537v2",
                "http://arxiv.org/pdf/2310.19537v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19536v1",
            "title": "Adversarial Batch Inverse Reinforcement Learning: Learn to Reward from\n  Imperfect Demonstration for Interactive Recommendation",
            "updated": "2023-10-30T13:43:20Z",
            "published": "2023-10-30T13:43:20Z",
            "summary": "Rewards serve as a measure of user satisfaction and act as a limiting factor\nin interactive recommender systems. In this research, we focus on the problem\nof learning to reward (LTR), which is fundamental to reinforcement learning.\nPrevious approaches either introduce additional procedures for learning to\nreward, thereby increasing the complexity of optimization, or assume that\nuser-agent interactions provide perfect demonstrations, which is not feasible\nin practice. Ideally, we aim to employ a unified approach that optimizes both\nthe reward and policy using compositional demonstrations. However, this\nrequirement presents a challenge since rewards inherently quantify user\nfeedback on-policy, while recommender agents approximate off-policy future\ncumulative valuation. To tackle this challenge, we propose a novel batch\ninverse reinforcement learning paradigm that achieves the desired properties.\nOur method utilizes discounted stationary distribution correction to combine\nLTR and recommender agent evaluation. To fulfill the compositional requirement,\nwe incorporate the concept of pessimism through conservation. Specifically, we\nmodify the vanilla correction using Bellman transformation and enforce KL\nregularization to constrain consecutive policy updates. We use two real-world\ndatasets which represent two compositional coverage to conduct empirical\nstudies, the results also show that the proposed method relatively improves\nboth effectiveness (2.3\\%) and efficiency (11.53\\%)",
            "author": [
                "Jialin Liu",
                "Xinyan Su",
                "Zeyu He",
                "Xiangyu Zhao",
                "Jun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19536v1",
                "http://arxiv.org/pdf/2310.19536v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19535v2",
            "title": "Revitalizing Legacy Video Content: Deinterlacing with Bidirectional\n  Information Propagation",
            "updated": "2023-12-05T15:06:02Z",
            "published": "2023-10-30T13:43:19Z",
            "summary": "Due to old CRT display technology and limited transmission bandwidth, early\nfilm and TV broadcasts commonly used interlaced scanning. This meant each field\ncontained only half of the information. Since modern displays require full\nframes, this has spurred research into deinterlacing, i.e. restoring the\nmissing information in legacy video content. In this paper, we present a\ndeep-learning-based method for deinterlacing animated and live-action content.\nOur proposed method supports bidirectional spatio-temporal information\npropagation across multiple scales to leverage information in both space and\ntime. More specifically, we design a Flow-guided Refinement Block (FRB) which\nperforms feature refinement including alignment, fusion, and rectification.\nAdditionally, our method can process multiple fields simultaneously, reducing\nper-frame processing time, and potentially enabling real-time processing. Our\nexperimental results demonstrate that our proposed method achieves superior\nperformance compared to existing methods.",
            "author": [
                "Zhaowei Gao",
                "Mingyang Song",
                "Christopher Schroers",
                "Yang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19535v2",
                "http://arxiv.org/pdf/2310.19535v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19531v3",
            "title": "InfoEntropy Loss to Mitigate Bias of Learning Difficulties for\n  Generative Language Models",
            "updated": "2023-11-10T09:35:30Z",
            "published": "2023-10-30T13:33:21Z",
            "summary": "Generative language models are usually pretrained on large text corpus via\npredicting the next token (i.e., sub-word/word/phrase) given the previous ones.\nRecent works have demonstrated the impressive performance of large generative\nlanguage models on downstream tasks. However, existing generative language\nmodels generally neglect an inherent challenge in text corpus during training,\ni.e., the imbalance between frequent tokens and infrequent ones. It can lead a\nlanguage model to be dominated by common and easy-to-learn tokens, thereby\noverlooking the infrequent and difficult-to-learn ones. To alleviate that, we\npropose an Information Entropy Loss (InfoEntropy Loss) function. During\ntraining, it can dynamically assess the learning difficulty of a to-be-learned\ntoken, according to the information entropy of the corresponding predicted\nprobability distribution over the vocabulary. Then it scales the training loss\nadaptively, trying to lead the model to focus more on the difficult-to-learn\ntokens. On the Pile dataset, we train generative language models at different\nscales of 468M, 1.2B, and 6.7B parameters. Experiments reveal that models\nincorporating the proposed InfoEntropy Loss can gain consistent performance\nimprovement on downstream benchmarks.",
            "author": [
                "Zhenpeng Su",
                "Xing Wu",
                "Xue Bai",
                "Zijia Lin",
                "Hui Chen",
                "Guiguang Ding",
                "Wei Zhou",
                "Songlin Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19531v3",
                "http://arxiv.org/pdf/2310.19531v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19527v1",
            "title": "Decoupled Actor-Critic",
            "updated": "2023-10-30T13:28:06Z",
            "published": "2023-10-30T13:28:06Z",
            "summary": "Actor-Critic methods are in a stalemate of two seemingly irreconcilable\nproblems. Firstly, critic proneness towards overestimation requires sampling\ntemporal-difference targets from a conservative policy optimized using\nlower-bound Q-values. Secondly, well-known results show that policies that are\noptimistic in the face of uncertainty yield lower regret levels. To remedy this\ndichotomy, we propose Decoupled Actor-Critic (DAC). DAC is an off-policy\nalgorithm that learns two distinct actors by gradient backpropagation: a\nconservative actor used for temporal-difference learning and an optimistic\nactor used for exploration. We test DAC on DeepMind Control tasks in low and\nhigh replay ratio regimes and ablate multiple design choices. Despite minimal\ncomputational overhead, DAC achieves state-of-the-art performance and sample\nefficiency on locomotion tasks.",
            "author": [
                "Michal Nauman",
                "Marek Cygan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19527v1",
                "http://arxiv.org/pdf/2310.19527v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19522v2",
            "title": "Are Natural Domain Foundation Models Useful for Medical Image\n  Classification?",
            "updated": "2023-11-14T12:21:41Z",
            "published": "2023-10-30T13:21:56Z",
            "summary": "The deep learning field is converging towards the use of general foundation\nmodels that can be easily adapted for diverse tasks. While this paradigm shift\nhas become common practice within the field of natural language processing,\nprogress has been slower in computer vision. In this paper we attempt to\naddress this issue by investigating the transferability of various\nstate-of-the-art foundation models to medical image classification tasks.\nSpecifically, we evaluate the performance of five foundation models, namely\nSAM, SEEM, DINOv2, BLIP, and OpenCLIP across four well-established medical\nimaging datasets. We explore different training settings to fully harness the\npotential of these models. Our study shows mixed results. DINOv2 consistently\noutperforms the standard practice of ImageNet pretraining. However, other\nfoundation models failed to consistently beat this established baseline\nindicating limitations in their transferability to medical image classification\ntasks.",
            "author": [
                "Joana Pal\u00e9s Huix",
                "Adithya Raju Ganeshan",
                "Johan Fredin Haslum",
                "Magnus S\u00f6derberg",
                "Christos Matsoukas",
                "Kevin Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19522v2",
                "http://arxiv.org/pdf/2310.19522v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19519v1",
            "title": "A General Neural Causal Model for Interactive Recommendation",
            "updated": "2023-10-30T13:21:04Z",
            "published": "2023-10-30T13:21:04Z",
            "summary": "Survivor bias in observational data leads the optimization of recommender\nsystems towards local optima. Currently most solutions re-mines existing\nhuman-system collaboration patterns to maximize longer-term satisfaction by\nreinforcement learning. However, from the causal perspective, mitigating\nsurvivor effects requires answering a counterfactual problem, which is\ngenerally unidentifiable and inestimable. In this work, we propose a neural\ncausal model to achieve counterfactual inference. Specifically, we first build\na learnable structural causal model based on its available graphical\nrepresentations which qualitatively characterizes the preference transitions.\nMitigation of the survivor bias is achieved though counterfactual consistency.\nTo identify the consistency, we use the Gumbel-max function as structural\nconstrains. To estimate the consistency, we apply reinforcement optimizations,\nand use Gumbel-Softmax as a trade-off to get a differentiable function. Both\ntheoretical and empirical studies demonstrate the effectiveness of our\nsolution.",
            "author": [
                "Jialin Liu",
                "Xinyan Su",
                "Peng Zhou",
                "Xiangyu Zhao",
                "Jun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19519v1",
                "http://arxiv.org/pdf/2310.19519v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19515v1",
            "title": "Transformer-based nowcasting of radar composites from satellite images\n  for severe weather",
            "updated": "2023-10-30T13:17:38Z",
            "published": "2023-10-30T13:17:38Z",
            "summary": "Weather radar data are critical for nowcasting and an integral component of\nnumerical weather prediction models. While weather radar data provide valuable\ninformation at high resolution, their ground-based nature limits their\navailability, which impedes large-scale applications. In contrast,\nmeteorological satellites cover larger domains but with coarser resolution.\n  However, with the rapid advancements in data-driven methodologies and modern\nsensors aboard geostationary satellites, new opportunities are emerging to\nbridge the gap between ground- and space-based observations, ultimately leading\nto more skillful weather prediction with high accuracy.\n  Here, we present a Transformer-based model for nowcasting ground-based radar\nimage sequences using satellite data up to two hours lead time. Trained on a\ndataset reflecting severe weather conditions, the model predicts radar fields\noccurring under different weather phenomena and shows robustness against\nrapidly growing/decaying fields and complex field structures.\n  Model interpretation reveals that the infrared channel centered at 10.3 $\\mu\nm$ (C13) contains skillful information for all weather conditions, while\nlightning data have the highest relative feature importance in severe weather\nconditions, particularly in shorter lead times.\n  The model can support precipitation nowcasting across large domains without\nan explicit need for radar towers, enhance numerical weather prediction and\nhydrological models, and provide radar proxy for data-scarce regions. Moreover,\nthe open-source framework facilitates progress towards operational data-driven\nnowcasting.",
            "author": [
                "\u00c7a\u011flar K\u00fc\u00e7\u00fck",
                "Apostolos Giannakos",
                "Stefan Schneider",
                "Alexander Jann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19515v1",
                "http://arxiv.org/pdf/2310.19515v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19513v1",
            "title": "Inverse folding for antibody sequence design using deep learning",
            "updated": "2023-10-30T13:12:41Z",
            "published": "2023-10-30T13:12:41Z",
            "summary": "We consider the problem of antibody sequence design given 3D structural\ninformation. Building on previous work, we propose a fine-tuned inverse folding\nmodel that is specifically optimised for antibody structures and outperforms\ngeneric protein models on sequence recovery and structure robustness when\napplied on antibodies, with notable improvement on the hypervariable CDR-H3\nloop. We study the canonical conformations of complementarity-determining\nregions and find improved encoding of these loops into known clusters. Finally,\nwe consider the applications of our model to drug discovery and binder design\nand evaluate the quality of proposed sequences using physics-based methods.",
            "author": [
                "Fr\u00e9d\u00e9ric A. Dreyer",
                "Daniel Cutting",
                "Constantin Schneider",
                "Henry Kenlay",
                "Charlotte M. Deane"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19513v1",
                "http://arxiv.org/pdf/2310.19513v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19511v1",
            "title": "Rule-Based Lloyd Algorithm for Multi-Robot Motion Planning and Control\n  with Safety and Convergence Guarantees",
            "updated": "2023-10-30T13:10:05Z",
            "published": "2023-10-30T13:10:05Z",
            "summary": "This paper presents a distributed rule-based Lloyd algorithm (RBL) for\nmulti-robot motion planning and control. The main limitations of the basic\nLoyd-based algorithm (LB) concern deadlock issues and the failure to address\ndynamic constraints effectively. Our contribution is twofold. First, we show\nhow RBL is able to provide safety and convergence to the goal region without\nrelying on communication between robots, nor neighbors control inputs, nor\nsynchronization between the robots. We considered both case of holonomic and\nnon-holonomic robots with control inputs saturation. Second, we show that the\nLloyd-based algorithm (without rules) can be successfully used as a safety\nlayer for learning-based approaches, leading to non-negligible benefits. We\nfurther prove the soundness, reliability, and scalability of RBL through\nextensive simulations, an updated comparison with the state of the art, and\nexperimental validations on small-scale car-like robots.",
            "author": [
                "Manuel Boldrer",
                "Alvaro Serra-Gomez",
                "Lorenzo Lyons",
                "Javier Alonso-Mora",
                "Laura Ferranti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19511v1",
                "http://arxiv.org/pdf/2310.19511v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19503v2",
            "title": "Trust, Accountability, and Autonomy in Knowledge Graph-based AI for\n  Self-determination",
            "updated": "2023-10-31T09:16:13Z",
            "published": "2023-10-30T12:51:52Z",
            "summary": "Knowledge Graphs (KGs) have emerged as fundamental platforms for powering\nintelligent decision-making and a wide range of Artificial Intelligence (AI)\nservices across major corporations such as Google, Walmart, and AirBnb. KGs\ncomplement Machine Learning (ML) algorithms by providing data context and\nsemantics, thereby enabling further inference and question-answering\ncapabilities. The integration of KGs with neuronal learning (e.g., Large\nLanguage Models (LLMs)) is currently a topic of active research, commonly named\nneuro-symbolic AI. Despite the numerous benefits that can be accomplished with\nKG-based AI, its growing ubiquity within online services may result in the loss\nof self-determination for citizens as a fundamental societal issue. The more we\nrely on these technologies, which are often centralised, the less citizens will\nbe able to determine their own destinies. To counter this threat, AI\nregulation, such as the European Union (EU) AI Act, is being proposed in\ncertain regions. The regulation sets what technologists need to do, leading to\nquestions concerning: How can the output of AI systems be trusted? What is\nneeded to ensure that the data fuelling and the inner workings of these\nartefacts are transparent? How can AI be made accountable for its\ndecision-making? This paper conceptualises the foundational topics and research\npillars to support KG-based AI for self-determination. Drawing upon this\nconceptual framework, challenges and opportunities for citizen\nself-determination are illustrated and analysed in a real-world scenario. As a\nresult, we propose a research agenda aimed at accomplishing the recommended\nobjectives.",
            "author": [
                "Luis-Daniel Ib\u00e1\u00f1ez",
                "John Domingue",
                "Sabrina Kirrane",
                "Oshani Seneviratne",
                "Aisling Third",
                "Maria-Esther Vidal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19503v2",
                "http://arxiv.org/pdf/2310.19503v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19495v1",
            "title": "Deep Learning for Visual Navigation of Underwater Robots",
            "updated": "2023-10-30T12:37:49Z",
            "published": "2023-10-30T12:37:49Z",
            "summary": "This paper aims to briefly survey deep learning methods for visual navigation\nof underwater robotics. The scope of this paper includes the visual perception\nof underwater robotics with deep learning methods, the available visual\nunderwater datasets, imitation learning, and reinforcement learning methods for\nnavigation. Additionally, relevant works will be categorized under the\nimitation learning or deep learning paradigm for underwater robots for clarity\nof the training methodologies in the current landscape. Literature that uses\ndeep learning algorithms to process non-visual data for underwater navigation\nwill not be considered, except as contrasting examples.",
            "author": [
                "M. Sunbeam"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19495v1",
                "http://arxiv.org/pdf/2310.19495v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19491v1",
            "title": "Generator Identification for Linear SDEs with Additive and\n  Multiplicative Noise",
            "updated": "2023-10-30T12:28:53Z",
            "published": "2023-10-30T12:28:53Z",
            "summary": "In this paper, we present conditions for identifying the generator of a\nlinear stochastic differential equation (SDE) from the distribution of its\nsolution process with a given fixed initial state. These identifiability\nconditions are crucial in causal inference using linear SDEs as they enable the\nidentification of the post-intervention distributions from its observational\ndistribution. Specifically, we derive a sufficient and necessary condition for\nidentifying the generator of linear SDEs with additive noise, as well as a\nsufficient condition for identifying the generator of linear SDEs with\nmultiplicative noise. We show that the conditions derived for both types of\nSDEs are generic. Moreover, we offer geometric interpretations of the derived\nidentifiability conditions to enhance their understanding. To validate our\ntheoretical results, we perform a series of simulations, which support and\nsubstantiate the established findings.",
            "author": [
                "Yuanyuan Wang",
                "Xi Geng",
                "Wei Huang",
                "Biwei Huang",
                "Mingming Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19491v1",
                "http://arxiv.org/pdf/2310.19491v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.LG",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19489v1",
            "title": "Adaptive Meta-Learning-Based KKL Observer Design for Nonlinear Dynamical\n  Systems",
            "updated": "2023-10-30T12:25:14Z",
            "published": "2023-10-30T12:25:14Z",
            "summary": "The theory of Kazantzis-Kravaris/Luenberger (KKL) observer design introduces\na methodology that uses a nonlinear transformation map and its left inverse to\nestimate the state of a nonlinear system through the introduction of a linear\nobserver state space. Data-driven approaches using artificial neural networks\nhave demonstrated the ability to accurately approximate these transformation\nmaps. This paper presents a novel approach to observer design for nonlinear\ndynamical systems through meta-learning, a concept in machine learning that\naims to optimize learning models for fast adaptation to a distribution of tasks\nthrough an improved focus on the intrinsic properties of the underlying\nlearning problem. We introduce a framework that leverages information from\nmeasurements of the system output to design a learning-based KKL observer\ncapable of online adaptation to a variety of system conditions and attributes.\nTo validate the effectiveness of our approach, we present comprehensive\nexperimental results for the estimation of nonlinear system states with varying\ninitial conditions and internal parameters, demonstrating high accuracy,\ngeneralization capability, and robustness against noise.",
            "author": [
                "Lukas Trommer",
                "Halil Yigit Oksuz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19489v1",
                "http://arxiv.org/pdf/2310.19489v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19485v1",
            "title": "Anomalous tensile strength and thermal expansion, and low thermal\n  conductivity in wide band gap boron monoxide monolayer",
            "updated": "2023-10-30T12:13:58Z",
            "published": "2023-10-30T12:13:58Z",
            "summary": "Most recently the formation of boron monoxide (BO) in the two-dimensional\n(2D) form has been confirmed experimentally (J. Am. Chem. Soc. 2023, 145,\n14660). Motivated by the aforementioned finding, herein we theoretically\nexplore the key physical properties of the single-layer and suspended BO.\nDensity functional theory (DFT) results reveal that BO monolayer yields a large\nindirect band gap of 3.78 (2.18) eV on the basis of HSE06(PBE) functional.\nAb-initio molecular dynamics results reveal the remarkable thermal stability of\nthe BO monolayer at 1000 K. The thermal and mechanical properties at room\ntemperature are furthermore investigated using a machine learning interatomic\npotential (MLIP). The developed MLIP-based model close to the ground state\ncould very precisely reproduce the DFT predictions for the mechanical\nproperties of the BO monolayer. The elastic modulus, tensile strength and\nlattice thermal conductivity of the BO monolayer at room temperature are\npredicted to be 107 GPa, 25 GPa and 5.6 W/mK, respectively. At the room\ntemperature the BO monolayer is noticeably predicted to yield an ultrahigh\nnegative thermal expansion coefficient, by almost 17 folds larger than that of\nthe single-layer graphene. The presented results reveal the large indirect\nelectronic band gap, decent thermal and dynamical stability, anomalously low\nelastic modulus to tensile strength ratio, ultrahigh negative thermal expansion\ncoefficients and low lattice thermal conductivity of the BO monolayer.",
            "author": [
                "Bohayra Mortazavi",
                "Fazel Shojaei",
                "Fei Ding",
                "Xiaoying Zhuang"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.flatc.2023.100575",
                "http://arxiv.org/abs/2310.19485v1",
                "http://arxiv.org/pdf/2310.19485v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19477v2",
            "title": "VDIP-TGV: Blind Image Deconvolution via Variational Deep Image Prior\n  Empowered by Total Generalized Variation",
            "updated": "2023-11-10T14:26:34Z",
            "published": "2023-10-30T12:03:18Z",
            "summary": "Recovering clear images from blurry ones with an unknown blur kernel is a\nchallenging problem. Deep image prior (DIP) proposes to use the deep network as\na regularizer for a single image rather than as a supervised model, which\nachieves encouraging results in the nonblind deblurring problem. However, since\nthe relationship between images and the network architectures is unclear, it is\nhard to find a suitable architecture to provide sufficient constraints on the\nestimated blur kernels and clean images. Also, DIP uses the sparse maximum a\nposteriori (MAP), which is insufficient to enforce the selection of the\nrecovery image. Recently, variational deep image prior (VDIP) was proposed to\nimpose constraints on both blur kernels and recovery images and take the\nstandard deviation of the image into account during the optimization process by\nthe variational principle. However, we empirically find that VDIP struggles\nwith processing image details and tends to generate suboptimal results when the\nblur kernel is large. Therefore, we combine total generalized variational (TGV)\nregularization with VDIP in this paper to overcome these shortcomings of VDIP.\nTGV is a flexible regularization that utilizes the characteristics of partial\nderivatives of varying orders to regularize images at different scales,\nreducing oil painting artifacts while maintaining sharp edges. The proposed\nVDIP-TGV effectively recovers image edges and details by supplementing extra\ngradient information through TGV. Additionally, this model is solved by the\nalternating direction method of multipliers (ADMM), which effectively combines\ntraditional algorithms and deep learning methods. Experiments show that our\nproposed VDIP-TGV surpasses various state-of-the-art models quantitatively and\nqualitatively.",
            "author": [
                "Tingting Wu",
                "Zhiyan Du",
                "Zhi Li",
                "Feng-Lei Fan",
                "Tieyong Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19477v2",
                "http://arxiv.org/pdf/2310.19477v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19470v1",
            "title": "Grokking Tickets: Lottery Tickets Accelerate Grokking",
            "updated": "2023-10-30T11:58:44Z",
            "published": "2023-10-30T11:58:44Z",
            "summary": "Grokking is one of the most surprising puzzles in neural network\ngeneralization: a network first reaches a memorization solution with perfect\ntraining accuracy and poor generalization, but with further training, it\nreaches a perfectly generalized solution. We aim to analyze the mechanism of\ngrokking from the lottery ticket hypothesis, identifying the process to find\nthe lottery tickets (good sparse subnetworks) as the key to describing the\ntransitional phase between memorization and generalization. We refer to these\nsubnetworks as ''Grokking tickets'', which is identified via magnitude pruning\nafter perfect generalization. First, using ''Grokking tickets'', we show that\nthe lottery tickets drastically accelerate grokking compared to the dense\nnetworks on various configurations (MLP and Transformer, and an arithmetic and\nimage classification tasks). Additionally, to verify that ''Grokking ticket''\nare a more critical factor than weight norms, we compared the ''good''\nsubnetworks with a dense network having the same L1 and L2 norms. Results show\nthat the subnetworks generalize faster than the controlled dense model. In\nfurther investigations, we discovered that at an appropriate pruning rate,\ngrokking can be achieved even without weight decay. We also show that speedup\ndoes not happen when using tickets identified at the memorization solution or\ntransition between memorization and generalization or when pruning networks at\nthe initialization (Random pruning, Grasp, SNIP, and Synflow). The results\nindicate that the weight norm of network parameters is not enough to explain\nthe process of grokking, but the importance of finding good subnetworks to\ndescribe the transition from memorization to generalization. The implementation\ncode can be accessed via this link:\n\\url{https://github.com/gouki510/Grokking-Tickets}.",
            "author": [
                "Gouki Minegishi",
                "Yusuke Iwasawa",
                "Yutaka Matsuo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19470v1",
                "http://arxiv.org/pdf/2310.19470v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19468v1",
            "title": "Regret-Minimization Algorithms for Multi-Agent Cooperative Learning\n  Systems",
            "updated": "2023-10-30T11:50:31Z",
            "published": "2023-10-30T11:50:31Z",
            "summary": "A Multi-Agent Cooperative Learning (MACL) system is an artificial\nintelligence (AI) system where multiple learning agents work together to\ncomplete a common task. Recent empirical success of MACL systems in various\ndomains (e.g. traffic control, cloud computing, robotics) has sparked active\nresearch into the design and analysis of MACL systems for sequential decision\nmaking problems. One important metric of the learning algorithm for decision\nmaking problems is its regret, i.e. the difference between the highest\nachievable reward and the actual reward that the algorithm gains. The design\nand development of a MACL system with low-regret learning algorithms can create\nhuge economic values. In this thesis, I analyze MACL systems for different\nsequential decision making problems. Concretely, the Chapter 3 and 4\ninvestigate the cooperative multi-agent multi-armed bandit problems, with\nfull-information or bandit feedback, in which multiple learning agents can\nexchange their information through a communication network and the agents can\nonly observe the rewards of the actions they choose. Chapter 5 considers the\ncommunication-regret trade-off for online convex optimization in the\ndistributed setting. Chapter 6 discusses how to form high-productive teams for\nagents based on their unknown but fixed types using adaptive incremental\nmatchings. For the above problems, I present the regret lower bounds for\nfeasible learning algorithms and provide the efficient algorithms to achieve\nthis bound. The regret bounds I present in Chapter 3, 4 and 5 quantify how the\nregret depends on the connectivity of the communication network and the\ncommunication delay, thus giving useful guidance on design of the communication\nprotocol in MACL systems",
            "author": [
                "Jialin Yi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19468v1",
                "http://arxiv.org/pdf/2310.19468v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19464v1",
            "title": "Generative Neural Fields by Mixtures of Neural Implicit Functions",
            "updated": "2023-10-30T11:41:41Z",
            "published": "2023-10-30T11:41:41Z",
            "summary": "We propose a novel approach to learning the generative neural fields\nrepresented by linear combinations of implicit basis networks. Our algorithm\nlearns basis networks in the form of implicit neural representations and their\ncoefficients in a latent space by either conducting meta-learning or adopting\nauto-decoding paradigms. The proposed method easily enlarges the capacity of\ngenerative neural fields by increasing the number of basis networks while\nmaintaining the size of a network for inference to be small through their\nweighted model averaging. Consequently, sampling instances using the model is\nefficient in terms of latency and memory footprint. Moreover, we customize\ndenoising diffusion probabilistic model for a target task to sample latent\nmixture coefficients, which allows our final model to generate unseen data\neffectively. Experiments show that our approach achieves competitive generation\nperformance on diverse benchmarks for images, voxel data, and NeRF scenes\nwithout sophisticated designs for specific modalities and domains.",
            "author": [
                "Tackgeun You",
                "Mijeong Kim",
                "Jungtaek Kim",
                "Bohyung Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19464v1",
                "http://arxiv.org/pdf/2310.19464v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19463v1",
            "title": "Optimize Planning Heuristics to Rank, not to Estimate Cost-to-Goal",
            "updated": "2023-10-30T11:39:49Z",
            "published": "2023-10-30T11:39:49Z",
            "summary": "In imitation learning for planning, parameters of heuristic functions are\noptimized against a set of solved problem instances. This work revisits the\nnecessary and sufficient conditions of strictly optimally efficient heuristics\nfor forward search algorithms, mainly A* and greedy best-first search, which\nexpand only states on the returned optimal path. It then proposes a family of\nloss functions based on ranking tailored for a given variant of the forward\nsearch algorithm. Furthermore, from a learning theory point of view, it\ndiscusses why optimizing cost-to-goal \\hstar\\ is unnecessarily difficult. The\nexperimental comparison on a diverse set of problems unequivocally supports the\nderived theory.",
            "author": [
                "Leah Chrestien",
                "Tom\u00e1s Pevn\u00fd",
                "Stefan Edelkamp",
                "Anton\u00edn Komenda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19463v1",
                "http://arxiv.org/pdf/2310.19463v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19462v2",
            "title": "Constituency Parsing using LLMs",
            "updated": "2023-10-31T07:19:51Z",
            "published": "2023-10-30T11:39:11Z",
            "summary": "Constituency parsing is a fundamental yet unsolved natural language\nprocessing task. In this paper, we explore the potential of recent large\nlanguage models (LLMs) that have exhibited remarkable performance across\nvarious domains and tasks to tackle this task. We employ three linearization\nstrategies to transform output trees into symbol sequences, such that LLMs can\nsolve constituency parsing by generating linearized trees. We conduct\nexperiments using a diverse range of LLMs, including ChatGPT, GPT-4, OPT,\nLLaMA, and Alpaca, comparing their performance against the state-of-the-art\nconstituency parsers. Our experiments encompass zero-shot, few-shot, and\nfull-training learning settings, and we evaluate the models on one in-domain\nand five out-of-domain test datasets. Our findings reveal insights into LLMs'\nperformance, generalization abilities, and challenges in constituency parsing.",
            "author": [
                "Xuefeng Bai",
                "Jialong Wu",
                "Yulong Chen",
                "Zhongqing Wang",
                "Yue Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19462v2",
                "http://arxiv.org/pdf/2310.19462v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19460v1",
            "title": "Denoising Diffusion Probabilistic Models for Hardware-Impaired\n  Communication Systems: Towards Wireless Generative AI",
            "updated": "2023-10-30T11:33:01Z",
            "published": "2023-10-30T11:33:01Z",
            "summary": "Thanks to the outstanding achievements from state-of-the-art generative\nmodels like ChatGPT and diffusion models, generative AI has gained substantial\nattention across various industrial and academic domains. In this paper,\ndenoising diffusion probabilistic models (DDPMs) are proposed for a practical\nfinite-precision wireless communication system with hardware-impaired\ntransceivers. The intuition behind DDPM is to decompose the data generation\nprocess over the so-called \"denoising\" steps. Inspired by this, a DDPM-based\nreceiver is proposed for a practical wireless communication scheme that faces\nrealistic non-idealities, including hardware impairments (HWI), channel\ndistortions, and quantization errors. It is shown that our approach provides\nnetwork resilience under low-SNR regimes, near-invariant reconstruction\nperformance with respect to different HWI levels and quantization errors, and\nrobust out-of-distribution performance against non-Gaussian noise. Moreover,\nthe reconstruction performance of our scheme is evaluated in terms of cosine\nsimilarity and mean-squared error (MSE), highlighting more than 25 dB\nimprovement compared to the conventional deep neural network (DNN)-based\nreceivers.",
            "author": [
                "Mehdi Letafati",
                "Samad Ali",
                "Matti Latva-aho"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19460v1",
                "http://arxiv.org/pdf/2310.19460v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19459v2",
            "title": "Security Challenges for Cloud or Fog Computing-Based AI Applications",
            "updated": "2023-11-03T08:40:42Z",
            "published": "2023-10-30T11:32:50Z",
            "summary": "Security challenges for Cloud or Fog-based machine learning services pose\nseveral concerns. Securing the underlying Cloud or Fog services is essential,\nas successful attacks against these services, on which machine learning\napplications rely, can lead to significant impairments of these applications.\nBecause the requirements for AI applications can also be different, we\ndifferentiate according to whether they are used in the Cloud or in a Fog\nComputing network. This then also results in different threats or attack\npossibilities. For Cloud platforms, the responsibility for security can be\ndivided between different parties. Security deficiencies at a lower level can\nhave a direct impact on the higher level where user data is stored. While\nresponsibilities are simpler for Fog Computing networks, by moving services to\nthe edge of the network, we have to secure them against physical access to the\ndevices. We conclude by outlining specific information security requirements\nfor AI applications.",
            "author": [
                "Amir Pakmehr",
                "Andreas A\u00dfmuth",
                "Christoph P. Neumann",
                "Gerald Pirkl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19459v2",
                "http://arxiv.org/pdf/2310.19459v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19454v1",
            "title": "MMM and MMMSynth: Clustering of heterogeneous tabular data, and\n  synthetic data generation",
            "updated": "2023-10-30T11:26:01Z",
            "published": "2023-10-30T11:26:01Z",
            "summary": "We provide new algorithms for two tasks relating to heterogeneous tabular\ndatasets: clustering, and synthetic data generation. Tabular datasets typically\nconsist of heterogeneous data types (numerical, ordinal, categorical) in\ncolumns, but may also have hidden cluster structure in their rows: for example,\nthey may be drawn from heterogeneous (geographical, socioeconomic,\nmethodological) sources, such that the outcome variable they describe (such as\nthe presence of a disease) may depend not only on the other variables but on\nthe cluster context. Moreover, sharing of biomedical data is often hindered by\npatient confidentiality laws, and there is current interest in algorithms to\ngenerate synthetic tabular data from real data, for example via deep learning.\n  We demonstrate a novel EM-based clustering algorithm, MMM (``Madras Mixture\nModel''), that outperforms standard algorithms in determining clusters in\nsynthetic heterogeneous data, and recovers structure in real data. Based on\nthis, we demonstrate a synthetic tabular data generation algorithm, MMMsynth,\nthat pre-clusters the input data, and generates cluster-wise synthetic data\nassuming cluster-specific data distributions for the input columns. We\nbenchmark this algorithm by testing the performance of standard ML algorithms\nwhen they are trained on synthetic data and tested on real published datasets.\nOur synthetic data generation algorithm outperforms other literature\ntabular-data generators, and approaches the performance of training purely with\nreal data.",
            "author": [
                "Chandrani Kumari",
                "Rahul Siddharthan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19454v1",
                "http://arxiv.org/pdf/2310.19454v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19450v2",
            "title": "Hodge-Compositional Edge Gaussian Processes",
            "updated": "2023-10-31T11:57:06Z",
            "published": "2023-10-30T11:22:25Z",
            "summary": "We propose principled Gaussian processes (GPs) for modeling functions defined\nover the edge set of a simplicial 2-complex, a structure similar to a graph in\nwhich edges may form triangular faces. This approach is intended for learning\nflow-type data on networks where edge flows can be characterized by the\ndiscrete divergence and curl. Drawing upon the Hodge decomposition, we first\ndevelop classes of divergence-free and curl-free edge GPs, suitable for various\napplications. We then combine them to create \\emph{Hodge-compositional edge\nGPs} that are expressive enough to represent any edge function. These GPs\nfacilitate direct and independent learning for the different Hodge components\nof edge functions, enabling us to capture their relevance during hyperparameter\noptimization. To highlight their practical potential, we apply them for flow\ndata inference in currency exchange, ocean flows and water supply networks,\ncomparing them to alternative models.",
            "author": [
                "Maosheng Yang",
                "Viacheslav Borovitskiy",
                "Elvin Isufi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19450v2",
                "http://arxiv.org/pdf/2310.19450v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19449v1",
            "title": "Large-Scale Application of Fault Injection into PyTorch Models -- an\n  Extension to PyTorchFI for Validation Efficiency",
            "updated": "2023-10-30T11:18:35Z",
            "published": "2023-10-30T11:18:35Z",
            "summary": "Transient or permanent faults in hardware can render the output of Neural\nNetworks (NN) incorrect without user-specific traces of the error, i.e. silent\ndata errors (SDE). On the other hand, modern NNs also possess an inherent\nredundancy that can tolerate specific faults. To establish a safety case, it is\nnecessary to distinguish and quantify both types of corruptions. To study the\neffects of hardware (HW) faults on software (SW) in general and NN models in\nparticular, several fault injection (FI) methods have been established in\nrecent years. Current FI methods focus on the methodology of injecting faults\nbut often fall short of accounting for large-scale FI tests, where many fault\nlocations based on a particular fault model need to be analyzed in a short\ntime. Results need to be concise, repeatable, and comparable. To address these\nrequirements and enable fault injection as the default component in a machine\nlearning development cycle, we introduce a novel fault injection framework\ncalled PyTorchALFI (Application Level Fault Injection for PyTorch) based on\nPyTorchFI. PyTorchALFI provides an efficient way to define randomly generated\nand reusable sets of faults to inject into PyTorch models, defines complex test\nscenarios, enhances data sets, and generates test KPIs while tightly coupling\nfault-free, faulty, and modified NN. In this paper, we provide details about\nthe definition of test scenarios, software architecture, and several examples\nof how to use the new framework to apply iterative changes in fault location\nand number, compare different model modifications, and analyze test results.",
            "author": [
                "Ralf Graafe",
                "Qutub Syed Sha",
                "Florian Geissler",
                "Michael Paulitsch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19449v1",
                "http://arxiv.org/pdf/2310.19449v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19445v1",
            "title": "A Federated Learning Framework for Stenosis Detection",
            "updated": "2023-10-30T11:13:40Z",
            "published": "2023-10-30T11:13:40Z",
            "summary": "This study explores the use of Federated Learning (FL) for stenosis detection\nin coronary angiography images (CA). Two heterogeneous datasets from two\ninstitutions were considered: Dataset 1 includes 1219 images from 200 patients,\nwhich we acquired at the Ospedale Riuniti of Ancona (Italy); Dataset 2 includes\n7492 sequential images from 90 patients from a previous study available in the\nliterature. Stenosis detection was performed by using a Faster R-CNN model. In\nour FL framework, only the weights of the model backbone were shared among the\ntwo client institutions, using Federated Averaging (FedAvg) for weight\naggregation. We assessed the performance of stenosis detection using Precision\n(P rec), Recall (Rec), and F1 score (F1). Our results showed that the FL\nframework does not substantially affects clients 2 performance, which already\nachieved good performance with local training; for client 1, instead, FL\nframework increases the performance with respect to local model of +3.76%,\n+17.21% and +10.80%, respectively, reaching P rec = 73.56, Rec = 67.01 and F1 =\n70.13. With such results, we showed that FL may enable multicentric studies\nrelevant to automatic stenosis detection in CA by addressing data heterogeneity\nfrom various institutions, while preserving patient privacy.",
            "author": [
                "Mariachiara Di Cosmo",
                "Giovanna Migliorelli",
                "Matteo Francioni",
                "Andi Mucaj",
                "Alessandro Maolo",
                "Alessandro Aprile",
                "Emanuele Frontoni",
                "Maria Chiara Fiorentino",
                "Sara Moccia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19445v1",
                "http://arxiv.org/pdf/2310.19445v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19444v1",
            "title": "One-for-All: Bridge the Gap Between Heterogeneous Architectures in\n  Knowledge Distillation",
            "updated": "2023-10-30T11:13:02Z",
            "published": "2023-10-30T11:13:02Z",
            "summary": "Knowledge distillation~(KD) has proven to be a highly effective approach for\nenhancing model performance through a teacher-student training scheme. However,\nmost existing distillation methods are designed under the assumption that the\nteacher and student models belong to the same model family, particularly the\nhint-based approaches. By using centered kernel alignment (CKA) to compare the\nlearned features between heterogeneous teacher and student models, we observe\nsignificant feature divergence. This divergence illustrates the ineffectiveness\nof previous hint-based methods in cross-architecture distillation. To tackle\nthe challenge in distilling heterogeneous models, we propose a simple yet\neffective one-for-all KD framework called OFA-KD, which significantly improves\nthe distillation performance between heterogeneous architectures. Specifically,\nwe project intermediate features into an aligned latent space such as the\nlogits space, where architecture-specific information is discarded.\nAdditionally, we introduce an adaptive target enhancement scheme to prevent the\nstudent from being disturbed by irrelevant information. Extensive experiments\nwith various architectures, including CNN, Transformer, and MLP, demonstrate\nthe superiority of our OFA-KD framework in enabling distillation between\nheterogeneous architectures. Specifically, when equipped with our OFA-KD, the\nstudent models achieve notable performance improvements, with a maximum gain of\n8.0% on the CIFAR-100 dataset and 0.7% on the ImageNet-1K dataset. PyTorch code\nand checkpoints can be found at https://github.com/Hao840/OFAKD.",
            "author": [
                "Zhiwei Hao",
                "Jianyuan Guo",
                "Kai Han",
                "Yehui Tang",
                "Han Hu",
                "Yunhe Wang",
                "Chang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19444v1",
                "http://arxiv.org/pdf/2310.19444v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19439v1",
            "title": "Asymmetric Diffusion Based Channel-Adaptive Secure Wireless Semantic\n  Communications",
            "updated": "2023-10-30T11:00:47Z",
            "published": "2023-10-30T11:00:47Z",
            "summary": "Semantic communication has emerged as a new deep learning-based communication\nparadigm that drives the research of end-to-end data transmission in tasks like\nimage classification, and image reconstruction. However, the security problem\ncaused by semantic attacks has not been well explored, resulting in\nvulnerabilities within semantic communication systems exposed to potential\nsemantic perturbations. In this paper, we propose a secure semantic\ncommunication system, DiffuSeC, which leverages the diffusion model and deep\nreinforcement learning (DRL) to address this issue. With the diffusing module\nin the sender end and the asymmetric denoising module in the receiver end, the\nDiffuSeC mitigates the perturbations added by semantic attacks, including data\nsource attacks and channel attacks. To further improve the robustness under\nunstable channel conditions caused by semantic attacks, we developed a\nDRL-based channel-adaptive diffusion step selection scheme to achieve stable\nperformance under fluctuating environments. A timestep synchronization scheme\nis designed for diffusion timestep coordination between the two ends.\nSimulation results demonstrate that the proposed DiffuSeC shows higher robust\naccuracy than previous works under a wide range of channel conditions, and can\nquickly adjust the model state according to signal-to-noise ratios (SNRs) in\nunstable environments.",
            "author": [
                "Xintian Ren",
                "Jun Wu",
                "Hansong Xu",
                "Qianqian Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19439v1",
                "http://arxiv.org/pdf/2310.19439v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19433v1",
            "title": "Ordinal classification for interval-valued data and interval-valued\n  functional data",
            "updated": "2023-10-30T10:45:03Z",
            "published": "2023-10-30T10:45:03Z",
            "summary": "The aim of ordinal classification is to predict the ordered labels of the\noutput from a set of observed inputs. Interval-valued data refers to data in\nthe form of intervals. For the first time, interval-valued data and\ninterval-valued functional data are considered as inputs in an ordinal\nclassification problem. Six ordinal classifiers for interval data and\ninterval-valued functional data are proposed. Three of them are parametric, one\nof them is based on ordinal binary decompositions and the other two are based\non ordered logistic regression. The other three methods are based on the use of\ndistances between interval data and kernels on interval data. One of the\nmethods uses the weighted $k$-nearest-neighbor technique for ordinal\nclassification. Another method considers kernel principal component analysis\nplus an ordinal classifier. And the sixth method, which is the method that\nperforms best, uses a kernel-induced ordinal random forest. They are compared\nwith na\\\"ive approaches in an extensive experimental study with synthetic and\noriginal real data sets, about human global development, and weather data. The\nresults show that considering ordering and interval-valued information improves\nthe accuracy. The source code and data sets are available at\nhttps://github.com/aleixalcacer/OCFIVD.",
            "author": [
                "Aleix Alcacer",
                "Marina Mart\u00ednez-Garcia",
                "Irene Epifanio"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.eswa.2023.122277",
                "http://arxiv.org/abs/2310.19433v1",
                "http://arxiv.org/pdf/2310.19433v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP",
                "stat.ML",
                "62H30, 62R10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19432v1",
            "title": "Explaining the Decisions of Deep Policy Networks for Robotic\n  Manipulations",
            "updated": "2023-10-30T10:44:12Z",
            "published": "2023-10-30T10:44:12Z",
            "summary": "Deep policy networks enable robots to learn behaviors to solve various\nreal-world complex tasks in an end-to-end fashion. However, they lack\ntransparency to provide the reasons of actions. Thus, such a black-box model\noften results in low reliability and disruptive actions during the deployment\nof the robot in practice. To enhance its transparency, it is important to\nexplain robot behaviors by considering the extent to which each input feature\ncontributes to determining a given action. In this paper, we present an\nexplicit analysis of deep policy models through input attribution methods to\nexplain how and to what extent each input feature affects the decisions of the\nrobot policy models. To this end, we present two methods for applying input\nattribution methods to robot policy networks: (1) we measure the importance\nfactor of each joint torque to reflect the influence of the motor torque on the\nend-effector movement, and (2) we modify a relevance propagation method to\nhandle negative inputs and outputs in deep policy networks properly. To the\nbest of our knowledge, this is the first report to identify the dynamic changes\nof input attributions of multi-modal sensor inputs in deep policy networks\nonline for robotic manipulation.",
            "author": [
                "Seongun Kim",
                "Jaesik Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19432v1",
                "http://arxiv.org/pdf/2310.19432v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19430v1",
            "title": "Roadmap on Photovoltaic Absorber Materials for Sustainable Energy\n  Conversion",
            "updated": "2023-10-30T10:43:25Z",
            "published": "2023-10-30T10:43:25Z",
            "summary": "Photovoltaics (PVs) are a critical technology for curbing growing levels of\nanthropogenic greenhouse gas emissions, and meeting increases in future demand\nfor low-carbon electricity. In order to fulfil ambitions for net-zero carbon\ndioxide equivalent (CO<sub>2</sub>eq) emissions worldwide, the global\ncumulative capacity of solar PVs must increase by an order of magnitude from\n0.9 TWp in 2021 to 8.5 TWp by 2050 according to the International Renewable\nEnergy Agency, which is considered to be a highly conservative estimate. In\n2020, the Henry Royce Institute brought together the UK PV community to discuss\nthe critical technological and infrastructure challenges that need to be\novercome to address the vast challenges in accelerating PV deployment. Herein,\nwe examine the key developments in the global community, especially the\nprogress made in the field since this earlier roadmap, bringing together\nexperts primarily from the UK across the breadth of the photovoltaics\ncommunity. The focus is both on the challenges in improving the efficiency,\nstability and levelized cost of electricity of current technologies for\nutility-scale PVs, as well as the fundamental questions in novel technologies\nthat can have a significant impact on emerging markets, such as indoor PVs,\nspace PVs, and agrivoltaics. We discuss challenges in advanced metrology and\ncomputational tools, as well as the growing synergies between PVs and solar\nfuels, and offer a perspective on the environmental sustainability of the PV\nindustry. Through this roadmap, we emphasize promising pathways forward in both\nthe short- and long-term, and for communities working on technologies across a\nrange of maturity levels to learn from each other.",
            "author": [
                "James C. Blakesley",
                "Ruy S. Bonilla",
                "Marina Freitag",
                "Alex M. Ganose",
                "Nicola Gasparini",
                "Pascal Kaienburg",
                "George Koutsourakis",
                "Jonathan D. Major",
                "Jenny Nelson",
                "Nakita K. Noel",
                "Bart Roose",
                "Jae Sung Yun",
                "Simon Aliwell",
                "Pietro P. Altermatt",
                "Tayebeh Ameri",
                "Virgil Andrei",
                "Ardalan Armin",
                "Diego Bagnis",
                "Jenny Baker",
                "Hamish Beath",
                "Mathieu Bellanger",
                "Philippe Berrouard",
                "Jochen Blumberger",
                "Stuart A. Boden",
                "Hugo Bronstein",
                "Matthew J. Carnie",
                "Chris Case",
                "Fernando A. Castro",
                "Yi-Ming Chang",
                "Elmer Chao",
                "Tracey M. Clarke",
                "Graeme Cooke",
                "Pablo Docampo",
                "Ken Durose",
                "James R. Durrant",
                "Marina R. Filip",
                "Richard H. Friend",
                "Jarvist M. Frost",
                "Elizabeth A. Gibson",
                "Alexander J. Gillett",
                "Pooja Goddard",
                "Severin N. Habisreutinger",
                "Martin Heeney",
                "Arthur D. Hendsbee",
                "Louise C. Hirst",
                "M. Saiful Islam",
                "K. D. G. Imalka Jayawardena",
                "Michael B. Johnston",
                "Matthias Kauer",
                "Jeff Kettle",
                "Ji-Seon Kim",
                "Dan Lamb",
                "David Lidzey",
                "Jihoo Lim",
                "Roderick MacKenzie",
                "Nigel Mason",
                "Iain McCulloch",
                "Keith P. McKenna",
                "Sebastian B. Meier",
                "Paul Meredith",
                "Graham Morse",
                "John D. Murphy",
                "Chris Nicklin",
                "Paloma Ortega-Arriaga",
                "Thomas Osterberg",
                "Jay B. Patel",
                "Anthony Peaker",
                "Moritz Riede",
                "Martyn Rush",
                "James W. Ryan",
                "David O. Scanlon",
                "Peter J. Skabara",
                "Franky So",
                "Henry J. Snaith",
                "Ludmilla Steier",
                "Jarla Thiesbrummel",
                "Alessandro Troisi",
                "Craig Underwood",
                "Karsten Walzer",
                "Trystan Watson",
                "J. Michael Walls",
                "Aron Walsh",
                "Lucy D. Whalley",
                "Benedict Winchester",
                "Samuel D. Stranks",
                "Robert L. Z. Hoye"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19430v1",
                "http://arxiv.org/pdf/2310.19430v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19427v1",
            "title": "Refining Diffusion Planner for Reliable Behavior Synthesis by Automatic\n  Detection of Infeasible Plans",
            "updated": "2023-10-30T10:35:42Z",
            "published": "2023-10-30T10:35:42Z",
            "summary": "Diffusion-based planning has shown promising results in long-horizon,\nsparse-reward tasks by training trajectory diffusion models and conditioning\nthe sampled trajectories using auxiliary guidance functions. However, due to\ntheir nature as generative models, diffusion models are not guaranteed to\ngenerate feasible plans, resulting in failed execution and precluding planners\nfrom being useful in safety-critical applications. In this work, we propose a\nnovel approach to refine unreliable plans generated by diffusion models by\nproviding refining guidance to error-prone plans. To this end, we suggest a new\nmetric named restoration gap for evaluating the quality of individual plans\ngenerated by the diffusion model. A restoration gap is estimated by a gap\npredictor which produces restoration gap guidance to refine a diffusion\nplanner. We additionally present an attribution map regularizer to prevent\nadversarial refining guidance that could be generated from the sub-optimal gap\npredictor, which enables further refinement of infeasible plans. We demonstrate\nthe effectiveness of our approach on three different benchmarks in offline\ncontrol settings that require long-horizon planning. We also illustrate that\nour approach presents explainability by presenting the attribution maps of the\ngap predictor and highlighting error-prone transitions, allowing for a deeper\nunderstanding of the generated plans.",
            "author": [
                "Kyowoon Lee",
                "Seongun Kim",
                "Jaesik Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19427v1",
                "http://arxiv.org/pdf/2310.19427v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19424v1",
            "title": "Variational Curriculum Reinforcement Learning for Unsupervised Discovery\n  of Skills",
            "updated": "2023-10-30T10:34:25Z",
            "published": "2023-10-30T10:34:25Z",
            "summary": "Mutual information-based reinforcement learning (RL) has been proposed as a\npromising framework for retrieving complex skills autonomously without a\ntask-oriented reward function through mutual information (MI) maximization or\nvariational empowerment. However, learning complex skills is still challenging,\ndue to the fact that the order of training skills can largely affect sample\nefficiency. Inspired by this, we recast variational empowerment as curriculum\nlearning in goal-conditioned RL with an intrinsic reward function, which we\nname Variational Curriculum RL (VCRL). From this perspective, we propose a\nnovel approach to unsupervised skill discovery based on information theory,\ncalled Value Uncertainty Variational Curriculum (VUVC). We prove that, under\nregularity conditions, VUVC accelerates the increase of entropy in the visited\nstates compared to the uniform curriculum. We validate the effectiveness of our\napproach on complex navigation and robotic manipulation tasks in terms of\nsample efficiency and state coverage speed. We also demonstrate that the skills\ndiscovered by our method successfully complete a real-world robot navigation\ntask in a zero-shot setup and that incorporating these skills with a global\nplanner further increases the performance.",
            "author": [
                "Seongun Kim",
                "Kyowoon Lee",
                "Jaesik Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19424v1",
                "http://arxiv.org/pdf/2310.19424v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19420v1",
            "title": "Mean BERTs make erratic language teachers: the effectiveness of latent\n  bootstrapping in low-resource settings",
            "updated": "2023-10-30T10:31:32Z",
            "published": "2023-10-30T10:31:32Z",
            "summary": "This paper explores the use of latent bootstrapping, an alternative\nself-supervision technique, for pretraining language models. Unlike the typical\npractice of using self-supervision on discrete subwords, latent bootstrapping\nleverages contextualized embeddings for a richer supervision signal. We conduct\nexperiments to assess how effective this approach is for acquiring linguistic\nknowledge from limited resources. Specifically, our experiments are based on\nthe BabyLM shared task, which includes pretraining on two small curated corpora\nand an evaluation on four linguistic benchmarks.",
            "author": [
                "David Samuel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19420v1",
                "http://arxiv.org/pdf/2310.19420v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19418v1",
            "title": "GaitFormer: Learning Gait Representations with Noisy Multi-Task Learning",
            "updated": "2023-10-30T10:28:44Z",
            "published": "2023-10-30T10:28:44Z",
            "summary": "Gait analysis is proven to be a reliable way to perform person identification\nwithout relying on subject cooperation. Walking is a biometric that does not\nsignificantly change in short periods of time and can be regarded as unique to\neach person. So far, the study of gait analysis focused mostly on\nidentification and demographics estimation, without considering many of the\npedestrian attributes that appearance-based methods rely on. In this work,\nalongside gait-based person identification, we explore pedestrian attribute\nidentification solely from movement patterns. We propose DenseGait, the largest\ndataset for pretraining gait analysis systems containing 217K anonymized\ntracklets, annotated automatically with 42 appearance attributes. DenseGait is\nconstructed by automatically processing video streams and offers the full array\nof gait covariates present in the real world. We make the dataset available to\nthe research community. Additionally, we propose GaitFormer, a\ntransformer-based model that after pretraining in a multi-task fashion on\nDenseGait, achieves 92.5% accuracy on CASIA-B and 85.33% on FVG, without\nutilizing any manually annotated data. This corresponds to a +14.2% and +9.67%\naccuracy increase compared to similar methods. Moreover, GaitFormer is able to\naccurately identify gender information and a multitude of appearance attributes\nutilizing only movement patterns. The code to reproduce the experiments is made\npublicly.",
            "author": [
                "Adrian Cosma",
                "Emilian Radoi"
            ],
            "link": [
                "http://dx.doi.org/10.3390/s22186803",
                "http://arxiv.org/abs/2310.19418v1",
                "http://arxiv.org/pdf/2310.19418v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19416v1",
            "title": "Machine learning on quantum experimental data toward solving quantum\n  many-body problems",
            "updated": "2023-10-30T10:25:59Z",
            "published": "2023-10-30T10:25:59Z",
            "summary": "Advancements in the implementation of quantum hardware have enabled the\nacquisition of data that are intractable for emulation with classical\ncomputers. The integration of classical machine learning (ML) algorithms with\nthese data holds potential for unveiling obscure patterns. Although this hybrid\napproach extends the class of efficiently solvable problems compared to using\nonly classical computers, this approach has been realized for solving\nrestricted problems because of the prevalence of noise in current quantum\ncomputers. Here, we extend the applicability of the hybrid approach to problems\nof interest in many-body physics, such as predicting the properties of the\nground state of a given Hamiltonian and classifying quantum phases. By\nperforming experiments with various error-reducing procedures on\nsuperconducting quantum hardware with 127 qubits, we managed to acquire refined\ndata from the quantum computer. This enabled us to demonstrate the successful\nimplementation of classical ML algorithms for systems with up to 44 qubits. Our\nresults verify the scalability and effectiveness of the classical ML algorithms\nfor processing quantum experimental data.",
            "author": [
                "Gyungmin Cho",
                "Dohun Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19416v1",
                "http://arxiv.org/pdf/2310.19416v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19411v1",
            "title": "Intelligent Breast Cancer Diagnosis with Heuristic-assisted\n  Trans-Res-U-Net and Multiscale DenseNet using Mammogram Images",
            "updated": "2023-10-30T10:22:14Z",
            "published": "2023-10-30T10:22:14Z",
            "summary": "Breast cancer (BC) significantly contributes to cancer-related mortality in\nwomen, underscoring the criticality of early detection for optimal patient\noutcomes. A mammography is a key tool for identifying and diagnosing breast\nabnormalities; however, accurately distinguishing malignant mass lesions\nremains challenging. To address this issue, we propose a novel deep learning\napproach for BC screening utilizing mammography images. Our proposed model\ncomprises three distinct stages: data collection from established benchmark\nsources, image segmentation employing an Atrous Convolution-based Attentive and\nAdaptive Trans-Res-UNet (ACA-ATRUNet) architecture, and BC identification via\nan Atrous Convolution-based Attentive and Adaptive Multi-scale DenseNet\n(ACA-AMDN) model. The hyperparameters within the ACA-ATRUNet and ACA-AMDN\nmodels are optimised using the Modified Mussel Length-based Eurasian\nOystercatcher Optimization (MML-EOO) algorithm. Performance evaluation,\nleveraging multiple metrics, is conducted, and a comparative analysis against\nconventional methods is presented. Our experimental findings reveal that the\nproposed BC detection framework attains superior precision rates in early\ndisease detection, demonstrating its potential to enhance mammography-based\nscreening methodologies.",
            "author": [
                "Muhammad Yaqub",
                "Feng Jinchao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19411v1",
                "http://arxiv.org/pdf/2310.19411v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19410v1",
            "title": "Generated Distributions Are All You Need for Membership Inference\n  Attacks Against Generative Models",
            "updated": "2023-10-30T10:21:26Z",
            "published": "2023-10-30T10:21:26Z",
            "summary": "Generative models have demonstrated revolutionary success in various visual\ncreation tasks, but in the meantime, they have been exposed to the threat of\nleaking private information of their training data. Several membership\ninference attacks (MIAs) have been proposed to exhibit the privacy\nvulnerability of generative models by classifying a query image as a training\ndataset member or nonmember. However, these attacks suffer from major\nlimitations, such as requiring shadow models and white-box access, and either\nignoring or only focusing on the unique property of diffusion models, which\nblock their generalization to multiple generative models. In contrast, we\npropose the first generalized membership inference attack against a variety of\ngenerative models such as generative adversarial networks, [variational]\nautoencoders, implicit functions, and the emerging diffusion models. We\nleverage only generated distributions from target generators and auxiliary\nnon-member datasets, therefore regarding target generators as black boxes and\nagnostic to their architectures or application scenarios. Experiments validate\nthat all the generative models are vulnerable to our attack. For instance, our\nwork achieves attack AUC $>0.99$ against DDPM, DDIM, and FastDPM trained on\nCIFAR-10 and CelebA. And the attack against VQGAN, LDM (for the\ntext-conditional generation), and LIIF achieves AUC $>0.90.$ As a result, we\nappeal to our community to be aware of such privacy leakage risks when\ndesigning and publishing generative models.",
            "author": [
                "Minxing Zhang",
                "Ning Yu",
                "Rui Wen",
                "Michael Backes",
                "Yang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19410v1",
                "http://arxiv.org/pdf/2310.19410v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19407v1",
            "title": "Resource Constrained Semantic Segmentation for Waste Sorting",
            "updated": "2023-10-30T10:19:40Z",
            "published": "2023-10-30T10:19:40Z",
            "summary": "This work addresses the need for efficient waste sorting strategies in\nMaterials Recovery Facilities to minimize the environmental impact of rising\nwaste. We propose resource-constrained semantic segmentation models for\nsegmenting recyclable waste in industrial settings. Our goal is to develop\nmodels that fit within a 10MB memory constraint, suitable for edge applications\nwith limited processing capacity. We perform the experiments on three networks:\nICNet, BiSeNet (Xception39 backbone), and ENet. Given the aforementioned\nlimitation, we implement quantization and pruning techniques on the broader\nnets, achieving positive results while marginally impacting the Mean IoU\nmetric. Furthermore, we propose a combination of Focal and Lov\\'asz loss that\naddresses the implicit class imbalance resulting in better performance compared\nwith the Cross-entropy loss function.",
            "author": [
                "Elisa Cascina",
                "Andrea Pellegrino",
                "Lorenzo Tozzi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19407v1",
                "http://arxiv.org/pdf/2310.19407v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19406v2",
            "title": "Discovering Black Hole Mass Scaling Relations with Symbolic Regression",
            "updated": "2023-11-20T10:33:36Z",
            "published": "2023-10-30T10:19:38Z",
            "summary": "Our knowledge of supermassive black holes (SMBHs) and their relation to their\nhost galaxies is still limited, and there are only around 150 SMBHs that have\ntheir masses directly measured and confirmed. Better black hole mass scaling\nrelations will help us reveal the physics of black holes, as well as predict\nblack hole masses that are not yet measured. Here, we apply symbolic\nregression, combined with random forest to those directly-measured black hole\nmasses and host galaxy properties, and find a collection of higher-dimensional\n(N-D) black hole mass scaling relations. These N-D black hole mass scaling\nrelations have scatter smaller than any of the existing black hole mass scaling\nrelations. One of the best among them involves the parameters of central\nstellar velocity dispersion, bulge-to-total ratio, and density at the black\nhole's sphere-of-influence with an intrinsic scatter of $\\epsilon=0.083\\,\\\n\\text{dex}$, significantly lower than $\\epsilon \\sim 0.3\\,\\ \\text{dex}$ for the\nM-$\\sigma$ relation. These relations will inspire black hole physics, test\nblack hole models implemented in simulations, and estimate unknown black hole\nmasses on an unprecedented precision.",
            "author": [
                "Zehao Jin",
                "Benjamin L. Davis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19406v2",
                "http://arxiv.org/pdf/2310.19406v2"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06284v1",
            "title": "Efficient Generation of Multimodal Fluid Simulation Data",
            "updated": "2023-10-30T10:05:11Z",
            "published": "2023-10-30T10:05:11Z",
            "summary": "Applying the representational power of machine learning to the prediction of\ncomplex fluid dynamics has been a relevant subject of study for years. However,\nthe amount of available fluid simulation data does not match the notoriously\nhigh requirements of machine learning methods. Researchers have typically\naddressed this issue by generating their own datasets, preventing a consistent\nevaluation of their proposed approaches. Our work introduces a generation\nprocedure for synthetic multi-modal fluid simulations datasets. By leveraging a\nGPU implementation, our procedure is also efficient enough that no data needs\nto be exchanged between users, except for configuration files required to\nreproduce the dataset. Furthermore, our procedure allows multiple modalities\n(generating both geometry and photorealistic renderings) and is general enough\nfor it to be applied to various tasks in data-driven fluid simulation. We then\nemploy our framework to generate a set of thoughtfully designed benchmark\ndatasets, which attempt to span specific fluid simulation scenarios in a\nmeaningful way. The properties of our contributions are demonstrated by\nevaluating recently published algorithms for the neural fluid simulation and\nfluid inverse rendering tasks using our benchmark datasets. Our contribution\naims to fulfill the community's need for standardized benchmarks, fostering\nresearch that is more reproducible and robust than previous endeavors.",
            "author": [
                "Daniele Baieri",
                "Donato Crisostomi",
                "Stefano Esposito",
                "Filippo Maggioli",
                "Emanuele Rodol\u00e0"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06284v1",
                "http://arxiv.org/pdf/2311.06284v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cs.GR",
                "physics.flu-dyn",
                "68U20",
                "I.2.6; I.3; I.6.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19394v1",
            "title": "LightSAGE: Graph Neural Networks for Large Scale Item Retrieval in\n  Shopee's Advertisement Recommendation",
            "updated": "2023-10-30T09:57:06Z",
            "published": "2023-10-30T09:57:06Z",
            "summary": "Graph Neural Network (GNN) is the trending solution for item retrieval in\nrecommendation problems. Most recent reports, however, focus heavily on new\nmodel architectures. This may bring some gaps when applying GNN in the\nindustrial setup, where, besides the model, constructing the graph and handling\ndata sparsity also play critical roles in the overall success of the project.\nIn this work, we report how GNN is applied for large-scale e-commerce item\nretrieval at Shopee. We introduce our simple yet novel and impactful techniques\nin graph construction, modeling, and handling data skewness. Specifically, we\nconstruct high-quality item graphs by combining strong-signal user behaviors\nwith high-precision collaborative filtering (CF) algorithm. We then develop a\nnew GNN architecture named LightSAGE to produce high-quality items' embeddings\nfor vector search. Finally, we design multiple strategies to handle cold-start\nand long-tail items, which are critical in an advertisement (ads) system. Our\nmodels bring improvement in offline evaluations, online A/B tests, and are\ndeployed to the main traffic of Shopee's Recommendation Advertisement system.",
            "author": [
                "Dang Minh Nguyen",
                "Chenfei Wang",
                "Yan Shen",
                "Yifan Zeng"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3604915.3608863",
                "http://arxiv.org/abs/2310.19394v1",
                "http://arxiv.org/pdf/2310.19394v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG",
                "H.3.3; I.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19392v1",
            "title": "A Clinical Guideline Driven Automated Linear Feature Extraction for\n  Vestibular Schwannoma",
            "updated": "2023-10-30T09:54:24Z",
            "published": "2023-10-30T09:54:24Z",
            "summary": "Vestibular Schwannoma is a benign brain tumour that grows from one of the\nbalance nerves. Patients may be treated by surgery, radiosurgery or with a\nconservative \"wait-and-scan\" strategy. Clinicians typically use manually\nextracted linear measurements to aid clinical decision making. This work aims\nto automate and improve this process by using deep learning based segmentation\nto extract relevant clinical features through computational algorithms. To the\nbest of our knowledge, our study is the first to propose an automated approach\nto replicate local clinical guidelines. Our deep learning based segmentation\nprovided Dice-scores of 0.8124 +- 0.2343 and 0.8969 +- 0.0521 for extrameatal\nand whole tumour regions respectively for T2 weighted MRI, whereas 0.8222 +-\n0.2108 and 0.9049 +- 0.0646 were obtained for T1 weighted MRI. We propose a\nnovel algorithm to choose and extract the most appropriate maximum linear\nmeasurement from the segmented regions based on the size of the extrameatal\nportion of the tumour. Using this tool, clinicians will be provided with a\nvisual guide and related metrics relating to tumour progression that will\nfunction as a clinical decision aid. In this study, we utilize 187 scans\nobtained from 50 patients referred to a tertiary specialist neurosurgical\nservice in the United Kingdom. The measurements extracted manually by an expert\nneuroradiologist indicated a significant correlation with the automated\nmeasurements (p < 0.0001).",
            "author": [
                "Navodini Wijethilake",
                "Steve Connor",
                "Anna Oviedova",
                "Rebecca Burger",
                "Tom Vercauteren",
                "Jonathan Shapey"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19392v1",
                "http://arxiv.org/pdf/2310.19392v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19391v1",
            "title": "Causal Fair Metric: Bridging Causality, Individual Fairness, and\n  Adversarial Robustness",
            "updated": "2023-10-30T09:53:42Z",
            "published": "2023-10-30T09:53:42Z",
            "summary": "Adversarial perturbation is used to expose vulnerabilities in machine\nlearning models, while the concept of individual fairness aims to ensure\nequitable treatment regardless of sensitive attributes. Despite their initial\ndifferences, both concepts rely on metrics to generate similar input data\ninstances. These metrics should be designed to align with the data's\ncharacteristics, especially when it is derived from causal structure and should\nreflect counterfactuals proximity. Previous attempts to define such metrics\noften lack general assumptions about data or structural causal models. In this\nresearch, we introduce a causal fair metric formulated based on causal\nstructures that encompass sensitive attributes. For robustness analysis, the\nconcept of protected causal perturbation is presented. Additionally, we delve\ninto metric learning, proposing a method for metric estimation and deployment\nin real-world problems. The introduced metric has applications in the fields\nadversarial training, fair learning, algorithmic recourse, and causal\nreinforcement learning.",
            "author": [
                "Ahmad-Reza Ehyaei",
                "Golnoosh Farnadi",
                "Samira Samadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19391v1",
                "http://arxiv.org/pdf/2310.19391v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19390v1",
            "title": "Implicit Manifold Gaussian Process Regression",
            "updated": "2023-10-30T09:52:48Z",
            "published": "2023-10-30T09:52:48Z",
            "summary": "Gaussian process regression is widely used because of its ability to provide\nwell-calibrated uncertainty estimates and handle small or sparse datasets.\nHowever, it struggles with high-dimensional data. One possible way to scale\nthis technique to higher dimensions is to leverage the implicit low-dimensional\nmanifold upon which the data actually lies, as postulated by the manifold\nhypothesis. Prior work ordinarily requires the manifold structure to be\nexplicitly provided though, i.e. given by a mesh or be known to be one of the\nwell-known manifolds like the sphere. In contrast, in this paper we propose a\nGaussian process regression technique capable of inferring implicit structure\ndirectly from data (labeled and unlabeled) in a fully differentiable way. For\nthe resulting model, we discuss its convergence to the Mat\\'ern Gaussian\nprocess on the assumed manifold. Our technique scales up to hundreds of\nthousands of data points, and may improve the predictive performance and\ncalibration of the standard Gaussian process regression in\nhigh-dimensional~settings.",
            "author": [
                "Bernardo Fichera",
                "Viacheslav Borovitskiy",
                "Andreas Krause",
                "Aude Billard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19390v1",
                "http://arxiv.org/pdf/2310.19390v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19385v2",
            "title": "Gradient-free online learning of subgrid-scale dynamics with neural\n  emulators",
            "updated": "2023-11-02T10:44:56Z",
            "published": "2023-10-30T09:46:35Z",
            "summary": "In this paper, we propose a generic algorithm to train machine learning-based\nsubgrid parametrizations online, i.e., with $\\textit{a posteriori}$ loss\nfunctions for non-differentiable numerical solvers. The proposed approach\nleverage neural emulators to train an approximation of the reduced state-space\nsolver, which is then used to allows gradient propagation through temporal\nintegration steps. The algorithm is able to recover most of the benefit of\nonline strategies without having to compute the gradient of the original\nsolver. It is demonstrated that training the neural emulator and\nparametrization components separately with respective loss quantities is\nnecessary in order to minimize the propagation of some approximation bias.",
            "author": [
                "Hugo Frezat",
                "Ronan Fablet",
                "Guillaume Balarac",
                "Julien Le Sommer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19385v2",
                "http://arxiv.org/pdf/2310.19385v2"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cs.LG",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19384v1",
            "title": "Deep anytime-valid hypothesis testing",
            "updated": "2023-10-30T09:46:19Z",
            "published": "2023-10-30T09:46:19Z",
            "summary": "We propose a general framework for constructing powerful, sequential\nhypothesis tests for a large class of nonparametric testing problems. The null\nhypothesis for these problems is defined in an abstract form using the action\nof two known operators on the data distribution. This abstraction allows for a\nunified treatment of several classical tasks, such as two-sample testing,\nindependence testing, and conditional-independence testing, as well as modern\nproblems, such as testing for adversarial robustness of machine learning (ML)\nmodels. Our proposed framework has the following advantages over classical\nbatch tests: 1) it continuously monitors online data streams and efficiently\naggregates evidence against the null, 2) it provides tight control over the\ntype I error without the need for multiple testing correction, 3) it adapts the\nsample size requirement to the unknown hardness of the problem. We develop a\nprincipled approach of leveraging the representation capability of ML models\nwithin the testing-by-betting framework, a game-theoretic approach for\ndesigning sequential tests. Empirical results on synthetic and real-world\ndatasets demonstrate that tests instantiated using our general framework are\ncompetitive against specialized baselines on several tasks.",
            "author": [
                "Teodora Pandeva",
                "Patrick Forr\u00e9",
                "Aaditya Ramdas",
                "Shubhanshu Shekhar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19384v1",
                "http://arxiv.org/pdf/2310.19384v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19381v1",
            "title": "Protecting Publicly Available Data With Machine Learning Shortcuts",
            "updated": "2023-10-30T09:38:03Z",
            "published": "2023-10-30T09:38:03Z",
            "summary": "Machine-learning (ML) shortcuts or spurious correlations are artifacts in\ndatasets that lead to very good training and test performance but severely\nlimit the model's generalization capability. Such shortcuts are insidious\nbecause they go unnoticed due to good in-domain test performance. In this\npaper, we explore the influence of different shortcuts and show that even\nsimple shortcuts are difficult to detect by explainable AI methods. We then\nexploit this fact and design an approach to defend online databases against\ncrawlers: providers such as dating platforms, clothing manufacturers, or used\ncar dealers have to deal with a professionalized crawling industry that grabs\nand resells data points on a large scale. We show that a deterrent can be\ncreated by deliberately adding ML shortcuts. Such augmented datasets are then\nunusable for ML use cases, which deters crawlers and the unauthorized use of\ndata from the internet. Using real-world data from three use cases, we show\nthat the proposed approach renders such collected data unusable, while the\nshortcut is at the same time difficult to notice in human perception. Thus, our\nproposed approach can serve as a proactive protection against illegitimate data\ncrawling.",
            "author": [
                "Nicolas M. M\u00fcller",
                "Maximilian Burgert",
                "Pascal Debus",
                "Jennifer Williams",
                "Philip Sperl",
                "Konstantin B\u00f6ttinger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19381v1",
                "http://arxiv.org/pdf/2310.19381v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19380v2",
            "title": "TransXNet: Learning Both Global and Local Dynamics with a Dual Dynamic\n  Token Mixer for Visual Recognition",
            "updated": "2023-11-30T01:48:03Z",
            "published": "2023-10-30T09:35:56Z",
            "summary": "Recent studies have integrated convolution into transformers to introduce\ninductive bias and improve generalization performance. However, the static\nnature of conventional convolution prevents it from dynamically adapting to\ninput variations, resulting in a representation discrepancy between convolution\nand self-attention as self-attention calculates attention matrices dynamically.\nFurthermore, when stacking token mixers that consist of convolution and\nself-attention to form a deep network, the static nature of convolution hinders\nthe fusion of features previously generated by self-attention into convolution\nkernels. These two limitations result in a sub-optimal representation capacity\nof the constructed networks. To find a solution, we propose a lightweight Dual\nDynamic Token Mixer (D-Mixer) that aggregates global information and local\ndetails in an input-dependent way. D-Mixer works by applying an efficient\nglobal attention module and an input-dependent depthwise convolution separately\non evenly split feature segments, endowing the network with strong inductive\nbias and an enlarged effective receptive field. We use D-Mixer as the basic\nbuilding block to design TransXNet, a novel hybrid CNN-Transformer vision\nbackbone network that delivers compelling performance. In the ImageNet-1K image\nclassification task, TransXNet-T surpasses Swin-T by 0.3% in top-1 accuracy\nwhile requiring less than half of the computational cost. Furthermore,\nTransXNet-S and TransXNet-B exhibit excellent model scalability, achieving\ntop-1 accuracy of 83.8% and 84.6% respectively, with reasonable computational\ncosts. Additionally, our proposed network architecture demonstrates strong\ngeneralization capabilities in various dense prediction tasks, outperforming\nother state-of-the-art networks while having lower computational costs. Code is\navailable at https://github.com/LMMMEng/TransXNet.",
            "author": [
                "Meng Lou",
                "Hong-Yu Zhou",
                "Sibei Yang",
                "Yizhou Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19380v2",
                "http://arxiv.org/pdf/2310.19380v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19374v1",
            "title": "Measuring arrangement and size distributions of flowing droplets in\n  microchannels through deep learning",
            "updated": "2023-10-30T09:29:39Z",
            "published": "2023-10-30T09:29:39Z",
            "summary": "In microfluidic systems, droplets undergo intricate deformations as they\ntraverse flow-focusing junctions, posing a challenging task for accurate\nmeasurement, especially during short transit times. This study investigates the\nphysical behavior of droplets within dense emulsions in diverse microchannel\ngeometries, specifically focusing on the impact of varying opening angles\nwithin the primary channel and injection rates of fluid components. Employing a\nsophisticated droplet tracking tool based on deep-learning techniques, we\nanalyze multiple frames from flow-focusing experiments to quantitatively\ncharacterize droplet deformation in terms of ratio between maximum width and\nheight and propensity to form liquid with hexagonal crystalline order. Our\nfindings reveal the existence of an optimal opening angle where shape\ndeformations are minimal and crystal-like arrangement is maximal. Variations of\nfluid injection rates are also found to affect size and packing fraction of the\nemulsion in the exit channel. This paper offers insights into deformations,\nsize and structure of fluid emulsions relative to microchannel geometry and\nother flow-related parameters captured through machine learning, with potential\nimplications for the design of microchips utilized in cellular transport and\ntissue engineering applications.",
            "author": [
                "Mihir Durve",
                "Sibilla Orsini",
                "Adriano Tiribocchi",
                "Andrea Montessori",
                "Jean-Michel Tucny",
                "Marco Lauricella",
                "Andrea Camposeo",
                "Dario Pisignano",
                "Sauro Succi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19374v1",
                "http://arxiv.org/pdf/2310.19374v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19368v1",
            "title": "Color Equivariant Convolutional Networks",
            "updated": "2023-10-30T09:18:49Z",
            "published": "2023-10-30T09:18:49Z",
            "summary": "Color is a crucial visual cue readily exploited by Convolutional Neural\nNetworks (CNNs) for object recognition. However, CNNs struggle if there is data\nimbalance between color variations introduced by accidental recording\nconditions. Color invariance addresses this issue but does so at the cost of\nremoving all color information, which sacrifices discriminative power. In this\npaper, we propose Color Equivariant Convolutions (CEConvs), a novel deep\nlearning building block that enables shape feature sharing across the color\nspectrum while retaining important color information. We extend the notion of\nequivariance from geometric to photometric transformations by incorporating\nparameter sharing over hue-shifts in a neural network. We demonstrate the\nbenefits of CEConvs in terms of downstream performance to various tasks and\nimproved robustness to color changes, including train-test distribution shifts.\nOur approach can be seamlessly integrated into existing architectures, such as\nResNets, and offers a promising solution for addressing color-based domain\nshifts in CNNs.",
            "author": [
                "Attila Lengyel",
                "Ombretta Strafforello",
                "Robert-Jan Bruintjes",
                "Alexander Gielisse",
                "Jan van Gemert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19368v1",
                "http://arxiv.org/pdf/2310.19368v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19360v1",
            "title": "Balance, Imbalance, and Rebalance: Understanding Robust Overfitting from\n  a Minimax Game Perspective",
            "updated": "2023-10-30T09:00:11Z",
            "published": "2023-10-30T09:00:11Z",
            "summary": "Adversarial Training (AT) has become arguably the state-of-the-art algorithm\nfor extracting robust features. However, researchers recently notice that AT\nsuffers from severe robust overfitting problems, particularly after learning\nrate (LR) decay. In this paper, we explain this phenomenon by viewing\nadversarial training as a dynamic minimax game between the model trainer and\nthe attacker. Specifically, we analyze how LR decay breaks the balance between\nthe minimax game by empowering the trainer with a stronger memorization\nability, and show such imbalance induces robust overfitting as a result of\nmemorizing non-robust features. We validate this understanding with extensive\nexperiments, and provide a holistic view of robust overfitting from the\ndynamics of both the two game players. This understanding further inspires us\nto alleviate robust overfitting by rebalancing the two players by either\nregularizing the trainer's capacity or improving the attack strength.\nExperiments show that the proposed ReBalanced Adversarial Training (ReBAT) can\nattain good robustness and does not suffer from robust overfitting even after\nvery long training. Code is available at https://github.com/PKU-ML/ReBAT.",
            "author": [
                "Yifei Wang",
                "Liangchen Li",
                "Jiansheng Yang",
                "Zhouchen Lin",
                "Yisen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19360v1",
                "http://arxiv.org/pdf/2310.19360v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19845v1",
            "title": "Modified Genetic Algorithm for Feature Selection and Hyper Parameter\n  Optimization: Case of XGBoost in Spam Prediction",
            "updated": "2023-10-30T09:00:05Z",
            "published": "2023-10-30T09:00:05Z",
            "summary": "Recently, spam on online social networks has attracted attention in the\nresearch and business world. Twitter has become the preferred medium to spread\nspam content. Many research efforts attempted to encounter social networks\nspam. Twitter brought extra challenges represented by the feature space size,\nand imbalanced data distributions. Usually, the related research works focus on\npart of these main challenges or produce black-box models. In this paper, we\npropose a modified genetic algorithm for simultaneous dimensionality reduction\nand hyper parameter optimization over imbalanced datasets. The algorithm\ninitialized an eXtreme Gradient Boosting classifier and reduced the features\nspace of tweets dataset; to generate a spam prediction model. The model is\nvalidated using a 50 times repeated 10-fold stratified cross-validation, and\nanalyzed using nonparametric statistical tests. The resulted prediction model\nattains on average 82.32\\% and 92.67\\% in terms of geometric mean and accuracy\nrespectively, utilizing less than 10\\% of the total feature space. The\nempirical results show that the modified genetic algorithm outperforms $Chi^2$\nand $PCA$ feature selection methods. In addition, eXtreme Gradient Boosting\noutperforms many machine learning algorithms, including BERT-based deep\nlearning model, in spam prediction. Furthermore, the proposed approach is\napplied to SMS spam modeling and compared to related works.",
            "author": [
                "Nazeeh Ghatasheh",
                "Ismail Altaharwa",
                "Khaled Aldebei"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ACCESS.2022.3196905",
                "http://arxiv.org/abs/2310.19845v1",
                "http://arxiv.org/pdf/2310.19845v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.NE",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19359v1",
            "title": "Introducing instance label correlation in multiple instance learning.\n  Application to cancer detection on histopathological images",
            "updated": "2023-10-30T08:57:59Z",
            "published": "2023-10-30T08:57:59Z",
            "summary": "In the last years, the weakly supervised paradigm of multiple instance\nlearning (MIL) has become very popular in many different areas. A paradigmatic\nexample is computational pathology, where the lack of patch-level labels for\nwhole-slide images prevents the application of supervised models. Probabilistic\nMIL methods based on Gaussian Processes (GPs) have obtained promising results\ndue to their excellent uncertainty estimation capabilities. However, these are\ngeneral-purpose MIL methods that do not take into account one important fact:\nin (histopathological) images, the labels of neighboring patches are expected\nto be correlated. In this work, we extend a state-of-the-art GP-based MIL\nmethod, which is called VGPMIL-PR, to exploit such correlation. To do so, we\ndevelop a novel coupling term inspired by the statistical physics Ising model.\nWe use variational inference to estimate all the model parameters.\nInterestingly, the VGPMIL-PR formulation is recovered when the weight that\nregulates the strength of the Ising term vanishes. The performance of the\nproposed method is assessed in two real-world problems of prostate cancer\ndetection. We show that our model achieves better results than other\nstate-of-the-art probabilistic MIL methods. We also provide different\nvisualizations and analysis to gain insights into the influence of the novel\nIsing term. These insights are expected to facilitate the application of the\nproposed model to other research areas.",
            "author": [
                "Pablo Morales-\u00c1lvarez",
                "Arne Schmidt",
                "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
                "Rafael Molina"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.patcog.2023.110057",
                "http://arxiv.org/abs/2310.19359v1",
                "http://arxiv.org/pdf/2310.19359v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19843v1",
            "title": "Modeling the Telemarketing Process using Genetic Algorithms and Extreme\n  Boosting: Feature Selection and Cost-Sensitive Analytical Approach",
            "updated": "2023-10-30T08:46:55Z",
            "published": "2023-10-30T08:46:55Z",
            "summary": "Currently, almost all direct marketing activities take place virtually rather\nthan in person, weakening interpersonal skills at an alarming pace.\nFurthermore, businesses have been striving to sense and foster the tendency of\ntheir clients to accept a marketing offer. The digital transformation and the\nincreased virtual presence forced firms to seek novel marketing research\napproaches. This research aims at leveraging the power of telemarketing data in\nmodeling the willingness of clients to make a term deposit and finding the most\nsignificant characteristics of the clients. Real-world data from a Portuguese\nbank and national socio-economic metrics are used to model the telemarketing\ndecision-making process. This research makes two key contributions. First,\npropose a novel genetic algorithm-based classifier to select the best\ndiscriminating features and tune classifier parameters simultaneously. Second,\nbuild an explainable prediction model. The best-generated classification models\nwere intensively validated using 50 times repeated 10-fold stratified\ncross-validation and the selected features have been analyzed. The models\nsignificantly outperform the related works in terms of class of interest\naccuracy, they attained an average of 89.07\\% and 0.059 in terms of geometric\nmean and type I error respectively. The model is expected to maximize the\npotential profit margin at the least possible cost and provide more insights to\nsupport marketing decision-making.",
            "author": [
                "Nazeeh Ghatasheh",
                "Ismail Altaharwa",
                "Khaled Aldebei"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ACCESS.2023.3292840",
                "http://arxiv.org/abs/2310.19843v1",
                "http://arxiv.org/pdf/2310.19843v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19351v1",
            "title": "Semi- and Weakly-Supervised Domain Generalization for Object Detection",
            "updated": "2023-10-30T08:46:26Z",
            "published": "2023-10-30T08:46:26Z",
            "summary": "Object detectors do not work well when domains largely differ between\ntraining and testing data. To solve this problem, domain generalization\napproaches, which require training data with ground-truth labels from multiple\ndomains, have been proposed. However, it is time-consuming and labor-intensive\nto collect those data for object detection because not only class labels but\nalso bounding boxes must be annotated. To overcome the problem of domain gap in\nobject detection without requiring expensive annotations, we propose to\nconsider two new problem settings: semi-supervised domain generalizable object\ndetection (SS-DGOD) and weakly-supervised DGOD (WS-DGOD). In contrast to the\nconventional domain generalization for object detection that requires labeled\ndata from multiple domains, SS-DGOD and WS-DGOD require labeled data only from\none domain and unlabeled or weakly-labeled data from multiple domains for\ntraining. We show that object detectors can be effectively trained on the\nproposed settings with the same student-teacher learning framework, where a\nstudent network is trained with pseudo labels output from a teacher on the\nunlabeled or weakly-labeled data. The experimental results demonstrate that the\nobject detectors trained on the proposed settings significantly outperform\nbaseline detectors trained on one labeled domain data and perform comparably to\nor better than those trained on unsupervised domain adaptation (UDA) settings,\nwhile ours do not use target domain data for training in contrast to UDA.",
            "author": [
                "Ryosuke Furuta",
                "Yoichi Sato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19351v1",
                "http://arxiv.org/pdf/2310.19351v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19350v1",
            "title": "Disorder-dependent Li diffusion in $\\mathrm{Li_6PS_5Cl}$ investigated by\n  machine learning potential",
            "updated": "2023-10-30T08:46:07Z",
            "published": "2023-10-30T08:46:07Z",
            "summary": "Solid-state electrolytes with argyrodite structures, such as\n$\\mathrm{Li_6PS_5Cl}$, have attracted considerable attention due to their\nsuperior safety compared to liquid electrolytes and higher ionic conductivity\nthan other solid electrolytes. Although experimental efforts have been made to\nenhance conductivity by controlling the degree of disorder, the underlying\ndiffusion mechanism is not yet fully understood. Moreover, existing theoretical\nanalyses based on ab initio MD simulations have limitations in addressing\nvarious types of disorder at room temperature. In this study, we directly\ninvestigate Li-ion diffusion in $\\mathrm{Li_6PS_5Cl}$ at 300 K using\nlarge-scale, long-term MD simulations empowered by machine learning potentials\n(MLPs). To ensure the convergence of conductivity values within an error range\nof 10%, we employ a 25 ns simulation using a $5\\times5\\times5$ supercell\ncontaining 6500 atoms. The computed Li-ion conductivity, activation energies,\nand equilibrium site occupancies align well with experimental observations.\nNotably, Li-ion conductivity peaks when Cl ions occupy 25% of the 4c sites,\nrather than at 50% where the disorder is maximized. This phenomenon is\nexplained by the interplay between inter-cage and intra-cage jumps. By\nelucidating the key factors affecting Li-ion diffusion in\n$\\mathrm{Li_6PS_5Cl}$, this work paves the way for optimizing ionic\nconductivity in the argyrodite family.",
            "author": [
                "Jiho Lee",
                "Suyeon Ju",
                "Seungwoo Hwang",
                "Jinmu You",
                "Jisu Jung",
                "Youngho Kang",
                "Seungwu Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19350v1",
                "http://arxiv.org/pdf/2310.19350v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00721v1",
            "title": "Empathy Detection Using Machine Learning on Text, Audiovisual, Audio or\n  Physiological Signals",
            "updated": "2023-10-30T08:34:12Z",
            "published": "2023-10-30T08:34:12Z",
            "summary": "Empathy is a social skill that indicates an individual's ability to\nunderstand others. Over the past few years, empathy has drawn attention from\nvarious disciplines, including but not limited to Affective Computing,\nCognitive Science and Psychology. Empathy is a context-dependent term; thus,\ndetecting or recognising empathy has potential applications in society,\nhealthcare and education. Despite being a broad and overlapping topic, the\navenue of empathy detection studies leveraging Machine Learning remains\nunderexplored from a holistic literature perspective. To this end, we\nsystematically collect and screen 801 papers from 10 well-known databases and\nanalyse the selected 54 papers. We group the papers based on input modalities\nof empathy detection systems, i.e., text, audiovisual, audio and physiological\nsignals. We examine modality-specific pre-processing and network architecture\ndesign protocols, popular dataset descriptions and availability details, and\nevaluation protocols. We further discuss the potential applications, deployment\nchallenges and research gaps in the Affective Computing-based empathy domain,\nwhich can facilitate new avenues of exploration. We believe that our work is a\nstepping stone to developing a privacy-preserving and unbiased empathic system\ninclusive of culture, diversity and multilingualism that can be deployed in\npractice to enhance the overall well-being of human life.",
            "author": [
                "Md Rakibul Hasan",
                "Md Zakir Hossain",
                "Shreya Ghosh",
                "Susannah Soon",
                "Tom Gedeon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00721v1",
                "http://arxiv.org/pdf/2311.00721v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19343v1",
            "title": "Quantile Super Learning for independent and online settings with\n  application to solar power forecasting",
            "updated": "2023-10-30T08:34:07Z",
            "published": "2023-10-30T08:34:07Z",
            "summary": "Estimating quantiles of an outcome conditional on covariates is of\nfundamental interest in statistics with broad application in probabilistic\nprediction and forecasting. We propose an ensemble method for conditional\nquantile estimation, Quantile Super Learning, that combines predictions from\nmultiple candidate algorithms based on their empirical performance measured\nwith respect to a cross-validated empirical risk of the quantile loss function.\nWe present theoretical guarantees for both iid and online data scenarios. The\nperformance of our approach for quantile estimation and in forming prediction\nintervals is tested in simulation studies. Two case studies related to solar\nenergy are used to illustrate Quantile Super Learning: in an iid setting, we\npredict the physical properties of perovskite materials for photovoltaic cells,\nand in an online setting we forecast ground solar irradiance based on output\nfrom dynamic weather ensemble models.",
            "author": [
                "Herbert Susmann",
                "Antoine Chambaz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19343v1",
                "http://arxiv.org/pdf/2310.19343v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19342v1",
            "title": "Label-Only Model Inversion Attacks via Knowledge Transfer",
            "updated": "2023-10-30T08:32:12Z",
            "published": "2023-10-30T08:32:12Z",
            "summary": "In a model inversion (MI) attack, an adversary abuses access to a machine\nlearning (ML) model to infer and reconstruct private training data. Remarkable\nprogress has been made in the white-box and black-box setups, where the\nadversary has access to the complete model or the model's soft output\nrespectively. However, there is very limited study in the most challenging but\npractically important setup: Label-only MI attacks, where the adversary only\nhas access to the model's predicted label (hard label) without confidence\nscores nor any other model information.\n  In this work, we propose LOKT, a novel approach for label-only MI attacks.\nOur idea is based on transfer of knowledge from the opaque target model to\nsurrogate models. Subsequently, using these surrogate models, our approach can\nharness advanced white-box attacks. We propose knowledge transfer based on\ngenerative modelling, and introduce a new model, Target model-assisted ACGAN\n(T-ACGAN), for effective knowledge transfer. Our method casts the challenging\nlabel-only MI into the more tractable white-box setup. We provide analysis to\nsupport that surrogate models based on our approach serve as effective proxies\nfor the target model for MI. Our experiments show that our method significantly\noutperforms existing SOTA Label-only MI attack by more than 15% across all MI\nbenchmarks. Furthermore, our method compares favorably in terms of query\nbudget. Our study highlights rising privacy threats for ML models even when\nminimal information (i.e., hard labels) is exposed. Our study highlights rising\nprivacy threats for ML models even when minimal information (i.e., hard labels)\nis exposed. Our code, demo, models and reconstructed data are available at our\nproject page: https://ngoc-nguyen-0.github.io/lokt/",
            "author": [
                "Ngoc-Bao Nguyen",
                "Keshigeyan Chandrasegaran",
                "Milad Abdollahzadeh",
                "Ngai-Man Cheung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19342v1",
                "http://arxiv.org/pdf/2310.19342v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19332v1",
            "title": "Solar Flare Prediction and Feature Selection using Light Gradient\n  Boosting Machine Algorithm",
            "updated": "2023-10-30T08:04:48Z",
            "published": "2023-10-30T08:04:48Z",
            "summary": "Solar flares are among the most severe space weather phenomena, and they have\nthe capacity to generate radiation storms and radio disruptions on Earth. The\naccurate prediction of solar flare events remains a significant challenge,\nrequiring continuous monitoring and identification of specific features that\ncan aid in forecasting this phenomenon, particularly for different classes of\nsolar flares. In this study, we aim to forecast C and M class solar flares\nutilising a machine-learning algorithm, namely the Light Gradient Boosting\nMachine. We have utilised a dataset spanning 9 years, obtained from the\nSpace-weather Helioseismic and Magnetic Imager Active Region Patches (SHARP),\nwith a temporal resolution of 1 hour. A total of 37 flare features were\nconsidered in our analysis, comprising of 25 active region parameters and 12\nflare history features. To address the issue of class imbalance in solar flare\ndata, we employed the Synthetic Minority Oversampling Technique (SMOTE). We\nused two labeling approaches in our study: a fixed 24-hour window label and a\nvarying window that considers the changing nature of solar activity. Then, the\ndeveloped machine learning algorithm was trained and tested using forecast\nverification metrics, with an emphasis on evaluating the true skill statistic\n(TSS). Furthermore, we implemented a feature selection algorithm to determine\nthe most significant features from the pool of 37 features that could\ndistinguish between flaring and non-flaring active regions. We found that\nutilising a limited set of useful features resulted in improved prediction\nperformance. For the 24-hour prediction window, we achieved a TSS of 0.63\n(0.69) and accuracy of 0.90 (0.97) for $\\geq$C ($\\geq$M) class solar flares.",
            "author": [
                "Vysakh P. A.",
                "Prateek Mayank"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19332v1",
                "http://arxiv.org/pdf/2310.19332v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19331v1",
            "title": "AdapINT: A Flexible and Adaptive In-Band Network Telemetry System Based\n  on Deep Reinforcement Learning",
            "updated": "2023-10-30T08:02:35Z",
            "published": "2023-10-30T08:02:35Z",
            "summary": "In-band Network Telemetry (INT) has emerged as a promising network\nmeasurement technology. However, existing network telemetry systems lack the\nflexibility to meet diverse telemetry requirements and are also difficult to\nadapt to dynamic network environments. In this paper, we propose AdapINT, a\nversatile and adaptive in-band network telemetry framework assisted by\ndual-timescale probes, including long-period auxiliary probes (APs) and\nshort-period dynamic probes (DPs). Technically, the APs collect basic network\nstatus information, which is used for the path planning of DPs. To achieve full\nnetwork coverage, we propose an auxiliary probes path deployment (APPD)\nalgorithm based on the Depth-First-Search (DFS). The DPs collect specific\nnetwork information for telemetry tasks. To ensure that the DPs can meet\ndiverse telemetry requirements and adapt to dynamic network environments, we\napply the deep reinforcement learning (DRL) technique and transfer learning\nmethod to design the dynamic probes path deployment (DPPD) algorithm. The\nevaluation results show that AdapINT can redesign the telemetry system\naccording to telemetry requirements and network environments. AdapINT can\nreduce telemetry latency by 75\\% in online games and video conferencing\nscenarios. For overhead-aware networks, AdapINT can reduce control overheads by\n34\\% in cloud computing services.",
            "author": [
                "Penghui Zhang",
                "Hua Zhang",
                "Yibo Pi",
                "Zijian Cao",
                "Jingyu Wang",
                "Jianxin Liao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19331v1",
                "http://arxiv.org/pdf/2310.19331v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19842v1",
            "title": "Musical Form Generation",
            "updated": "2023-10-30T08:02:08Z",
            "published": "2023-10-30T08:02:08Z",
            "summary": "While recent generative models can produce engaging music, their utility is\nlimited. The variation in the music is often left to chance, resulting in\ncompositions that lack structure. Pieces extending beyond a minute can become\nincoherent or repetitive. This paper introduces an approach for generating\nstructured, arbitrarily long musical pieces. Central to this approach is the\ncreation of musical segments using a conditional generative model, with\ntransitions between these segments. The generation of prompts that determine\nthe high-level composition is distinct from the creation of finer, lower-level\ndetails. A large language model is then used to suggest the musical form.",
            "author": [
                "Lilac Atassi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19842v1",
                "http://arxiv.org/pdf/2310.19842v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19841v1",
            "title": "An interpretable clustering approach to safety climate analysis:\n  examining driver group distinction in safety climate perceptions",
            "updated": "2023-10-30T07:53:42Z",
            "published": "2023-10-30T07:53:42Z",
            "summary": "The transportation industry, particularly the trucking sector, is prone to\nworkplace accidents and fatalities. Accidents involving large trucks accounted\nfor a considerable percentage of overall traffic fatalities. Recognizing the\ncrucial role of safety climate in accident prevention, researchers have sought\nto understand its factors and measure its impact within organizations. While\nexisting data-driven safety climate studies have made remarkable progress,\nclustering employees based on their safety climate perception is innovative and\nhas not been extensively utilized in research. Identifying clusters of drivers\nbased on their safety climate perception allows the organization to profile its\nworkforce and devise more impactful interventions. The lack of utilizing the\nclustering approach could be due to difficulties interpreting or explaining the\nfactors influencing employees' cluster membership. Moreover, existing\nsafety-related studies did not compare multiple clustering algorithms,\nresulting in potential bias. To address these issues, this study introduces an\ninterpretable clustering approach for safety climate analysis. This study\ncompares 5 algorithms for clustering truck drivers based on their safety\nclimate perceptions. It proposes a novel method for quantitatively evaluating\npartial dependence plots (QPDP). To better interpret the clustering results,\nthis study introduces different interpretable machine learning measures (SHAP,\nPFI, and QPDP). Drawing on data collected from more than 7,000 American truck\ndrivers, this study significantly contributes to the scientific literature. It\nhighlights the critical role of supervisory care promotion in distinguishing\nvarious driver groups. The Python code is available at\nhttps://github.com/NUS-DBE/truck-driver-safety-climate.",
            "author": [
                "Kailai Sun",
                "Tianxiang Lan",
                "Yang Miang Goh",
                "Sufiana Safiena",
                "Yueng-Hsiang Huang",
                "Bailey Lytle",
                "Yimin He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19841v1",
                "http://arxiv.org/pdf/2310.19841v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19324v1",
            "title": "TempME: Towards the Explainability of Temporal Graph Neural Networks via\n  Motif Discovery",
            "updated": "2023-10-30T07:51:41Z",
            "published": "2023-10-30T07:51:41Z",
            "summary": "Temporal graphs are widely used to model dynamic systems with time-varying\ninteractions. In real-world scenarios, the underlying mechanisms of generating\nfuture interactions in dynamic systems are typically governed by a set of\nrecurring substructures within the graph, known as temporal motifs. Despite the\nsuccess and prevalence of current temporal graph neural networks (TGNN), it\nremains uncertain which temporal motifs are recognized as the significant\nindications that trigger a certain prediction from the model, which is a\ncritical challenge for advancing the explainability and trustworthiness of\ncurrent TGNNs. To address this challenge, we propose a novel approach, called\nTemporal Motifs Explainer (TempME), which uncovers the most pivotal temporal\nmotifs guiding the prediction of TGNNs. Derived from the information bottleneck\nprinciple, TempME extracts the most interaction-related motifs while minimizing\nthe amount of contained information to preserve the sparsity and succinctness\nof the explanation. Events in the explanations generated by TempME are verified\nto be more spatiotemporally correlated than those of existing approaches,\nproviding more understandable insights. Extensive experiments validate the\nsuperiority of TempME, with up to 8.21% increase in terms of explanation\naccuracy across six real-world datasets and up to 22.96% increase in boosting\nthe prediction Average Precision of current TGNNs.",
            "author": [
                "Jialin Chen",
                "Rex Ying"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19324v1",
                "http://arxiv.org/pdf/2310.19324v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19323v1",
            "title": "A Low-Complexity Machine Learning Design for mmWave Beam Prediction",
            "updated": "2023-10-30T07:48:15Z",
            "published": "2023-10-30T07:48:15Z",
            "summary": "The 3rd Generation Partnership Project (3GPP) is currently studying machine\nlearning (ML) for the fifth generation (5G)-Advanced New Radio (NR) air\ninterface, where spatial and temporal-domain beam prediction are important use\ncases. With this background, this letter presents a low-complexity ML design\nthat expedites the spatial-domain beam prediction to reduce the power\nconsumption and the reference signaling overhead, which are currently\nimperative for frequent beam measurements. Complexity analysis and evaluation\nresults showcase that the proposed model achieves state-of-the-art accuracy\nwith lower computational complexity, resulting in reduced power consumption and\nfaster beam prediction. Furthermore, important observations on the\ngeneralization of the proposed model are presented in this letter.",
            "author": [
                "Muhammad Qurratulain Khan",
                "Abdo Gaber",
                "Mohammad Parvini",
                "Philipp Schulz",
                "Gerhard Fettweis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19323v1",
                "http://arxiv.org/pdf/2310.19323v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19322v1",
            "title": "ProNet: Progressive Neural Network for Multi-Horizon Time Series\n  Forecasting",
            "updated": "2023-10-30T07:46:40Z",
            "published": "2023-10-30T07:46:40Z",
            "summary": "In this paper, we introduce ProNet, an novel deep learning approach designed\nfor multi-horizon time series forecasting, adaptively blending autoregressive\n(AR) and non-autoregressive (NAR) strategies. Our method involves dividing the\nforecasting horizon into segments, predicting the most crucial steps in each\nsegment non-autoregressively, and the remaining steps autoregressively. The\nsegmentation process relies on latent variables, which effectively capture the\nsignificance of individual time steps through variational inference. In\ncomparison to AR models, ProNet showcases remarkable advantages, requiring\nfewer AR iterations, resulting in faster prediction speed, and mitigating error\naccumulation. On the other hand, when compared to NAR models, ProNet takes into\naccount the interdependency of predictions in the output space, leading to\nimproved forecasting accuracy. Our comprehensive evaluation, encompassing four\nlarge datasets, and an ablation study, demonstrate the effectiveness of ProNet,\nhighlighting its superior performance in terms of accuracy and prediction\nspeed, outperforming state-of-the-art AR and NAR forecasting models.",
            "author": [
                "Yang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19322v1",
                "http://arxiv.org/pdf/2310.19322v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19321v1",
            "title": "D4Explainer: In-Distribution GNN Explanations via Discrete Denoising\n  Diffusion",
            "updated": "2023-10-30T07:41:42Z",
            "published": "2023-10-30T07:41:42Z",
            "summary": "The widespread deployment of Graph Neural Networks (GNNs) sparks significant\ninterest in their explainability, which plays a vital role in model auditing\nand ensuring trustworthy graph learning. The objective of GNN explainability is\nto discern the underlying graph structures that have the most significant\nimpact on model predictions. Ensuring that explanations generated are reliable\nnecessitates consideration of the in-distribution property, particularly due to\nthe vulnerability of GNNs to out-of-distribution data. Unfortunately,\nprevailing explainability methods tend to constrain the generated explanations\nto the structure of the original graph, thereby downplaying the significance of\nthe in-distribution property and resulting in explanations that lack\nreliability. To address these challenges, we propose D4Explainer, a novel\napproach that provides in-distribution GNN explanations for both counterfactual\nand model-level explanation scenarios. The proposed D4Explainer incorporates\ngenerative graph distribution learning into the optimization objective, which\naccomplishes two goals: 1) generate a collection of diverse counterfactual\ngraphs that conform to the in-distribution property for a given instance, and\n2) identify the most discriminative graph patterns that contribute to a\nspecific class prediction, thus serving as model-level explanations. It is\nworth mentioning that D4Explainer is the first unified framework that combines\nboth counterfactual and model-level explanations. Empirical evaluations\nconducted on synthetic and real-world datasets provide compelling evidence of\nthe state-of-the-art performance achieved by D4Explainer in terms of\nexplanation accuracy, faithfulness, diversity, and robustness.",
            "author": [
                "Jialin Chen",
                "Shirley Wu",
                "Abhijit Gupta",
                "Rex Ying"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19321v1",
                "http://arxiv.org/pdf/2310.19321v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19319v1",
            "title": "Dual-Directed Algorithm Design for Efficient Pure Exploration",
            "updated": "2023-10-30T07:29:17Z",
            "published": "2023-10-30T07:29:17Z",
            "summary": "We consider pure-exploration problems in the context of stochastic sequential\nadaptive experiments with a finite set of alternative options. The goal of the\ndecision-maker is to accurately answer a query question regarding the\nalternatives with high confidence with minimal measurement efforts. A typical\nquery question is to identify the alternative with the best performance,\nleading to ranking and selection problems, or best-arm identification in the\nmachine learning literature. We focus on the fixed-precision setting and derive\na sufficient condition for optimality in terms of a notion of strong\nconvergence to the optimal allocation of samples. Using dual variables, we\ncharacterize the necessary and sufficient conditions for an allocation to be\noptimal. The use of dual variables allow us to bypass the combinatorial\nstructure of the optimality conditions that relies solely on primal variables.\nRemarkably, these optimality conditions enable an extension of top-two\nalgorithm design principle, initially proposed for best-arm identification.\nFurthermore, our optimality conditions give rise to a straightforward yet\nefficient selection rule, termed information-directed selection, which\nadaptively picks from a candidate set based on information gain of the\ncandidates. We outline the broad contexts where our algorithmic approach can be\nimplemented. We establish that, paired with information-directed selection,\ntop-two Thompson sampling is (asymptotically) optimal for Gaussian best-arm\nidentification, solving a glaring open problem in the pure exploration\nliterature. Our algorithm is optimal for $\\epsilon$-best-arm identification and\nthresholding bandit problems. Our analysis also leads to a general principle to\nguide adaptations of Thompson sampling for pure-exploration problems. Numerical\nexperiments highlight the exceptional efficiency of our proposed algorithms\nrelative to existing ones.",
            "author": [
                "Chao Qin",
                "Wei You"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19319v1",
                "http://arxiv.org/pdf/2310.19319v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19313v1",
            "title": "L2T-DLN: Learning to Teach with Dynamic Loss Network",
            "updated": "2023-10-30T07:21:40Z",
            "published": "2023-10-30T07:21:40Z",
            "summary": "With the concept of teaching being introduced to the machine learning\ncommunity, a teacher model start using dynamic loss functions to teach the\ntraining of a student model. The dynamic intends to set adaptive loss functions\nto different phases of student model learning. In existing works, the teacher\nmodel 1) merely determines the loss function based on the present states of the\nstudent model, i.e., disregards the experience of the teacher; 2) only utilizes\nthe states of the student model, e.g., training iteration number and\nloss/accuracy from training/validation sets, while ignoring the states of the\nloss function. In this paper, we first formulate the loss adjustment as a\ntemporal task by designing a teacher model with memory units, and, therefore,\nenables the student learning to be guided by the experience of the teacher\nmodel. Then, with a dynamic loss network, we can additionally use the states of\nthe loss to assist the teacher learning in enhancing the interactions between\nthe teacher and the student model. Extensive experiments demonstrate our\napproach can enhance student learning and improve the performance of various\ndeep models on real-world tasks, including classification, objective detection,\nand semantic segmentation scenarios.",
            "author": [
                "Zhoyang Hai",
                "Liyuan Pan",
                "Xiabi Liu",
                "Zhengzheng Liu",
                "Mirna Yunita"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19313v1",
                "http://arxiv.org/pdf/2310.19313v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19308v2",
            "title": "Free from Bellman Completeness: Trajectory Stitching via Model-based\n  Return-conditioned Supervised Learning",
            "updated": "2023-12-02T11:27:53Z",
            "published": "2023-10-30T07:03:14Z",
            "summary": "Off-policy dynamic programming (DP) techniques such as $Q$-learning have\nproven to be important in sequential decision-making problems. In the presence\nof function approximation, however, these techniques often diverge due to the\nabsence of Bellman completeness in the function classes considered, a crucial\ncondition for the success of DP-based methods. In this paper, we show how\noff-policy learning techniques based on return-conditioned supervised learning\n(RCSL) are able to circumvent these challenges of Bellman completeness,\nconverging under significantly more relaxed assumptions inherited from\nsupervised learning. We prove there exists a natural environment in which if\none uses two-layer multilayer perceptron as the function approximator, the\nlayer width needs to grow linearly with the state space size to satisfy Bellman\ncompleteness while a constant layer width is enough for RCSL. These findings\ntake a step towards explaining the superior empirical performance of RCSL\nmethods compared to DP-based methods in environments with near-optimal\ndatasets. Furthermore, in order to learn from sub-optimal datasets, we propose\na simple framework called MBRCSL, granting RCSL methods the ability of dynamic\nprogramming to stitch together segments from distinct trajectories. MBRCSL\nleverages learned dynamics models and forward sampling to accomplish trajectory\nstitching while avoiding the need for Bellman completeness that plagues all\ndynamic programming algorithms. We propose both theoretical analysis and\nexperimental evaluation to back these claims, outperforming state-of-the-art\nmodel-free and model-based offline RL algorithms across several simulated\nrobotics problems.",
            "author": [
                "Zhaoyi Zhou",
                "Chuning Zhu",
                "Runlong Zhou",
                "Qiwen Cui",
                "Abhishek Gupta",
                "Simon Shaolei Du"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19308v2",
                "http://arxiv.org/pdf/2310.19308v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02165v1",
            "title": "Teaching mathematical modeling for sustainability: Enhancing\n  interdisciplinary skills in students",
            "updated": "2023-10-30T07:00:38Z",
            "published": "2023-10-30T07:00:38Z",
            "summary": "We developed a pilot course focused on mathematical modeling within the\ntertiary education framework, with a distinct emphasis on sustainability and\nsustainable development. While an applicable textbook exists for this liberal\narts course, it is noticeable that numerous examples within it are not directly\naligned with sustainability concerns. To address this gap, our study\nstrategically integrated the teaching and learning of modeling by carefully\nselecting classroom examples that closely align with the context of\nsustainability. By employing an innovative and adaptable approach to the course\ncontent delivery, we fostered interdisciplinary collaboration among students,\nimproved their comprehension, and enhanced their interdisciplinary skills.",
            "author": [
                "N. Karjanto"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02165v1",
                "http://arxiv.org/pdf/2312.02165v1"
            ],
            "primary_category": "math.HO",
            "category": [
                "math.HO",
                "97M10, 97U20, 97U30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19306v1",
            "title": "A Planning-and-Exploring Approach to Extreme-Mechanics Force Fields",
            "updated": "2023-10-30T06:59:01Z",
            "published": "2023-10-30T06:59:01Z",
            "summary": "Extreme mechanical processes such as strong lattice distortion and bond\nbreakage during fracture are ubiquitous in nature and engineering, which often\nlead to catastrophic failure of structures. However, understanding the\nnucleation and growth of cracks is challenged by their multiscale\ncharacteristics spanning from atomic-level structures at the crack tip to the\nstructural features where the load is applied. Molecular simulations offer an\nimportant tool to resolve the progressive microstructural changes at crack\nfronts and are widely used to explore processes therein, such as mechanical\nenergy dissipation, crack path selection, and dynamic instabilities (e.g.,\nkinking, branching). Empirical force fields developed based on local\ndescriptors based on atomic positions and the bond orders do not yield\nsatisfying predictions of fracture, even for the nonlinear, anisotropic\nstress-strain relations and the energy densities of edges. High-fidelity force\nfields thus should include the tensorial nature of strain and the energetics of\nrare events during fracture, which, unfortunately, have not been taken into\naccount in both the state-of-the-art empirical and machine-learning force\nfields. Based on data generated by first-principles calculations, we develop a\nneural network-based force field for fracture, NN-F$^3$, by combining\npre-sampling of the space of strain states and active-learning techniques to\nexplore the transition states at critical bonding distances. The capability of\nNN-F$^3$ is demonstrated by studying the rupture of h-BN and twisted bilayer\ngraphene as model problems. The simulation results confirm recent experimental\nfindings and highlight the necessity to include the knowledge of electronic\nstructures from first-principles calculations in predicting extreme mechanical\nprocesses.",
            "author": [
                "Pengjie Shi",
                "Zhiping Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19306v1",
                "http://arxiv.org/pdf/2310.19306v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.stat-mech",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19304v1",
            "title": "Privacy-Preserving Federated Learning over Vertically and Horizontally\n  Partitioned Data for Financial Anomaly Detection",
            "updated": "2023-10-30T06:51:33Z",
            "published": "2023-10-30T06:51:33Z",
            "summary": "The effective detection of evidence of financial anomalies requires\ncollaboration among multiple entities who own a diverse set of data, such as a\npayment network system (PNS) and its partner banks. Trust among these financial\ninstitutions is limited by regulation and competition. Federated learning (FL)\nenables entities to collaboratively train a model when data is either\nvertically or horizontally partitioned across the entities. However, in\nreal-world financial anomaly detection scenarios, the data is partitioned both\nvertically and horizontally and hence it is not possible to use existing FL\napproaches in a plug-and-play manner.\n  Our novel solution, PV4FAD, combines fully homomorphic encryption (HE),\nsecure multi-party computation (SMPC), differential privacy (DP), and\nrandomization techniques to balance privacy and accuracy during training and to\nprevent inference threats at model deployment time. Our solution provides input\nprivacy through HE and SMPC, and output privacy against inference time attacks\nthrough DP. Specifically, we show that, in the honest-but-curious threat model,\nbanks do not learn any sensitive features about PNS transactions, and the PNS\ndoes not learn any information about the banks' dataset but only learns\nprediction labels. We also develop and analyze a DP mechanism to protect output\nprivacy during inference. Our solution generates high-utility models by\nsignificantly reducing the per-bank noise level while satisfying distributed\nDP. To ensure high accuracy, our approach produces an ensemble model, in\nparticular, a random forest. This enables us to take advantage of the\nwell-known properties of ensembles to reduce variance and increase accuracy.\nOur solution won second prize in the first phase of the U.S. Privacy Enhancing\nTechnologies (PETs) Prize Challenge.",
            "author": [
                "Swanand Ravindra Kadhe",
                "Heiko Ludwig",
                "Nathalie Baracaldo",
                "Alan King",
                "Yi Zhou",
                "Keith Houck",
                "Ambrish Rawat",
                "Mark Purcell",
                "Naoise Holohan",
                "Mikio Takeuchi",
                "Ryo Kawahara",
                "Nir Drucker",
                "Hayim Shaul",
                "Eyal Kushnir",
                "Omri Soceanu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19304v1",
                "http://arxiv.org/pdf/2310.19304v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19300v1",
            "title": "Stage-Aware Learning for Dynamic Treatments",
            "updated": "2023-10-30T06:35:31Z",
            "published": "2023-10-30T06:35:31Z",
            "summary": "Recent advances in dynamic treatment regimes (DTRs) provide powerful optimal\ntreatment searching algorithms, which are tailored to individuals' specific\nneeds and able to maximize their expected clinical benefits. However, existing\nalgorithms could suffer from insufficient sample size under optimal treatments,\nespecially for chronic diseases involving long stages of decision-making. To\naddress these challenges, we propose a novel individualized learning method\nwhich estimates the DTR with a focus on prioritizing alignment between the\nobserved treatment trajectory and the one obtained by the optimal regime across\ndecision stages. By relaxing the restriction that the observed trajectory must\nbe fully aligned with the optimal treatments, our approach substantially\nimproves the sample efficiency and stability of inverse probability weighted\nbased methods. In particular, the proposed learning scheme builds a more\ngeneral framework which includes the popular outcome weighted learning\nframework as a special case of ours. Moreover, we introduce the notion of stage\nimportance scores along with an attention mechanism to explicitly account for\nheterogeneity among decision stages. We establish the theoretical properties of\nthe proposed approach, including the Fisher consistency and finite-sample\nperformance bound. Empirically, we evaluate the proposed method in extensive\nsimulated environments and a real case study for COVID-19 pandemic.",
            "author": [
                "Hanwen Ye",
                "Wenzhuo Zhou",
                "Ruoqing Zhu",
                "Annie Qu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19300v1",
                "http://arxiv.org/pdf/2310.19300v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19297v1",
            "title": "On Measuring Fairness in Generative Models",
            "updated": "2023-10-30T06:33:48Z",
            "published": "2023-10-30T06:33:48Z",
            "summary": "Recently, there has been increased interest in fair generative models. In\nthis work, we conduct, for the first time, an in-depth study on fairness\nmeasurement, a critical component in gauging progress on fair generative\nmodels. We make three contributions. First, we conduct a study that reveals\nthat the existing fairness measurement framework has considerable measurement\nerrors, even when highly accurate sensitive attribute (SA) classifiers are\nused. These findings cast doubts on previously reported fairness improvements.\nSecond, to address this issue, we propose CLassifier Error-Aware Measurement\n(CLEAM), a new framework which uses a statistical model to account for\ninaccuracies in SA classifiers. Our proposed CLEAM reduces measurement errors\nsignificantly, e.g., 4.98% $\\rightarrow$ 0.62% for StyleGAN2 w.r.t. Gender.\nAdditionally, CLEAM achieves this with minimal additional overhead. Third, we\nutilize CLEAM to measure fairness in important text-to-image generator and\nGANs, revealing considerable biases in these models that raise concerns about\ntheir applications. Code and more resources:\nhttps://sutd-visual-computing-group.github.io/CLEAM/.",
            "author": [
                "Christopher T. H. Teo",
                "Milad Abdollahzadeh",
                "Ngai-Man Cheung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19297v1",
                "http://arxiv.org/pdf/2310.19297v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19295v1",
            "title": "ROAM: memory-efficient large DNN training via optimized operator\n  ordering and memory layout",
            "updated": "2023-10-30T06:29:21Z",
            "published": "2023-10-30T06:29:21Z",
            "summary": "As deep learning models continue to increase in size, the memory requirements\nfor training have surged. While high-level techniques like offloading,\nrecomputation, and compression can alleviate memory pressure, they also\nintroduce overheads. However, a memory-efficient execution plan that includes a\nreasonable operator execution order and tensor memory layout can significantly\nincrease the models' memory efficiency and reduce overheads from high-level\ntechniques. In this paper, we propose ROAM which operates on computation graph\nlevel to derive memory-efficient execution plan with optimized operator order\nand tensor memory layout for models. We first propose sophisticated theories\nthat carefully consider model structure and training memory load to support\noptimization for large complex graphs that have not been well supported in the\npast. An efficient tree-based algorithm is further proposed to search task\ndivisions automatically, along with delivering high performance and\neffectiveness to solve the problem. Experiments show that ROAM achieves a\nsubstantial memory reduction of 35.7%, 13.3%, and 27.2% compared to Pytorch and\ntwo state-of-the-art methods and offers a remarkable 53.7x speedup. The\nevaluation conducted on the expansive GPT2-XL further validates ROAM's\nscalability.",
            "author": [
                "Huiyao Shu",
                "Ang Wang",
                "Ziji Shi",
                "Hanyu Zhao",
                "Yong Li",
                "Lu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19295v1",
                "http://arxiv.org/pdf/2310.19295v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19293v1",
            "title": "FetusMapV2: Enhanced Fetal Pose Estimation in 3D Ultrasound",
            "updated": "2023-10-30T06:18:47Z",
            "published": "2023-10-30T06:18:47Z",
            "summary": "Fetal pose estimation in 3D ultrasound (US) involves identifying a set of\nassociated fetal anatomical landmarks. Its primary objective is to provide\ncomprehensive information about the fetus through landmark connections, thus\nbenefiting various critical applications, such as biometric measurements, plane\nlocalization, and fetal movement monitoring. However, accurately estimating the\n3D fetal pose in US volume has several challenges, including poor image\nquality, limited GPU memory for tackling high dimensional data, symmetrical or\nambiguous anatomical structures, and considerable variations in fetal poses. In\nthis study, we propose a novel 3D fetal pose estimation framework (called\nFetusMapV2) to overcome the above challenges. Our contribution is three-fold.\nFirst, we propose a heuristic scheme that explores the complementary network\nstructure-unconstrained and activation-unreserved GPU memory management\napproaches, which can enlarge the input image resolution for better results\nunder limited GPU memory. Second, we design a novel Pair Loss to mitigate\nconfusion caused by symmetrical and similar anatomical structures. It separates\nthe hidden classification task from the landmark localization task and thus\nprogressively eases model learning. Last, we propose a shape priors-based\nself-supervised learning by selecting the relatively stable landmarks to refine\nthe pose online. Extensive experiments and diverse applications on a\nlarge-scale fetal US dataset including 1000 volumes with 22 landmarks per\nvolume demonstrate that our method outperforms other strong competitors.",
            "author": [
                "Chaoyu Chen",
                "Xin Yang",
                "Yuhao Huang",
                "Wenlong Shi",
                "Yan Cao",
                "Mingyuan Luo",
                "Xindi Hu",
                "Lei Zhue",
                "Lequan Yu",
                "Kejuan Yue",
                "Yuanji Zhang",
                "Yi Xiong",
                "Dong Ni",
                "Weijun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19293v1",
                "http://arxiv.org/pdf/2310.19293v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19291v2",
            "title": "A3SA: Advanced Data Augmentation via Adjoint Sensitivity Analysis",
            "updated": "2023-11-06T05:54:31Z",
            "published": "2023-10-30T06:12:44Z",
            "summary": "Innovative machine learning techniques have facilitated the inverse design of\nphotonic structures for numerous practical applications. Nevertheless, within\nthese approaches, the quantity of data and the initial data distribution are\nparamount for the discovery of highly efficient photonic devices. These devices\noften require simulated data ranging from thousands to several hundred thousand\ndata points. This issue has consistently posed a major hurdle in machine\nlearning-based photonic design problems. Therefore, we propose a novel data\naugmentation algorithm grounded in the adjoint method, capable of generating\nmore than 300 times the amount of original data while enhancing device\nefficiency. The adjoint method forecasts changes in the figure of merit (FoM)\nresulting from structural perturbations, requiring only two full-wave Maxwell\nsimulations for this prediction. By leveraging the adjoint gradient values, we\ncan augment and label several thousand new data points without any additional\ncomputations. Furthermore, the augmented data generated by the proposed\nalgorithm displays significantly improved FoMs owing to the precise FoM change\npredictions enabled by the adjoint gradients. We apply this algorithm to a\nmulti-layered metalens design problem and demonstrate that it consequently\nexhibits a 343-fold increase in data generation efficiency. After incorporating\nthe proposed algorithm into a generative adversarial network (GAN), the\noptimized metalens exhibits a maximum focusing efficiency of 92.93%, comparable\nto the theoretical upper bound (93.80%).",
            "author": [
                "Chanik Kang",
                "Dongjin Seo",
                "Svetlana V Boriskina",
                "Haejun Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19291v2",
                "http://arxiv.org/pdf/2310.19291v2"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19289v1",
            "title": "AMLNet: Adversarial Mutual Learning Neural Network for\n  Non-AutoRegressive Multi-Horizon Time Series Forecasting",
            "updated": "2023-10-30T06:10:00Z",
            "published": "2023-10-30T06:10:00Z",
            "summary": "Multi-horizon time series forecasting, crucial across diverse domains,\ndemands high accuracy and speed. While AutoRegressive (AR) models excel in\nshort-term predictions, they suffer speed and error issues as the horizon\nextends. Non-AutoRegressive (NAR) models suit long-term predictions but\nstruggle with interdependence, yielding unrealistic results. We introduce\nAMLNet, an innovative NAR model that achieves realistic forecasts through an\nonline Knowledge Distillation (KD) approach. AMLNet harnesses the strengths of\nboth AR and NAR models by training a deep AR decoder and a deep NAR decoder in\na collaborative manner, serving as ensemble teachers that impart knowledge to a\nshallower NAR decoder. This knowledge transfer is facilitated through two key\nmechanisms: 1) outcome-driven KD, which dynamically weights the contribution of\nKD losses from the teacher models, enabling the shallow NAR decoder to\nincorporate the ensemble's diversity; and 2) hint-driven KD, which employs\nadversarial training to extract valuable insights from the model's hidden\nstates for distillation. Extensive experimentation showcases AMLNet's\nsuperiority over conventional AR and NAR models, thereby presenting a promising\navenue for multi-horizon time series forecasting that enhances accuracy and\nexpedites computation.",
            "author": [
                "Yang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19289v1",
                "http://arxiv.org/pdf/2310.19289v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19287v1",
            "title": "Enhancing Scalability and Reliability in Semi-Decentralized Federated\n  Learning With Blockchain: Trust Penalization and Asynchronous Functionality",
            "updated": "2023-10-30T06:05:50Z",
            "published": "2023-10-30T06:05:50Z",
            "summary": "The paper presents an innovative approach to address the challenges of\nscalability and reliability in Distributed Federated Learning by leveraging the\nintegration of blockchain technology. The paper focuses on enhancing the\ntrustworthiness of participating nodes through a trust penalization mechanism\nwhile also enabling asynchronous functionality for efficient and robust model\nupdates. By combining Semi-Decentralized Federated Learning with Blockchain\n(SDFL-B), the proposed system aims to create a fair, secure and transparent\nenvironment for collaborative machine learning without compromising data\nprivacy. The research presents a comprehensive system architecture,\nmethodologies, experimental results, and discussions that demonstrate the\nadvantages of this novel approach in fostering scalable and reliable SDFL-B\nsystems.",
            "author": [
                "Ajay Kumar Shrestha",
                "Faijan Ahamad Khan",
                "Mohammed Afaan Shaikh",
                "Amir Jaberzadeh",
                "Jason Geng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19287v1",
                "http://arxiv.org/pdf/2310.19287v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19285v1",
            "title": "Facilitating Graph Neural Networks with Random Walk on Simplicial\n  Complexes",
            "updated": "2023-10-30T06:03:34Z",
            "published": "2023-10-30T06:03:34Z",
            "summary": "Node-level random walk has been widely used to improve Graph Neural Networks.\nHowever, there is limited attention to random walk on edge and, more generally,\non $k$-simplices. This paper systematically analyzes how random walk on\ndifferent orders of simplicial complexes (SC) facilitates GNNs in their\ntheoretical expressivity. First, on $0$-simplices or node level, we establish a\nconnection between existing positional encoding (PE) and structure encoding\n(SE) methods through the bridge of random walk. Second, on $1$-simplices or\nedge level, we bridge edge-level random walk and Hodge $1$-Laplacians and\ndesign corresponding edge PE respectively. In the spatial domain, we directly\nmake use of edge level random walk to construct EdgeRWSE. Based on the spectral\nanalysis of Hodge $1$-Laplcians, we propose Hodge1Lap, a permutation\nequivariant and expressive edge-level positional encoding. Third, we generalize\nour theory to random walk on higher-order simplices and propose the general\nprinciple to design PE on simplices based on random walk and Hodge Laplacians.\nInter-level random walk is also introduced to unify a wide range of simplicial\nnetworks. Extensive experiments verify the effectiveness of our random\nwalk-based methods.",
            "author": [
                "Cai Zhou",
                "Xiyuan Wang",
                "Muhan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19285v1",
                "http://arxiv.org/pdf/2310.19285v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19283v2",
            "title": "rTsfNet: a DNN model with Multi-head 3D Rotation and Time Series Feature\n  Extraction for IMU-based Human Activity Recognition",
            "updated": "2023-11-01T06:01:12Z",
            "published": "2023-10-30T05:51:50Z",
            "summary": "This paper proposes rTsfNet, a DNN model with Multi-head 3D Rotation and Time\nSeries Feature Extraction, as a new DNN model for IMU-based human activity\nrecognition (HAR). rTsfNet automatically selects 3D bases from which features\nshould be derived by deriving 3D rotation parameters within the DNN. Then, time\nseries features (TSFs), the wisdom of many researchers, are derived and realize\nHAR using MLP. Although a model that does not use CNN, it achieved the highest\naccuracy than existing models under well-managed benchmark conditions and\nmultiple datasets: UCI HAR, PAMAP2, Daphnet, and OPPORTUNITY, which target\ndifferent activities.",
            "author": [
                "Yu Enokibori"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19283v2",
                "http://arxiv.org/pdf/2310.19283v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19276v1",
            "title": "Machine Learning Regularization for the Minimum Volume Formula of Toric\n  Calabi-Yau 3-folds",
            "updated": "2023-10-30T05:25:50Z",
            "published": "2023-10-30T05:25:50Z",
            "summary": "We present a collection of explicit formulas for the minimum volume of\nSasaki-Einstein 5-manifolds. The cone over these 5-manifolds is a toric\nCalabi-Yau 3-fold. These toric Calabi-Yau 3-folds are associated with an\ninfinite class of 4d N=1 supersymmetric gauge theories, which are realized as\nworldvolume theories of D3-branes probing the toric Calabi-Yau 3-folds. Under\nthe AdS/CFT correspondence, the minimum volume of the Sasaki-Einstein base is\ninversely proportional to the central charge of the corresponding 4d N=1\nsuperconformal field theories. The presented formulas for the minimum volume\nare in terms of geometric invariants of the toric Calabi-Yau 3-folds. These\nexplicit results are derived by implementing machine learning regularization\ntechniques that advance beyond previous applications of machine learning for\ndetermining the minimum volume. Moreover, the use of machine learning\nregularization allows us to present interpretable and explainable formulas for\nthe minimum volume. Our work confirms that, even for extensive sets of toric\nCalabi-Yau 3-folds, the proposed formulas approximate the minimum volume with\nremarkable accuracy.",
            "author": [
                "Eugene Choi",
                "Rak-Kyeong Seong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19276v1",
                "http://arxiv.org/pdf/2310.19276v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cs.LG",
                "math-ph",
                "math.AG",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19274v2",
            "title": "Prediction of Effective Elastic Moduli of Rocks using Graph Neural\n  Networks",
            "updated": "2023-11-22T18:27:15Z",
            "published": "2023-10-30T05:13:58Z",
            "summary": "This study presents a Graph Neural Networks (GNNs)-based approach for\npredicting the effective elastic moduli of rocks from their digital CT-scan\nimages. We use the Mapper algorithm to transform 3D digital rock images into\ngraph datasets, encapsulating essential geometrical information. These graphs,\nafter training, prove effective in predicting elastic moduli. Our GNN model\nshows robust predictive capabilities across various graph sizes derived from\nvarious subcube dimensions. Not only does it perform well on the test dataset,\nbut it also maintains high prediction accuracy for unseen rocks and unexplored\nsubcube sizes. Comparative analysis with Convolutional Neural Networks (CNNs)\nreveals the superior performance of GNNs in predicting unseen rock properties.\nMoreover, the graph representation of microstructures significantly reduces GPU\nmemory requirements (compared to the grid representation for CNNs), enabling\ngreater flexibility in the batch size selection. This work demonstrates the\npotential of GNN models in enhancing the prediction accuracy of rock properties\nand boosting the efficiency of digital rock analysis.",
            "author": [
                "Jaehong Chung",
                "Rasool Ahmad",
                "WaiChing Sun",
                "Wei Cai",
                "Tapan Mukerji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19274v2",
                "http://arxiv.org/pdf/2310.19274v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.comp-ph",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19273v1",
            "title": "The Memory Perturbation Equation: Understanding Model's Sensitivity to\n  Data",
            "updated": "2023-10-30T05:12:24Z",
            "published": "2023-10-30T05:12:24Z",
            "summary": "Understanding model's sensitivity to its training data is crucial but can\nalso be challenging and costly, especially during training. To simplify such\nissues, we present the Memory-Perturbation Equation (MPE) which relates model's\nsensitivity to perturbation in its training data. Derived using Bayesian\nprinciples, the MPE unifies existing sensitivity measures, generalizes them to\na wide-variety of models and algorithms, and unravels useful properties\nregarding sensitivities. Our empirical results show that sensitivity estimates\nobtained during training can be used to faithfully predict generalization on\nunseen test data. The proposed equation is expected to be useful for future\nresearch on robust and adaptive learning.",
            "author": [
                "Peter Nickl",
                "Lu Xu",
                "Dharmesh Tailor",
                "Thomas M\u00f6llenhoff",
                "Mohammad Emtiyaz Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19273v1",
                "http://arxiv.org/pdf/2310.19273v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19272v1",
            "title": "NPCL: Neural Processes for Uncertainty-Aware Continual Learning",
            "updated": "2023-10-30T05:10:00Z",
            "published": "2023-10-30T05:10:00Z",
            "summary": "Continual learning (CL) aims to train deep neural networks efficiently on\nstreaming data while limiting the forgetting caused by new tasks. However,\nlearning transferable knowledge with less interference between tasks is\ndifficult, and real-world deployment of CL models is limited by their inability\nto measure predictive uncertainties. To address these issues, we propose\nhandling CL tasks with neural processes (NPs), a class of meta-learners that\nencode different tasks into probabilistic distributions over functions all\nwhile providing reliable uncertainty estimates. Specifically, we propose an\nNP-based CL approach (NPCL) with task-specific modules arranged in a\nhierarchical latent variable model. We tailor regularizers on the learned\nlatent distributions to alleviate forgetting. The uncertainty estimation\ncapabilities of the NPCL can also be used to handle the task head/module\ninference challenge in CL. Our experiments show that the NPCL outperforms\nprevious CL approaches. We validate the effectiveness of uncertainty estimation\nin the NPCL for identifying novel data and evaluating instance-level model\nconfidence. Code is available at \\url{https://github.com/srvCodes/NPCL}.",
            "author": [
                "Saurav Jha",
                "Dong Gong",
                "He Zhao",
                "Lina Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19272v1",
                "http://arxiv.org/pdf/2310.19272v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19271v1",
            "title": "Learning to love diligent trolls: Accounting for rater effects in the\n  dialogue safety task",
            "updated": "2023-10-30T05:08:23Z",
            "published": "2023-10-30T05:08:23Z",
            "summary": "Chatbots have the risk of generating offensive utterances, which must be\navoided. Post-deployment, one way for a chatbot to continuously improve is to\nsource utterance/label pairs from feedback by live users. However, among users\nare trolls, who provide training examples with incorrect labels. To de-troll\ntraining data, previous work removed training examples that have high\nuser-aggregated cross-validation (CV) error. However, CV is expensive; and in a\ncoordinated attack, CV may be overwhelmed by trolls in number and in\nconsistency among themselves. In the present work, I address both limitations\nby proposing a solution inspired by methodology in automated essay scoring\n(AES): have multiple users rate each utterance, then perform latent class\nanalysis (LCA) to infer correct labels. As it does not require GPU\ncomputations, LCA is inexpensive. In experiments, I found that the AES-like\nsolution can infer training labels with high accuracy when trolls are\nconsistent, even when trolls are the majority.",
            "author": [
                "Michael John Ilagan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19271v1",
                "http://arxiv.org/pdf/2310.19271v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19270v1",
            "title": "Invariant kernels on Riemannian symmetric spaces: a harmonic-analytic\n  approach",
            "updated": "2023-10-30T05:06:52Z",
            "published": "2023-10-30T05:06:52Z",
            "summary": "This work aims to prove that the classical Gaussian kernel, when defined on a\nnon-Euclidean symmetric space, is never positive-definite for any choice of\nparameter. To achieve this goal, the paper develops new geometric and\nanalytical arguments. These provide a rigorous characterization of the\npositive-definiteness of the Gaussian kernel, which is complete but for a\nlimited number of scenarios in low dimensions that are treated by numerical\ncomputations. Chief among these results are the L$^{\\!\\scriptscriptstyle\np}$-$\\hspace{0.02cm}$Godement theorems (where $p = 1,2$), which provide\nverifiable necessary and sufficient conditions for a kernel defined on a\nsymmetric space of non-compact type to be positive-definite. A celebrated\ntheorem, sometimes called the Bochner-Godement theorem, already gives such\nconditions and is far more general in its scope, but is especially hard to\napply. Beyond the connection with the Gaussian kernel, the new results in this\nwork lay out a blueprint for the study of invariant kernels on symmetric\nspaces, bringing forth specific harmonic analysis tools that suggest many\nfuture applications.",
            "author": [
                "Nathael Da Costa",
                "Cyrus Mostajeran",
                "Juan-Pablo Ortega",
                "Salem Said"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19270v1",
                "http://arxiv.org/pdf/2310.19270v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.DG",
                "stat.ML",
                "43A35, 43A85, 43A90, 46E22, 53C35, 53Z50"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19263v1",
            "title": "A Metadata-Driven Approach to Understand Graph Neural Networks",
            "updated": "2023-10-30T04:25:02Z",
            "published": "2023-10-30T04:25:02Z",
            "summary": "Graph Neural Networks (GNNs) have achieved remarkable success in various\napplications, but their performance can be sensitive to specific data\nproperties of the graph datasets they operate on. Current literature on\nunderstanding the limitations of GNNs has primarily employed a\n$\\textit{model-driven}$ approach that leverage heuristics and domain knowledge\nfrom network science or graph theory to model the GNN behaviors, which is\ntime-consuming and highly subjective. In this work, we propose a\n$\\textit{metadata-driven}$ approach to analyze the sensitivity of GNNs to graph\ndata properties, motivated by the increasing availability of graph learning\nbenchmarks. We perform a multivariate sparse regression analysis on the\nmetadata derived from benchmarking GNN performance across diverse datasets,\nyielding a set of salient data properties. To validate the effectiveness of our\ndata-driven approach, we focus on one identified data property, the degree\ndistribution, and investigate how this property influences GNN performance\nthrough theoretical analysis and controlled experiments. Our theoretical\nfindings reveal that datasets with more balanced degree distribution exhibit\nbetter linear separability of node representations, thus leading to better GNN\nperformance. We also conduct controlled experiments using synthetic datasets\nwith varying degree distributions, and the results align well with our\ntheoretical findings. Collectively, both the theoretical analysis and\ncontrolled experiments verify that the proposed metadata-driven approach is\neffective in identifying critical data properties for GNNs.",
            "author": [
                "Ting Wei Li",
                "Qiaozhu Mei",
                "Jiaqi Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19263v1",
                "http://arxiv.org/pdf/2310.19263v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19261v1",
            "title": "Diversify & Conquer: Outcome-directed Curriculum RL via\n  Out-of-Distribution Disagreement",
            "updated": "2023-10-30T04:12:19Z",
            "published": "2023-10-30T04:12:19Z",
            "summary": "Reinforcement learning (RL) often faces the challenges of uninformed search\nproblems where the agent should explore without access to the domain knowledge\nsuch as characteristics of the environment or external rewards. To tackle these\nchallenges, this work proposes a new approach for curriculum RL called\nDiversify for Disagreement & Conquer (D2C). Unlike previous curriculum learning\nmethods, D2C requires only a few examples of desired outcomes and works in any\nenvironment, regardless of its geometry or the distribution of the desired\noutcome examples. The proposed method performs diversification of the\ngoal-conditional classifiers to identify similarities between visited and\ndesired outcome states and ensures that the classifiers disagree on states from\nout-of-distribution, which enables quantifying the unexplored region and\ndesigning an arbitrary goal-conditioned intrinsic reward signal in a simple and\nintuitive way. The proposed method then employs bipartite matching to define a\ncurriculum learning objective that produces a sequence of well-adjusted\nintermediate goals, which enable the agent to automatically explore and conquer\nthe unexplored region. We present experimental results demonstrating that D2C\noutperforms prior curriculum RL methods in both quantitative and qualitative\naspects, even with the arbitrarily distributed desired outcome examples.",
            "author": [
                "Daesol Cho",
                "Seungjae Lee",
                "H. Jin Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19261v1",
                "http://arxiv.org/pdf/2310.19261v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19253v2",
            "title": "Flow-based distributionally robust optimization",
            "updated": "2023-11-07T02:09:17Z",
            "published": "2023-10-30T03:53:31Z",
            "summary": "We present a computationally efficient framework, called FlowDRO, for solving\nflow-based distributionally robust optimization (DRO) problems with Wasserstein\nuncertainty sets while aiming to find continuous worst-case distribution (also\ncalled the Least Favorable Distribution, LFD). The requirement for LFD to be\ncontinuous is so that the algorithm can be scalable to problems with larger\nsample sizes and achieve better generalization capability for the induced\nrobust algorithms. To tackle the computationally challenging infinitely\ndimensional optimization problem, we leverage flow-based models and\ncontinuous-time invertible transport maps between the data distribution and the\ntarget distribution. We also develop a Wasserstein proximal gradient flow type\nof algorithm. In theory, we establish the equivalence of the solution by\noptimal transport map to the original formulation, as well as the dual form of\nthe problem through Wasserstein calculus and Brenier theorem. In practice, we\nparameterize the transport maps by a sequence of neural networks progressively\ntrained in blocks by gradient descent. Our computational framework is general,\ncan handle high-dimensional data with large sample sizes, and can be useful for\nvarious applications. We demonstrate its usage in adversarial learning,\ndistributionally robust hypothesis testing, and a new mechanism for data-driven\ndistribution perturbation differential privacy, where the proposed method gives\nstrong empirical performance on real high-dimensional data.",
            "author": [
                "Chen Xu",
                "Jonghyeok Lee",
                "Xiuyuan Cheng",
                "Yao Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19253v2",
                "http://arxiv.org/pdf/2310.19253v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19252v1",
            "title": "Revisiting Evaluation Metrics for Semantic Segmentation: Optimization\n  and Evaluation of Fine-grained Intersection over Union",
            "updated": "2023-10-30T03:45:15Z",
            "published": "2023-10-30T03:45:15Z",
            "summary": "Semantic segmentation datasets often exhibit two types of imbalance:\n\\textit{class imbalance}, where some classes appear more frequently than others\nand \\textit{size imbalance}, where some objects occupy more pixels than others.\nThis causes traditional evaluation metrics to be biased towards\n\\textit{majority classes} (e.g. overall pixel-wise accuracy) and \\textit{large\nobjects} (e.g. mean pixel-wise accuracy and per-dataset mean intersection over\nunion). To address these shortcomings, we propose the use of fine-grained mIoUs\nalong with corresponding worst-case metrics, thereby offering a more holistic\nevaluation of segmentation techniques. These fine-grained metrics offer less\nbias towards large objects, richer statistical information, and valuable\ninsights into model and dataset auditing. Furthermore, we undertake an\nextensive benchmark study, where we train and evaluate 15 modern neural\nnetworks with the proposed metrics on 12 diverse natural and aerial\nsegmentation datasets. Our benchmark study highlights the necessity of not\nbasing evaluations on a single metric and confirms that fine-grained mIoUs\nreduce the bias towards large objects. Moreover, we identify the crucial role\nplayed by architecture designs and loss functions, which lead to best practices\nin optimizing fine-grained metrics. The code is available at\n\\href{https://github.com/zifuwanggg/JDTLosses}{https://github.com/zifuwanggg/JDTLosses}.",
            "author": [
                "Zifu Wang",
                "Maxim Berman",
                "Amal Rannen-Triki",
                "Philip H. S. Torr",
                "Devis Tuia",
                "Tinne Tuytelaars",
                "Luc Van Gool",
                "Jiaqian Yu",
                "Matthew B. Blaschko"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19252v1",
                "http://arxiv.org/pdf/2310.19252v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19251v1",
            "title": "Pre-trained Recommender Systems: A Causal Debiasing Perspective",
            "updated": "2023-10-30T03:37:32Z",
            "published": "2023-10-30T03:37:32Z",
            "summary": "Recent studies on pre-trained vision/language models have demonstrated the\npractical benefit of a new, promising solution-building paradigm in AI where\nmodels can be pre-trained on broad data describing a generic task space and\nthen adapted successfully to solve a wide range of downstream tasks, even when\ntraining data is severely limited (e.g., in zero- or few-shot learning\nscenarios). Inspired by such progress, we investigate in this paper the\npossibilities and challenges of adapting such a paradigm to the context of\nrecommender systems, which is less investigated from the perspective of\npre-trained model. In particular, we propose to develop a generic recommender\nthat captures universal interaction patterns by training on generic user-item\ninteraction data extracted from different domains, which can then be fast\nadapted to improve few-shot learning performance in unseen new domains (with\nlimited data).\n  However, unlike vision/language data which share strong conformity in the\nsemantic space, universal patterns underlying recommendation data collected\nacross different domains (e.g., different countries or different E-commerce\nplatforms) are often occluded by both in-domain and cross-domain biases\nimplicitly imposed by the cultural differences in their user and item bases, as\nwell as their uses of different e-commerce platforms. As shown in our\nexperiments, such heterogeneous biases in the data tend to hinder the\neffectiveness of the pre-trained model. To address this challenge, we further\nintroduce and formalize a causal debiasing perspective, which is substantiated\nvia a hierarchical Bayesian deep learning model, named PreRec. Our empirical\nstudies on real-world data show that the proposed model could significantly\nimprove the recommendation performance in zero- and few-shot learning settings\nunder both cross-market and cross-platform scenarios.",
            "author": [
                "Ziqian Lin",
                "Hao Ding",
                "Nghia Hoang",
                "Branislav Kveton",
                "Anoop Deoras",
                "Hao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19251v1",
                "http://arxiv.org/pdf/2310.19251v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19250v1",
            "title": "Assessment of Differentially Private Synthetic Data for Utility and\n  Fairness in End-to-End Machine Learning Pipelines for Tabular Data",
            "updated": "2023-10-30T03:37:16Z",
            "published": "2023-10-30T03:37:16Z",
            "summary": "Differentially private (DP) synthetic data sets are a solution for sharing\ndata while preserving the privacy of individual data providers. Understanding\nthe effects of utilizing DP synthetic data in end-to-end machine learning\npipelines impacts areas such as health care and humanitarian action, where data\nis scarce and regulated by restrictive privacy laws. In this work, we\ninvestigate the extent to which synthetic data can replace real, tabular data\nin machine learning pipelines and identify the most effective synthetic data\ngeneration techniques for training and evaluating machine learning models. We\ninvestigate the impacts of differentially private synthetic data on downstream\nclassification tasks from the point of view of utility as well as fairness. Our\nanalysis is comprehensive and includes representatives of the two main types of\nsynthetic data generation algorithms: marginal-based and GAN-based. To the best\nof our knowledge, our work is the first that: (i) proposes a training and\nevaluation framework that does not assume that real data is available for\ntesting the utility and fairness of machine learning models trained on\nsynthetic data; (ii) presents the most extensive analysis of synthetic data set\ngeneration algorithms in terms of utility and fairness when used for training\nmachine learning models; and (iii) encompasses several different definitions of\nfairness. Our findings demonstrate that marginal-based synthetic data\ngenerators surpass GAN-based ones regarding model training utility for tabular\ndata. Indeed, we show that models trained using data generated by\nmarginal-based algorithms can exhibit similar utility to models trained using\nreal data. Our analysis also reveals that the marginal-based synthetic data\ngenerator MWEM PGM can train models that simultaneously achieve utility and\nfairness characteristics close to those obtained by models trained with real\ndata.",
            "author": [
                "Mayana Pereira",
                "Meghana Kshirsagar",
                "Sumit Mukherjee",
                "Rahul Dodhia",
                "Juan Lavista Ferres",
                "Rafael de Sousa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19250v1",
                "http://arxiv.org/pdf/2310.19250v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19248v1",
            "title": "IMPRESS: Evaluating the Resilience of Imperceptible Perturbations\n  Against Unauthorized Data Usage in Diffusion-Based Generative AI",
            "updated": "2023-10-30T03:33:41Z",
            "published": "2023-10-30T03:33:41Z",
            "summary": "Diffusion-based image generation models, such as Stable Diffusion or DALL-E\n2, are able to learn from given images and generate high-quality samples\nfollowing the guidance from prompts. For instance, they can be used to create\nartistic images that mimic the style of an artist based on his/her original\nartworks or to maliciously edit the original images for fake content. However,\nsuch ability also brings serious ethical issues without proper authorization\nfrom the owner of the original images. In response, several attempts have been\nmade to protect the original images from such unauthorized data usage by adding\nimperceptible perturbations, which are designed to mislead the diffusion model\nand make it unable to properly generate new samples. In this work, we introduce\na perturbation purification platform, named IMPRESS, to evaluate the\neffectiveness of imperceptible perturbations as a protective measure. IMPRESS\nis based on the key observation that imperceptible perturbations could lead to\na perceptible inconsistency between the original image and the\ndiffusion-reconstructed image, which can be used to devise a new optimization\nstrategy for purifying the image, which may weaken the protection of the\noriginal image from unauthorized data usage (e.g., style mimicking, malicious\nediting). The proposed IMPRESS platform offers a comprehensive evaluation of\nseveral contemporary protection methods, and can be used as an evaluation\nplatform for future protection methods.",
            "author": [
                "Bochuan Cao",
                "Changjiang Li",
                "Ting Wang",
                "Jinyuan Jia",
                "Bo Li",
                "Jinghui Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19248v1",
                "http://arxiv.org/pdf/2310.19248v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19247v1",
            "title": "Uncertainty-guided Boundary Learning for Imbalanced Social Event\n  Detection",
            "updated": "2023-10-30T03:32:04Z",
            "published": "2023-10-30T03:32:04Z",
            "summary": "Real-world social events typically exhibit a severe class-imbalance\ndistribution, which makes the trained detection model encounter a serious\ngeneralization challenge. Most studies solve this problem from the frequency\nperspective and emphasize the representation or classifier learning for tail\nclasses. While in our observation, compared to the rarity of classes, the\ncalibrated uncertainty estimated from well-trained evidential deep learning\nnetworks better reflects model performance. To this end, we propose a novel\nuncertainty-guided class imbalance learning framework - UCL$_{SED}$, and its\nvariant - UCL-EC$_{SED}$, for imbalanced social event detection tasks. We aim\nto improve the overall model performance by enhancing model generalization to\nthose uncertain classes. Considering performance degradation usually comes from\nmisclassifying samples as their confusing neighboring classes, we focus on\nboundary learning in latent space and classifier learning with high-quality\nuncertainty estimation. First, we design a novel uncertainty-guided contrastive\nlearning loss, namely UCL and its variant - UCL-EC, to manipulate\ndistinguishable representation distribution for imbalanced data. During\ntraining, they force all classes, especially uncertain ones, to adaptively\nadjust a clear separable boundary in the feature space. Second, to obtain more\nrobust and accurate class uncertainty, we combine the results of multi-view\nevidential classifiers via the Dempster-Shafer theory under the supervision of\nan additional calibration method. We conduct experiments on three severely\nimbalanced social event datasets including Events2012\\_100, Events2018\\_100,\nand CrisisLexT\\_7. Our model significantly improves social event representation\nand classification tasks in almost all classes, especially those uncertain\nones.",
            "author": [
                "Jiaqian Ren",
                "Hao Peng",
                "Lei Jiang",
                "Zhiwei Liu",
                "Jia Wu",
                "Zhengtao Yu",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19247v1",
                "http://arxiv.org/pdf/2310.19247v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19246v1",
            "title": "A spectral regularisation framework for latent variable models designed\n  for single channel applications",
            "updated": "2023-10-30T03:24:54Z",
            "published": "2023-10-30T03:24:54Z",
            "summary": "Latent variable models (LVMs) are commonly used to capture the underlying\ndependencies, patterns, and hidden structure in observed data. Source\nduplication is a by-product of the data hankelisation pre-processing step\ncommon to single channel LVM applications, which hinders practical LVM\nutilisation. In this article, a Python package titled\nspectrally-regularised-LVMs is presented. The proposed package addresses the\nsource duplication issue via the addition of a novel spectral regularisation\nterm. This package provides a framework for spectral regularisation in single\nchannel LVM applications, thereby making it easier to investigate and utilise\nLVMs with spectral regularisation. This is achieved via the use of symbolic or\nexplicit representations of potential LVM objective functions which are\nincorporated into a framework that uses spectral regularisation during the LVM\nparameter estimation process. The objective of this package is to provide a\nconsistent linear LVM optimisation framework which incorporates spectral\nregularisation and caters to single channel time-series applications.",
            "author": [
                "Ryan Balshaw",
                "P. Stephan Heyns",
                "Daniel N. Wilke",
                "Stephan Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19246v1",
                "http://arxiv.org/pdf/2310.19246v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME",
                "60G35, 62M15, 62M10, 91B84, 49K45",
                "G.3; I.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16126v1",
            "title": "A Hierarchical Training Paradigm for Antibody Structure-sequence\n  Co-design",
            "updated": "2023-10-30T02:39:15Z",
            "published": "2023-10-30T02:39:15Z",
            "summary": "Therapeutic antibodies are an essential and rapidly expanding drug modality.\nThe binding specificity between antibodies and antigens is decided by\ncomplementarity-determining regions (CDRs) at the tips of these Y-shaped\nproteins. In this paper, we propose a hierarchical training paradigm (HTP) for\nthe antibody sequence-structure co-design. HTP consists of four levels of\ntraining stages, each corresponding to a specific protein modality within a\nparticular protein domain. Through carefully crafted tasks in different stages,\nHTP seamlessly and effectively integrates geometric graph neural networks\n(GNNs) with large-scale protein language models to excavate evolutionary\ninformation from not only geometric structures but also vast antibody and\nnon-antibody sequence databases, which determines ligand binding pose and\nstrength. Empirical experiments show that HTP sets the new state-of-the-art\nperformance in the co-design problem as well as the fix-backbone design. Our\nresearch offers a hopeful path to unleash the potential of deep generative\narchitectures and seeks to illuminate the way forward for the antibody sequence\nand structure co-design challenge.",
            "author": [
                "Fang Wu",
                "Stan Z. Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16126v1",
                "http://arxiv.org/pdf/2311.16126v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19232v1",
            "title": "Adapter Pruning using Tropical Characterization",
            "updated": "2023-10-30T02:20:44Z",
            "published": "2023-10-30T02:20:44Z",
            "summary": "Adapters are widely popular parameter-efficient transfer learning approaches\nin natural language processing that insert trainable modules in between layers\nof a pre-trained language model. Apart from several heuristics, however, there\nhas been a lack of studies analyzing the optimal number of adapter parameters\nneeded for downstream applications. In this paper, we propose an adapter\npruning approach by studying the tropical characteristics of trainable modules.\nWe cast it as an optimization problem that aims to prune parameters from the\nadapter layers without changing the orientation of underlying tropical\nhypersurfaces. Our experiments on five NLP datasets show that tropical geometry\ntends to identify more relevant parameters to prune when compared with the\nmagnitude-based baseline, while a combined approach works best across the\ntasks.",
            "author": [
                "Rishabh Bhardwaj",
                "Tushar Vaidya",
                "Soujanya Poria"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19232v1",
                "http://arxiv.org/pdf/2310.19232v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19231v1",
            "title": "There Are No Data Like More Data- Datasets for Deep Learning in Earth\n  Observation",
            "updated": "2023-10-30T02:19:16Z",
            "published": "2023-10-30T02:19:16Z",
            "summary": "Carefully curated and annotated datasets are the foundation of machine\nlearning, with particularly data-hungry deep neural networks forming the core\nof what is often called Artificial Intelligence (AI). Due to the massive\nsuccess of deep learning applied to Earth Observation (EO) problems, the focus\nof the community has been largely on the development of ever-more sophisticated\ndeep neural network architectures and training strategies largely ignoring the\noverall importance of datasets. For that purpose, numerous task-specific\ndatasets have been created that were largely ignored by previously published\nreview articles on AI for Earth observation. With this article, we want to\nchange the perspective and put machine learning datasets dedicated to Earth\nobservation data and applications into the spotlight. Based on a review of the\nhistorical developments, currently available resources are described and a\nperspective for future developments is formed. We hope to contribute to an\nunderstanding that the nature of our data is what distinguishes the Earth\nobservation community from many other communities that apply deep learning\ntechniques to image data, and that a detailed understanding of EO data\npeculiarities is among the core competencies of our discipline.",
            "author": [
                "Michael Schmitt",
                "Seyed Ali Ahmadi",
                "Yonghao Xu",
                "Gulsen Taskin",
                "Ujjwal Verma",
                "Francescopaolo Sica",
                "Ronny Hansch"
            ],
            "link": [
                "http://dx.doi.org/10.1109/MGRS.2023.3293459",
                "http://arxiv.org/abs/2310.19231v1",
                "http://arxiv.org/pdf/2310.19231v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19226v1",
            "title": "Knolling bot 2.0: Enhancing Object Organization with Self-supervised\n  Graspability Estimation",
            "updated": "2023-10-30T02:14:11Z",
            "published": "2023-10-30T02:14:11Z",
            "summary": "Building on recent advancements in transformer based approaches for domestic\nrobots performing knolling, the art of organizing scattered items into neat\narrangements. This paper introduces Knolling bot 2.0. Recognizing the\nchallenges posed by piles of objects or items situated closely together, this\nupgraded system incorporates a self-supervised graspability estimation model.\nIf objects are deemed ungraspable, an additional behavior will be executed to\nseparate the objects before knolling the table. By integrating this grasp\nprediction mechanism with existing visual perception and transformer based\nknolling models, an advanced system capable of decluttering and organizing even\nmore complex and densely populated table settings is demonstrated. Experimental\nevaluations demonstrate the effectiveness of this module, yielding a\ngraspability prediction accuracy of 95.7%.",
            "author": [
                "Yuhang Hu",
                "Zhizhuo Zhang",
                "Hod Lipson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19226v1",
                "http://arxiv.org/pdf/2310.19226v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19225v1",
            "title": "Stochastic Configuration Machines: FPGA Implementation",
            "updated": "2023-10-30T02:04:20Z",
            "published": "2023-10-30T02:04:20Z",
            "summary": "Neural networks for industrial applications generally have additional\nconstraints such as response speed, memory size and power usage. Randomized\nlearners can address some of these issues. However, hardware solutions can\nprovide better resource reduction whilst maintaining the model's performance.\nStochastic configuration networks (SCNs) are a prime choice in industrial\napplications due to their merits and feasibility for data modelling. Stochastic\nConfiguration Machines (SCMs) extend this to focus on reducing the memory\nconstraints by limiting the randomized weights to a binary value with a scalar\nfor each node and using a mechanism model to improve the learning performance\nand result interpretability. This paper aims to implement SCM models on a field\nprogrammable gate array (FPGA) and introduce binary-coded inputs to the\nalgorithm. Results are reported for two benchmark and two industrial datasets,\nincluding SCM with single-layer and deep architectures.",
            "author": [
                "Matthew J. Felicetti",
                "Dianhui Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19225v1",
                "http://arxiv.org/pdf/2310.19225v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19223v1",
            "title": "Modular Anti-noise Deep Learning Network for Robotic Grasp Detection\n  Based on RGB Images",
            "updated": "2023-10-30T02:01:49Z",
            "published": "2023-10-30T02:01:49Z",
            "summary": "While traditional methods relies on depth sensors, the current trend leans\ntowards utilizing cost-effective RGB images, despite their absence of depth\ncues. This paper introduces an interesting approach to detect grasping pose\nfrom a single RGB image. To this end, we propose a modular learning network\naugmented with grasp detection and semantic segmentation, tailored for robots\nequipped with parallel-plate grippers. Our network not only identifies\ngraspable objects but also fuses prior grasp analyses with semantic\nsegmentation, thereby boosting grasp detection precision. Significantly, our\ndesign exhibits resilience, adeptly handling blurred and noisy visuals. Key\ncontributions encompass a trainable network for grasp detection from RGB\nimages, a modular design facilitating feasible grasp implementation, and an\narchitecture robust against common image distortions. We demonstrate the\nfeasibility and accuracy of our proposed approach through practical experiments\nand evaluations.",
            "author": [
                "Zhaocong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19223v1",
                "http://arxiv.org/pdf/2310.19223v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19222v1",
            "title": "Maximum Knowledge Orthogonality Reconstruction with Gradients in\n  Federated Learning",
            "updated": "2023-10-30T02:01:48Z",
            "published": "2023-10-30T02:01:48Z",
            "summary": "Federated learning (FL) aims at keeping client data local to preserve\nprivacy. Instead of gathering the data itself, the server only collects\naggregated gradient updates from clients. Following the popularity of FL, there\nhas been considerable amount of work, revealing the vulnerability of FL\napproaches by reconstructing the input data from gradient updates. Yet, most\nexisting works assume an FL setting with unrealistically small batch size, and\nhave poor image quality when the batch size is large. Other works modify the\nneural network architectures or parameters to the point of being suspicious,\nand thus, can be detected by clients. Moreover, most of them can only\nreconstruct one sample input from a large batch. To address these limitations,\nwe propose a novel and completely analytical approach, referred to as the\nmaximum knowledge orthogonality reconstruction (MKOR), to reconstruct clients'\ninput data. Our proposed method reconstructs a mathematically proven high\nquality image from large batches. MKOR only requires the server to send\nsecretly modified parameters to clients and can efficiently and inconspicuously\nreconstruct the input images from clients' gradient updates. We evaluate MKOR's\nperformance on the MNIST, CIFAR-100, and ImageNet dataset and compare it with\nthe state-of-the-art works. The results show that MKOR outperforms the existing\napproaches, and draws attention to a pressing need for further research on the\nprivacy protection of FL so that comprehensive defense approaches can be\ndeveloped.",
            "author": [
                "Feng Wang",
                "Senem Velipasalar",
                "M. Cenk Gursoy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19222v1",
                "http://arxiv.org/pdf/2310.19222v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19220v1",
            "title": "From Stream to Pool: Dynamic Pricing Beyond i.i.d. Arrivals",
            "updated": "2023-10-30T01:53:37Z",
            "published": "2023-10-30T01:53:37Z",
            "summary": "The dynamic pricing problem has been extensively studied under the\n\\textbf{stream} model: A stream of customers arrives sequentially, each with an\nindependently and identically distributed valuation. However, this formulation\nis not entirely reflective of the real world. In many scenarios, high-valuation\ncustomers tend to make purchases earlier and leave the market, leading to a\n\\emph{shift} in the valuation distribution. Thus motivated, we consider a model\nwhere a \\textbf{pool} of $n$ non-strategic unit-demand customers interact\nrepeatedly with the seller. Each customer monitors the price intermittently\naccording to an independent Poisson process and makes a purchase if the\nobserved price is lower than her \\emph{private} valuation, whereupon she leaves\nthe market permanently. We present a minimax \\emph{optimal} algorithm that\nefficiently computes a non-adaptive policy which guarantees a $1/k$ fraction of\nthe optimal revenue, given any set of $k$ prices. Moreover, we present an\nadaptive \\emph{learn-then-earn} policy based on a novel \\emph{debiasing}\napproach, and prove an $\\tilde O(kn^{3/4})$ regret bound. We further improve\nthe bound to $\\tilde O(k^{3/4} n^{3/4})$ using martingale concentration\ninequalities.",
            "author": [
                "Titing Cui",
                "Su Jia",
                "Thomas Lavastida"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19220v1",
                "http://arxiv.org/pdf/2310.19220v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19218v2",
            "title": "A Survey of Federated Unlearning: A Taxonomy, Challenges and Future\n  Directions",
            "updated": "2023-11-09T18:26:11Z",
            "published": "2023-10-30T01:34:33Z",
            "summary": "With the development of trustworthy Federated Learning (FL), the requirement\nof implementing right to be forgotten gives rise to the area of Federated\nUnlearning (FU). Comparing to machine unlearning, a major challenge of FU lies\nin the decentralized and privacy-preserving nature of FL, in which clients\njointly train a global model without sharing their raw data, making it\nsubstantially more intricate to selectively unlearn specific information. In\nthat regard, many efforts have been made to tackle the challenges of FU and\nhave achieved significant progress. In this paper, we present a comprehensive\nsurvey of FU. Specially, we provide the existing algorithms, objectives,\nevaluation metrics, and identify some challenges of FU. By reviewing and\ncomparing some studies, we summarize them into a taxonomy for various schemes,\npotential applications and future directions.",
            "author": [
                "Jiaxi Yang",
                "Yang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19218v2",
                "http://arxiv.org/pdf/2310.19218v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19216v1",
            "title": "Optimal Status Updates for Minimizing Age of Correlated Information in\n  IoT Networks with Energy Harvesting Sensors",
            "updated": "2023-10-30T01:03:47Z",
            "published": "2023-10-30T01:03:47Z",
            "summary": "Many real-time applications of the Internet of Things (IoT) need to deal with\ncorrelated information generated by multiple sensors. The design of efficient\nstatus update strategies that minimize the Age of Correlated Information (AoCI)\nis a key factor. In this paper, we consider an IoT network consisting of\nsensors equipped with the energy harvesting (EH) capability. We optimize the\naverage AoCI at the data fusion center (DFC) by appropriately managing the\nenergy harvested by sensors, whose true battery states are unobservable during\nthe decision-making process. Particularly, we first formulate the dynamic\nstatus update procedure as a partially observable Markov decision process\n(POMDP), where the environmental dynamics are unknown to the DFC. In order to\naddress the challenges arising from the causality of energy usage, unknown\nenvironmental dynamics, unobservability of sensors'true battery states, and\nlarge-scale discrete action space, we devise a deep reinforcement learning\n(DRL)-based dynamic status update algorithm. The algorithm leverages the\nadvantages of the soft actor-critic and long short-term memory techniques.\nMeanwhile, it incorporates our proposed action decomposition and mapping\nmechanism. Extensive simulations are conducted to validate the effectiveness of\nour proposed algorithm by comparing it with available DRL algorithms for\nPOMDPs.",
            "author": [
                "Chao Xu",
                "Xinyan Zhang",
                "Howard H. Yang",
                "Xijun Wang",
                "Nikolaos Pappas",
                "Dusit Niyato",
                "Tony Q. S. Quek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19216v1",
                "http://arxiv.org/pdf/2310.19216v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19215v1",
            "title": "On the accuracy and efficiency of group-wise clipping in differentially\n  private optimization",
            "updated": "2023-10-30T01:01:15Z",
            "published": "2023-10-30T01:01:15Z",
            "summary": "Recent advances have substantially improved the accuracy, memory cost, and\ntraining speed of differentially private (DP) deep learning, especially on\nlarge vision and language models with millions to billions of parameters. In\nthis work, we thoroughly study the per-sample gradient clipping style, a key\ncomponent in DP optimization. We show that different clipping styles have the\nsame time complexity but instantiate an accuracy-memory trade-off: while the\nall-layer clipping (of coarse granularity) is the most prevalent and usually\ngives the best accuracy, it incurs heavier memory cost compared to other\ngroup-wise clipping, such as the layer-wise clipping (of finer granularity). We\nformalize this trade-off through our convergence theory and complexity\nanalysis. Importantly, we demonstrate that the accuracy gap between group-wise\nclipping and all-layer clipping becomes smaller for larger models, while the\nmemory advantage of the group-wise clipping remains. Consequently, the\ngroup-wise clipping allows DP optimization of large models to achieve high\naccuracy and low peak memory simultaneously.",
            "author": [
                "Zhiqi Bu",
                "Ruixuan Liu",
                "Yu-Xiang Wang",
                "Sheng Zha",
                "George Karypis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19215v1",
                "http://arxiv.org/pdf/2310.19215v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CC",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19214v1",
            "title": "Factor Fitting, Rank Allocation, and Partitioning in Multilevel Low Rank\n  Matrices",
            "updated": "2023-10-30T00:52:17Z",
            "published": "2023-10-30T00:52:17Z",
            "summary": "We consider multilevel low rank (MLR) matrices, defined as a row and column\npermutation of a sum of matrices, each one a block diagonal refinement of the\nprevious one, with all blocks low rank given in factored form. MLR matrices\nextend low rank matrices but share many of their properties, such as the total\nstorage required and complexity of matrix-vector multiplication. We address\nthree problems that arise in fitting a given matrix by an MLR matrix in the\nFrobenius norm. The first problem is factor fitting, where we adjust the\nfactors of the MLR matrix. The second is rank allocation, where we choose the\nranks of the blocks in each level, subject to the total rank having a given\nvalue, which preserves the total storage needed for the MLR matrix. The final\nproblem is to choose the hierarchical partition of rows and columns, along with\nthe ranks and factors. This paper is accompanied by an open source package that\nimplements the proposed methods.",
            "author": [
                "Tetiana Parshakova",
                "Trevor Hastie",
                "Eric Darve",
                "Stephen Boyd"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19214v1",
                "http://arxiv.org/pdf/2310.19214v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.MS",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19211v1",
            "title": "Investigative Pattern Detection Framework for Counterterrorism",
            "updated": "2023-10-30T00:45:05Z",
            "published": "2023-10-30T00:45:05Z",
            "summary": "Law-enforcement investigations aimed at preventing attacks by violent\nextremists have become increasingly important for public safety. The problem is\nexacerbated by the massive data volumes that need to be scanned to identify\ncomplex behaviors of extremists and groups. Automated tools are required to\nextract information to respond queries from analysts, continually scan new\ninformation, integrate them with past events, and then alert about emerging\nthreats. We address challenges in investigative pattern detection and develop\nan Investigative Pattern Detection Framework for Counterterrorism (INSPECT).\nThe framework integrates numerous computing tools that include machine learning\ntechniques to identify behavioral indicators and graph pattern matching\ntechniques to detect risk profiles/groups. INSPECT also automates multiple\ntasks for large-scale mining of detailed forensic biographies, forming\nknowledge networks, and querying for behavioral indicators and radicalization\ntrajectories. INSPECT targets human-in-the-loop mode of investigative search\nand has been validated and evaluated using an evolving dataset on domestic\njihadism.",
            "author": [
                "Shashika R. Muramudalige",
                "Benjamin W. K. Hung",
                "Rosanne Libretti",
                "Jytte Klausen",
                "Anura P. Jayasumana"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19211v1",
                "http://arxiv.org/pdf/2310.19211v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19210v1",
            "title": "Generalized Category Discovery with Clustering Assignment Consistency",
            "updated": "2023-10-30T00:32:47Z",
            "published": "2023-10-30T00:32:47Z",
            "summary": "Generalized category discovery (GCD) is a recently proposed open-world task.\nGiven a set of images consisting of labeled and unlabeled instances, the goal\nof GCD is to automatically cluster the unlabeled samples using information\ntransferred from the labeled dataset. The unlabeled dataset comprises both\nknown and novel classes. The main challenge is that unlabeled novel class\nsamples and unlabeled known class samples are mixed together in the unlabeled\ndataset. To address the GCD without knowing the class number of unlabeled\ndataset, we propose a co-training-based framework that encourages clustering\nconsistency. Specifically, we first introduce weak and strong augmentation\ntransformations to generate two sufficiently different views for the same\nsample. Then, based on the co-training assumption, we propose a consistency\nrepresentation learning strategy, which encourages consistency between\nfeature-prototype similarity and clustering assignment. Finally, we use the\ndiscriminative embeddings learned from the semi-supervised representation\nlearning process to construct an original sparse network and use a community\ndetection method to obtain the clustering results and the number of categories\nsimultaneously. Extensive experiments show that our method achieves\nstate-of-the-art performance on three generic benchmarks and three fine-grained\nvisual recognition datasets. Especially in the ImageNet-100 data set, our\nmethod significantly exceeds the best baseline by 15.5\\% and 7.0\\% on the\n\\texttt{Novel} and \\texttt{All} classes, respectively.",
            "author": [
                "Xiangli Yang",
                "Xinglin Pan",
                "Irwin King",
                "Zenglin Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19210v1",
                "http://arxiv.org/pdf/2310.19210v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19206v1",
            "title": "Leveraging generative artificial intelligence to simulate student\n  learning behavior",
            "updated": "2023-10-30T00:09:59Z",
            "published": "2023-10-30T00:09:59Z",
            "summary": "Student simulation presents a transformative approach to enhance learning\noutcomes, advance educational research, and ultimately shape the future of\neffective pedagogy. We explore the feasibility of using large language models\n(LLMs), a remarkable achievement in AI, to simulate student learning behaviors.\nUnlike conventional machine learning based prediction, we leverage LLMs to\ninstantiate virtual students with specific demographics and uncover intricate\ncorrelations among learning experiences, course materials, understanding\nlevels, and engagement. Our objective is not merely to predict learning\noutcomes but to replicate learning behaviors and patterns of real students. We\nvalidate this hypothesis through three experiments. The first experiment, based\non a dataset of N = 145, simulates student learning outcomes from demographic\ndata, revealing parallels with actual students concerning various demographic\nfactors. The second experiment (N = 4524) results in increasingly realistic\nsimulated behaviors with more assessment history for virtual students\nmodelling. The third experiment (N = 27), incorporating prior knowledge and\ncourse interactions, indicates a strong link between virtual students' learning\nbehaviors and fine-grained mappings from test questions, course materials,\nengagement and understanding levels. Collectively, these findings deepen our\nunderstanding of LLMs and demonstrate its viability for student simulation,\nempowering more adaptable curricula design to enhance inclusivity and\neducational effectiveness.",
            "author": [
                "Songlin Xu",
                "Xinyu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19206v1",
                "http://arxiv.org/pdf/2310.19206v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19202v1",
            "title": "Improved Motor Imagery Classification Using Adaptive Spatial Filters\n  Based on Particle Swarm Optimization Algorithm",
            "updated": "2023-10-29T23:53:37Z",
            "published": "2023-10-29T23:53:37Z",
            "summary": "As a typical self-paced brain-computer interface (BCI) system, the motor\nimagery (MI) BCI has been widely applied in fields such as robot control,\nstroke rehabilitation, and assistance for patients with stroke or spinal cord\ninjury. Many studies have focused on the traditional spatial filters obtained\nthrough the common spatial pattern (CSP) method. However, the CSP method can\nonly obtain fixed spatial filters for specific input signals. Besides, CSP\nmethod only focuses on the variance difference of two types of\nelectroencephalogram (EEG) signals, so the decoding ability of EEG signals is\nlimited. To obtain more effective spatial filters for better extraction of\nspatial features that can improve classification to MI-EEG, this paper proposes\nan adaptive spatial filter solving method based on particle swarm optimization\nalgorithm (PSO). A training and testing framework based on filter bank and\nspatial filters (FBCSP-ASP) is designed for MI EEG signal classification.\nComparative experiments are conducted on two public datasets (2a and 2b) from\nBCI competition IV, which show the outstanding average recognition accuracy of\nFBCSP-ASP. The proposed method has achieved significant performance improvement\non MI-BCI. The classification accuracy of the proposed method has reached\n74.61% and 81.19% on datasets 2a and 2b, respectively. Compared with the\nbaseline algorithm (FBCSP), the proposed algorithm improves 11.44% and 7.11% on\ntwo datasets respectively. Furthermore, the analysis based on mutual\ninformation, t-SNE and Shapley values further proves that ASP features have\nexcellent decoding ability for MI-EEG signals, and explains the improvement of\nclassification performance by the introduction of ASP features.",
            "author": [
                "Xiong Xiong",
                "Ying Wang",
                "Tianyuan Song",
                "Jinguo Huang",
                "Guixia Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19202v1",
                "http://arxiv.org/pdf/2310.19202v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19200v1",
            "title": "Popularity, face and voice: Predicting and interpreting livestreamers'\n  retail performance using machine learning techniques",
            "updated": "2023-10-29T23:48:34Z",
            "published": "2023-10-29T23:48:34Z",
            "summary": "Livestreaming commerce, a hybrid of e-commerce and self-media, has expanded\nthe broad spectrum of traditional sales performance determinants. To\ninvestigate the factors that contribute to the success of livestreaming\ncommerce, we construct a longitudinal firm-level database with 19,175\nobservations, covering an entire livestreaming subsector. By comparing the\nforecasting accuracy of eight machine learning models, we identify a random\nforest model that provides the best prediction of gross merchandise volume\n(GMV). Furthermore, we utilize explainable artificial intelligence to open the\nblack-box of machine learning model, discovering four new facts: 1) variables\nrepresenting the popularity of livestreaming events are crucial features in\npredicting GMV. And voice attributes are more important than appearance; 2)\npopularity is a major determinant of sales for female hosts, while vocal\naesthetics is more decisive for their male counterparts; 3) merits and\ndrawbacks of the voice are not equally valued in the livestreaming market; 4)\nbased on changes of comments, page views and likes, sales growth can be divided\ninto three stages. Finally, we innovatively propose a 3D-SHAP diagram that\ndemonstrates the relationship between predicting feature importance, target\nvariable, and its predictors. This diagram identifies bottlenecks for both\nbeginner and top livestreamers, providing insights into ways to optimize their\nsales performance.",
            "author": [
                "Xiong Xiong",
                "Fan Yang",
                "Li Su"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19200v1",
                "http://arxiv.org/pdf/2310.19200v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19198v1",
            "title": "Enhancing Motor Imagery Decoding in Brain Computer Interfaces using\n  Riemann Tangent Space Mapping and Cross Frequency Coupling",
            "updated": "2023-10-29T23:37:47Z",
            "published": "2023-10-29T23:37:47Z",
            "summary": "Objective: Motor Imagery (MI) serves as a crucial experimental paradigm\nwithin the realm of Brain Computer Interfaces (BCIs), aiming to decoding motor\nintentions from electroencephalogram (EEG) signals. Method: Drawing inspiration\nfrom Riemannian geometry and Cross-Frequency Coupling (CFC), this paper\nintroduces a novel approach termed Riemann Tangent Space Mapping using\nDichotomous Filter Bank with Convolutional Neural Network (DFBRTS) to enhance\nthe representation quality and decoding capability pertaining to MI features.\nDFBRTS first initiates the process by meticulously filtering EEG signals\nthrough a Dichotomous Filter Bank, structured in the fashion of a complete\nbinary tree. Subsequently, it employs Riemann Tangent Space Mapping to extract\nsalient EEG signal features within each sub-band. Finally, a lightweight\nconvolutional neural network is employed for further feature extraction and\nclassification, operating under the joint supervision of cross-entropy and\ncenter loss. To validate the efficacy, extensive experiments were conducted\nusing DFBRTS on two well-established benchmark datasets: the BCI competition IV\n2a (BCIC-IV-2a) dataset and the OpenBMI dataset. The performance of DFBRTS was\nbenchmarked against several state-of-the-art MI decoding methods, alongside\nother Riemannian geometry-based MI decoding approaches. Results: DFBRTS\nsignificantly outperforms other MI decoding algorithms on both datasets,\nachieving a remarkable classification accuracy of 78.16% for four-class and\n71.58% for two-class hold-out classification, as compared to the existing\nbenchmarks.",
            "author": [
                "Xiong Xiong",
                "Li Su",
                "Jinguo Huang",
                "Guixia Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19198v1",
                "http://arxiv.org/pdf/2310.19198v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19197v1",
            "title": "concrete: Targeted Estimation of Survival and Competing Risks in\n  Continuous Time",
            "updated": "2023-10-29T23:36:41Z",
            "published": "2023-10-29T23:36:41Z",
            "summary": "This article introduces the R package concrete, which implements a recently\ndeveloped targeted maximum likelihood estimator (TMLE) for the cause-specific\nabsolute risks of time-to-event outcomes measured in continuous time.\nCross-validated Super Learner machine learning ensembles are used to estimate\npropensity scores and conditional cause-specific hazards, which are then\ntargeted to produce robust and efficient plug-in estimates of the effects of\nstatic or dynamic interventions on a binary treatment given at baseline\nquantified as risk differences or risk ratios. Influence curve-based asymptotic\ninference is provided for TMLE estimates and simultaneous confidence bands can\nbe computed for target estimands spanning multiple multiple times or events. In\nthis paper we review the one-step continuous-time TMLE methodology as it is\nsituated in an overarching causal inference workflow, describe its\nimplementation, and demonstrate the use of the package on the PBC dataset.",
            "author": [
                "David Chen",
                "Helene C. W. Rytgaard",
                "Edwin C. H. Fong",
                "Jens M. Tarp",
                "Maya L. Petersen",
                "Mark J. van der Laan",
                "Thomas A. Gerds"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19197v1",
                "http://arxiv.org/pdf/2310.19197v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02096v2",
            "title": "Variational Autoencoders for Noise Reduction in Industrial LLRF Systems",
            "updated": "2023-11-07T19:01:44Z",
            "published": "2023-10-29T23:29:49Z",
            "summary": "Industrial particle accelerators inherently operate in much dirtier\nenvironments than typical research accelerators. This leads to an increase in\nnoise both in the RF system and in other electronic systems. Combined with the\nfact that industrial accelerators are mass produced, there is less attention\ngiven to optimizing the performance of an individual system. As a result,\nindustrial systems tend to under perform considering their hardware hardware\ncapabilities. With the growing demand for accelerators for medical\nsterilization, food irradiation, cancer treatment, and imaging, improving the\nsignal processing of these machines will increase the margin for the deployment\nof these systems. Our work is focusing on using machine learning techniques to\nreduce the noise of RF signals used for pulse-to-pulse feedback in industrial\naccelerators. We will review our algorithms, simulation results, and results\nworking with measured data. We will then discuss next steps for deployment and\ntesting on an industrial system.",
            "author": [
                "J. P. Edelen",
                "M. J. Henderson",
                "J. Einstein-Curtis",
                "C. C. Hall",
                "J. A. Diaz Cruz",
                "A. L. Edelen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02096v2",
                "http://arxiv.org/pdf/2311.02096v2"
            ],
            "primary_category": "physics.acc-ph",
            "category": [
                "physics.acc-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10931v1",
            "title": "FLORIDA: Fake-looking Real Images Dataset",
            "updated": "2023-10-29T23:25:10Z",
            "published": "2023-10-29T23:25:10Z",
            "summary": "Although extensive research has been carried out to evaluate the\neffectiveness of AI tools and models in detecting deep fakes, the question\nremains unanswered regarding whether these models can accurately identify\ngenuine images that appear artificial. In this study, as an initial step\ntowards addressing this issue, we have curated a dataset of 510 genuine images\nthat exhibit a fake appearance and conducted an assessment using two AI models.\nWe show that two models exhibited subpar performance when applied to our\ndataset. Additionally, our dataset can serve as a valuable tool for assessing\nthe ability of deep learning models to comprehend complex visual stimuli. We\nanticipate that this research will stimulate further discussions and\ninvestigations in this area. Our dataset is accessible at\nhttps://github.com/aliborji/FLORIDA.",
            "author": [
                "Ali Borji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10931v1",
                "http://arxiv.org/pdf/2311.10931v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19192v1",
            "title": "Conformal Normalization in Recurrent Neural Network of Grid Cells",
            "updated": "2023-10-29T23:12:56Z",
            "published": "2023-10-29T23:12:56Z",
            "summary": "Grid cells in the entorhinal cortex of the mammalian brain exhibit striking\nhexagon firing patterns in their response maps as the animal (e.g., a rat)\nnavigates in a 2D open environment. The responses of the population of grid\ncells collectively form a vector in a high-dimensional neural activity space,\nand this vector represents the self-position of the agent in the 2D physical\nspace. As the agent moves, the vector is transformed by a recurrent neural\nnetwork that takes the velocity of the agent as input. In this paper, we\npropose a simple and general conformal normalization of the input velocity for\nthe recurrent neural network, so that the local displacement of the position\nvector in the high-dimensional neural space is proportional to the local\ndisplacement of the agent in the 2D physical space, regardless of the direction\nof the input velocity. Our numerical experiments on the minimally simple linear\nand non-linear recurrent networks show that conformal normalization leads to\nthe emergence of the hexagon grid patterns. Furthermore, we derive a new\ntheoretical understanding that connects conformal normalization to the\nemergence of hexagon grid patterns in navigation tasks.",
            "author": [
                "Dehong Xu",
                "Ruiqi Gao",
                "Wen-Hao Zhang",
                "Xue-Xin Wei",
                "Ying Nian Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19192v1",
                "http://arxiv.org/pdf/2310.19192v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19188v1",
            "title": "3DMiner: Discovering Shapes from Large-Scale Unannotated Image Datasets",
            "updated": "2023-10-29T23:08:19Z",
            "published": "2023-10-29T23:08:19Z",
            "summary": "We present 3DMiner -- a pipeline for mining 3D shapes from challenging\nlarge-scale unannotated image datasets. Unlike other unsupervised 3D\nreconstruction methods, we assume that, within a large-enough dataset, there\nmust exist images of objects with similar shapes but varying backgrounds,\ntextures, and viewpoints. Our approach leverages the recent advances in\nlearning self-supervised image representations to cluster images with\ngeometrically similar shapes and find common image correspondences between\nthem. We then exploit these correspondences to obtain rough camera estimates as\ninitialization for bundle-adjustment. Finally, for every image cluster, we\napply a progressive bundle-adjusting reconstruction method to learn a neural\noccupancy field representing the underlying shape. We show that this procedure\nis robust to several types of errors introduced in previous steps (e.g., wrong\ncamera poses, images containing dissimilar shapes, etc.), allowing us to obtain\nshape and pose annotations for images in-the-wild. When using images from Pix3D\nchairs, our method is capable of producing significantly better results than\nstate-of-the-art unsupervised 3D reconstruction techniques, both quantitatively\nand qualitatively. Furthermore, we show how 3DMiner can be applied to\nin-the-wild data by reconstructing shapes present in images from the LAION-5B\ndataset. Project Page: https://ttchengab.github.io/3dminerOfficial",
            "author": [
                "Ta-Ying Cheng",
                "Matheus Gadelha",
                "Soren Pirk",
                "Thibault Groueix",
                "Radomir Mech",
                "Andrew Markham",
                "Niki Trigoni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19188v1",
                "http://arxiv.org/pdf/2310.19188v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19187v1",
            "title": "Haptic-Enhanced Virtual Reality Simulator for Robot-Assisted Femur\n  Fracture Surgery",
            "updated": "2023-10-29T23:07:51Z",
            "published": "2023-10-29T23:07:51Z",
            "summary": "In this paper, we develop a virtual reality (VR) simulator for the Robossis\nrobot-assisted femur fracture surgery. Due to the steep learning curve for such\nprocedures, a VR simulator is essential for training surgeon(s) and staff. The\nRobossis Surgical Simulator (RSS) is designed to immerse user(s) in a realistic\nsurgery setting using the Robossis system as completed in a previous real-world\ncadaveric procedure. The RSS is designed to interface the Sigma-7 Haptic\nController with the Robossis Surgical Robot (RSR) and the Meta Quest VR\nheadset. Results show that the RSR follows user commands in 6 DOF and prevents\nthe overlapping of bone segments. This development demonstrates a promising\navenue for future implementation of the Robossis system.",
            "author": [
                "Fayez H. Alruwaili",
                "David W. Halim-Banoub",
                "Jessica Rodgers",
                "Adam Dalkilic",
                "Christopher Haydel",
                "Javad Parvizi",
                "Iulian I. Iordachita",
                "Mohammad H. Abedin-Nasab"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19187v1",
                "http://arxiv.org/pdf/2310.19187v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19182v1",
            "title": "Fast Trainable Projection for Robust Fine-Tuning",
            "updated": "2023-10-29T22:52:43Z",
            "published": "2023-10-29T22:52:43Z",
            "summary": "Robust fine-tuning aims to achieve competitive in-distribution (ID)\nperformance while maintaining the out-of-distribution (OOD) robustness of a\npre-trained model when transferring it to a downstream task. Recently,\nprojected gradient descent has been successfully used in robust fine-tuning by\nconstraining the deviation from the initialization of the fine-tuned model\nexplicitly through projection. However, algorithmically, two limitations\nprevent this method from being adopted more widely, scalability and efficiency.\nIn this paper, we propose a new projection-based fine-tuning algorithm, Fast\nTrainable Projection (FTP) for computationally efficient learning of per-layer\nprojection constraints, resulting in an average $35\\%$ speedup on our\nbenchmarks compared to prior works. FTP can be combined with existing\noptimizers such as AdamW, and be used in a plug-and-play fashion. Finally, we\nshow that FTP is a special instance of hyper-optimizers that tune the\nhyper-parameters of optimizers in a learnable manner through nested\ndifferentiation. Empirically, we show superior robustness on OOD datasets,\nincluding domain shifts and natural corruptions, across four different vision\ntasks with five different pre-trained models. Additionally, we demonstrate that\nFTP is broadly applicable and beneficial to other learning scenarios such as\nlow-label and continual learning settings thanks to its easy adaptability. The\ncode will be available at https://github.com/GT-RIPL/FTP.git.",
            "author": [
                "Junjiao Tian",
                "Yen-Cheng Liu",
                "James Seale Smith",
                "Zsolt Kira"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19182v1",
                "http://arxiv.org/pdf/2310.19182v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19179v1",
            "title": "Subjective Quality Evaluation of Point Clouds Using a Head Mounted\n  Display",
            "updated": "2023-10-29T22:45:07Z",
            "published": "2023-10-29T22:45:07Z",
            "summary": "This paper reports on a subjective quality evaluation of static point clouds\nencoded with the MPEG codecs V-PCC and G-PCC, the deep learning-based codec\nRS-DLPCC, and the popular Draco codec. 18 subjects visualized 3D\nrepresentations of distorted point clouds using a Head Mounted Display, which\nallowed for a direct comparison with their reference. The Mean Opinion Scores\n(MOS) obtained in this subjective evaluation were compared with the MOS from\ntwo previous studies, where the same content was visualized either on a 2D\ndisplay or a 3D stereoscopic display, through the Pearson Correlation, Spearman\nRank Order Correlation, Root Mean Square Error, and the Outlier Ratio. The\nresults indicate that the three studies are highly correlated with one another.\nMoreover, a statistical analysis between all evaluations showed no significant\ndifferences between them.",
            "author": [
                "Joao Prazeres",
                "Rafael Rodrigues",
                "Manuela Pereira",
                "Antonio M. G. Pinheiro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19179v1",
                "http://arxiv.org/pdf/2310.19179v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19177v1",
            "title": "Robustifying Language Models with Test-Time Adaptation",
            "updated": "2023-10-29T22:37:54Z",
            "published": "2023-10-29T22:37:54Z",
            "summary": "Large-scale language models achieved state-of-the-art performance over a\nnumber of language tasks. However, they fail on adversarial language examples,\nwhich are sentences optimized to fool the language models but with similar\nsemantic meanings for humans. While prior work focuses on making the language\nmodel robust at training time, retraining for robustness is often unrealistic\nfor large-scale foundation models. Instead, we propose to make the language\nmodels robust at test time. By dynamically adapting the input sentence with\npredictions from masked words, we show that we can reverse many language\nadversarial attacks. Since our approach does not require any training, it works\nfor novel tasks at test time and can adapt to novel adversarial corruptions.\nVisualizations and empirical results on two popular sentence classification\ndatasets demonstrate that our method can repair adversarial language attacks\nover 65% o",
            "author": [
                "Noah Thomas McDermott",
                "Junfeng Yang",
                "Chengzhi Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19177v1",
                "http://arxiv.org/pdf/2310.19177v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19174v1",
            "title": "Predicting recovery following stroke: deep learning, multimodal data and\n  feature selection using explainable AI",
            "updated": "2023-10-29T22:31:20Z",
            "published": "2023-10-29T22:31:20Z",
            "summary": "Machine learning offers great potential for automated prediction of\npost-stroke symptoms and their response to rehabilitation. Major challenges for\nthis endeavour include the very high dimensionality of neuroimaging data, the\nrelatively small size of the datasets available for learning, and how to\neffectively combine neuroimaging and tabular data (e.g. demographic information\nand clinical characteristics). This paper evaluates several solutions based on\ntwo strategies. The first is to use 2D images that summarise MRI scans. The\nsecond is to select key features that improve classification accuracy.\nAdditionally, we introduce the novel approach of training a convolutional\nneural network (CNN) on images that combine regions-of-interest extracted from\nMRIs, with symbolic representations of tabular data. We evaluate a series of\nCNN architectures (both 2D and a 3D) that are trained on different\nrepresentations of MRI and tabular data, to predict whether a composite measure\nof post-stroke spoken picture description ability is in the aphasic or\nnon-aphasic range. MRI and tabular data were acquired from 758 English speaking\nstroke survivors who participated in the PLORAS study. The classification\naccuracy for a baseline logistic regression was 0.678 for lesion size alone,\nrising to 0.757 and 0.813 when initial symptom severity and recovery time were\nsuccessively added. The highest classification accuracy 0.854 was observed when\n8 regions-of-interest was extracted from each MRI scan and combined with lesion\nsize, initial severity and recovery time in a 2D Residual Neural Network.Our\nfindings demonstrate how imaging and tabular data can be combined for high\npost-stroke classification accuracy, even when the dataset is small in machine\nlearning terms. We conclude by proposing how the current models could be\nimproved to achieve even higher levels of accuracy using images from hospital\nscanners.",
            "author": [
                "Adam White",
                "Margarita Saranti",
                "Artur d'Avila Garcez",
                "Thomas M. H. Hope",
                "Cathy J. Price",
                "Howard Bowman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19174v1",
                "http://arxiv.org/pdf/2310.19174v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19168v1",
            "title": "BirdSAT: Cross-View Contrastive Masked Autoencoders for Bird Species\n  Classification and Mapping",
            "updated": "2023-10-29T22:08:00Z",
            "published": "2023-10-29T22:08:00Z",
            "summary": "We propose a metadata-aware self-supervised learning~(SSL)~framework useful\nfor fine-grained classification and ecological mapping of bird species around\nthe world. Our framework unifies two SSL strategies: Contrastive Learning~(CL)\nand Masked Image Modeling~(MIM), while also enriching the embedding space with\nmetadata available with ground-level imagery of birds. We separately train\nuni-modal and cross-modal ViT on a novel cross-view global bird species dataset\ncontaining ground-level imagery, metadata (location, time), and corresponding\nsatellite imagery. We demonstrate that our models learn fine-grained and\ngeographically conditioned features of birds, by evaluating on two downstream\ntasks: fine-grained visual classification~(FGVC) and cross-modal retrieval.\nPre-trained models learned using our framework achieve SotA performance on FGVC\nof iNAT-2021 birds and in transfer learning settings for CUB-200-2011 and\nNABirds datasets. Moreover, the impressive cross-modal retrieval performance of\nour model enables the creation of species distribution maps across any\ngeographic region. The dataset and source code will be released at\nhttps://github.com/mvrl/BirdSAT}.",
            "author": [
                "Srikumar Sastry",
                "Subash Khanal",
                "Aayush Dhakal",
                "Di Huang",
                "Nathan Jacobs"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19168v1",
                "http://arxiv.org/pdf/2310.19168v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19167v1",
            "title": "Rare Event Probability Learning by Normalizing Flows",
            "updated": "2023-10-29T21:59:33Z",
            "published": "2023-10-29T21:59:33Z",
            "summary": "A rare event is defined by a low probability of occurrence. Accurate\nestimation of such small probabilities is of utmost importance across diverse\ndomains. Conventional Monte Carlo methods are inefficient, demanding an\nexorbitant number of samples to achieve reliable estimates. Inspired by the\nexact sampling capabilities of normalizing flows, we revisit this challenge and\npropose normalizing flow assisted importance sampling, termed NOFIS. NOFIS\nfirst learns a sequence of proposal distributions associated with predefined\nnested subset events by minimizing KL divergence losses. Next, it estimates the\nrare event probability by utilizing importance sampling in conjunction with the\nlast proposal. The efficacy of our NOFIS method is substantiated through\ncomprehensive qualitative visualizations, affirming the optimality of the\nlearned proposal distribution, as well as a series of quantitative experiments\nencompassing $10$ distinct test cases, which highlight NOFIS's superiority over\nbaseline approaches.",
            "author": [
                "Zhenggqi Gao",
                "Dinghuai Zhang",
                "Luca Daniel",
                "Duane S. Boning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19167v1",
                "http://arxiv.org/pdf/2310.19167v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19166v1",
            "title": "The Power of Explainability in Forecast-Informed Deep Learning Models\n  for Flood Mitigation",
            "updated": "2023-10-29T21:56:22Z",
            "published": "2023-10-29T21:56:22Z",
            "summary": "Floods can cause horrific harm to life and property. However, they can be\nmitigated or even avoided by the effective use of hydraulic structures such as\ndams, gates, and pumps. By pre-releasing water via these structures in advance\nof extreme weather events, water levels are sufficiently lowered to prevent\nfloods. In this work, we propose FIDLAR, a Forecast Informed Deep Learning\nArchitecture, achieving flood management in watersheds with hydraulic\nstructures in an optimal manner by balancing out flood mitigation and\nunnecessary wastage of water via pre-releases. We perform experiments with\nFIDLAR using data from the South Florida Water Management District, which\nmanages a coastal area that is highly prone to frequent storms and floods.\nResults show that FIDLAR performs better than the current state-of-the-art with\nseveral orders of magnitude speedup and with provably better pre-release\nschedules. The dramatic speedups make it possible for FIDLAR to be used for\nreal-time flood management. The main contribution of this paper is the\neffective use of tools for model explainability, allowing us to understand the\ncontribution of the various environmental factors towards its decisions.",
            "author": [
                "Jimeng Shi",
                "Vitalii Stebliankin",
                "Giri Narasimhan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19166v1",
                "http://arxiv.org/pdf/2310.19166v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19163v1",
            "title": "RAIFLE: Reconstruction Attacks on Interaction-based Federated Learning\n  with Active Data Manipulation",
            "updated": "2023-10-29T21:47:24Z",
            "published": "2023-10-29T21:47:24Z",
            "summary": "Federated learning (FL) has recently emerged as a privacy-preserving approach\nfor machine learning in domains that rely on user interactions, particularly\nrecommender systems (RS) and online learning to rank (OLTR). While there has\nbeen substantial research on the privacy of traditional FL, little attention\nhas been paid to studying the privacy properties of these interaction-based FL\n(IFL) systems. In this work, we show that IFL can introduce unique challenges\nconcerning user privacy, particularly when the central server has knowledge and\ncontrol over the items that users interact with. Specifically, we demonstrate\nthe threat of reconstructing user interactions by presenting RAIFLE, a general\noptimization-based reconstruction attack framework customized for IFL. RAIFLE\nemploys Active Data Manipulation (ADM), a novel attack technique unique to IFL,\nwhere the server actively manipulates the training features of the items to\ninduce adversarial behaviors in the local FL updates. We show that RAIFLE is\nmore impactful than existing FL privacy attacks in the IFL context, and\ndescribe how it can undermine privacy defenses like secure aggregation and\nprivate information retrieval. Based on our findings, we propose and discuss\ncountermeasure guidelines to mitigate our attack in the context of federated\nRS/OLTR specifically and IFL more broadly.",
            "author": [
                "Dzung Pham",
                "Shreyas Kulkarni",
                "Amir Houmansadr"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19163v1",
                "http://arxiv.org/pdf/2310.19163v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19159v1",
            "title": "Transfer Learning in Transformer-Based Demand Forecasting For Home\n  Energy Management System",
            "updated": "2023-10-29T21:19:08Z",
            "published": "2023-10-29T21:19:08Z",
            "summary": "Increasingly, homeowners opt for photovoltaic (PV) systems and/or battery\nstorage to minimize their energy bills and maximize renewable energy usage.\nThis has spurred the development of advanced control algorithms that maximally\nachieve those goals. However, a common challenge faced while developing such\ncontrollers is the unavailability of accurate forecasts of household power\nconsumption, especially for shorter time resolutions (15 minutes) and in a\ndata-efficient manner. In this paper, we analyze how transfer learning can help\nby exploiting data from multiple households to improve a single house's load\nforecasting. Specifically, we train an advanced forecasting model (a temporal\nfusion transformer) using data from multiple different households, and then\nfinetune this global model on a new household with limited data (i.e. only a\nfew days). The obtained models are used for forecasting power consumption of\nthe household for the next 24 hours~(day-ahead) at a time resolution of 15\nminutes, with the intention of using these forecasts in advanced controllers\nsuch as Model Predictive Control. We show the benefit of this transfer learning\nsetup versus solely using the individual new household's data, both in terms of\n(i) forecasting accuracy ($\\sim$15\\% MAE reduction) and (ii) control\nperformance ($\\sim$2\\% energy cost reduction), using real-world household data.",
            "author": [
                "Gargya Gokhale",
                "Jonas Van Gompel",
                "Bert Claessens",
                "Chris Develder"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3600100.3626635",
                "http://arxiv.org/abs/2310.19159v1",
                "http://arxiv.org/pdf/2310.19159v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19155v1",
            "title": "Real-World Implementation of Reinforcement Learning Based Energy\n  Coordination for a Cluster of Households",
            "updated": "2023-10-29T21:10:38Z",
            "published": "2023-10-29T21:10:38Z",
            "summary": "Given its substantial contribution of 40\\% to global power consumption, the\nbuilt environment has received increasing attention to serve as a source of\nflexibility to assist the modern power grid. In that respect, previous research\nmainly focused on energy management of individual buildings. In contrast, in\nthis paper, we focus on aggregated control of a set of residential buildings,\nto provide grid supporting services, that eventually should include ancillary\nservices. In particular, we present a real-life pilot study that studies the\neffectiveness of reinforcement-learning (RL) in coordinating the power\nconsumption of 8 residential buildings to jointly track a target power signal.\nOur RL approach relies solely on observed data from individual households and\ndoes not require any explicit building models or simulators, making it\npractical to implement and easy to scale. We show the feasibility of our\nproposed RL-based coordination strategy in a real-world setting. In a 4-week\ncase study, we demonstrate a hierarchical control system, relying on an\nRL-based ranking system to select which households to activate flex assets\nfrom, and a real-time PI control-based power dispatch mechanism to control the\nselected assets. Our results demonstrate satisfactory power tracking, and the\neffectiveness of the RL-based ranks which are learnt in a purely data-driven\nmanner.",
            "author": [
                "Gargya Gokhale",
                "Niels Tiben",
                "Marie-Sophie Verwee",
                "Manu Lahariya",
                "Bert Claessens",
                "Chris Develder"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3600100.3625681",
                "http://arxiv.org/abs/2310.19155v1",
                "http://arxiv.org/pdf/2310.19155v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19152v2",
            "title": "BERT Lost Patience Won't Be Robust to Adversarial Slowdown",
            "updated": "2023-10-31T04:19:59Z",
            "published": "2023-10-29T21:06:34Z",
            "summary": "In this paper, we systematically evaluate the robustness of multi-exit\nlanguage models against adversarial slowdown. To audit their robustness, we\ndesign a slowdown attack that generates natural adversarial text bypassing\nearly-exit points. We use the resulting WAFFLE attack as a vehicle to conduct a\ncomprehensive evaluation of three multi-exit mechanisms with the GLUE benchmark\nagainst adversarial slowdown. We then show our attack significantly reduces the\ncomputational savings provided by the three methods in both white-box and\nblack-box settings. The more complex a mechanism is, the more vulnerable it is\nto adversarial slowdown. We also perform a linguistic analysis of the perturbed\ntext inputs, identifying common perturbation patterns that our attack\ngenerates, and comparing them with standard adversarial text attacks. Moreover,\nwe show that adversarial training is ineffective in defeating our slowdown\nattack, but input sanitization with a conversational model, e.g., ChatGPT, can\nremove perturbations effectively. This result suggests that future work is\nneeded for developing efficient yet robust multi-exit models. Our code is\navailable at: https://github.com/ztcoalson/WAFFLE",
            "author": [
                "Zachary Coalson",
                "Gabriel Ritter",
                "Rakesh Bobba",
                "Sanghyun Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19152v2",
                "http://arxiv.org/pdf/2310.19152v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19147v1",
            "title": "Optimal Scoring for Dynamic Information Acquisition",
            "updated": "2023-10-29T20:46:05Z",
            "published": "2023-10-29T20:46:05Z",
            "summary": "A principal seeks to learn about a binary state and can do so by enlisting an\nagent to acquire information over time using a Poisson information arrival\ntechnology. The agent learns about this state privately, and his effort choices\nare unobserved by the principal. The principal can reward the agent with a\nprize of fixed value as a function of the agent's sequence of reports and the\nrealized state. We identify conditions that each individually ensure that the\nprincipal cannot do better than by eliciting a single report from the agent\nafter all information has been acquired. We also show that such a static\ncontract is suboptimal under sufficiently strong violations of these\nconditions. We contrast our solution to the case where the agent acquires\ninformation \"all at once;\" notably, the optimal contract in the dynamic\nenvironment may provide strictly positive base rewards to the agent even if his\nprediction about the state is incorrect.",
            "author": [
                "Yingkai Li",
                "Jonathan Libgober"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19147v1",
                "http://arxiv.org/pdf/2310.19147v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19145v1",
            "title": "Learning to Follow Object-Centric Image Editing Instructions Faithfully",
            "updated": "2023-10-29T20:39:11Z",
            "published": "2023-10-29T20:39:11Z",
            "summary": "Natural language instructions are a powerful interface for editing the\noutputs of text-to-image diffusion models. However, several challenges need to\nbe addressed: 1) underspecification (the need to model the implicit meaning of\ninstructions) 2) grounding (the need to localize where the edit has to be\nperformed), 3) faithfulness (the need to preserve the elements of the image not\naffected by the edit instruction). Current approaches focusing on image editing\nwith natural language instructions rely on automatically generated paired data,\nwhich, as shown in our investigation, is noisy and sometimes nonsensical,\nexacerbating the above issues. Building on recent advances in segmentation,\nChain-of-Thought prompting, and visual question answering, we significantly\nimprove the quality of the paired data. In addition, we enhance the supervision\nsignal by highlighting parts of the image that need to be changed by the\ninstruction. The model fine-tuned on the improved data is capable of performing\nfine-grained object-centric edits better than state-of-the-art baselines,\nmitigating the problems outlined above, as shown by automatic and human\nevaluations. Moreover, our model is capable of generalizing to domains unseen\nduring training, such as visual metaphors.",
            "author": [
                "Tuhin Chakrabarty",
                "Kanishk Singh",
                "Arkadiy Saakyan",
                "Smaranda Muresan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19145v1",
                "http://arxiv.org/pdf/2310.19145v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19142v1",
            "title": "MAG-GNN: Reinforcement Learning Boosted Graph Neural Network",
            "updated": "2023-10-29T20:32:21Z",
            "published": "2023-10-29T20:32:21Z",
            "summary": "While Graph Neural Networks (GNNs) recently became powerful tools in graph\nlearning tasks, considerable efforts have been spent on improving GNNs'\nstructural encoding ability. A particular line of work proposed subgraph GNNs\nthat use subgraph information to improve GNNs' expressivity and achieved great\nsuccess. However, such effectivity sacrifices the efficiency of GNNs by\nenumerating all possible subgraphs. In this paper, we analyze the necessity of\ncomplete subgraph enumeration and show that a model can achieve a comparable\nlevel of expressivity by considering a small subset of the subgraphs. We then\nformulate the identification of the optimal subset as a combinatorial\noptimization problem and propose Magnetic Graph Neural Network (MAG-GNN), a\nreinforcement learning (RL) boosted GNN, to solve the problem. Starting with a\ncandidate subgraph set, MAG-GNN employs an RL agent to iteratively update the\nsubgraphs to locate the most expressive set for prediction. This reduces the\nexponential complexity of subgraph enumeration to the constant complexity of a\nsubgraph search algorithm while keeping good expressivity. We conduct extensive\nexperiments on many datasets, showing that MAG-GNN achieves competitive\nperformance to state-of-the-art methods and even outperforms many subgraph\nGNNs. We also demonstrate that MAG-GNN effectively reduces the running time of\nsubgraph GNNs.",
            "author": [
                "Lecheng Kong",
                "Jiarui Feng",
                "Hao Liu",
                "Dacheng Tao",
                "Yixin Chen",
                "Muhan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19142v1",
                "http://arxiv.org/pdf/2310.19142v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19138v1",
            "title": "Backward and Forward Inference in Interacting Independent-Cascade\n  Processes: A Scalable and Convergent Message-Passing Approach",
            "updated": "2023-10-29T20:03:38Z",
            "published": "2023-10-29T20:03:38Z",
            "summary": "We study the problems of estimating the past and future evolutions of two\ndiffusion processes that spread concurrently on a network. Specifically, given\na known network $G=(V, \\overrightarrow{E})$ and a (possibly noisy) snapshot\n$\\mathcal{O}_n$ of its state taken at (a possibly unknown) time $W$, we wish to\ndetermine the posterior distributions of the initial state of the network and\nthe infection times of its nodes. These distributions are useful in finding\nsource nodes of epidemics and rumors -- $\\textit{backward inference}$ -- , and\nestimating the spread of a fixed set of source nodes -- $\\textit{forward\ninference}$.\n  To model the interaction between the two processes, we study an extension of\nthe independent-cascade (IC) model where, when a node gets infected with either\nprocess, its susceptibility to the other one changes. First, we derive the\nexact joint probability of the initial state of the network and the\nobservation-snapshot $\\mathcal{O}_n$. Then, using the machinery of\nfactor-graphs, factor-graph transformations, and the generalized\ndistributive-law, we derive a Belief-Propagation (BP) based algorithm that is\nscalable to large networks and can converge on graphs of arbitrary topology (at\na likely expense in approximation accuracy).",
            "author": [
                "Nouman Khan",
                "Kangle Mu",
                "Mehrdad Moharrami",
                "Vijay Subramanian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19138v1",
                "http://arxiv.org/pdf/2310.19138v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19137v1",
            "title": "Automaton Distillation: Neuro-Symbolic Transfer Learning for Deep\n  Reinforcement Learning",
            "updated": "2023-10-29T19:59:55Z",
            "published": "2023-10-29T19:59:55Z",
            "summary": "Reinforcement learning (RL) is a powerful tool for finding optimal policies\nin sequential decision processes. However, deep RL methods suffer from two\nweaknesses: collecting the amount of agent experience required for practical RL\nproblems is prohibitively expensive, and the learned policies exhibit poor\ngeneralization on tasks outside of the training distribution. To mitigate these\nissues, we introduce automaton distillation, a form of neuro-symbolic transfer\nlearning in which Q-value estimates from a teacher are distilled into a\nlow-dimensional representation in the form of an automaton. We then propose two\nmethods for generating Q-value estimates: static transfer, which reasons over\nan abstract Markov Decision Process constructed based on prior knowledge, and\ndynamic transfer, where symbolic information is extracted from a teacher Deep\nQ-Network (DQN). The resulting Q-value estimates from either method are used to\nbootstrap learning in the target environment via a modified DQN loss function.\nWe list several failure modes of existing automaton-based transfer methods and\ndemonstrate that both static and dynamic automaton distillation decrease the\ntime required to find optimal policies for various decision tasks.",
            "author": [
                "Suraj Singireddy",
                "Andre Beckus",
                "George Atia",
                "Sumit Jha",
                "Alvaro Velasquez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19137v1",
                "http://arxiv.org/pdf/2310.19137v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19128v1",
            "title": "Prediction of local elasto-plastic stress and strain fields in a\n  two-phase composite microstructure using a deep convolutional neural network",
            "updated": "2023-10-29T19:34:53Z",
            "published": "2023-10-29T19:34:53Z",
            "summary": "Design and analysis of inelastic materials requires prediction of physical\nresponses that evolve under loading. Numerical simulation of such behavior\nusing finite element (FE) approaches can call for significant time and\ncomputational effort. To address this challenge, this paper demonstrates a deep\nlearning (DL) framework that is capable of predicting micro-scale\nelasto-plastic strains and stresses in a two-phase medium, at a much greater\nspeed than traditional FE simulations. The proposed framework uses a deep\nconvolutional neural network (CNN), specifically a U-Net architecture with 3D\noperations, to map the composite microstructure to the corresponding stress and\nstrain fields under a predetermined load path. In particular, the model is\napplied to a two-phase fiber reinforced plastic (FRP) composite microstructure\nsubjected to a given loading-unloading path, predicting the corresponding\nstress and strain fields at discrete intermediate load steps. A novel two-step\ntraining approach provides more accurate predictions of stress, by first\ntraining the model to predict strain fields and then using those strain fields\nas input to the model that predicts the stress fields. This efficient\ndata-driven approach enables accurate prediction of physical fields in\ninelastic materials, based solely on microstructure images and loading\ninformation.",
            "author": [
                "Indrashish Saha",
                "Ashwini Gupta",
                "Lori Graham-Brady"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19128v1",
                "http://arxiv.org/pdf/2310.19128v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19126v1",
            "title": "Worst-case Performance of Popular Approximate Nearest Neighbor Search\n  Implementations: Guarantees and Limitations",
            "updated": "2023-10-29T19:25:48Z",
            "published": "2023-10-29T19:25:48Z",
            "summary": "Graph-based approaches to nearest neighbor search are popular and powerful\ntools for handling large datasets in practice, but they have limited\ntheoretical guarantees. We study the worst-case performance of recent\ngraph-based approximate nearest neighbor search algorithms, such as HNSW, NSG\nand DiskANN. For DiskANN, we show that its \"slow preprocessing\" version\nprovably supports approximate nearest neighbor search query with constant\napproximation ratio and poly-logarithmic query time, on data sets with bounded\n\"intrinsic\" dimension. For the other data structure variants studied, including\nDiskANN with \"fast preprocessing\", HNSW and NSG, we present a family of\ninstances on which the empirical query time required to achieve a \"reasonable\"\naccuracy is linear in instance size. For example, for DiskANN, we show that the\nquery procedure can take at least $0.1 n$ steps on instances of size $n$ before\nit encounters any of the $5$ nearest neighbors of the query.",
            "author": [
                "Piotr Indyk",
                "Haike Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19126v1",
                "http://arxiv.org/pdf/2310.19126v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CG",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19124v1",
            "title": "Software engineering for deep learning applications: usage of SWEng and\n  MLops tools in GitHub repositories",
            "updated": "2023-10-29T19:21:33Z",
            "published": "2023-10-29T19:21:33Z",
            "summary": "The rising popularity of deep learning (DL) methods and techniques has\ninvigorated interest in the topic of SE4DL, the application of software\nengineering (SE) practices on deep learning software. Despite the novel\nengineering challenges brought on by the data-driven and non-deterministic\nparadigm of DL software, little work has been invested into developing\nAI-targeted SE tools. On the other hand, tools tackling more general\nengineering issues in DL are actively used and referred to under the umbrella\nterm of ``MLOps tools''. Furthermore, the available literature supports the\nutility of conventional SE tooling in DL software development. Building upon\nprevious MSR research on tool usage in open-source software works, we identify\nconventional and MLOps tools adopted in popular applied DL projects that use\nPython as the main programming language. About 70% of the GitHub repositories\nmined contained at least one conventional SE tool. Software configuration\nmanagement tools are the most adopted, while the opposite applies to\nmaintenance tools. Substantially fewer MLOps tools were in use, with only 9\ntools out of a sample of 80 used in at least one repository. The majority of\nthem were open-source rather than proprietary. One of these tools, TensorBoard,\nwas found to be adopted in about half of the repositories in our study.\nConsequently, the use of conventional SE tooling demonstrates its relevance to\nDL software. Further research is recommended on the adoption of MLOps tooling\nby open-source projects, focusing on the relevance of particular tool types,\nthe development of required tools, as well as ways to promote the use of\nalready available tools.",
            "author": [
                "Evangelia Panourgia",
                "Theodoros Plessas",
                "Diomidis Spinellis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19124v1",
                "http://arxiv.org/pdf/2310.19124v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19117v1",
            "title": "Finding Optimal Training Parameters for Quantum Generative Adversarial\n  Networks",
            "updated": "2023-10-29T19:09:18Z",
            "published": "2023-10-29T19:09:18Z",
            "summary": "Some of the most impressive achievements of contemporary Machine Learning\nsystems comes from the GAN (Generative Adversarial Network) structure. DALLE-2\nand GPT- 3, two of the most impressive and recognizable feats of ML in recent\nyears, were both trained using adversarial techniques. The world of Quantum\nComputing is already well aware of the value of such techniques on near-term\nQuantum Hardware: QGANs provide a highly efficient method for loading classical\ndata into a quantum state. We investigate the performance of these techniques\nin an attempt to determine some of the optimal training parameters in a\nQiskit-style Parameterized Circuit QGAN framework.",
            "author": [
                "C. Strynar",
                "R. M. Rajapakse"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19117v1",
                "http://arxiv.org/pdf/2310.19117v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19112v2",
            "title": "Efficient IoT Inference via Context-Awareness",
            "updated": "2023-12-03T09:15:04Z",
            "published": "2023-10-29T18:57:15Z",
            "summary": "While existing strategies to execute deep learning-based classification on\nlow-power platforms assume the models are trained on all classes of interest,\nthis paper posits that adopting context-awareness i.e. narrowing down a\nclassification task to the current deployment context consisting of only recent\ninference queries can substantially enhance performance in resource-constrained\nenvironments. We propose a new paradigm, CACTUS, for scalable and efficient\ncontext-aware classification where a micro-classifier recognizes a small set of\nclasses relevant to the current context and, when context change happens (e.g.,\na new class comes into the scene), rapidly switches to another suitable\nmicro-classifier. CACTUS features several innovations, including optimizing the\ntraining cost of context-aware classifiers, enabling on-the-fly context-aware\nswitching between classifiers, and balancing context switching costs and\nperformance gains via simple yet effective switching policies. We show that\nCACTUS achieves significant benefits in accuracy, latency, and compute budget\nacross a range of datasets and IoT platforms.",
            "author": [
                "Mohammad Mehdi Rastikerdar",
                "Jin Huang",
                "Shiwei Fang",
                "Hui Guan",
                "Deepak Ganesan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19112v2",
                "http://arxiv.org/pdf/2310.19112v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19836v1",
            "title": "Two-dimensional Parameter Relationships for W UMa-type Systems Revisited",
            "updated": "2023-10-29T18:52:26Z",
            "published": "2023-10-29T18:52:26Z",
            "summary": "Reviewing the empirical and theoretical parameter relationships between\nvarious parameters is a good way to understand more about contact binary\nsystems. In this investigation, two-dimensional (2D) relationships for\nP-M_V(system), P-L_1,2, M_1,2-L_1,2, and q-L_ratio were revisited. The sample\nused is related to 118 contact binary systems with an orbital period shorter\nthan 0.6 days whose absolute parameters were estimated based on the Gaia Data\nRelease 3 (DR3) parallax. We reviewed previous studies on 2D relationships and\nupdated six parameter relationships. Therefore, Markov chain Monte Carlo (MCMC)\nand Machine Learning (ML) methods were used, and the outcomes were compared. We\nselected 22 contact binary systems from eight previous studies for comparison,\nwhich had light curve solutions using spectroscopic data. The results show that\nthe systems are in good agreement with the results of this study.",
            "author": [
                "Atila Poro",
                "Ehsan Paki",
                "Ailar Alizadehsabegh",
                "Mehdi Khodadadilori",
                "Selda Ranjbar Salehian",
                "Mahya Hedayatjoo",
                "Fatemeh Hashemi",
                "Yasaman Dashti",
                "Fatemeh Mohammadizadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19836v1",
                "http://arxiv.org/pdf/2310.19836v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19109v2",
            "title": "Dynamic Task and Weight Prioritization Curriculum Learning for\n  Multimodal Imagery",
            "updated": "2023-11-07T14:59:17Z",
            "published": "2023-10-29T18:46:33Z",
            "summary": "This paper explores post-disaster analytics using multimodal deep learning\nmodels trained with curriculum learning method. Studying post-disaster\nanalytics is important as it plays a crucial role in mitigating the impact of\ndisasters by providing timely and accurate insights into the extent of damage\nand the allocation of resources. We propose a curriculum learning strategy to\nenhance the performance of multimodal deep learning models. Curriculum learning\nemulates the progressive learning sequence in human education by training deep\nlearning models on increasingly complex data. Our primary objective is to\ndevelop a curriculum-trained multimodal deep learning model, with a particular\nfocus on visual question answering (VQA) capable of jointly processing image\nand text data, in conjunction with semantic segmentation for disaster analytics\nusing the\nFloodNet\\footnote{https://github.com/BinaLab/FloodNet-Challenge-EARTHVISION2021}\ndataset. To achieve this, U-Net model is used for semantic segmentation and\nimage encoding. A custom built text classifier is used for visual question\nanswering. Existing curriculum learning methods rely on manually defined\ndifficulty functions. We introduce a novel curriculum learning approach termed\nDynamic Task and Weight Prioritization (DATWEP), which leverages a\ngradient-based method to automatically decide task difficulty during curriculum\nlearning training, thereby eliminating the need for explicit difficulty\ncomputation. The integration of DATWEP into our multimodal model shows\nimprovement on VQA performance. Source code is available at\nhttps://github.com/fualsan/DATWEP.",
            "author": [
                "Huseyin Fuat Alsan",
                "Taner Arsan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19109v2",
                "http://arxiv.org/pdf/2310.19109v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19103v1",
            "title": "Proving Linear Mode Connectivity of Neural Networks via Optimal\n  Transport",
            "updated": "2023-10-29T18:35:05Z",
            "published": "2023-10-29T18:35:05Z",
            "summary": "The energy landscape of high-dimensional non-convex optimization problems is\ncrucial to understanding the effectiveness of modern deep neural network\narchitectures. Recent works have experimentally shown that two different\nsolutions found after two runs of a stochastic training are often connected by\nvery simple continuous paths (e.g., linear) modulo a permutation of the\nweights. In this paper, we provide a framework theoretically explaining this\nempirical observation. Based on convergence rates in Wasserstein distance of\nempirical measures, we show that, with high probability, two wide enough\ntwo-layer neural networks trained with stochastic gradient descent are linearly\nconnected. Additionally, we express upper and lower bounds on the width of each\nlayer of two deep neural networks with independent neuron weights to be\nlinearly connected. Finally, we empirically demonstrate the validity of our\napproach by showing how the dimension of the support of the weight distribution\nof neurons, which dictates Wasserstein convergence rates is correlated with\nlinear mode connectivity.",
            "author": [
                "Damien Ferbach",
                "Baptiste Goujaud",
                "Gauthier Gidel",
                "Aymeric Dieuleveut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19103v1",
                "http://arxiv.org/pdf/2310.19103v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19102v2",
            "title": "Atom: Low-bit Quantization for Efficient and Accurate LLM Serving",
            "updated": "2023-11-07T17:47:11Z",
            "published": "2023-10-29T18:33:05Z",
            "summary": "The growing demand for Large Language Models (LLMs) in applications such as\ncontent generation, intelligent chatbots, and sentiment analysis poses\nconsiderable challenges for LLM service providers. To efficiently use GPU\nresources and boost throughput, batching multiple requests has emerged as a\npopular paradigm; to further speed up batching, LLM quantization techniques\nreduce memory consumption and increase computing capacity. However, prevalent\nquantization schemes (e.g., 8-bit weight-activation quantization) cannot fully\nleverage the capabilities of modern GPUs, such as 4-bit integer operators,\nresulting in sub-optimal performance.\n  To maximize LLMs' serving throughput, we introduce Atom, a low-bit\nquantization method that achieves high throughput improvements with negligible\naccuracy loss. Atom significantly boosts serving throughput by using low-bit\noperators and considerably reduces memory consumption via low-bit quantization.\nIt attains high accuracy by applying a novel mixed-precision and fine-grained\nquantization process. We evaluate Atom on 4-bit weight-activation quantization\nsetups in the serving context. Atom improves end-to-end throughput by up to\n$7.73\\times$ compared to the FP16 and by $2.53\\times$ compared to INT8\nquantization, while maintaining the same latency target.",
            "author": [
                "Yilong Zhao",
                "Chien-Yu Lin",
                "Kan Zhu",
                "Zihao Ye",
                "Lequn Chen",
                "Size Zheng",
                "Luis Ceze",
                "Arvind Krishnamurthy",
                "Tianqi Chen",
                "Baris Kasikci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19102v2",
                "http://arxiv.org/pdf/2310.19102v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19835v1",
            "title": "CrossEAI: Using Explainable AI to generate better bounding boxes for\n  Chest X-ray images",
            "updated": "2023-10-29T17:48:39Z",
            "published": "2023-10-29T17:48:39Z",
            "summary": "Explainability is critical for deep learning applications in healthcare which\nare mandated to provide interpretations to both patients and doctors according\nto legal regulations and responsibilities. Explainable AI methods, such as\nfeature importance using integrated gradients, model approximation using LIME,\nor neuron activation and layer conductance to provide interpretations for\ncertain health risk predictions. In medical imaging diagnosis, disease\nclassification usually achieves high accuracy, but generated bounding boxes\nhave much lower Intersection over Union (IoU). Different methods with\nself-supervised or semi-supervised learning strategies have been proposed, but\nfew improvements have been identified for bounding box generation. Previous\nwork shows that bounding boxes generated by these methods are usually larger\nthan ground truth and contain major non-disease area. This paper utilizes the\nadvantages of post-hoc AI explainable methods to generate bounding boxes for\nchest x-ray image diagnosis. In this work, we propose CrossEAI which combines\nheatmap and gradient map to generate more targeted bounding boxes. By using\nweighted average of Guided Backpropagation and Grad-CAM++, we are able to\ngenerate bounding boxes which are closer to the ground truth. We evaluate our\nmodel on a chest x-ray dataset. The performance has significant improvement\nover the state of the art model with the same setting, with $9\\%$ improvement\nin average of all diseases over all IoU. Moreover, as a model that does not use\nany ground truth bounding box information for training, we achieve same\nperformance in general as the model that uses $80\\%$ of the ground truth\nbounding box information for training",
            "author": [
                "Jinze Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19835v1",
                "http://arxiv.org/pdf/2310.19835v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19091v1",
            "title": "Bridging the Gap: Towards an Expanded Toolkit for ML-Supported\n  Decision-Making in the Public Sector",
            "updated": "2023-10-29T17:44:48Z",
            "published": "2023-10-29T17:44:48Z",
            "summary": "Machine Learning (ML) systems are becoming instrumental in the public sector,\nwith applications spanning areas like criminal justice, social welfare,\nfinancial fraud detection, and public health. While these systems offer great\npotential benefits to institutional decision-making processes, such as improved\nefficiency and reliability, they still face the challenge of aligning intricate\nand nuanced policy objectives with the precise formalization requirements\nnecessitated by ML models. In this paper, we aim to bridge the gap between ML\nand public sector decision-making by presenting a comprehensive overview of key\ntechnical challenges where disjunctions between policy goals and ML models\ncommonly arise. We concentrate on pivotal points of the ML pipeline that\nconnect the model to its operational environment, delving into the significance\nof representative training data and highlighting the importance of a model\nsetup that facilitates effective decision-making. Additionally, we link these\nchallenges with emerging methodological advancements, encompassing causal ML,\ndomain adaptation, uncertainty quantification, and multi-objective\noptimization, illustrating the path forward for harmonizing ML and public\nsector objectives.",
            "author": [
                "Unai Fischer Abaigar",
                "Christoph Kern",
                "Noam Barda",
                "Frauke Kreuter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19091v1",
                "http://arxiv.org/pdf/2310.19091v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "cs.HC",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19089v1",
            "title": "Pushdown Layers: Encoding Recursive Structure in Transformer Language\n  Models",
            "updated": "2023-10-29T17:27:18Z",
            "published": "2023-10-29T17:27:18Z",
            "summary": "Recursion is a prominent feature of human language, and fundamentally\nchallenging for self-attention due to the lack of an explicit recursive-state\ntracking mechanism. Consequently, Transformer language models poorly capture\nlong-tail recursive structure and exhibit sample-inefficient syntactic\ngeneralization. This work introduces Pushdown Layers, a new self-attention\nlayer that models recursive state via a stack tape that tracks estimated depths\nof every token in an incremental parse of the observed prefix. Transformer LMs\nwith Pushdown Layers are syntactic language models that autoregressively and\nsynchronously update this stack tape as they predict new tokens, in turn using\nthe stack tape to softly modulate attention over tokens -- for instance,\nlearning to \"skip\" over closed constituents. When trained on a corpus of\nstrings annotated with silver constituency parses, Transformers equipped with\nPushdown Layers achieve dramatically better and 3-5x more sample-efficient\nsyntactic generalization, while maintaining similar perplexities. Pushdown\nLayers are a drop-in replacement for standard self-attention. We illustrate\nthis by finetuning GPT2-medium with Pushdown Layers on an automatically parsed\nWikiText-103, leading to improvements on several GLUE text classification\ntasks.",
            "author": [
                "Shikhar Murty",
                "Pratyusha Sharma",
                "Jacob Andreas",
                "Christopher D. Manning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19089v1",
                "http://arxiv.org/pdf/2310.19089v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19081v1",
            "title": "Deep Audio Analyzer: a Framework to Industrialize the Research on Audio\n  Forensics",
            "updated": "2023-10-29T17:04:24Z",
            "published": "2023-10-29T17:04:24Z",
            "summary": "Deep Audio Analyzer is an open source speech framework that aims to simplify\nthe research and the development process of neural speech processing pipelines,\nallowing users to conceive, compare and share results in a fast and\nreproducible way. This paper describes the core architecture designed to\nsupport several tasks of common interest in the audio forensics field, showing\npossibility of creating new tasks thus customizing the framework. By means of\nDeep Audio Analyzer, forensics examiners (i.e. from Law Enforcement Agencies)\nand researchers will be able to visualize audio features, easily evaluate\nperformances on pretrained models, to create, export and share new audio\nanalysis workflows by combining deep neural network models with few clicks. One\nof the advantages of this tool is to speed up research and practical\nexperimentation, in the field of audio forensics analysis thus also improving\nexperimental reproducibility by exporting and sharing pipelines. All features\nare developed in modules accessible by the user through a Graphic User\nInterface. Index Terms: Speech Processing, Deep Learning Audio, Deep Learning\nAudio Pipeline creation, Audio Forensics.",
            "author": [
                "Valerio Francesco Puglisi",
                "Oliver Giudice",
                "Sebastiano Battiato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19081v1",
                "http://arxiv.org/pdf/2310.19081v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19080v2",
            "title": "Reward Finetuning for Faster and More Accurate Unsupervised Object\n  Discovery",
            "updated": "2023-11-05T18:57:59Z",
            "published": "2023-10-29T17:03:12Z",
            "summary": "Recent advances in machine learning have shown that Reinforcement Learning\nfrom Human Feedback (RLHF) can improve machine learning models and align them\nwith human preferences. Although very successful for Large Language Models\n(LLMs), these advancements have not had a comparable impact in research for\nautonomous vehicles -- where alignment with human expectations can be\nimperative. In this paper, we propose to adapt similar RL-based methods to\nunsupervised object discovery, i.e. learning to detect objects from LiDAR\npoints without any training labels. Instead of labels, we use simple heuristics\nto mimic human feedback. More explicitly, we combine multiple heuristics into a\nsimple reward function that positively correlates its score with bounding box\naccuracy, i.e., boxes containing objects are scored higher than those without.\nWe start from the detector's own predictions to explore the space and reinforce\nboxes with high rewards through gradient updates. Empirically, we demonstrate\nthat our approach is not only more accurate, but also orders of magnitudes\nfaster to train compared to prior works on object discovery.",
            "author": [
                "Katie Z Luo",
                "Zhenzhen Liu",
                "Xiangyu Chen",
                "Yurong You",
                "Sagie Benaim",
                "Cheng Perng Phoo",
                "Mark Campbell",
                "Wen Sun",
                "Bharath Hariharan",
                "Kilian Q. Weinberger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19080v2",
                "http://arxiv.org/pdf/2310.19080v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19075v1",
            "title": "Bespoke Solvers for Generative Flow Models",
            "updated": "2023-10-29T16:58:31Z",
            "published": "2023-10-29T16:58:31Z",
            "summary": "Diffusion or flow-based models are powerful generative paradigms that are\nnotoriously hard to sample as samples are defined as solutions to\nhigh-dimensional Ordinary or Stochastic Differential Equations (ODEs/SDEs)\nwhich require a large Number of Function Evaluations (NFE) to approximate well.\nExisting methods to alleviate the costly sampling process include model\ndistillation and designing dedicated ODE solvers. However, distillation is\ncostly to train and sometimes can deteriorate quality, while dedicated solvers\nstill require relatively large NFE to produce high quality samples. In this\npaper we introduce \"Bespoke solvers\", a novel framework for constructing custom\nODE solvers tailored to the ODE of a given pre-trained flow model. Our approach\noptimizes an order consistent and parameter-efficient solver (e.g., with 80\nlearnable parameters), is trained for roughly 1% of the GPU time required for\ntraining the pre-trained model, and significantly improves approximation and\ngeneration quality compared to dedicated solvers. For example, a Bespoke solver\nfor a CIFAR10 model produces samples with Fr\\'echet Inception Distance (FID) of\n2.73 with 10 NFE, and gets to 1% of the Ground Truth (GT) FID (2.59) for this\nmodel with only 20 NFE. On the more challenging ImageNet-64$\\times$64, Bespoke\nsamples at 2.2 FID with 10 NFE, and gets within 2% of GT FID (1.71) with 20\nNFE.",
            "author": [
                "Neta Shaul",
                "Juan Perez",
                "Ricky T. Q. Chen",
                "Ali Thabet",
                "Albert Pumarola",
                "Yaron Lipman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19075v1",
                "http://arxiv.org/pdf/2310.19075v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19069v1",
            "title": "Efficient Cluster Selection for Personalized Federated Learning: A\n  Multi-Armed Bandit Approach",
            "updated": "2023-10-29T16:46:50Z",
            "published": "2023-10-29T16:46:50Z",
            "summary": "Federated learning (FL) offers a decentralized training approach for machine\nlearning models, prioritizing data privacy. However, the inherent heterogeneity\nin FL networks, arising from variations in data distribution, size, and device\ncapabilities, poses challenges in user federation. Recognizing this,\nPersonalized Federated Learning (PFL) emphasizes tailoring learning processes\nto individual data profiles. In this paper, we address the complexity of\nclustering users in PFL, especially in dynamic networks, by introducing a\ndynamic Upper Confidence Bound (dUCB) algorithm inspired by the multi-armed\nbandit (MAB) approach. The dUCB algorithm ensures that new users can\neffectively find the best cluster for their data distribution by balancing\nexploration and exploitation. The performance of our algorithm is evaluated in\nvarious cases, showing its effectiveness in handling dynamic federated learning\nscenarios.",
            "author": [
                "Zhou Ni",
                "Morteza Hashemi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19069v1",
                "http://arxiv.org/pdf/2310.19069v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19068v1",
            "title": "Sketching Algorithms for Sparse Dictionary Learning: PTAS and Turnstile\n  Streaming",
            "updated": "2023-10-29T16:46:26Z",
            "published": "2023-10-29T16:46:26Z",
            "summary": "Sketching algorithms have recently proven to be a powerful approach both for\ndesigning low-space streaming algorithms as well as fast polynomial time\napproximation schemes (PTAS). In this work, we develop new techniques to extend\nthe applicability of sketching-based approaches to the sparse dictionary\nlearning and the Euclidean $k$-means clustering problems. In particular, we\ninitiate the study of the challenging setting where the dictionary/clustering\nassignment for each of the $n$ input points must be output, which has\nsurprisingly received little attention in prior work. On the fast algorithms\nfront, we obtain a new approach for designing PTAS's for the $k$-means\nclustering problem, which generalizes to the first PTAS for the sparse\ndictionary learning problem. On the streaming algorithms front, we obtain new\nupper bounds and lower bounds for dictionary learning and $k$-means clustering.\nIn particular, given a design matrix $\\mathbf A\\in\\mathbb R^{n\\times d}$ in a\nturnstile stream, we show an $\\tilde O(nr/\\epsilon^2 + dk/\\epsilon)$ space\nupper bound for $r$-sparse dictionary learning of size $k$, an $\\tilde\nO(n/\\epsilon^2 + dk/\\epsilon)$ space upper bound for $k$-means clustering, as\nwell as an $\\tilde O(n)$ space upper bound for $k$-means clustering on random\norder row insertion streams with a natural \"bounded sensitivity\" assumption. On\nthe lower bounds side, we obtain a general $\\tilde\\Omega(n/\\epsilon +\ndk/\\epsilon)$ lower bound for $k$-means clustering, as well as an\n$\\tilde\\Omega(n/\\epsilon^2)$ lower bound for algorithms which can estimate the\ncost of a single fixed set of candidate centers.",
            "author": [
                "Gregory Dexter",
                "Petros Drineas",
                "David P. Woodruff",
                "Taisuke Yasuda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19068v1",
                "http://arxiv.org/pdf/2310.19068v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19066v1",
            "title": "Gauge-optimal approximate learning for small data classification\n  problems",
            "updated": "2023-10-29T16:46:05Z",
            "published": "2023-10-29T16:46:05Z",
            "summary": "Small data learning problems are characterized by a significant discrepancy\nbetween the limited amount of response variable observations and the large\nfeature space dimension. In this setting, the common learning tools struggle to\nidentify the features important for the classification task from those that\nbear no relevant information, and cannot derive an appropriate learning rule\nwhich allows to discriminate between different classes. As a potential solution\nto this problem, here we exploit the idea of reducing and rotating the feature\nspace in a lower-dimensional gauge and propose the Gauge-Optimal Approximate\nLearning (GOAL) algorithm, which provides an analytically tractable joint\nsolution to the dimension reduction, feature segmentation and classification\nproblems for small data learning problems. We prove that the optimal solution\nof the GOAL algorithm consists in piecewise-linear functions in the Euclidean\nspace, and that it can be approximated through a monotonically convergent\nalgorithm which presents -- under the assumption of a discrete segmentation of\nthe feature space -- a closed-form solution for each optimization substep and\nan overall linear iteration cost scaling. The GOAL algorithm has been compared\nto other state-of-the-art machine learning (ML) tools on both synthetic data\nand challenging real-world applications from climate science and bioinformatics\n(i.e., prediction of the El Nino Southern Oscillation and inference of\nepigenetically-induced gene-activity networks from limited experimental data).\nThe experimental results show that the proposed algorithm outperforms the\nreported best competitors for these problems both in learning performance and\ncomputational cost.",
            "author": [
                "Edoardo Vecchi",
                "Davide Bassetti",
                "Fabio Graziato",
                "Lukas Pospisil",
                "Illia Horenko"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19066v1",
                "http://arxiv.org/pdf/2310.19066v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19065v1",
            "title": "Evaluating LLP Methods: Challenges and Approaches",
            "updated": "2023-10-29T16:45:20Z",
            "published": "2023-10-29T16:45:20Z",
            "summary": "Learning from Label Proportions (LLP) is an established machine learning\nproblem with numerous real-world applications. In this setting, data items are\ngrouped into bags, and the goal is to learn individual item labels, knowing\nonly the features of the data and the proportions of labels in each bag.\nAlthough LLP is a well-established problem, it has several unusual aspects that\ncreate challenges for benchmarking learning methods. Fundamental complications\narise because of the existence of different LLP variants, i.e., dependence\nstructures that can exist between items, labels, and bags. Accordingly, the\nfirst algorithmic challenge is the generation of variant-specific datasets\ncapturing the diversity of dependence structures and bag characteristics. The\nsecond methodological challenge is model selection, i.e., hyperparameter\ntuning; due to the nature of LLP, model selection cannot easily use the\nstandard machine learning paradigm. The final benchmarking challenge consists\nof properly evaluating LLP solution methods across various LLP variants. We\nnote that there is very little consideration of these issues in prior work, and\nthere are no general solutions for these challenges proposed to date. To\naddress these challenges, we develop methods capable of generating LLP datasets\nmeeting the requirements of different variants. We use these methods to\ngenerate a collection of datasets encompassing the spectrum of LLP problem\ncharacteristics, which can be used in future evaluation studies. Additionally,\nwe develop guidelines for benchmarking LLP algorithms, including the model\nselection and evaluation steps. Finally, we illustrate the new methods and\nguidelines by performing an extensive benchmark of a set of well-known LLP\nalgorithms. We show that choosing the best algorithm depends critically on the\nLLP variant and model selection method, demonstrating the need for our proposed\napproach.",
            "author": [
                "Gabriel Franco",
                "Giovanni Comarela",
                "Mark Crovella"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19065v1",
                "http://arxiv.org/pdf/2310.19065v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19064v1",
            "title": "Revisiting the Learnability of Apple Tasting",
            "updated": "2023-10-29T16:37:51Z",
            "published": "2023-10-29T16:37:51Z",
            "summary": "In online binary classification under \\textit{apple tasting} feedback, the\nlearner only observes the true label if it predicts \"1\". First studied by\n\\cite{helmbold2000apple}, we revisit this classical partial-feedback setting\nand study online learnability from a combinatorial perspective. We show that\nthe Littlestone dimension continues to prove a tight quantitative\ncharacterization of apple tasting in the agnostic setting, closing an open\nquestion posed by \\cite{helmbold2000apple}. In addition, we give a new\ncombinatorial parameter, called the Effective width, that tightly quantifies\nthe minimax expected mistakes in the realizable setting. As a corollary, we use\nthe Effective width to establish a \\textit{trichotomy} of the minimax expected\nnumber of mistakes in the realizable setting. In particular, we show that in\nthe realizable setting, the expected number of mistakes for any learner under\napple tasting feedback can only be $\\Theta(1), \\Theta(\\sqrt{T})$, or\n$\\Theta(T)$.",
            "author": [
                "Vinod Raman",
                "Unique Subedi",
                "Ananth Raman",
                "Ambuj Tewari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19064v1",
                "http://arxiv.org/pdf/2310.19064v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19063v1",
            "title": "Feature Aggregation in Joint Sound Classification and Localization\n  Neural Networks",
            "updated": "2023-10-29T16:37:14Z",
            "published": "2023-10-29T16:37:14Z",
            "summary": "This study addresses the application of deep learning techniques in joint\nsound signal classification and localization networks. Current state-of-the-art\nsound source localization deep learning networks lack feature aggregation\nwithin their architecture. Feature aggregation enhances model performance by\nenabling the consolidation of information from different feature scales,\nthereby improving feature robustness and invariance. This is particularly\nimportant in SSL networks, which must differentiate direct and indirect\nacoustic signals. To address this gap, we adapt feature aggregation techniques\nfrom computer vision neural networks to signal detection neural networks.\nAdditionally, we propose the Scale Encoding Network (SEN) for feature\naggregation to encode features from various scales, compressing the network for\nmore computationally efficient aggregation. To evaluate the efficacy of feature\naggregation in SSL networks, we integrated the following computer vision\nfeature aggregation sub-architectures into a SSL control architecture: Path\nAggregation Network (PANet), Weighted Bi-directional Feature Pyramid Network\n(BiFPN), and SEN. These sub-architectures were evaluated using two metrics for\nsignal classification and two metrics for direction-of-arrival regression.\nPANet and BiFPN are established aggregators in computer vision models, while\nthe proposed SEN is a more compact aggregator. The results suggest that models\nincorporating feature aggregations outperformed the control model, the Sound\nEvent Localization and Detection network (SELDnet), in both sound signal\nclassification and localization. The feature aggregation techniques enhance the\nperformance of sound detection neural networks, particularly in\ndirection-of-arrival regression.",
            "author": [
                "Brendan Healy",
                "Patrick McNamee",
                "Zahra Nili Ahmadabadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19063v1",
                "http://arxiv.org/pdf/2310.19063v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19062v2",
            "title": "A multi-modal table tennis robot system",
            "updated": "2023-11-25T15:29:59Z",
            "published": "2023-10-29T16:35:29Z",
            "summary": "In recent years, robotic table tennis has become a popular research challenge\nfor perception and robot control. Here, we present an improved table tennis\nrobot system with high accuracy vision detection and fast robot reaction. Based\non previous work, our system contains a KUKA robot arm with 6 DOF, with four\nframe-based cameras and two additional event-based cameras. We developed a\nnovel calibration approach to calibrate this multimodal perception system. For\ntable tennis, spin estimation is crucial. Therefore, we introduced a novel, and\nmore accurate spin estimation approach. Finally, we show how combining the\noutput of an event-based camera and a Spiking Neural Network (SNN) can be used\nfor accurate ball detection.",
            "author": [
                "Andreas Ziegler",
                "Thomas Gossard",
                "Karl Vetter",
                "Jonas Tebbe",
                "Andreas Zell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19062v2",
                "http://arxiv.org/pdf/2310.19062v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19059v1",
            "title": "Escaping Saddle Points in Heterogeneous Federated Learning via\n  Distributed SGD with Communication Compression",
            "updated": "2023-10-29T16:24:53Z",
            "published": "2023-10-29T16:24:53Z",
            "summary": "We consider the problem of finding second-order stationary points of\nheterogeneous federated learning (FL). Previous works in FL mostly focus on\nfirst-order convergence guarantees, which do not rule out the scenario of\nunstable saddle points. Meanwhile, it is a key bottleneck of FL to achieve\ncommunication efficiency without compensating the learning accuracy, especially\nwhen local data are highly heterogeneous across different clients. Given this,\nwe propose a novel algorithm Power-EF that only communicates compressed\ninformation via a novel error-feedback scheme. To our knowledge, Power-EF is\nthe first distributed and compressed SGD algorithm that provably escapes saddle\npoints in heterogeneous FL without any data homogeneity assumptions. In\nparticular, Power-EF improves to second-order stationary points after visiting\nfirst-order (possibly saddle) points, using additional gradient queries and\ncommunication rounds only of almost the same order required by first-order\nconvergence, and the convergence rate exhibits a linear speedup in terms of the\nnumber of workers. Our theory improves/recovers previous results, while\nextending to much more tolerant settings on the local data. Numerical\nexperiments are provided to complement the theory.",
            "author": [
                "Sijin Chen",
                "Zhize Li",
                "Yuejie Chi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19059v1",
                "http://arxiv.org/pdf/2310.19059v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19057v1",
            "title": "A Unique Training Strategy to Enhance Language Models Capabilities for\n  Health Mention Detection from Social Media Content",
            "updated": "2023-10-29T16:08:33Z",
            "published": "2023-10-29T16:08:33Z",
            "summary": "An ever-increasing amount of social media content requires advanced AI-based\ncomputer programs capable of extracting useful information. Specifically, the\nextraction of health-related content from social media is useful for the\ndevelopment of diverse types of applications including disease spread,\nmortality rate prediction, and finding the impact of diverse types of drugs on\ndiverse types of diseases. Language models are competent in extracting the\nsyntactic and semantics of text. However, they face a hard time extracting\nsimilar patterns from social media texts. The primary reason for this shortfall\nlies in the non-standardized writing style commonly employed by social media\nusers. Following the need for an optimal language model competent in extracting\nuseful patterns from social media text, the key goal of this paper is to train\nlanguage models in such a way that they learn to derive generalized patterns.\nThe key goal is achieved through the incorporation of random weighted\nperturbation and contrastive learning strategies. On top of a unique training\nstrategy, a meta predictor is proposed that reaps the benefits of 5 different\nlanguage models for discriminating posts of social media text into non-health\nand health-related classes. Comprehensive experimentation across 3 public\nbenchmark datasets reveals that the proposed training strategy improves the\nperformance of the language models up to 3.87%, in terms of F1-score, as\ncompared to their performance with traditional training. Furthermore, the\nproposed meta predictor outperforms existing health mention classification\npredictors across all 3 benchmark datasets.",
            "author": [
                "Pervaiz Iqbal Khan",
                "Muhammad Nabeel Asim",
                "Andreas Dengel",
                "Sheraz Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19057v1",
                "http://arxiv.org/pdf/2310.19057v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19055v1",
            "title": "A Survey on Recent Named Entity Recognition and Relation Classification\n  Methods with Focus on Few-Shot Learning Approaches",
            "updated": "2023-10-29T16:02:46Z",
            "published": "2023-10-29T16:02:46Z",
            "summary": "Named entity recognition and relation classification are key stages for\nextracting information from unstructured text. Several natural language\nprocessing applications utilize the two tasks, such as information retrieval,\nknowledge graph construction and completion, question answering and other\ndomain-specific applications, such as biomedical data mining. We present a\nsurvey of recent approaches in the two tasks with focus on few-shot learning\napproaches. Our work compares the main approaches followed in the two\nparadigms. Additionally, we report the latest metric scores in the two tasks\nwith a structured analysis that considers the results in the few-shot learning\nscope.",
            "author": [
                "Sakher Alqaaidi",
                "Elika Bozorgi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19055v1",
                "http://arxiv.org/pdf/2310.19055v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19054v1",
            "title": "Object-centric architectures enable efficient causal representation\n  learning",
            "updated": "2023-10-29T16:01:03Z",
            "published": "2023-10-29T16:01:03Z",
            "summary": "Causal representation learning has showed a variety of settings in which we\ncan disentangle latent variables with identifiability guarantees (up to some\nreasonable equivalence class). Common to all of these approaches is the\nassumption that (1) the latent variables are represented as $d$-dimensional\nvectors, and (2) that the observations are the output of some injective\ngenerative function of these latent variables. While these assumptions appear\nbenign, we show that when the observations are of multiple objects, the\ngenerative function is no longer injective and disentanglement fails in\npractice. We can address this failure by combining recent developments in\nobject-centric learning and causal representation learning. By modifying the\nSlot Attention architecture arXiv:2006.15055, we develop an object-centric\narchitecture that leverages weak supervision from sparse perturbations to\ndisentangle each object's properties. This approach is more data-efficient in\nthe sense that it requires significantly fewer perturbations than a comparable\napproach that encodes to a Euclidean space and we show that this approach\nsuccessfully disentangles the properties of a set of objects in a series of\nsimple image-based disentanglement experiments.",
            "author": [
                "Amin Mansouri",
                "Jason Hartford",
                "Yan Zhang",
                "Yoshua Bengio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19054v1",
                "http://arxiv.org/pdf/2310.19054v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19053v1",
            "title": "Datasets and Benchmarks for Nanophotonic Structure and Parametric Design\n  Simulations",
            "updated": "2023-10-29T15:57:42Z",
            "published": "2023-10-29T15:57:42Z",
            "summary": "Nanophotonic structures have versatile applications including solar cells,\nanti-reflective coatings, electromagnetic interference shielding, optical\nfilters, and light emitting diodes. To design and understand these nanophotonic\nstructures, electrodynamic simulations are essential. These simulations enable\nus to model electromagnetic fields over time and calculate optical properties.\nIn this work, we introduce frameworks and benchmarks to evaluate nanophotonic\nstructures in the context of parametric structure design problems. The\nbenchmarks are instrumental in assessing the performance of optimization\nalgorithms and identifying an optimal structure based on target optical\nproperties. Moreover, we explore the impact of varying grid sizes in\nelectrodynamic simulations, shedding light on how evaluation fidelity can be\nstrategically leveraged in enhancing structure designs.",
            "author": [
                "Jungtaek Kim",
                "Mingxuan Li",
                "Oliver Hinder",
                "Paul W. Leu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19053v1",
                "http://arxiv.org/pdf/2310.19053v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.optics",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19043v1",
            "title": "Differentially Private Permutation Tests: Applications to Kernel Methods",
            "updated": "2023-10-29T15:13:36Z",
            "published": "2023-10-29T15:13:36Z",
            "summary": "Recent years have witnessed growing concerns about the privacy of sensitive\ndata. In response to these concerns, differential privacy has emerged as a\nrigorous framework for privacy protection, gaining widespread recognition in\nboth academic and industrial circles. While substantial progress has been made\nin private data analysis, existing methods often suffer from impracticality or\na significant loss of statistical efficiency. This paper aims to alleviate\nthese concerns in the context of hypothesis testing by introducing\ndifferentially private permutation tests. The proposed framework extends\nclassical non-private permutation tests to private settings, maintaining both\nfinite-sample validity and differential privacy in a rigorous manner. The power\nof the proposed test depends on the choice of a test statistic, and we\nestablish general conditions for consistency and non-asymptotic uniform power.\nTo demonstrate the utility and practicality of our framework, we focus on\nreproducing kernel-based test statistics and introduce differentially private\nkernel tests for two-sample and independence testing: dpMMD and dpHSIC. The\nproposed kernel tests are straightforward to implement, applicable to various\ntypes of data, and attain minimax optimal power across different privacy\nregimes. Our empirical evaluations further highlight their competitive power\nunder various synthetic and real-world scenarios, emphasizing their practical\nvalue. The code is publicly available to facilitate the implementation of our\nframework.",
            "author": [
                "Ilmun Kim",
                "Antonin Schrab"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19043v1",
                "http://arxiv.org/pdf/2310.19043v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.CR",
                "cs.LG",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19041v1",
            "title": "On Linear Separation Capacity of Self-Supervised Representation Learning",
            "updated": "2023-10-29T15:08:35Z",
            "published": "2023-10-29T15:08:35Z",
            "summary": "Recent advances in self-supervised learning have highlighted the efficacy of\ndata augmentation in learning data representation from unlabeled data. Training\na linear model atop these enhanced representations can yield an adept\nclassifier. Despite the remarkable empirical performance, the underlying\nmechanisms that enable data augmentation to unravel nonlinear data structures\ninto linearly separable representations remain elusive. This paper seeks to\nbridge this gap by investigating under what conditions learned representations\ncan linearly separate manifolds when data is drawn from a multi-manifold model.\nOur investigation reveals that data augmentation offers additional information\nbeyond observed data and can thus improve the information-theoretic optimal\nrate of linear separation capacity. In particular, we show that self-supervised\nlearning can linearly separate manifolds with a smaller distance than\nunsupervised learning, underscoring the additional benefits of data\naugmentation. Our theoretical analysis further underscores that the performance\nof downstream linear classifiers primarily hinges on the linear separability of\ndata representations rather than the size of the labeled data set, reaffirming\nthe viability of constructing efficient classifiers with limited labeled data\namid an expansive unlabeled data set.",
            "author": [
                "Shulei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19041v1",
                "http://arxiv.org/pdf/2310.19041v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19039v1",
            "title": "Machine Learning for the identification of phase-transitions in\n  interacting agent-based systems",
            "updated": "2023-10-29T15:07:08Z",
            "published": "2023-10-29T15:07:08Z",
            "summary": "Deriving closed-form, analytical expressions for reduced-order models, and\njudiciously choosing the closures leading to them, has long been the strategy\nof choice for studying phase- and noise-induced transitions for agent-based\nmodels (ABMs). In this paper, we propose a data-driven framework that pinpoints\nphase transitions for an ABM in its mean-field limit, using a smaller number of\nvariables than traditional closed-form models. To this end, we use the manifold\nlearning algorithm Diffusion Maps to identify a parsimonious set of data-driven\nlatent variables, and show that they are in one-to-one correspondence with the\nexpected theoretical order parameter of the ABM. We then utilize a deep\nlearning framework to obtain a conformal reparametrization of the data-driven\ncoordinates that facilitates, in our example, the identification of a single\nparameter-dependent ODE in these coordinates. We identify this ODE through a\nresidual neural network inspired by a numerical integration scheme (forward\nEuler). We then use the identified ODE -- enabled through an odd symmetry\ntransformation -- to construct the bifurcation diagram exhibiting the phase\ntransition.",
            "author": [
                "Nikolaos Evangelou",
                "Dimitrios G. Giovanis",
                "George A. Kevrekidis",
                "Grigorios A. Pavliotis",
                "Ioannis G. Kevrekidis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19039v1",
                "http://arxiv.org/pdf/2310.19039v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19038v1",
            "title": "Boosting Decision-Based Black-Box Adversarial Attack with Gradient\n  Priors",
            "updated": "2023-10-29T15:05:39Z",
            "published": "2023-10-29T15:05:39Z",
            "summary": "Decision-based methods have shown to be effective in black-box adversarial\nattacks, as they can obtain satisfactory performance and only require to access\nthe final model prediction. Gradient estimation is a critical step in black-box\nadversarial attacks, as it will directly affect the query efficiency. Recent\nworks have attempted to utilize gradient priors to facilitate score-based\nmethods to obtain better results. However, these gradient priors still suffer\nfrom the edge gradient discrepancy issue and the successive iteration gradient\ndirection issue, thus are difficult to simply extend to decision-based methods.\nIn this paper, we propose a novel Decision-based Black-box Attack framework\nwith Gradient Priors (DBA-GP), which seamlessly integrates the data-dependent\ngradient prior and time-dependent prior into the gradient estimation procedure.\nFirst, by leveraging the joint bilateral filter to deal with each random\nperturbation, DBA-GP can guarantee that the generated perturbations in edge\nlocations are hardly smoothed, i.e., alleviating the edge gradient discrepancy,\nthus remaining the characteristics of the original image as much as possible.\nSecond, by utilizing a new gradient updating strategy to automatically adjust\nthe successive iteration gradient direction, DBA-GP can accelerate the\nconvergence speed, thus improving the query efficiency. Extensive experiments\nhave demonstrated that the proposed method outperforms other strong baselines\nsignificantly.",
            "author": [
                "Han Liu",
                "Xingshuo Huang",
                "Xiaotong Zhang",
                "Qimai Li",
                "Fenglong Ma",
                "Wei Wang",
                "Hongyang Chen",
                "Hong Yu",
                "Xianchao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19038v1",
                "http://arxiv.org/pdf/2310.19038v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19035v1",
            "title": "Does Invariant Graph Learning via Environment Augmentation Learn\n  Invariance?",
            "updated": "2023-10-29T14:57:37Z",
            "published": "2023-10-29T14:57:37Z",
            "summary": "Invariant graph representation learning aims to learn the invariance among\ndata from different environments for out-of-distribution generalization on\ngraphs. As the graph environment partitions are usually expensive to obtain,\naugmenting the environment information has become the de facto approach.\nHowever, the usefulness of the augmented environment information has never been\nverified. In this work, we find that it is fundamentally impossible to learn\ninvariant graph representations via environment augmentation without additional\nassumptions. Therefore, we develop a set of minimal assumptions, including\nvariation sufficiency and variation consistency, for feasible invariant graph\nlearning. We then propose a new framework Graph invAriant Learning Assistant\n(GALA). GALA incorporates an assistant model that needs to be sensitive to\ngraph environment changes or distribution shifts. The correctness of the proxy\npredictions by the assistant model hence can differentiate the variations in\nspurious subgraphs. We show that extracting the maximally invariant subgraph to\nthe proxy predictions provably identifies the underlying invariant subgraph for\nsuccessful OOD generalization under the established minimal assumptions.\nExtensive experiments on datasets including DrugOOD with various graph\ndistribution shifts confirm the effectiveness of GALA.",
            "author": [
                "Yongqiang Chen",
                "Yatao Bian",
                "Kaiwen Zhou",
                "Binghui Xie",
                "Bo Han",
                "James Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19035v1",
                "http://arxiv.org/pdf/2310.19035v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19030v2",
            "title": "Reinforced Galton-Watson processes II: Large time behaviors",
            "updated": "2023-11-12T17:07:54Z",
            "published": "2023-10-29T14:41:11Z",
            "summary": "Reinforced Galton-Watson processes have been introduced in arxiv:2306.02476\nas population models with non-overlapping generations, such that reproduction\nevents along genealogical lines can be repeated at random. We investigate here\nsome of their sample path properties such as asymptotic growth rates and\nsurvival, for which the effects of reinforcement on the evolution appear quite\nstrikingly.",
            "author": [
                "Jean Bertoin",
                "Bastien Mallein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19030v2",
                "http://arxiv.org/pdf/2310.19030v2"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60J80 (primary) 60J85 (secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19025v2",
            "title": "An Improved Relaxation for Oracle-Efficient Adversarial Contextual\n  Bandits",
            "updated": "2023-11-10T16:14:10Z",
            "published": "2023-10-29T14:31:34Z",
            "summary": "We present an oracle-efficient relaxation for the adversarial contextual\nbandits problem, where the contexts are sequentially drawn i.i.d from a known\ndistribution and the cost sequence is chosen by an online adversary. Our\nalgorithm has a regret bound of\n$O(T^{\\frac{2}{3}}(K\\log(|\\Pi|))^{\\frac{1}{3}})$ and makes at most $O(K)$ calls\nper round to an offline optimization oracle, where $K$ denotes the number of\nactions, $T$ denotes the number of rounds and $\\Pi$ denotes the set of\npolicies. This is the first result to improve the prior best bound of\n$O((TK)^{\\frac{2}{3}}(\\log(|\\Pi|))^{\\frac{1}{3}})$ as obtained by Syrgkanis et\nal. at NeurIPS 2016, and the first to match the original bound of Langford and\nZhang at NeurIPS 2007 which was obtained for the stochastic case.",
            "author": [
                "Kiarash Banihashem",
                "MohammadTaghi Hajiaghayi",
                "Suho Shin",
                "Max Springer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19025v2",
                "http://arxiv.org/pdf/2310.19025v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19022v1",
            "title": "Optimization Landscape of Policy Gradient Methods for Discrete-time\n  Static Output Feedback",
            "updated": "2023-10-29T14:25:57Z",
            "published": "2023-10-29T14:25:57Z",
            "summary": "In recent times, significant advancements have been made in delving into the\noptimization landscape of policy gradient methods for achieving optimal control\nin linear time-invariant (LTI) systems. Compared with state-feedback control,\noutput-feedback control is more prevalent since the underlying state of the\nsystem may not be fully observed in many practical settings. This paper\nanalyzes the optimization landscape inherent to policy gradient methods when\napplied to static output feedback (SOF) control in discrete-time LTI systems\nsubject to quadratic cost. We begin by establishing crucial properties of the\nSOF cost, encompassing coercivity, L-smoothness, and M-Lipschitz continuous\nHessian. Despite the absence of convexity, we leverage these properties to\nderive novel findings regarding convergence (and nearly dimension-free rate) to\nstationary points for three policy gradient methods, including the vanilla\npolicy gradient method, the natural policy gradient method, and the\nGauss-Newton method. Moreover, we provide proof that the vanilla policy\ngradient method exhibits linear convergence towards local minima when\ninitialized near such minima. The paper concludes by presenting numerical\nexamples that validate our theoretical findings. These results not only\ncharacterize the performance of gradient descent for optimizing the SOF problem\nbut also provide insights into the effectiveness of general policy gradient\nmethods within the realm of reinforcement learning.",
            "author": [
                "Jingliang Duan",
                "Jie Li",
                "Xuyang Chen",
                "Kai Zhao",
                "Shengbo Eben Li",
                "Lin Zhao"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TCYB.2023.3323316",
                "http://arxiv.org/abs/2310.19022v1",
                "http://arxiv.org/pdf/2310.19022v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19019v2",
            "title": "TeacherLM: Teaching to Fish Rather Than Giving the Fish, Language\n  Modeling Likewise",
            "updated": "2023-10-31T06:49:13Z",
            "published": "2023-10-29T14:16:54Z",
            "summary": "Large Language Models (LLMs) exhibit impressive reasoning and data\naugmentation capabilities in various NLP tasks. However, what about small\nmodels? In this work, we propose TeacherLM-7.1B, capable of annotating relevant\nfundamentals, chain of thought, and common mistakes for most NLP samples, which\nmakes annotation more than just an answer, thus allowing other models to learn\n\"why\" instead of just \"what\". The TeacherLM-7.1B model achieved a zero-shot\nscore of 52.3 on MMLU, surpassing most models with over 100B parameters. Even\nmore remarkable is its data augmentation ability. Based on TeacherLM-7.1B, we\naugmented 58 NLP datasets and taught various student models with different\nparameters from OPT and BLOOM series in a multi-task setting. The experimental\nresults indicate that the data augmentation provided by TeacherLM has brought\nsignificant benefits. We will release the TeacherLM series of models and\naugmented datasets as open-source.",
            "author": [
                "Nan He",
                "Hanyu Lai",
                "Chenyang Zhao",
                "Zirui Cheng",
                "Junting Pan",
                "Ruoyu Qin",
                "Ruofan Lu",
                "Rui Lu",
                "Yunchen Zhang",
                "Gangming Zhao",
                "Zhaohui Hou",
                "Zhiyuan Huang",
                "Shaoqing Lu",
                "Ding Liang",
                "Mingjie Zhan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19019v2",
                "http://arxiv.org/pdf/2310.19019v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19011v1",
            "title": "Efficient Test-Time Adaptation for Super-Resolution with Second-Order\n  Degradation and Reconstruction",
            "updated": "2023-10-29T13:58:57Z",
            "published": "2023-10-29T13:58:57Z",
            "summary": "Image super-resolution (SR) aims to learn a mapping from low-resolution (LR)\nto high-resolution (HR) using paired HR-LR training images. Conventional SR\nmethods typically gather the paired training data by synthesizing LR images\nfrom HR images using a predetermined degradation model, e.g., Bicubic\ndown-sampling. However, the realistic degradation type of test images may\nmismatch with the training-time degradation type due to the dynamic changes of\nthe real-world scenarios, resulting in inferior-quality SR images. To address\nthis, existing methods attempt to estimate the degradation model and train an\nimage-specific model, which, however, is quite time-consuming and impracticable\nto handle rapidly changing domain shifts. Moreover, these methods largely\nconcentrate on the estimation of one degradation type (e.g., blur degradation),\noverlooking other degradation types like noise and JPEG in real-world test-time\nscenarios, thus limiting their practicality. To tackle these problems, we\npresent an efficient test-time adaptation framework for SR, named SRTTA, which\nis able to quickly adapt SR models to test domains with different/unknown\ndegradation types. Specifically, we design a second-order degradation scheme to\nconstruct paired data based on the degradation type of the test image, which is\npredicted by a pre-trained degradation classifier. Then, we adapt the SR model\nby implementing feature-level reconstruction learning from the initial test\nimage to its second-order degraded counterparts, which helps the SR model\ngenerate plausible HR images. Extensive experiments are conducted on newly\nsynthesized corrupted DIV2K datasets with 8 different degradations and several\nreal-world datasets, demonstrating that our SRTTA framework achieves an\nimpressive improvement over existing methods with satisfying speed. The source\ncode is available at https://github.com/DengZeshuai/SRTTA.",
            "author": [
                "Zeshuai Deng",
                "Zhuokun Chen",
                "Shuaicheng Niu",
                "Thomas H. Li",
                "Bohan Zhuang",
                "Mingkui Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19011v1",
                "http://arxiv.org/pdf/2310.19011v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19007v2",
            "title": "Behavior Alignment via Reward Function Optimization",
            "updated": "2023-10-31T04:58:20Z",
            "published": "2023-10-29T13:45:07Z",
            "summary": "Designing reward functions for efficiently guiding reinforcement learning\n(RL) agents toward specific behaviors is a complex task. This is challenging\nsince it requires the identification of reward structures that are not sparse\nand that avoid inadvertently inducing undesirable behaviors. Naively modifying\nthe reward structure to offer denser and more frequent feedback can lead to\nunintended outcomes and promote behaviors that are not aligned with the\ndesigner's intended goal. Although potential-based reward shaping is often\nsuggested as a remedy, we systematically investigate settings where deploying\nit often significantly impairs performance. To address these issues, we\nintroduce a new framework that uses a bi-level objective to learn\n\\emph{behavior alignment reward functions}. These functions integrate auxiliary\nrewards reflecting a designer's heuristics and domain knowledge with the\nenvironment's primary rewards. Our approach automatically determines the most\neffective way to blend these types of feedback, thereby enhancing robustness\nagainst heuristic reward misspecification. Remarkably, it can also adapt an\nagent's policy optimization process to mitigate suboptimalities resulting from\nlimitations and biases inherent in the underlying RL algorithms. We evaluate\nour method's efficacy on a diverse set of tasks, from small-scale experiments\nto high-dimensional control challenges. We investigate heuristic auxiliary\nrewards of varying quality -- some of which are beneficial and others\ndetrimental to the learning process. Our results show that our framework offers\na robust and principled way to integrate designer-specified heuristics. It not\nonly addresses key shortcomings of existing approaches but also consistently\nleads to high-performing solutions, even when given misaligned or\npoorly-specified auxiliary reward functions.",
            "author": [
                "Dhawal Gupta",
                "Yash Chandak",
                "Scott M. Jordan",
                "Philip S. Thomas",
                "Bruno Castro da Silva"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19007v2",
                "http://arxiv.org/pdf/2310.19007v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19005v2",
            "title": "Kernel-based Joint Multiple Graph Learning and Clustering of Graph\n  Signals",
            "updated": "2023-11-07T11:12:31Z",
            "published": "2023-10-29T13:41:12Z",
            "summary": "Within the context of Graph Signal Processing (GSP), Graph Learning (GL) is\nconcerned with the inference of the graph's underlying structure from nodal\nobservations. However, real-world data often contains diverse information,\nnecessitating the simultaneous clustering and learning of multiple graphs. In\npractical applications, valuable node-specific covariates, represented as\nkernels, have been underutilized by existing graph signal clustering methods.\nIn this letter, we propose a new framework, named Kernel-based joint Multiple\nGL and clustering of graph signals (KMGL), that leverages a multi-convex\noptimization approach. This allows us to integrate node-side information,\nconstruct low-pass filters, and efficiently solve the optimization problem. The\nexperiments demonstrate that KMGL significantly enhances the robustness of GL\nand clustering, particularly in scenarios with high noise levels and a\nsubstantial number of clusters. These findings underscore the potential of KMGL\nfor improving the performance of GSP methods in diverse, real-world\napplications.",
            "author": [
                "Mohamad H. Alizade",
                "Aref Einizade",
                "Jhony H. Giraldo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19005v2",
                "http://arxiv.org/pdf/2310.19005v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19001v1",
            "title": "Uncovering Prototypical Knowledge for Weakly Open-Vocabulary Semantic\n  Segmentation",
            "updated": "2023-10-29T13:18:00Z",
            "published": "2023-10-29T13:18:00Z",
            "summary": "This paper studies the problem of weakly open-vocabulary semantic\nsegmentation (WOVSS), which learns to segment objects of arbitrary classes\nusing mere image-text pairs. Existing works turn to enhance the vanilla vision\ntransformer by introducing explicit grouping recognition, i.e., employing\nseveral group tokens/centroids to cluster the image tokens and perform the\ngroup-text alignment. Nevertheless, these methods suffer from a granularity\ninconsistency regarding the usage of group tokens, which are aligned in the\nall-to-one v.s. one-to-one manners during the training and inference phases,\nrespectively. We argue that this discrepancy arises from the lack of elaborate\nsupervision for each group token. To bridge this granularity gap, this paper\nexplores explicit supervision for the group tokens from the prototypical\nknowledge. To this end, this paper proposes the non-learnable prototypical\nregularization (NPR) where non-learnable prototypes are estimated from source\nfeatures to serve as supervision and enable contrastive matching of the group\ntokens. This regularization encourages the group tokens to segment objects with\nless redundancy and capture more comprehensive semantic regions, leading to\nincreased compactness and richness. Based on NPR, we propose the prototypical\nguidance segmentation network (PGSeg) that incorporates multi-modal\nregularization by leveraging prototypical sources from both images and texts at\ndifferent levels, progressively enhancing the segmentation capability with\ndiverse prototypical patterns. Experimental results show that our proposed\nmethod achieves state-of-the-art performance on several benchmark datasets. The\nsource code is available at https://github.com/Ferenas/PGSeg.",
            "author": [
                "Fei Zhang",
                "Tianfei Zhou",
                "Boyang Li",
                "Hao He",
                "Chaofan Ma",
                "Tianjiao Zhang",
                "Jiangchao Yao",
                "Ya Zhang",
                "Yanfeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19001v1",
                "http://arxiv.org/pdf/2310.19001v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18999v2",
            "title": "DynPoint: Dynamic Neural Point For View Synthesis",
            "updated": "2023-10-31T05:33:03Z",
            "published": "2023-10-29T12:55:53Z",
            "summary": "The introduction of neural radiance fields has greatly improved the\neffectiveness of view synthesis for monocular videos. However, existing\nalgorithms face difficulties when dealing with uncontrolled or lengthy\nscenarios, and require extensive training time specific to each new scenario.\nTo tackle these limitations, we propose DynPoint, an algorithm designed to\nfacilitate the rapid synthesis of novel views for unconstrained monocular\nvideos. Rather than encoding the entirety of the scenario information into a\nlatent representation, DynPoint concentrates on predicting the explicit 3D\ncorrespondence between neighboring frames to realize information aggregation.\nSpecifically, this correspondence prediction is achieved through the estimation\nof consistent depth and scene flow information across frames. Subsequently, the\nacquired correspondence is utilized to aggregate information from multiple\nreference frames to a target frame, by constructing hierarchical neural point\nclouds. The resulting framework enables swift and accurate view synthesis for\ndesired views of target frames. The experimental results obtained demonstrate\nthe considerable acceleration of training time achieved - typically an order of\nmagnitude - by our proposed method while yielding comparable outcomes compared\nto prior approaches. Furthermore, our method exhibits strong robustness in\nhandling long-duration videos without learning a canonical representation of\nvideo content.",
            "author": [
                "Kaichen Zhou",
                "Jia-Xing Zhong",
                "Sangyun Shin",
                "Kai Lu",
                "Yiyuan Yang",
                "Andrew Markham",
                "Niki Trigoni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18999v2",
                "http://arxiv.org/pdf/2310.18999v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18988v1",
            "title": "A U-turn on Double Descent: Rethinking Parameter Counting in Statistical\n  Learning",
            "updated": "2023-10-29T12:05:39Z",
            "published": "2023-10-29T12:05:39Z",
            "summary": "Conventional statistical wisdom established a well-understood relationship\nbetween model complexity and prediction error, typically presented as a\nU-shaped curve reflecting a transition between under- and overfitting regimes.\nHowever, motivated by the success of overparametrized neural networks, recent\ninfluential work has suggested this theory to be generally incomplete,\nintroducing an additional regime that exhibits a second descent in test error\nas the parameter count p grows past sample size n - a phenomenon dubbed double\ndescent. While most attention has naturally been given to the deep-learning\nsetting, double descent was shown to emerge more generally across non-neural\nmodels: known cases include linear regression, trees, and boosting. In this\nwork, we take a closer look at evidence surrounding these more classical\nstatistical machine learning methods and challenge the claim that observed\ncases of double descent truly extend the limits of a traditional U-shaped\ncomplexity-generalization curve therein. We show that once careful\nconsideration is given to what is being plotted on the x-axes of their double\ndescent plots, it becomes apparent that there are implicitly multiple\ncomplexity axes along which the parameter count grows. We demonstrate that the\nsecond descent appears exactly (and only) when and where the transition between\nthese underlying axes occurs, and that its location is thus not inherently tied\nto the interpolation threshold p=n. We then gain further insight by adopting a\nclassical nonparametric statistics perspective. We interpret the investigated\nmethods as smoothers and propose a generalized measure for the effective number\nof parameters they use on unseen examples, using which we find that their\napparent double descent curves indeed fold back into more traditional convex\nshapes - providing a resolution to tensions between double descent and\nstatistical intuition.",
            "author": [
                "Alicia Curth",
                "Alan Jeffares",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18988v1",
                "http://arxiv.org/pdf/2310.18988v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18987v2",
            "title": "Path Analysis for Effective Fault Localization in Deep Neural Networks",
            "updated": "2023-11-06T16:27:58Z",
            "published": "2023-10-29T12:01:15Z",
            "summary": "Deep learning has revolutionized various real-world applications, but the\nquality of Deep Neural Networks (DNNs) remains a concern. DNNs are complex and\nhave millions of parameters, making it difficult to determine their\ncontributions to fulfilling a task. Moreover, the behavior of a DNN is highly\ninfluenced by the data used during training, making it challenging to collect\nenough data to exercise all potential DNN behavior under all possible\nscenarios. This paper proposes NP SBFL method to locate faulty neural pathways\n(NP) using spectrum-based fault localization (SBFL). Our method identifies\ncritical neurons using the layer-wise relevance propagation (LRP) technique and\ndetermines which critical neurons are faulty. Moreover, we propose a\nmulti-stage gradient ascent (MGA), an extension of gradient ascent (GA), to\neffectively activate a sequence of neurons one at a time while maintaining the\nactivation of previous neurons, so we are able to test the reported faulty\npathways. We evaluated the effectiveness of our method, i.e. NP-SBFL-MGA, on\ntwo commonly used datasets, MNIST and CIFAR-10, two baselines DeepFault and\nNP-SBFL-GA, and three suspicious neuron measures, Tarantula, Ochiai, and\nBarinel. The empirical results showed that NP-SBFL-MGA is statistically more\neffective than the baselines at identifying suspicious paths and synthesizing\nadversarial inputs. Particularly, Tarantula on NP-SBFL-MGA had the highest\nfault detection rate at 96.75%, surpassing DeepFault on Ochiai (89.90%) and\nNP-SBFL-GA on Ochiai (60.61%). Our approach also yielded comparable results to\nthe baselines in synthesizing naturalness inputs, and we found a positive\ncorrelation between the coverage of critical paths and the number of failed\ntests in DNN fault localization.",
            "author": [
                "Soroush Hashemifar",
                "Saeed Parsa",
                "Akram Kalaee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18987v2",
                "http://arxiv.org/pdf/2310.18987v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.NE",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18985v1",
            "title": "Predicting RNA-small molecule binding sites by 3D structure",
            "updated": "2023-10-29T11:50:18Z",
            "published": "2023-10-29T11:50:18Z",
            "summary": "The prediction of RNA-small molecule binding sites is crucial for the\ndiscovery of effective drugs. Various computational methods have been developed\nto address this challenge, using information about the structure and sequence\nof RNA. In this study, we introduce CplxCavity, a combination of a new\nalgorithm and a machine learning model specifically designed to predict\nRNA-small molecule binding sites. CplxCavity leverages the 3D structure of RNA\nor RNA complexes to identify surface cavities that have the potential to bind\nwith small molecules. Our results demonstrate that CplxCavity outperforms\nexisting methods by accurately identifying binding sites for small molecules on\nRNA or RNA complexes. The introduction of CplxCavity represents a significant\nadvancement in computational tools for studying RNA-ligand interactions, and\noffers promising prospects for accelerating drug discovery and the development\nof therapies targeting RNA.",
            "author": [
                "Nan Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18985v1",
                "http://arxiv.org/pdf/2310.18985v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18975v1",
            "title": "Blacksmith: Fast Adversarial Training of Vision Transformers via a\n  Mixture of Single-step and Multi-step Methods",
            "updated": "2023-10-29T10:48:44Z",
            "published": "2023-10-29T10:48:44Z",
            "summary": "Despite the remarkable success achieved by deep learning algorithms in\nvarious domains, such as computer vision, they remain vulnerable to adversarial\nperturbations. Adversarial Training (AT) stands out as one of the most\neffective solutions to address this issue; however, single-step AT can lead to\nCatastrophic Overfitting (CO). This scenario occurs when the adversarially\ntrained network suddenly loses robustness against multi-step attacks like\nProjected Gradient Descent (PGD). Although several approaches have been\nproposed to address this problem in Convolutional Neural Networks (CNNs), we\nfound out that they do not perform well when applied to Vision Transformers\n(ViTs). In this paper, we propose Blacksmith, a novel training strategy to\novercome the CO problem, specifically in ViTs. Our approach utilizes either of\nPGD-2 or Fast Gradient Sign Method (FGSM) randomly in a mini-batch during the\nadversarial training of the neural network. This will increase the diversity of\nour training attacks, which could potentially mitigate the CO issue. To manage\nthe increased training time resulting from this combination, we craft the PGD-2\nattack based on only the first half of the layers, while FGSM is applied\nend-to-end. Through our experiments, we demonstrate that our novel method\neffectively prevents CO, achieves PGD-2 level performance, and outperforms\nother existing techniques including N-FGSM, which is the state-of-the-art\nmethod in fast training for CNNs.",
            "author": [
                "Mahdi Salmani",
                "Alireza Dehghanpour Farashah",
                "Mohammad Azizmalayeri",
                "Mahdi Amiri",
                "Navid Eslami",
                "Mohammad Taghi Manzuri",
                "Mohammad Hossein Rohban"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18975v1",
                "http://arxiv.org/pdf/2310.18975v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18974v1",
            "title": "EtiCor: Corpus for Analyzing LLMs for Etiquettes",
            "updated": "2023-10-29T10:47:23Z",
            "published": "2023-10-29T10:47:23Z",
            "summary": "Etiquettes are an essential ingredient of day-to-day interactions among\npeople. Moreover, etiquettes are region-specific, and etiquettes in one region\nmight contradict those in other regions. In this paper, we propose EtiCor, an\nEtiquettes Corpus, having texts about social norms from five different regions\nacross the globe. The corpus provides a test bed for evaluating LLMs for\nknowledge and understanding of region-specific etiquettes. Additionally, we\npropose the task of Etiquette Sensitivity. We experiment with state-of-the-art\nLLMs (Delphi, Falcon40B, and GPT-3.5). Initial results indicate that LLMs,\nmostly fail to understand etiquettes from regions from non-Western world.",
            "author": [
                "Ashutosh Dwivedi",
                "Pradhyumna Lavania",
                "Ashutosh Modi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18974v1",
                "http://arxiv.org/pdf/2310.18974v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18970v1",
            "title": "TRIAGE: Characterizing and auditing training data for improved\n  regression",
            "updated": "2023-10-29T10:31:59Z",
            "published": "2023-10-29T10:31:59Z",
            "summary": "Data quality is crucial for robust machine learning algorithms, with the\nrecent interest in data-centric AI emphasizing the importance of training data\ncharacterization. However, current data characterization methods are largely\nfocused on classification settings, with regression settings largely\nunderstudied. To address this, we introduce TRIAGE, a novel data\ncharacterization framework tailored to regression tasks and compatible with a\nbroad class of regressors. TRIAGE utilizes conformal predictive distributions\nto provide a model-agnostic scoring method, the TRIAGE score. We operationalize\nthe score to analyze individual samples' training dynamics and characterize\nsamples as under-, over-, or well-estimated by the model. We show that TRIAGE's\ncharacterization is consistent and highlight its utility to improve performance\nvia data sculpting/filtering, in multiple regression settings. Additionally,\nbeyond sample level, we show TRIAGE enables new approaches to dataset selection\nand feature acquisition. Overall, TRIAGE highlights the value unlocked by data\ncharacterization in real-world regression applications",
            "author": [
                "Nabeel Seedat",
                "Jonathan Crabb\u00e9",
                "Zhaozhi Qian",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18970v1",
                "http://arxiv.org/pdf/2310.18970v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18969v1",
            "title": "Analyzing Vision Transformers for Image Classification in Class\n  Embedding Space",
            "updated": "2023-10-29T10:25:23Z",
            "published": "2023-10-29T10:25:23Z",
            "summary": "Despite the growing use of transformer models in computer vision, a\nmechanistic understanding of these networks is still needed. This work\nintroduces a method to reverse-engineer Vision Transformers trained to solve\nimage classification tasks. Inspired by previous research in NLP, we\ndemonstrate how the inner representations at any level of the hierarchy can be\nprojected onto the learned class embedding space to uncover how these networks\nbuild categorical representations for their predictions. We use our framework\nto show how image tokens develop class-specific representations that depend on\nattention mechanisms and contextual information, and give insights on how\nself-attention and MLP layers differentially contribute to this categorical\ncomposition. We additionally demonstrate that this method (1) can be used to\ndetermine the parts of an image that would be important for detecting the class\nof interest, and (2) exhibits significant advantages over traditional linear\nprobing approaches. Taken together, our results position our proposed framework\nas a powerful tool for mechanistic interpretability and explainability\nresearch.",
            "author": [
                "Martina G. Vilas",
                "Timothy Schauml\u00f6ffel",
                "Gemma Roig"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18969v1",
                "http://arxiv.org/pdf/2310.18969v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18968v1",
            "title": "A hybrid deep learning method for finite-horizon mean-field game\n  problems",
            "updated": "2023-10-29T10:20:58Z",
            "published": "2023-10-29T10:20:58Z",
            "summary": "This paper develops a new deep learning algorithm to solve a class of\nfinite-horizon mean-field games. The proposed hybrid algorithm uses Markov\nchain approximation method combined with a stochastic approximation-based\niterative deep learning algorithm. Under the framework of finite-horizon\nmean-field games, the induced measure and Monte-Carlo algorithm are adopted to\nestablish the iterative mean-field interaction in MCAM and deep learning,\nrespectively. The Markov chain approximation method plays a key role in\nconstructing the iterative algorithm and estimating an initial value of a\nneural network, whereas stochastic approximation is used to find accurate\nparameters in a bounded region. The convergence of the hybrid algorithm is\nproved; two numerical examples are provided to illustrate the results.",
            "author": [
                "Yu Zhang",
                "Zhuo Jin",
                "Jiaqin Wei",
                "George Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18968v1",
                "http://arxiv.org/pdf/2310.18968v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18966v1",
            "title": "Spacecraft Autonomous Decision-Planning for Collision Avoidance: a\n  Reinforcement Learning Approach",
            "updated": "2023-10-29T10:15:33Z",
            "published": "2023-10-29T10:15:33Z",
            "summary": "The space environment around the Earth is becoming increasingly populated by\nboth active spacecraft and space debris. To avoid potential collision events,\nsignificant improvements in Space Situational Awareness (SSA) activities and\nCollision Avoidance (CA) technologies are allowing the tracking and maneuvering\nof spacecraft with increasing accuracy and reliability. However, these\nprocedures still largely involve a high level of human intervention to make the\nnecessary decisions. For an increasingly complex space environment, this\ndecision-making strategy is not likely to be sustainable. Therefore, it is\nimportant to successfully introduce higher levels of automation for key Space\nTraffic Management (STM) processes to ensure the level of reliability needed\nfor navigating a large number of spacecraft. These processes range from\ncollision risk detection to the identification of the appropriate action to\ntake and the execution of avoidance maneuvers. This work proposes an\nimplementation of autonomous CA decision-making capabilities on spacecraft\nbased on Reinforcement Learning (RL) techniques. A novel methodology based on a\nPartially Observable Markov Decision Process (POMDP) framework is developed to\ntrain the Artificial Intelligence (AI) system on board the spacecraft,\nconsidering epistemic and aleatory uncertainties. The proposed framework\nconsiders imperfect monitoring information about the status of the debris in\norbit and allows the AI system to effectively learn stochastic policies to\nperform accurate Collision Avoidance Maneuvers (CAMs). The objective is to\nsuccessfully delegate the decision-making process for autonomously implementing\na CAM to the spacecraft without human intervention. This approach would allow\nfor a faster response in the decision-making process and for highly\ndecentralized operations.",
            "author": [
                "Nicolas Bourriez",
                "Adrien Loizeau",
                "Adam F. Abdin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18966v1",
                "http://arxiv.org/pdf/2310.18966v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18961v3",
            "title": "AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly\n  Detection",
            "updated": "2023-12-03T07:26:16Z",
            "published": "2023-10-29T10:03:49Z",
            "summary": "Zero-shot anomaly detection (ZSAD) requires detection models trained using\nauxiliary data to detect anomalies without any training sample in a target\ndataset. It is a crucial task when training data is not accessible due to\nvarious concerns, \\eg, data privacy, yet it is challenging since the models\nneed to generalize to anomalies across different domains where the appearance\nof foreground objects, abnormal regions, and background features, such as\ndefects/tumors on different products/organs, can vary significantly. Recently\nlarge pre-trained vision-language models (VLMs), such as CLIP, have\ndemonstrated strong zero-shot recognition ability in various vision tasks,\nincluding anomaly detection. However, their ZSAD performance is weak since the\nVLMs focus more on modeling the class semantics of the foreground objects\nrather than the abnormality/normality in the images. In this paper we introduce\na novel approach, namely AnomalyCLIP, to adapt CLIP for accurate ZSAD across\ndifferent domains. The key insight of AnomalyCLIP is to learn object-agnostic\ntext prompts that capture generic normality and abnormality in an image\nregardless of its foreground objects. This allows our model to focus on the\nabnormal image regions rather than the object semantics, enabling generalized\nnormality and abnormality recognition on diverse types of objects. Large-scale\nexperiments on 17 real-world anomaly detection datasets show that AnomalyCLIP\nachieves superior zero-shot performance of detecting and segmenting anomalies\nin datasets of highly diverse class semantics from various defect inspection\nand medical imaging domains. Code will be made available at\nhttps://github.com/zqhang/AnomalyCLIP.",
            "author": [
                "Qihang Zhou",
                "Guansong Pang",
                "Yu Tian",
                "Shibo He",
                "Jiming Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18961v3",
                "http://arxiv.org/pdf/2310.18961v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18956v1",
            "title": "End-to-End Autoregressive Retrieval via Bootstrapping for Smart Reply\n  Systems",
            "updated": "2023-10-29T09:56:17Z",
            "published": "2023-10-29T09:56:17Z",
            "summary": "Reply suggestion systems represent a staple component of many instant\nmessaging and email systems. However, the requirement to produce sets of\nreplies, rather than individual replies, makes the task poorly suited for\nout-of-the-box retrieval architectures, which only consider individual\nmessage-reply similarity. As a result, these system often rely on additional\npost-processing modules to diversify the outputs. However, these approaches are\nultimately bottlenecked by the performance of the initial retriever, which in\npractice struggles to present a sufficiently diverse range of options to the\ndownstream diversification module, leading to the suggestions being less\nrelevant to the user. In this paper, we consider a novel approach that\nradically simplifies this pipeline through an autoregressive text-to-text\nretrieval model, that learns the smart reply task end-to-end from a dataset of\n(message, reply set) pairs obtained via bootstrapping. Empirical results show\nthis method consistently outperforms a range of state-of-the-art baselines\nacross three datasets, corresponding to a 5.1%-17.9% improvement in relevance,\nand a 0.5%-63.1% improvement in diversity compared to the best baseline\napproach. We make our code publicly available.",
            "author": [
                "Benjamin Towle",
                "Ke Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18956v1",
                "http://arxiv.org/pdf/2310.18956v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18955v1",
            "title": "Playing in the Dark: No-regret Learning with Adversarial Constraints",
            "updated": "2023-10-29T09:55:41Z",
            "published": "2023-10-29T09:55:41Z",
            "summary": "We study a generalization of the classic Online Convex Optimization (OCO)\nframework by considering additional long-term adversarial constraints.\nSpecifically, after an online policy decides its action on a round, in addition\nto a convex cost function, the adversary also reveals a set of $k$ convex\nconstraints. The cost and the constraint functions could change arbitrarily\nwith time, and no information about the future functions is assumed to be\navailable. In this paper, we propose a meta-policy that simultaneously achieves\na sublinear cumulative constraint violation and a sublinear regret. This is\nachieved via a black box reduction of the constrained problem to the standard\nOCO problem for a recursively constructed sequence of surrogate cost functions.\nWe show that optimal performance bounds can be achieved by solving the\nsurrogate problem using any adaptive OCO policy enjoying a standard\ndata-dependent regret bound. A new Lyapunov-based proof technique is presented\nthat reveals a connection between regret and certain sequential inequalities\nthrough a novel decomposition result. We conclude the paper by highlighting\napplications to online multi-task learning and network control problems.",
            "author": [
                "Abhishek Sinha",
                "Rahul Vaze"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18955v1",
                "http://arxiv.org/pdf/2310.18955v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18954v1",
            "title": "Mask Propagation for Efficient Video Semantic Segmentation",
            "updated": "2023-10-29T09:55:28Z",
            "published": "2023-10-29T09:55:28Z",
            "summary": "Video Semantic Segmentation (VSS) involves assigning a semantic label to each\npixel in a video sequence. Prior work in this field has demonstrated promising\nresults by extending image semantic segmentation models to exploit temporal\nrelationships across video frames; however, these approaches often incur\nsignificant computational costs. In this paper, we propose an efficient mask\npropagation framework for VSS, called MPVSS. Our approach first employs a\nstrong query-based image segmentor on sparse key frames to generate accurate\nbinary masks and class predictions. We then design a flow estimation module\nutilizing the learned queries to generate a set of segment-aware flow maps,\neach associated with a mask prediction from the key frame. Finally, the\nmask-flow pairs are warped to serve as the mask predictions for the non-key\nframes. By reusing predictions from key frames, we circumvent the need to\nprocess a large volume of video frames individually with resource-intensive\nsegmentors, alleviating temporal redundancy and significantly reducing\ncomputational costs. Extensive experiments on VSPW and Cityscapes demonstrate\nthat our mask propagation framework achieves SOTA accuracy and efficiency\ntrade-offs. For instance, our best model with Swin-L backbone outperforms the\nSOTA MRCFA using MiT-B5 by 4.0% mIoU, requiring only 26% FLOPs on the VSPW\ndataset. Moreover, our framework reduces up to 4x FLOPs compared to the\nper-frame Mask2Former baseline with only up to 2% mIoU degradation on the\nCityscapes validation set. Code is available at\nhttps://github.com/ziplab/MPVSS.",
            "author": [
                "Yuetian Weng",
                "Mingfei Han",
                "Haoyu He",
                "Mingjie Li",
                "Lina Yao",
                "Xiaojun Chang",
                "Bohan Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18954v1",
                "http://arxiv.org/pdf/2310.18954v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18953v1",
            "title": "TIC-TAC: A Framework To Learn And Evaluate Your Covariance",
            "updated": "2023-10-29T09:54:03Z",
            "published": "2023-10-29T09:54:03Z",
            "summary": "We study the problem of unsupervised heteroscedastic covariance estimation,\nwhere the goal is to learn the multivariate target distribution $\\mathcal{N}(y,\n\\Sigma_y | x )$ given an observation $x$. This problem is particularly\nchallenging as $\\Sigma_{y}$ varies for different samples (heteroscedastic) and\nno annotation for the covariance is available (unsupervised). Typically,\nstate-of-the-art methods predict the mean $f_{\\theta}(x)$ and covariance\n$\\textrm{Cov}(f_{\\theta}(x))$ of the target distribution through two neural\nnetworks trained using the negative log-likelihood. This raises two questions:\n(1) Does the predicted covariance truly capture the randomness of the predicted\nmean? (2) In the absence of ground-truth annotation, how can we quantify the\nperformance of covariance estimation? We address (1) by deriving TIC: Taylor\nInduced Covariance, which captures the randomness of the multivariate\n$f_{\\theta}(x)$ by incorporating its gradient and curvature around $x$ through\nthe second order Taylor polynomial. Furthermore, we tackle (2) by introducing\nTAC: Task Agnostic Correlations, a metric which leverages conditioning of the\nnormal distribution to evaluate the covariance. We verify the effectiveness of\nTIC through multiple experiments spanning synthetic (univariate, multivariate)\nand real-world datasets (UCI Regression, LSP, and MPII Human Pose Estimation).\nOur experiments show that TIC outperforms state-of-the-art in accurately\nlearning the covariance, as quantified through TAC.",
            "author": [
                "Megh Shukla",
                "Mathieu Salzmann",
                "Alexandre Alahi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18953v1",
                "http://arxiv.org/pdf/2310.18953v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18949v1",
            "title": "Customize StyleGAN with One Hand Sketch",
            "updated": "2023-10-29T09:32:33Z",
            "published": "2023-10-29T09:32:33Z",
            "summary": "Generating images from human sketches typically requires dedicated networks\ntrained from scratch. In contrast, the emergence of the pre-trained\nVision-Language models (e.g., CLIP) has propelled generative applications based\non controlling the output imagery of existing StyleGAN models with text inputs\nor reference images. Parallelly, our work proposes a framework to control\nStyleGAN imagery with a single user sketch. In particular, we learn a\nconditional distribution in the latent space of a pre-trained StyleGAN model\nvia energy-based learning and propose two novel energy functions leveraging\nCLIP for cross-domain semantic supervision. Once trained, our model can\ngenerate multi-modal images semantically aligned with the input sketch.\nQuantitative evaluations on synthesized datasets have shown that our approach\nimproves significantly from previous methods in the one-shot regime. The\nsuperiority of our method is further underscored when experimenting with a wide\nrange of human sketches of diverse styles and poses. Surprisingly, our models\noutperform the previous baseline regarding both the range of sketch inputs and\nimage qualities despite operating with a stricter setting: with no extra\ntraining data and single sketch input.",
            "author": [
                "Shaocong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18949v1",
                "http://arxiv.org/pdf/2310.18949v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18948v2",
            "title": "Building a Safer Maritime Environment Through Multi-Path Long-Term\n  Vessel Trajectory Forecasting",
            "updated": "2023-11-18T10:51:15Z",
            "published": "2023-10-29T09:15:22Z",
            "summary": "Maritime transportation is paramount in achieving global economic growth,\nentailing concurrent ecological obligations in sustainability and safeguarding\nendangered marine species, most notably preserving large whale populations. In\nthis regard, the Automatic Identification System (AIS) data plays a significant\nrole by offering real-time streaming data on vessel movement, allowing enhanced\ntraffic monitoring. This study explores using AIS data to prevent\nvessel-to-whale collisions by forecasting long-term vessel trajectories from\nengineered AIS data sequences. For such a task, we have developed an\nencoder-decoder model architecture using Bidirectional Long Short-Term Memory\nNetworks (Bi-LSTM) to predict the next 12 hours of vessel trajectories using 1\nto 3 hours of AIS data as input. We feed the model with probabilistic features\nengineered from historical AIS data that refer to each trajectory's potential\nroute and destination. The model then predicts the vessel's trajectory,\nconsidering these additional features by leveraging convolutional layers for\nspatial feature learning and a position-aware attention mechanism that\nincreases the importance of recent timesteps of a sequence during temporal\nfeature learning. The probabilistic features have an F1 Score of approximately\n85% and 75% for each feature type, respectively, demonstrating their\neffectiveness in augmenting information to the neural network. We test our\nmodel on the Gulf of St. Lawrence, a region known to be the habitat of North\nAtlantic Right Whales (NARW). Our model achieved a high R2 score of over 98%\nusing various techniques and features. It stands out among other approaches as\nit can make complex decisions during turnings and path selection. Our study\nhighlights the potential of data engineering and trajectory forecasting models\nfor marine life species preservation.",
            "author": [
                "Gabriel Spadon",
                "Jay Kumar",
                "Matthew Smith",
                "Sarah Vela",
                "Romina Gehrmann",
                "Derek Eden",
                "Joshua van Berkel",
                "Amilcar Soares",
                "Ronan Fablet",
                "Ronald Pelot",
                "Stan Matwin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18948v2",
                "http://arxiv.org/pdf/2310.18948v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DM",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18940v2",
            "title": "Language Agents with Reinforcement Learning for Strategic Play in the\n  Werewolf Game",
            "updated": "2023-12-04T07:34:35Z",
            "published": "2023-10-29T09:02:57Z",
            "summary": "Agents built with large language models (LLMs) have recently achieved great\nadvancements. However, most of the efforts focus on single-agent or cooperative\nsettings, leaving more general multi-agent environments underexplored. We\npropose a new framework powered by reinforcement learning (RL) to develop\nstrategic language agents, i.e., LLM-based agents with strategic thinking\nability, for a popular language game, Werewolf. Werewolf is a social deduction\ngame with hidden roles that involves both cooperation and competition and\nemphasizes deceptive communication and diverse gameplay. Our agent tackles this\ngame by first using LLMs to reason about potential deceptions and generate a\nset of strategically diverse actions. Then an RL policy, which selects an\naction from the candidates, is learned by population-based training to enhance\nthe agents' decision-making ability. By combining LLMs with the RL policy, our\nagent produces a variety of emergent strategies, achieves the highest win rate\nagainst other LLM-based agents, and stays robust against adversarial human\nplayers in the Werewolf game.",
            "author": [
                "Zelai Xu",
                "Chao Yu",
                "Fei Fang",
                "Yu Wang",
                "Yi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18940v2",
                "http://arxiv.org/pdf/2310.18940v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18938v1",
            "title": "Machine Learning Algorithms to Predict Chess960 Result and Develop\n  Opening Themes",
            "updated": "2023-10-29T08:54:26Z",
            "published": "2023-10-29T08:54:26Z",
            "summary": "This work focuses on the analysis of Chess 960, also known as Fischer Random\nChess, a variant of traditional chess where the starting positions of the\npieces are randomized. The study aims to predict the game outcome using machine\nlearning techniques and develop an opening theme for each starting position.\nThe first part of the analysis utilizes machine learning models to predict the\ngame result based on certain moves in each position. The methodology involves\nsegregating raw data from .pgn files into usable formats and creating datasets\ncomprising approximately 500 games for each starting position. Three machine\nlearning algorithms -- KNN Clustering, Random Forest, and Gradient Boosted\nTrees -- have been used to predict the game outcome. To establish an opening\ntheme, the board is divided into five regions: center, white kingside, white\nqueenside, black kingside, and black queenside. The data from games played by\ntop engines in all 960 positions is used to track the movement of pieces in the\nopening. By analysing the change in the number of pieces in each region at\nspecific moves, the report predicts the region towards which the game is\ndeveloping. These models provide valuable insights into predicting game\noutcomes and understanding the opening theme in Chess 960.",
            "author": [
                "Shreyan Deo",
                "Nishchal Dwivedi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18938v1",
                "http://arxiv.org/pdf/2310.18938v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18937v1",
            "title": "The Utility of \"Even if...\" Semifactual Explanation to Optimise Positive\n  Outcomes",
            "updated": "2023-10-29T08:52:23Z",
            "published": "2023-10-29T08:52:23Z",
            "summary": "When users receive either a positive or negative outcome from an automated\nsystem, Explainable AI (XAI) has almost exclusively focused on how to mutate\nnegative outcomes into positive ones by crossing a decision boundary using\ncounterfactuals (e.g., \\textit{\"If you earn 2k more, we will accept your loan\napplication\"}). Here, we instead focus on \\textit{positive} outcomes, and take\nthe novel step of using XAI to optimise them (e.g., \\textit{\"Even if you wish\nto half your down-payment, we will still accept your loan application\"}).\nExplanations such as these that employ \"even if...\" reasoning, and do not cross\na decision boundary, are known as semifactuals. To instantiate semifactuals in\nthis context, we introduce the concept of \\textit{Gain} (i.e., how much a user\nstands to benefit from the explanation), and consider the first causal\nformalisation of semifactuals. Tests on benchmark datasets show our algorithms\nare better at maximising gain compared to prior work, and that causality is\nimportant in the process. Most importantly however, a user study supports our\nmain hypothesis by showing people find semifactual explanations more useful\nthan counterfactuals when they receive the positive outcome of a loan\nacceptance.",
            "author": [
                "Eoin M. Kenny",
                "Weipeng Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18937v1",
                "http://arxiv.org/pdf/2310.18937v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18936v2",
            "title": "Adversarial Examples Are Not Real Features",
            "updated": "2023-11-20T12:35:55Z",
            "published": "2023-10-29T08:50:27Z",
            "summary": "The existence of adversarial examples has been a mystery for years and\nattracted much interest. A well-known theory by \\citet{ilyas2019adversarial}\nexplains adversarial vulnerability from a data perspective by showing that one\ncan extract non-robust features from adversarial examples and these features\nalone are useful for classification. However, the explanation remains quite\ncounter-intuitive since non-robust features are mostly noise features to\nhumans. In this paper, we re-examine the theory from a larger context by\nincorporating multiple learning paradigms. Notably, we find that contrary to\ntheir good usefulness under supervised learning, non-robust features attain\npoor usefulness when transferred to other self-supervised learning paradigms,\nsuch as contrastive learning, masked image modeling, and diffusion models. It\nreveals that non-robust features are not really as useful as robust or natural\nfeatures that enjoy good transferability between these paradigms. Meanwhile,\nfor robustness, we also show that naturally trained encoders from robust\nfeatures are largely non-robust under AutoAttack. Our cross-paradigm\nexamination suggests that the non-robust features are not really useful but\nmore like paradigm-wise shortcuts, and robust features alone might be\ninsufficient to attain reliable model robustness. Code is available at\n\\url{https://github.com/PKU-ML/AdvNotRealFeatures}.",
            "author": [
                "Ang Li",
                "Yifei Wang",
                "Yiwen Guo",
                "Yisen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18936v2",
                "http://arxiv.org/pdf/2310.18936v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18935v1",
            "title": "Implicit Bias of Gradient Descent for Two-layer ReLU and Leaky ReLU\n  Networks on Nearly-orthogonal Data",
            "updated": "2023-10-29T08:47:48Z",
            "published": "2023-10-29T08:47:48Z",
            "summary": "The implicit bias towards solutions with favorable properties is believed to\nbe a key reason why neural networks trained by gradient-based optimization can\ngeneralize well. While the implicit bias of gradient flow has been widely\nstudied for homogeneous neural networks (including ReLU and leaky ReLU\nnetworks), the implicit bias of gradient descent is currently only understood\nfor smooth neural networks. Therefore, implicit bias in non-smooth neural\nnetworks trained by gradient descent remains an open question. In this paper,\nwe aim to answer this question by studying the implicit bias of gradient\ndescent for training two-layer fully connected (leaky) ReLU neural networks. We\nshowed that when the training data are nearly-orthogonal, for leaky ReLU\nactivation function, gradient descent will find a network with a stable rank\nthat converges to $1$, whereas for ReLU activation function, gradient descent\nwill find a neural network with a stable rank that is upper bounded by a\nconstant. Additionally, we show that gradient descent will find a neural\nnetwork such that all the training data points have the same normalized margin\nasymptotically. Experiments on both synthetic and real data backup our\ntheoretical findings.",
            "author": [
                "Yiwen Kou",
                "Zixiang Chen",
                "Quanquan Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18935v1",
                "http://arxiv.org/pdf/2310.18935v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18933v1",
            "title": "Label Poisoning is All You Need",
            "updated": "2023-10-29T08:03:45Z",
            "published": "2023-10-29T08:03:45Z",
            "summary": "In a backdoor attack, an adversary injects corrupted data into a model's\ntraining dataset in order to gain control over its predictions on images with a\nspecific attacker-defined trigger. A typical corrupted training example\nrequires altering both the image, by applying the trigger, and the label.\nModels trained on clean images, therefore, were considered safe from backdoor\nattacks. However, in some common machine learning scenarios, the training\nlabels are provided by potentially malicious third-parties. This includes\ncrowd-sourced annotation and knowledge distillation. We, hence, investigate a\nfundamental question: can we launch a successful backdoor attack by only\ncorrupting labels? We introduce a novel approach to design label-only backdoor\nattacks, which we call FLIP, and demonstrate its strengths on three datasets\n(CIFAR-10, CIFAR-100, and Tiny-ImageNet) and four architectures (ResNet-32,\nResNet-18, VGG-19, and Vision Transformer). With only 2% of CIFAR-10 labels\ncorrupted, FLIP achieves a near-perfect attack success rate of 99.4% while\nsuffering only a 1.8% drop in the clean test accuracy. Our approach builds upon\nthe recent advances in trajectory matching, originally introduced for dataset\ndistillation.",
            "author": [
                "Rishi D. Jha",
                "Jonathan Hayase",
                "Sewoong Oh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18933v1",
                "http://arxiv.org/pdf/2310.18933v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18932v1",
            "title": "Self Attention with Temporal Prior: Can We Learn More from Arrow of\n  Time?",
            "updated": "2023-10-29T08:00:13Z",
            "published": "2023-10-29T08:00:13Z",
            "summary": "Many of diverse phenomena in nature often inherently encode both short and\nlong term temporal dependencies, short term dependencies especially resulting\nfrom the direction of flow of time. In this respect, we discovered experimental\nevidences suggesting that {\\it interrelations} of these events are higher for\ncloser time stamps. However, to be able for attention based models to learn\nthese regularities in short term dependencies, it requires large amounts of\ndata which are often infeasible. This is due to the reason that, while they are\ngood at learning piece wised temporal dependencies, attention based models lack\nstructures that encode biases in time series. As a resolution, we propose a\nsimple and efficient method that enables attention layers to better encode\nshort term temporal bias of these data sets by applying learnable, adaptive\nkernels directly to the attention matrices. For the experiments, we chose\nvarious prediction tasks using Electronic Health Records (EHR) data sets since\nthey are great examples that have underlying long and short term temporal\ndependencies. The results of our experiments show exceptional classification\nresults compared to best performing models on most of the task and data sets.",
            "author": [
                "Kyung Geun Kim",
                "Byeong Tak Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18932v1",
                "http://arxiv.org/pdf/2310.18932v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18930v1",
            "title": "Retrofitting Light-weight Language Models for Emotions using Supervised\n  Contrastive Learning",
            "updated": "2023-10-29T07:43:34Z",
            "published": "2023-10-29T07:43:34Z",
            "summary": "We present a novel retrofitting method to induce emotion aspects into\npre-trained language models (PLMs) such as BERT and RoBERTa. Our method updates\npre-trained network weights using contrastive learning so that the text\nfragments exhibiting similar emotions are encoded nearby in the representation\nspace, and the fragments with different emotion content are pushed apart. While\ndoing so, it also ensures that the linguistic knowledge already present in PLMs\nis not inadvertently perturbed. The language models retrofitted by our method,\ni.e., BERTEmo and RoBERTaEmo, produce emotion-aware text representations, as\nevaluated through different clustering and retrieval metrics. For the\ndownstream tasks on sentiment analysis and sarcasm detection, they perform\nbetter than their pre-trained counterparts (about 1% improvement in F1-score)\nand other existing approaches. Additionally, a more significant boost in\nperformance is observed for the retrofitted models over pre-trained ones in\nfew-shot learning setting.",
            "author": [
                "Sapan Shah",
                "Sreedhar Reddy",
                "Pushpak Bhattacharyya"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18930v1",
                "http://arxiv.org/pdf/2310.18930v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18928v1",
            "title": "A transfer learning approach with convolutional neural network for Face\n  Mask Detection",
            "updated": "2023-10-29T07:38:33Z",
            "published": "2023-10-29T07:38:33Z",
            "summary": "Due to the epidemic of the coronavirus (Covid-19) and its rapid spread around\nthe world, the world has faced an enormous crisis. To prevent the spread of the\ncoronavirus, the World Health Organization (WHO) has introduced the use of\nmasks and keeping social distance as the best preventive method. So, developing\nan automatic monitoring system for detecting facemasks in some crowded places\nis essential. To do this, we propose a mask recognition system based on\ntransfer learning and Inception v3 architecture. In the proposed method, two\ndatasets are used simultaneously for training including the Simulated Mask Face\nDataset (SMFD) and MaskedFace-Net (MFN) This paper tries to increase the\naccuracy of the proposed system by optimally setting hyper-parameters and\naccurately designing the fully connected layers. The main advantage of the\nproposed method is that in addition to masked and unmasked faces, it can also\ndetect cases of incorrect use of mask. Therefore, the proposed method\nclassifies the input face images into three categories. Experimental results\nshow the high accuracy and efficiency of the proposed method; so, this method\nhas achieved an accuracy of 99.47% and 99.33% in training and test data\nrespectively",
            "author": [
                "Abolfazl Younesi",
                "Reza Afrouzian",
                "Yousef Seyfari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18928v1",
                "http://arxiv.org/pdf/2310.18928v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18926v1",
            "title": "CHAIN: Exploring Global-Local Spatio-Temporal Information for Improved\n  Self-Supervised Video Hashing",
            "updated": "2023-10-29T07:36:11Z",
            "published": "2023-10-29T07:36:11Z",
            "summary": "Compressing videos into binary codes can improve retrieval speed and reduce\nstorage overhead. However, learning accurate hash codes for video retrieval can\nbe challenging due to high local redundancy and complex global dependencies\nbetween video frames, especially in the absence of labels. Existing\nself-supervised video hashing methods have been effective in designing\nexpressive temporal encoders, but have not fully utilized the temporal dynamics\nand spatial appearance of videos due to less challenging and unreliable\nlearning tasks. To address these challenges, we begin by utilizing the\ncontrastive learning task to capture global spatio-temporal information of\nvideos for hashing. With the aid of our designed augmentation strategies, which\nfocus on spatial and temporal variations to create positive pairs, the learning\nframework can generate hash codes that are invariant to motion, scale, and\nviewpoint. Furthermore, we incorporate two collaborative learning tasks, i.e.,\nframe order verification and scene change regularization, to capture local\nspatio-temporal details within video frames, thereby enhancing the perception\nof temporal structure and the modeling of spatio-temporal relationships. Our\nproposed Contrastive Hashing with Global-Local Spatio-temporal Information\n(CHAIN) outperforms state-of-the-art self-supervised video hashing methods on\nfour video benchmark datasets. Our codes will be released.",
            "author": [
                "Rukai Wei",
                "Yu Liu",
                "Jingkuan Song",
                "Heng Cui",
                "Yanzhao Xie",
                "Ke Zhou"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3613440",
                "http://arxiv.org/abs/2310.18926v1",
                "http://arxiv.org/pdf/2310.18926v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18924v1",
            "title": "Remaining Useful Life Prediction of Lithium-ion Batteries using\n  Spatio-temporal Multimodal Attention Networks",
            "updated": "2023-10-29T07:32:32Z",
            "published": "2023-10-29T07:32:32Z",
            "summary": "Lithium-ion batteries are widely used in various applications, including\nelectric vehicles and renewable energy storage. The prediction of the remaining\nuseful life (RUL) of batteries is crucial for ensuring reliable and efficient\noperation, as well as reducing maintenance costs. However, determining the life\ncycle of batteries in real-world scenarios is challenging, and existing methods\nhave limitations in predicting the number of cycles iteratively. In addition,\nexisting works often oversimplify the datasets, neglecting important features\nof the batteries such as temperature, internal resistance, and material type.\nTo address these limitations, this paper proposes a two-stage remaining useful\nlife prediction scheme for Lithium-ion batteries using a spatio-temporal\nmultimodal attention network (ST-MAN). The proposed model is designed to\niteratively predict the number of cycles required for the battery to reach the\nend of its useful life, based on available data. The proposed ST-MAN is to\ncapture the complex spatio-temporal dependencies in the battery data, including\nthe features that are often neglected in existing works. Experimental results\ndemonstrate that the proposed ST-MAN model outperforms existing CNN and\nLSTM-based methods, achieving state-of-the-art performance in predicting the\nremaining useful life of Li-ion batteries. The proposed method has the\npotential to improve the reliability and efficiency of battery operations and\nis applicable in various industries, including automotive and renewable energy.",
            "author": [
                "Sungho Suh",
                "Dhruv Aditya Mittal",
                "Hymalai Bello",
                "Bo Zhou",
                "Mayank Shekhar Jha",
                "Paul Lukowicz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18924v1",
                "http://arxiv.org/pdf/2310.18924v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18921v1",
            "title": "QWID: Quantized Weed Identification Deep neural network",
            "updated": "2023-10-29T06:43:01Z",
            "published": "2023-10-29T06:43:01Z",
            "summary": "In this paper, we present an efficient solution for weed classification in\nagriculture. We focus on optimizing model performance at inference while\nrespecting the constraints of the agricultural domain. We propose a Quantized\nDeep Neural Network model that classifies a dataset of 9 weed classes using\n8-bit integer (int8) quantization, a departure from standard 32-bit floating\npoint (fp32) models. Recognizing the hardware resource limitations in\nagriculture, our model balances model size, inference time, and accuracy,\naligning with practical requirements. We evaluate the approach on ResNet-50 and\nInceptionV3 architectures, comparing their performance against their int8\nquantized versions. Transfer learning and fine-tuning are applied using the\nDeepWeeds dataset. The results show staggering model size and inference time\nreductions while maintaining accuracy in real-world production scenarios like\nDesktop, Mobile and Raspberry Pi. Our work sheds light on a promising direction\nfor efficient AI in agriculture, holding potential for broader applications.\n  Code: https://github.com/parikshit14/QNN-for-weed",
            "author": [
                "Parikshit Singh Rathore"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18921v1",
                "http://arxiv.org/pdf/2310.18921v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18919v2",
            "title": "Posterior Sampling with Delayed Feedback for Reinforcement Learning with\n  Linear Function Approximation",
            "updated": "2023-11-04T01:38:40Z",
            "published": "2023-10-29T06:12:43Z",
            "summary": "Recent studies in reinforcement learning (RL) have made significant progress\nby leveraging function approximation to alleviate the sample complexity hurdle\nfor better performance. Despite the success, existing provably efficient\nalgorithms typically rely on the accessibility of immediate feedback upon\ntaking actions. The failure to account for the impact of delay in observations\ncan significantly degrade the performance of real-world systems due to the\nregret blow-up. In this work, we tackle the challenge of delayed feedback in RL\nwith linear function approximation by employing posterior sampling, which has\nbeen shown to empirically outperform the popular UCB algorithms in a wide range\nof regimes. We first introduce Delayed-PSVI, an optimistic value-based\nalgorithm that effectively explores the value function space via noise\nperturbation with posterior sampling. We provide the first analysis for\nposterior sampling algorithms with delayed feedback in RL and show our\nalgorithm achieves $\\widetilde{O}(\\sqrt{d^3H^3 T} + d^2H^2 E[\\tau])$ worst-case\nregret in the presence of unknown stochastic delays. Here $E[\\tau]$ is the\nexpected delay. To further improve its computational efficiency and to expand\nits applicability in high-dimensional RL problems, we incorporate a\ngradient-based approximate sampling scheme via Langevin dynamics for\nDelayed-LPSVI, which maintains the same order-optimal regret guarantee with\n$\\widetilde{O}(dHK)$ computational cost. Empirical evaluations are performed to\ndemonstrate the statistical and computational efficacy of our algorithms.",
            "author": [
                "Nikki Lijing Kuang",
                "Ming Yin",
                "Mengdi Wang",
                "Yu-Xiang Wang",
                "Yi-An Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18919v2",
                "http://arxiv.org/pdf/2310.18919v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18918v1",
            "title": "Hyperbolic Graph Neural Networks at Scale: A Meta Learning Approach",
            "updated": "2023-10-29T06:11:49Z",
            "published": "2023-10-29T06:11:49Z",
            "summary": "The progress in hyperbolic neural networks (HNNs) research is hindered by\ntheir absence of inductive bias mechanisms, which are essential for\ngeneralizing to new tasks and facilitating scalable learning over large\ndatasets. In this paper, we aim to alleviate these issues by learning\ngeneralizable inductive biases from the nodes' local subgraph and transfer them\nfor faster learning over new subgraphs with a disjoint set of nodes, edges, and\nlabels in a few-shot setting. We introduce a novel method, Hyperbolic GRAph\nMeta Learner (H-GRAM), that, for the tasks of node classification and link\nprediction, learns transferable information from a set of support local\nsubgraphs in the form of hyperbolic meta gradients and label hyperbolic\nprotonets to enable faster learning over a query set of new tasks dealing with\ndisjoint subgraphs. Furthermore, we show that an extension of our meta-learning\nframework also mitigates the scalability challenges seen in HNNs faced by\nexisting approaches. Our comparative analysis shows that H-GRAM effectively\nlearns and transfers information in multiple challenging few-shot settings\ncompared to other state-of-the-art baselines. Additionally, we demonstrate\nthat, unlike standard HNNs, our approach is able to scale over large graph\ndatasets and improve performance over its Euclidean counterparts.",
            "author": [
                "Nurendra Choudhary",
                "Nikhil Rao",
                "Chandan K. Reddy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18918v1",
                "http://arxiv.org/pdf/2310.18918v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18913v1",
            "title": "Debiasing Algorithm through Model Adaptation",
            "updated": "2023-10-29T05:50:03Z",
            "published": "2023-10-29T05:50:03Z",
            "summary": "Large language models are becoming the go-to solution for various language\ntasks. However, with growing capacity, models are prone to rely on spurious\ncorrelations stemming from biases and stereotypes present in the training data.\nThis work proposes a novel method for detecting and mitigating gender bias in\nlanguage models. We perform causal analysis to identify problematic model\ncomponents and discover that mid-upper feed-forward layers are most prone to\nconvey biases. Based on the analysis results, we adapt the model by multiplying\nthese layers by a linear projection. Our titular method, DAMA, significantly\ndecreases bias as measured by diverse metrics while maintaining the model's\nperformance on downstream tasks. We release code for our method and models,\nwhich retrain LLaMA's state-of-the-art performance while being significantly\nless biased.",
            "author": [
                "Tomasz Limisiewicz",
                "David Mare\u010dek",
                "Tom\u00e1\u0161 Musil"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18913v1",
                "http://arxiv.org/pdf/2310.18913v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18912v1",
            "title": "Sentence Bag Graph Formulation for Biomedical Distant Supervision\n  Relation Extraction",
            "updated": "2023-10-29T05:48:04Z",
            "published": "2023-10-29T05:48:04Z",
            "summary": "We introduce a novel graph-based framework for alleviating key challenges in\ndistantly-supervised relation extraction and demonstrate its effectiveness in\nthe challenging and important domain of biomedical data. Specifically, we\npropose a graph view of sentence bags referring to an entity pair, which\nenables message-passing based aggregation of information related to the entity\npair over the sentence bag. The proposed framework alleviates the common\nproblem of noisy labeling in distantly supervised relation extraction and also\neffectively incorporates inter-dependencies between sentences within a bag.\nExtensive experiments on two large-scale biomedical relation datasets and the\nwidely utilized NYT dataset demonstrate that our proposed framework\nsignificantly outperforms the state-of-the-art methods for biomedical distant\nsupervision relation extraction while also providing excellent performance for\nrelation extraction in the general text mining domain.",
            "author": [
                "Hao Zhang",
                "Yang Liu",
                "Xiaoyan Liu",
                "Tianming Liang",
                "Gaurav Sharma",
                "Liang Xue",
                "Maozu Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18912v1",
                "http://arxiv.org/pdf/2310.18912v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18910v1",
            "title": "InstanT: Semi-supervised Learning with Instance-dependent Thresholds",
            "updated": "2023-10-29T05:31:43Z",
            "published": "2023-10-29T05:31:43Z",
            "summary": "Semi-supervised learning (SSL) has been a fundamental challenge in machine\nlearning for decades. The primary family of SSL algorithms, known as\npseudo-labeling, involves assigning pseudo-labels to confident unlabeled\ninstances and incorporating them into the training set. Therefore, the\nselection criteria of confident instances are crucial to the success of SSL.\nRecently, there has been growing interest in the development of SSL methods\nthat use dynamic or adaptive thresholds. Yet, these methods typically apply the\nsame threshold to all samples, or use class-dependent thresholds for instances\nbelonging to a certain class, while neglecting instance-level information. In\nthis paper, we propose the study of instance-dependent thresholds, which has\nthe highest degree of freedom compared with existing methods. Specifically, we\ndevise a novel instance-dependent threshold function for all unlabeled\ninstances by utilizing their instance-level ambiguity and the\ninstance-dependent error rates of pseudo-labels, so instances that are more\nlikely to have incorrect pseudo-labels will have higher thresholds.\nFurthermore, we demonstrate that our instance-dependent threshold function\nprovides a bounded probabilistic guarantee for the correctness of the\npseudo-labels it assigns.",
            "author": [
                "Muyang Li",
                "Runze Wu",
                "Haoyu Liu",
                "Jun Yu",
                "Xun Yang",
                "Bo Han",
                "Tongliang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18910v1",
                "http://arxiv.org/pdf/2310.18910v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18908v1",
            "title": "Estimating the Rate-Distortion Function by Wasserstein Gradient Descent",
            "updated": "2023-10-29T05:29:59Z",
            "published": "2023-10-29T05:29:59Z",
            "summary": "In the theory of lossy compression, the rate-distortion (R-D) function $R(D)$\ndescribes how much a data source can be compressed (in bit-rate) at any given\nlevel of fidelity (distortion). Obtaining $R(D)$ for a given data source\nestablishes the fundamental performance limit for all compression algorithms.\nWe propose a new method to estimate $R(D)$ from the perspective of optimal\ntransport. Unlike the classic Blahut--Arimoto algorithm which fixes the support\nof the reproduction distribution in advance, our Wasserstein gradient descent\nalgorithm learns the support of the optimal reproduction distribution by moving\nparticles. We prove its local convergence and analyze the sample complexity of\nour R-D estimator based on a connection to entropic optimal transport.\nExperimentally, we obtain comparable or tighter bounds than state-of-the-art\nneural network methods on low-rate sources while requiring considerably less\ntuning and computation effort. We also highlight a connection to\nmaximum-likelihood deconvolution and introduce a new class of sources that can\nbe used as test cases with known solutions to the R-D problem.",
            "author": [
                "Yibo Yang",
                "Stephan Eckstein",
                "Marcel Nutz",
                "Stephan Mandt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18908v1",
                "http://arxiv.org/pdf/2310.18908v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "math.IT",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18907v1",
            "title": "Topological, or Non-topological? A Deep Learning Based Prediction",
            "updated": "2023-10-29T05:29:49Z",
            "published": "2023-10-29T05:29:49Z",
            "summary": "Prediction and discovery of new materials with desired properties are at the\nforefront of quantum science and technology research. A major bottleneck in\nthis field is the computational resources and time complexity related to\nfinding new materials from ab initio calculations. In this work, an effective\nand robust deep learning-based model is proposed by incorporating persistent\nhomology and graph neural network which offers an accuracy of 91.4% and an F1\nscore of 88.5% in classifying topological vs. non-topological materials,\noutperforming the other state-of-the-art classifier models. The incorporation\nof the graph neural network encodes the underlying relation between the atoms\ninto the model based on their own crystalline structures and thus proved to be\nan effective method to represent and process non-euclidean data like molecules\nwith a relatively shallow network. The persistent homology pipeline in the\nsuggested neural network is capable of integrating the atom-specific\ntopological information into the deep learning model, increasing robustness,\nand gain in performance. It is believed that the presented work will be an\nefficacious tool for predicting the topological class and therefore enable the\nhigh-throughput search for novel materials in this field.",
            "author": [
                "Ashiqur Rasul",
                "Md Shafayat Hossain",
                "Ankan Ghosh Dastider",
                "Himaddri Roy",
                "M. Zahid Hasan",
                "Quazi D. M. Khosru"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18907v1",
                "http://arxiv.org/pdf/2310.18907v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18904v1",
            "title": "Identifiable Contrastive Learning with Automatic Feature Importance\n  Discovery",
            "updated": "2023-10-29T05:20:54Z",
            "published": "2023-10-29T05:20:54Z",
            "summary": "Existing contrastive learning methods rely on pairwise sample contrast\n$z_x^\\top z_{x'}$ to learn data representations, but the learned features often\nlack clear interpretability from a human perspective. Theoretically, it lacks\nfeature identifiability and different initialization may lead to totally\ndifferent features. In this paper, we study a new method named tri-factor\ncontrastive learning (triCL) that involves a 3-factor contrast in the form of\n$z_x^\\top S z_{x'}$, where $S=\\text{diag}(s_1,\\dots,s_k)$ is a learnable\ndiagonal matrix that automatically captures the importance of each feature. We\nshow that by this simple extension, triCL can not only obtain identifiable\nfeatures that eliminate randomness but also obtain more interpretable features\nthat are ordered according to the importance matrix $S$. We show that features\nwith high importance have nice interpretability by capturing common classwise\nfeatures, and obtain superior performance when evaluated for image retrieval\nusing a few features. The proposed triCL objective is general and can be\napplied to different contrastive learning methods like SimCLR and CLIP. We\nbelieve that it is a better alternative to existing 2-factor contrastive\nlearning by improving its identifiability and interpretability with minimal\noverhead. Code is available at\nhttps://github.com/PKU-ML/Tri-factor-Contrastive-Learning.",
            "author": [
                "Qi Zhang",
                "Yifei Wang",
                "Yisen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18904v1",
                "http://arxiv.org/pdf/2310.18904v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18899v1",
            "title": "Multi-task deep learning for large-scale building detail extraction from\n  high-resolution satellite imagery",
            "updated": "2023-10-29T04:43:30Z",
            "published": "2023-10-29T04:43:30Z",
            "summary": "Understanding urban dynamics and promoting sustainable development requires\ncomprehensive insights about buildings. While geospatial artificial\nintelligence has advanced the extraction of such details from Earth\nobservational data, existing methods often suffer from computational\ninefficiencies and inconsistencies when compiling unified building-related\ndatasets for practical applications. To bridge this gap, we introduce the\nMulti-task Building Refiner (MT-BR), an adaptable neural network tailored for\nsimultaneous extraction of spatial and attributional building details from\nhigh-resolution satellite imagery, exemplified by building rooftops, urban\nfunctional types, and roof architectural types. Notably, MT-BR can be\nfine-tuned to incorporate additional building details, extending its\napplicability. For large-scale applications, we devise a novel spatial sampling\nscheme that strategically selects limited but representative image samples.\nThis process optimizes both the spatial distribution of samples and the urban\nenvironmental characteristics they contain, thus enhancing extraction\neffectiveness while curtailing data preparation expenditures. We further\nenhance MT-BR's predictive performance and generalization capabilities through\nthe integration of advanced augmentation techniques. Our quantitative results\nhighlight the efficacy of the proposed methods. Specifically, networks trained\nwith datasets curated via our sampling method demonstrate improved predictive\naccuracy relative to those using alternative sampling approaches, with no\nalterations to network architecture. Moreover, MT-BR consistently outperforms\nother state-of-the-art methods in extracting building details across various\nmetrics. The real-world practicality is also demonstrated in an application\nacross Shanghai, generating a unified dataset that encompasses both the spatial\nand attributional details of buildings.",
            "author": [
                "Zhen Qian",
                "Min Chen",
                "Zhuo Sun",
                "Fan Zhang",
                "Qingsong Xu",
                "Jinzhao Guo",
                "Zhiwei Xie",
                "Zhixin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18899v1",
                "http://arxiv.org/pdf/2310.18899v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18897v1",
            "title": "Learning Subgrid-Scale Models in Discontinuous Galerkin Methods with\n  Neural Ordinary Differential Equations for Compressible Navier--Stokes\n  Equations",
            "updated": "2023-10-29T04:26:23Z",
            "published": "2023-10-29T04:26:23Z",
            "summary": "The growing computing power over the years has enabled simulations to become\nmore complex and accurate. However, high-fidelity simulations, while immensely\nvaluable for scientific discovery and problem solving, come with significant\ncomputational demands. As a result, it is common to run a low-fidelity model\nwith a subgrid-scale model to reduce the computational cost, but selecting the\nappropriate subgrid-scale models and tuning them are challenging. We propose a\nnovel method for learning the subgrid-scale model effects when simulating\npartial differential equations using neural ordinary differential equations in\nthe context of discontinuous Galerkin (DG) spatial discretization. Our approach\nlearns the missing scales of the low-order DG solver at a continuous level and\nhence improves the accuracy of the low-order DG approximations as well as\naccelerates the filtered high-order DG simulations with a certain degree of\nprecision. We demonstrate the performance of our approach through\nmultidimensional Taylor--Green vortex examples at different Reynolds numbers\nand times, which cover laminar, transitional, and turbulent regimes. The\nproposed method not only reconstructs the subgrid-scale from the low-order\n(1st-order) approximation but also speeds up the filtered high-order DG\n(6th-order) simulation by two orders of magnitude.",
            "author": [
                "Shinhoo Kang",
                "Emil M. Constantinescu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18897v1",
                "http://arxiv.org/pdf/2310.18897v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.LG",
                "cs.NA",
                "math.NA",
                "68T07, 76M10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18894v1",
            "title": "Emergence of Shape Bias in Convolutional Neural Networks through\n  Activation Sparsity",
            "updated": "2023-10-29T04:07:52Z",
            "published": "2023-10-29T04:07:52Z",
            "summary": "Current deep-learning models for object recognition are known to be heavily\nbiased toward texture. In contrast, human visual systems are known to be biased\ntoward shape and structure. What could be the design principles in human visual\nsystems that led to this difference? How could we introduce more shape bias\ninto the deep learning models? In this paper, we report that sparse coding, a\nubiquitous principle in the brain, can in itself introduce shape bias into the\nnetwork. We found that enforcing the sparse coding constraint using a\nnon-differential Top-K operation can lead to the emergence of structural\nencoding in neurons in convolutional neural networks, resulting in a smooth\ndecomposition of objects into parts and subparts and endowing the networks with\nshape bias. We demonstrated this emergence of shape bias and its functional\nbenefits for different network structures with various datasets. For object\nrecognition convolutional neural networks, the shape bias leads to greater\nrobustness against style and pattern change distraction. For the image\nsynthesis generative adversary networks, the emerged shape bias leads to more\ncoherent and decomposable structures in the synthesized images. Ablation\nstudies suggest that sparse codes tend to encode structures, whereas the more\ndistributed codes tend to favor texture. Our code is host at the github\nrepository: \\url{https://github.com/Crazy-Jack/nips2023_shape_vs_texture}",
            "author": [
                "Tianqin Li",
                "Ziqi Wen",
                "Yangfan Li",
                "Tai Sing Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18894v1",
                "http://arxiv.org/pdf/2310.18894v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18893v1",
            "title": "Ever Evolving Evaluator (EV3): Towards Flexible and Reliable\n  Meta-Optimization for Knowledge Distillation",
            "updated": "2023-10-29T04:00:33Z",
            "published": "2023-10-29T04:00:33Z",
            "summary": "We introduce EV3, a novel meta-optimization framework designed to efficiently\ntrain scalable machine learning models through an intuitive\nexplore-assess-adapt protocol. In each iteration of EV3, we explore various\nmodel parameter updates, assess them using pertinent evaluation methods, and\nadapt the model based on the optimal updates and previous progress history. EV3\noffers substantial flexibility without imposing stringent constraints like\ndifferentiability on the key objectives relevant to the tasks of interest.\nMoreover, this protocol welcomes updates with biased gradients and allows for\nthe use of a diversity of losses and optimizers. Additionally, in scenarios\nwith multiple objectives, it can be used to dynamically prioritize tasks. With\ninspiration drawn from evolutionary algorithms, meta-learning, and neural\narchitecture search, we investigate an application of EV3 to knowledge\ndistillation. Our experimental results illustrate EV3's capability to safely\nexplore model spaces, while hinting at its potential applicability across\nnumerous domains due to its inherent flexibility and adaptability.",
            "author": [
                "Li Ding",
                "Masrour Zoghi",
                "Guy Tennenholtz",
                "Maryam Karimzadehgan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18893v1",
                "http://arxiv.org/pdf/2310.18893v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18891v2",
            "title": "Social Interaction-Aware Dynamical Models and Decision Making for\n  Autonomous Vehicles",
            "updated": "2023-10-31T03:57:56Z",
            "published": "2023-10-29T03:43:50Z",
            "summary": "Interaction-aware Autonomous Driving (IAAD) is a rapidly growing field of\nresearch that focuses on the development of autonomous vehicles (AVs) that are\ncapable of interacting safely and efficiently with human road users. This is a\nchallenging task, as it requires the autonomous vehicle to be able to\nunderstand and predict the behaviour of human road users. In this literature\nreview, the current state of IAAD research is surveyed in this work. Commencing\nwith an examination of terminology, attention is drawn to challenges and\nexisting models employed for modelling the behaviour of drivers and\npedestrians. Next, a comprehensive review is conducted on various techniques\nproposed for interaction modelling, encompassing cognitive methods, machine\nlearning approaches, and game-theoretic methods. The conclusion is reached\nthrough a discussion of potential advantages and risks associated with IAAD,\nalong with the illumination of pivotal research inquiries necessitating future\nexploration.",
            "author": [
                "Luca Crosato",
                "Kai Tian",
                "Hubert P. H Shum",
                "Edmond S. L. Ho",
                "Yafei Wang",
                "Chongfeng Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18891v2",
                "http://arxiv.org/pdf/2310.18891v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CY",
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18890v1",
            "title": "Towards Generalized Multi-stage Clustering: Multi-view Self-distillation",
            "updated": "2023-10-29T03:35:34Z",
            "published": "2023-10-29T03:35:34Z",
            "summary": "Existing multi-stage clustering methods independently learn the salient\nfeatures from multiple views and then perform the clustering task.\nParticularly, multi-view clustering (MVC) has attracted a lot of attention in\nmulti-view or multi-modal scenarios. MVC aims at exploring common semantics and\npseudo-labels from multiple views and clustering in a self-supervised manner.\nHowever, limited by noisy data and inadequate feature learning, such a\nclustering paradigm generates overconfident pseudo-labels that mis-guide the\nmodel to produce inaccurate predictions. Therefore, it is desirable to have a\nmethod that can correct this pseudo-label mistraction in multi-stage clustering\nto avoid the bias accumulation. To alleviate the effect of overconfident\npseudo-labels and improve the generalization ability of the model, this paper\nproposes a novel multi-stage deep MVC framework where multi-view\nself-distillation (DistilMVC) is introduced to distill dark knowledge of label\ndistribution. Specifically, in the feature subspace at different hierarchies,\nwe explore the common semantics of multiple views through contrastive learning\nand obtain pseudo-labels by maximizing the mutual information between views.\nAdditionally, a teacher network is responsible for distilling pseudo-labels\ninto dark knowledge, supervising the student network and improving its\npredictive capabilities to enhance the robustness. Extensive experiments on\nreal-world multi-view datasets show that our method has better clustering\nperformance than state-of-the-art methods.",
            "author": [
                "Jiatai Wang",
                "Zhiwei Xu",
                "Xin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18890v1",
                "http://arxiv.org/pdf/2310.18890v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18888v1",
            "title": "D2NO: Efficient Handling of Heterogeneous Input Function Spaces with\n  Distributed Deep Neural Operators",
            "updated": "2023-10-29T03:29:59Z",
            "published": "2023-10-29T03:29:59Z",
            "summary": "Neural operators have been applied in various scientific fields, such as\nsolving parametric partial differential equations, dynamical systems with\ncontrol, and inverse problems. However, challenges arise when dealing with\ninput functions that exhibit heterogeneous properties, requiring multiple\nsensors to handle functions with minimal regularity. To address this issue,\ndiscretization-invariant neural operators have been used, allowing the sampling\nof diverse input functions with different sensor locations. However, existing\nframeworks still require an equal number of sensors for all functions. In our\nstudy, we propose a novel distributed approach to further relax the\ndiscretization requirements and solve the heterogeneous dataset challenges. Our\nmethod involves partitioning the input function space and processing individual\ninput functions using independent and separate neural networks. A centralized\nneural network is used to handle shared information across all output\nfunctions. This distributed methodology reduces the number of gradient descent\nback-propagation steps, improving efficiency while maintaining accuracy. We\ndemonstrate that the corresponding neural network is a universal approximator\nof continuous nonlinear operators and present four numerical examples to\nvalidate its performance.",
            "author": [
                "Zecheng Zhang",
                "Christian Moya",
                "Lu Lu",
                "Guang Lin",
                "Hayden Schaeffer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18888v1",
                "http://arxiv.org/pdf/2310.18888v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18887v1",
            "title": "Dynamo-Depth: Fixing Unsupervised Depth Estimation for Dynamical Scenes",
            "updated": "2023-10-29T03:24:16Z",
            "published": "2023-10-29T03:24:16Z",
            "summary": "Unsupervised monocular depth estimation techniques have demonstrated\nencouraging results but typically assume that the scene is static. These\ntechniques suffer when trained on dynamical scenes, where apparent object\nmotion can equally be explained by hypothesizing the object's independent\nmotion, or by altering its depth. This ambiguity causes depth estimators to\npredict erroneous depth for moving objects. To resolve this issue, we introduce\nDynamo-Depth, an unifying approach that disambiguates dynamical motion by\njointly learning monocular depth, 3D independent flow field, and motion\nsegmentation from unlabeled monocular videos. Specifically, we offer our key\ninsight that a good initial estimation of motion segmentation is sufficient for\njointly learning depth and independent motion despite the fundamental\nunderlying ambiguity. Our proposed method achieves state-of-the-art performance\non monocular depth estimation on Waymo Open and nuScenes Dataset with\nsignificant improvement in the depth of moving objects. Code and additional\nresults are available at https://dynamo-depth.github.io.",
            "author": [
                "Yihong Sun",
                "Bharath Hariharan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18887v1",
                "http://arxiv.org/pdf/2310.18887v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18885v1",
            "title": "A foundational neural operator that continuously learns without\n  forgetting",
            "updated": "2023-10-29T03:20:10Z",
            "published": "2023-10-29T03:20:10Z",
            "summary": "Machine learning has witnessed substantial growth, leading to the development\nof advanced artificial intelligence models crafted to address a wide range of\nreal-world challenges spanning various domains, such as computer vision,\nnatural language processing, and scientific computing. Nevertheless, the\ncreation of custom models for each new task remains a resource-intensive\nundertaking, demanding considerable computational time and memory resources. In\nthis study, we introduce the concept of the Neural Combinatorial Wavelet Neural\nOperator (NCWNO) as a foundational model for scientific computing. This model\nis specifically designed to excel in learning from a diverse spectrum of\nphysics and continuously adapt to the solution operators associated with\nparametric partial differential equations (PDEs). The NCWNO leverages a gated\nstructure that employs local wavelet experts to acquire shared features across\nmultiple physical systems, complemented by a memory-based ensembling approach\namong these local wavelet experts. This combination enables rapid adaptation to\nnew challenges. The proposed foundational model offers two key advantages: (i)\nit can simultaneously learn solution operators for multiple parametric PDEs,\nand (ii) it can swiftly generalize to new parametric PDEs with minimal\nfine-tuning. The proposed NCWNO is the first foundational operator learning\nalgorithm distinguished by its (i) robustness against catastrophic forgetting,\n(ii) the maintenance of positive transfer for new parametric PDEs, and (iii)\nthe facilitation of knowledge transfer across dissimilar tasks. Through an\nextensive set of benchmark examples, we demonstrate that the NCWNO can\noutperform task-specific baseline operator learning frameworks with minimal\nhyperparameter tuning at the prediction stage. We also show that with minimal\nfine-tuning, the NCWNO performs accurate combinatorial learning of new\nparametric PDEs.",
            "author": [
                "Tapas Tripura",
                "Souvik Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18885v1",
                "http://arxiv.org/pdf/2310.18885v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18884v1",
            "title": "Simple and Asymmetric Graph Contrastive Learning without Augmentations",
            "updated": "2023-10-29T03:14:20Z",
            "published": "2023-10-29T03:14:20Z",
            "summary": "Graph Contrastive Learning (GCL) has shown superior performance in\nrepresentation learning in graph-structured data. Despite their success, most\nexisting GCL methods rely on prefabricated graph augmentation and homophily\nassumptions. Thus, they fail to generalize well to heterophilic graphs where\nconnected nodes may have different class labels and dissimilar features. In\nthis paper, we study the problem of conducting contrastive learning on\nhomophilic and heterophilic graphs. We find that we can achieve promising\nperformance simply by considering an asymmetric view of the neighboring nodes.\nThe resulting simple algorithm, Asymmetric Contrastive Learning for Graphs\n(GraphACL), is easy to implement and does not rely on graph augmentations and\nhomophily assumptions. We provide theoretical and empirical evidence that\nGraphACL can capture one-hop local neighborhood information and two-hop\nmonophily similarity, which are both important for modeling heterophilic\ngraphs. Experimental results show that the simple GraphACL significantly\noutperforms state-of-the-art graph contrastive learning and self-supervised\nlearning methods on homophilic and heterophilic graphs. The code of GraphACL is\navailable at https://github.com/tengxiao1/GraphACL.",
            "author": [
                "Teng Xiao",
                "Huaisheng Zhu",
                "Zhengyu Chen",
                "Suhang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18884v1",
                "http://arxiv.org/pdf/2310.18884v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18882v1",
            "title": "Differentiable Learning of Generalized Structured Matrices for Efficient\n  Deep Neural Networks",
            "updated": "2023-10-29T03:07:30Z",
            "published": "2023-10-29T03:07:30Z",
            "summary": "This paper investigates efficient deep neural networks (DNNs) to replace\ndense unstructured weight matrices with structured ones that possess desired\nproperties. The challenge arises because the optimal weight matrix structure in\npopular neural network models is obscure in most cases and may vary from layer\nto layer even in the same network. Prior structured matrices proposed for\nefficient DNNs were mostly hand-crafted without a generalized framework to\nsystematically learn them. To address this issue, we propose a generalized and\ndifferentiable framework to learn efficient structures of weight matrices by\ngradient descent. We first define a new class of structured matrices that\ncovers a wide range of structured matrices in the literature by adjusting the\nstructural parameters. Then, the frequency-domain differentiable\nparameterization scheme based on the Gaussian-Dirichlet kernel is adopted to\nlearn the structural parameters by proximal gradient descent. Finally, we\nintroduce an effective initialization method for the proposed scheme. Our\nmethod learns efficient DNNs with structured matrices, achieving lower\ncomplexity and/or higher performance than prior approaches that employ\nlow-rank, block-sparse, or block-low-rank matrices.",
            "author": [
                "Changwoo Lee",
                "Hun-Seok Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18882v1",
                "http://arxiv.org/pdf/2310.18882v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "eess.IV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18877v1",
            "title": "Pre-trained Speech Processing Models Contain Human-Like Biases that\n  Propagate to Speech Emotion Recognition",
            "updated": "2023-10-29T02:27:56Z",
            "published": "2023-10-29T02:27:56Z",
            "summary": "Previous work has established that a person's demographics and speech style\naffect how well speech processing models perform for them. But where does this\nbias come from? In this work, we present the Speech Embedding Association Test\n(SpEAT), a method for detecting bias in one type of model used for many speech\ntasks: pre-trained models. The SpEAT is inspired by word embedding association\ntests in natural language processing, which quantify intrinsic bias in a\nmodel's representations of different concepts, such as race or valence\n(something's pleasantness or unpleasantness) and capture the extent to which a\nmodel trained on large-scale socio-cultural data has learned human-like biases.\nUsing the SpEAT, we test for six types of bias in 16 English speech models\n(including 4 models also trained on multilingual data), which come from the\nwav2vec 2.0, HuBERT, WavLM, and Whisper model families. We find that 14 or more\nmodels reveal positive valence (pleasantness) associations with abled people\nover disabled people, with European-Americans over African-Americans, with\nfemales over males, with U.S. accented speakers over non-U.S. accented\nspeakers, and with younger people over older people. Beyond establishing that\npre-trained speech models contain these biases, we also show that they can have\nreal world effects. We compare biases found in pre-trained models to biases in\ndownstream models adapted to the task of Speech Emotion Recognition (SER) and\nfind that in 66 of the 96 tests performed (69%), the group that is more\nassociated with positive valence as indicated by the SpEAT also tends to be\npredicted as speaking with higher valence by the downstream model. Our work\nprovides evidence that, like text and image-based models, pre-trained speech\nbased-models frequently learn human-like biases. Our work also shows that bias\nfound in pre-trained models can propagate to the downstream task of SER.",
            "author": [
                "Isaac Slaughter",
                "Craig Greenberg",
                "Reva Schwartz",
                "Aylin Caliskan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18877v1",
                "http://arxiv.org/pdf/2310.18877v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18875v1",
            "title": "Feature calibration for computer models",
            "updated": "2023-10-29T02:23:17Z",
            "published": "2023-10-29T02:23:17Z",
            "summary": "Computer model calibration involves using partial and imperfect observations\nof the real world to learn which values of a model's input parameters lead to\noutputs that are consistent with real-world observations. When calibrating\nmodels with high-dimensional output (e.g. a spatial field), it is common to\nrepresent the output as a linear combination of a small set of basis vectors.\nOften, when trying to calibrate to such output, what is important to the\ncredibility of the model is that key emergent physical phenomena are\nrepresented, even if not faithfully or in the right place. In these cases,\ncomparison of model output and data in a linear subspace is inappropriate and\nwill usually lead to poor model calibration. To overcome this, we present\nkernel-based history matching (KHM), generalising the meaning of the technique\nsufficiently to be able to project model outputs and observations into a\nhigher-dimensional feature space, where patterns can be compared without their\nlocation necessarily being fixed. We develop the technical methodology, present\nan expert-driven kernel selection algorithm, and then apply the techniques to\nthe calibration of boundary layer clouds for the French climate model IPSL-CM.",
            "author": [
                "Wenzhe Xu",
                "Daniel B. Williamson",
                "Frederic Hourdin",
                "Romain Roehrig"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18875v1",
                "http://arxiv.org/pdf/2310.18875v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18868v1",
            "title": "Correlation Aware Sparsified Mean Estimation Using Random Projection",
            "updated": "2023-10-29T01:45:52Z",
            "published": "2023-10-29T01:45:52Z",
            "summary": "We study the problem of communication-efficient distributed vector mean\nestimation, a commonly used subroutine in distributed optimization and\nFederated Learning (FL). Rand-$k$ sparsification is a commonly used technique\nto reduce communication cost, where each client sends $k < d$ of its\ncoordinates to the server. However, Rand-$k$ is agnostic to any correlations,\nthat might exist between clients in practical scenarios. The recently proposed\nRand-$k$-Spatial estimator leverages the cross-client correlation information\nat the server to improve Rand-$k$'s performance. Yet, the performance of\nRand-$k$-Spatial is suboptimal. We propose the Rand-Proj-Spatial estimator with\na more flexible encoding-decoding procedure, which generalizes the encoding of\nRand-$k$ by projecting the client vectors to a random $k$-dimensional subspace.\nWe utilize Subsampled Randomized Hadamard Transform (SRHT) as the projection\nmatrix and show that Rand-Proj-Spatial with SRHT outperforms Rand-$k$-Spatial,\nusing the correlation information more efficiently. Furthermore, we propose an\napproach to incorporate varying degrees of correlation and suggest a practical\nvariant of Rand-Proj-Spatial when the correlation information is not available\nto the server. Experiments on real-world distributed optimization tasks\nshowcase the superior performance of Rand-Proj-Spatial compared to\nRand-$k$-Spatial and other more sophisticated sparsification techniques.",
            "author": [
                "Shuli Jiang",
                "Pranay Sharma",
                "Gauri Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18868v1",
                "http://arxiv.org/pdf/2310.18868v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18865v1",
            "title": "MUST: A Multilingual Student-Teacher Learning approach for low-resource\n  speech recognition",
            "updated": "2023-10-29T01:38:36Z",
            "published": "2023-10-29T01:38:36Z",
            "summary": "Student-teacher learning or knowledge distillation (KD) has been previously\nused to address data scarcity issue for training of speech recognition (ASR)\nsystems. However, a limitation of KD training is that the student model classes\nmust be a proper or improper subset of the teacher model classes. It prevents\ndistillation from even acoustically similar languages if the character sets are\nnot same. In this work, the aforementioned limitation is addressed by proposing\na MUltilingual Student-Teacher (MUST) learning which exploits a posteriors\nmapping approach. A pre-trained mapping model is used to map posteriors from a\nteacher language to the student language ASR. These mapped posteriors are used\nas soft labels for KD learning. Various teacher ensemble schemes are\nexperimented to train an ASR model for low-resource languages. A model trained\nwith MUST learning reduces relative character error rate (CER) up to 9.5% in\ncomparison with a baseline monolingual ASR.",
            "author": [
                "Muhammad Umar Farooq",
                "Rehan Ahmad",
                "Thomas Hain"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18865v1",
                "http://arxiv.org/pdf/2310.18865v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18861v1",
            "title": "Peer-to-Peer Deep Learning for Beyond-5G IoT",
            "updated": "2023-10-29T01:18:45Z",
            "published": "2023-10-29T01:18:45Z",
            "summary": "We present P2PL, a practical multi-device peer-to-peer deep learning\nalgorithm that, unlike the federated learning paradigm, does not require\ncoordination from edge servers or the cloud. This makes P2PL well-suited for\nthe sheer scale of beyond-5G computing environments like smart cities that\notherwise create range, latency, bandwidth, and single point of failure issues\nfor federated approaches.\n  P2PL introduces max norm synchronization to catalyze training, retains\non-device deep model training to preserve privacy, and leverages local\ninter-device communication to implement distributed consensus. Each device\niteratively alternates between two phases: 1) on-device learning and 2)\ndistributed cooperation where they combine model parameters with nearby\ndevices. We empirically show that all participating devices achieve the same\ntest performance attained by federated and centralized training -- even with\n100 devices and relaxed singly stochastic consensus weights. We extend these\nexperimental results to settings with diverse network topologies, sparse and\nintermittent communication, and non-IID data distributions.",
            "author": [
                "Srinivasa Pranav",
                "Jos\u00e9 M. F. Moura"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18861v1",
                "http://arxiv.org/pdf/2310.18861v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18860v2",
            "title": "Bayes beats Cross Validation: Efficient and Accurate Ridge Regression\n  via Expectation Maximization",
            "updated": "2023-11-03T02:00:03Z",
            "published": "2023-10-29T01:13:55Z",
            "summary": "We present a novel method for tuning the regularization hyper-parameter,\n$\\lambda$, of a ridge regression that is faster to compute than leave-one-out\ncross-validation (LOOCV) while yielding estimates of the regression parameters\nof equal, or particularly in the setting of sparse covariates, superior quality\nto those obtained by minimising the LOOCV risk. The LOOCV risk can suffer from\nmultiple and bad local minima for finite $n$ and thus requires the\nspecification of a set of candidate $\\lambda$, which can fail to provide good\nsolutions. In contrast, we show that the proposed method is guaranteed to find\na unique optimal solution for large enough $n$, under relatively mild\nconditions, without requiring the specification of any difficult to determine\nhyper-parameters. This is based on a Bayesian formulation of ridge regression\nthat we prove to have a unimodal posterior for large enough $n$, allowing for\nboth the optimal $\\lambda$ and the regression coefficients to be jointly\nlearned within an iterative expectation maximization (EM) procedure.\nImportantly, we show that by utilizing an appropriate preprocessing step, a\nsingle iteration of the main EM loop can be implemented in $O(\\min(n, p))$\noperations, for input data with $n$ rows and $p$ columns. In contrast,\nevaluating a single value of $\\lambda$ using fast LOOCV costs $O(n \\min(n, p))$\noperations when using the same preprocessing. This advantage amounts to an\nasymptotic improvement of a factor of $l$ for $l$ candidate values for\n$\\lambda$ (in the regime $q, p \\in O(\\sqrt{n})$ where $q$ is the number of\nregression targets).",
            "author": [
                "Shu Yu Tew",
                "Mario Boley",
                "Daniel F. Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18860v2",
                "http://arxiv.org/pdf/2310.18860v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18859v1",
            "title": "SiDA: Sparsity-Inspired Data-Aware Serving for Efficient and Scalable\n  Large Mixture-of-Experts Models",
            "updated": "2023-10-29T01:08:55Z",
            "published": "2023-10-29T01:08:55Z",
            "summary": "Mixture-of-Experts (MoE) has emerged as a favorable architecture in the era\nof large models due to its inherent advantage, i.e., enlarging model capacity\nwithout incurring notable computational overhead. Yet, the realization of such\nbenefits often results in ineffective GPU memory utilization, as large portions\nof the model parameters remain dormant during inference. Moreover, the memory\ndemands of large models consistently outpace the memory capacity of\ncontemporary GPUs. Addressing this, we introduce SiDA (Sparsity-inspired\nData-Aware), an efficient inference approach tailored for large MoE models.\nSiDA judiciously exploits both the system's main memory, which is now abundant\nand readily scalable, and GPU memory by capitalizing on the inherent sparsity\non expert activation in MoE models. By adopting a data-aware perspective, SiDA\nachieves enhanced model efficiency with a neglectable performance drop.\nSpecifically, SiDA attains a remarkable speedup in MoE inference with up to\n3.93X throughput increasing, up to 75% latency reduction, and up to 80% GPU\nmemory saving with down to 1% performance drop. This work paves the way for\nscalable and efficient deployment of large MoE models, even in\nmemory-constrained systems.",
            "author": [
                "Zhixu Du",
                "Shiyu Li",
                "Yuhao Wu",
                "Xiangyu Jiang",
                "Jingwei Sun",
                "Qilin Zheng",
                "Yongkai Wu",
                "Ang Li",
                "Hai \"Helen\" Li",
                "Yiran Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18859v1",
                "http://arxiv.org/pdf/2310.18859v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18850v1",
            "title": "Exploring Data Augmentations on Self-/Semi-/Fully- Supervised\n  Pre-trained Models",
            "updated": "2023-10-28T23:46:31Z",
            "published": "2023-10-28T23:46:31Z",
            "summary": "Data augmentation has become a standard component of vision pre-trained\nmodels to capture the invariance between augmented views. In practice,\naugmentation techniques that mask regions of a sample with zero/mean values or\npatches from other samples are commonly employed in pre-trained models with\nself-/semi-/fully-supervised contrastive losses. However, the underlying\nmechanism behind the effectiveness of these augmentation techniques remains\npoorly explored. To investigate the problems, we conduct an empirical study to\nquantify how data augmentation affects performance. Concretely, we apply 4\ntypes of data augmentations termed with Random Erasing, CutOut, CutMix and\nMixUp to a series of self-/semi-/fully- supervised pre-trained models. We\nreport their performance on vision tasks such as image classification, object\ndetection, instance segmentation, and semantic segmentation. We then explicitly\nevaluate the invariance and diversity of the feature embedding. We observe\nthat: 1) Masking regions of the images decreases the invariance of the learned\nfeature embedding while providing a more considerable diversity. 2) Manual\nannotations do not change the invariance or diversity of the learned feature\nembedding. 3) The MixUp approach improves the diversity significantly, with\nonly a marginal decrease in terms of the invariance.",
            "author": [
                "Shentong Mo",
                "Zhun Sun",
                "Chao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18850v1",
                "http://arxiv.org/pdf/2310.18850v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18849v2",
            "title": "Deep Learning-based Compressed Domain Multimedia for Man and Machine: A\n  Taxonomy and Application to Point Cloud Classification",
            "updated": "2023-11-17T15:53:50Z",
            "published": "2023-10-28T23:38:30Z",
            "summary": "In the current golden age of multimedia, human visualization is no longer the\nsingle main target, with the final consumer often being a machine which\nperforms some processing or computer vision tasks. In both cases, deep learning\nplays a undamental role in extracting features from the multimedia\nrepresentation data, usually producing a compressed representation referred to\nas latent representation. The increasing development and adoption of deep\nlearning-based solutions in a wide area of multimedia applications have opened\nan exciting new vision where a common compressed multimedia representation is\nused for both man and machine. The main benefits of this vision are two-fold:\ni) improved performance for the computer vision tasks, since the effects of\ncoding artifacts are mitigated; and ii) reduced computational complexity, since\nprior decoding is not required. This paper proposes the first taxonomy for\ndesigning compressed domain computer vision solutions driven by the\narchitecture and weights compatibility with an available spatio-temporal\ncomputer vision processor. The potential of the proposed taxonomy is\ndemonstrated for the specific case of point cloud classification by designing\nnovel compressed domain processors using the JPEG Pleno Point Cloud Coding\nstandard under development and adaptations of the PointGrid classifier.\nExperimental results show that the designed compressed domain point cloud\nclassification solutions can significantly outperform the spatial-temporal\ndomain classification benchmarks when applied to the decompressed data,\ncontaining coding artifacts, and even surpass their performance when applied to\nthe original uncompressed data.",
            "author": [
                "Abdelrahman Seleem",
                "Andr\u00e9 F. R. Guarda",
                "Nuno M. M. Rodrigues",
                "Fernando Pereira"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18849v2",
                "http://arxiv.org/pdf/2310.18849v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16125v1",
            "title": "Vision-Based Incoming Traffic Estimator Using Deep Neural Network on\n  General Purpose Embedded Hardware",
            "updated": "2023-10-28T23:33:00Z",
            "published": "2023-10-28T23:33:00Z",
            "summary": "Traffic management is a serious problem in many cities around the world. Even\nthe suburban areas are now experiencing regular traffic congestion.\nInappropriate traffic control wastes fuel, time, and the productivity of\nnations. Though traffic signals are used to improve traffic flow, they often\ncause problems due to inappropriate or obsolete timing that does not tally with\nthe actual traffic intensity at the intersection. Traffic intensity\ndetermination based on statistical methods only gives the average intensity\nexpected at any given time. However, to control traffic accurately, it is\nrequired to know the real-time traffic intensity. In this research, image\nprocessing and machine learning have been used to estimate actual traffic\nintensity in real time. General-purpose electronic hardware has been used for\nin-situ image processing based on the edge-detection method. A deep neural\nnetwork (DNN) was trained to infer traffic intensity in each image in real\ntime. The trained DNN estimated traffic intensity accurately in 90% of the\nreal-time images during road tests. The electronic system was implemented on a\nRaspberry Pi single-board computer; hence, it is cost-effective for large-scale\ndeployment.",
            "author": [
                "K. G. Zoysa",
                "S. R. Munasinghe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16125v1",
                "http://arxiv.org/pdf/2311.16125v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18847v1",
            "title": "World Model Based Sim2Real Transfer for Visual Navigation",
            "updated": "2023-10-28T23:25:19Z",
            "published": "2023-10-28T23:25:19Z",
            "summary": "Sim2Real transfer has gained popularity because it helps transfer from\ninexpensive simulators to real world. This paper presents a novel system that\nfuses components in a traditional \\textit{World Model} into a robust system,\ntrained entirely within a simulator, that \\textit{Zero-Shot} transfers to the\nreal world. To facilitate transfer, we use an intermediary representation that\nare based on \\textit{Bird's Eye View (BEV)} images. Thus, our robot learns to\nnavigate in a simulator by first learning to translate from complex\n\\textit{First-Person View (FPV)} based RGB images to BEV representations, then\nlearning to navigate using those representations. Later, when tested in the\nreal world, the robot uses the perception model that translates FPV-based RGB\nimages to embeddings that are used by the downstream policy. The incorporation\nof state-checking modules using \\textit{Anchor images} and \\textit{Mixture\nDensity LSTM} not only interpolates uncertain and missing observations but also\nenhances the robustness of the model when exposed to the real-world\nenvironment. We trained the model using data collected using a\n\\textit{Differential drive} robot in the CARLA simulator. Our methodology's\neffectiveness is shown through the deployment of trained models onto a\n\\textit{Real world Differential drive} robot. Lastly we release a comprehensive\ncodebase, dataset and models for training and deployment that are available to\nthe public.",
            "author": [
                "Chen Liu",
                "Kiran Lekkala",
                "Laurent Itti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18847v1",
                "http://arxiv.org/pdf/2310.18847v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18845v1",
            "title": "Application of Collaborative Learning Paradigms within Software\n  Engineering Education: A Systematic Mapping Study",
            "updated": "2023-10-28T23:16:38Z",
            "published": "2023-10-28T23:16:38Z",
            "summary": "Collaboration is used in Software Engineering (SE) to develop software.\nIndustry seeks SE graduates with collaboration skills to contribute to\nproductive software development. SE educators can use Collaborative Learning\n(CL) to help students develop collaboration skills. This paper uses a\nSystematic Mapping Study (SMS) to examine the application of the CL educational\ntheory in SE Education. The SMS identified 14 papers published between 2011 and\n2022. We used qualitative analysis to classify the papers into four CL\nparadigms: Conditions, Effect, Interactions, and Computer-Supported\nCollaborative Learning (CSCL). We found a high interest in CSCL, with a shift\nin student interaction research to computer-mediated technologies. We discussed\nthe 14 papers in depth, describing their goals and further analysing the CSCL\nresearch. Almost half the papers did not achieve the appropriate level of\nsupporting evidence; however, calibrating the instruments presented could\nstrengthen findings and support multiple CL paradigms, especially opportunities\nto learn at the social and community levels, where research was lacking. Though\nour results demonstrate limited CL educational theory applied in SE Education,\nwe discuss future work to layer the theory on existing study designs for more\neffective teaching strategies.",
            "author": [
                "Rita Garcia",
                "Christoph Treude",
                "Andrew Valentine"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3626252.3630780",
                "http://arxiv.org/abs/2310.18845v1",
                "http://arxiv.org/pdf/2310.18845v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18844v1",
            "title": "BanditPAM++: Faster $k$-medoids Clustering",
            "updated": "2023-10-28T23:11:16Z",
            "published": "2023-10-28T23:11:16Z",
            "summary": "Clustering is a fundamental task in data science with wide-ranging\napplications. In $k$-medoids clustering, cluster centers must be actual\ndatapoints and arbitrary distance metrics may be used; these features allow for\ngreater interpretability of the cluster centers and the clustering of exotic\nobjects in $k$-medoids clustering, respectively. $k$-medoids clustering has\nrecently grown in popularity due to the discovery of more efficient $k$-medoids\nalgorithms. In particular, recent research has proposed BanditPAM, a randomized\n$k$-medoids algorithm with state-of-the-art complexity and clustering accuracy.\nIn this paper, we present BanditPAM++, which accelerates BanditPAM via two\nalgorithmic improvements, and is $O(k)$ faster than BanditPAM in complexity and\nsubstantially faster than BanditPAM in wall-clock runtime. First, we\ndemonstrate that BanditPAM has a special structure that allows the reuse of\nclustering information $\\textit{within}$ each iteration. Second, we demonstrate\nthat BanditPAM has additional structure that permits the reuse of information\n$\\textit{across}$ different iterations. These observations inspire our proposed\nalgorithm, BanditPAM++, which returns the same clustering solutions as\nBanditPAM but often several times faster. For example, on the CIFAR10 dataset,\nBanditPAM++ returns the same results as BanditPAM but runs over 10$\\times$\nfaster. Finally, we provide a high-performance C++ implementation of\nBanditPAM++, callable from Python and R, that may be of interest to\npractitioners at https://github.com/motiwari/BanditPAM. Auxiliary code to\nreproduce all of our experiments via a one-line script is available at\nhttps://github.com/ThrunGroup/BanditPAM_plusplus_experiments.",
            "author": [
                "Mo Tiwari",
                "Ryan Kang",
                "Donghyun Lee",
                "Sebastian Thrun",
                "Chris Piech",
                "Ilan Shomorony",
                "Martin Jinye Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18844v1",
                "http://arxiv.org/pdf/2310.18844v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68",
                "I.m; I.2.0; I.2.6; K.3.2; I.2.m"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18841v1",
            "title": "A randomized algorithm for nonconvex minimization with inexact\n  evaluations and complexity guarantees",
            "updated": "2023-10-28T22:57:56Z",
            "published": "2023-10-28T22:57:56Z",
            "summary": "We consider minimization of a smooth nonconvex function with inexact oracle\naccess to gradient and Hessian (but not the function value) to achieve\n$(\\epsilon_{g}, \\epsilon_{H})$-approximate second-order optimality. A novel\nfeature of our method is that if an approximate direction of negative curvature\nis chosen as the step, we choose its sense to be positive or negative with\nequal probability. We also use relative inexactness measures on gradient and\nHessian and relax the coupling between the first- and second-order tolerances\n$\\epsilon_{g}$ and $\\epsilon_{H}$. Our convergence analysis includes both an\nexpectation bound based on martingale analysis and a high-probability bound\nbased on concentration inequalities. We apply our algorithm to empirical risk\nminimization problems and obtain gradient sample complexity.",
            "author": [
                "Shuyao Li",
                "Stephen J. Wright"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18841v1",
                "http://arxiv.org/pdf/2310.18841v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18836v2",
            "title": "Design of Cluster-Randomized Trials with Cross-Cluster Interference",
            "updated": "2023-11-20T04:02:24Z",
            "published": "2023-10-28T22:36:37Z",
            "summary": "Cluster-randomized trials often involve units that are irregularly\ndistributed in space without well-separated communities. In these settings,\ncluster construction is a critical aspect of the design due to the potential\nfor cross-cluster interference. The existing literature relies on partial\ninterference models, which take clusters as given and assume no cross-cluster\ninterference. We relax this assumption by allowing interference to decay with\ngeographic distance between units. This induces a bias-variance trade-off:\nconstructing fewer, larger clusters reduces bias due to interference but\nincreases variance. We propose new estimators that exclude units most\npotentially impacted by cross-cluster interference and show that this\nsubstantially reduces asymptotic bias relative to conventional\ndifference-in-means estimators. We provide formal justification for a new\ndesign that chooses the number of clusters to balance the asymptotic bias and\nvariance of our estimators and uses unsupervised learning to automate cluster\nconstruction.",
            "author": [
                "Michael P. Leung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18836v2",
                "http://arxiv.org/pdf/2310.18836v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18835v1",
            "title": "Experience-weighted attraction learning in network coordination games",
            "updated": "2023-10-28T22:35:05Z",
            "published": "2023-10-28T22:35:05Z",
            "summary": "This paper studies the action dynamics of network coordination games with\nbounded-rational agents. I apply the experience-weighted attraction (EWA) model\nto the analysis as the EWA model has several free parameters that can capture\ndifferent aspects of agents' behavioural features. I show that the set of\npossible long-term action patterns can be largely different when the\nbehavioural parameters vary, ranging from a unique possibility in which all\nagents favour the risk-dominant option to some set of outcomes richer than the\ncollection of Nash equilibria. Monotonicity and non-monotonicity in the\nrelationship between the number of possible long-term action profiles and the\nbehavioural parameters are explored. I also study the question of influential\nagents in terms of whose initial predispositions are important to the actions\nof the whole network. The importance of agents can be represented by a left\neigenvector of a Jacobian matrix provided that agents' initial attractions are\nclose to some neutral level. Numerical calculations examine the predictive\npower of the eigenvector for the long-run action profile and how agents'\ninfluences are impacted by their behavioural features and network positions.",
            "author": [
                "Fulin Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18835v1",
                "http://arxiv.org/pdf/2310.18835v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18832v1",
            "title": "Responsible AI (RAI) Games and Ensembles",
            "updated": "2023-10-28T22:17:30Z",
            "published": "2023-10-28T22:17:30Z",
            "summary": "Several recent works have studied the societal effects of AI; these include\nissues such as fairness, robustness, and safety. In many of these objectives, a\nlearner seeks to minimize its worst-case loss over a set of predefined\ndistributions (known as uncertainty sets), with usual examples being perturbed\nversions of the empirical distribution. In other words, aforementioned problems\ncan be written as min-max problems over these uncertainty sets. In this work,\nwe provide a general framework for studying these problems, which we refer to\nas Responsible AI (RAI) games. We provide two classes of algorithms for solving\nthese games: (a) game-play based algorithms, and (b) greedy stagewise\nestimation algorithms. The former class is motivated by online learning and\ngame theory, whereas the latter class is motivated by the classical statistical\nliterature on boosting, and regression. We empirically demonstrate the\napplicability and competitive performance of our techniques for solving several\nRAI problems, particularly around subpopulation shift.",
            "author": [
                "Yash Gupta",
                "Runtian Zhai",
                "Arun Suggala",
                "Pradeep Ravikumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18832v1",
                "http://arxiv.org/pdf/2310.18832v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18830v1",
            "title": "Translating away Translationese without Parallel Data",
            "updated": "2023-10-28T22:11:25Z",
            "published": "2023-10-28T22:11:25Z",
            "summary": "Translated texts exhibit systematic linguistic differences compared to\noriginal texts in the same language, and these differences are referred to as\ntranslationese. Translationese has effects on various cross-lingual natural\nlanguage processing tasks, potentially leading to biased results. In this\npaper, we explore a novel approach to reduce translationese in translated\ntexts: translation-based style transfer. As there are no parallel\nhuman-translated and original data in the same language, we use a\nself-supervised approach that can learn from comparable (rather than parallel)\nmono-lingual original and translated data. However, even this self-supervised\napproach requires some parallel data for validation. We show how we can\neliminate the need for parallel validation data by combining the\nself-supervised loss with an unsupervised loss. This unsupervised loss\nleverages the original language model loss over the style-transferred output\nand a semantic similarity loss between the input and style-transferred output.\nWe evaluate our approach in terms of original vs. translationese binary\nclassification in addition to measuring content preservation and target-style\nfluency. The results show that our approach is able to reduce translationese\nclassifier accuracy to a level of a random classifier after style transfer\nwhile adequately preserving the content and fluency in the target original\nstyle.",
            "author": [
                "Rricha Jalota",
                "Koel Dutta Chowdhury",
                "Cristina Espa\u00f1a-Bonet",
                "Josef van Genabith"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18830v1",
                "http://arxiv.org/pdf/2310.18830v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18824v1",
            "title": "Intrinsic Gaussian Vector Fields on Manifolds",
            "updated": "2023-10-28T21:17:36Z",
            "published": "2023-10-28T21:17:36Z",
            "summary": "Various applications ranging from robotics to climate science require\nmodeling signals on non-Euclidean domains, such as the sphere. Gaussian process\nmodels on manifolds have recently been proposed for such tasks, in particular\nwhen uncertainty quantification is needed. In the manifold setting,\nvector-valued signals can behave very differently from scalar-valued ones, with\nmuch of the progress so far focused on modeling the latter. The former,\nhowever, are crucial for many applications, such as modeling wind speeds or\nforce fields of unknown dynamical systems. In this paper, we propose novel\nGaussian process models for vector-valued signals on manifolds that are\nintrinsically defined and account for the geometry of the space in\nconsideration. We provide computational primitives needed to deploy the\nresulting Hodge-Mat\\'ern Gaussian vector fields on the two-dimensional sphere\nand the hypertori. Further, we highlight two generalization directions:\ndiscrete two-dimensional meshes and \"ideal\" manifolds like hyperspheres, Lie\ngroups, and homogeneous spaces. Finally, we show that our Gaussian vector\nfields constitute considerably more refined inductive biases than the extrinsic\nfields proposed before.",
            "author": [
                "Daniel Robert-Nicoud",
                "Andreas Krause",
                "Viacheslav Borovitskiy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18824v1",
                "http://arxiv.org/pdf/2310.18824v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18823v1",
            "title": "Successfully Applying Lottery Ticket Hypothesis to Diffusion Model",
            "updated": "2023-10-28T21:09:50Z",
            "published": "2023-10-28T21:09:50Z",
            "summary": "Despite the success of diffusion models, the training and inference of\ndiffusion models are notoriously expensive due to the long chain of the reverse\nprocess. In parallel, the Lottery Ticket Hypothesis (LTH) claims that there\nexists winning tickets (i.e., aproperly pruned sub-network together with\noriginal weight initialization) that can achieve performance competitive to the\noriginal dense neural network when trained in isolation. In this work, we for\nthe first time apply LTH to diffusion models. We empirically find subnetworks\nat sparsity 90%-99% without compromising performance for denoising diffusion\nprobabilistic models on benchmarks (CIFAR-10, CIFAR-100, MNIST). Moreover,\nexisting LTH works identify the subnetworks with a unified sparsity along\ndifferent layers. We observe that the similarity between two winning tickets of\na model varies from block to block. Specifically, the upstream layers from two\nwinning tickets for a model tend to be more similar than the downstream layers.\nTherefore, we propose to find the winning ticket with varying sparsity along\ndifferent layers in the model. Experimental results demonstrate that our method\ncan find sparser sub-models that require less memory for storage and reduce the\nnecessary number of FLOPs. Codes are available at\nhttps://github.com/osier0524/Lottery-Ticket-to-DDPM.",
            "author": [
                "Chao Jiang",
                "Bo Hui",
                "Bohan Liu",
                "Da Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18823v1",
                "http://arxiv.org/pdf/2310.18823v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18816v1",
            "title": "Adaptive Test-Time Personalization for Federated Learning",
            "updated": "2023-10-28T20:42:47Z",
            "published": "2023-10-28T20:42:47Z",
            "summary": "Personalized federated learning algorithms have shown promising results in\nadapting models to various distribution shifts. However, most of these methods\nrequire labeled data on testing clients for personalization, which is usually\nunavailable in real-world scenarios. In this paper, we introduce a novel\nsetting called test-time personalized federated learning (TTPFL), where clients\nlocally adapt a global model in an unsupervised way without relying on any\nlabeled data during test-time. While traditional test-time adaptation (TTA) can\nbe used in this scenario, most of them inherently assume training data come\nfrom a single domain, while they come from multiple clients (source domains)\nwith different distributions. Overlooking these domain interrelationships can\nresult in suboptimal generalization. Moreover, most TTA algorithms are designed\nfor a specific kind of distribution shift and lack the flexibility to handle\nmultiple kinds of distribution shifts in FL. In this paper, we find that this\nlack of flexibility partially results from their pre-defining which modules to\nadapt in the model. To tackle this challenge, we propose a novel algorithm\ncalled ATP to adaptively learns the adaptation rates for each module in the\nmodel from distribution shifts among source domains. Theoretical analysis\nproves the strong generalization of ATP. Extensive experiments demonstrate its\nsuperiority in handling various distribution shifts including label shift,\nimage corruptions, and domain shift, outperforming existing TTA methods across\nmultiple datasets and model architectures. Our code is available at\nhttps://github.com/baowenxuan/ATP .",
            "author": [
                "Wenxuan Bao",
                "Tianxin Wei",
                "Haohan Wang",
                "Jingrui He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18816v1",
                "http://arxiv.org/pdf/2310.18816v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18815v1",
            "title": "Rethinking Semi-Supervised Federated Learning: How to co-train\n  fully-labeled and fully-unlabeled client imaging data",
            "updated": "2023-10-28T20:41:41Z",
            "published": "2023-10-28T20:41:41Z",
            "summary": "The most challenging, yet practical, setting of semi-supervised federated\nlearning (SSFL) is where a few clients have fully labeled data whereas the\nother clients have fully unlabeled data. This is particularly common in\nhealthcare settings where collaborating partners (typically hospitals) may have\nimages but not annotations. The bottleneck in this setting is the joint\ntraining of labeled and unlabeled clients as the objective function for each\nclient varies based on the availability of labels. This paper investigates an\nalternative way for effective training with labeled and unlabeled clients in a\nfederated setting. We propose a novel learning scheme specifically designed for\nSSFL which we call Isolated Federated Learning (IsoFed) that circumvents the\nproblem by avoiding simple averaging of supervised and semi-supervised models\ntogether. In particular, our training approach consists of two parts - (a)\nisolated aggregation of labeled and unlabeled client models, and (b) local\nself-supervised pretraining of isolated global models in all clients. We\nevaluate our model performance on medical image datasets of four different\nmodalities publicly available within the biomedical image classification\nbenchmark MedMNIST. We further vary the proportion of labeled clients and the\ndegree of heterogeneity to demonstrate the effectiveness of the proposed method\nunder varied experimental settings.",
            "author": [
                "Pramit Saha",
                "Divyanshu Mishra",
                "J. Alison Noble"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18815v1",
                "http://arxiv.org/pdf/2310.18815v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18814v1",
            "title": "Stability of Random Forests and Coverage of Random-Forest Prediction\n  Intervals",
            "updated": "2023-10-28T20:38:53Z",
            "published": "2023-10-28T20:38:53Z",
            "summary": "We establish stability of random forests under the mild condition that the\nsquared response ($Y^2$) does not have a heavy tail. In particular, our\nanalysis holds for the practical version of random forests that is implemented\nin popular packages like \\texttt{randomForest} in \\texttt{R}. Empirical results\nshow that stability may persist even beyond our assumption and hold for\nheavy-tailed $Y^2$. Using the stability property, we prove a non-asymptotic\nlower bound for the coverage probability of prediction intervals constructed\nfrom the out-of-bag error of random forests. With another mild condition that\nis typically satisfied when $Y$ is continuous, we also establish a\ncomplementary upper bound, which can be similarly established for the jackknife\nprediction interval constructed from an arbitrary stable algorithm. We also\ndiscuss the asymptotic coverage probability under assumptions weaker than those\nconsidered in previous literature. Our work implies that random forests, with\nits stability property, is an effective machine learning method that can\nprovide not only satisfactory point prediction but also justified interval\nprediction at almost no extra computational cost.",
            "author": [
                "Yan Wang",
                "Huaiqing Wu",
                "Dan Nettleton"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18814v1",
                "http://arxiv.org/pdf/2310.18814v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18813v1",
            "title": "The Synergy of Speculative Decoding and Batching in Serving Large\n  Language Models",
            "updated": "2023-10-28T20:36:36Z",
            "published": "2023-10-28T20:36:36Z",
            "summary": "Large Language Models (LLMs) like GPT are state-of-the-art text generation\nmodels that provide significant assistance in daily routines. However, LLM\nexecution is inherently sequential, since they only produce one token at a\ntime, thus incurring low hardware utilization on modern GPUs. Batching and\nspeculative decoding are two techniques to improve GPU hardware utilization in\nLLM inference. To study their synergy, we implement a prototype implementation\nand perform an extensive characterization analysis on various LLM models and\nGPU architectures. We observe that the optimal speculation length depends on\nthe batch size used. We analyze the key observation and build a quantitative\nmodel to explain it. Based on our analysis, we propose a new adaptive\nspeculative decoding strategy that chooses the optimal speculation length for\ndifferent batch sizes. Our evaluations show that our proposed method can\nachieve equal or better performance than the state-of-the-art speculation\ndecoding schemes with fixed speculation length.",
            "author": [
                "Qidong Su",
                "Christina Giannoula",
                "Gennady Pekhimenko"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18813v1",
                "http://arxiv.org/pdf/2310.18813v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18811v1",
            "title": "Hierarchical Framework for Interpretable and Probabilistic Model-Based\n  Safe Reinforcement Learning",
            "updated": "2023-10-28T20:30:57Z",
            "published": "2023-10-28T20:30:57Z",
            "summary": "The difficulty of identifying the physical model of complex systems has led\nto exploring methods that do not rely on such complex modeling of the systems.\nDeep reinforcement learning has been the pioneer for solving this problem\nwithout the need for relying on the physical model of complex systems by just\ninteracting with it. However, it uses a black-box learning approach that makes\nit difficult to be applied within real-world and safety-critical systems\nwithout providing explanations of the actions derived by the model.\nFurthermore, an open research question in deep reinforcement learning is how to\nfocus the policy learning of critical decisions within a sparse domain. This\npaper proposes a novel approach for the use of deep reinforcement learning in\nsafety-critical systems. It combines the advantages of probabilistic modeling\nand reinforcement learning with the added benefits of interpretability and\nworks in collaboration and synchronization with conventional decision-making\nstrategies. The BC-SRLA is activated in specific situations which are\nidentified autonomously through the fused information of probabilistic model\nand reinforcement learning, such as abnormal conditions or when the system is\nnear-to-failure. Further, it is initialized with a baseline policy using policy\ncloning to allow minimum interactions with the environment to address the\nchallenges associated with using RL in safety-critical industries. The\neffectiveness of the BC-SRLA is demonstrated through a case study in\nmaintenance applied to turbofan engines, where it shows superior performance to\nthe prior art and other baselines.",
            "author": [
                "Ammar N. Abbas",
                "Georgios C. Chasparis",
                "John D. Kelleher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18811v1",
                "http://arxiv.org/pdf/2310.18811v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18807v1",
            "title": "OC-NMN: Object-centric Compositional Neural Module Network for\n  Generative Visual Analogical Reasoning",
            "updated": "2023-10-28T20:12:58Z",
            "published": "2023-10-28T20:12:58Z",
            "summary": "A key aspect of human intelligence is the ability to imagine -- composing\nlearned concepts in novel ways -- to make sense of new scenarios. Such capacity\nis not yet attained for machine learning systems. In this work, in the context\nof visual reasoning, we show how modularity can be leveraged to derive a\ncompositional data augmentation framework inspired by imagination. Our method,\ndenoted Object-centric Compositional Neural Module Network (OC-NMN), decomposes\nvisual generative reasoning tasks into a series of primitives applied to\nobjects without using a domain-specific language. We show that our modular\narchitectural choices can be used to generate new training tasks that lead to\nbetter out-of-distribution generalization. We compare our model to existing and\nnew baselines in proposed visual reasoning benchmark that consists of applying\narithmetic operations to MNIST digits.",
            "author": [
                "Rim Assouel",
                "Pau Rodriguez",
                "Perouz Taslakian",
                "David Vazquez",
                "Yoshua Bengio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18807v1",
                "http://arxiv.org/pdf/2310.18807v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18805v2",
            "title": "Inverse distance weighting attention",
            "updated": "2023-12-06T21:06:07Z",
            "published": "2023-10-28T20:11:01Z",
            "summary": "We report the effects of replacing the scaled dot-product (within softmax)\nattention with the negative-log of Euclidean distance. This form of attention\nsimplifies to inverse distance weighting interpolation. Used in simple one\nhidden layer networks and trained with vanilla cross-entropy loss on\nclassification problems, it tends to produce a key matrix containing prototypes\nand a value matrix with corresponding logits. We also show that the resulting\ninterpretable networks can be augmented with manually-constructed prototypes to\nperform low-impact handling of special cases.",
            "author": [
                "Calvin McCarter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18805v2",
                "http://arxiv.org/pdf/2310.18805v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18804v1",
            "title": "Open Visual Knowledge Extraction via Relation-Oriented Multimodality\n  Model Prompting",
            "updated": "2023-10-28T20:09:29Z",
            "published": "2023-10-28T20:09:29Z",
            "summary": "Images contain rich relational knowledge that can help machines understand\nthe world. Existing methods on visual knowledge extraction often rely on the\npre-defined format (e.g., sub-verb-obj tuples) or vocabulary (e.g., relation\ntypes), restricting the expressiveness of the extracted knowledge. In this\nwork, we take a first exploration to a new paradigm of open visual knowledge\nextraction. To achieve this, we present OpenVik which consists of an open\nrelational region detector to detect regions potentially containing relational\nknowledge and a visual knowledge generator that generates format-free knowledge\nby prompting the large multimodality model with the detected region of\ninterest. We also explore two data enhancement techniques for diversifying the\ngenerated format-free visual knowledge. Extensive knowledge quality evaluations\nhighlight the correctness and uniqueness of the extracted open visual knowledge\nby OpenVik. Moreover, integrating our extracted knowledge across various visual\nreasoning applications shows consistent improvements, indicating the real-world\napplicability of OpenVik.",
            "author": [
                "Hejie Cui",
                "Xinyu Fang",
                "Zihan Zhang",
                "Ran Xu",
                "Xuan Kan",
                "Xin Liu",
                "Yue Yu",
                "Manling Li",
                "Yangqiu Song",
                "Carl Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18804v1",
                "http://arxiv.org/pdf/2310.18804v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18803v1",
            "title": "Weakly Coupled Deep Q-Networks",
            "updated": "2023-10-28T20:07:57Z",
            "published": "2023-10-28T20:07:57Z",
            "summary": "We propose weakly coupled deep Q-networks (WCDQN), a novel deep reinforcement\nlearning algorithm that enhances performance in a class of structured problems\ncalled weakly coupled Markov decision processes (WCMDP). WCMDPs consist of\nmultiple independent subproblems connected by an action space constraint, which\nis a structural property that frequently emerges in practice. Despite this\nappealing structure, WCMDPs quickly become intractable as the number of\nsubproblems grows. WCDQN employs a single network to train multiple DQN\n\"subagents\", one for each subproblem, and then combine their solutions to\nestablish an upper bound on the optimal action value. This guides the main DQN\nagent towards optimality. We show that the tabular version, weakly coupled\nQ-learning (WCQL), converges almost surely to the optimal action value.\nNumerical experiments show faster convergence compared to DQN and related\ntechniques in settings with as many as 10 subproblems, $3^{10}$ total actions,\nand a continuous state space.",
            "author": [
                "Ibrahim El Shar",
                "Daniel R. Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18803v1",
                "http://arxiv.org/pdf/2310.18803v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18795v1",
            "title": "A Review on the Applications of Machine Learning for Tinnitus Diagnosis\n  Using EEG Signals",
            "updated": "2023-10-28T19:49:43Z",
            "published": "2023-10-28T19:49:43Z",
            "summary": "Tinnitus is a prevalent hearing disorder that can be caused by various\nfactors such as age, hearing loss, exposure to loud noises, ear infections or\ntumors, certain medications, head or neck injuries, and psychological\nconditions like anxiety and depression. While not every patient requires\nmedical attention, about 20% of sufferers seek clinical intervention. Early\ndiagnosis is crucial for effective treatment. New developments have been made\nin tinnitus detection to aid in early detection of this illness. Over the past\nfew years, there has been a notable growth in the usage of\nelectroencephalography (EEG) to study variations in oscillatory brain activity\nrelated to tinnitus. However, the results obtained from numerous studies vary\ngreatly, leading to conflicting conclusions. Currently, clinicians rely solely\non their expertise to identify individuals with tinnitus. Researchers in this\nfield have incorporated various data modalities and machine-learning techniques\nto aid clinicians in identifying tinnitus characteristics and classifying\npeople with tinnitus. The purpose of writing this article is to review articles\nthat focus on using machine learning (ML) to identify or predict tinnitus\npatients using EEG signals as input data. We have evaluated 11 articles\npublished between 2016 and 2023 using a systematic literature review (SLR)\nmethod. This article arranges perfect summaries of all the research reviewed\nand compares the significant aspects of each. Additionally, we performed\nstatistical analyses to gain a deeper comprehension of the most recent research\nin this area. Almost all of the reviewed articles followed a five-step\nprocedure to achieve the goal of tinnitus. Disclosure. Finally, we discuss the\nopen affairs and challenges in this method of tinnitus recognition or\nprediction and suggest future directions for research.",
            "author": [
                "Farzaneh Ramezani",
                "Hamidreza Bolhasani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18795v1",
                "http://arxiv.org/pdf/2310.18795v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18788v1",
            "title": "PrObeD: Proactive Object Detection Wrapper",
            "updated": "2023-10-28T19:25:01Z",
            "published": "2023-10-28T19:25:01Z",
            "summary": "Previous research in $2D$ object detection focuses on various tasks,\nincluding detecting objects in generic and camouflaged images. These works are\nregarded as passive works for object detection as they take the input image as\nis. However, convergence to global minima is not guaranteed to be optimal in\nneural networks; therefore, we argue that the trained weights in the object\ndetector are not optimal. To rectify this problem, we propose a wrapper based\non proactive schemes, PrObeD, which enhances the performance of these object\ndetectors by learning a signal. PrObeD consists of an encoder-decoder\narchitecture, where the encoder network generates an image-dependent signal\ntermed templates to encrypt the input images, and the decoder recovers this\ntemplate from the encrypted images. We propose that learning the optimum\ntemplate results in an object detector with an improved detection performance.\nThe template acts as a mask to the input images to highlight semantics useful\nfor the object detector. Finetuning the object detector with these encrypted\nimages enhances the detection performance for both generic and camouflaged. Our\nexperiments on MS-COCO, CAMO, COD$10$K, and NC$4$K datasets show improvement\nover different detectors after applying PrObeD. Our models/codes are available\nat https://github.com/vishal3477/Proactive-Object-Detection.",
            "author": [
                "Vishal Asnani",
                "Abhinav Kumar",
                "Suya You",
                "Xiaoming Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18788v1",
                "http://arxiv.org/pdf/2310.18788v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18786v1",
            "title": "A Competitive Algorithm for Agnostic Active Learning",
            "updated": "2023-10-28T19:01:16Z",
            "published": "2023-10-28T19:01:16Z",
            "summary": "For some hypothesis classes and input distributions, active agnostic learning\nneeds exponentially fewer samples than passive learning; for other classes and\ndistributions, it offers little to no improvement. The most popular algorithms\nfor agnostic active learning express their performance in terms of a parameter\ncalled the disagreement coefficient, but it is known that these algorithms are\ninefficient on some inputs.\n  We take a different approach to agnostic active learning, getting an\nalgorithm that is competitive with the optimal algorithm for any binary\nhypothesis class $H$ and distribution $D_X$ over $X$. In particular, if any\nalgorithm can use $m^*$ queries to get $O(\\eta)$ error, then our algorithm uses\n$O(m^* \\log |H|)$ queries to get $O(\\eta)$ error. Our algorithm lies in the\nvein of the splitting-based approach of Dasgupta [2004], which gets a similar\nresult for the realizable ($\\eta = 0$) setting.\n  We also show that it is NP-hard to do better than our algorithm's $O(\\log\n|H|)$ overhead in general.",
            "author": [
                "Eric Price",
                "Yihan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18786v1",
                "http://arxiv.org/pdf/2310.18786v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18784v3",
            "title": "High-probability Convergence Bounds for Nonlinear Stochastic Gradient\n  Descent Under Heavy-tailed Noise",
            "updated": "2023-12-04T20:45:39Z",
            "published": "2023-10-28T18:53:41Z",
            "summary": "Several recent works have studied the convergence \\textit{in high\nprobability} of stochastic gradient descent (SGD) and its clipped variant.\nCompared to vanilla SGD, clipped SGD is practically more stable and has the\nadditional theoretical benefit of logarithmic dependence on the failure\nprobability. However, the convergence of other practical nonlinear variants of\nSGD, e.g., sign SGD, quantized SGD and normalized SGD, that achieve improved\ncommunication efficiency or accelerated convergence is much less understood. In\nthis work, we study the convergence bounds \\textit{in high probability} of a\nbroad class of nonlinear SGD methods. For strongly convex loss functions with\nLipschitz continuous gradients, we prove a logarithmic dependence on the\nfailure probability, even when the noise is heavy-tailed. Strictly more general\nthan the results for clipped SGD, our results hold for any nonlinearity with\nbounded (component-wise or joint) outputs, such as clipping, normalization, and\nquantization. Further, existing results with heavy-tailed noise assume bounded\n$\\eta$-th central moments, with $\\eta \\in (1,2]$. In contrast, our refined\nanalysis works even for $\\eta=1$, strictly relaxing the noise moment\nassumptions in the literature.",
            "author": [
                "Aleksandar Armacki",
                "Pranay Sharma",
                "Gauri Joshi",
                "Dragana Bajovic",
                "Dusan Jakovetic",
                "Soummya Kar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18784v3",
                "http://arxiv.org/pdf/2310.18784v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18780v1",
            "title": "Laughing Hyena Distillery: Extracting Compact Recurrences From\n  Convolutions",
            "updated": "2023-10-28T18:40:03Z",
            "published": "2023-10-28T18:40:03Z",
            "summary": "Recent advances in attention-free sequence models rely on convolutions as\nalternatives to the attention operator at the core of Transformers. In\nparticular, long convolution sequence models have achieved state-of-the-art\nperformance in many domains, but incur a significant cost during\nauto-regressive inference workloads -- naively requiring a full pass (or\ncaching of activations) over the input sequence for each generated token --\nsimilarly to attention-based models. In this paper, we seek to enable $\\mathcal\nO(1)$ compute and memory cost per token in any pre-trained long convolution\narchitecture to reduce memory footprint and increase throughput during\ngeneration. Concretely, our methods consist in extracting low-dimensional\nlinear state-space models from each convolution layer, building upon rational\ninterpolation and model-order reduction techniques. We further introduce\narchitectural improvements to convolution-based layers such as Hyena: by\nweight-tying the filters across channels into heads, we achieve higher\npre-training quality and reduce the number of filters to be distilled. The\nresulting model achieves 10x higher throughput than Transformers and 1.5x\nhigher than Hyena at 1.3B parameters, without any loss in quality after\ndistillation.",
            "author": [
                "Stefano Massaroli",
                "Michael Poli",
                "Daniel Y. Fu",
                "Hermann Kumbong",
                "Rom N. Parnichkun",
                "Aman Timalsina",
                "David W. Romero",
                "Quinn McIntyre",
                "Beidi Chen",
                "Atri Rudra",
                "Ce Zhang",
                "Christopher Re",
                "Stefano Ermon",
                "Yoshua Bengio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18780v1",
                "http://arxiv.org/pdf/2310.18780v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18777v1",
            "title": "Improving Compositional Generalization Using Iterated Learning and\n  Simplicial Embeddings",
            "updated": "2023-10-28T18:30:30Z",
            "published": "2023-10-28T18:30:30Z",
            "summary": "Compositional generalization, the ability of an agent to generalize to unseen\ncombinations of latent factors, is easy for humans but hard for deep neural\nnetworks. A line of research in cognitive science has hypothesized a process,\n``iterated learning,'' to help explain how human language developed this\nability; the theory rests on simultaneous pressures towards compressibility\n(when an ignorant agent learns from an informed one) and expressivity (when it\nuses the representation for downstream tasks). Inspired by this process, we\npropose to improve the compositional generalization of deep networks by using\niterated learning on models with simplicial embeddings, which can approximately\ndiscretize representations. This approach is further motivated by an analysis\nof compositionality based on Kolmogorov complexity. We show that this\ncombination of changes improves compositional generalization over other\napproaches, demonstrating these improvements both on vision tasks with\nwell-understood latent factors and on real molecular graph prediction tasks\nwhere the latent structure is unknown.",
            "author": [
                "Yi Ren",
                "Samuel Lavoie",
                "Mikhail Galkin",
                "Danica J. Sutherland",
                "Aaron Courville"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18777v1",
                "http://arxiv.org/pdf/2310.18777v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18774v1",
            "title": "Reflection coupling for unadjusted generalized Hamiltonian Monte Carlo\n  in the nonconvex stochastic gradient case",
            "updated": "2023-10-28T18:25:59Z",
            "published": "2023-10-28T18:25:59Z",
            "summary": "Contraction in Wasserstein 1-distance with explicit rates is established for\ngeneralized Hamiltonian Monte Carlo with stochastic gradients under possibly\nnonconvex conditions. The algorithms considered include splitting schemes of\nkinetic Langevin diffusion. As consequence, quantitative Gaussian concentration\nbounds are provided for empirical averages. Convergence in Wasserstein\n2-distance, total variation and relative entropy are also given, together with\nnumerical bias estimates.",
            "author": [
                "Martin Chak",
                "Pierre Monmarch\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18774v1",
                "http://arxiv.org/pdf/2310.18774v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "stat.CO",
                "stat.ML",
                "60J05, 65P10, 65C05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18773v1",
            "title": "CityRefer: Geography-aware 3D Visual Grounding Dataset on City-scale\n  Point Cloud Data",
            "updated": "2023-10-28T18:05:32Z",
            "published": "2023-10-28T18:05:32Z",
            "summary": "City-scale 3D point cloud is a promising way to express detailed and\ncomplicated outdoor structures. It encompasses both the appearance and geometry\nfeatures of segmented city components, including cars, streets, and buildings,\nthat can be utilized for attractive applications such as user-interactive\nnavigation of autonomous vehicles and drones. However, compared to the\nextensive text annotations available for images and indoor scenes, the scarcity\nof text annotations for outdoor scenes poses a significant challenge for\nachieving these applications. To tackle this problem, we introduce the\nCityRefer dataset for city-level visual grounding. The dataset consists of 35k\nnatural language descriptions of 3D objects appearing in SensatUrban city\nscenes and 5k landmarks labels synchronizing with OpenStreetMap. To ensure the\nquality and accuracy of the dataset, all descriptions and labels in the\nCityRefer dataset are manually verified. We also have developed a baseline\nsystem that can learn encoded language descriptions, 3D object instances, and\ngeographical information about the city's landmarks to perform visual grounding\non the CityRefer dataset. To the best of our knowledge, the CityRefer dataset\nis the largest city-level visual grounding dataset for localizing specific 3D\nobjects.",
            "author": [
                "Taiki Miyanishi",
                "Fumiya Kitamori",
                "Shuhei Kurita",
                "Jungdae Lee",
                "Motoaki Kawanabe",
                "Nakamasa Inoue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18773v1",
                "http://arxiv.org/pdf/2310.18773v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18772v1",
            "title": "A Data-driven Recommendation Framework for Optimal Walker Designs",
            "updated": "2023-10-28T18:04:38Z",
            "published": "2023-10-28T18:04:38Z",
            "summary": "The rapidly advancing fields of statistical modeling and machine learning\nhave significantly enhanced data-driven design and optimization. This paper\nfocuses on leveraging these design algorithms to optimize a medical walker, an\nintegral part of gait rehabilitation and physiological therapy of the lower\nextremities. To achieve the desirable qualities of a walker, we train a\npredictive machine-learning model to identify trade-offs between performance\nobjectives, thus enabling the use of efficient optimization algorithms. To do\nthis, we use an Automated Machine Learning model utilizing a stacked-ensemble\napproach shown to outperform traditional ML models. However, training a\npredictive model requires vast amounts of data for accuracy. Due to limited\npublicly available walker designs, this paper presents a dataset of more than\n5,000 parametric walker designs with performance values to assess mass,\nstructural integrity, and stability. These performance values include\ndisplacement vectors for the given load case, stress coefficients, mass, and\nother physical properties. We also introduce a novel method of systematically\ncalculating the stability index of a walker. We use MultiObjective\nCounterfactuals for Design (MCD), a novel genetic-based optimization algorithm,\nto explore the diverse 16-dimensional design space and search for\nhigh-performing designs based on numerous objectives. This paper presents\npotential walker designs that demonstrate up to a 30% mass reduction while\nincreasing structural stability and integrity. This work takes a step toward\nthe improved development of assistive mobility devices.",
            "author": [
                "Advaith Narayanan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18772v1",
                "http://arxiv.org/pdf/2310.18772v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18770v1",
            "title": "Leveraging Multimodal Features and Item-level User Feedback for Bundle\n  Construction",
            "updated": "2023-10-28T17:54:26Z",
            "published": "2023-10-28T17:54:26Z",
            "summary": "Automatic bundle construction is a crucial prerequisite step in various\nbundle-aware online services. Previous approaches are mostly designed to model\nthe bundling strategy of existing bundles. However, it is hard to acquire\nlarge-scale well-curated bundle dataset, especially for those platforms that\nhave not offered bundle services before. Even for platforms with mature bundle\nservices, there are still many items that are included in few or even zero\nbundles, which give rise to sparsity and cold-start challenges in the bundle\nconstruction models. To tackle these issues, we target at leveraging multimodal\nfeatures, item-level user feedback signals, and the bundle composition\ninformation, to achieve a comprehensive formulation of bundle construction.\nNevertheless, such formulation poses two new technical challenges: 1) how to\nlearn effective representations by optimally unifying multiple features, and 2)\nhow to address the problems of modality missing, noise, and sparsity problems\ninduced by the incomplete query bundles. In this work, to address these\ntechnical challenges, we propose a Contrastive Learning-enhanced Hierarchical\nEncoder method (CLHE). Specifically, we use self-attention modules to combine\nthe multimodal and multi-item features, and then leverage both item- and\nbundle-level contrastive learning to enhance the representation learning, thus\nto counter the modality missing, noise, and sparsity problems. Extensive\nexperiments on four datasets in two application domains demonstrate that our\nmethod outperforms a list of SOTA methods. The code and dataset are available\nat https://github.com/Xiaohao-Liu/CLHE.",
            "author": [
                "Yunshan Ma",
                "Xiaohao Liu",
                "Yinwei Wei",
                "Zhulin Tao",
                "Xiang Wang",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18770v1",
                "http://arxiv.org/pdf/2310.18770v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.MM",
                "H.3.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18769v1",
            "title": "Linear Mode Connectivity in Sparse Neural Networks",
            "updated": "2023-10-28T17:51:39Z",
            "published": "2023-10-28T17:51:39Z",
            "summary": "With the rise in interest of sparse neural networks, we study how neural\nnetwork pruning with synthetic data leads to sparse networks with unique\ntraining properties. We find that distilled data, a synthetic summarization of\nthe real data, paired with Iterative Magnitude Pruning (IMP) unveils a new\nclass of sparse networks that are more stable to SGD noise on the real data,\nthan either the dense model, or subnetworks found with real data in IMP. That\nis, synthetically chosen subnetworks often train to the same minima, or exhibit\nlinear mode connectivity. We study this through linear interpolation, loss\nlandscape visualizations, and measuring the diagonal of the hessian. While\ndataset distillation as a field is still young, we find that these properties\nlead to synthetic subnetworks matching the performance of traditional IMP with\nup to 150x less training points in settings where distilled data applies.",
            "author": [
                "Luke McDermott",
                "Daniel Cummings"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18769v1",
                "http://arxiv.org/pdf/2310.18769v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18767v1",
            "title": "Enhancing Epileptic Seizure Detection with EEG Feature Embeddings",
            "updated": "2023-10-28T17:46:21Z",
            "published": "2023-10-28T17:46:21Z",
            "summary": "Epilepsy is one of the most prevalent brain disorders that disrupts the lives\nof millions worldwide. For patients with drug-resistant seizures, there exist\nimplantable devices capable of monitoring neural activity, promptly triggering\nneurostimulation to regulate seizures, or alerting patients of potential\nepisodes. Next-generation seizure detection systems heavily rely on\nhigh-accuracy machine learning-based classifiers to detect the seizure onset.\nHere, we propose to enhance the seizure detection performance by learning\ninformative embeddings of the EEG signal. We empirically demonstrate, for the\nfirst time, that converting raw EEG signals to appropriate embeddings can\nsignificantly boost the performance of seizure detection algorithms.\nImportantly, we show that embedding features, which converts the raw EEG into\nan alternative representation, is beneficial for various machine learning\nmodels such as Logistic Regression, Multi-Layer Perceptron, Support Vector\nMachines, and Gradient Boosted Trees. The experiments were conducted on the\nCHB-MIT scalp EEG dataset. With the proposed EEG feature embeddings, we achieve\nsignificant improvements in sensitivity, specificity, and AUC score across\nmultiple models. By employing this approach alongside an SVM classifier, we\nwere able to attain state-of-the-art classification performance with a\nsensitivity of 100% and specificity of 99%, setting a new benchmark in the\nfield.",
            "author": [
                "Arman Zarei",
                "Bingzhao Zhu",
                "Mahsa Shoaran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18767v1",
                "http://arxiv.org/pdf/2310.18767v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18765v2",
            "title": "Rethinking Semi-Supervised Imbalanced Node Classification from\n  Bias-Variance Decomposition",
            "updated": "2023-11-10T13:23:07Z",
            "published": "2023-10-28T17:28:07Z",
            "summary": "This paper introduces a new approach to address the issue of class imbalance\nin graph neural networks (GNNs) for learning on graph-structured data. Our\napproach integrates imbalanced node classification and Bias-Variance\nDecomposition, establishing a theoretical framework that closely relates data\nimbalance to model variance. We also leverage graph augmentation technique to\nestimate the variance, and design a regularization term to alleviate the impact\nof imbalance. Exhaustive tests are conducted on multiple benchmarks, including\nnaturally imbalanced datasets and public-split class-imbalanced datasets,\ndemonstrating that our approach outperforms state-of-the-art methods in various\nimbalanced scenarios. This work provides a novel theoretical perspective for\naddressing the problem of imbalanced node classification in GNNs.",
            "author": [
                "Divin Yan",
                "Gengchen Wei",
                "Chen Yang",
                "Shengzhong Zhang",
                "Zengfeng Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18765v2",
                "http://arxiv.org/pdf/2310.18765v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14674v1",
            "title": "Emotion-Oriented Behavior Model Using Deep Learning",
            "updated": "2023-10-28T17:27:59Z",
            "published": "2023-10-28T17:27:59Z",
            "summary": "Emotions, as a fundamental ingredient of any social interaction, lead to\nbehaviors that represent the effectiveness of the interaction through facial\nexpressions and gestures in humans. Hence an agent must possess the social and\ncognitive abilities to understand human social parameters and behave\naccordingly. However, no such emotion-oriented behavior model is presented yet\nin the existing research. The emotion prediction may generate appropriate\nagents' behaviors for effective interaction using conversation modality.\nConsidering the importance of emotions, and behaviors, for an agent's social\ninteraction, an Emotion-based Behavior model is presented in this paper for\nSocio-cognitive artificial agents. The proposed model is implemented using\ntweets data trained on multiple models like Long Short-Term Memory (LSTM),\nConvolution Neural Network (CNN) and Bidirectional Encoder Representations from\nTransformers (BERT) for emotion prediction with an average accuracy of 92%, and\n55% respectively. Further, using emotion predictions from CNN-LSTM, the\nbehavior module responds using facial expressions and gestures using Behavioral\nMarkup Language (BML). The accuracy of emotion-based behavior predictions is\nstatistically validated using the 2-tailed Pearson correlation on the data\ncollected from human users through questionnaires. Analysis shows that all\nemotion-based behaviors accurately depict human-like gestures and facial\nexpressions based on the significant correlation at the 0.01 and 0.05 levels.\nThis study is a steppingstone to a multi-faceted artificial agent interaction\nbased on emotion-oriented behaviors. Cognition has significance regarding\nsocial interaction among humans.",
            "author": [
                "Muhammad Arslan Raza",
                "Muhammad Shoaib Farooq",
                "Adel Khelifi",
                "Atif Alvi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14674v1",
                "http://arxiv.org/pdf/2311.14674v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18762v1",
            "title": "Purify++: Improving Diffusion-Purification with Advanced Diffusion\n  Models and Control of Randomness",
            "updated": "2023-10-28T17:18:38Z",
            "published": "2023-10-28T17:18:38Z",
            "summary": "Adversarial attacks can mislead neural network classifiers. The defense\nagainst adversarial attacks is important for AI safety. Adversarial\npurification is a family of approaches that defend adversarial attacks with\nsuitable pre-processing. Diffusion models have been shown to be effective for\nadversarial purification. Despite their success, many aspects of diffusion\npurification still remain unexplored. In this paper, we investigate and improve\nupon three limiting designs of diffusion purification: the use of an improved\ndiffusion model, advanced numerical simulation techniques, and optimal control\nof randomness. Based on our findings, we propose Purify++, a new diffusion\npurification algorithm that is now the state-of-the-art purification method\nagainst several adversarial attacks. Our work presents a systematic exploration\nof the limits of diffusion purification methods.",
            "author": [
                "Boya Zhang",
                "Weijian Luo",
                "Zhihua Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18762v1",
                "http://arxiv.org/pdf/2310.18762v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18760v2",
            "title": "Integration of persistent Laplacian and pre-trained transformer for\n  protein solubility changes upon mutation",
            "updated": "2023-11-02T20:19:28Z",
            "published": "2023-10-28T17:13:47Z",
            "summary": "Protein mutations can significantly influence protein solubility, which\nresults in altered protein functions and leads to various diseases. Despite of\ntremendous effort, machine learning prediction of protein solubility changes\nupon mutation remains a challenging task as indicated by the poor scores of\nnormalized Correct Prediction Ratio (CPR). Part of the challenge stems from the\nfact that there is no three-dimensional (3D) structures for the wild-type and\nmutant proteins. This work integrates persistent Laplacians and pre-trained\nTransformer for the task. The Transformer, pretrained with hunderds of millions\nof protein sequences, embeds wild-type and mutant sequences, while persistent\nLaplacians track the topological invariant change and homotopic shape evolution\ninduced by mutations in 3D protein structures, which are rendered from\nAlphaFold2. The resulting machine learning model was trained on an extensive\ndata set labeled with three solubility types. Our model outperforms all\nexisting predictive methods and improves the state-of-the-art up to 15%.",
            "author": [
                "JunJie Wee",
                "Jiahui Chen",
                "Kelin Xia",
                "Guo-Wei Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18760v2",
                "http://arxiv.org/pdf/2310.18760v2"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18743v1",
            "title": "Optimization of utility-based shortfall risk: A non-asymptotic viewpoint",
            "updated": "2023-10-28T15:57:58Z",
            "published": "2023-10-28T15:57:58Z",
            "summary": "We consider the problems of estimation and optimization of utility-based\nshortfall risk (UBSR), which is a popular risk measure in finance. In the\ncontext of UBSR estimation, we derive a non-asymptotic bound on the\nmean-squared error of the classical sample average approximation (SAA) of UBSR.\nNext, in the context of UBSR optimization, we derive an expression for the UBSR\ngradient under a smooth parameterization. This expression is a ratio of\nexpectations, both of which involve the UBSR. We use SAA for the numerator as\nwell as denominator in the UBSR gradient expression to arrive at a biased\ngradient estimator. We derive non-asymptotic bounds on the estimation error,\nwhich show that our gradient estimator is asymptotically unbiased. We\nincorporate the aforementioned gradient estimator into a stochastic gradient\n(SG) algorithm for UBSR optimization. Finally, we derive non-asymptotic bounds\nthat quantify the rate of convergence of our SG algorithm for UBSR\noptimization.",
            "author": [
                "Sumedh Gupte",
                "Prashanth L. A.",
                "Sanjay P. Bhat"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18743v1",
                "http://arxiv.org/pdf/2310.18743v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18741v1",
            "title": "On Training Implicit Meta-Learning With Applications to Inductive\n  Weighing in Consistency Regularization",
            "updated": "2023-10-28T15:50:03Z",
            "published": "2023-10-28T15:50:03Z",
            "summary": "Meta-learning that uses implicit gradient have provided an exciting\nalternative to standard techniques which depend on the trajectory of the inner\nloop training. Implicit meta-learning (IML), however, require computing\n$2^{nd}$ order gradients, particularly the Hessian which is impractical to\ncompute for modern deep learning models. Various approximations for the Hessian\nwere proposed but a systematic comparison of their compute cost, stability,\ngeneralization of solution found and estimation accuracy were largely\noverlooked. In this study, we start by conducting a systematic comparative\nanalysis of the various approximation methods and their effect when\nincorporated into IML training routines. We establish situations where\ncatastrophic forgetting is exhibited in IML and explain their cause in terms of\nthe inability of the approximations to estimate the curvature at convergence\npoints. Sources of IML training instability are demonstrated and remedied. A\ndetailed analysis of the effeciency of various inverse Hessian-vector product\napproximation methods is also provided. Subsequently, we use the insights\ngained to propose and evaluate a novel semi-supervised learning algorithm that\nlearns to inductively weigh consistency regularization losses. We show how\ntraining a \"Confidence Network\" to extract domain specific features can learn\nto up-weigh useful images and down-weigh out-of-distribution samples. Results\noutperform the baseline FixMatch performance.",
            "author": [
                "Fady Rezk"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18741v1",
                "http://arxiv.org/pdf/2310.18741v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18740v1",
            "title": "TraceDiag: Adaptive, Interpretable, and Efficient Root Cause Analysis on\n  Large-Scale Microservice Systems",
            "updated": "2023-10-28T15:49:00Z",
            "published": "2023-10-28T15:49:00Z",
            "summary": "Root Cause Analysis (RCA) is becoming increasingly crucial for ensuring the\nreliability of microservice systems. However, performing RCA on modern\nmicroservice systems can be challenging due to their large scale, as they\nusually comprise hundreds of components, leading significant human effort. This\npaper proposes TraceDiag, an end-to-end RCA framework that addresses the\nchallenges for large-scale microservice systems. It leverages reinforcement\nlearning to learn a pruning policy for the service dependency graph to\nautomatically eliminates redundant components, thereby significantly improving\nthe RCA efficiency. The learned pruning policy is interpretable and fully\nadaptive to new RCA instances. With the pruned graph, a causal-based method can\nbe executed with high accuracy and efficiency. The proposed TraceDiag framework\nis evaluated on real data traces collected from the Microsoft Exchange system,\nand demonstrates superior performance compared to state-of-the-art RCA\napproaches. Notably, TraceDiag has been integrated as a critical component in\nthe Microsoft M365 Exchange, resulting in a significant improvement in the\nsystem's reliability and a considerable reduction in the human effort required\nfor RCA.",
            "author": [
                "Ruomeng Ding",
                "Chaoyun Zhang",
                "Lu Wang",
                "Yong Xu",
                "Minghua Ma",
                "Xiaomin Wu",
                "Meng Zhang",
                "Qingjun Chen",
                "Xin Gao",
                "Xuedong Gao",
                "Hao Fan",
                "Saravan Rajmohan",
                "Qingwei Lin",
                "Dongmei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18740v1",
                "http://arxiv.org/pdf/2310.18740v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18738v1",
            "title": "TLM: Token-Level Masking for Transformers",
            "updated": "2023-10-28T15:42:47Z",
            "published": "2023-10-28T15:42:47Z",
            "summary": "Structured dropout approaches, such as attention dropout and DropHead, have\nbeen investigated to regularize the multi-head attention mechanism in\nTransformers. In this paper, we propose a new regularization scheme based on\ntoken-level rather than structure-level to reduce overfitting. Specifically, we\ndevise a novel Token-Level Masking (TLM) training strategy for Transformers to\nregularize the connections of self-attention, which consists of two masking\ntechniques that are effective and easy to implement. The underlying idea is to\nmanipulate the connections between tokens in the multi-head attention via\nmasking, where the networks are forced to exploit partial neighbors'\ninformation to produce a meaningful representation. The generality and\neffectiveness of TLM are thoroughly evaluated via extensive experiments on 4\ndiversified NLP tasks across 18 datasets, including natural language\nunderstanding benchmark GLUE, ChineseGLUE, Chinese Grammatical Error\nCorrection, and data-to-text generation. The results indicate that TLM can\nconsistently outperform attention dropout and DropHead, e.g., it increases by\n0.5 points relative to DropHead with BERT-large on GLUE. Moreover, TLM can\nestablish a new record on the data-to-text benchmark Rotowire (18.93 BLEU). Our\ncode will be publicly available at https://github.com/Young1993/tlm.",
            "author": [
                "Yangjun Wu",
                "Kebin Fang",
                "Dongxiang Zhang",
                "Han Wang",
                "Hao Zhang",
                "Gang Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18738v1",
                "http://arxiv.org/pdf/2310.18738v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18737v1",
            "title": "Pre-training with Random Orthogonal Projection Image Modeling",
            "updated": "2023-10-28T15:42:07Z",
            "published": "2023-10-28T15:42:07Z",
            "summary": "Masked Image Modeling (MIM) is a powerful self-supervised strategy for visual\npre-training without the use of labels. MIM applies random crops to input\nimages, processes them with an encoder, and then recovers the masked inputs\nwith a decoder, which encourages the network to capture and learn structural\ninformation about objects and scenes. The intermediate feature representations\nobtained from MIM are suitable for fine-tuning on downstream tasks. In this\npaper, we propose an Image Modeling framework based on random orthogonal\nprojection instead of binary masking as in MIM. Our proposed Random Orthogonal\nProjection Image Modeling (ROPIM) reduces spatially-wise token information\nunder guaranteed bound on the noise variance and can be considered as masking\nentire spatial image area under locally varying masking degrees. Since ROPIM\nuses a random subspace for the projection that realizes the masking step, the\nreadily available complement of the subspace can be used during unmasking to\npromote recovery of removed information. In this paper, we show that using\nrandom orthogonal projection leads to superior performance compared to\ncrop-based masking. We demonstrate state-of-the-art results on several popular\nbenchmarks.",
            "author": [
                "Maryam Haghighat",
                "Peyman Moghadam",
                "Shaheer Mohamed",
                "Piotr Koniusz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18737v1",
                "http://arxiv.org/pdf/2310.18737v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18735v1",
            "title": "Curriculum Learning for Graph Neural Networks: Which Edges Should We\n  Learn First",
            "updated": "2023-10-28T15:35:34Z",
            "published": "2023-10-28T15:35:34Z",
            "summary": "Graph Neural Networks (GNNs) have achieved great success in representing data\nwith dependencies by recursively propagating and aggregating messages along the\nedges. However, edges in real-world graphs often have varying degrees of\ndifficulty, and some edges may even be noisy to the downstream tasks.\nTherefore, existing GNNs may lead to suboptimal learned representations because\nthey usually treat every edge in the graph equally. On the other hand,\nCurriculum Learning (CL), which mimics the human learning principle of learning\ndata samples in a meaningful order, has been shown to be effective in improving\nthe generalization ability and robustness of representation learners by\ngradually proceeding from easy to more difficult samples during training.\nUnfortunately, existing CL strategies are designed for independent data samples\nand cannot trivially generalize to handle data dependencies. To address these\nissues, we propose a novel CL strategy to gradually incorporate more edges into\ntraining according to their difficulty from easy to hard, where the degree of\ndifficulty is measured by how well the edges are expected given the model\ntraining status. We demonstrate the strength of our proposed method in\nimproving the generalization ability and robustness of learned representations\nthrough extensive experiments on nine synthetic datasets and nine real-world\ndatasets. The code for our proposed method is available at\nhttps://github.com/rollingstonezz/Curriculum_learning_for_GNNs.",
            "author": [
                "Zheng Zhang",
                "Junxiang Wang",
                "Liang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18735v1",
                "http://arxiv.org/pdf/2310.18735v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18728v2",
            "title": "Debunking Free Fusion Myth: Online Multi-view Anomaly Detection with\n  Disentangled Product-of-Experts Modeling",
            "updated": "2023-10-31T22:52:08Z",
            "published": "2023-10-28T15:14:43Z",
            "summary": "Multi-view or even multi-modal data is appealing yet challenging for\nreal-world applications. Detecting anomalies in multi-view data is a prominent\nrecent research topic. However, most of the existing methods 1) are only\nsuitable for two views or type-specific anomalies, 2) suffer from the issue of\nfusion disentanglement, and 3) do not support online detection after model\ndeployment. To address these challenges, our main ideas in this paper are\nthree-fold: multi-view learning, disentangled representation learning, and\ngenerative model. To this end, we propose dPoE, a novel multi-view variational\nautoencoder model that involves (1) a Product-of-Experts (PoE) layer in\ntackling multi-view data, (2) a Total Correction (TC) discriminator in\ndisentangling view-common and view-specific representations, and (3) a joint\nloss function in wrapping up all components. In addition, we devise theoretical\ninformation bounds to control both view-common and view-specific\nrepresentations. Extensive experiments on six real-world datasets markedly\ndemonstrate that the proposed dPoE outperforms baselines.",
            "author": [
                "Hao Wang",
                "Zhi-Qi Cheng",
                "Jingdong Sun",
                "Xin Yang",
                "Xiao Wu",
                "Hongyang Chen",
                "Yan Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18728v2",
                "http://arxiv.org/pdf/2310.18728v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18727v1",
            "title": "Latent class analysis by regularized spectral clustering",
            "updated": "2023-10-28T15:09:08Z",
            "published": "2023-10-28T15:09:08Z",
            "summary": "The latent class model is a powerful tool for identifying latent classes\nwithin populations that share common characteristics for categorical data in\nsocial, psychological, and behavioral sciences. In this article, we propose two\nnew algorithms to estimate a latent class model for categorical data. Our\nalgorithms are developed by using a newly defined regularized Laplacian matrix\ncalculated from the response matrix. We provide theoretical convergence rates\nof our algorithms by considering a sparsity parameter and show that our\nalgorithms stably yield consistent latent class analysis under mild conditions.\nAdditionally, we propose a metric to capture the strength of latent class\nanalysis and several procedures designed based on this metric to infer how many\nlatent classes one should use for real-world categorical data. The efficiency\nand accuracy of our algorithms are verified by extensive simulated experiments,\nand we further apply our algorithms to real-world categorical data with\npromising results.",
            "author": [
                "Huan Qing"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18727v1",
                "http://arxiv.org/pdf/2310.18727v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18725v2",
            "title": "The Evolution of the Interplay Between Input Distributions and Linear\n  Regions in Networks",
            "updated": "2023-11-07T04:44:14Z",
            "published": "2023-10-28T15:04:53Z",
            "summary": "It is commonly recognized that the expressiveness of deep neural networks is\ncontingent upon a range of factors, encompassing their depth, width, and other\nrelevant considerations. Currently, the practical performance of the majority\nof deep neural networks remains uncertain. For ReLU (Rectified Linear Unit)\nnetworks with piecewise linear activations, the number of linear convex regions\nserves as a natural metric to gauge the network's expressivity. In this paper,\nwe count the number of linear convex regions in deep neural networks based on\nReLU. In particular, we prove that for any one-dimensional input, there exists\na minimum threshold for the number of neurons required to express it. We also\nempirically observe that for the same network, intricate inputs hinder its\ncapacity to express linear regions. Furthermore, we unveil the iterative\nrefinement process of decision boundaries in ReLU networks during training. We\naspire for our research to serve as an inspiration for network optimization\nendeavors and aids in the exploration and analysis of the behaviors exhibited\nby deep networks.",
            "author": [
                "Xuan Qi",
                "Yi Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18725v2",
                "http://arxiv.org/pdf/2310.18725v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18724v1",
            "title": "WCLD: Curated Large Dataset of Criminal Cases from Wisconsin Circuit\n  Courts",
            "updated": "2023-10-28T15:04:29Z",
            "published": "2023-10-28T15:04:29Z",
            "summary": "Machine learning based decision-support tools in criminal justice systems are\nsubjects of intense discussions and academic research. There are important open\nquestions about the utility and fairness of such tools. Academic researchers\noften rely on a few small datasets that are not sufficient to empirically study\nvarious real-world aspects of these questions. In this paper, we contribute\nWCLD, a curated large dataset of 1.5 million criminal cases from circuit courts\nin the U.S. state of Wisconsin. We used reliable public data from 1970 to 2020\nto curate attributes like prior criminal counts and recidivism outcomes. The\ndataset contains large number of samples from five racial groups, in addition\nto information like sex and age (at judgment and first offense). Other\nattributes in this dataset include neighborhood characteristics obtained from\ncensus data, detailed types of offense, charge severity, case decisions,\nsentence lengths, year of filing etc. We also provide pseudo-identifiers for\njudge, county and zipcode. The dataset will not only enable researchers to more\nrigorously study algorithmic fairness in the context of criminal justice, but\nalso relate algorithmic challenges with various systemic issues. We also\ndiscuss in detail the process of constructing the dataset and provide a\ndatasheet. The WCLD dataset is available at\n\\url{https://clezdata.github.io/wcld/}.",
            "author": [
                "Elliott Ash",
                "Naman Goel",
                "Nianyun Li",
                "Claudia Marangon",
                "Peiyao Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18724v1",
                "http://arxiv.org/pdf/2310.18724v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18717v1",
            "title": "On the Accuracy of Hotelling-Type Asymmetric Tensor Deflation: A Random\n  Tensor Analysis",
            "updated": "2023-10-28T14:40:10Z",
            "published": "2023-10-28T14:40:10Z",
            "summary": "This work introduces an asymptotic study of Hotelling-type tensor deflation\nin the presence of noise, in the regime of large tensor dimensions.\nSpecifically, we consider a low-rank asymmetric tensor model of the form\n$\\sum_{i=1}^r \\beta_i{\\mathcal{A}}_i + {\\mathcal{W}}$ where $\\beta_i\\geq 0$ and\nthe ${\\mathcal{A}}_i$'s are unit-norm rank-one tensors such that $\\left|\n\\langle {\\mathcal{A}}_i, {\\mathcal{A}}_j \\rangle \\right| \\in [0, 1]$ for $i\\neq\nj$ and ${\\mathcal{W}}$ is an additive noise term. Assuming that the dominant\ncomponents are successively estimated from the noisy observation and\nsubsequently subtracted, we leverage recent advances in random tensor theory in\nthe regime of asymptotically large tensor dimensions to analytically\ncharacterize the estimated singular values and the alignment of estimated and\ntrue singular vectors at each step of the deflation procedure. Furthermore,\nthis result can be used to construct estimators of the signal-to-noise ratios\n$\\beta_i$ and the alignments between the estimated and true rank-1 signal\ncomponents.",
            "author": [
                "Mohamed El Amine Seddik",
                "Maxime Guillaud",
                "Alexis Decurninge",
                "Jos\u00e9 Henrique de Morais Goulart"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18717v1",
                "http://arxiv.org/pdf/2310.18717v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18716v1",
            "title": "Laplacian Canonization: A Minimalist Approach to Sign and Basis\n  Invariant Spectral Embedding",
            "updated": "2023-10-28T14:35:10Z",
            "published": "2023-10-28T14:35:10Z",
            "summary": "Spectral embedding is a powerful graph embedding technique that has received\na lot of attention recently due to its effectiveness on Graph Transformers.\nHowever, from a theoretical perspective, the universal expressive power of\nspectral embedding comes at the price of losing two important invariance\nproperties of graphs, sign and basis invariance, which also limits its\neffectiveness on graph data. To remedy this issue, many previous methods\ndeveloped costly approaches to learn new invariants and suffer from high\ncomputation complexity. In this work, we explore a minimal approach that\nresolves the ambiguity issues by directly finding canonical directions for the\neigenvectors, named Laplacian Canonization (LC). As a pure pre-processing\nmethod, LC is light-weighted and can be applied to any existing GNNs. We\nprovide a thorough investigation, from theory to algorithm, on this approach,\nand discover an efficient algorithm named Maximal Axis Projection (MAP) that\nworks for both sign and basis invariance and successfully canonizes more than\n90% of all eigenvectors. Experiments on real-world benchmark datasets like\nZINC, MOLTOX21, and MOLPCBA show that MAP consistently outperforms existing\nmethods while bringing minimal computation overhead. Code is available at\nhttps://github.com/PKU-ML/LaplacianCanonization.",
            "author": [
                "Jiangyan Ma",
                "Yifei Wang",
                "Yisen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18716v1",
                "http://arxiv.org/pdf/2310.18716v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18715v1",
            "title": "Robust Offline Policy Evaluation and Optimization with Heavy-Tailed\n  Rewards",
            "updated": "2023-10-28T14:24:26Z",
            "published": "2023-10-28T14:24:26Z",
            "summary": "This paper endeavors to augment the robustness of offline reinforcement\nlearning (RL) in scenarios laden with heavy-tailed rewards, a prevalent\ncircumstance in real-world applications. We propose two algorithmic frameworks,\nROAM and ROOM, for robust off-policy evaluation (OPE) and offline policy\noptimization (OPO), respectively. Central to our frameworks is the strategic\nincorporation of the median-of-means method with offline RL, enabling\nstraightforward uncertainty estimation for the value function estimator. This\nnot only adheres to the principle of pessimism in OPO but also adeptly manages\nheavy-tailed rewards. Theoretical results and extensive experiments demonstrate\nthat our two frameworks outperform existing methods on the logged dataset\nexhibits heavy-tailed reward distributions.",
            "author": [
                "Jin Zhu",
                "Runzhe Wan",
                "Zhengling Qi",
                "Shikai Luo",
                "Chengchun Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18715v1",
                "http://arxiv.org/pdf/2310.18715v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18713v1",
            "title": "Episodic Multi-Task Learning with Heterogeneous Neural Processes",
            "updated": "2023-10-28T14:12:40Z",
            "published": "2023-10-28T14:12:40Z",
            "summary": "This paper focuses on the data-insufficiency problem in multi-task learning\nwithin an episodic training setup. Specifically, we explore the potential of\nheterogeneous information across tasks and meta-knowledge among episodes to\neffectively tackle each task with limited data. Existing meta-learning methods\noften fail to take advantage of crucial heterogeneous information in a single\nepisode, while multi-task learning models neglect reusing experience from\nearlier episodes. To address the problem of insufficient data, we develop\nHeterogeneous Neural Processes (HNPs) for the episodic multi-task setup. Within\nthe framework of hierarchical Bayes, HNPs effectively capitalize on prior\nexperiences as meta-knowledge and capture task-relatedness among heterogeneous\ntasks, mitigating data-insufficiency. Meanwhile, transformer-structured\ninference modules are designed to enable efficient inferences toward\nmeta-knowledge and task-relatedness. In this way, HNPs can learn more powerful\nfunctional priors for adapting to novel heterogeneous tasks in each meta-test\nepisode. Experimental results show the superior performance of the proposed\nHNPs over typical baselines, and ablation studies verify the effectiveness of\nthe designed inference modules.",
            "author": [
                "Jiayi Shen",
                "Xiantong Zhen",
                "Qi",
                "Wang",
                "Marcel Worring"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18713v1",
                "http://arxiv.org/pdf/2310.18713v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18709v1",
            "title": "Audio-Visual Instance Segmentation",
            "updated": "2023-10-28T13:37:52Z",
            "published": "2023-10-28T13:37:52Z",
            "summary": "In this paper, we propose a new multi-modal task, namely audio-visual\ninstance segmentation (AVIS), in which the goal is to identify, segment, and\ntrack individual sounding object instances in audible videos, simultaneously.\nTo our knowledge, it is the first time that instance segmentation has been\nextended into the audio-visual domain. To better facilitate this research, we\nconstruct the first audio-visual instance segmentation benchmark (AVISeg).\nSpecifically, AVISeg consists of 1,258 videos with an average duration of 62.6\nseconds from YouTube and public audio-visual datasets, where 117 videos have\nbeen annotated by using an interactive semi-automatic labeling tool based on\nthe Segment Anything Model (SAM). In addition, we present a simple baseline\nmodel for the AVIS task. Our new model introduces an audio branch and a\ncross-modal fusion module to Mask2Former to locate all sounding objects.\nFinally, we evaluate the proposed method using two backbones on AVISeg. We\nbelieve that AVIS will inspire the community towards a more comprehensive\nmulti-modal understanding.",
            "author": [
                "Ruohao Guo",
                "Yaru Chen",
                "Yanyu Qi",
                "Wenzhen Yue",
                "Dantong Niu",
                "Xianghua Ying"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18709v1",
                "http://arxiv.org/pdf/2310.18709v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.MM",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18706v1",
            "title": "ALERTA-Net: A Temporal Distance-Aware Recurrent Networks for Stock\n  Movement and Volatility Prediction",
            "updated": "2023-10-28T13:31:39Z",
            "published": "2023-10-28T13:31:39Z",
            "summary": "For both investors and policymakers, forecasting the stock market is\nessential as it serves as an indicator of economic well-being. To this end, we\nharness the power of social media data, a rich source of public sentiment, to\nenhance the accuracy of stock market predictions. Diverging from conventional\nmethods, we pioneer an approach that integrates sentiment analysis,\nmacroeconomic indicators, search engine data, and historical prices within a\nmulti-attention deep learning model, masterfully decoding the complex patterns\ninherent in the data. We showcase the state-of-the-art performance of our\nproposed model using a dataset, specifically curated by us, for predicting\nstock market movements and volatility.",
            "author": [
                "Shengkun Wang",
                "YangXiao Bai",
                "Kaiqun Fu",
                "Linhan Wang",
                "Chang-Tien Lu",
                "Taoran Ji"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3625007.3627488",
                "http://arxiv.org/abs/2310.18706v1",
                "http://arxiv.org/pdf/2310.18706v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19831v1",
            "title": "Explaining by Imitating: Understanding Decisions by Interpretable Policy\n  Learning",
            "updated": "2023-10-28T13:06:14Z",
            "published": "2023-10-28T13:06:14Z",
            "summary": "Understanding human behavior from observed data is critical for transparency\nand accountability in decision-making. Consider real-world settings such as\nhealthcare, in which modeling a decision-maker's policy is challenging -- with\nno access to underlying states, no knowledge of environment dynamics, and no\nallowance for live experimentation. We desire learning a data-driven\nrepresentation of decision-making behavior that (1) inheres transparency by\ndesign, (2) accommodates partial observability, and (3) operates completely\noffline. To satisfy these key criteria, we propose a novel model-based Bayesian\nmethod for interpretable policy learning (\"Interpole\") that jointly estimates\nan agent's (possibly biased) belief-update process together with their\n(possibly suboptimal) belief-action mapping. Through experiments on both\nsimulated and real-world data for the problem of Alzheimer's disease diagnosis,\nwe illustrate the potential of our approach as an investigative device for\nauditing, quantifying, and understanding human decision-making behavior.",
            "author": [
                "Alihan H\u00fcy\u00fck",
                "Daniel Jarrett",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19831v1",
                "http://arxiv.org/pdf/2310.19831v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18703v1",
            "title": "Detangling the role of climate in vegetation productivity with an\n  explainable convolutional neural network",
            "updated": "2023-10-28T13:04:30Z",
            "published": "2023-10-28T13:04:30Z",
            "summary": "Forests of the Earth are a vital carbon sink while providing an essential\nhabitat for biodiversity. Vegetation productivity (VP) is a critical indicator\nof carbon uptake in the atmosphere. The leaf area index is a crucial vegetation\nindex used in VP estimation. This work proposes to predict the leaf area index\n(LAI) using climate variables to better understand future productivity\ndynamics; our approach leverages the capacities of the V-Net architecture for\nspatiotemporal LAI prediction. Preliminary results are well-aligned with\nestablished quality standards of LAI products estimated from Earth observation\ndata. We hope that this work serves as a robust foundation for subsequent\nresearch endeavours, particularly for the incorporation of prediction\nattribution methodologies, which hold promise for elucidating the underlying\nclimate change drivers of global vegetation productivity.",
            "author": [
                "Ricardo Barros Louren\u00e7o",
                "Michael J. Smith",
                "Sylvia Smullin",
                "Umangi Jain",
                "Alemu Gonsamo",
                "Arthur Ouaknine"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18703v1",
                "http://arxiv.org/pdf/2310.18703v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18702v1",
            "title": "Towards Combinatorial Generalization for Catalysts: A Kohn-Sham\n  Charge-Density Approach",
            "updated": "2023-10-28T13:04:05Z",
            "published": "2023-10-28T13:04:05Z",
            "summary": "The Kohn-Sham equations underlie many important applications such as the\ndiscovery of new catalysts. Recent machine learning work on catalyst modeling\nhas focused on prediction of the energy, but has so far not yet demonstrated\nsignificant out-of-distribution generalization. Here we investigate another\napproach based on the pointwise learning of the Kohn-Sham charge-density. On a\nnew dataset of bulk catalysts with charge densities, we show density models can\ngeneralize to new structures with combinations of elements not seen at train\ntime, a form of combinatorial generalization. We show that over 80% of binary\nand ternary test cases achieve faster convergence than standard baselines in\nDensity Functional Theory, amounting to an average reduction of 13% in the\nnumber of iterations required to reach convergence, which may be of independent\ninterest. Our results suggest that density learning is a viable alternative,\ntrading greater inference costs for a step towards combinatorial\ngeneralization, a key property for applications.",
            "author": [
                "Phillip Pope",
                "David Jacobs"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18702v1",
                "http://arxiv.org/pdf/2310.18702v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18701v1",
            "title": "Efficient Algorithms for Generalized Linear Bandits with Heavy-tailed\n  Rewards",
            "updated": "2023-10-28T13:01:10Z",
            "published": "2023-10-28T13:01:10Z",
            "summary": "This paper investigates the problem of generalized linear bandits with\nheavy-tailed rewards, whose $(1+\\epsilon)$-th moment is bounded for some\n$\\epsilon\\in (0,1]$. Although there exist methods for generalized linear\nbandits, most of them focus on bounded or sub-Gaussian rewards and are not\nwell-suited for many real-world scenarios, such as financial markets and\nweb-advertising. To address this issue, we propose two novel algorithms based\non truncation and mean of medians. These algorithms achieve an almost optimal\nregret bound of $\\widetilde{O}(dT^{\\frac{1}{1+\\epsilon}})$, where $d$ is the\ndimension of contextual information and $T$ is the time horizon. Our\ntruncation-based algorithm supports online learning, distinguishing it from\nexisting truncation-based approaches. Additionally, our mean-of-medians-based\nalgorithm requires only $O(\\log T)$ rewards and one estimator per epoch, making\nit more practical. Moreover, our algorithms improve the regret bounds by a\nlogarithmic factor compared to existing algorithms when $\\epsilon=1$. Numerical\nexperimental results confirm the merits of our algorithms.",
            "author": [
                "Bo Xue",
                "Yimu Wang",
                "Yuanyu Wan",
                "Jinfeng Yi",
                "Lijun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18701v1",
                "http://arxiv.org/pdf/2310.18701v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18700v1",
            "title": "Empowering Collaborative Filtering with Principled Adversarial\n  Contrastive Loss",
            "updated": "2023-10-28T12:57:39Z",
            "published": "2023-10-28T12:57:39Z",
            "summary": "Contrastive Learning (CL) has achieved impressive performance in\nself-supervised learning tasks, showing superior generalization ability.\nInspired by the success, adopting CL into collaborative filtering (CF) is\nprevailing in semi-supervised top-K recommendations. The basic idea is to\nroutinely conduct heuristic-based data augmentation and apply contrastive\nlosses (e.g., InfoNCE) on the augmented views. Yet, some CF-tailored challenges\nmake this adoption suboptimal, such as the issue of out-of-distribution, the\nrisk of false negatives, and the nature of top-K evaluation. They necessitate\nthe CL-based CF scheme to focus more on mining hard negatives and\ndistinguishing false negatives from the vast unlabeled user-item interactions,\nfor informative contrast signals. Worse still, there is limited understanding\nof contrastive loss in CF methods, especially w.r.t. its generalization\nability. To bridge the gap, we delve into the reasons underpinning the success\nof contrastive loss in CF, and propose a principled Adversarial InfoNCE loss\n(AdvInfoNCE), which is a variant of InfoNCE, specially tailored for CF methods.\nAdvInfoNCE adaptively explores and assigns hardness to each negative instance\nin an adversarial fashion and further utilizes a fine-grained hardness-aware\nranking criterion to empower the recommender's generalization ability. Training\nCF models with AdvInfoNCE, we validate the effectiveness of AdvInfoNCE on both\nsynthetic and real-world benchmark datasets, thus showing its generalization\nability to mitigate out-of-distribution problems. Given the theoretical\nguarantees and empirical superiority of AdvInfoNCE over most contrastive loss\nfunctions, we advocate its adoption as a standard loss in recommender systems,\nparticularly for the out-of-distribution tasks. Codes are available at\nhttps://github.com/LehengTHU/AdvInfoNCE.",
            "author": [
                "An Zhang",
                "Leheng Sheng",
                "Zhibo Cai",
                "Xiang Wang",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18700v1",
                "http://arxiv.org/pdf/2310.18700v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18698v1",
            "title": "Triplet Attention Transformer for Spatiotemporal Predictive Learning",
            "updated": "2023-10-28T12:49:33Z",
            "published": "2023-10-28T12:49:33Z",
            "summary": "Spatiotemporal predictive learning offers a self-supervised learning paradigm\nthat enables models to learn both spatial and temporal patterns by predicting\nfuture sequences based on historical sequences. Mainstream methods are\ndominated by recurrent units, yet they are limited by their lack of\nparallelization and often underperform in real-world scenarios. To improve\nprediction quality while maintaining computational efficiency, we propose an\ninnovative triplet attention transformer designed to capture both inter-frame\ndynamics and intra-frame static features. Specifically, the model incorporates\nthe Triplet Attention Module (TAM), which replaces traditional recurrent units\nby exploring self-attention mechanisms in temporal, spatial, and channel\ndimensions. In this configuration: (i) temporal tokens contain abstract\nrepresentations of inter-frame, facilitating the capture of inherent temporal\ndependencies; (ii) spatial and channel attention combine to refine the\nintra-frame representation by performing fine-grained interactions across\nspatial and channel dimensions. Alternating temporal, spatial, and\nchannel-level attention allows our approach to learn more complex short- and\nlong-range spatiotemporal dependencies. Extensive experiments demonstrate\nperformance surpassing existing recurrent-based and recurrent-free methods,\nachieving state-of-the-art under multi-scenario examination including moving\nobject trajectory prediction, traffic flow prediction, driving scene\nprediction, and human motion capture.",
            "author": [
                "Xuesong Nie",
                "Xi Chen",
                "Haoyuan Jin",
                "Zhihang Zhu",
                "Yunfeng Yan",
                "Donglian Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18698v1",
                "http://arxiv.org/pdf/2310.18698v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18696v1",
            "title": "Probing LLMs for Joint Encoding of Linguistic Categories",
            "updated": "2023-10-28T12:46:40Z",
            "published": "2023-10-28T12:46:40Z",
            "summary": "Large Language Models (LLMs) exhibit impressive performance on a range of NLP\ntasks, due to the general-purpose linguistic knowledge acquired during\npretraining. Existing model interpretability research (Tenney et al., 2019)\nsuggests that a linguistic hierarchy emerges in the LLM layers, with lower\nlayers better suited to solving syntactic tasks and higher layers employed for\nsemantic processing. Yet, little is known about how encodings of different\nlinguistic phenomena interact within the models and to what extent processing\nof linguistically-related categories relies on the same, shared model\nrepresentations. In this paper, we propose a framework for testing the joint\nencoding of linguistic categories in LLMs. Focusing on syntax, we find evidence\nof joint encoding both at the same (related part-of-speech (POS) classes) and\ndifferent (POS classes and related syntactic dependency relations) levels of\nlinguistic hierarchy. Our cross-lingual experiments show that the same patterns\nhold across languages in multilingual LLMs.",
            "author": [
                "Giulio Starace",
                "Konstantinos Papakostas",
                "Rochelle Choenni",
                "Apostolos Panagiotopoulos",
                "Matteo Rosati",
                "Alina Leidinger",
                "Ekaterina Shutova"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18696v1",
                "http://arxiv.org/pdf/2310.18696v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18689v1",
            "title": "Foundational Models in Medical Imaging: A Comprehensive Survey and\n  Future Vision",
            "updated": "2023-10-28T12:08:12Z",
            "published": "2023-10-28T12:08:12Z",
            "summary": "Foundation models, large-scale, pre-trained deep-learning models adapted to a\nwide range of downstream tasks have gained significant interest lately in\nvarious deep-learning problems undergoing a paradigm shift with the rise of\nthese models. Trained on large-scale dataset to bridge the gap between\ndifferent modalities, foundation models facilitate contextual reasoning,\ngeneralization, and prompt capabilities at test time. The predictions of these\nmodels can be adjusted for new tasks by augmenting the model input with\ntask-specific hints called prompts without requiring extensive labeled data and\nretraining. Capitalizing on the advances in computer vision, medical imaging\nhas also marked a growing interest in these models. To assist researchers in\nnavigating this direction, this survey intends to provide a comprehensive\noverview of foundation models in the domain of medical imaging. Specifically,\nwe initiate our exploration by providing an exposition of the fundamental\nconcepts forming the basis of foundation models. Subsequently, we offer a\nmethodical taxonomy of foundation models within the medical domain, proposing a\nclassification system primarily structured around training strategies, while\nalso incorporating additional facets such as application domains, imaging\nmodalities, specific organs of interest, and the algorithms integral to these\nmodels. Furthermore, we emphasize the practical use case of some selected\napproaches and then discuss the opportunities, applications, and future\ndirections of these large-scale pre-trained models, for analyzing medical\nimages. In the same vein, we address the prevailing challenges and research\npathways associated with foundational models in medical imaging. These\nencompass the areas of interpretability, data management, computational\nrequirements, and the nuanced issue of contextual comprehension.",
            "author": [
                "Bobby Azad",
                "Reza Azad",
                "Sania Eskandari",
                "Afshin Bozorgpour",
                "Amirhossein Kazerouni",
                "Islem Rekik",
                "Dorit Merhof"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18689v1",
                "http://arxiv.org/pdf/2310.18689v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18688v1",
            "title": "Clairvoyance: A Pipeline Toolkit for Medical Time Series",
            "updated": "2023-10-28T12:08:03Z",
            "published": "2023-10-28T12:08:03Z",
            "summary": "Time-series learning is the bread and butter of data-driven *clinical\ndecision support*, and the recent explosion in ML research has demonstrated\ngreat potential in various healthcare settings. At the same time, medical\ntime-series problems in the wild are challenging due to their highly\n*composite* nature: They entail design choices and interactions among\ncomponents that preprocess data, impute missing values, select features, issue\npredictions, estimate uncertainty, and interpret models. Despite exponential\ngrowth in electronic patient data, there is a remarkable gap between the\npotential and realized utilization of ML for clinical research and decision\nsupport. In particular, orchestrating a real-world project lifecycle poses\nchallenges in engineering (i.e. hard to build), evaluation (i.e. hard to\nassess), and efficiency (i.e. hard to optimize). Designed to address these\nissues simultaneously, Clairvoyance proposes a unified, end-to-end,\nautoML-friendly pipeline that serves as a (i) software toolkit, (ii) empirical\nstandard, and (iii) interface for optimization. Our ultimate goal lies in\nfacilitating transparent and reproducible experimentation with complex\ninference workflows, providing integrated pathways for (1) personalized\nprediction, (2) treatment-effect estimation, and (3) information acquisition.\nThrough illustrative examples on real-world data in outpatient, general wards,\nand intensive-care settings, we illustrate the applicability of the pipeline\nparadigm on core tasks in the healthcare journey. To the best of our knowledge,\nClairvoyance is the first to demonstrate viability of a comprehensive and\nautomatable pipeline for clinical time-series ML.",
            "author": [
                "Daniel Jarrett",
                "Jinsung Yoon",
                "Ioana Bica",
                "Zhaozhi Qian",
                "Ari Ercole",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18688v1",
                "http://arxiv.org/pdf/2310.18688v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18687v1",
            "title": "Unsupervised Behavior Extraction via Random Intent Priors",
            "updated": "2023-10-28T12:03:34Z",
            "published": "2023-10-28T12:03:34Z",
            "summary": "Reward-free data is abundant and contains rich prior knowledge of human\nbehaviors, but it is not well exploited by offline reinforcement learning (RL)\nalgorithms. In this paper, we propose UBER, an unsupervised approach to extract\nuseful behaviors from offline reward-free datasets via diversified rewards.\nUBER assigns different pseudo-rewards sampled from a given prior distribution\nto different agents to extract a diverse set of behaviors, and reuse them as\ncandidate policies to facilitate the learning of new tasks. Perhaps\nsurprisingly, we show that rewards generated from random neural networks are\nsufficient to extract diverse and useful behaviors, some even close to expert\nones. We provide both empirical and theoretical evidence to justify the use of\nrandom priors for the reward function. Experiments on multiple benchmarks\nshowcase UBER's ability to learn effective and diverse behavior sets that\nenhance sample efficiency for online RL, outperforming existing baselines. By\nreducing reliance on human supervision, UBER broadens the applicability of RL\nto real-world scenarios with abundant reward-free data.",
            "author": [
                "Hao Hu",
                "Yiqin Yang",
                "Jianing Ye",
                "Ziqing Mai",
                "Chongjie Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18687v1",
                "http://arxiv.org/pdf/2310.18687v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18681v1",
            "title": "DySurv: Dynamic Deep Learning Model for Survival Prediction in the ICU",
            "updated": "2023-10-28T11:29:09Z",
            "published": "2023-10-28T11:29:09Z",
            "summary": "Survival analysis helps approximate underlying distributions of\ntime-to-events which in the case of critical care like in the ICU can be a\npowerful tool for dynamic mortality risk prediction. Extending beyond the\nclassical Cox model, deep learning techniques have been leveraged over the last\nyears relaxing the many constraints of their counterparts from statistical\nmethods. In this work, we propose a novel conditional variational\nautoencoder-based method called DySurv which uses a combination of static and\ntime-series measurements from patient electronic health records in estimating\nrisk of death dynamically in the ICU. DySurv has been tested on standard\nbenchmarks where it outperforms most existing methods including other deep\nlearning methods and we evaluate it on a real-world patient database from\nMIMIC-IV. The predictive capacity of DySurv is consistent and the survival\nestimates remain disentangled across different datasets supporting the idea\nthat dynamic deep learning models based on conditional variational inference in\nmulti-task cases can be robust models for survival analysis.",
            "author": [
                "Munib Mesinovic",
                "Peter Watkinson",
                "Tingting Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18681v1",
                "http://arxiv.org/pdf/2310.18681v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18679v2",
            "title": "N-Critics: Self-Refinement of Large Language Models with Ensemble of\n  Critics",
            "updated": "2023-11-08T13:23:20Z",
            "published": "2023-10-28T11:22:22Z",
            "summary": "We propose a self-correction mechanism for Large Language Models (LLMs) to\nmitigate issues such as toxicity and fact hallucination. This method involves\nrefining model outputs through an ensemble of critics and the model's own\nfeedback. Drawing inspiration from human behavior, we explore whether LLMs can\nemulate the self-correction process observed in humans who often engage in\nself-reflection and seek input from others to refine their understanding of\ncomplex topics. Our approach is model-agnostic and can be applied across\nvarious domains to enhance trustworthiness by addressing fairness, bias, and\nrobustness concerns. We consistently observe performance improvements in LLMs\nfor reducing toxicity and correcting factual errors.",
            "author": [
                "Sajad Mousavi",
                "Ricardo Luna Guti\u00e9rrez",
                "Desik Rengarajan",
                "Vineet Gundecha",
                "Ashwin Ramesh Babu",
                "Avisek Naug",
                "Antonio Guillen",
                "Soumyendu Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18679v2",
                "http://arxiv.org/pdf/2310.18679v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18677v1",
            "title": "Energy-Based Models for Anomaly Detection: A Manifold Diffusion Recovery\n  Approach",
            "updated": "2023-10-28T11:18:39Z",
            "published": "2023-10-28T11:18:39Z",
            "summary": "We present a new method of training energy-based models (EBMs) for anomaly\ndetection that leverages low-dimensional structures within data. The proposed\nalgorithm, Manifold Projection-Diffusion Recovery (MPDR), first perturbs a data\npoint along a low-dimensional manifold that approximates the training dataset.\nThen, EBM is trained to maximize the probability of recovering the original\ndata. The training involves the generation of negative samples via MCMC, as in\nconventional EBM training, but from a different distribution concentrated near\nthe manifold. The resulting near-manifold negative samples are highly\ninformative, reflecting relevant modes of variation in data. An energy function\nof MPDR effectively learns accurate boundaries of the training data\ndistribution and excels at detecting out-of-distribution samples. Experimental\nresults show that MPDR exhibits strong performance across various anomaly\ndetection tasks involving diverse data types, such as images, vectors, and\nacoustic signals.",
            "author": [
                "Sangwoong Yoon",
                "Young-Uk Jin",
                "Yung-Kyun Noh",
                "Frank C. Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18677v1",
                "http://arxiv.org/pdf/2310.18677v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18672v1",
            "title": "Maximum Independent Set: Self-Training through Dynamic Programming",
            "updated": "2023-10-28T10:58:25Z",
            "published": "2023-10-28T10:58:25Z",
            "summary": "This work presents a graph neural network (GNN) framework for solving the\nmaximum independent set (MIS) problem, inspired by dynamic programming (DP).\nSpecifically, given a graph, we propose a DP-like recursive algorithm based on\nGNNs that firstly constructs two smaller sub-graphs, predicts the one with the\nlarger MIS, and then uses it in the next recursive call. To train our\nalgorithm, we require annotated comparisons of different graphs concerning\ntheir MIS size. Annotating the comparisons with the output of our algorithm\nleads to a self-training process that results in more accurate self-annotation\nof the comparisons and vice versa. We provide numerical evidence showing the\nsuperiority of our method vs prior methods in multiple synthetic and real-world\ndatasets.",
            "author": [
                "Lorenzo Brusca",
                "Lars C. P. M. Quaedvlieg",
                "Stratis Skoulakis",
                "Grigorios G Chrysos",
                "Volkan Cevher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18672v1",
                "http://arxiv.org/pdf/2310.18672v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18660v2",
            "title": "Foundation Models for Generalist Geospatial Artificial Intelligence",
            "updated": "2023-11-08T18:25:24Z",
            "published": "2023-10-28T10:19:55Z",
            "summary": "Significant progress in the development of highly adaptable and reusable\nArtificial Intelligence (AI) models is expected to have a significant impact on\nEarth science and remote sensing. Foundation models are pre-trained on large\nunlabeled datasets through self-supervision, and then fine-tuned for various\ndownstream tasks with small labeled datasets. This paper introduces a\nfirst-of-a-kind framework for the efficient pre-training and fine-tuning of\nfoundational models on extensive geospatial data. We have utilized this\nframework to create Prithvi, a transformer-based geospatial foundational model\npre-trained on more than 1TB of multispectral satellite imagery from the\nHarmonized Landsat-Sentinel 2 (HLS) dataset. Our study demonstrates the\nefficacy of our framework in successfully fine-tuning Prithvi to a range of\nEarth observation tasks that have not been tackled by previous work on\nfoundation models involving multi-temporal cloud gap imputation, flood mapping,\nwildfire scar segmentation, and multi-temporal crop segmentation. Our\nexperiments show that the pre-trained model accelerates the fine-tuning process\ncompared to leveraging randomly initialized weights. In addition, pre-trained\nPrithvi compares well against the state-of-the-art, e.g., outperforming a\nconditional GAN model in multi-temporal cloud imputation by up to 5pp (or 5.7%)\nin the structural similarity index. Finally, due to the limited availability of\nlabeled data in the field of Earth observation, we gradually reduce the\nquantity of available labeled data for refining the model to evaluate data\nefficiency and demonstrate that data can be decreased significantly without\naffecting the model's accuracy. The pre-trained 100 million parameter model and\ncorresponding fine-tuning workflows have been released publicly as open source\ncontributions to the global Earth sciences community through Hugging Face.",
            "author": [
                "Johannes Jakubik",
                "Sujit Roy",
                "C. E. Phillips",
                "Paolo Fraccaro",
                "Denys Godwin",
                "Bianca Zadrozny",
                "Daniela Szwarcman",
                "Carlos Gomes",
                "Gabby Nyirjesy",
                "Blair Edwards",
                "Daiki Kimura",
                "Naomi Simumba",
                "Linsong Chu",
                "S. Karthik Mukkavilli",
                "Devyani Lambhate",
                "Kamal Das",
                "Ranjini Bangalore",
                "Dario Oliveira",
                "Michal Muszynski",
                "Kumar Ankur",
                "Muthukumaran Ramasubramanian",
                "Iksha Gurung",
                "Sam Khallaghi",
                "Hanxi",
                "Li",
                "Michael Cecil",
                "Maryam Ahmadi",
                "Fatemeh Kordi",
                "Hamed Alemohammad",
                "Manil Maskey",
                "Raghu Ganti",
                "Kommy Weldemariam",
                "Rahul Ramachandran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18660v2",
                "http://arxiv.org/pdf/2310.18660v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18655v1",
            "title": "Systematic Improvement of Empirical Energy Functions in the Era of\n  Machine Learning",
            "updated": "2023-10-28T09:50:49Z",
            "published": "2023-10-28T09:50:49Z",
            "summary": "The impact of targeted replacement of individual terms in empirical force\nfields is quantitatively assessed for pure water, dichloromethane (DCM), and\nsolvated K$^+$ and Cl$^-$ ions. For the electrostatics, point charges (PCs) and\nmachine learning (ML)based minimally distributed charges (MDCM) fitted to the\nmolecular electrostatic potential are evaluated together with electrostatics\nbased on the Coulomb integral. The impact of explicitly including second-order\nterms is investigated by adding a fragment molecular orbital (FMO)-derived\npolarization energy to an existing force field, in this case CHARMM. It is\ndemonstrated that anisotropic electrostatics reduce the RMSE for water (by 1.6\nkcal/mol), DCM (by 0.8 kcal/mol) and for solvated Cl$^-$ clusters (by 0.4\nkcal/mol). An additional polarization term can be neglected for DCM but notably\nimproves errors in pure water (by 1.1 kcal/mol) and in Cl$^-$ clusters (by 0.4\nkcal/mol) and is key to describing solvated K$^+$, reducing the RMSE by 2.3\nkcal/mol. A 12-6 Lennard-Jones functional form is found to perform\nsatisfactorily with PC and MDCM electrostatics, but is not appropriate for\ndescriptions that account for the electrostatic penetration energy. The\nimportance of many-body contributions is assessed by comparing a strictly\n2-body approach with self-consistent reference data. DCM can be approximated\nwell with a 2-body potential while water and solvated K$^+$ and Cl$^-$ ions\nrequire explicit many-body corrections. The present work systematically\nquantifies which terms improve the performance of an existing force field and\nwhat reference data to use for parametrizing these terms in a tractable fashion\nfor ML fitting of pure and heterogeneous systems.",
            "author": [
                "Mike Devereux",
                "Eric D. Boittier",
                "Markus Meuwly"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18655v1",
                "http://arxiv.org/pdf/2310.18655v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "physics.atm-clus"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18654v1",
            "title": "Causal discovery in a complex industrial system: A time series benchmark",
            "updated": "2023-10-28T09:47:02Z",
            "published": "2023-10-28T09:47:02Z",
            "summary": "Causal discovery outputs a causal structure, represented by a graph, from\nobserved data. For time series data, there is a variety of methods, however, it\nis difficult to evaluate these on real data as realistic use cases very rarely\ncome with a known causal graph to which output can be compared. In this paper,\nwe present a dataset from an industrial subsystem at the European Spallation\nSource along with its causal graph which has been constructed from expert\nknowledge. This provides a testbed for causal discovery from time series\nobservations of complex systems, and we believe this can help inform the\ndevelopment of causal discovery methodology.",
            "author": [
                "S\u00f8ren Wengel Mogensen",
                "Karin Rathsman",
                "Per Nilsson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18654v1",
                "http://arxiv.org/pdf/2310.18654v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18653v1",
            "title": "Feature Guided Masked Autoencoder for Self-supervised Learning in Remote\n  Sensing",
            "updated": "2023-10-28T09:43:13Z",
            "published": "2023-10-28T09:43:13Z",
            "summary": "Self-supervised learning guided by masked image modelling, such as Masked\nAutoEncoder (MAE), has attracted wide attention for pretraining vision\ntransformers in remote sensing. However, MAE tends to excessively focus on\npixel details, thereby limiting the model's capacity for semantic\nunderstanding, in particular for noisy SAR images. In this paper, we explore\nspectral and spatial remote sensing image features as improved\nMAE-reconstruction targets. We first conduct a study on reconstructing various\nimage features, all performing comparably well or better than raw pixels. Based\non such observations, we propose Feature Guided Masked Autoencoder (FG-MAE):\nreconstructing a combination of Histograms of Oriented Graidents (HOG) and\nNormalized Difference Indices (NDI) for multispectral images, and\nreconstructing HOG for SAR images. Experimental results on three downstream\ntasks illustrate the effectiveness of FG-MAE with a particular boost for SAR\nimagery. Furthermore, we demonstrate the well-inherited scalability of FG-MAE\nand release a first series of pretrained vision transformers for medium\nresolution SAR and multispectral images.",
            "author": [
                "Yi Wang",
                "Hugo Hern\u00e1ndez Hern\u00e1ndez",
                "Conrad M Albrecht",
                "Xiao Xiang Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18653v1",
                "http://arxiv.org/pdf/2310.18653v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18651v3",
            "title": "LG-Self: Local-Global Self-Supervised Visual Representation Learning",
            "updated": "2023-11-07T07:02:59Z",
            "published": "2023-10-28T09:35:30Z",
            "summary": "Self-supervised representation learning methods mainly focus on image-level\ninstance discrimination. This study explores the potential benefits of\nincorporating patch-level discrimination into existing methods to enhance the\nquality of learned representations by simultaneously looking at local and\nglobal visual features. Towards this idea, we present a straightforward yet\neffective patch-matching algorithm that can find the corresponding patches\nacross the augmented views of an image. The augmented views are subsequently\nfed into a self-supervised learning framework employing Vision Transformer\n(ViT) as its backbone. The result is the generation of both image-level and\npatch-level representations. Leveraging the proposed patch-matching algorithm,\nthe model minimizes the representation distance between not only the CLS tokens\nbut also the corresponding patches. As a result, the model gains a more\ncomprehensive understanding of both the entirety of the image as well as its\nfiner details. We pretrain the proposed method on small, medium, and\nlarge-scale datasets. It is shown that our approach could outperform\nstate-of-the-art image-level representation learning methods on both image\nclassification and downstream tasks. Keywords: Self-Supervised Learning; Visual\nRepresentations; Local-Global Representation Learning; Patch-Wise\nRepresentation Learning; Vision Transformer (ViT)",
            "author": [
                "Ali Javidani",
                "Mohammad Amin Sadeghi",
                "Babak Nadjar Araabi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18651v3",
                "http://arxiv.org/pdf/2310.18651v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18647v1",
            "title": "Sleep Deprivation in the Forward-Forward Algorithm",
            "updated": "2023-10-28T09:09:44Z",
            "published": "2023-10-28T09:09:44Z",
            "summary": "This paper aims to explore the separation of the two forward passes in the\nForward-Forward algorithm from a biological perspective in the context of\nsleep. We show the size of the gap between the sleep and awake phase influences\nthe learning capabilities of the algorithm and highlight the importance of\nnegative data in diminishing the devastating effects of sleep deprivation.",
            "author": [
                "Mircea-Tudor Lic\u0103",
                "David Dinucu-Jianu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18647v1",
                "http://arxiv.org/pdf/2310.18647v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18646v1",
            "title": "Predicting Agricultural Commodities Prices with Machine Learning: A\n  Review of Current Research",
            "updated": "2023-10-28T09:09:29Z",
            "published": "2023-10-28T09:09:29Z",
            "summary": "Agricultural price prediction is crucial for farmers, policymakers, and other\nstakeholders in the agricultural sector. However, it is a challenging task due\nto the complex and dynamic nature of agricultural markets. Machine learning\nalgorithms have the potential to revolutionize agricultural price prediction by\nimproving accuracy, real-time prediction, customization, and integration. This\npaper reviews recent research on machine learning algorithms for agricultural\nprice prediction. We discuss the importance of agriculture in developing\ncountries and the problems associated with crop price falls. We then identify\nthe challenges of predicting agricultural prices and highlight how machine\nlearning algorithms can support better prediction. Next, we present a\ncomprehensive analysis of recent research, discussing the strengths and\nweaknesses of various machine learning techniques. We conclude that machine\nlearning has the potential to revolutionize agricultural price prediction, but\nfurther research is essential to address the limitations and challenges\nassociated with this approach.",
            "author": [
                "Nhat-Quang Tran",
                "Anna Felipe",
                "Thanh Nguyen Ngoc",
                "Tom Huynh",
                "Quang Tran",
                "Arthur Tang",
                "Thuy Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18646v1",
                "http://arxiv.org/pdf/2310.18646v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18640v1",
            "title": "Switching Temporary Teachers for Semi-Supervised Semantic Segmentation",
            "updated": "2023-10-28T08:49:16Z",
            "published": "2023-10-28T08:49:16Z",
            "summary": "The teacher-student framework, prevalent in semi-supervised semantic\nsegmentation, mainly employs the exponential moving average (EMA) to update a\nsingle teacher's weights based on the student's. However, EMA updates raise a\nproblem in that the weights of the teacher and student are getting coupled,\ncausing a potential performance bottleneck. Furthermore, this problem may\nbecome more severe when training with more complicated labels such as\nsegmentation masks but with few annotated data. This paper introduces Dual\nTeacher, a simple yet effective approach that employs dual temporary teachers\naiming to alleviate the coupling problem for the student. The temporary\nteachers work in shifts and are progressively improved, so consistently prevent\nthe teacher and student from becoming excessively close. Specifically, the\ntemporary teachers periodically take turns generating pseudo-labels to train a\nstudent model and maintain the distinct characteristics of the student model\nfor each epoch. Consequently, Dual Teacher achieves competitive performance on\nthe PASCAL VOC, Cityscapes, and ADE20K benchmarks with remarkably shorter\ntraining times than state-of-the-art methods. Moreover, we demonstrate that our\napproach is model-agnostic and compatible with both CNN- and Transformer-based\nmodels. Code is available at \\url{https://github.com/naver-ai/dual-teacher}.",
            "author": [
                "Jaemin Na",
                "Jung-Woo Ha",
                "Hyung Jin Chang",
                "Dongyoon Han",
                "Wonjun Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18640v1",
                "http://arxiv.org/pdf/2310.18640v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18639v2",
            "title": "Towards Plastic and Stable Exemplar-Free Incremental Learning: A\n  Dual-Learner Framework with Cumulative Parameter Averaging",
            "updated": "2023-11-21T03:23:39Z",
            "published": "2023-10-28T08:48:44Z",
            "summary": "The dilemma between plasticity and stability presents a significant challenge\nin Incremental Learning (IL), especially in the exemplar-free scenario where\naccessing old-task samples is strictly prohibited during the learning of a new\ntask. A straightforward solution to this issue is learning and storing an\nindependent model for each task, known as Single Task Learning (STL). Despite\nthe linear growth in model storage with the number of tasks in STL, we\nempirically discover that averaging these model parameters can potentially\npreserve knowledge across all tasks. Inspired by this observation, we propose a\nDual-Learner framework with Cumulative Parameter Averaging (DLCPA). DLCPA\nemploys a dual-learner design: a plastic learner focused on acquiring new-task\nknowledge and a stable learner responsible for accumulating all learned\nknowledge. The knowledge from the plastic learner is transferred to the stable\nlearner via cumulative parameter averaging. Additionally, several task-specific\nclassifiers work in cooperation with the stable learner to yield the final\nprediction. Specifically, when learning a new task, these modules are updated\nin a cyclic manner: i) the plastic learner is initially optimized using a\nself-supervised loss besides the supervised loss to enhance the feature\nextraction robustness; ii) the stable learner is then updated with respect to\nthe plastic learner in a cumulative parameter averaging manner to maintain its\ntask-wise generalization; iii) the task-specific classifier is accordingly\noptimized to align with the stable learner. Experimental results on CIFAR-100\nand Tiny-ImageNet show that DLCPA outperforms several state-of-the-art\nexemplar-free baselines in both Task-IL and Class-IL settings.",
            "author": [
                "Wenju Sun",
                "Qingyong Li",
                "Wen Wang",
                "Yangli-ao Geng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18639v2",
                "http://arxiv.org/pdf/2310.18639v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18636v1",
            "title": "Electrical Impedance Tomography: A Fair Comparative Study on Deep\n  Learning and Analytic-based Approaches",
            "updated": "2023-10-28T08:45:51Z",
            "published": "2023-10-28T08:45:51Z",
            "summary": "Electrical Impedance Tomography (EIT) is a powerful imaging technique with\ndiverse applications, e.g., medical diagnosis, industrial monitoring, and\nenvironmental studies. The EIT inverse problem is about inferring the internal\nconductivity distribution of an object from measurements taken on its boundary.\nIt is severely ill-posed, necessitating advanced computational methods for\naccurate image reconstructions. Recent years have witnessed significant\nprogress, driven by innovations in analytic-based approaches and deep learning.\nThis review explores techniques for solving the EIT inverse problem, focusing\non the interplay between contemporary deep learning-based strategies and\nclassical analytic-based methods. Four state-of-the-art deep learning\nalgorithms are rigorously examined, harnessing the representational\ncapabilities of deep neural networks to reconstruct intricate conductivity\ndistributions. In parallel, two analytic-based methods, rooted in mathematical\nformulations and regularisation techniques, are dissected for their strengths\nand limitations. These methodologies are evaluated through various numerical\nexperiments, encompassing diverse scenarios that reflect real-world\ncomplexities. A suite of performance metrics is employed to assess the efficacy\nof these methods. These metrics collectively provide a nuanced understanding of\nthe methods' ability to capture essential features and delineate complex\nconductivity patterns. One novel feature of the study is the incorporation of\nvariable conductivity scenarios, introducing a level of heterogeneity that\nmimics textured inclusions. This departure from uniform conductivity\nassumptions mimics realistic scenarios where tissues or materials exhibit\nspatially varying electrical properties. Exploring how each method responds to\nsuch variable conductivity scenarios opens avenues for understanding their\nrobustness and adaptability.",
            "author": [
                "Derick Nganyu Tanyu",
                "Jianfeng Ning",
                "Andreas Hauptmann",
                "Bangti Jin",
                "Peter Maass"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18636v1",
                "http://arxiv.org/pdf/2310.18636v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE",
                "cs.CV",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18634v1",
            "title": "SSL Framework for Causal Inconsistency between Structures and\n  Representations",
            "updated": "2023-10-28T08:29:49Z",
            "published": "2023-10-28T08:29:49Z",
            "summary": "The cross-pollination of deep learning and causal discovery has catalyzed a\nburgeoning field of research seeking to elucidate causal relationships within\nnon-statistical data forms like images, videos, and text. Such data, often\nbeing named `indefinite data', exhibit unique challenges-inconsistency between\ncausal structure and representation, which are not common in conventional data\nforms. To tackle this issue, we theoretically develop intervention strategies\nsuitable for indefinite data and derive causal consistency condition (CCC).\nMoreover, we design a self-supervised learning (SSL) framework that considers\ninterventions as `views' and CCC as a `philosophy' with two implement examples\non Supervised Specialized Models (SSMs) and Large Language Models (LLMs),\nrespectively. To evaluate pure inconsistency manifestations, we have prepared\nthe first high-quality causal dialogue dataset-Causalogue. Evaluations are also\nperformed on three other downstream tasks. Extensive experimentation has\nsubstantiated the efficacy of our methodology, illuminating how CCC could\npotentially play an influential role in various fields.",
            "author": [
                "Hang Chen",
                "Xinyu Yang",
                "Keqing Du"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18634v1",
                "http://arxiv.org/pdf/2310.18634v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18633v1",
            "title": "Setting the Trap: Capturing and Defeating Backdoors in Pretrained\n  Language Models through Honeypots",
            "updated": "2023-10-28T08:21:16Z",
            "published": "2023-10-28T08:21:16Z",
            "summary": "In the field of natural language processing, the prevalent approach involves\nfine-tuning pretrained language models (PLMs) using local samples. Recent\nresearch has exposed the susceptibility of PLMs to backdoor attacks, wherein\nthe adversaries can embed malicious prediction behaviors by manipulating a few\ntraining samples. In this study, our objective is to develop a\nbackdoor-resistant tuning procedure that yields a backdoor-free model, no\nmatter whether the fine-tuning dataset contains poisoned samples. To this end,\nwe propose and integrate a honeypot module into the original PLM, specifically\ndesigned to absorb backdoor information exclusively. Our design is motivated by\nthe observation that lower-layer representations in PLMs carry sufficient\nbackdoor features while carrying minimal information about the original tasks.\nConsequently, we can impose penalties on the information acquired by the\nhoneypot module to inhibit backdoor creation during the fine-tuning process of\nthe stem network. Comprehensive experiments conducted on benchmark datasets\nsubstantiate the effectiveness and robustness of our defensive strategy.\nNotably, these results indicate a substantial reduction in the attack success\nrate ranging from 10\\% to 40\\% when compared to prior state-of-the-art methods.",
            "author": [
                "Ruixiang Tang",
                "Jiayi Yuan",
                "Yiming Li",
                "Zirui Liu",
                "Rui Chen",
                "Xia Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18633v1",
                "http://arxiv.org/pdf/2310.18633v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18629v1",
            "title": "Explainable Modeling for Wind Power Forecasting: A Glass-Box Approach\n  with Exceptional Accuracy",
            "updated": "2023-10-28T07:56:42Z",
            "published": "2023-10-28T07:56:42Z",
            "summary": "Machine learning models (e.g., neural networks) achieve high accuracy in wind\npower forecasting, but they are usually regarded as black boxes that lack\ninterpretability. To address this issue, the paper proposes a glass-box\napproach that combines exceptional accuracy with transparency for wind power\nforecasting. Specifically, advanced artificial intelligence methods (e.g.,\ngradient boosting) are innovatively employed to create shape functions within\nthe forecasting model. These functions effectively map the intricate non-linear\nrelationships between wind power output and input features. Furthermore, the\nforecasting model is enriched by incorporating interaction terms that adeptly\ncapture interdependencies and synergies among the input features. Simulation\nresults show that the proposed glass-box approach effectively interprets the\nresults of wind power forecasting from both global and instance perspectives.\nBesides, it outperforms most benchmark models and exhibits comparable\nperformance to the best-performing neural networks. This dual strength of\ntransparency and high accuracy positions the proposed glass-box approach as a\ncompelling choice for reliable wind power forecasting.",
            "author": [
                "Wenlong Liao",
                "Fernando Port\u00e9-Agel",
                "Jiannong Fang",
                "Birgitte Bak-Jensen",
                "Guangchun Ruan",
                "Zhe Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18629v1",
                "http://arxiv.org/pdf/2310.18629v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18628v1",
            "title": "Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive\n  Learning for Code Generation",
            "updated": "2023-10-28T07:54:39Z",
            "published": "2023-10-28T07:54:39Z",
            "summary": "With the rise of powerful closed-sourced LLMs (ChatGPT, GPT-4), there are\nincreasing interests in distilling the capabilies of close-sourced LLMs to\nsmaller open-sourced LLMs. Previous distillation methods usually prompt ChatGPT\nto generate a set of instructions and answers, for the student model to learn.\nHowever, such standard distillation approach neglects the merits and conditions\nof the student model. Inspired by modern teaching principles, we design a\npersonalised distillation process, in which the student attempts to solve a\ntask first, then the teacher provides an adaptive refinement for the student to\nimprove. Instead of feeding the student with teacher's prior, personalised\ndistillation enables personalised learning for the student model, as it only\nlearns on examples it makes mistakes upon and learns to improve its own\nsolution. On code generation, personalised distillation consistently\noutperforms standard distillation with only one third of the data. With only\n2.5-3K personalised examples that incur a data-collection cost of 4-6$, we\nboost CodeGen-mono-16B by 7% to achieve 36.4% pass@1 and StarCoder by 12.2% to\nachieve 45.8% pass@1 on HumanEval.",
            "author": [
                "Hailin Chen",
                "Amrita Saha",
                "Steven Hoi",
                "Shafiq Joty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18628v1",
                "http://arxiv.org/pdf/2310.18628v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18626v2",
            "title": "Benchmark Generation Framework with Customizable Distortions for Image\n  Classifier Robustness",
            "updated": "2023-11-08T13:44:53Z",
            "published": "2023-10-28T07:40:42Z",
            "summary": "We present a novel framework for generating adversarial benchmarks to\nevaluate the robustness of image classification models. Our framework allows\nusers to customize the types of distortions to be optimally applied to images,\nwhich helps address the specific distortions relevant to their deployment. The\nbenchmark can generate datasets at various distortion levels to assess the\nrobustness of different image classifiers. Our results show that the\nadversarial samples generated by our framework with any of the image\nclassification models, like ResNet-50, Inception-V3, and VGG-16, are effective\nand transferable to other models causing them to fail. These failures happen\neven when these models are adversarially retrained using state-of-the-art\ntechniques, demonstrating the generalizability of our adversarial samples. We\nachieve competitive performance in terms of net $L_2$ distortion compared to\nstate-of-the-art benchmark techniques on CIFAR-10 and ImageNet; however, we\ndemonstrate our framework achieves such results with simple distortions like\nGaussian noise without introducing unnatural artifacts or color bleeds. This is\nmade possible by a model-based reinforcement learning (RL) agent and a\ntechnique that reduces a deep tree search of the image for model sensitivity to\nperturbations, to a one-level analysis and action. The flexibility of choosing\ndistortions and setting classification probability thresholds for multiple\nclasses makes our framework suitable for algorithmic audits.",
            "author": [
                "Soumyendu Sarkar",
                "Ashwin Ramesh Babu",
                "Sajad Mousavi",
                "Zachariah Carmichael",
                "Vineet Gundecha",
                "Sahand Ghorbanpour",
                "Ricardo Luna",
                "Gutierrez Antonio Guillen",
                "Avisek Naug"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18626v2",
                "http://arxiv.org/pdf/2310.18626v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18622v1",
            "title": "Arbitrarily Scalable Environment Generators via Neural Cellular Automata",
            "updated": "2023-10-28T07:30:09Z",
            "published": "2023-10-28T07:30:09Z",
            "summary": "We study the problem of generating arbitrarily large environments to improve\nthe throughput of multi-robot systems. Prior work proposes Quality Diversity\n(QD) algorithms as an effective method for optimizing the environments of\nautomated warehouses. However, these approaches optimize only relatively small\nenvironments, falling short when it comes to replicating real-world warehouse\nsizes. The challenge arises from the exponential increase in the search space\nas the environment size increases. Additionally, the previous methods have only\nbeen tested with up to 350 robots in simulations, while practical warehouses\ncould host thousands of robots. In this paper, instead of optimizing\nenvironments, we propose to optimize Neural Cellular Automata (NCA) environment\ngenerators via QD algorithms. We train a collection of NCA generators with QD\nalgorithms in small environments and then generate arbitrarily large\nenvironments from the generators at test time. We show that NCA environment\ngenerators maintain consistent, regularized patterns regardless of environment\nsize, significantly enhancing the scalability of multi-robot systems in two\ndifferent domains with up to 2,350 robots. Additionally, we demonstrate that\nour method scales a single-agent reinforcement learning policy to arbitrarily\nlarge environments with similar patterns. We include the source code at\n\\url{https://github.com/lunjohnzhang/warehouse_env_gen_nca_public}.",
            "author": [
                "Yulun Zhang",
                "Matthew C. Fontaine",
                "Varun Bhatt",
                "Stefanos Nikolaidis",
                "Jiaoyang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18622v1",
                "http://arxiv.org/pdf/2310.18622v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.MA",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18620v2",
            "title": "ODM3D: Alleviating Foreground Sparsity for Semi-Supervised Monocular 3D\n  Object Detection",
            "updated": "2023-11-07T02:55:02Z",
            "published": "2023-10-28T07:12:09Z",
            "summary": "Monocular 3D object detection (M3OD) is a significant yet inherently\nchallenging task in autonomous driving due to absence of explicit depth cues in\na single RGB image. In this paper, we strive to boost currently underperforming\nmonocular 3D object detectors by leveraging an abundance of unlabelled data via\nsemi-supervised learning. Our proposed ODM3D framework entails cross-modal\nknowledge distillation at various levels to inject LiDAR-domain knowledge into\na monocular detector during training. By identifying foreground sparsity as the\nmain culprit behind existing methods' suboptimal training, we exploit the\nprecise localisation information embedded in LiDAR points to enable more\nforeground-attentive and efficient distillation via the proposed BEV occupancy\nguidance mask, leading to notably improved knowledge transfer and M3OD\nperformance. Besides, motivated by insights into why existing cross-modal\nGT-sampling techniques fail on our task at hand, we further design a novel\ncross-modal object-wise data augmentation strategy for effective RGB-LiDAR\njoint learning. Our method ranks 1st in both KITTI validation and test\nbenchmarks, significantly surpassing all existing monocular methods, supervised\nor semi-supervised, on both BEV and 3D detection metrics.",
            "author": [
                "Weijia Zhang",
                "Dongnan Liu",
                "Chao Ma",
                "Weidong Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18620v2",
                "http://arxiv.org/pdf/2310.18620v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18619v1",
            "title": "Dense Retrieval as Indirect Supervision for Large-space Decision Making",
            "updated": "2023-10-28T07:00:28Z",
            "published": "2023-10-28T07:00:28Z",
            "summary": "Many discriminative natural language understanding (NLU) tasks have large\nlabel spaces. Learning such a process of large-space decision making is\nparticularly challenging due to the lack of training instances per label and\nthe difficulty of selection among many fine-grained labels. Inspired by dense\nretrieval methods for passage finding in open-domain QA, we propose a\nreformulation of large-space discriminative NLU tasks as a learning-to-retrieve\ntask, leading to a novel solution named Dense Decision Retrieval (DDR ).\nInstead of predicting fine-grained decisions as logits, DDR adopts a\ndual-encoder architecture that learns to predict by retrieving from a decision\nthesaurus. This approach not only leverages rich indirect supervision signals\nfrom easy-to-consume learning resources for dense retrieval, it also leads to\nenhanced prediction generalizability with a semantically meaningful\nrepresentation of the large decision space. When evaluated on tasks with\ndecision spaces ranging from hundreds to hundred-thousand scales, DDR\noutperforms strong baselines greatly by 27.54% in P@1 on two extreme\nmulti-label classification tasks, 1.17% in F1 score ultra-fine entity typing,\nand 1.26% in accuracy on three few-shot intent classification tasks on average.\nCode and resources are available at https://github.com/luka-group/DDR",
            "author": [
                "Nan Xu",
                "Fei Wang",
                "Mingtao Dong",
                "Muhao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18619v1",
                "http://arxiv.org/pdf/2310.18619v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18617v1",
            "title": "Pessimistic Off-Policy Multi-Objective Optimization",
            "updated": "2023-10-28T06:50:15Z",
            "published": "2023-10-28T06:50:15Z",
            "summary": "Multi-objective optimization is a type of decision making problems where\nmultiple conflicting objectives are optimized. We study offline optimization of\nmulti-objective policies from data collected by an existing policy. We propose\na pessimistic estimator for the multi-objective policy values that can be\neasily plugged into existing formulas for hypervolume computation and\noptimized. The estimator is based on inverse propensity scores (IPS), and\nimproves upon a naive IPS estimator in both theory and experiments. Our\nanalysis is general, and applies beyond our IPS estimators and methods for\noptimizing them. The pessimistic estimator can be optimized by policy gradients\nand performs well in all of our experiments.",
            "author": [
                "Shima Alizadeh",
                "Aniruddha Bhargava",
                "Karthick Gopalswamy",
                "Lalit Jain",
                "Branislav Kveton",
                "Ge Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18617v1",
                "http://arxiv.org/pdf/2310.18617v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18615v1",
            "title": "Temporally Disentangled Representation Learning under Unknown\n  Nonstationarity",
            "updated": "2023-10-28T06:46:03Z",
            "published": "2023-10-28T06:46:03Z",
            "summary": "In unsupervised causal representation learning for sequential data with\ntime-delayed latent causal influences, strong identifiability results for the\ndisentanglement of causally-related latent variables have been established in\nstationary settings by leveraging temporal structure. However, in nonstationary\nsetting, existing work only partially addressed the problem by either utilizing\nobserved auxiliary variables (e.g., class labels and/or domain indexes) as side\ninformation or assuming simplified latent causal dynamics. Both constrain the\nmethod to a limited range of scenarios. In this study, we further explored the\nMarkov Assumption under time-delayed causally related process in nonstationary\nsetting and showed that under mild conditions, the independent latent\ncomponents can be recovered from their nonlinear mixture up to a permutation\nand a component-wise transformation, without the observation of auxiliary\nvariables. We then introduce NCTRL, a principled estimation framework, to\nreconstruct time-delayed latent causal variables and identify their relations\nfrom measured sequential data only. Empirical evaluations demonstrated the\nreliable identification of time-delayed latent causal influences, with our\nmethodology substantially outperforming existing baselines that fail to exploit\nthe nonstationarity adequately and then, consequently, cannot distinguish\ndistribution shifts.",
            "author": [
                "Xiangchen Song",
                "Weiran Yao",
                "Yewen Fan",
                "Xinshuai Dong",
                "Guangyi Chen",
                "Juan Carlos Niebles",
                "Eric Xing",
                "Kun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18615v1",
                "http://arxiv.org/pdf/2310.18615v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18614v1",
            "title": "Hierarchical Mutual Information Analysis: Towards Multi-view Clustering\n  in The Wild",
            "updated": "2023-10-28T06:43:57Z",
            "published": "2023-10-28T06:43:57Z",
            "summary": "Multi-view clustering (MVC) can explore common semantics from unsupervised\nviews generated by different sources, and thus has been extensively used in\napplications of practical computer vision. Due to the spatio-temporal\nasynchronism, multi-view data often suffer from view missing and are unaligned\nin real-world applications, which makes it difficult to learn consistent\nrepresentations. To address the above issues, this work proposes a deep MVC\nframework where data recovery and alignment are fused in a hierarchically\nconsistent way to maximize the mutual information among different views and\nensure the consistency of their latent spaces. More specifically, we first\nleverage dual prediction to fill in missing views while achieving the\ninstance-level alignment, and then take the contrastive reconstruction to\nachieve the class-level alignment. To the best of our knowledge, this could be\nthe first successful attempt to handle the missing and unaligned data problem\nseparately with different learning paradigms. Extensive experiments on public\ndatasets demonstrate that our method significantly outperforms state-of-the-art\nmethods on multi-view clustering even in the cases of view missing and\nunalignment.",
            "author": [
                "Jiatai Wang",
                "Zhiwei Xu",
                "Xuewen Yang",
                "Xin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18614v1",
                "http://arxiv.org/pdf/2310.18614v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18612v1",
            "title": "Efficient kernel surrogates for neural network-based regression",
            "updated": "2023-10-28T06:41:47Z",
            "published": "2023-10-28T06:41:47Z",
            "summary": "Despite their immense promise in performing a variety of learning tasks, a\ntheoretical understanding of the effectiveness and limitations of Deep Neural\nNetworks (DNNs) has so far eluded practitioners. This is partly due to the\ninability to determine the closed forms of the learned functions, making it\nharder to assess their precise dependence on the training data and to study\ntheir generalization properties on unseen datasets. Recent work has shown that\nrandomly initialized DNNs in the infinite width limit converge to kernel\nmachines relying on a Neural Tangent Kernel (NTK) with known closed form. These\nresults suggest, and experimental evidence corroborates, that empirical kernel\nmachines can also act as surrogates for finite width DNNs. The high\ncomputational cost of assembling the full NTK, however, makes this approach\ninfeasible in practice, motivating the need for low-cost approximations. In the\ncurrent work, we study the performance of the Conjugate Kernel (CK), an\nefficient approximation to the NTK that has been observed to yield fairly\nsimilar results. For the regression problem of smooth functions and\nclassification using logistic regression, we show that the CK performance is\nonly marginally worse than that of the NTK and, in certain cases, is shown to\nbe superior. In particular, we establish bounds for the relative test losses,\nverify them with numerical tests, and identify the regularity of the kernel as\nthe key determinant of performance. In addition to providing a theoretical\ngrounding for using CKs instead of NTKs, our framework provides insights into\nunderstanding the robustness of the various approximants and suggests a recipe\nfor improving DNN accuracy inexpensively. We present a demonstration of this on\nthe foundation model GPT-2 by comparing its performance on a classification\ntask using a conventional approach and our prescription.",
            "author": [
                "Saad Qadeer",
                "Andrew Engel",
                "Adam Tsou",
                "Max Vargas",
                "Panos Stinis",
                "Tony Chiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18612v1",
                "http://arxiv.org/pdf/2310.18612v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18609v1",
            "title": "Deep3DSketch+: Obtaining Customized 3D Model by Single Free-Hand Sketch\n  through Deep Learning",
            "updated": "2023-10-28T06:36:53Z",
            "published": "2023-10-28T06:36:53Z",
            "summary": "As 3D models become critical in today's manufacturing and product design,\nconventional 3D modeling approaches based on Computer-Aided Design (CAD) are\nlabor-intensive, time-consuming, and have high demands on the creators. This\nwork aims to introduce an alternative approach to 3D modeling by utilizing\nfree-hand sketches to obtain desired 3D models. We introduce Deep3DSketch+,\nwhich is a deep-learning algorithm that takes the input of a single free-hand\nsketch and produces a complete and high-fidelity model that matches the sketch\ninput. The neural network has view- and structural-awareness enabled by a Shape\nDiscriminator (SD) and a Stroke Enhancement Module (SEM), which overcomes the\nlimitations of sparsity and ambiguity of the sketches. The network design also\nbrings high robustness to partial sketch input in industrial applications.Our\napproach has undergone extensive experiments, demonstrating its\nstate-of-the-art (SOTA) performance on both synthetic and real-world datasets.\nThese results validate the effectiveness and superiority of our method compared\nto existing techniques. We have demonstrated the conversion of free-hand\nsketches into physical 3D objects using additive manufacturing. We believe that\nour approach has the potential to accelerate product design and democratize\ncustomized manufacturing.",
            "author": [
                "Ying Zang",
                "Chenglong Fu",
                "Tianrun Chen",
                "Yuanqi Hu",
                "Qingshan Liu",
                "Wenjun Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18609v1",
                "http://arxiv.org/pdf/2310.18609v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18608v1",
            "title": "Embedding in Recommender Systems: A Survey",
            "updated": "2023-10-28T06:31:06Z",
            "published": "2023-10-28T06:31:06Z",
            "summary": "Recommender systems have become an essential component of many online\nplatforms, providing personalized recommendations to users. A crucial aspect is\nembedding techniques that coverts the high-dimensional discrete features, such\nas user and item IDs, into low-dimensional continuous vectors and can enhance\nthe recommendation performance. Applying embedding techniques captures complex\nentity relationships and has spurred substantial research. In this survey, we\nprovide an overview of the recent literature on embedding techniques in\nrecommender systems. This survey covers embedding methods like collaborative\nfiltering, self-supervised learning, and graph-based techniques. Collaborative\nfiltering generates embeddings capturing user-item preferences, excelling in\nsparse data. Self-supervised methods leverage contrastive or generative\nlearning for various tasks. Graph-based techniques like node2vec exploit\ncomplex relationships in network-rich environments. Addressing the scalability\nchallenges inherent to embedding methods, our survey delves into innovative\ndirections within the field of recommendation systems. These directions aim to\nenhance performance and reduce computational complexity, paving the way for\nimproved recommender systems. Among these innovative approaches, we will\nintroduce Auto Machine Learning (AutoML), hash techniques, and quantization\ntechniques in this survey. We discuss various architectures and techniques and\nhighlight the challenges and future directions in these aspects. This survey\naims to provide a comprehensive overview of the state-of-the-art in this\nrapidly evolving field and serve as a useful resource for researchers and\npractitioners working in the area of recommender systems.",
            "author": [
                "Xiangyu Zhao",
                "Maolin Wang",
                "Xinjian Zhao",
                "Jiansheng Li",
                "Shucheng Zhou",
                "Dawei Yin",
                "Qing Li",
                "Jiliang Tang",
                "Ruocheng Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18608v1",
                "http://arxiv.org/pdf/2310.18608v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18606v1",
            "title": "Where have you been? A Study of Privacy Risk for Point-of-Interest\n  Recommendation",
            "updated": "2023-10-28T06:17:52Z",
            "published": "2023-10-28T06:17:52Z",
            "summary": "As location-based services (LBS) have grown in popularity, the collection of\nhuman mobility data has become increasingly extensive to build machine learning\n(ML) models offering enhanced convenience to LBS users. However, the\nconvenience comes with the risk of privacy leakage since this type of data\nmight contain sensitive information related to user identities, such as\nhome/work locations. Prior work focuses on protecting mobility data privacy\nduring transmission or prior to release, lacking the privacy risk evaluation of\nmobility data-based ML models. To better understand and quantify the privacy\nleakage in mobility data-based ML models, we design a privacy attack suite\ncontaining data extraction and membership inference attacks tailored for\npoint-of-interest (POI) recommendation models, one of the most widely used\nmobility data-based ML models. These attacks in our attack suite assume\ndifferent adversary knowledge and aim to extract different types of sensitive\ninformation from mobility data, providing a holistic privacy risk assessment\nfor POI recommendation models. Our experimental evaluation using two real-world\nmobility datasets demonstrates that current POI recommendation models are\nvulnerable to our attacks. We also present unique findings to understand what\ntypes of mobility data are more susceptible to privacy attacks. Finally, we\nevaluate defenses against these attacks and highlight future directions and\nchallenges.",
            "author": [
                "Kunlin Cai",
                "Jinghuai Zhang",
                "Will Shand",
                "Zhiqing Hong",
                "Guang Wang",
                "Desheng Zhang",
                "Jianfeng Chi",
                "Yuan Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18606v1",
                "http://arxiv.org/pdf/2310.18606v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18605v1",
            "title": "TorchDEQ: A Library for Deep Equilibrium Models",
            "updated": "2023-10-28T06:16:10Z",
            "published": "2023-10-28T06:16:10Z",
            "summary": "Deep Equilibrium (DEQ) Models, an emerging class of implicit models that maps\ninputs to fixed points of neural networks, are of growing interest in the deep\nlearning community. However, training and applying DEQ models is currently done\nin an ad-hoc fashion, with various techniques spread across the literature. In\nthis work, we systematically revisit DEQs and present TorchDEQ, an\nout-of-the-box PyTorch-based library that allows users to define, train, and\ninfer using DEQs over multiple domains with minimal code and best practices.\nUsing TorchDEQ, we build a ``DEQ Zoo'' that supports six published implicit\nmodels across different domains. By developing a joint framework that\nincorporates the best practices across all models, we have substantially\nimproved the performance, training stability, and efficiency of DEQs on ten\ndatasets across all six projects in the DEQ Zoo. TorchDEQ and DEQ Zoo are\nreleased as \\href{https://github.com/locuslab/torchdeq}{open source}.",
            "author": [
                "Zhengyang Geng",
                "J. Zico Kolter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18605v1",
                "http://arxiv.org/pdf/2310.18605v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18604v1",
            "title": "Anaphor Assisted Document-Level Relation Extraction",
            "updated": "2023-10-28T06:11:18Z",
            "published": "2023-10-28T06:11:18Z",
            "summary": "Document-level relation extraction (DocRE) involves identifying relations\nbetween entities distributed in multiple sentences within a document. Existing\nmethods focus on building a heterogeneous document graph to model the internal\nstructure of an entity and the external interaction between entities. However,\nthere are two drawbacks in existing methods. On one hand, anaphor plays an\nimportant role in reasoning to identify relations between entities but is\nignored by these methods. On the other hand, these methods achieve\ncross-sentence entity interactions implicitly by utilizing a document or\nsentences as intermediate nodes. Such an approach has difficulties in learning\nfine-grained interactions between entities across different sentences,\nresulting in sub-optimal performance. To address these issues, we propose an\nAnaphor-Assisted (AA) framework for DocRE tasks. Experimental results on the\nwidely-used datasets demonstrate that our model achieves a new state-of-the-art\nperformance.",
            "author": [
                "Chonggang Lu",
                "Richong Zhang",
                "Kai Sun",
                "Jaein Kim",
                "Cunwang Zhang",
                "Yongyi Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18604v1",
                "http://arxiv.org/pdf/2310.18604v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18603v1",
            "title": "Large Language Models Are Better Adversaries: Exploring Generative\n  Clean-Label Backdoor Attacks Against Text Classifiers",
            "updated": "2023-10-28T06:11:07Z",
            "published": "2023-10-28T06:11:07Z",
            "summary": "Backdoor attacks manipulate model predictions by inserting innocuous triggers\ninto training and test data. We focus on more realistic and more challenging\nclean-label attacks where the adversarial training examples are correctly\nlabeled. Our attack, LLMBkd, leverages language models to automatically insert\ndiverse style-based triggers into texts. We also propose a poison selection\ntechnique to improve the effectiveness of both LLMBkd as well as existing\ntextual backdoor attacks. Lastly, we describe REACT, a baseline defense to\nmitigate backdoor attacks via antidote training examples. Our evaluations\ndemonstrate LLMBkd's effectiveness and efficiency, where we consistently\nachieve high attack success rates across a wide range of styles with little\neffort and no model training.",
            "author": [
                "Wencong You",
                "Zayd Hammoudeh",
                "Daniel Lowd"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18603v1",
                "http://arxiv.org/pdf/2310.18603v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18601v1",
            "title": "Online Decision Mediation",
            "updated": "2023-10-28T05:59:43Z",
            "published": "2023-10-28T05:59:43Z",
            "summary": "Consider learning a decision support assistant to serve as an intermediary\nbetween (oracle) expert behavior and (imperfect) human behavior: At each time,\nthe algorithm observes an action chosen by a fallible agent, and decides\nwhether to *accept* that agent's decision, *intervene* with an alternative, or\n*request* the expert's opinion. For instance, in clinical diagnosis,\nfully-autonomous machine behavior is often beyond ethical affordances, thus\nreal-world decision support is often limited to monitoring and forecasting.\nInstead, such an intermediary would strike a prudent balance between the former\n(purely prescriptive) and latter (purely descriptive) approaches, while\nproviding an efficient interface between human mistakes and expert feedback. In\nthis work, we first formalize the sequential problem of *online decision\nmediation* -- that is, of simultaneously learning and evaluating mediator\npolicies from scratch with *abstentive feedback*: In each round, deferring to\nthe oracle obviates the risk of error, but incurs an upfront penalty, and\nreveals the otherwise hidden expert action as a new training data point.\nSecond, we motivate and propose a solution that seeks to trade off (immediate)\nloss terms against (future) improvements in generalization error; in doing so,\nwe identify why conventional bandit algorithms may fail. Finally, through\nexperiments and sensitivities on a variety of datasets, we illustrate\nconsistent gains over applicable benchmarks on performance measures with\nrespect to the mediator policy, the learned model, and the decision-making\nsystem as a whole.",
            "author": [
                "Daniel Jarrett",
                "Alihan H\u00fcy\u00fck",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18601v1",
                "http://arxiv.org/pdf/2310.18601v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18598v1",
            "title": "Domain Generalisation via Risk Distribution Matching",
            "updated": "2023-10-28T05:23:55Z",
            "published": "2023-10-28T05:23:55Z",
            "summary": "We propose a novel approach for domain generalisation (DG) leveraging risk\ndistributions to characterise domains, thereby achieving domain invariance. In\nour findings, risk distributions effectively highlight differences between\ntraining domains and reveal their inherent complexities. In testing, we may\nobserve similar, or potentially intensifying in magnitude, divergences between\nrisk distributions. Hence, we propose a compelling proposition: Minimising the\ndivergences between risk distributions across training domains leads to robust\ninvariance for DG. The key rationale behind this concept is that a model,\ntrained on domain-invariant or stable features, may consistently produce\nsimilar risk distributions across various domains. Building upon this idea, we\npropose Risk Distribution Matching (RDM). Using the maximum mean discrepancy\n(MMD) distance, RDM aims to minimise the variance of risk distributions across\ntraining domains. However, when the number of domains increases, the direct\noptimisation of variance leads to linear growth in MMD computations, resulting\nin inefficiency. Instead, we propose an approximation that requires only one\nMMD computation, by aligning just two distributions: that of the worst-case\ndomain and the aggregated distribution from all domains. Notably, this method\nempirically outperforms optimising distributional variance while being\ncomputationally more efficient. Unlike conventional DG matching algorithms, RDM\nstands out for its enhanced efficacy by concentrating on scalar risk\ndistributions, sidestepping the pitfalls of high-dimensional challenges seen in\nfeature or gradient matching. Our extensive experiments on standard benchmark\ndatasets demonstrate that RDM shows superior generalisation capability over\nstate-of-the-art DG methods.",
            "author": [
                "Toan Nguyen",
                "Kien Do",
                "Bao Duong",
                "Thin Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18598v1",
                "http://arxiv.org/pdf/2310.18598v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18593v1",
            "title": "Fair Streaming Principal Component Analysis: Statistical and Algorithmic\n  Viewpoint",
            "updated": "2023-10-28T05:09:30Z",
            "published": "2023-10-28T05:09:30Z",
            "summary": "Fair Principal Component Analysis (PCA) is a problem setting where we aim to\nperform PCA while making the resulting representation fair in that the\nprojected distributions, conditional on the sensitive attributes, match one\nanother. However, existing approaches to fair PCA have two main problems:\ntheoretically, there has been no statistical foundation of fair PCA in terms of\nlearnability; practically, limited memory prevents us from using existing\napproaches, as they explicitly rely on full access to the entire data. On the\ntheoretical side, we rigorously formulate fair PCA using a new notion called\n\\emph{probably approximately fair and optimal} (PAFO) learnability. On the\npractical side, motivated by recent advances in streaming algorithms for\naddressing memory limitation, we propose a new setting called \\emph{fair\nstreaming PCA} along with a memory-efficient algorithm, fair noisy power method\n(FNPM). We then provide its {\\it statistical} guarantee in terms of\nPAFO-learnability, which is the first of its kind in fair PCA literature.\nLastly, we verify the efficacy and memory efficiency of our algorithm on\nreal-world datasets.",
            "author": [
                "Junghyun Lee",
                "Hanseul Cho",
                "Se-Young Yun",
                "Chulhee Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18593v1",
                "http://arxiv.org/pdf/2310.18593v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18591v1",
            "title": "Inverse Decision Modeling: Learning Interpretable Representations of\n  Behavior",
            "updated": "2023-10-28T05:05:01Z",
            "published": "2023-10-28T05:05:01Z",
            "summary": "Decision analysis deals with modeling and enhancing decision processes. A\nprincipal challenge in improving behavior is in obtaining a transparent\ndescription of existing behavior in the first place. In this paper, we develop\nan expressive, unifying perspective on inverse decision modeling: a framework\nfor learning parameterized representations of sequential decision behavior.\nFirst, we formalize the forward problem (as a normative standard), subsuming\ncommon classes of control behavior. Second, we use this to formalize the\ninverse problem (as a descriptive model), generalizing existing work on\nimitation/reward learning -- while opening up a much broader class of research\nproblems in behavior representation. Finally, we instantiate this approach with\nan example (inverse bounded rational control), illustrating how this structure\nenables learning (interpretable) representations of (bounded) rationality --\nwhile naturally capturing intuitive notions of suboptimal actions, biased\nbeliefs, and imperfect knowledge of environments.",
            "author": [
                "Daniel Jarrett",
                "Alihan H\u00fcy\u00fck",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18591v1",
                "http://arxiv.org/pdf/2310.18591v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18590v2",
            "title": "Using Early Readouts to Mediate Featural Bias in Distillation",
            "updated": "2023-11-08T13:13:13Z",
            "published": "2023-10-28T04:58:15Z",
            "summary": "Deep networks tend to learn spurious feature-label correlations in real-world\nsupervised learning tasks. This vulnerability is aggravated in distillation,\nwhere a student model may have lesser representational capacity than the\ncorresponding teacher model. Often, knowledge of specific spurious correlations\nis used to reweight instances & rebalance the learning process. We propose a\nnovel early readout mechanism whereby we attempt to predict the label using\nrepresentations from earlier network layers. We show that these early readouts\nautomatically identify problem instances or groups in the form of confident,\nincorrect predictions. Leveraging these signals to modulate the distillation\nloss on an instance level allows us to substantially improve not only group\nfairness measures across benchmark datasets, but also overall accuracy of the\nstudent model. We also provide secondary analyses that bring insight into the\nrole of feature learning in supervision and distillation.",
            "author": [
                "Rishabh Tiwari",
                "Durga Sivasubramanian",
                "Anmol Mekala",
                "Ganesh Ramakrishnan",
                "Pradeep Shenoy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18590v2",
                "http://arxiv.org/pdf/2310.18590v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18589v1",
            "title": "This Looks Like Those: Illuminating Prototypical Concepts Using Multiple\n  Visualizations",
            "updated": "2023-10-28T04:54:48Z",
            "published": "2023-10-28T04:54:48Z",
            "summary": "We present ProtoConcepts, a method for interpretable image classification\ncombining deep learning and case-based reasoning using prototypical parts.\nExisting work in prototype-based image classification uses a ``this looks like\nthat'' reasoning process, which dissects a test image by finding prototypical\nparts and combining evidence from these prototypes to make a final\nclassification. However, all of the existing prototypical part-based image\nclassifiers provide only one-to-one comparisons, where a single training image\npatch serves as a prototype to compare with a part of our test image. With\nthese single-image comparisons, it can often be difficult to identify the\nunderlying concept being compared (e.g., ``is it comparing the color or the\nshape?''). Our proposed method modifies the architecture of prototype-based\nnetworks to instead learn prototypical concepts which are visualized using\nmultiple image patches. Having multiple visualizations of the same prototype\nallows us to more easily identify the concept captured by that prototype (e.g.,\n``the test image and the related training patches are all the same shade of\nblue''), and allows our model to create richer, more interpretable visual\nexplanations. Our experiments show that our ``this looks like those'' reasoning\nprocess can be applied as a modification to a wide range of existing\nprototypical image classification networks while achieving comparable accuracy\non benchmark datasets.",
            "author": [
                "Chiyu Ma",
                "Brandon Zhao",
                "Chaofan Chen",
                "Cynthia Rudin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18589v1",
                "http://arxiv.org/pdf/2310.18589v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18586v1",
            "title": "Optimal Transport for Kernel Gaussian Mixture Models",
            "updated": "2023-10-28T04:31:49Z",
            "published": "2023-10-28T04:31:49Z",
            "summary": "The Wasserstein distance from optimal mass transport (OMT) is a powerful\nmathematical tool with numerous applications that provides a natural measure of\nthe distance between two probability distributions. Several methods to\nincorporate OMT into widely used probabilistic models, such as Gaussian or\nGaussian mixture, have been developed to enhance the capability of modeling\ncomplex multimodal densities of real datasets. However, very few studies have\nexplored the OMT problems in a reproducing kernel Hilbert space (RKHS), wherein\nthe kernel trick is utilized to avoid the need to explicitly map input data\ninto a high-dimensional feature space. In the current study, we propose a\nWasserstein-type metric to compute the distance between two Gaussian mixtures\nin a RKHS via the kernel trick, i.e., kernel Gaussian mixture models.",
            "author": [
                "Jung Hun Oh",
                "Rena Elkin",
                "Anish Kumar Simhal",
                "Jiening Zhu",
                "Joseph O Deasy",
                "Allen Tannenbaum"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18586v1",
                "http://arxiv.org/pdf/2310.18586v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18583v2",
            "title": "Self-Supervised Multi-Modality Learning for Multi-Label Skin Lesion\n  Classification",
            "updated": "2023-11-16T05:02:34Z",
            "published": "2023-10-28T04:16:08Z",
            "summary": "The clinical diagnosis of skin lesion involves the analysis of dermoscopic\nand clinical modalities. Dermoscopic images provide a detailed view of the\nsurface structures whereas clinical images offer a complementary macroscopic\ninformation. The visual diagnosis of melanoma is also based on seven-point\nchecklist which involves identifying different visual attributes. Recently,\nsupervised learning approaches such as convolutional neural networks (CNNs)\nhave shown great performances using both dermoscopic and clinical modalities\n(Multi-modality). The seven different visual attributes in the checklist are\nalso used to further improve the the diagnosis. The performances of these\napproaches, however, are still reliant on the availability of large-scaled\nlabeled data. The acquisition of annotated dataset is an expensive and\ntime-consuming task, more so with annotating multi-attributes. To overcome this\nlimitation, we propose a self-supervised learning (SSL) algorithm for\nmulti-modality skin lesion classification. Our algorithm enables the\nmulti-modality learning by maximizing the similarities between paired\ndermoscopic and clinical images from different views. In addition, we generate\nsurrogate pseudo-multi-labels that represent seven attributes via clustering\nanalysis. We also propose a label-relation-aware module to refine each\npseudo-label embedding and capture the interrelationships between\npseudo-multi-labels. We validated the effectiveness of our algorithm using\nwell-benchmarked seven-point skin lesion dataset. Our results show that our\nalgorithm achieved better performances than other state-of-the-art SSL\ncounterparts.",
            "author": [
                "Hao Wang",
                "Euijoon Ahn",
                "Lei Bi",
                "Jinman Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18583v2",
                "http://arxiv.org/pdf/2310.18583v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18582v1",
            "title": "Data-driven learning of the generalized Langevin equation with\n  state-dependent memory",
            "updated": "2023-10-28T04:10:39Z",
            "published": "2023-10-28T04:10:39Z",
            "summary": "We present a data-driven method to learn stochastic reduced models of complex\nsystems that retain a state-dependent memory beyond the standard generalized\nLangevin equation (GLE) with a homogeneous kernel. The constructed model\nnaturally encodes the heterogeneous energy dissipation by jointly learning a\nset of state features and the non-Markovian coupling among the features.\nNumerical results demonstrate the limitation of the standard GLE and the\nessential role of the broadly overlooked state-dependency nature in predicting\nmolecule kinetics related to conformation relaxation and transition.",
            "author": [
                "Pei Ge",
                "Zhongqiang Zhang",
                "Huan Lei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18582v1",
                "http://arxiv.org/pdf/2310.18582v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18574v1",
            "title": "Breaking the Trilemma of Privacy, Utility, Efficiency via Controllable\n  Machine Unlearning",
            "updated": "2023-10-28T03:24:54Z",
            "published": "2023-10-28T03:24:54Z",
            "summary": "Machine Unlearning (MU) algorithms have become increasingly critical due to\nthe imperative adherence to data privacy regulations. The primary objective of\nMU is to erase the influence of specific data samples on a given model without\nthe need to retrain it from scratch. Accordingly, existing methods focus on\nmaximizing user privacy protection. However, there are different degrees of\nprivacy regulations for each real-world web-based application. Exploring the\nfull spectrum of trade-offs between privacy, model utility, and runtime\nefficiency is critical for practical unlearning scenarios. Furthermore,\ndesigning the MU algorithm with simple control of the aforementioned trade-off\nis desirable but challenging due to the inherent complex interaction. To\naddress the challenges, we present Controllable Machine Unlearning (ConMU), a\nnovel framework designed to facilitate the calibration of MU. The ConMU\nframework contains three integral modules: an important data selection module\nthat reconciles the runtime efficiency and model generalization, a progressive\nGaussian mechanism module that balances privacy and model generalization, and\nan unlearning proxy that controls the trade-offs between privacy and runtime\nefficiency. Comprehensive experiments on various benchmark datasets have\ndemonstrated the robust adaptability of our control mechanism and its\nsuperiority over established unlearning methods. ConMU explores the full\nspectrum of the Privacy-Utility-Efficiency trade-off and allows practitioners\nto account for different real-world regulations. Source code available at:\nhttps://github.com/guangyaodou/ConMU.",
            "author": [
                "Zheyuan Liu",
                "Guangyao Dou",
                "Yijun Tian",
                "Chunhui Zhang",
                "Eli Chien",
                "Ziwei Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18574v1",
                "http://arxiv.org/pdf/2310.18574v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18564v1",
            "title": "A General Framework for Robust G-Invariance in G-Equivariant Networks",
            "updated": "2023-10-28T02:27:34Z",
            "published": "2023-10-28T02:27:34Z",
            "summary": "We introduce a general method for achieving robust group-invariance in\ngroup-equivariant convolutional neural networks ($G$-CNNs), which we call the\n$G$-triple-correlation ($G$-TC) layer. The approach leverages the theory of the\ntriple-correlation on groups, which is the unique, lowest-degree polynomial\ninvariant map that is also complete. Many commonly used invariant maps - such\nas the max - are incomplete: they remove both group and signal structure. A\ncomplete invariant, by contrast, removes only the variation due to the actions\nof the group, while preserving all information about the structure of the\nsignal. The completeness of the triple correlation endows the $G$-TC layer with\nstrong robustness, which can be observed in its resistance to invariance-based\nadversarial attacks. In addition, we observe that it yields measurable\nimprovements in classification accuracy over standard Max $G$-Pooling in\n$G$-CNN architectures. We provide a general and efficient implementation of the\nmethod for any discretized group, which requires only a table defining the\ngroup's product structure. We demonstrate the benefits of this method for\n$G$-CNNs defined on both commutative and non-commutative groups - $SO(2)$,\n$O(2)$, $SO(3)$, and $O(3)$ (discretized as the cyclic $C8$, dihedral $D16$,\nchiral octahedral $O$ and full octahedral $O_h$ groups) - acting on\n$\\mathbb{R}^2$ and $\\mathbb{R}^3$ on both $G$-MNIST and $G$-ModelNet10\ndatasets.",
            "author": [
                "Sophia Sanborn",
                "Nina Miolane"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18564v1",
                "http://arxiv.org/pdf/2310.18564v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18562v1",
            "title": "Optimization-Free Test-Time Adaptation for Cross-Person Activity\n  Recognition",
            "updated": "2023-10-28T02:20:33Z",
            "published": "2023-10-28T02:20:33Z",
            "summary": "Human Activity Recognition (HAR) models often suffer from performance\ndegradation in real-world applications due to distribution shifts in activity\npatterns across individuals. Test-Time Adaptation (TTA) is an emerging learning\nparadigm that aims to utilize the test stream to adjust predictions in\nreal-time inference, which has not been explored in HAR before. However, the\nhigh computational cost of optimization-based TTA algorithms makes it\nintractable to run on resource-constrained edge devices. In this paper, we\npropose an Optimization-Free Test-Time Adaptation (OFTTA) framework for\nsensor-based HAR. OFTTA adjusts the feature extractor and linear classifier\nsimultaneously in an optimization-free manner. For the feature extractor, we\npropose Exponential DecayTest-time Normalization (EDTN) to replace the\nconventional batch normalization (CBN) layers. EDTN combines CBN and Test-time\nbatch Normalization (TBN) to extract reliable features against domain shifts\nwith TBN's influence decreasing exponentially in deeper layers. For the\nclassifier, we adjust the prediction by computing the distance between the\nfeature and the prototype, which is calculated by a maintained support set. In\naddition, the update of the support set is based on the pseudo label, which can\nbenefit from reliable features extracted by EDTN. Extensive experiments on\nthree public cross-person HAR datasets and two different TTA settings\ndemonstrate that OFTTA outperforms the state-of-the-art TTA approaches in both\nclassification performance and computational efficiency. Finally, we verify the\nsuperiority of our proposed OFTTA on edge devices, indicating possible\ndeployment in real applications. Our code is available at\n\\href{https://github.com/Claydon-Wang/OFTTA}{this https URL}.",
            "author": [
                "Shuoyuan Wang",
                "Jindong Wang",
                "HuaJun Xi",
                "Bob Zhang",
                "Lei Zhang",
                "Hongxin Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18562v1",
                "http://arxiv.org/pdf/2310.18562v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18560v1",
            "title": "Interpretable machine learning for finding intermediate-mass black holes",
            "updated": "2023-10-28T02:15:09Z",
            "published": "2023-10-28T02:15:09Z",
            "summary": "Definitive evidence that globular clusters (GCs) host intermediate-mass black\nholes (IMBHs) is elusive. Machine learning (ML) models trained on GC\nsimulations can in principle predict IMBH host candidates based on observable\nfeatures. This approach has two limitations: first, an accurate ML model is\nexpected to be a black box due to complexity; second, despite our efforts to\nrealistically simulate GCs, the simulation physics or initial conditions may\nfail to fully reflect reality. Therefore our training data may be biased,\nleading to a failure in generalization on observational data. Both the first\nissue -- explainability/interpretability -- and the second -- out of\ndistribution generalization and fairness -- are active areas of research in ML.\nHere we employ techniques from these fields to address them: we use the anchors\nmethod to explain an XGBoost classifier; we also independently train a natively\ninterpretable model using Certifiably Optimal RulE ListS (CORELS). The\nresulting model has a clear physical meaning, but loses some performance with\nrespect to XGBoost. We evaluate potential candidates in real data based not\nonly on classifier predictions but also on their similarity to the training\ndata, measured by the likelihood of a kernel density estimation model. This\nmeasures the realism of our simulated data and mitigates the risk that our\nmodels may produce biased predictions by working in extrapolation. We apply our\nclassifiers to real GCs, obtaining a predicted classification, a measure of the\nconfidence of the prediction, an out-of-distribution flag, a local rule\nexplaining the prediction of XGBoost and a global rule from CORELS.",
            "author": [
                "Mario Pasquato",
                "Piero Trevisan",
                "Abbas Askar",
                "Pablo Lemos",
                "Gaia Carenini",
                "Michela Mapelli",
                "Yashar Hezaveh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18560v1",
                "http://arxiv.org/pdf/2310.18560v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.HE",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18555v1",
            "title": "Group Robust Classification Without Any Group Information",
            "updated": "2023-10-28T01:29:18Z",
            "published": "2023-10-28T01:29:18Z",
            "summary": "Empirical risk minimization (ERM) is sensitive to spurious correlations in\nthe training data, which poses a significant risk when deploying systems\ntrained under this paradigm in high-stake applications. While the existing\nliterature focuses on maximizing group-balanced or worst-group accuracy,\nestimating these accuracies is hindered by costly bias annotations. This study\ncontends that current bias-unsupervised approaches to group robustness continue\nto rely on group information to achieve optimal performance. Firstly, these\nmethods implicitly assume that all group combinations are represented during\ntraining. To illustrate this, we introduce a systematic generalization task on\nthe MPI3D dataset and discover that current algorithms fail to improve the ERM\nbaseline when combinations of observed attribute values are missing. Secondly,\nbias labels are still crucial for effective model selection, restricting the\npracticality of these methods in real-world scenarios. To address these\nlimitations, we propose a revised methodology for training and validating\ndebiased models in an entirely bias-unsupervised manner. We achieve this by\nemploying pretrained self-supervised models to reliably extract bias\ninformation, which enables the integration of a logit adjustment training loss\nwith our validation criterion. Our empirical analysis on synthetic and\nreal-world tasks provides evidence that our approach overcomes the identified\nchallenges and consistently enhances robust accuracy, attaining performance\nwhich is competitive with or outperforms that of state-of-the-art methods,\nwhich, conversely, rely on bias labels for validation.",
            "author": [
                "Christos Tsirigotis",
                "Joao Monteiro",
                "Pau Rodriguez",
                "David Vazquez",
                "Aaron Courville"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18555v1",
                "http://arxiv.org/pdf/2310.18555v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18554v1",
            "title": "Improved Regret Bounds of (Multinomial) Logistic Bandits via\n  Regret-to-Confidence-Set Conversion",
            "updated": "2023-10-28T01:27:52Z",
            "published": "2023-10-28T01:27:52Z",
            "summary": "Logistic bandit is a ubiquitous framework of modeling users' choices, e.g.,\nclick vs. no click for advertisement recommender system. We observe that the\nprior works overlook or neglect dependencies in $S \\geq \\lVert \\theta_\\star\n\\rVert_2$, where $\\theta_\\star \\in \\mathbb{R}^d$ is the unknown parameter\nvector, which is particularly problematic when $S$ is large, e.g., $S \\geq d$.\nIn this work, we improve the dependency on $S$ via a novel approach called {\\it\nregret-to-confidence set conversion (R2CS)}, which allows us to construct a\nconvex confidence set based on only the \\textit{existence} of an online\nlearning algorithm with a regret guarantee. Using R2CS, we obtain a strict\nimprovement in the regret bound w.r.t. $S$ in logistic bandits while retaining\ncomputational feasibility and the dependence on other factors such as $d$ and\n$T$. We apply our new confidence set to the regret analyses of logistic bandits\nwith a new martingale concentration step that circumvents an additional factor\nof $S$. We then extend this analysis to multinomial logistic bandits and obtain\nsimilar improvements in the regret, showing the efficacy of R2CS. While we\napplied R2CS to the (multinomial) logistic model, R2CS is a generic approach\nfor developing confidence sets that can be used for various models, which can\nbe of independent interest.",
            "author": [
                "Junghyun Lee",
                "Se-Young Yun",
                "Kwang-Sung Jun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18554v1",
                "http://arxiv.org/pdf/2310.18554v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18552v1",
            "title": "The Role of Reference Points in Machine-Learned Atomistic Simulation\n  Models",
            "updated": "2023-10-28T01:02:14Z",
            "published": "2023-10-28T01:02:14Z",
            "summary": "This paper introduces the Chemical Environment Modeling Theory (CEMT), a\nnovel, generalized framework designed to overcome the limitations inherent in\ntraditional atom-centered Machine Learning Force Field (MLFF) models, widely\nused in atomistic simulations of chemical systems. CEMT demonstrated enhanced\nflexibility and adaptability by allowing reference points to exist anywhere\nwithin the modeled domain and thus, enabling the study of various model\narchitectures. Utilizing Gaussian Multipole (GMP) featurization functions,\nseveral models with different reference point sets, including finite difference\ngrid-centered and bond-centered models, were tested to analyze the variance in\ncapabilities intrinsic to models built on distinct reference points. The\nresults underscore the potential of non-atom-centered reference points in force\ntraining, revealing variations in prediction accuracy, inference speed and\nlearning efficiency. Finally, a unique connection between CEMT and real-space\norbital-free finite element Density Functional Theory (FE-DFT) is established,\nand the implications include the enhancement of data efficiency and robustness.\nIt allows the leveraging of spatially-resolved energy densities and charge\ndensities from FE-DFT calculations, as well as serving as a pivotal step\ntowards integrating known quantum-mechanical laws into the architecture of ML\nmodels.",
            "author": [
                "Xiangyun Lei",
                "Weike Ye",
                "Joseph Montoya",
                "Tim Mueller",
                "Linda Hung",
                "Jens Hummelshoej"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18552v1",
                "http://arxiv.org/pdf/2310.18552v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18549v1",
            "title": "Deep Intrinsic Decomposition with Adversarial Learning for Hyperspectral\n  Image Classification",
            "updated": "2023-10-28T00:41:25Z",
            "published": "2023-10-28T00:41:25Z",
            "summary": "Convolutional neural networks (CNNs) have been demonstrated their powerful\nability to extract discriminative features for hyperspectral image\nclassification. However, general deep learning methods for CNNs ignore the\ninfluence of complex environmental factor which enlarges the intra-class\nvariance and decreases the inter-class variance. This multiplies the difficulty\nto extract discriminative features. To overcome this problem, this work\ndevelops a novel deep intrinsic decomposition with adversarial learning, namely\nAdverDecom, for hyperspectral image classification to mitigate the negative\nimpact of environmental factors on classification performance. First, we\ndevelop a generative network for hyperspectral image (HyperNet) to extract the\nenvironmental-related feature and category-related feature from the image.\nThen, a discriminative network is constructed to distinguish different\nenvironmental categories. Finally, a environmental and category joint learning\nloss is developed for adversarial learning to make the deep model learn\ndiscriminative features. Experiments are conducted over three commonly used\nreal-world datasets and the comparison results show the superiority of the\nproposed method. The implementation of the proposed method and other compared\nmethods could be accessed at https://github.com/shendu-sw/Adversarial Learning\nIntrinsic Decomposition for the sake of reproducibility.",
            "author": [
                "Zhiqiang Gong",
                "Xian Zhou",
                "Wen Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18549v1",
                "http://arxiv.org/pdf/2310.18549v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18547v1",
            "title": "Punica: Multi-Tenant LoRA Serving",
            "updated": "2023-10-28T00:33:37Z",
            "published": "2023-10-28T00:33:37Z",
            "summary": "Low-rank adaptation (LoRA) has become an important and popular method to\nadapt pre-trained models to specific domains. We present Punica, a system to\nserve multiple LoRA models in a shared GPU cluster. Punica contains a new CUDA\nkernel design that allows batching of GPU operations for different LoRA models.\nThis allows a GPU to hold only a single copy of the underlying pre-trained\nmodel when serving multiple, different LoRA models, significantly enhancing GPU\nefficiency in terms of both memory and computation. Our scheduler consolidates\nmulti-tenant LoRA serving workloads in a shared GPU cluster. With a fixed-sized\nGPU cluster, our evaluations show that Punica achieves 12x higher throughput in\nserving multiple LoRA models compared to state-of-the-art LLM serving systems\nwhile only adding 2ms latency per token. Punica is open source at\nhttps://github.com/punica-ai/punica .",
            "author": [
                "Lequn Chen",
                "Zihao Ye",
                "Yongji Wu",
                "Danyang Zhuo",
                "Luis Ceze",
                "Arvind Krishnamurthy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18547v1",
                "http://arxiv.org/pdf/2310.18547v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18542v1",
            "title": "End-to-end Feature Selection Approach for Learning Skinny Trees",
            "updated": "2023-10-28T00:15:10Z",
            "published": "2023-10-28T00:15:10Z",
            "summary": "Joint feature selection and tree ensemble learning is a challenging task.\nPopular tree ensemble toolkits e.g., Gradient Boosted Trees and Random Forests\nsupport feature selection post-training based on feature importances, which are\nknown to be misleading, and can significantly hurt performance. We propose\nSkinny Trees: a toolkit for feature selection in tree ensembles, such that\nfeature selection and tree ensemble learning occurs simultaneously. It is based\non an end-to-end optimization approach that considers feature selection in\ndifferentiable trees with Group $\\ell_0 - \\ell_2$ regularization. We optimize\nwith a first-order proximal method and present convergence guarantees for a\nnon-convex and non-smooth objective. Interestingly, dense-to-sparse\nregularization scheduling can lead to more expressive and sparser tree\nensembles than vanilla proximal method. On 15 synthetic and real-world\ndatasets, Skinny Trees can achieve $1.5\\times$ - $620\\times$ feature\ncompression rates, leading up to $10\\times$ faster inference over dense trees,\nwithout any loss in performance. Skinny Trees lead to superior feature\nselection than many existing toolkits e.g., in terms of AUC performance for\n$25\\%$ feature budget, Skinny Trees outperforms LightGBM by $10.2\\%$ (up to\n$37.7\\%$), and Random Forests by $3\\%$ (up to $12.5\\%$).",
            "author": [
                "Shibal Ibrahim",
                "Kayhan Behdin",
                "Rahul Mazumder"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18542v1",
                "http://arxiv.org/pdf/2310.18542v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18541v1",
            "title": "ReConTab: Regularized Contrastive Representation Learning for Tabular\n  Data",
            "updated": "2023-10-28T00:05:28Z",
            "published": "2023-10-28T00:05:28Z",
            "summary": "Representation learning stands as one of the critical machine learning\ntechniques across various domains. Through the acquisition of high-quality\nfeatures, pre-trained embeddings significantly reduce input space redundancy,\nbenefiting downstream pattern recognition tasks such as classification,\nregression, or detection. Nonetheless, in the domain of tabular data, feature\nengineering and selection still heavily rely on manual intervention, leading to\ntime-consuming processes and necessitating domain expertise. In response to\nthis challenge, we introduce ReConTab, a deep automatic representation learning\nframework with regularized contrastive learning. Agnostic to any type of\nmodeling task, ReConTab constructs an asymmetric autoencoder based on the same\nraw features from model inputs, producing low-dimensional representative\nembeddings. Specifically, regularization techniques are applied for raw feature\nselection. Meanwhile, ReConTab leverages contrastive learning to distill the\nmost pertinent information for downstream tasks. Experiments conducted on\nextensive real-world datasets substantiate the framework's capacity to yield\nsubstantial and robust performance improvements. Furthermore, we empirically\ndemonstrate that pre-trained embeddings can seamlessly integrate as easily\nadaptable features, enhancing the performance of various traditional methods\nsuch as XGBoost and Random Forest.",
            "author": [
                "Suiyao Chen",
                "Jing Wu",
                "Naira Hovakimyan",
                "Handong Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18541v1",
                "http://arxiv.org/pdf/2310.18541v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18539v1",
            "title": "Prediction of Yield Surface of Single Crystal Copper from Discrete\n  Dislocation Dynamics and Geometric Learning",
            "updated": "2023-10-27T23:38:49Z",
            "published": "2023-10-27T23:38:49Z",
            "summary": "A yield surface of a material is a set of critical stress conditions beyond\nwhich macroscopic plastic deformation begins. For crystalline solids, plastic\ndeformation occurs by the motion of dislocations, which can be captured by\ndiscrete dislocation dynamics (DDD) simulations. In this paper, we predict the\nyield surfaces and strain-hardening behaviors using DDD simulations and a\ngeometric manifold learning approach. The yield surfaces in the\nthree-dimensional space of plane stress are constructed for single-crystal\ncopper subjected to uniaxial loading along the $[100]$ and $[110]$ directions,\nrespectively. With increasing plastic deformation under $[100]$ loading, the\nyield surface expands nearly uniformly in all directions, corresponding to\nisotropic hardening. In contrast, under $[110]$ loading, latent hardening is\nobserved, where the yield surface remains nearly unchanged in the orientations\nin the vicinity of the loading direction itself, but expands in other\ndirections, resulting in an asymmetric shape. This difference in hardening\nbehaviors is attributed to the different dislocation multiplication behaviors\non various slip systems under the two loading conditions.",
            "author": [
                "Wu-Rong Jian",
                "Mian Xiao",
                "WaiChing Sun",
                "Wei Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18539v1",
                "http://arxiv.org/pdf/2310.18539v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18538v1",
            "title": "Evaluating Cross-Domain Text-to-SQL Models and Benchmarks",
            "updated": "2023-10-27T23:36:14Z",
            "published": "2023-10-27T23:36:14Z",
            "summary": "Text-to-SQL benchmarks play a crucial role in evaluating the progress made in\nthe field and the ranking of different models. However, accurately matching a\nmodel-generated SQL query to a reference SQL query in a benchmark fails for\nvarious reasons, such as underspecified natural language queries, inherent\nassumptions in both model-generated and reference queries, and the\nnon-deterministic nature of SQL output under certain conditions. In this paper,\nwe conduct an extensive study of several prominent cross-domain text-to-SQL\nbenchmarks and re-evaluate some of the top-performing models within these\nbenchmarks, by both manually evaluating the SQL queries and rewriting them in\nequivalent expressions. Our evaluation reveals that attaining a perfect\nperformance on these benchmarks is unfeasible due to the multiple\ninterpretations that can be derived from the provided samples. Furthermore, we\nfind that the true performance of the models is underestimated and their\nrelative performance changes after a re-evaluation. Most notably, our\nevaluation reveals a surprising discovery: a recent GPT4-based model surpasses\nthe gold standard reference queries in the Spider benchmark in our human\nevaluation. This finding highlights the importance of interpreting benchmark\nevaluations cautiously, while also acknowledging the critical role of\nadditional independent evaluations in driving advancements in the field.",
            "author": [
                "Mohammadreza Pourreza",
                "Davood Rafiei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18538v1",
                "http://arxiv.org/pdf/2310.18538v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18535v1",
            "title": "Contextual Stochastic Bilevel Optimization",
            "updated": "2023-10-27T23:24:37Z",
            "published": "2023-10-27T23:24:37Z",
            "summary": "We introduce contextual stochastic bilevel optimization (CSBO) -- a\nstochastic bilevel optimization framework with the lower-level problem\nminimizing an expectation conditioned on some contextual information and the\nupper-level decision variable. This framework extends classical stochastic\nbilevel optimization when the lower-level decision maker responds optimally not\nonly to the decision of the upper-level decision maker but also to some side\ninformation and when there are multiple or even infinite many followers. It\ncaptures important applications such as meta-learning, personalized federated\nlearning, end-to-end learning, and Wasserstein distributionally robust\noptimization with side information (WDRO-SI). Due to the presence of contextual\ninformation, existing single-loop methods for classical stochastic bilevel\noptimization are unable to converge. To overcome this challenge, we introduce\nan efficient double-loop gradient method based on the Multilevel Monte-Carlo\n(MLMC) technique and establish its sample and computational complexities. When\nspecialized to stochastic nonconvex optimization, our method matches existing\nlower bounds. For meta-learning, the complexity of our method does not depend\non the number of tasks. Numerical experiments further validate our theoretical\nresults.",
            "author": [
                "Yifan Hu",
                "Jie Wang",
                "Yao Xie",
                "Andreas Krause",
                "Daniel Kuhn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18535v1",
                "http://arxiv.org/pdf/2310.18535v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18534v3",
            "title": "Multi Time Scale World Models",
            "updated": "2023-12-04T10:20:40Z",
            "published": "2023-10-27T23:18:44Z",
            "summary": "Intelligent agents use internal world models to reason and make predictions\nabout different courses of their actions at many scales. Devising learning\nparadigms and architectures that allow machines to learn world models that\noperate at multiple levels of temporal abstractions while dealing with complex\nuncertainty predictions is a major technical hurdle. In this work, we propose a\nprobabilistic formalism to learn multi-time scale world models which we call\nthe Multi Time Scale State Space (MTS3) model. Our model uses a computationally\nefficient inference scheme on multiple time scales for highly accurate\nlong-horizon predictions and uncertainty estimates over several seconds into\nthe future. Our experiments, which focus on action conditional long horizon\nfuture predictions, show that MTS3 outperforms recent methods on several system\nidentification benchmarks including complex simulated and real-world dynamical\nsystems. Code is available at this repository: https://github.com/ALRhub/MTS3.",
            "author": [
                "Vaisakh Shaj",
                "Saleh Gholam Zadeh",
                "Ozan Demir",
                "Luiz Ricardo Douat",
                "Gerhard Neumann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18534v3",
                "http://arxiv.org/pdf/2310.18534v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18531v1",
            "title": "Feature Selection in the Contrastive Analysis Setting",
            "updated": "2023-10-27T23:16:03Z",
            "published": "2023-10-27T23:16:03Z",
            "summary": "Contrastive analysis (CA) refers to the exploration of variations uniquely\nenriched in a target dataset as compared to a corresponding background dataset\ngenerated from sources of variation that are irrelevant to a given task. For\nexample, a biomedical data analyst may wish to find a small set of genes to use\nas a proxy for variations in genomic data only present among patients with a\ngiven disease (target) as opposed to healthy control subjects (background).\nHowever, as of yet the problem of feature selection in the CA setting has\nreceived little attention from the machine learning community. In this work we\npresent contrastive feature selection (CFS), a method for performing feature\nselection in the CA setting. We motivate our approach with a novel\ninformation-theoretic analysis of representation learning in the CA setting,\nand we empirically validate CFS on a semi-synthetic dataset and four real-world\nbiomedical datasets. We find that our method consistently outperforms\npreviously proposed state-of-the-art supervised and fully unsupervised feature\nselection methods not designed for the CA setting. An open-source\nimplementation of our method is available at https://github.com/suinleelab/CFS.",
            "author": [
                "Ethan Weinberger",
                "Ian Covert",
                "Su-In Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18531v1",
                "http://arxiv.org/pdf/2310.18531v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18529v2",
            "title": "FPM-INR: Fourier ptychographic microscopy image stack reconstruction\n  using implicit neural representations",
            "updated": "2023-10-31T20:22:28Z",
            "published": "2023-10-27T23:13:49Z",
            "summary": "Image stacks provide invaluable 3D information in various biological and\npathological imaging applications. Fourier ptychographic microscopy (FPM)\nenables reconstructing high-resolution, wide field-of-view image stacks without\nz-stack scanning, thus significantly accelerating image acquisition. However,\nexisting FPM methods take tens of minutes to reconstruct and gigabytes of\nmemory to store a high-resolution volumetric scene, impeding fast\ngigapixel-scale remote digital pathology. While deep learning approaches have\nbeen explored to address this challenge, existing methods poorly generalize to\nnovel datasets and can produce unreliable hallucinations. This work presents\nFPM-INR, a compact and efficient framework that integrates physics-based\noptical models with implicit neural representations (INR) to represent and\nreconstruct FPM image stacks. FPM-INR is agnostic to system design or sample\ntypes and does not require external training data. In our demonstrated\nexperiments, FPM-INR substantially outperforms traditional FPM algorithms with\nup to a 25-fold increase in speed and an 80-fold reduction in memory usage for\ncontinuous image stack representations.",
            "author": [
                "Haowen Zhou",
                "Brandon Y. Feng",
                "Haiyun Guo",
                "Siyu Lin",
                "Mingshu Liang",
                "Christopher A. Metzler",
                "Changhuei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18529v2",
                "http://arxiv.org/pdf/2310.18529v2"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18526v1",
            "title": "Sample based Explanations via Generalized Representers",
            "updated": "2023-10-27T22:54:47Z",
            "published": "2023-10-27T22:54:47Z",
            "summary": "We propose a general class of sample based explanations of machine learning\nmodels, which we term generalized representers. To measure the effect of a\ntraining sample on a model's test prediction, generalized representers use two\ncomponents: a global sample importance that quantifies the importance of the\ntraining point to the model and is invariant to test samples, and a local\nsample importance that measures similarity between the training sample and the\ntest point with a kernel. A key contribution of the paper is to show that\ngeneralized representers are the only class of sample based explanations\nsatisfying a natural set of axiomatic properties. We discuss approaches to\nextract global importances given a kernel, and also natural choices of kernels\ngiven modern non-linear models. As we show, many popular existing sample based\nexplanations could be cast as generalized representers with particular choices\nof kernels and approaches to extract global importances. Additionally, we\nconduct empirical comparisons of different generalized representers on two\nimage and two text classification datasets.",
            "author": [
                "Che-Ping Tsai",
                "Chih-Kuan Yeh",
                "Pradeep Ravikumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18526v1",
                "http://arxiv.org/pdf/2310.18526v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18523v1",
            "title": "Using convolutional neural networks for stereological characterization\n  of 3D hetero-aggregates based on synthetic STEM data",
            "updated": "2023-10-27T22:49:08Z",
            "published": "2023-10-27T22:49:08Z",
            "summary": "The structural characterization of hetero-aggregates in 3D is of great\ninterest, e.g., for deriving process-structure or structure-property\nrelationships. However, since 3D imaging techniques are often difficult to\nperform as well as time and cost intensive, a characterization of\nhetero-aggregates based on 2D image data is desirable, but often non-trivial.\nTo overcome the issues of characterizing 3D structures from 2D measurements, a\nmethod is presented that relies on machine learning combined with methods of\nspatial stochastic modeling, where the latter are utilized for the generation\nof synthetic training data. This kind of training data has the advantage that\ntime-consuming experiments for the synthesis of differently structured\nmaterials followed by their 3D imaging can be avoided. More precisely, a\nparametric stochastic 3D model is presented, from which a wide spectrum of\nvirtual hetero-aggregates can be generated. Additionally, the virtual\nstructures are passed to a physics-based simulation tool in order to generate\nvirtual scanning transmission electron microscopy (STEM) images. The preset\nparameters of the 3D model together with the simulated STEM images serve as a\ndatabase for the training of convolutional neural networks, which can be used\nto determine the parameters of the underlying 3D model and, consequently, to\npredict 3D structures of hetero-aggregates from 2D STEM images. Furthermore, an\nerror analysis is performed to evaluate the prediction power of the trained\nneural networks with respect to structural descriptors, e.g. the\nhetero-coordination number.",
            "author": [
                "Lukas Fuchs",
                "Tom Kirstein",
                "Christoph Mahr",
                "Orkun Furat",
                "Valentin Baric",
                "Andreas Rosenauer",
                "Lutz Maedler",
                "Volker Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18523v1",
                "http://arxiv.org/pdf/2310.18523v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18519v1",
            "title": "Practical trainable temporal post-processor for multi-state quantum\n  measurement",
            "updated": "2023-10-27T22:36:59Z",
            "published": "2023-10-27T22:36:59Z",
            "summary": "We develop and demonstrate a trainable temporal post-processor (TPP),\nharnessing a simple but versatile machine learning algorithm to provide optimal\nprocessing of quantum measurement data subject to arbitrary noise processes,\nfor the readout of an arbitrary number of quantum states. We demonstrate the\nTPP on the essential task of qubit state readout, which has historically relied\non temporal processing via matched filters in spite of their applicability only\nfor specific noise conditions. Our results show that the TPP can reliably\noutperform standard filtering approaches under complex readout conditions, such\nas high power readout. Using simulations of quantum measurement noise sources,\nwe show that this advantage relies on the TPP's ability to learn optimal linear\nfilters that account for general quantum noise correlations in data, such as\nthose due to quantum jumps, or correlated noise added by a phase-preserving\nquantum amplifier. Furthermore, for signals subject to Gaussian white noise\nprocesses, the TPP provides a linearly-scaling semi-analytic generalization of\nmatched filtering to an arbitrary number of states. The TPP can be efficiently,\nautonomously, and reliably trained on measurement data, and requires only\nlinear operations, making it ideal for FPGA implementations in cQED for\nreal-time processing of measurement data from general quantum systems.",
            "author": [
                "Saeed A. Khan",
                "Ryan Kaufman",
                "Boris Mesits",
                "Michael Hatridge",
                "Hakan E. T\u00fcreci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18519v1",
                "http://arxiv.org/pdf/2310.18519v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18517v1",
            "title": "Learning to recognize occluded and small objects with partial inputs",
            "updated": "2023-10-27T22:29:27Z",
            "published": "2023-10-27T22:29:27Z",
            "summary": "Recognizing multiple objects in an image is challenging due to occlusions,\nand becomes even more so when the objects are small. While promising, existing\nmulti-label image recognition models do not explicitly learn context-based\nrepresentations, and hence struggle to correctly recognize small and occluded\nobjects. Intuitively, recognizing occluded objects requires knowledge of\npartial input, and hence context. Motivated by this intuition, we propose\nMasked Supervised Learning (MSL), a single-stage, model-agnostic learning\nparadigm for multi-label image recognition. The key idea is to learn\ncontext-based representations using a masked branch and to model label\nco-occurrence using label consistency. Experimental results demonstrate the\nsimplicity, applicability and more importantly the competitive performance of\nMSL against previous state-of-the-art methods on standard multi-label image\nrecognition benchmarks. In addition, we show that MSL is robust to random\nmasking and demonstrate its effectiveness in recognizing non-masked objects.\nCode and pretrained models are available on GitHub.",
            "author": [
                "Hasib Zunair",
                "A. Ben Hamza"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18517v1",
                "http://arxiv.org/pdf/2310.18517v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18516v1",
            "title": "Operator is the Model",
            "updated": "2023-10-27T22:29:23Z",
            "published": "2023-10-27T22:29:23Z",
            "summary": "Koopman operator based models emerged as the leading methodology for machine\nlearning of dynamical systems. But their scope is much larger. In fact they\npresent a new take on modeling of physical systems, and even language. In this\narticle I present some of the underlying mathematical structures, applications,\nconnections to other methodologies such as transformer architectures",
            "author": [
                "Igor Mezi\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18516v1",
                "http://arxiv.org/pdf/2310.18516v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18515v2",
            "title": "Learning to design protein-protein interactions with enhanced\n  generalization",
            "updated": "2023-11-27T21:21:48Z",
            "published": "2023-10-27T22:22:44Z",
            "summary": "Discovering mutations enhancing protein-protein interactions (PPIs) is\ncritical for advancing biomedical research and developing improved\ntherapeutics. While machine learning approaches have substantially advanced the\nfield, they often struggle to generalize beyond training data in practical\nscenarios. The contributions of this work are three-fold. First, we construct\nPPIRef, the largest and non-redundant dataset of 3D protein-protein\ninteractions, enabling effective large-scale learning. Second, we leverage the\nPPIRef dataset to pre-train PPIformer, a new SE(3)-equivariant model\ngeneralizing across diverse protein-binder variants. We fine-tune PPIformer to\npredict effects of mutations on protein-protein interactions via a\nthermodynamically motivated adjustment of the pre-training loss function.\nFinally, we demonstrate the enhanced generalization of our new PPIformer\napproach by outperforming other state-of-the-art methods on new, non-leaking\nsplits of standard labeled PPI mutational data and independent case studies\noptimizing a human antibody against SARS-CoV-2 and increasing the thrombolytic\nactivity of staphylokinase.",
            "author": [
                "Anton Bushuiev",
                "Roman Bushuiev",
                "Petr Kouba",
                "Anatolii Filkin",
                "Marketa Gabrielova",
                "Michal Gabriel",
                "Jiri Sedlar",
                "Tomas Pluskal",
                "Jiri Damborsky",
                "Stanislav Mazurenko",
                "Josef Sivic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18515v2",
                "http://arxiv.org/pdf/2310.18515v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18512v2",
            "title": "Preventing Language Models From Hiding Their Reasoning",
            "updated": "2023-10-31T19:13:43Z",
            "published": "2023-10-27T22:02:29Z",
            "summary": "Large language models (LLMs) often benefit from intermediate steps of\nreasoning to generate answers to complex problems. When these intermediate\nsteps of reasoning are used to monitor the activity of the model, it is\nessential that this explicit reasoning is faithful, i.e. that it reflects what\nthe model is actually reasoning about. In this work, we focus on one potential\nway intermediate steps of reasoning could be unfaithful: encoded reasoning,\nwhere an LLM could encode intermediate steps of reasoning in the generated text\nin a way that is not understandable to human readers. We show that language\nmodels can be trained to make use of encoded reasoning to get higher\nperformance without the user understanding the intermediate steps of reasoning.\nWe argue that, as language models get stronger, this behavior becomes more\nlikely to appear naturally. Finally, we describe a methodology that enables the\nevaluation of defenses against encoded reasoning, and show that, under the\nright conditions, paraphrasing successfully prevents even the best encoding\nschemes we built from encoding more than 3 bits of information per KB of text.",
            "author": [
                "Fabien Roger",
                "Ryan Greenblatt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18512v2",
                "http://arxiv.org/pdf/2310.18512v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06281v2",
            "title": "Efficient Parallelization of an Ubiquitous Sequential Computation",
            "updated": "2023-11-15T14:53:19Z",
            "published": "2023-10-27T21:58:55Z",
            "summary": "We find a succinct expression for computing the sequence $x_t = a_t x_{t-1} +\nb_t$ in parallel with two prefix sums, given $t = (1, 2, \\dots, n)$, $a_t \\in\n\\mathbb{R}^n$, $b_t \\in \\mathbb{R}^n$, and initial value $x_0 \\in \\mathbb{R}$.\nOn $n$ parallel processors, the computation of $n$ elements incurs\n$\\mathcal{O}(\\log n)$ time and $\\mathcal{O}(n)$ space. Sequences of this form\nare ubiquitous in science and engineering, making efficient parallelization\nuseful for a vast number of applications. We implement our expression in\nsoftware, test it on parallel hardware, and verify that it executes faster than\nsequential computation by a factor of $\\frac{n}{\\log n}$.",
            "author": [
                "Franz A. Heinsen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06281v2",
                "http://arxiv.org/pdf/2311.06281v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18509v1",
            "title": "Deep Reinforcement Learning for Weapons to Targets Assignment in a\n  Hypersonic strike",
            "updated": "2023-10-27T21:58:05Z",
            "published": "2023-10-27T21:58:05Z",
            "summary": "We use deep reinforcement learning (RL) to optimize a weapons to target\nassignment (WTA) policy for multi-vehicle hypersonic strike against multiple\ntargets. The objective is to maximize the total value of destroyed targets in\neach episode. Each randomly generated episode varies the number and initial\nconditions of the hypersonic strike weapons (HSW) and targets, the value\ndistribution of the targets, and the probability of a HSW being intercepted. We\ncompare the performance of this WTA policy to that of a benchmark WTA policy\nderived using non-linear integer programming (NLIP), and find that the RL WTA\npolicy gives near optimal performance with a 1000X speedup in computation time,\nallowing real time operation that facilitates autonomous decision making in the\nmission end game.",
            "author": [
                "Brian Gaudet",
                "Kris Drozd",
                "Roberto Furfaro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18509v1",
                "http://arxiv.org/pdf/2310.18509v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18505v1",
            "title": "Multi-fidelity Design of Porous Microstructures for Thermofluidic\n  Applications",
            "updated": "2023-10-27T21:51:11Z",
            "published": "2023-10-27T21:51:11Z",
            "summary": "As modern electronic devices are increasingly miniaturized and integrated,\ntheir performance relies more heavily on effective thermal management.\nTwo-phase cooling methods enhanced by porous surfaces, which capitalize on\nthin-film evaporation atop structured porous surfaces, are emerging as\npotential solutions. In such porous structures, the optimum heat dissipation\ncapacity relies on two competing objectives that depend on mass and heat\ntransfer. The computational costs of evaluating these objectives, the high\ndimensionality of the design space which a voxelated microstructure\nrepresentation, and the manufacturability constraints hinder the optimization\nprocess for thermal management. We address these challenges by developing a\ndata-driven framework for designing optimal porous microstructures for cooling\napplications. In our framework we leverage spectral density functions (SDFs) to\nencode the design space via a handful of interpretable variables and, in turn,\nefficiently search it. We develop physics-based formulas to quantify the\nthermofluidic properties and feasibility of candidate designs via offline\nsimulations. To decrease the reliance on expensive simulations, we generate\nmulti-fidelity data and build emulators to find Pareto-optimal designs. We\napply our approach to a canonical problem on evaporator wick design and obtain\nfin-like topologies in the optimal microstructures which are also\ncharacteristics often observed in industrial applications.",
            "author": [
                "Jonathan Tammer Eweis-LaBolle",
                "Chuanning Zhao",
                "Yoonjin Won",
                "Ramin Bostanabad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18505v1",
                "http://arxiv.org/pdf/2310.18505v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18498v1",
            "title": "GPT-4 Vision on Medical Image Classification -- A Case Study on COVID-19\n  Dataset",
            "updated": "2023-10-27T21:28:36Z",
            "published": "2023-10-27T21:28:36Z",
            "summary": "This technical report delves into the application of GPT-4 Vision (GPT-4V) in\nthe nuanced realm of COVID-19 image classification, leveraging the\ntransformative potential of in-context learning to enhance diagnostic\nprocesses.",
            "author": [
                "Ruibo Chen",
                "Tianyi Xiong",
                "Yihan Wu",
                "Guodong Liu",
                "Zhengmian Hu",
                "Lichang Chen",
                "Yanshuo Chen",
                "Chenxi Liu",
                "Heng Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18498v1",
                "http://arxiv.org/pdf/2310.18498v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18496v1",
            "title": "How Well Do Feature-Additive Explainers Explain Feature-Additive\n  Predictors?",
            "updated": "2023-10-27T21:16:28Z",
            "published": "2023-10-27T21:16:28Z",
            "summary": "Surging interest in deep learning from high-stakes domains has precipitated\nconcern over the inscrutable nature of black box neural networks. Explainable\nAI (XAI) research has led to an abundance of explanation algorithms for these\nblack boxes. Such post hoc explainers produce human-comprehensible\nexplanations, however, their fidelity with respect to the model is not well\nunderstood - explanation evaluation remains one of the most challenging issues\nin XAI. In this paper, we ask a targeted but important question: can popular\nfeature-additive explainers (e.g., LIME, SHAP, SHAPR, MAPLE, and PDP) explain\nfeature-additive predictors? Herein, we evaluate such explainers on ground\ntruth that is analytically derived from the additive structure of a model. We\ndemonstrate the efficacy of our approach in understanding these explainers\napplied to symbolic expressions, neural networks, and generalized additive\nmodels on thousands of synthetic and several real-world tasks. Our results\nsuggest that all explainers eventually fail to correctly attribute the\nimportance of features, especially when a decision-making process involves\nfeature interactions.",
            "author": [
                "Zachariah Carmichael",
                "Walter J. Scheirer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18496v1",
                "http://arxiv.org/pdf/2310.18496v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18491v1",
            "title": "Publicly Detectable Watermarking for Language Models",
            "updated": "2023-10-27T21:08:51Z",
            "published": "2023-10-27T21:08:51Z",
            "summary": "We construct the first provable watermarking scheme for language models with\npublic detectability or verifiability: we use a private key for watermarking\nand a public key for watermark detection. Our protocol is the first\nwatermarking scheme that does not embed a statistical signal in generated text.\nRather, we directly embed a publicly-verifiable cryptographic signature using a\nform of rejection sampling. We show that our construction meets strong formal\nsecurity guarantees and preserves many desirable properties found in schemes in\nthe private-key watermarking setting. In particular, our watermarking scheme\nretains distortion-freeness and model agnosticity. We implement our scheme and\nmake empirical measurements over open models in the 7B parameter range. Our\nexperiments suggest that our watermarking scheme meets our formal claims while\npreserving text quality.",
            "author": [
                "Jaiden Fairoze",
                "Sanjam Garg",
                "Somesh Jha",
                "Saeed Mahloujifar",
                "Mohammad Mahmoody",
                "Mingyuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18491v1",
                "http://arxiv.org/pdf/2310.18491v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18481v1",
            "title": "MOSEL: Inference Serving Using Dynamic Modality Selection",
            "updated": "2023-10-27T20:50:56Z",
            "published": "2023-10-27T20:50:56Z",
            "summary": "Rapid advancements over the years have helped machine learning models reach\npreviously hard-to-achieve goals, sometimes even exceeding human capabilities.\nHowever, to attain the desired accuracy, the model sizes and in turn their\ncomputational requirements have increased drastically. Thus, serving\npredictions from these models to meet any target latency and cost requirements\nof applications remains a key challenge, despite recent work in building\ninference-serving systems as well as algorithmic approaches that dynamically\nadapt models based on inputs. In this paper, we introduce a form of dynamism,\nmodality selection, where we adaptively choose modalities from inference inputs\nwhile maintaining the model quality. We introduce MOSEL, an automated inference\nserving system for multi-modal ML models that carefully picks input modalities\nper request based on user-defined performance and accuracy requirements. MOSEL\nexploits modality configurations extensively, improving system throughput by\n3.6$\\times$ with an accuracy guarantee and shortening job completion times by\n11$\\times$.",
            "author": [
                "Bodun Hu",
                "Le Xu",
                "Jeongyoon Moon",
                "Neeraja J. Yadwadkar",
                "Aditya Akella"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18481v1",
                "http://arxiv.org/pdf/2310.18481v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.OS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18479v1",
            "title": "Weighted Sampled Split Learning (WSSL): Balancing Privacy, Robustness,\n  and Fairness in Distributed Learning Environments",
            "updated": "2023-10-27T20:50:21Z",
            "published": "2023-10-27T20:50:21Z",
            "summary": "This study presents Weighted Sampled Split Learning (WSSL), an innovative\nframework tailored to bolster privacy, robustness, and fairness in distributed\nmachine learning systems. Unlike traditional approaches, WSSL disperses the\nlearning process among multiple clients, thereby safeguarding data\nconfidentiality. Central to WSSL's efficacy is its utilization of weighted\nsampling. This approach ensures equitable learning by tactically selecting\ninfluential clients based on their contributions. Our evaluation of WSSL\nspanned various client configurations and employed two distinct datasets: Human\nGait Sensor and CIFAR-10. We observed three primary benefits: heightened model\naccuracy, enhanced robustness, and maintained fairness across diverse client\ncompositions. Notably, our distributed frameworks consistently surpassed\ncentralized counterparts, registering accuracy peaks of 82.63% and 75.51% for\nthe Human Gait Sensor and CIFAR-10 datasets, respectively. These figures\ncontrast with the top accuracies of 81.12% and 58.60% achieved by centralized\nsystems. Collectively, our findings champion WSSL as a potent and scalable\nsuccessor to conventional centralized learning, marking it as a pivotal stride\nforward in privacy-focused, resilient, and impartial distributed machine\nlearning.",
            "author": [
                "Manish Osti",
                "Aashray Thakuri",
                "Basheer Qolomany",
                "Aos Mulahuwaish"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18479v1",
                "http://arxiv.org/pdf/2310.18479v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18477v2",
            "title": "Understanding and Improving Ensemble Adversarial Defense",
            "updated": "2023-11-02T11:57:18Z",
            "published": "2023-10-27T20:43:29Z",
            "summary": "The strategy of ensemble has become popular in adversarial defense, which\ntrains multiple base classifiers to defend against adversarial attacks in a\ncooperative manner. Despite the empirical success, theoretical explanations on\nwhy an ensemble of adversarially trained classifiers is more robust than single\nones remain unclear. To fill in this gap, we develop a new error theory\ndedicated to understanding ensemble adversarial defense, demonstrating a\nprovable 0-1 loss reduction on challenging sample sets in an adversarial\ndefense scenario. Guided by this theory, we propose an effective approach to\nimprove ensemble adversarial defense, named interactive global adversarial\ntraining (iGAT). The proposal includes (1) a probabilistic distributing rule\nthat selectively allocates to different base classifiers adversarial examples\nthat are globally challenging to the ensemble, and (2) a regularization term to\nrescue the severest weaknesses of the base classifiers. Being tested over\nvarious existing ensemble adversarial defense techniques, iGAT is capable of\nboosting their performance by increases up to 17% evaluated using CIFAR10 and\nCIFAR100 datasets under both white-box and black-box attacks.",
            "author": [
                "Yian Deng",
                "Tingting Mu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18477v2",
                "http://arxiv.org/pdf/2310.18477v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18472v1",
            "title": "Parameter-Efficient Methods for Metastases Detection from Clinical Notes",
            "updated": "2023-10-27T20:30:59Z",
            "published": "2023-10-27T20:30:59Z",
            "summary": "Understanding the progression of cancer is crucial for defining treatments\nfor patients. The objective of this study is to automate the detection of\nmetastatic liver disease from free-style computed tomography (CT) radiology\nreports. Our research demonstrates that transferring knowledge using three\napproaches can improve model performance. First, we utilize generic language\nmodels (LMs), pretrained in a self-supervised manner. Second, we use a\nsemi-supervised approach to train our model by automatically annotating a large\nunlabeled dataset; this approach substantially enhances the model's\nperformance. Finally, we transfer knowledge from related tasks by designing a\nmulti-task transfer learning methodology. We leverage the recent advancement of\nparameter-efficient LM adaptation strategies to improve performance and\ntraining efficiency. Our dataset consists of CT reports collected at Memorial\nSloan Kettering Cancer Center (MSKCC) over the course of 12 years. 2,641\nreports were manually annotated by domain experts; among them, 841 reports have\nbeen annotated for the presence of liver metastases. Our best model achieved an\nF1-score of 73.8%, a precision of 84%, and a recall of 65.8%.",
            "author": [
                "Maede Ashofteh Barabadi",
                "Xiaodan Zhu",
                "Wai Yip Chan",
                "Amber L. Simpson",
                "Richard K. G. Do"
            ],
            "link": [
                "http://dx.doi.org/10.21428/594757db.8bee12fd",
                "http://arxiv.org/abs/2310.18472v1",
                "http://arxiv.org/pdf/2310.18472v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18471v2",
            "title": "Causal disentanglement of multimodal data",
            "updated": "2023-11-08T18:54:52Z",
            "published": "2023-10-27T20:30:11Z",
            "summary": "Causal representation learning algorithms discover lower-dimensional\nrepresentations of data that admit a decipherable interpretation of cause and\neffect; as achieving such interpretable representations is challenging, many\ncausal learning algorithms utilize elements indicating prior information, such\nas (linear) structural causal models, interventional data, or weak supervision.\nUnfortunately, in exploratory causal representation learning, such elements and\nprior information may not be available or warranted. Alternatively, scientific\ndatasets often have multiple modalities or physics-based constraints, and the\nuse of such scientific, multimodal data has been shown to improve\ndisentanglement in fully unsupervised settings. Consequently, we introduce a\ncausal representation learning algorithm (causalPIMA) that can use multimodal\ndata and known physics to discover important features with causal\nrelationships. Our innovative algorithm utilizes a new differentiable\nparametrization to learn a directed acyclic graph (DAG) together with a latent\nspace of a variational autoencoder in an end-to-end differentiable framework\nvia a single, tractable evidence lower bound loss function. We place a Gaussian\nmixture prior on the latent space and identify each of the mixtures with an\noutcome of the DAG nodes; this novel identification enables feature discovery\nwith causal relationships. Tested against a synthetic and a scientific dataset,\nour results demonstrate the capability of learning an interpretable causal\nstructure while simultaneously discovering key features in a fully unsupervised\nsetting.",
            "author": [
                "Elise Walker",
                "Jonas A. Actor",
                "Carianne Martinez",
                "Nathaniel Trask"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18471v2",
                "http://arxiv.org/pdf/2310.18471v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18469v1",
            "title": "Semi-Synthetic Dataset Augmentation for Application-Specific Gaze\n  Estimation",
            "updated": "2023-10-27T20:27:22Z",
            "published": "2023-10-27T20:27:22Z",
            "summary": "Although the number of gaze estimation datasets is growing, the application\nof appearance-based gaze estimation methods is mostly limited to estimating the\npoint of gaze on a screen. This is in part because most datasets are generated\nin a similar fashion, where the gaze target is on a screen close to camera's\norigin. In other applications such as assistive robotics or marketing research,\nthe 3D point of gaze might not be close to the camera's origin, meaning models\ntrained on current datasets do not generalize well to these tasks. We therefore\nsuggest generating a textured tridimensional mesh of the face and rendering the\ntraining images from a virtual camera at a specific position and orientation\nrelated to the application as a mean of augmenting the existing datasets. In\nour tests, this lead to an average 47% decrease in gaze estimation angular\nerror.",
            "author": [
                "Cedric Leblond-Menard",
                "Gabriel Picard-Krashevski",
                "Sofiane Achiche"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18469v1",
                "http://arxiv.org/pdf/2310.18469v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18465v1",
            "title": "Minimax Optimal Submodular Optimization with Bandit Feedback",
            "updated": "2023-10-27T20:19:03Z",
            "published": "2023-10-27T20:19:03Z",
            "summary": "We consider maximizing a monotonic, submodular set function $f: 2^{[n]}\n\\rightarrow [0,1]$ under stochastic bandit feedback. Specifically, $f$ is\nunknown to the learner but at each time $t=1,\\dots,T$ the learner chooses a set\n$S_t \\subset [n]$ with $|S_t| \\leq k$ and receives reward $f(S_t) + \\eta_t$\nwhere $\\eta_t$ is mean-zero sub-Gaussian noise. The objective is to minimize\nthe learner's regret over $T$ times with respect to ($1-e^{-1}$)-approximation\nof maximum $f(S_*)$ with $|S_*| = k$, obtained through greedy maximization of\n$f$. To date, the best regret bound in the literature scales as $k n^{1/3}\nT^{2/3}$. And by trivially treating every set as a unique arm one deduces that\n$\\sqrt{ {n \\choose k} T }$ is also achievable. In this work, we establish the\nfirst minimax lower bound for this setting that scales like\n$\\mathcal{O}(\\min_{i \\le k}(in^{1/3}T^{2/3} + \\sqrt{n^{k-i}T}))$. Moreover, we\npropose an algorithm that is capable of matching the lower bound regret.",
            "author": [
                "Artin Tajdini",
                "Lalit Jain",
                "Kevin Jamieson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18465v1",
                "http://arxiv.org/pdf/2310.18465v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18459v1",
            "title": "VFAS-Grasp: Closed Loop Grasping with Visual Feedback and Adaptive\n  Sampling",
            "updated": "2023-10-27T20:12:30Z",
            "published": "2023-10-27T20:12:30Z",
            "summary": "We consider the problem of closed-loop robotic grasping and present a novel\nplanner which uses Visual Feedback and an uncertainty-aware Adaptive Sampling\nstrategy (VFAS) to close the loop. At each iteration, our method VFAS-Grasp\nbuilds a set of candidate grasps by generating random perturbations of a seed\ngrasp. The candidates are then scored using a novel metric which combines a\nlearned grasp-quality estimator, the uncertainty in the estimate and the\ndistance from the seed proposal to promote temporal consistency. Additionally,\nwe present two mechanisms to improve the efficiency of our sampling strategy:\nWe dynamically scale the sampling region size and number of samples in it based\non past grasp scores. We also leverage a motion vector field estimator to shift\nthe center of our sampling region. We demonstrate that our algorithm can run in\nreal time (20 Hz) and is capable of improving grasp performance for static\nscenes by refining the initial grasp proposal. We also show that it can enable\ngrasping of slow moving objects, such as those encountered during human to\nrobot handover.",
            "author": [
                "Pedro Piacenza",
                "Jiacheng Yuan",
                "Jinwook Huh",
                "Volkan Isler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18459v1",
                "http://arxiv.org/pdf/2310.18459v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18457v1",
            "title": "LLMSTEP: LLM proofstep suggestions in Lean",
            "updated": "2023-10-27T20:10:56Z",
            "published": "2023-10-27T20:10:56Z",
            "summary": "We present LLMSTEP, a tool for integrating a language model into the Lean\nproof assistant. LLMSTEP is a Lean 4 tactic that sends a user's proof state to\na server hosting a language model. The language model generates suggestions,\nwhich are checked in Lean and displayed to a user in their development\nenvironment. We provide a baseline language model, along with code for\nfine-tuning and evaluation to support further development. We provide server\nimplementations that run on CPU, a CUDA GPU, or a Google Colab notebook, as a\nstep towards fast, effective language model suggestions for any user.",
            "author": [
                "Sean Welleck",
                "Rahul Saha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18457v1",
                "http://arxiv.org/pdf/2310.18457v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "I.2.2; I.2.5; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18455v1",
            "title": "Approximate Heavy Tails in Offline (Multi-Pass) Stochastic Gradient\n  Descent",
            "updated": "2023-10-27T20:06:03Z",
            "published": "2023-10-27T20:06:03Z",
            "summary": "A recent line of empirical studies has demonstrated that SGD might exhibit a\nheavy-tailed behavior in practical settings, and the heaviness of the tails\nmight correlate with the overall performance. In this paper, we investigate the\nemergence of such heavy tails. Previous works on this problem only considered,\nup to our knowledge, online (also called single-pass) SGD, in which the\nemergence of heavy tails in theoretical findings is contingent upon access to\nan infinite amount of data. Hence, the underlying mechanism generating the\nreported heavy-tailed behavior in practical settings, where the amount of\ntraining data is finite, is still not well-understood. Our contribution aims to\nfill this gap. In particular, we show that the stationary distribution of\noffline (also called multi-pass) SGD exhibits 'approximate' power-law tails and\nthe approximation error is controlled by how fast the empirical distribution of\nthe training data converges to the true underlying data distribution in the\nWasserstein metric. Our main takeaway is that, as the number of data points\nincreases, offline SGD will behave increasingly 'power-law-like'. To achieve\nthis result, we first prove nonasymptotic Wasserstein convergence bounds for\noffline SGD to online SGD as the number of data points increases, which can be\ninteresting on their own. Finally, we illustrate our theory on various\nexperiments conducted on synthetic data and neural networks.",
            "author": [
                "Krunoslav Lehman Pavasovic",
                "Alain Durmus",
                "Umut Simsekli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18455v1",
                "http://arxiv.org/pdf/2310.18455v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18454v1",
            "title": "T5 meets Tybalt: Author Attribution in Early Modern English Drama Using\n  Large Language Models",
            "updated": "2023-10-27T20:04:57Z",
            "published": "2023-10-27T20:04:57Z",
            "summary": "Large language models have shown breakthrough potential in many NLP domains.\nHere we consider their use for stylometry, specifically authorship\nidentification in Early Modern English drama. We find both promising and\nconcerning results; LLMs are able to accurately predict the author of\nsurprisingly short passages but are also prone to confidently misattribute\ntexts to specific authors. A fine-tuned t5-large model outperforms all tested\nbaselines, including logistic regression, SVM with a linear kernel, and cosine\ndelta, at attributing small passages. However, we see indications that the\npresence of certain authors in the model's pre-training data affects predictive\nresults in ways that are difficult to assess.",
            "author": [
                "Rebecca M. M. Hicke",
                "David Mimno"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18454v1",
                "http://arxiv.org/pdf/2310.18454v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18449v1",
            "title": "Bayesian Optimization with Hidden Constraints via Latent Decision Models",
            "updated": "2023-10-27T19:47:26Z",
            "published": "2023-10-27T19:47:26Z",
            "summary": "Bayesian optimization (BO) has emerged as a potent tool for addressing\nintricate decision-making challenges, especially in public policy domains such\nas police districting. However, its broader application in public policymaking\nis hindered by the complexity of defining feasible regions and the\nhigh-dimensionality of decisions. This paper introduces the Hidden-Constrained\nLatent Space Bayesian Optimization (HC-LSBO), a novel BO method integrated with\na latent decision model. This approach leverages a variational autoencoder to\nlearn the distribution of feasible decisions, enabling a two-way mapping\nbetween the original decision space and a lower-dimensional latent space. By\ndoing so, HC-LSBO captures the nuances of hidden constraints inherent in public\npolicymaking, allowing for optimization in the latent space while evaluating\nobjectives in the original space. We validate our method through numerical\nexperiments on both synthetic and real data sets, with a specific focus on\nlarge-scale police districting problems in Atlanta, Georgia. Our results reveal\nthat HC-LSBO offers notable improvements in performance and efficiency compared\nto the baselines.",
            "author": [
                "Wenqian Xing",
                "Jungho Lee",
                "Chong Liu",
                "Shixiang Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18449v1",
                "http://arxiv.org/pdf/2310.18449v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18446v2",
            "title": "A Novel Skip Orthogonal List for Dynamic Optimal Transport Problem",
            "updated": "2023-11-25T19:05:40Z",
            "published": "2023-10-27T19:42:23Z",
            "summary": "Optimal transportation is a fundamental topic that has attracted a great\namount of attention from machine learning community in the past decades. In\nthis paper, we consider an interesting discrete dynamic optimal transport\nproblem: can we efficiently update the optimal transport plan when the weights\nor the locations of the data points change? This problem is naturally motivated\nby several applications in machine learning. For example, we often need to\ncompute the optimal transportation cost between two different data sets; if\nsome change happens to a few data points, should we re-compute the high\ncomplexity cost function or update the cost by some efficient dynamic data\nstructure? We are aware that several dynamic maximum flow algorithms have been\nproposed before, however, the research on dynamic minimum cost flow problem is\nstill quite limited, to the best of our knowledge. We propose a novel 2D Skip\nOrthogonal List together with some dynamic tree techniques. Although our\nalgorithm is based on the conventional simplex method, it can efficiently\ncomplete each pivoting operation within $O(|V|)$ time with high probability\nwhere $V$ is the set of all supply and demand nodes. Since dynamic\nmodifications typically do not introduce significant changes, our algorithm\nrequires only a few simplex iterations in practice. So our algorithm is more\nefficient than re-computing the optimal transportation cost that needs at least\none traversal over all the $O(|E|) = O(|V|^2)$ variables in general cases. Our\nexperiments demonstrate that our algorithm significantly outperforms existing\nalgorithms in the dynamic scenarios.",
            "author": [
                "Xiaoyang Xu",
                "Hu Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18446v2",
                "http://arxiv.org/pdf/2310.18446v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.AI",
                "cs.CG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18444v1",
            "title": "M3C: A Framework towards Convergent, Flexible, and Unsupervised Learning\n  of Mixture Graph Matching and Clustering",
            "updated": "2023-10-27T19:40:34Z",
            "published": "2023-10-27T19:40:34Z",
            "summary": "Existing graph matching methods typically assume that there are similar\nstructures between graphs and they are matchable. However, these assumptions do\nnot align with real-world applications. This work addresses a more realistic\nscenario where graphs exhibit diverse modes, requiring graph grouping before or\nalong with matching, a task termed mixture graph matching and clustering. We\nintroduce Minorize-Maximization Matching and Clustering (M3C), a learning-free\nalgorithm that guarantees theoretical convergence through the\nMinorize-Maximization framework and offers enhanced flexibility via relaxed\nclustering. Building on M3C, we develop UM3C, an unsupervised model that\nincorporates novel edge-wise affinity learning and pseudo label selection.\nExtensive experimental results on public benchmarks demonstrate that our method\noutperforms state-of-the-art graph matching and mixture graph matching and\nclustering approaches in both accuracy and efficiency. Source code will be made\npublicly available.",
            "author": [
                "Jiaxin Lu",
                "Zetian Jiang",
                "Tianzhe Wang",
                "Junchi Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18444v1",
                "http://arxiv.org/pdf/2310.18444v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18443v1",
            "title": "Towards a fuller understanding of neurons with Clustered Compositional\n  Explanations",
            "updated": "2023-10-27T19:39:50Z",
            "published": "2023-10-27T19:39:50Z",
            "summary": "Compositional Explanations is a method for identifying logical formulas of\nconcepts that approximate the neurons' behavior. However, these explanations\nare linked to the small spectrum of neuron activations (i.e., the highest ones)\nused to check the alignment, thus lacking completeness. In this paper, we\npropose a generalization, called Clustered Compositional Explanations, that\ncombines Compositional Explanations with clustering and a novel search\nheuristic to approximate a broader spectrum of the neurons' behavior. We define\nand address the problems connected to the application of these methods to\nmultiple ranges of activations, analyze the insights retrievable by using our\nalgorithm, and propose desiderata qualities that can be used to study the\nexplanations returned by different algorithms.",
            "author": [
                "Biagio La Rosa",
                "Leilani H. Gilpin",
                "Roberto Capobianco"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18443v1",
                "http://arxiv.org/pdf/2310.18443v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18439v1",
            "title": "Machine learning detecting Majorana Zero Mode from Zero Bias Peak\n  measurements",
            "updated": "2023-10-27T19:26:55Z",
            "published": "2023-10-27T19:26:55Z",
            "summary": "Majorana zero modes (MZMs), emerging as exotic quasiparticles that carry\nnon-Abelian statistics, hold great promise for achieving fault-tolerant\ntopological quantum computation. A key signature of the presence of MZMs is the\nzero-bias peaks (ZBPs) from tunneling differential conductance. However, the\nidentification of MZMs from ZBPs has faced tremendous challenges, due to the\npresence of topological trivial states that generate spurious ZBP signals. In\nthis work, we introduce a machine-learning framework that can discern MZM from\nother signals using ZBP data. Quantum transport simulation from tight-binding\nmodels is used to generate the training data, while persistent cohomology\nanalysis confirms the feasibility of classification via machine learning. In\nparticular, even with added data noise, XGBoost classifier reaches $85\\%$\naccuracy for 1D tunneling conductance data and $94\\%$ for 2D data incorporating\nZeeman splitting. Tests on prior ZBP experiments show that some data are more\nlikely to originate from MZM than others. Our model offers a quantitative\napproach to assess MZMs using ZBP data. Furthermore, our results shed light on\nthe use of machine learning on exotic quantum systems with\nexperimental-computational integration.",
            "author": [
                "Mouyang Cheng",
                "Ryotaro Okabe",
                "Abhijatmedhi Chotrattanapituk",
                "Mingda Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18439v1",
                "http://arxiv.org/pdf/2310.18439v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18438v1",
            "title": "Exploring Shape Embedding for Cloth-Changing Person Re-Identification\n  via 2D-3D Correspondences",
            "updated": "2023-10-27T19:26:30Z",
            "published": "2023-10-27T19:26:30Z",
            "summary": "Cloth-Changing Person Re-Identification (CC-ReID) is a common and realistic\nproblem since fashion constantly changes over time and people's aesthetic\npreferences are not set in stone. While most existing cloth-changing ReID\nmethods focus on learning cloth-agnostic identity representations from coarse\nsemantic cues (e.g. silhouettes and part segmentation maps), they neglect the\ncontinuous shape distributions at the pixel level. In this paper, we propose\nContinuous Surface Correspondence Learning (CSCL), a new shape embedding\nparadigm for cloth-changing ReID. CSCL establishes continuous correspondences\nbetween a 2D image plane and a canonical 3D body surface via pixel-to-vertex\nclassification, which naturally aligns a person image to the surface of a 3D\nhuman model and simultaneously obtains pixel-wise surface embeddings. We\nfurther extract fine-grained shape features from the learned surface embeddings\nand then integrate them with global RGB features via a carefully designed\ncross-modality fusion module. The shape embedding paradigm based on 2D-3D\ncorrespondences remarkably enhances the model's global understanding of human\nbody shape. To promote the study of ReID under clothing change, we construct 3D\nDense Persons (DP3D), which is the first large-scale cloth-changing ReID\ndataset that provides densely annotated 2D-3D correspondences and a precise 3D\nmesh for each person image, while containing diverse cloth-changing cases over\nall four seasons. Experiments on both cloth-changing and cloth-consistent ReID\nbenchmarks validate the effectiveness of our method.",
            "author": [
                "Yubin Wang",
                "Huimin Yu",
                "Yuming Yan",
                "Shuyi Song",
                "Biyang Liu",
                "Yichong Lu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3611715",
                "http://arxiv.org/abs/2310.18438v1",
                "http://arxiv.org/pdf/2310.18438v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18437v1",
            "title": "Inclination Angles for Be Stars Determined Using Machine Learning",
            "updated": "2023-10-27T19:23:55Z",
            "published": "2023-10-27T19:23:55Z",
            "summary": "We test the viability of training machine learning algorithms with synthetic\nH alpha line profiles to determine the inclination angles of Be stars (the\nangle between the central B star's rotation axis and the observer's line of\nsight) from a single observed medium-resolution, moderate S/N, spectrum. The\nperformance of three different machine learning algorithms were compared:\nneural networks tasked with regression, neural networks tasked with\nclassification, and support vector regression. Of these three algorithms,\nneural networks tasked with regression consistently outperformed the other\nmethods with a RMSE error of 7.6 degrees on an observational sample of 92\ngalactic Be stars with inclination angles known from direct H alpha profile\nfitting, from the spectroscopic signature of gravitational darkening, and, in a\nfew cases, from interferometric observations that resolved the disk. The\ntrained neural networks enable a quick and useful determination of the\ninclination angles of observed Be stars which can be used to search for\ncorrelated spin axes in young open clusters or to extract an equatorial\nrotation velocity from a measurement of v sin(i).",
            "author": [
                "B. D. Lailey",
                "T. A. A. Sigut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18437v1",
                "http://arxiv.org/pdf/2310.18437v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    }
]