[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:da82e3010679795bda2b4b8552a71a3a4143b8aa",
            "@type": "ScholarlyArticle",
            "paperId": "da82e3010679795bda2b4b8552a71a3a4143b8aa",
            "corpusId": 13224164,
            "url": "https://www.semanticscholar.org/paper/da82e3010679795bda2b4b8552a71a3a4143b8aa",
            "title": "DeepDTA: deep drug\u2013target binding affinity prediction",
            "venue": "Bioinform.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1801.10193",
                "DBLP": "journals/bioinformatics/OzturkOO18a",
                "PubMedCentral": "6129291",
                "MAG": "2785947426",
                "DOI": "10.1093/bioinformatics/bty593",
                "CorpusId": 13224164,
                "PubMed": "30423097"
            },
            "abstract": "Motivation The identification of novel drug\u2010target (DT) interactions is a substantial part of the drug discovery process. Most of the computational methods that have been proposed to predict DT interactions have focused on binary classification, where the goal is to determine whether a DT pair interacts or not. However, protein\u2010ligand interactions assume a continuum of binding strength values, also called binding affinity and predicting this value still remains a challenge. The increase in the affinity data available in DT knowledge\u2010bases allows the use of advanced learning techniques such as deep learning architectures in the prediction of binding affinities. In this study, we propose a deep\u2010learning based model that uses only sequence information of both targets and drugs to predict DT interaction binding affinities. The few studies that focus on DT binding affinity prediction use either 3D structures of protein\u2010ligand complexes or 2D features of compounds. One novel approach used in this work is the modeling of protein sequences and compound 1D representations with convolutional neural networks (CNNs). Results The results show that the proposed deep learning based model that uses the 1D representations of targets and drugs is an effective approach for drug target binding affinity prediction. The model in which high\u2010level representations of a drug and a target are constructed via CNNs achieved the best Concordance Index (CI) performance in one of our larger benchmark datasets, outperforming the KronRLS algorithm and SimBoost, a state\u2010of\u2010the\u2010art method for DT binding affinity prediction. Availability and implementation https://github.com/hkmztrk/DeepDTA Supplementary information Supplementary data are available at Bioinformatics online.",
            "referenceCount": 73,
            "citationCount": 645,
            "influentialCitationCount": 85,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/bioinformatics/article-pdf/34/17/i821/25702584/bty593.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-01-30",
            "journal": {
                "name": "Bioinformatics",
                "volume": "34"
            },
            "citationStyles": {
                "bibtex": "@Article{\u00d6zt\u00fcrk2018DeepDTADD,\n author = {Hakime \u00d6zt\u00fcrk and E. Olmez and Arzucan \u00d6zg\u00fcr},\n booktitle = {Bioinform.},\n journal = {Bioinformatics},\n pages = {i821 - i829},\n title = {DeepDTA: deep drug\u2013target binding affinity prediction},\n volume = {34},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:09b43b59879d59493df2a93c216746f2cf50f4ac",
            "@type": "ScholarlyArticle",
            "paperId": "09b43b59879d59493df2a93c216746f2cf50f4ac",
            "corpusId": 1010081,
            "url": "https://www.semanticscholar.org/paper/09b43b59879d59493df2a93c216746f2cf50f4ac",
            "title": "Deep transfer metric learning",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/cvpr/HuLT15",
                "MAG": "1916279783",
                "DOI": "10.1109/CVPR.2015.7298629",
                "CorpusId": 1010081
            },
            "abstract": "Conventional metric learning methods usually assume that the training and test samples are captured in similar scenarios so that their distributions are assumed to be the same. This assumption doesn't hold in many real visual recognition applications, especially when samples are captured across different datasets. In this paper, we propose a new deep transfer metric learning (DTML) method to learn a set of hierarchical nonlinear transformations for cross-domain visual recognition by transferring discriminative knowledge from the labeled source domain to the unlabeled target domain. Specifically, our DTML learns a deep metric network by maximizing the inter-class variations and minimizing the intra-class variations, and minimizing the distribution divergence between the source domain and the target domain at the top layer of the network. To better exploit the discriminative information from the source domain, we further develop a deeply supervised transfer metric learning (DSTML) method by including an additional objective on DTML where the output of both the hidden layers and the top layer are optimized jointly. Experimental results on cross-dataset face verification and person re-identification validate the effectiveness of the proposed methods.",
            "referenceCount": 40,
            "citationCount": 258,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dr.ntu.edu.sg/bitstream/10356/80552/1/Deep%20transfer%20metric%20learning.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-06-07",
            "journal": {
                "name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hu2015DeepTM,\n author = {Junlin Hu and Jiwen Lu and Yap-Peng Tan and Jie Zhou},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {325-333},\n title = {Deep transfer metric learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7ea35b35392c6ef5738635cec7d17b24fe3e4f04",
            "@type": "ScholarlyArticle",
            "paperId": "7ea35b35392c6ef5738635cec7d17b24fe3e4f04",
            "corpusId": 2706459,
            "url": "https://www.semanticscholar.org/paper/7ea35b35392c6ef5738635cec7d17b24fe3e4f04",
            "title": "Deep forest",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/ZhouF17",
                "ArXiv": "1702.08835",
                "MAG": "2804482613",
                "PubMedCentral": "8291612",
                "DOI": "10.1093/nsr/nwy108",
                "CorpusId": 2706459,
                "PubMed": "34691833"
            },
            "abstract": "Abstract Current deep-learning models are mostly built upon neural networks, i.e. multiple layers of parameterized differentiable non-linear modules that can be trained by backpropagation. In this paper, we explore the possibility of building deep models based on non-differentiable modules such as decision trees. After a discussion about the mystery behind deep neural networks, particularly by contrasting them with shallow neural networks and traditional machine-learning techniques such as decision trees and boosting machines, we conjecture that the success of deep neural networks owes much to three characteristics, i.e. layer-by-layer processing, in-model feature transformation and sufficient model complexity. On one hand, our conjecture may offer inspiration for theoretical understanding of deep learning; on the other hand, to verify the conjecture, we propose an approach that generates deep forest holding these characteristics. This is a decision-tree ensemble approach, with fewer hyper-parameters than deep neural networks, and its model complexity can be automatically determined in a data-dependent way. Experiments show that its performance is quite robust to hyper-parameter settings, such that in most cases, even across different data from different domains, it is able to achieve excellent performance by using the same default setting. This study opens the door to deep learning based on non-differentiable modules without gradient-based adjustment, and exhibits the possibility of constructing deep models without backpropagation.",
            "referenceCount": 75,
            "citationCount": 989,
            "influentialCitationCount": 135,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/nsr/article-pdf/6/1/74/27981411/nwy108.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-02-28",
            "journal": {
                "name": "National Science Review",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhou2017DeepF,\n author = {Zhi-Hua Zhou and Ji Feng},\n booktitle = {International Joint Conference on Artificial Intelligence},\n journal = {National Science Review},\n pages = {74 - 86},\n title = {Deep forest},\n volume = {6},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7ee368e60d0b826e78f965aad8d6c7d406127104",
            "@type": "ScholarlyArticle",
            "paperId": "7ee368e60d0b826e78f965aad8d6c7d406127104",
            "corpusId": 740114,
            "url": "https://www.semanticscholar.org/paper/7ee368e60d0b826e78f965aad8d6c7d406127104",
            "title": "Deep learning via semi-supervised embedding",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2407712691",
                "DBLP": "conf/icml/WestonRC08",
                "DOI": "10.1145/1390156.1390303",
                "CorpusId": 740114
            },
            "abstract": "We show how nonlinear embedding algorithms popular for use with shallow semi-supervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture. This provides a simple alternative to existing approaches to deep learning whilst yielding competitive error rates compared to those methods, and existing shallow semi-supervised techniques.",
            "referenceCount": 32,
            "citationCount": 1008,
            "influentialCitationCount": 88,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://infoscience.epfl.ch/record/192705/files/Weston_SPRINGER_2012.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-07-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Weston2008DeepLV,\n author = {J. Weston and F. Ratle and H. Mobahi and Ronan Collobert},\n booktitle = {International Conference on Machine Learning},\n pages = {639-655},\n title = {Deep learning via semi-supervised embedding},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:815c84ab906e43f3e6322f2ca3fd5e1360c64285",
            "@type": "ScholarlyArticle",
            "paperId": "815c84ab906e43f3e6322f2ca3fd5e1360c64285",
            "corpusId": 11790493,
            "url": "https://www.semanticscholar.org/paper/815c84ab906e43f3e6322f2ca3fd5e1360c64285",
            "title": "Human-level concept learning through probabilistic program induction",
            "venue": "Science",
            "publicationVenue": {
                "id": "urn:research:f59506a8-d8bb-4101-b3d4-c4ac3ed03dad",
                "name": "Science",
                "alternate_names": null,
                "issn": "0193-4511",
                "url": "https://www.jstor.org/journal/science"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2341708432",
                "DOI": "10.1126/science.aab3050",
                "CorpusId": 11790493,
                "PubMed": "26659050"
            },
            "abstract": "Handwritten characters drawn by a model Not only do children learn effortlessly, they do so quickly and with a remarkable ability to use what they have learned as the raw material for creating new stuff. Lake et al. describe a computational model that learns in a similar fashion and does so better than current deep learning algorithms. The model classifies, parses, and recreates handwritten characters, and can generate new letters of the alphabet that look \u201cright\u201d as judged by Turing-like tests of the model's output in comparison to what real humans produce. Science, this issue p. 1332 Combining the capacity to handle noise with probabilistic learning yields humanlike performance in a computational model. People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer ways than conventional algorithms\u2014for action, imagination, and explanation. We present a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world\u2019s alphabets. The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion. On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches. We also present several \u201cvisual Turing tests\u201d probing the model\u2019s creative generalization abilities, which in many cases are indistinguishable from human behavior.",
            "referenceCount": 101,
            "citationCount": 2639,
            "influentialCitationCount": 289,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://science.sciencemag.org/content/sci/350/6266/1332.full.pdf",
                "status": "CLOSED"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-12-11",
            "journal": {
                "name": "Science",
                "volume": "350"
            },
            "citationStyles": {
                "bibtex": "@Article{Lake2015HumanlevelCL,\n author = {B. Lake and R. Salakhutdinov and J. Tenenbaum},\n booktitle = {Science},\n journal = {Science},\n pages = {1332 - 1338},\n title = {Human-level concept learning through probabilistic program induction},\n volume = {350},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e2208a581439145f0709206ccfb0b763bbf05b55",
            "@type": "ScholarlyArticle",
            "paperId": "e2208a581439145f0709206ccfb0b763bbf05b55",
            "corpusId": 60497200,
            "url": "https://www.semanticscholar.org/paper/e2208a581439145f0709206ccfb0b763bbf05b55",
            "title": "Deep Extreme Learning Machine and Its Application in EEG Classification",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1525510058",
                "DOI": "10.1155/2015/129021",
                "CorpusId": 60497200
            },
            "abstract": "Recently, deep learning has aroused wide interest in machine learning fields. Deep learning is a multilayer perceptron artificial neural network algorithm. Deep learning has the advantage of approximating the complicated function and alleviating the optimization difficulty associated with deep models. Multilayer extreme learning machine (MLELM) is a learning algorithm of an artificial neural network which takes advantages of deep learning and extreme learning machine. Not only does MLELM approximate the complicated function but it also does not need to iterate during the training process. We combining with MLELM and extreme learning machine with kernel (KELM) put forward deep extreme learning machine (DELM) and apply it to EEG classification in this paper. This paper focuses on the application of DELM in the classification of the visual feedback experiment, using MATLAB and the second brain-computer interface (BCI) competition datasets. By simulating and analyzing the results of the experiments, effectiveness of the application of DELM in EEG classification is confirmed.",
            "referenceCount": 28,
            "citationCount": 155,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://downloads.hindawi.com/journals/mpe/2015/129021.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2015-05-27",
            "journal": {
                "name": "Mathematical Problems in Engineering",
                "volume": "2015"
            },
            "citationStyles": {
                "bibtex": "@Article{Ding2015DeepEL,\n author = {Shifei Ding and Nan Zhang and Xinzheng Xu and Lili Guo and Jian Zhang},\n journal = {Mathematical Problems in Engineering},\n pages = {1-11},\n title = {Deep Extreme Learning Machine and Its Application in EEG Classification},\n volume = {2015},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:17fa1c2a24ba8f731c8b21f1244463bc4b465681",
            "@type": "ScholarlyArticle",
            "paperId": "17fa1c2a24ba8f731c8b21f1244463bc4b465681",
            "corpusId": 205514,
            "url": "https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681",
            "title": "Deep multi-scale video prediction beyond mean square error",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2949900324",
                "DBLP": "journals/corr/MathieuCL15",
                "ArXiv": "1511.05440",
                "CorpusId": 205514
            },
            "abstract": "Learning to predict future images from a video sequence involves the construction of an internal representation that models the image evolution accurately, and therefore, to some degree, its content and dynamics. This is why pixel-space video prediction may be viewed as a promising avenue for unsupervised feature learning. In addition, while optical flow has been a very studied problem in computer vision for a long time, future frame prediction is rarely approached. Still, many vision applications could benefit from the knowledge of the next frames of videos, that does not require the complexity of tracking every pixel trajectories. In this work, we train a convolutional network to generate future frames given an input sequence. To deal with the inherently blurry predictions obtained from the standard Mean Squared Error (MSE) loss function, we propose three different and complementary feature learning strategies: a multi-scale architecture, an adversarial training method, and an image gradient difference loss function. We compare our predictions to different published results based on recurrent neural networks on the UCF101 dataset",
            "referenceCount": 35,
            "citationCount": 1740,
            "influentialCitationCount": 204,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-11-17",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1511.05440"
            },
            "citationStyles": {
                "bibtex": "@Article{Mathieu2015DeepMV,\n author = {Micha\u00ebl Mathieu and C. Couprie and Yann LeCun},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Deep multi-scale video prediction beyond mean square error},\n volume = {abs/1511.05440},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:29081e5c63d24fa8952e938dba68956cd47ac81d",
            "@type": "ScholarlyArticle",
            "paperId": "29081e5c63d24fa8952e938dba68956cd47ac81d",
            "corpusId": 71147030,
            "url": "https://www.semanticscholar.org/paper/29081e5c63d24fa8952e938dba68956cd47ac81d",
            "title": "Robust and Communication-Efficient Federated Learning From Non-i.i.d. Data",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1903.02891",
                "MAG": "2989289980",
                "DBLP": "journals/tnn/SattlerWMS20",
                "DOI": "10.1109/TNNLS.2019.2944481",
                "CorpusId": 71147030,
                "PubMed": "31689214"
            },
            "abstract": "Federated learning allows multiple parties to jointly train a deep learning model on their combined data, without any of the participants having to reveal their local data to a centralized server. This form of privacy-preserving collaborative learning, however, comes at the cost of a significant communication overhead during training. To address this problem, several compression methods have been proposed in the distributed training literature that can reduce the amount of required communication by up to three orders of magnitude. These existing methods, however, are only of limited utility in the federated learning setting, as they either only compress the upstream communication from the clients to the server (leaving the downstream communication uncompressed) or only perform well under idealized conditions, such as i.i.d. distribution of the client data, which typically cannot be found in federated learning. In this article, we propose sparse ternary compression (STC), a new compression framework that is specifically designed to meet the requirements of the federated learning environment. STC extends the existing compression technique of top- $k$ gradient sparsification with a novel mechanism to enable downstream compression as well as ternarization and optimal Golomb encoding of the weight updates. Our experiments on four different learning tasks demonstrate that STC distinctively outperforms federated averaging in common federated learning scenarios. These results advocate for a paradigm shift in federated optimization toward high-frequency low-bitwidth communication, in particular in the bandwidth-constrained learning environments.",
            "referenceCount": 44,
            "citationCount": 915,
            "influentialCitationCount": 42,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/5962385/9184294/08889996.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-07",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Sattler2019RobustAC,\n author = {Felix Sattler and Simon Wiedemann and K. M\u00fcller and W. Samek},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {3400-3413},\n title = {Robust and Communication-Efficient Federated Learning From Non-i.i.d. Data},\n volume = {31},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:00d736c540f80582279093cfc5ffe454a3226da9",
            "@type": "ScholarlyArticle",
            "paperId": "00d736c540f80582279093cfc5ffe454a3226da9",
            "corpusId": 207227372,
            "url": "https://www.semanticscholar.org/paper/00d736c540f80582279093cfc5ffe454a3226da9",
            "title": "Deep Graph Kernels",
            "venue": "Knowledge Discovery and Data Mining",
            "publicationVenue": {
                "id": "urn:research:a0edb93b-1e95-4128-a295-6b1659149cef",
                "name": "Knowledge Discovery and Data Mining",
                "alternate_names": [
                    "KDD",
                    "Knowl Discov Data Min"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigkdd/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/kdd/YanardagV15",
                "MAG": "2008857988",
                "DOI": "10.1145/2783258.2783417",
                "CorpusId": 207227372
            },
            "abstract": "In this paper, we present Deep Graph Kernels, a unified framework to learn latent representations of sub-structures for graphs, inspired by latest advancements in language modeling and deep learning. Our framework leverages the dependency information between sub-structures by learning their latent representations. We demonstrate instances of our framework on three popular graph kernels, namely Graphlet kernels, Weisfeiler-Lehman subtree kernels, and Shortest-Path graph kernels. Our experiments on several benchmark datasets show that Deep Graph Kernels achieve significant improvements in classification accuracy over state-of-the-art graph kernels.",
            "referenceCount": 36,
            "citationCount": 1070,
            "influentialCitationCount": 231,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-08-10",
            "journal": {
                "name": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Yanardag2015DeepGK,\n author = {Pinar Yanardag and S. Vishwanathan},\n booktitle = {Knowledge Discovery and Data Mining},\n journal = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},\n title = {Deep Graph Kernels},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ad84f49b2cd1b85a6d7df2304144a093f5b610a8",
            "@type": "ScholarlyArticle",
            "paperId": "ad84f49b2cd1b85a6d7df2304144a093f5b610a8",
            "corpusId": 6175936,
            "url": "https://www.semanticscholar.org/paper/ad84f49b2cd1b85a6d7df2304144a093f5b610a8",
            "title": "Learning from Noisy Labels with Deep Neural Networks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/corr/SukhbaatarF14",
                "ArXiv": "1406.2080",
                "MAG": "2963028646",
                "CorpusId": 6175936
            },
            "abstract": "The availability of large labeled datasets has allowed Convolutional Network models to achieve impressive recognition results. However, in many settings manual annotation of the data is impractical; instead our data has noisy labels, i.e. there is some freely available label for each image which may or may not be accurate. In this paper, we explore the performance of discriminatively-trained Convnets when trained on such noisy data. We introduce an extra noise layer into the network which adapts the network outputs to match the noisy label distribution. The parameters of this noise layer can be estimated as part of the training process and involve simple modifications to current training infrastructures for deep networks. We demonstrate the approaches on several datasets, including large scale experiments on the ImageNet classification benchmark.",
            "referenceCount": 18,
            "citationCount": 294,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-06-08",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1406.2080"
            },
            "citationStyles": {
                "bibtex": "@Article{Sukhbaatar2014LearningFN,\n author = {Sainbayar Sukhbaatar and R. Fergus},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Learning from Noisy Labels with Deep Neural Networks},\n volume = {abs/1406.2080},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a99d857ecc78316a0d9a774972b775058d5644ca",
            "@type": "ScholarlyArticle",
            "paperId": "a99d857ecc78316a0d9a774972b775058d5644ca",
            "corpusId": 10409742,
            "url": "https://www.semanticscholar.org/paper/a99d857ecc78316a0d9a774972b775058d5644ca",
            "title": "Continual Learning Through Synaptic Intelligence",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2737492962",
                "DBLP": "conf/icml/ZenkePG17",
                "CorpusId": 10409742,
                "PubMed": "31909397"
            },
            "abstract": "While deep learning has led to remarkable advances across diverse applications, it struggles in domains where the data distribution changes over the course of learning. In stark contrast, biological neural networks continually adapt to changing domains, possibly by leveraging complex molecular machinery to solve many tasks simultaneously. In this study, we introduce intelligent synapses that bring some of this biological complexity into artificial neural networks. Each synapse accumulates task relevant information over time, and exploits this information to rapidly store new memories without forgetting old ones. We evaluate our approach on continual learning of classification tasks, and show that it dramatically reduces forgetting while maintaining computational efficiency.",
            "referenceCount": 29,
            "citationCount": 1844,
            "influentialCitationCount": 275,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-13",
            "journal": {
                "name": "Proceedings of machine learning research",
                "volume": "70"
            },
            "citationStyles": {
                "bibtex": "@Article{Zenke2017ContinualLT,\n author = {Friedemann Zenke and Ben Poole and S. Ganguli},\n booktitle = {International Conference on Machine Learning},\n journal = {Proceedings of machine learning research},\n pages = {\n          3987-3995\n        },\n title = {Continual Learning Through Synaptic Intelligence},\n volume = {70},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca870d3dbfdddaef4a92e60f53d2077dbe0fdd0a",
            "@type": "ScholarlyArticle",
            "paperId": "ca870d3dbfdddaef4a92e60f53d2077dbe0fdd0a",
            "corpusId": 6011288,
            "url": "https://www.semanticscholar.org/paper/ca870d3dbfdddaef4a92e60f53d2077dbe0fdd0a",
            "title": "Deep & Cross Network for Ad Click Predictions",
            "venue": "ADKDD@KDD",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1708.05123",
                "MAG": "2750075801",
                "DBLP": "conf/kdd/WangFFW17",
                "DOI": "10.1145/3124749.3124754",
                "CorpusId": 6011288
            },
            "abstract": "Feature engineering has been the key to the success of many prediction models. However, the process is nontrivial and often requires manual feature engineering or exhaustive searching. DNNs are able to automatically learn feature interactions; however, they generate all the interactions implicitly, and are not necessarily efficient in learning all types of cross features. In this paper, we propose the Deep & Cross Network (DCN) which keeps the benefits of a DNN model, and beyond that, it introduces a novel cross network that is more efficient in learning certain bounded-degree feature interactions. In particular, DCN explicitly applies feature crossing at each layer, requires no manual feature engineering, and adds negligible extra complexity to the DNN model. Our experimental results have demonstrated its superiority over the state-of-art algorithms on the CTR prediction dataset and dense classification dataset, in terms of both model accuracy and memory usage.",
            "referenceCount": 19,
            "citationCount": 864,
            "influentialCitationCount": 181,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=3124754&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book"
            ],
            "publicationDate": "2017-08-14",
            "journal": {
                "name": "Proceedings of the ADKDD'17",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2017DeepC,\n author = {Ruoxi Wang and Bin Fu and G. Fu and Mingliang Wang},\n booktitle = {ADKDD@KDD},\n journal = {Proceedings of the ADKDD'17},\n title = {Deep & Cross Network for Ad Click Predictions},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:97e748935bef3db297b90aed736064a51e68668d",
            "@type": "ScholarlyArticle",
            "paperId": "97e748935bef3db297b90aed736064a51e68668d",
            "corpusId": 44085059,
            "url": "https://www.semanticscholar.org/paper/97e748935bef3db297b90aed736064a51e68668d",
            "title": "Protecting Intellectual Property of Deep Neural Networks with Watermarking",
            "venue": "ACM Asia Conference on Computer and Communications Security",
            "publicationVenue": {
                "id": "urn:research:87fc9c3c-cc7f-42aa-ba71-2700729a6788",
                "name": "ACM Asia Conference on Computer and Communications Security",
                "alternate_names": [
                    "AsiaCCS",
                    "ACM Asia Conf Comput Commun Secur",
                    "ACM Symposium on Information, Computer and Communications Security",
                    "ACM Symp Inf Comput Commun Secur",
                    "ASIACCS"
                ],
                "issn": null,
                "url": "https://dl.acm.org/conference/asia-ccs"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/ccs/ZhangGJWSHM18",
                "MAG": "2806082141",
                "DOI": "10.1145/3196494.3196550",
                "CorpusId": 44085059
            },
            "abstract": "Deep learning technologies, which are the key components of state-of-the-art Artificial Intelligence (AI) services, have shown great success in providing human-level capabilities for a variety of tasks, such as visual analysis, speech recognition, and natural language processing and etc. Building a production-level deep learning model is a non-trivial task, which requires a large amount of training data, powerful computing resources, and human expertises. Therefore, illegitimate reproducing, distribution, and the derivation of proprietary deep learning models can lead to copyright infringement and economic harm to model creators. Therefore, it is essential to devise a technique to protect the intellectual property of deep learning models and enable external verification of the model ownership. In this paper, we generalize the \"digital watermarking'' concept from multimedia ownership verification to deep neural network (DNNs) models. We investigate three DNN-applicable watermark generation algorithms, propose a watermark implanting approach to infuse watermark into deep learning models, and design a remote verification mechanism to determine the model ownership. By extending the intrinsic generalization and memorization capabilities of deep neural networks, we enable the models to learn specially crafted watermarks at training and activate with pre-specified predictions when observing the watermark patterns at inference. We evaluate our approach with two image recognition benchmark datasets. Our framework accurately (100%) and quickly verifies the ownership of all the remotely deployed deep learning models without affecting the model accuracy for normal input data. In addition, the embedded watermarks in DNN models are robust and resilient to different counter-watermark mechanisms, such as fine-tuning, parameter pruning, and model inversion attacks.",
            "referenceCount": 58,
            "citationCount": 404,
            "influentialCitationCount": 62,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Law",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2018-05-29",
            "journal": {
                "name": "Proceedings of the 2018 on Asia Conference on Computer and Communications Security",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018ProtectingIP,\n author = {Jialong Zhang and Zhongshu Gu and Jiyong Jang and Hui Wu and M. Stoecklin and Heqing Huang and Ian Molloy},\n booktitle = {ACM Asia Conference on Computer and Communications Security},\n journal = {Proceedings of the 2018 on Asia Conference on Computer and Communications Security},\n title = {Protecting Intellectual Property of Deep Neural Networks with Watermarking},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4b63e34276aa98d5345efa7fe09bb06d8a9d8f52",
            "@type": "ScholarlyArticle",
            "paperId": "4b63e34276aa98d5345efa7fe09bb06d8a9d8f52",
            "corpusId": 5865729,
            "url": "https://www.semanticscholar.org/paper/4b63e34276aa98d5345efa7fe09bb06d8a9d8f52",
            "title": "Deep Exploration via Bootstrapped DQN",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2950112945",
                "ArXiv": "1602.04621",
                "DBLP": "journals/corr/OsbandBPR16",
                "CorpusId": 5865729
            },
            "abstract": "Efficient exploration in complex environments remains a major challenge for reinforcement learning. We propose bootstrapped DQN, a simple algorithm that explores in a computationally and statistically efficient manner through use of randomized value functions. Unlike dithering strategies such as epsilon-greedy exploration, bootstrapped DQN carries out temporally-extended (or deep) exploration; this can lead to exponentially faster learning. We demonstrate these benefits in complex stochastic MDPs and in the large-scale Arcade Learning Environment. Bootstrapped DQN substantially improves learning times and performance across most Atari games.",
            "referenceCount": 47,
            "citationCount": 1076,
            "influentialCitationCount": 182,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-02-15",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Osband2016DeepEV,\n author = {Ian Osband and C. Blundell and A. Pritzel and Benjamin Van Roy},\n booktitle = {Neural Information Processing Systems},\n pages = {4026-4034},\n title = {Deep Exploration via Bootstrapped DQN},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:92495abbac86394cb759bec15a763dbf49a8e590",
            "@type": "ScholarlyArticle",
            "paperId": "92495abbac86394cb759bec15a763dbf49a8e590",
            "corpusId": 38796293,
            "url": "https://www.semanticscholar.org/paper/92495abbac86394cb759bec15a763dbf49a8e590",
            "title": "Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2951832676",
                "DBLP": "conf/iclr/LinHM0D18",
                "ArXiv": "1712.01887",
                "CorpusId": 38796293
            },
            "abstract": "Large-scale distributed training requires significant communication bandwidth for gradient exchange that limits the scalability of multi-node training, and requires expensive high-bandwidth network infrastructure. The situation gets even worse with distributed training on mobile devices (federated learning), which suffers from higher latency, lower throughput, and intermittent poor connections. In this paper, we find 99.9% of the gradient exchange in distributed SGD is redundant, and propose Deep Gradient Compression (DGC) to greatly reduce the communication bandwidth. To preserve accuracy during compression, DGC employs four methods: momentum correction, local gradient clipping, momentum factor masking, and warm-up training. We have applied Deep Gradient Compression to image classification, speech recognition, and language modeling with multiple datasets including Cifar10, ImageNet, Penn Treebank, and Librispeech Corpus. On these scenarios, Deep Gradient Compression achieves a gradient compression ratio from 270x to 600x without losing accuracy, cutting the gradient size of ResNet-50 from 97MB to 0.35MB, and for DeepSpeech from 488MB to 0.74MB. Deep gradient compression enables large-scale distributed training on inexpensive commodity 1Gbps Ethernet and facilitates distributed training on mobile.",
            "referenceCount": 40,
            "citationCount": 1104,
            "influentialCitationCount": 141,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-12-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1712.01887"
            },
            "citationStyles": {
                "bibtex": "@Article{Lin2017DeepGC,\n author = {Yujun Lin and Song Han and Huizi Mao and Yu Wang and W. Dally},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training},\n volume = {abs/1712.01887},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0cc956565c7d249d4197eeb1dbab6523c648b2c9",
            "@type": "ScholarlyArticle",
            "paperId": "0cc956565c7d249d4197eeb1dbab6523c648b2c9",
            "corpusId": 208547755,
            "url": "https://www.semanticscholar.org/paper/0cc956565c7d249d4197eeb1dbab6523c648b2c9",
            "title": "Dream to Control: Learning Behaviors by Latent Imagination",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2995298643",
                "ArXiv": "1912.01603",
                "DBLP": "conf/iclr/HafnerLB020",
                "CorpusId": 208547755
            },
            "abstract": "To select effective actions in complex environments, intelligent agents need to generalize from past experience. World models can represent knowledge about the environment to facilitate such generalization. While learning world models from high-dimensional sensory inputs is becoming feasible through deep learning, there are many potential ways for deriving behaviors from them. We present Dreamer, a reinforcement learning agent that solves long-horizon tasks purely by latent imagination. We efficiently learn behaviors by backpropagating analytic gradients of learned state values through trajectories imagined in the compact state space of a learned world model. On 20 challenging visual control tasks, Dreamer exceeds existing approaches in data-efficiency, computation time, and final performance.",
            "referenceCount": 71,
            "citationCount": 811,
            "influentialCitationCount": 161,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-12-03",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1912.01603"
            },
            "citationStyles": {
                "bibtex": "@Article{Hafner2019DreamTC,\n author = {Danijar Hafner and T. Lillicrap and Jimmy Ba and Mohammad Norouzi},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Dream to Control: Learning Behaviors by Latent Imagination},\n volume = {abs/1912.01603},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a742162820cdabee2831235665517d0e98041502",
            "@type": "ScholarlyArticle",
            "paperId": "a742162820cdabee2831235665517d0e98041502",
            "corpusId": 3470596,
            "url": "https://www.semanticscholar.org/paper/a742162820cdabee2831235665517d0e98041502",
            "title": "Deep Complex Networks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2962913459",
                "DBLP": "journals/corr/TrabelsiBSSSMRB17",
                "ArXiv": "1705.09792",
                "CorpusId": 3470596
            },
            "abstract": "At present, the vast majority of building blocks, techniques, and architectures for deep learning are based on real-valued operations and representations. However, recent work on recurrent neural networks and older fundamental theoretical analysis suggests that complex numbers could have a richer representational capacity and could also facilitate noise-robust memory retrieval mechanisms. Despite their attractive properties and potential for opening up entirely new neural architectures, complex-valued deep neural networks have been marginalized due to the absence of the building blocks required to design such models. In this work, we provide the key atomic components for complex-valued deep neural networks and apply them to convolutional feed-forward networks and convolutional LSTMs. More precisely, we rely on complex convolutions and present algorithms for complex batch-normalization, complex weight initialization strategies for complex-valued neural nets and we use them in experiments with end-to-end training schemes. We demonstrate that such complex-valued models are competitive with their real-valued counterparts. We test deep complex models on several computer vision tasks, on music transcription using the MusicNet dataset and on Speech Spectrum Prediction using the TIMIT dataset. We achieve state-of-the-art performance on these audio-related tasks.",
            "referenceCount": 54,
            "citationCount": 610,
            "influentialCitationCount": 108,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-05-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1705.09792"
            },
            "citationStyles": {
                "bibtex": "@Article{Trabelsi2017DeepCN,\n author = {C. Trabelsi and O. Bilaniuk and Dmitriy Serdyuk and Sandeep Subramanian and J. F. Santos and Soroush Mehri and Negar Rostamzadeh and Yoshua Bengio and C. Pal},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Deep Complex Networks},\n volume = {abs/1705.09792},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8195787260dfc6bc9abea3b1dac1ce15f747caa2",
            "@type": "ScholarlyArticle",
            "paperId": "8195787260dfc6bc9abea3b1dac1ce15f747caa2",
            "corpusId": 146101795,
            "url": "https://www.semanticscholar.org/paper/8195787260dfc6bc9abea3b1dac1ce15f747caa2",
            "title": "A Survey of Unsupervised Deep Domain Adaptation",
            "venue": "ACM Transactions on Intelligent Systems and Technology",
            "publicationVenue": {
                "id": "urn:research:0d993d4a-09ba-4df8-90a4-7dfe25f0cb9e",
                "name": "ACM Transactions on Intelligent Systems and Technology",
                "alternate_names": [
                    "ACM Trans Intell Syst Technol"
                ],
                "issn": "2157-6904",
                "url": "http://portal.acm.org/tist"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2940156133",
                "DBLP": "journals/tist/WilsonC20",
                "ArXiv": "1812.02849",
                "DOI": "10.1145/3400066",
                "CorpusId": 146101795,
                "PubMed": "34336374"
            },
            "abstract": "Deep learning has produced state-of-the-art results for a variety of tasks. While such approaches for supervised learning have performed well, they assume that training and testing data are drawn from the same distribution, which may not always be the case. As a complement to this challenge, single-source unsupervised domain adaptation can handle situations where a network is trained on labeled data from a source domain and unlabeled data from a related but different target domain with the goal of performing well at test-time on the target domain. Many single-source and typically homogeneous unsupervised deep domain adaptation approaches have thus been developed, combining the powerful, hierarchical representations from deep learning with domain adaptation to reduce reliance on potentially costly target data labels. This survey will compare these approaches by examining alternative methods, the unique and common elements, results, and theoretical insights. We follow this with a look at application areas and open research directions.",
            "referenceCount": 328,
            "citationCount": 538,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3400066",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-12-06",
            "journal": {
                "name": "ACM Transactions on Intelligent Systems and Technology (TIST)",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Wilson2018ASO,\n author = {Garrett Wilson and D. Cook},\n booktitle = {ACM Transactions on Intelligent Systems and Technology},\n journal = {ACM Transactions on Intelligent Systems and Technology (TIST)},\n pages = {1 - 46},\n title = {A Survey of Unsupervised Deep Domain Adaptation},\n volume = {11},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e49ff72d420c8d72e62a9353e3abc053445e59bd",
            "@type": "ScholarlyArticle",
            "paperId": "e49ff72d420c8d72e62a9353e3abc053445e59bd",
            "corpusId": 10443309,
            "url": "https://www.semanticscholar.org/paper/e49ff72d420c8d72e62a9353e3abc053445e59bd",
            "title": "Deep Convolutional Networks on Graph-Structured Data",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1506.05163",
                "MAG": "637153065",
                "DBLP": "journals/corr/HenaffBL15",
                "CorpusId": 10443309
            },
            "abstract": "Deep Learning's recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions. However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities. \nIn this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains, which are typically unknown and need to be estimated from the data. In particular, we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure, that we test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate.",
            "referenceCount": 20,
            "citationCount": 1439,
            "influentialCitationCount": 67,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-06-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1506.05163"
            },
            "citationStyles": {
                "bibtex": "@Article{Henaff2015DeepCN,\n author = {Mikael Henaff and Joan Bruna and Yann LeCun},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Convolutional Networks on Graph-Structured Data},\n volume = {abs/1506.05163},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2369db9921078c4bb76072ef7d6426e9f1dbfdb5",
            "@type": "ScholarlyArticle",
            "paperId": "2369db9921078c4bb76072ef7d6426e9f1dbfdb5",
            "corpusId": 37336258,
            "url": "https://www.semanticscholar.org/paper/2369db9921078c4bb76072ef7d6426e9f1dbfdb5",
            "title": "Deep Convolutional Neural Networks for Hyperspectral Image Classification",
            "venue": "J. Sensors",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1521436688",
                "DBLP": "journals/js/HuH0ZL15",
                "DOI": "10.1155/2015/258619",
                "CorpusId": 37336258
            },
            "abstract": "Recently, convolutional neural networks have demonstrated excellent performance on various visual tasks, including the classification of common two-dimensional images. In this paper, deep convolutional neural networks are employed to classify hyperspectral images directly in spectral domain. More specifically, the architecture of the proposed classifier contains five layers with weights which are the input layer, the convolutional layer, the max pooling layer, the full connection layer, and the output layer. These five layers are implemented on each spectral signature to discriminate against others. Experimental results based on several hyperspectral image data sets demonstrate that the proposed method can achieve better classification performance than some traditional methods, such as support vector machines and the conventional deep learning-based methods.",
            "referenceCount": 36,
            "citationCount": 1245,
            "influentialCitationCount": 92,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://downloads.hindawi.com/journals/js/2015/258619.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-07-30",
            "journal": {
                "name": "J. Sensors",
                "volume": "2015"
            },
            "citationStyles": {
                "bibtex": "@Article{Hu2015DeepCN,\n author = {Wei Hu and Yangyu Huang and Wei Li and Fan Zhang and Hengchao Li},\n booktitle = {J. Sensors},\n journal = {J. Sensors},\n pages = {258619:1-258619:12},\n title = {Deep Convolutional Neural Networks for Hyperspectral Image Classification},\n volume = {2015},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:58123025178256279bb060ca5da971b62bc329ee",
            "@type": "ScholarlyArticle",
            "paperId": "58123025178256279bb060ca5da971b62bc329ee",
            "corpusId": 7636159,
            "url": "https://www.semanticscholar.org/paper/58123025178256279bb060ca5da971b62bc329ee",
            "title": "Sharp Minima Can Generalize For Deep Nets",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/icml/DinhPBB17",
                "MAG": "2950928354",
                "ArXiv": "1703.04933",
                "CorpusId": 7636159
            },
            "abstract": "Despite their overwhelming capacity to overfit, deep learning architectures tend to generalize relatively well to unseen data, allowing them to be deployed in practice. However, explaining why this is the case is still an open area of research. One standing hypothesis that is gaining popularity, e.g. Hochreiter & Schmidhuber (1997); Keskar et al. (2017), is that the flatness of minima of the loss function found by stochastic gradient based methods results in good generalization. This paper argues that most notions of flatness are problematic for deep models and can not be directly applied to explain generalization. Specifically, when focusing on deep networks with rectifier units, we can exploit the particular geometry of parameter space induced by the inherent symmetries that these architectures exhibit to build equivalent models corresponding to arbitrarily sharper minima. Furthermore, if we allow to reparametrize a function, the geometry of its parameters can change drastically without affecting its generalization properties.",
            "referenceCount": 76,
            "citationCount": 624,
            "influentialCitationCount": 67,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-15",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Dinh2017SharpMC,\n author = {Laurent Dinh and Razvan Pascanu and Samy Bengio and Yoshua Bengio},\n booktitle = {International Conference on Machine Learning},\n pages = {1019-1028},\n title = {Sharp Minima Can Generalize For Deep Nets},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:28f7cc049f3f4a4db81f0d0a608a4f57636cc35b",
            "@type": "ScholarlyArticle",
            "paperId": "28f7cc049f3f4a4db81f0d0a608a4f57636cc35b",
            "corpusId": 18666195,
            "url": "https://www.semanticscholar.org/paper/28f7cc049f3f4a4db81f0d0a608a4f57636cc35b",
            "title": "Quantum-chemical insights from deep tensor neural networks",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2016,
            "externalIds": {
                "PubMedCentral": "5228054",
                "MAG": "2527189750",
                "ArXiv": "1609.08259",
                "DOI": "10.1038/ncomms13890",
                "CorpusId": 18666195,
                "PubMed": "28067221"
            },
            "abstract": null,
            "referenceCount": 72,
            "citationCount": 1047,
            "influentialCitationCount": 38,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/ncomms13890.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Physics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-27",
            "journal": {
                "name": "Nature Communications",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Sch\u00fctt2016QuantumchemicalIF,\n author = {Kristof T. Sch\u00fctt and F. Arbabzadah and Stefan Chmiela and K. M\u00fcller and A. Tkatchenko},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {Quantum-chemical insights from deep tensor neural networks},\n volume = {8},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:18c39ba04333d31c6cb10faf79d1f18692c38d0f",
            "@type": "ScholarlyArticle",
            "paperId": "18c39ba04333d31c6cb10faf79d1f18692c38d0f",
            "corpusId": 4404566,
            "url": "https://www.semanticscholar.org/paper/18c39ba04333d31c6cb10faf79d1f18692c38d0f",
            "title": "Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records",
            "venue": "Scientific Reports",
            "publicationVenue": {
                "id": "urn:research:f99f77b7-b1b6-44d3-984a-f288e9884b9b",
                "name": "Scientific Reports",
                "alternate_names": [
                    "Sci Rep"
                ],
                "issn": "2045-2322",
                "url": "http://www.nature.com/srep/"
            },
            "year": 2016,
            "externalIds": {
                "PubMedCentral": "4869115",
                "MAG": "2404901863",
                "DOI": "10.1038/srep26094",
                "CorpusId": 4404566,
                "PubMed": "27185194"
            },
            "abstract": null,
            "referenceCount": 51,
            "citationCount": 1236,
            "influentialCitationCount": 53,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/srep26094.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-05-17",
            "journal": {
                "name": "Scientific Reports",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Miotto2016DeepPA,\n author = {Riccardo Miotto and Li Li and B. Kidd and J. Dudley},\n booktitle = {Scientific Reports},\n journal = {Scientific Reports},\n title = {Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records},\n volume = {6},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:37be889f4654312109dc9c53395fe117adb0f72b",
            "@type": "ScholarlyArticle",
            "paperId": "37be889f4654312109dc9c53395fe117adb0f72b",
            "corpusId": 28121452,
            "url": "https://www.semanticscholar.org/paper/37be889f4654312109dc9c53395fe117adb0f72b",
            "title": "Stable architectures for deep neural networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1705.03341",
                "DBLP": "journals/corr/HaberR17",
                "MAG": "2612252966",
                "DOI": "10.1088/1361-6420/aa9a90",
                "CorpusId": 28121452
            },
            "abstract": "Deep neural networks have become invaluable tools for supervised machine learning, e.g. classification of text or images. While often offering superior results over traditional techniques and successfully expressing complicated patterns in data, deep architectures are known to be challenging to design and train such that they generalize well to new data. Critical issues with deep architectures are numerical instabilities in derivative-based learning algorithms commonly called exploding or vanishing gradients. In this paper, we propose new forward propagation techniques inspired by systems of ordinary differential equations (ODE) that overcome this challenge and lead to well-posed learning problems for arbitrarily deep networks. The backbone of our approach is our interpretation of deep learning as a parameter estimation problem of nonlinear dynamical systems. Given this formulation, we analyze stability and well-posedness of deep learning and use this new understanding to develop new network architectures. We relate the exploding and vanishing gradient phenomenon to the stability of the discrete ODE and present several strategies for stabilizing deep learning for very deep networks. While our new architectures restrict the solution space, several numerical experiments show their competitiveness with state-of-the-art networks.",
            "referenceCount": 57,
            "citationCount": 564,
            "influentialCitationCount": 77,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1705.03341",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Physics",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-05-09",
            "journal": {
                "name": "Inverse Problems",
                "volume": "34"
            },
            "citationStyles": {
                "bibtex": "@Article{Haber2017StableAF,\n author = {E. Haber and Lars Ruthotto},\n booktitle = {arXiv.org},\n journal = {Inverse Problems},\n title = {Stable architectures for deep neural networks},\n volume = {34},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:398c296d0cc7f9d180f84969f8937e6d3a413796",
            "@type": "ScholarlyArticle",
            "paperId": "398c296d0cc7f9d180f84969f8937e6d3a413796",
            "corpusId": 2161592,
            "url": "https://www.semanticscholar.org/paper/398c296d0cc7f9d180f84969f8937e6d3a413796",
            "title": "Multi-column deep neural networks for image classification",
            "venue": "2012 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2141125852",
                "DBLP": "conf/cvpr/CiresanMS12",
                "ArXiv": "1202.2745",
                "DOI": "10.1109/CVPR.2012.6248110",
                "CorpusId": 2161592
            },
            "abstract": "Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible, wide and deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks.",
            "referenceCount": 44,
            "citationCount": 3777,
            "influentialCitationCount": 177,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1202.2745",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-02-13",
            "journal": {
                "name": "2012 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ciresan2012MulticolumnDN,\n author = {D. Ciresan and U. Meier and J. Schmidhuber},\n booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {3642-3649},\n title = {Multi-column deep neural networks for image classification},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d4f62ffbf7c51a5ad01b89c6889c649bf48baac8",
            "@type": "ScholarlyArticle",
            "paperId": "d4f62ffbf7c51a5ad01b89c6889c649bf48baac8",
            "corpusId": 7331600,
            "url": "https://www.semanticscholar.org/paper/d4f62ffbf7c51a5ad01b89c6889c649bf48baac8",
            "title": "Permutation invariant training of deep models for speaker-independent multi-talker speech separation",
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "publicationVenue": {
                "id": "urn:research:0d6f7fba-7092-46b3-8039-93458dba736b",
                "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                "alternate_names": [
                    "Int Conf Acoust Speech Signal Process",
                    "IEEE Int Conf Acoust Speech Signal Process",
                    "ICASSP",
                    "International Conference on Acoustics, Speech, and Signal Processing"
                ],
                "issn": null,
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/YuKTJ16",
                "MAG": "2951295643",
                "ArXiv": "1607.00325",
                "DOI": "10.1109/ICASSP.2017.7952154",
                "CorpusId": 7331600
            },
            "abstract": "We propose a novel deep learning training criterion, named permutation invariant training (PIT), for speaker independent multi-talker speech separation, commonly known as the cocktail-party problem. Different from the multi-class regression technique and the deep clustering (DPCL) technique, our novel approach minimizes the separation error directly. This strategy effectively solves the long-lasting label permutation problem, that has prevented progress on deep learning based techniques for speech separation. We evaluated PIT on the WSJ0 and Danish mixed-speech separation tasks and found that it compares favorably to non-negative matrix factorization (NMF), computational auditory scene analysis (CASA), and DPCL and generalizes well over unseen speakers and languages. Since PIT is simple to implement and can be easily integrated and combined with other advanced techniques, we believe improvements built upon PIT can eventually solve the cocktail-party problem.",
            "referenceCount": 35,
            "citationCount": 705,
            "influentialCitationCount": 106,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1607.00325",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-07-01",
            "journal": {
                "name": "2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yu2016PermutationIT,\n author = {Dong Yu and Morten Kolb\u00e6k and Z. Tan and J. Jensen},\n booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},\n journal = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n pages = {241-245},\n title = {Permutation invariant training of deep models for speaker-independent multi-talker speech separation},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6bc4b1b9249671ae2fafe934659e14d402925000",
            "@type": "ScholarlyArticle",
            "paperId": "6bc4b1b9249671ae2fafe934659e14d402925000",
            "corpusId": 8478736,
            "url": "https://www.semanticscholar.org/paper/6bc4b1b9249671ae2fafe934659e14d402925000",
            "title": "Using Deep Neural Networks for Inverse Problems in Imaging: Beyond Analytical Methods",
            "venue": "IEEE Signal Processing Magazine",
            "publicationVenue": {
                "id": "urn:research:f62e5eab-173a-4e0a-a963-ed8de9835d22",
                "name": "IEEE Signal Processing Magazine",
                "alternate_names": [
                    "IEEE Signal Process Mag"
                ],
                "issn": "1053-5888",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=79"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/spm/LucasIMK18",
                "MAG": "2782977076",
                "DOI": "10.1109/MSP.2017.2760358",
                "CorpusId": 8478736
            },
            "abstract": "Traditionally, analytical methods have been used to solve imaging problems such as image restoration, inpainting, and superresolution (SR). In recent years, the fields of machine and deep learning have gained a lot of momentum in solving such imaging problems, often surpassing the performance provided by analytical approaches. Unlike analytical methods for which the problem is explicitly defined and domain-knowledge carefully engineered into the solution, deep neural networks (DNNs) do not benefit from such prior knowledge and instead make use of large data sets to learn the unknown solution to the inverse problem. In this article, we review deep-learning techniques for solving such inverse problems in imaging. More specifically, we review the popular neural network architectures used for imaging tasks, offering some insight as to how these deep-learning tools can solve the inverse problem. Furthermore, we address some fundamental questions, such as how deeplearning and analytical methods can be combined to provide better solutions to the inverse problem in addition to providing a discussion on the current limitations and future directions of the use of deep learning for solving inverse problem in imaging.",
            "referenceCount": 53,
            "citationCount": 423,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-01-10",
            "journal": {
                "name": "IEEE Signal Processing Magazine",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Lucas2018UsingDN,\n author = {Alice Lucas and Michael Iliadis and R. Molina and A. Katsaggelos},\n booktitle = {IEEE Signal Processing Magazine},\n journal = {IEEE Signal Processing Magazine},\n pages = {20-36},\n title = {Using Deep Neural Networks for Inverse Problems in Imaging: Beyond Analytical Methods},\n volume = {35},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c342c71cb23199f112d0bc644fcce56a7306bf94",
            "@type": "ScholarlyArticle",
            "paperId": "c342c71cb23199f112d0bc644fcce56a7306bf94",
            "corpusId": 3383786,
            "url": "https://www.semanticscholar.org/paper/c342c71cb23199f112d0bc644fcce56a7306bf94",
            "title": "Active Learning for Convolutional Neural Networks: A Core-Set Approach",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2774918944",
                "DBLP": "conf/iclr/SenerS18",
                "CorpusId": 3383786
            },
            "abstract": "Convolutional neural networks (CNNs) have been successfully applied to many recognition and learning tasks using a universal recipe; training a deep model on a very large dataset of supervised examples. However, this approach is rather restrictive in practice since collecting a large set of labeled images is very expensive. One way to ease this problem is coming up with smart ways for choosing images to be labelled from a very large collection (ie. active learning). \nOur empirical study suggests that many of the active learning heuristics in the literature are not effective when applied to CNNs in batch setting. Inspired by these limitations, we define the problem of active learning as core-set selection, ie. choosing set of points such that a model learned over the selected subset is competitive for the remaining data points. We further present a theoretical result characterizing the performance of any selected subset using the geometry of the datapoints. As an active learning algorithm, we choose the subset which is expected to yield best result according to our characterization. Our experiments show that the proposed method significantly outperforms existing approaches in image classification experiments by a large margin.",
            "referenceCount": 53,
            "citationCount": 1309,
            "influentialCitationCount": 298,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-08-01",
            "journal": {
                "name": "arXiv: Machine Learning",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Sener2017ActiveLF,\n author = {Ozan Sener and S. Savarese},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Machine Learning},\n title = {Active Learning for Convolutional Neural Networks: A Core-Set Approach},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b8084d5e193633462e56f897f3d81b2832b72dff",
            "@type": "ScholarlyArticle",
            "paperId": "b8084d5e193633462e56f897f3d81b2832b72dff",
            "corpusId": 10987393,
            "url": "https://www.semanticscholar.org/paper/b8084d5e193633462e56f897f3d81b2832b72dff",
            "title": "DeepID3: Face Recognition with Very Deep Neural Networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2140609507",
                "DBLP": "journals/corr/SunLWT15",
                "ArXiv": "1502.00873",
                "CorpusId": 10987393
            },
            "abstract": "The state-of-the-art of face recognition has been significantly advanced by the emergence of deep learning. Very deep neural networks recently achieved great success on general object recognition because of their superb learning capacity. This motivates us to investigate their effectiveness on face recognition. This paper proposes two very deep neural network architectures, referred to as DeepID3, for face recognition. These two architectures are rebuilt from stacked convolution and inception layers proposed in VGG net and GoogLeNet to make them suitable to face recognition. Joint face identification-verification supervisory signals are added to both intermediate and final feature extraction layers during training. An ensemble of the proposed two architectures achieves 99.53% LFW face verification accuracy and 96.0% LFW rank-1 face identification accuracy, respectively. A further discussion of LFW face verification result is given in the end.",
            "referenceCount": 21,
            "citationCount": 907,
            "influentialCitationCount": 58,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-02-03",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1502.00873"
            },
            "citationStyles": {
                "bibtex": "@Article{Sun2015DeepID3FR,\n author = {Yi Sun and Ding Liang and Xiaogang Wang and Xiaoou Tang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {DeepID3: Face Recognition with Very Deep Neural Networks},\n volume = {abs/1502.00873},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f9d119346b0773ea83251598fa5305bc75bac8ab",
            "@type": "ScholarlyArticle",
            "paperId": "f9d119346b0773ea83251598fa5305bc75bac8ab",
            "corpusId": 24309481,
            "url": "https://www.semanticscholar.org/paper/f9d119346b0773ea83251598fa5305bc75bac8ab",
            "title": "Spectral\u2013Spatial Classification of Hyperspectral Data Based on Deep Belief Network",
            "venue": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
            "publicationVenue": {
                "id": "urn:research:849b6687-df71-4d12-9c46-59f45d5ce951",
                "name": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
                "alternate_names": [
                    "IEEE J Sel Top Appl Earth Obs Remote Sens"
                ],
                "issn": "1939-1404",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=4609443"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/staeors/ChenZJ15",
                "MAG": "2090424610",
                "DOI": "10.1109/JSTARS.2015.2388577",
                "CorpusId": 24309481
            },
            "abstract": "Hyperspectral data classification is a hot topic in remote sensing community. In recent years, significant effort has been focused on this issue. However, most of the methods extract the features of original data in a shallow manner. In this paper, we introduce a deep learning approach into hyperspectral image classification. A new feature extraction (FE) and image classification framework are proposed for hyperspectral data analysis based on deep belief network (DBN). First, we verify the eligibility of restricted Boltzmann machine (RBM) and DBN by the following spectral information-based classification. Then, we propose a novel deep architecture, which combines the spectral-spatial FE and classification together to get high classification accuracy. The framework is a hybrid of principal component analysis (PCA), hierarchical learning-based FE, and logistic regression (LR). Experimental results with hyperspectral data indicate that the classifier provide competitive solution with the state-of-the-art methods. In addition, this paper reveals that deep learning system has huge potential for hyperspectral data classification.",
            "referenceCount": 56,
            "citationCount": 925,
            "influentialCitationCount": 48,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-01-23",
            "journal": {
                "name": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2015SpectralSpatialCO,\n author = {Yushi Chen and Xing Zhao and X. Jia},\n booktitle = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},\n journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},\n pages = {2381-2392},\n title = {Spectral\u2013Spatial Classification of Hyperspectral Data Based on Deep Belief Network},\n volume = {8},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6",
            "@type": "ScholarlyArticle",
            "paperId": "e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6",
            "corpusId": 2495132,
            "url": "https://www.semanticscholar.org/paper/e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6",
            "title": "Deep Canonical Correlation Analysis",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "1523385540",
                "DBLP": "conf/icml/AndrewABL13",
                "CorpusId": 2495132
            },
            "abstract": "We introduce Deep Canonical Correlation Analysis (DCCA), a method to learn complex nonlinear transformations of two views of data such that the resulting representations are highly linearly correlated. Parameters of both transformations are jointly learned to maximize the (regularized) total correlation. It can be viewed as a nonlinear extension of the linear method canonical correlation analysis (CCA). It is an alternative to the nonparametric method kernel canonical correlation analysis (KCCA) for learning correlated nonlinear transformations. Unlike KCCA, DCCA does not require an inner product, and has the advantages of a parametric method: training time scales well with data size and the training data need not be referenced when computing the representations of unseen instances. In experiments on two real-world datasets, we find that DCCA learns representations with significantly higher correlation than those learned by CCA and KCCA. We also introduce a novel non-saturating sigmoid function based on the cube root that may be useful more generally in feedforward neural networks.",
            "referenceCount": 39,
            "citationCount": 1554,
            "influentialCitationCount": 387,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-06-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Andrew2013DeepCC,\n author = {Galen Andrew and R. Arora and J. Bilmes and Karen Livescu},\n booktitle = {International Conference on Machine Learning},\n pages = {1247-1255},\n title = {Deep Canonical Correlation Analysis},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:77e3c48aa10535276e7f570a3af594ba63de7d65",
            "@type": "ScholarlyArticle",
            "paperId": "77e3c48aa10535276e7f570a3af594ba63de7d65",
            "corpusId": 2181703,
            "url": "https://www.semanticscholar.org/paper/77e3c48aa10535276e7f570a3af594ba63de7d65",
            "title": "Training Deep Neural Networks on Noisy Labels with Bootstrapping",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2014,
            "externalIds": {
                "ArXiv": "1412.6596",
                "DBLP": "journals/corr/ReedLASER14",
                "MAG": "2121056381",
                "CorpusId": 2181703
            },
            "abstract": "Current state-of-the-art deep learning systems for visual object recognition and detection use purely supervised training with regularization such as dropout to avoid overfitting. The performance depends critically on the amount of labeled examples, and in current practice the labels are assumed to be unambiguous and accurate. However, this assumption often does not hold; e.g. in recognition, class labels may be missing; in detection, objects in the image may not be localized; and in general, the labeling may be subjective. In this work we propose a generic way to handle noisy and incomplete labeling by augmenting the prediction objective with a notion of consistency. We consider a prediction consistent if the same prediction is made given similar percepts, where the notion of similarity is between deep network features computed from the input data. In experiments we demonstrate that our approach yields substantial robustness to label noise on several datasets. On MNIST handwritten digits, we show that our model is robust to label corruption. On the Toronto Face Database, we show that our model handles well the case of subjective labels in emotion recognition, achieving state-of-the- art results, and can also benefit from unlabeled face images with no modification to our method. On the ILSVRC2014 detection challenge data, we show that our approach extends to very deep networks, high resolution images and structured outputs, and results in improved scalable detection.",
            "referenceCount": 44,
            "citationCount": 891,
            "influentialCitationCount": 94,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-12-19",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1412.6596"
            },
            "citationStyles": {
                "bibtex": "@Article{Reed2014TrainingDN,\n author = {Scott E. Reed and Honglak Lee and Dragomir Anguelov and Christian Szegedy and D. Erhan and Andrew Rabinovich},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Training Deep Neural Networks on Noisy Labels with Bootstrapping},\n volume = {abs/1412.6596},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1d6e6adc7a841393fc10b78dc0018e550aff589d",
            "@type": "ScholarlyArticle",
            "paperId": "1d6e6adc7a841393fc10b78dc0018e550aff589d",
            "corpusId": 8049057,
            "url": "https://www.semanticscholar.org/paper/1d6e6adc7a841393fc10b78dc0018e550aff589d",
            "title": "Provable Bounds for Learning Some Deep Representations",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/icml/AroraBGM14",
                "MAG": "2143915663",
                "ArXiv": "1310.6343",
                "CorpusId": 8049057
            },
            "abstract": "We give algorithms with provable guarantees that learn a class of deep nets in the generative model view popularized by Hinton and others. Our generative model is an n node multilayer network that has degree at most n\u03b3 for some \u03b3 < 1 and each edge has a random edge weight in [-1, 1]. Our algorithm learns almost all networks in this class with polynomial running time. The sample complexity is quadratic or cubic depending upon the details of the model. \n \nThe algorithm uses layerwise learning. It is based upon a novel idea of observing correlations among features and using these to infer the underlying edge structure via a global graph recovery procedure. The analysis of the algorithm reveals interesting structure of neural nets with random edge weights.",
            "referenceCount": 26,
            "citationCount": 323,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-10-23",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Arora2013ProvableBF,\n author = {Sanjeev Arora and Aditya Bhaskara and Rong Ge and Tengyu Ma},\n booktitle = {International Conference on Machine Learning},\n pages = {584-592},\n title = {Provable Bounds for Learning Some Deep Representations},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ee661a5510ab1f035aa5dbf3d06109c388e6358d",
            "@type": "ScholarlyArticle",
            "paperId": "ee661a5510ab1f035aa5dbf3d06109c388e6358d",
            "corpusId": 3815411,
            "url": "https://www.semanticscholar.org/paper/ee661a5510ab1f035aa5dbf3d06109c388e6358d",
            "title": "Learning a variational network for reconstruction of accelerated MRI data",
            "venue": "Magnetic Resonance in Medicine",
            "publicationVenue": {
                "id": "urn:research:c1269fa2-b51c-4648-bf0c-95797c4a74cd",
                "name": "Magnetic Resonance in Medicine",
                "alternate_names": [
                    "Magn Reson Med"
                ],
                "issn": "0740-3194",
                "url": "http://www3.interscience.wiley.com/cgi-bin/jhome/10005196"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1704.00447",
                "MAG": "2952781412",
                "DBLP": "journals/corr/HammernikKKRSPK17",
                "DOI": "10.1002/mrm.26977",
                "CorpusId": 3815411,
                "PubMed": "29115689"
            },
            "abstract": "To allow fast and high\u2010quality reconstruction of clinical accelerated multi\u2010coil MR data by learning a variational network that combines the mathematical structure of variational models with deep learning.",
            "referenceCount": 66,
            "citationCount": 1205,
            "influentialCitationCount": 73,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mrm.26977",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-04-03",
            "journal": {
                "name": "Magnetic Resonance in Medicine",
                "volume": "79"
            },
            "citationStyles": {
                "bibtex": "@Article{Hammernik2017LearningAV,\n author = {K. Hammernik and Teresa Klatzer and Erich Kobler and M. Recht and D. Sodickson and T. Pock and F. Knoll},\n booktitle = {Magnetic Resonance in Medicine},\n journal = {Magnetic Resonance in Medicine},\n title = {Learning a variational network for reconstruction of accelerated MRI data},\n volume = {79},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:77e379fd57ea44638fc628623e383eccada82689",
            "@type": "ScholarlyArticle",
            "paperId": "77e379fd57ea44638fc628623e383eccada82689",
            "corpusId": 5731075,
            "url": "https://www.semanticscholar.org/paper/77e379fd57ea44638fc628623e383eccada82689",
            "title": "Kernel Methods for Deep Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2009,
            "externalIds": {
                "DBLP": "phd/us/Cho12",
                "MAG": "2167608136",
                "CorpusId": 5731075
            },
            "abstract": "We introduce a new family of positive-definite kernel functions that mimic the computation in large, multilayer neural nets. These kernel functions can be used in shallow architectures, such as support vector machines (SVMs), or in deep kernel-based architectures that we call multilayer kernel machines (MKMs). We evaluate SVMs and MKMs with these kernel functions on problems designed to illustrate the advantages of deep architectures. On several problems, we obtain better results than previous, leading benchmarks from both SVMs with Gaussian kernels as well as deep belief nets.",
            "referenceCount": 72,
            "citationCount": 722,
            "influentialCitationCount": 117,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2009-12-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cho2009KernelMF,\n author = {Youngmin Cho and L. Saul},\n booktitle = {Neural Information Processing Systems},\n pages = {342-350},\n title = {Kernel Methods for Deep Learning},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d2e4587744a89bad95fea69e08842cad6c8ff0dd",
            "@type": "ScholarlyArticle",
            "paperId": "d2e4587744a89bad95fea69e08842cad6c8ff0dd",
            "corpusId": 13123084,
            "url": "https://www.semanticscholar.org/paper/d2e4587744a89bad95fea69e08842cad6c8ff0dd",
            "title": "Temporal Ensembling for Semi-Supervised Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1610.02242",
                "DBLP": "journals/corr/LaineA16",
                "MAG": "2951970475",
                "CorpusId": 13123084
            },
            "abstract": "In this paper, we present a simple and efficient method for training deep neural networks in a semi-supervised setting where only a small portion of training data is labeled. We introduce self-ensembling, where we form a consensus prediction of the unknown labels using the outputs of the network-in-training on different epochs, and most importantly, under different regularization and input augmentation conditions. This ensemble prediction can be expected to be a better predictor for the unknown labels than the output of the network at the most recent training epoch, and can thus be used as a target for training. Using our method, we set new records for two standard semi-supervised learning benchmarks, reducing the (non-augmented) classification error rate from 18.44% to 7.05% in SVHN with 500 labels and from 18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16% by enabling the standard augmentations. We additionally obtain a clear improvement in CIFAR-100 classification accuracy by using random images from the Tiny Images dataset as unlabeled extra inputs during training. Finally, we demonstrate good tolerance to incorrect labels.",
            "referenceCount": 41,
            "citationCount": 1909,
            "influentialCitationCount": 256,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-10-07",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1610.02242"
            },
            "citationStyles": {
                "bibtex": "@Article{Laine2016TemporalEF,\n author = {S. Laine and Timo Aila},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Temporal Ensembling for Semi-Supervised Learning},\n volume = {abs/1610.02242},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8e22a4d2d6af1d21d29fdb875ca8b55fcfa69bf0",
            "@type": "ScholarlyArticle",
            "paperId": "8e22a4d2d6af1d21d29fdb875ca8b55fcfa69bf0",
            "corpusId": 148571749,
            "url": "https://www.semanticscholar.org/paper/8e22a4d2d6af1d21d29fdb875ca8b55fcfa69bf0",
            "title": "Learning Loss for Active Learning",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1905.03677",
                "MAG": "2956371155",
                "DBLP": "conf/cvpr/YooK19",
                "DOI": "10.1109/CVPR.2019.00018",
                "CorpusId": 148571749
            },
            "abstract": "The performance of deep neural networks improves with more annotated data. The problem is that the budget for annotation is limited. One solution to this is active learning, where a model asks human to annotate data that it perceived as uncertain. A variety of recent methods have been proposed to apply active learning to deep networks but most of them are either designed specific for their target tasks or computationally inefficient for large networks. In this paper, we propose a novel active learning method that is simple but task-agnostic, and works efficiently with the deep networks. We attach a small parametric module, named ``loss prediction module,'' to a target network, and learn it to predict target losses of unlabeled inputs. Then, this module can suggest data that the target model is likely to produce a wrong prediction. This method is task-agnostic as networks are learned from a single loss regardless of target tasks. We rigorously validate our method through image classification, object detection, and human pose estimation, with the recent network architectures. The results demonstrate that our method consistently outperforms the previous methods over the tasks.",
            "referenceCount": 60,
            "citationCount": 464,
            "influentialCitationCount": 126,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1905.03677",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-05-09",
            "journal": {
                "name": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yoo2019LearningLF,\n author = {Donggeun Yoo and In-So Kweon},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {93-102},\n title = {Learning Loss for Active Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2e34d2483808d6f0c78289fafc48c61dcdc068eb",
            "@type": "ScholarlyArticle",
            "paperId": "2e34d2483808d6f0c78289fafc48c61dcdc068eb",
            "corpusId": 206595579,
            "url": "https://www.semanticscholar.org/paper/2e34d2483808d6f0c78289fafc48c61dcdc068eb",
            "title": "Deep Cross-Modal Hashing",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/JiangL16",
                "MAG": "2266728343",
                "ArXiv": "1602.02255",
                "DOI": "10.1109/CVPR.2017.348",
                "CorpusId": 206595579
            },
            "abstract": "Due to its low storage cost and fast query speed, cross-modal hashing (CMH) has been widely used for similarity search in multimedia retrieval applications. However, most existing CMH methods are based on hand-crafted features which might not be optimally compatible with the hash-code learning procedure. As a result, existing CMH methods with hand-crafted features may not achieve satisfactory performance. In this paper, we propose a novel CMH method, called deep cross-modal hashing (DCMH), by integrating feature learning and hash-code learning intothe same framework. DCMH is an end-to-end learning framework with deep neural networks, one for each modality, to perform feature learning from scratch. Experiments on three real datasets with image-text modalities show that DCMH can outperform other baselines to achieve the state-of-the-art performance in cross-modal retrieval applications.",
            "referenceCount": 52,
            "citationCount": 532,
            "influentialCitationCount": 131,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-02-06",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Jiang2016DeepCH,\n author = {Qing-Yuan Jiang and Wu-Jun Li},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {3270-3278},\n title = {Deep Cross-Modal Hashing},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:62df84d6a4d26f95e4714796c2337c9848cc13b5",
            "@type": "ScholarlyArticle",
            "paperId": "62df84d6a4d26f95e4714796c2337c9848cc13b5",
            "corpusId": 1507815,
            "url": "https://www.semanticscholar.org/paper/62df84d6a4d26f95e4714796c2337c9848cc13b5",
            "title": "MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1512.01274",
                "DBLP": "journals/corr/ChenLLLWWXXZZ15",
                "MAG": "2186615578",
                "CorpusId": 1507815
            },
            "abstract": "MXNet is a multi-language machine learning (ML) library to ease the development of ML algorithms, especially for deep neural networks. Embedded in the host language, it blends declarative symbolic expression with imperative tensor computation. It offers auto differentiation to derive gradients. MXNet is computation and memory efficient and runs on various heterogeneous systems, ranging from mobile devices to distributed GPU clusters. \nThis paper describes both the API design and the system implementation of MXNet, and explains how embedding of both symbolic expression and tensor operation is handled in a unified fashion. Our preliminary experiments reveal promising results on large scale deep neural network applications using multiple GPU machines.",
            "referenceCount": 13,
            "citationCount": 2139,
            "influentialCitationCount": 273,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-12-03",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1512.01274"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2015MXNetAF,\n author = {Tianqi Chen and Mu Li and Yutian Li and Min Lin and Naiyan Wang and Minjie Wang and Tianjun Xiao and Bing Xu and Chiyuan Zhang and Zheng Zhang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems},\n volume = {abs/1512.01274},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:08bd705920792314e3ef806c28d0a7f40505634f",
            "@type": "ScholarlyArticle",
            "paperId": "08bd705920792314e3ef806c28d0a7f40505634f",
            "corpusId": 203736521,
            "url": "https://www.semanticscholar.org/paper/08bd705920792314e3ef806c28d0a7f40505634f",
            "title": "Clustered Federated Learning: Model-Agnostic Distributed Multitask Optimization Under Privacy Constraints",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3080934299",
                "DBLP": "journals/corr/abs-1910-01991",
                "ArXiv": "1910.01991",
                "DOI": "10.1109/TNNLS.2020.3015958",
                "CorpusId": 203736521,
                "PubMed": "32833654"
            },
            "abstract": "Federated learning (FL) is currently the most widely adopted framework for collaborative training of (deep) machine learning models under privacy constraints. Albeit its popularity, it has been observed that FL yields suboptimal results if the local clients\u2019 data distributions diverge. To address this issue, we present clustered FL (CFL), a novel federated multitask learning (FMTL) framework, which exploits geometric properties of the FL loss surface to group the client population into clusters with jointly trainable data distributions. In contrast to existing FMTL approaches, CFL does not require any modifications to the FL communication protocol to be made, is applicable to general nonconvex objectives (in particular, deep neural networks), does not require the number of clusters to be known a priori, and comes with strong mathematical guarantees on the clustering quality. CFL is flexible enough to handle client populations that vary over time and can be implemented in a privacy-preserving way. As clustering is only performed after FL has converged to a stationary point, CFL can be viewed as a postprocessing method that will always achieve greater or equal performance than conventional FL by allowing clients to arrive at more specialized models. We verify our theoretical analysis in experiments with deep convolutional and recurrent neural networks on commonly used FL data sets.",
            "referenceCount": 45,
            "citationCount": 511,
            "influentialCitationCount": 77,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/5962385/9505270/09174890.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-10-04",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "32"
            },
            "citationStyles": {
                "bibtex": "@Article{Sattler2019ClusteredFL,\n author = {Felix Sattler and K. M\u00fcller and W. Samek},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {3710-3722},\n title = {Clustered Federated Learning: Model-Agnostic Distributed Multitask Optimization Under Privacy Constraints},\n volume = {32},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3a5ac09e759f3223ee78b995ae2b519efc0f9292",
            "@type": "ScholarlyArticle",
            "paperId": "3a5ac09e759f3223ee78b995ae2b519efc0f9292",
            "corpusId": 20718228,
            "url": "https://www.semanticscholar.org/paper/3a5ac09e759f3223ee78b995ae2b519efc0f9292",
            "title": "Introduction to Reinforcement Learning",
            "venue": "Deep Reinforcement Learning",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3038962357",
                "DOI": "10.1007/978-981-13-8285-7_1",
                "CorpusId": 20718228
            },
            "abstract": null,
            "referenceCount": 26,
            "citationCount": 472,
            "influentialCitationCount": 36,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Deep Reinforcement Learning",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sewak2019IntroductionTR,\n author = {Mohit Sewak},\n booktitle = {Deep Reinforcement Learning},\n journal = {Deep Reinforcement Learning},\n title = {Introduction to Reinforcement Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:aee6d6b3282662b69a1020c95be725e0075428bd",
            "@type": "ScholarlyArticle",
            "paperId": "aee6d6b3282662b69a1020c95be725e0075428bd",
            "corpusId": 60035920,
            "url": "https://www.semanticscholar.org/paper/aee6d6b3282662b69a1020c95be725e0075428bd",
            "title": "Reinforcement Learning: An Introduction",
            "venue": "IEEE Transactions on Neural Networks",
            "publicationVenue": {
                "id": "urn:research:2ac50919-507e-41c7-93a8-721c4b804757",
                "name": "IEEE Transactions on Neural Networks",
                "alternate_names": [
                    "IEEE Trans Neural Netw"
                ],
                "issn": "1045-9227",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=72"
            },
            "year": 2005,
            "externalIds": {
                "DOI": "10.1109/tnn.2004.842673",
                "CorpusId": 60035920
            },
            "abstract": "Overview of the volume In the research area of artificial intelligence (AI) a branch that is becoming more and more important is reinforcement learning (RL). RL can be defined as learning how to map situations into actions interacting with the environment, so as to maximize a reward. Written by two pioneers in this field, this book aims at supplying the basic RL ideas and algorithms. Even if the main point of view is the AI and engineering perspective, the Sutton\u2013Barto book was designed to be accessible to readers of different disciplines. It turns out that the level of mathematical knowledge required to understand the material is not too deep and requires familiarity only with elementary notions of probability. The book has been divided into three parts. The Problem (three chapters) is the introductory part devoted to the problem description. Elementary Solution Methods (three chapters) describes the most important elementary solution methods in authors' opinion: dynamic programming (DP), simple Monte Carlo (MC) methods, and temporal-difference (TD) learning. A Unified View (five chapters) concerns a generalization of the previous methods, gives a unified view of RL, and provides some examples of real RL applications. Each chapter has many examples and exercises. Sections and exercises marked with a star (*) can be skipped during a first reading. At the end of every chapter there is a very interesting section dedicated to bibliographical and historical remarks. Chapter 1: Introduction The first chapter, an introduction to RL, emphasizes its main characteristics: interaction with environment, goal-directed learning, rewards, trade-off between exploration and exploitation. The four subelements into which a RL system can be subdivided are well explained: a policy, a reward function, a value function and, optionally, an environment model. Chapter 2: Evaluative Feedback One of the main characteristics of RL is that it uses training information that evaluates actions. This is well exemplified by the n-armed bandit problem described in this chapter, which in addition introduces the basic learning methods that will be used in the rest of the book. Concepts like action estimation, update rule, and greedy action selection become familiar. Chapter 3: The Reinforcement Learning Problem This is certainly the most important chapter of the first part, since it describes the RL problem and gives its mathematical formalization. For simplicity, the authors expressly consider discrete time steps and do not extend the treatment to the continuous time case. The Markov decision processes (MDPs), \u2026",
            "referenceCount": 0,
            "citationCount": 13842,
            "influentialCitationCount": 2314,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Transactions on Neural Networks",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Sutton2005ReinforcementLA,\n author = {R. S. Sutton},\n booktitle = {IEEE Transactions on Neural Networks},\n journal = {IEEE Transactions on Neural Networks},\n pages = {285-286},\n title = {Reinforcement Learning: An Introduction},\n volume = {16},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:39a1abcbb87d8ff48ee47d446411a3455451f25b",
            "@type": "ScholarlyArticle",
            "paperId": "39a1abcbb87d8ff48ee47d446411a3455451f25b",
            "corpusId": 1605434,
            "url": "https://www.semanticscholar.org/paper/39a1abcbb87d8ff48ee47d446411a3455451f25b",
            "title": "Deep Convolutional Neural Networks on Multichannel Time Series for Human Activity Recognition",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2288074780",
                "DBLP": "conf/ijcai/YangNSLK15",
                "CorpusId": 1605434
            },
            "abstract": "This paper focuses on human activity recognition (HAR) problem, in which inputs are multichannel time series signals acquired from a set of bodyworn inertial sensors and outputs are predefined human activities. In this problem, extracting effective features for identifying activities is a critical but challenging task. Most existing work relies on heuristic hand-crafted feature design and shallow feature learning architectures, which cannot find those distinguishing features to accurately classify different activities. In this paper, we propose a systematic feature learning method for HAR problem. This method adopts a deep convolutional neural networks (CNN) to automate feature learning from the raw inputs in a systematic way. Through the deep architecture, the learned features are deemed as the higher level abstract representation of low level raw time series signals. By leveraging the labelled information via supervised learning, the learned features are endowed with more discriminative power. Unified in one model, feature learning and classification are mutually enhanced. All these unique advantages of the CNN make it outperform other HAR algorithms, as verified in the experiments on the Opportunity Activity Recognition Challenge and other benchmark datasets.",
            "referenceCount": 27,
            "citationCount": 965,
            "influentialCitationCount": 74,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-07-25",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2015DeepCN,\n author = {Jianbo Yang and M. N. Nguyen and P. P. San and Xiaoli Li and S. Krishnaswamy},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {3995-4001},\n title = {Deep Convolutional Neural Networks on Multichannel Time Series for Human Activity Recognition},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:355d44f53428b1ac4fb2ab468d593c720640e5bd",
            "@type": "ScholarlyArticle",
            "paperId": "355d44f53428b1ac4fb2ab468d593c720640e5bd",
            "corpusId": 14201947,
            "url": "https://www.semanticscholar.org/paper/355d44f53428b1ac4fb2ab468d593c720640e5bd",
            "title": "Greedy Layer-Wise Training of Deep Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2110798204",
                "DBLP": "conf/nips/BengioLPL06",
                "DOI": "10.7551/mitpress/7503.003.0024",
                "CorpusId": 14201947
            },
            "abstract": "Complexity theory of circuits strongly suggests that deep architectures can be much more efficient (sometimes exponentially) than shallow architectures, in terms of computational elements required to represent some functions. Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization appears to often get stuck in poor solutions. Hinton et al. recently introduced a greedy layer-wise unsupervised learning algorithm for Deep Belief Networks (DBN), a generative model with many layers of hidden causal variables. In the context of the above optimization problem, we study this algorithm empirically and explore variants to better understand its success and extend it to cases where the inputs are continuous or where the structure of the input distribution is not revealing enough about the variable to be predicted in a supervised task. Our experiments also confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization.",
            "referenceCount": 18,
            "citationCount": 4369,
            "influentialCitationCount": 240,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.iro.umontreal.ca/~lisa/pointeurs/BengioNips2006All.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-12-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bengio2006GreedyLT,\n author = {Yoshua Bengio and Pascal Lamblin and D. Popovici and H. Larochelle},\n booktitle = {Neural Information Processing Systems},\n pages = {153-160},\n title = {Greedy Layer-Wise Training of Deep Networks},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:158824a969bfb81617378c024240344e36d6cc04",
            "@type": "ScholarlyArticle",
            "paperId": "158824a969bfb81617378c024240344e36d6cc04",
            "corpusId": 206757077,
            "url": "https://www.semanticscholar.org/paper/158824a969bfb81617378c024240344e36d6cc04",
            "title": "Learning Deep and Wide: A Spectral Method for Learning Deep Networks",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/tnn/ShaoWL14",
                "MAG": "1978508564",
                "DOI": "10.1109/TNNLS.2014.2308519",
                "CorpusId": 206757077,
                "PubMed": "25420251"
            },
            "abstract": "Building intelligent systems that are capable of extracting high-level representations from high-dimensional sensory data lies at the core of solving many computer vision-related tasks. We propose the multispectral neural networks (MSNN) to learn features from multicolumn deep neural networks and embed the penultimate hierarchical discriminative manifolds into a compact representation. The low-dimensional embedding explores the complementary property of different views wherein the distribution of each view is sufficiently smooth and hence achieves robustness, given few labeled training data. Our experiments show that spectrally embedding several deep neural networks can explore the optimum output from the multicolumn networks and consistently decrease the error rate compared with a single deep network.",
            "referenceCount": 32,
            "citationCount": 139,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-03-11",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{Shao2014LearningDA,\n author = {Ling Shao and Di Wu and Xuelong Li},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {2303-2308},\n title = {Learning Deep and Wide: A Spectral Method for Learning Deep Networks},\n volume = {25},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8948bea1e2436e51316f131170923cb5b7d870db",
            "@type": "ScholarlyArticle",
            "paperId": "8948bea1e2436e51316f131170923cb5b7d870db",
            "corpusId": 4508400,
            "url": "https://www.semanticscholar.org/paper/8948bea1e2436e51316f131170923cb5b7d870db",
            "title": "Learning with Hierarchical-Deep Models",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2153125595",
                "DBLP": "journals/pami/SalakhutdinovTT13",
                "DOI": "10.1109/TPAMI.2012.269",
                "CorpusId": 4508400,
                "PubMed": "23787346"
            },
            "abstract": "We introduce HD (or \u201cHierarchical-Deep\u201d) models, a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian (HB) models. Specifically, we show how we can learn a hierarchical Dirichlet process (HDP) prior over the activities of the top-level features in a deep Boltzmann machine (DBM). This compound HDP-DBM model learns to learn novel concepts from very few training example by learning low-level generic features, high-level features that capture correlations among low-level features, and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts. We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition, handwritten character recognition, and human motion capture datasets.",
            "referenceCount": 49,
            "citationCount": 223,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dspace.mit.edu/bitstream/1721.1/90947/1/HD_PAMI.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-08-01",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Salakhutdinov2013LearningWH,\n author = {R. Salakhutdinov and J. Tenenbaum and A. Torralba},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {1958-1971},\n title = {Learning with Hierarchical-Deep Models},\n volume = {35},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:37b5dfe87d82ba8f310155165d5bf841dc92dea2",
            "@type": "ScholarlyArticle",
            "paperId": "37b5dfe87d82ba8f310155165d5bf841dc92dea2",
            "corpusId": 15247298,
            "url": "https://www.semanticscholar.org/paper/37b5dfe87d82ba8f310155165d5bf841dc92dea2",
            "title": "Cyclical Learning Rates for Training Neural Networks",
            "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:acd15a6d-3248-41fb-8439-9a40aabe5608",
                "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                "alternate_names": [
                    "Workshop on Applications of Computer Vision",
                    "WACV",
                    "IEEE Work Conf Appl Comput Vis",
                    "Workshop Appl Comput Vis"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=2993"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2964054038",
                "DBLP": "conf/wacv/Smith17",
                "ArXiv": "1506.01186",
                "DOI": "10.1109/WACV.2017.58",
                "CorpusId": 15247298
            },
            "abstract": "It is known that the learning rate is the most important hyper-parameter to tune for training deep neural networks. This paper describes a new method for setting the learning rate, named cyclical learning rates, which practically eliminates the need to experimentally find the best values and schedule for the global learning rates. Instead of monotonically decreasing the learning rate, this method lets the learning rate cyclically vary between reasonable boundary values. Training with cyclical learning rates instead of fixed values achieves improved classification accuracy without a need to tune and often in fewer iterations. This paper also describes a simple way to estimate \"reasonable bounds\" \u2013 linearly increasing the learning rate of the network for a few epochs. In addition, cyclical learning rates are demonstrated on the CIFAR-10 and CIFAR-100 datasets with ResNets, Stochastic Depth networks, and DenseNets, and the ImageNet dataset with the AlexNet and GoogLeNet architectures. These are practical tools for everyone who trains neural networks.",
            "referenceCount": 34,
            "citationCount": 2053,
            "influentialCitationCount": 197,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1506.01186",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-06-03",
            "journal": {
                "name": "2017 IEEE Winter Conference on Applications of Computer Vision (WACV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Smith2015CyclicalLR,\n author = {L. Smith},\n booktitle = {IEEE Workshop/Winter Conference on Applications of Computer Vision},\n journal = {2017 IEEE Winter Conference on Applications of Computer Vision (WACV)},\n pages = {464-472},\n title = {Cyclical Learning Rates for Training Neural Networks},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fdbe123a6535720274db2518af49abe9e9daac87",
            "@type": "ScholarlyArticle",
            "paperId": "fdbe123a6535720274db2518af49abe9e9daac87",
            "corpusId": 15562587,
            "url": "https://www.semanticscholar.org/paper/fdbe123a6535720274db2518af49abe9e9daac87",
            "title": "Why and when can deep-but not shallow-networks avoid the curse of dimensionality: A review",
            "venue": "International Journal of Automation and Computing",
            "publicationVenue": {
                "id": "urn:research:ec733e98-d402-49a3-8cf0-e35b1fecbd84",
                "name": "International Journal of Automation and Computing",
                "alternate_names": [
                    "Int J Autom Comput"
                ],
                "issn": "1476-8186",
                "url": "https://link.springer.com/journal/11633"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/PoggioMRML16",
                "MAG": "2952301100",
                "ArXiv": "1611.00740",
                "DOI": "10.1007/s11633-017-1054-2",
                "CorpusId": 15562587
            },
            "abstract": null,
            "referenceCount": 68,
            "citationCount": 498,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2Fs11633-017-1054-2.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-11-02",
            "journal": {
                "name": "International Journal of Automation and Computing",
                "volume": "14"
            },
            "citationStyles": {
                "bibtex": "@Article{Poggio2016WhyAW,\n author = {T. Poggio and H. Mhaskar and L. Rosasco and B. Miranda and Q. Liao},\n booktitle = {International Journal of Automation and Computing},\n journal = {International Journal of Automation and Computing},\n pages = {503 - 519},\n title = {Why and when can deep-but not shallow-networks avoid the curse of dimensionality: A review},\n volume = {14},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:401192b00b650adfa5ac49de59b720e1c81f1410",
            "@type": "ScholarlyArticle",
            "paperId": "401192b00b650adfa5ac49de59b720e1c81f1410",
            "corpusId": 8217340,
            "url": "https://www.semanticscholar.org/paper/401192b00b650adfa5ac49de59b720e1c81f1410",
            "title": "Object Detectors Emerge in Deep Scene CNNs",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1899185266",
                "ArXiv": "1412.6856",
                "DBLP": "journals/corr/ZhouKLOT14",
                "CorpusId": 8217340
            },
            "abstract": "With the success of new computational architectures for visual processing, such as convolutional neural networks (CNN) and access to image databases with millions of labeled examples (e.g., ImageNet, Places), the state of the art in computer vision is advancing rapidly. One important factor for continued progress is to understand the representations that are learned by the inner layers of these deep architectures. Here we show that object detectors emerge from training CNNs to perform scene classification. As scenes are composed of objects, the CNN for scene classification automatically discovers meaningful objects detectors, representative of the learned scene categories. With object detectors emerging as a result of learning to recognize scenes, our work demonstrates that the same network can perform both scene recognition and object localization in a single forward-pass, without ever having been explicitly taught the notion of objects.",
            "referenceCount": 32,
            "citationCount": 1190,
            "influentialCitationCount": 82,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-12-21",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1412.6856"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhou2014ObjectDE,\n author = {Bolei Zhou and A. Khosla and \u00c0gata Lapedriza and A. Oliva and A. Torralba},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Object Detectors Emerge in Deep Scene CNNs},\n volume = {abs/1412.6856},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d1cbceec6bf279ea473dc950e049cb99088711f9",
            "@type": "ScholarlyArticle",
            "paperId": "d1cbceec6bf279ea473dc950e049cb99088711f9",
            "corpusId": 17055633,
            "url": "https://www.semanticscholar.org/paper/d1cbceec6bf279ea473dc950e049cb99088711f9",
            "title": "Change Detection in Synthetic Aperture Radar Images Based on Deep Neural Networks",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2221448138",
                "DBLP": "journals/tnn/GongZLMJ16",
                "DOI": "10.1109/TNNLS.2015.2435783",
                "CorpusId": 17055633,
                "PubMed": "26068879"
            },
            "abstract": "This paper presents a novel change detection approach for synthetic aperture radar images based on deep learning. The approach accomplishes the detection of the changed and unchanged areas by designing a deep neural network. The main guideline is to produce a change detection map directly from two images with the trained deep neural network. The method can omit the process of generating a difference image (DI) that shows difference degrees between multitemporal synthetic aperture radar images. Thus, it can avoid the effect of the DI on the change detection results. The learning algorithm for deep architectures includes unsupervised feature learning and supervised fine-tuning to complete classification. The unsupervised feature learning aims at learning the representation of the relationships between the two images. In addition, the supervised fine-tuning aims at learning the concepts of the changed and unchanged pixels. Experiments on real data sets and theoretical analysis indicate the advantages, feasibility, and potential of the proposed method. Moreover, based on the results achieved by various traditional algorithms, respectively, deep learning can further improve the detection performance.",
            "referenceCount": 50,
            "citationCount": 470,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Gong2016ChangeDI,\n author = {Maoguo Gong and Jiaojiao Zhao and Jia Liu and Q. Miao and L. Jiao},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {125-138},\n title = {Change Detection in Synthetic Aperture Radar Images Based on Deep Neural Networks},\n volume = {27},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:208cd4b25768f0096fb2e80e7690473da0e2a563",
            "@type": "ScholarlyArticle",
            "paperId": "208cd4b25768f0096fb2e80e7690473da0e2a563",
            "corpusId": 29153681,
            "url": "https://www.semanticscholar.org/paper/208cd4b25768f0096fb2e80e7690473da0e2a563",
            "title": "Meta-learning with differentiable closed-form solvers",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2952292344",
                "ArXiv": "1805.08136",
                "DBLP": "journals/corr/abs-1805-08136",
                "CorpusId": 29153681
            },
            "abstract": "Adapting deep networks to new concepts from a few examples is challenging, due to the high computational requirements of standard fine-tuning procedures. Most work on few-shot learning has thus focused on simple learning techniques for adaptation, such as nearest neighbours or gradient descent. Nonetheless, the machine learning literature contains a wealth of methods that learn non-deep models very efficiently. In this paper, we propose to use these fast convergent methods as the main adaptation mechanism for few-shot learning. The main idea is to teach a deep network to use standard machine learning tools, such as ridge regression, as part of its own internal model, enabling it to quickly adapt to novel data. This requires back-propagating errors through the solver steps. While normally the cost of the matrix operations involved in such a process would be significant, by using the Woodbury identity we can make the small number of examples work to our advantage. We propose both closed-form and iterative solvers, based on ridge regression and logistic regression components. Our methods constitute a simple and novel approach to the problem of few-shot learning and achieve performance competitive with or superior to the state of the art on three benchmarks.",
            "referenceCount": 72,
            "citationCount": 752,
            "influentialCitationCount": 191,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-05-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1805.08136"
            },
            "citationStyles": {
                "bibtex": "@Article{Bertinetto2018MetalearningWD,\n author = {Luca Bertinetto and Jo\u00e3o F. Henriques and Philip H. S. Torr and A. Vedaldi},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Meta-learning with differentiable closed-form solvers},\n volume = {abs/1805.08136},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:15561ab20c298e113b0008b7a029486a422e7ca3",
            "@type": "ScholarlyArticle",
            "paperId": "15561ab20c298e113b0008b7a029486a422e7ca3",
            "corpusId": 49194806,
            "url": "https://www.semanticscholar.org/paper/15561ab20c298e113b0008b7a029486a422e7ca3",
            "title": "Bilevel Programming for Hyperparameter Optimization and Meta-Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2949709344",
                "DBLP": "journals/corr/abs-1806-04910",
                "ArXiv": "1806.04910",
                "CorpusId": 49194806
            },
            "abstract": "We introduce a framework based on bilevel programming that unifies gradient-based hyperparameter optimization and meta-learning. We show that an approximate version of the bilevel problem can be solved by taking into explicit account the optimization dynamics for the inner objective. Depending on the specific setting, the outer variables take either the meaning of hyperparameters in a supervised learning problem or parameters of a meta-learner. We provide sufficient conditions under which solutions of the approximate problem converge to those of the exact problem. We instantiate our approach for meta-learning in the case of deep learning where representation layers are treated as hyperparameters shared across a set of training episodes. In experiments, we confirm our theoretical findings, present encouraging results for few-shot learning and contrast the bilevel approach against classical approaches for learning-to-learn.",
            "referenceCount": 47,
            "citationCount": 554,
            "influentialCitationCount": 80,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-06-13",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Franceschi2018BilevelPF,\n author = {Luca Franceschi and P. Frasconi and Saverio Salzo and Riccardo Grazzi and M. Pontil},\n booktitle = {International Conference on Machine Learning},\n pages = {1563-1572},\n title = {Bilevel Programming for Hyperparameter Optimization and Meta-Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:93a636f0b6d450217fda5aaa26c74bb6b232f498",
            "@type": "ScholarlyArticle",
            "paperId": "93a636f0b6d450217fda5aaa26c74bb6b232f498",
            "corpusId": 3502463,
            "url": "https://www.semanticscholar.org/paper/93a636f0b6d450217fda5aaa26c74bb6b232f498",
            "title": "Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1802-09127",
                "ArXiv": "1802.09127",
                "MAG": "2949264726",
                "CorpusId": 3502463
            },
            "abstract": "Recent advances in deep reinforcement learning have made significant strides in performance on applications such as Go and Atari games. However, developing practical methods to balance exploration and exploitation in complex domains remains largely unsolved. Thompson Sampling and its extension to reinforcement learning provide an elegant approach to exploration that only requires access to posterior samples of the model. At the same time, advances in approximate Bayesian methods have made posterior approximation for flexible neural network models practical. Thus, it is attractive to consider approximate Bayesian neural networks in a Thompson Sampling framework. To understand the impact of using an approximate posterior on Thompson Sampling, we benchmark well-established and recently developed methods for approximate posterior sampling combined with Thompson Sampling over a series of contextual bandit problems. We found that many approaches that have been successful in the supervised learning setting underperformed in the sequential decision-making scenario. In particular, we highlight the challenge of adapting slowly converging uncertainty estimates to the online setting.",
            "referenceCount": 58,
            "citationCount": 301,
            "influentialCitationCount": 49,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1802.09127"
            },
            "citationStyles": {
                "bibtex": "@Article{Riquelme2018DeepBB,\n author = {C. Riquelme and G. Tucker and Jasper Snoek},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling},\n volume = {abs/1802.09127},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3904315e2eca50d0086e4b7273f7fd707c652230",
            "@type": "ScholarlyArticle",
            "paperId": "3904315e2eca50d0086e4b7273f7fd707c652230",
            "corpusId": 6466088,
            "url": "https://www.semanticscholar.org/paper/3904315e2eca50d0086e4b7273f7fd707c652230",
            "title": "Meta-Learning with Memory-Augmented Neural Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/icml/SantoroBBWL16",
                "MAG": "2472819217",
                "CorpusId": 6466088
            },
            "abstract": "Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of \"one-shot learning.\" Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.",
            "referenceCount": 20,
            "citationCount": 1478,
            "influentialCitationCount": 81,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-19",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Santoro2016MetaLearningWM,\n author = {Adam Santoro and Sergey Bartunov and M. Botvinick and Daan Wierstra and T. Lillicrap},\n booktitle = {International Conference on Machine Learning},\n pages = {1842-1850},\n title = {Meta-Learning with Memory-Augmented Neural Networks},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d8d680aea59295c020b9d53d78dd8d954a876845",
            "@type": "ScholarlyArticle",
            "paperId": "d8d680aea59295c020b9d53d78dd8d954a876845",
            "corpusId": 54448258,
            "url": "https://www.semanticscholar.org/paper/d8d680aea59295c020b9d53d78dd8d954a876845",
            "title": "Meta-Transfer Learning for Few-Shot Learning",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/cvpr/SunLCS19",
                "MAG": "2903334135",
                "ArXiv": "1812.02391",
                "DOI": "10.1109/CVPR.2019.00049",
                "CorpusId": 54448258
            },
            "abstract": "Meta-learning has been proposed as a framework to address the challenging few-shot learning setting. The key idea is to leverage a large number of similar few-shot tasks in order to learn how to adapt a base-learner to a new task for which only a few labeled samples are available. As deep neural networks (DNNs) tend to overfit using a few samples only, meta-learning typically uses shallow neural networks (SNNs), thus limiting its effectiveness. In this paper we propose a novel few-shot learning method called meta-transfer learning (MTL) which learns to adapt a deep NN for few shot learning tasks. Specifically, \"meta\" refers to training multiple tasks, and \"transfer\" is achieved by learning scaling and shifting functions of DNN weights for each task. In addition, we introduce the hard task (HT) meta-batch scheme as an effective learning curriculum for MTL. We conduct experiments using (5-class, 1-shot) and (5-class, 5-shot) recognition tasks on two challenging few-shot learning benchmarks: miniImageNet and Fewshot-CIFAR100. Extensive comparisons to related works validate that our meta-transfer learning approach trained with the proposed HT meta-batch scheme achieves top performance. An ablation study also shows that both components contribute to fast convergence and high accuracy.",
            "referenceCount": 61,
            "citationCount": 864,
            "influentialCitationCount": 65,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-12-06",
            "journal": {
                "name": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sun2018MetaTransferLF,\n author = {Qianru Sun and Yaoyao Liu and Tat-Seng Chua and B. Schiele},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {403-412},\n title = {Meta-Transfer Learning for Few-Shot Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bf38dfb13352449b965c08282b66d3ffc5a0539f",
            "@type": "ScholarlyArticle",
            "paperId": "bf38dfb13352449b965c08282b66d3ffc5a0539f",
            "corpusId": 12219023,
            "url": "https://www.semanticscholar.org/paper/bf38dfb13352449b965c08282b66d3ffc5a0539f",
            "title": "Unsupervised feature learning for audio classification using convolutional deep belief networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2107789863",
                "DBLP": "conf/nips/LeePLN09",
                "CorpusId": 12219023
            },
            "abstract": "In recent years, deep learning approaches have gained significant interest as a way of building hierarchical representations from unlabeled data. However, to our knowledge, these deep learning approaches have not been extensively studied for auditory data. In this paper, we apply convolutional deep belief networks to audio data and empirically evaluate them on various audio classification tasks. In the case of speech data, we show that the learned features correspond to phones/phonemes. In addition, our feature representations learned from unlabeled audio data show very good performance for multiple audio classification tasks. We hope that this paper will inspire more research on deep learning approaches applied to a wide range of audio recognition tasks.",
            "referenceCount": 20,
            "citationCount": 1144,
            "influentialCitationCount": 47,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2009-12-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lee2009UnsupervisedFL,\n author = {Honglak Lee and Peter T. Pham and Yan Largman and A. Ng},\n booktitle = {Neural Information Processing Systems},\n pages = {1096-1104},\n title = {Unsupervised feature learning for audio classification using convolutional deep belief networks},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:01c40508dcb6f8e9efcdefe49e22bc0ccaf8881c",
            "@type": "ScholarlyArticle",
            "paperId": "01c40508dcb6f8e9efcdefe49e22bc0ccaf8881c",
            "corpusId": 15665411,
            "url": "https://www.semanticscholar.org/paper/01c40508dcb6f8e9efcdefe49e22bc0ccaf8881c",
            "title": "Learning Background-Aware Correlation Filters for Visual Tracking",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2949607263",
                "DBLP": "journals/corr/GaloogahiFL17",
                "ArXiv": "1703.04590",
                "DOI": "10.1109/ICCV.2017.129",
                "CorpusId": 15665411
            },
            "abstract": "Correlation Filters (CFs) have recently demonstrated excellent performance in terms of rapidly tracking objects under challenging photometric and geometric variations. The strength of the approach comes from its ability to efficiently learn - on the fly - how the object is changing over time. A fundamental drawback to CFs, however, is that the background of the target is not modeled over time which can result in suboptimal performance. Recent tracking algorithms have suggested to resolve this drawback by either learning CFs from more discriminative deep features (e.g. DeepSRDCF [9] and CCOT [11]) or learning complex deep trackers (e.g. MDNet [28] and FCNT [33]). While such methods have been shown to work well, they suffer from high complexity: extracting deep features or applying deep tracking frameworks is very computationally expensive. This limits the real-time performance of such methods, even on high-end GPUs. This work proposes a Background-Aware CF based on hand-crafted features (HOG [6]) that can efficiently model how both the foreground and background of the object varies over time. Our approach, like conventional CFs, is extremely computationally efficient- and extensive experiments over multiple tracking benchmarks demonstrate the superior accuracy and real-time performance of our method compared to the state-of-the-art trackers.",
            "referenceCount": 38,
            "citationCount": 929,
            "influentialCitationCount": 240,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1703.04590",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-14",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Galoogahi2017LearningBC,\n author = {Hamed Kiani Galoogahi and Ashton Fagg and S. Lucey},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2017 IEEE International Conference on Computer Vision (ICCV)},\n pages = {1144-1152},\n title = {Learning Background-Aware Correlation Filters for Visual Tracking},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ea58af907495e97c93997119db4a59fab5cd3683",
            "@type": "ScholarlyArticle",
            "paperId": "ea58af907495e97c93997119db4a59fab5cd3683",
            "corpusId": 10663248,
            "url": "https://www.semanticscholar.org/paper/ea58af907495e97c93997119db4a59fab5cd3683",
            "title": "Deep Machine Learning - A New Frontier in Artificial Intelligence Research [Research Frontier]",
            "venue": "IEEE Computational Intelligence Magazine",
            "publicationVenue": {
                "id": "urn:research:ee372de7-efda-4907-a03f-359292ea27f6",
                "name": "IEEE Computational Intelligence Magazine",
                "alternate_names": [
                    "IEEE Comput Intell Mag"
                ],
                "issn": "1556-603X",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=10207"
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2182924040",
                "DBLP": "journals/cim/ArelRK10",
                "DOI": "10.1109/MCI.2010.938364",
                "CorpusId": 10663248
            },
            "abstract": "This article provides an overview of the mainstream deep learning approaches and research directions proposed over the past decade. It is important to emphasize that each approach has strengths and \"weaknesses, depending on the application and context in \"which it is being used. Thus, this article presents a summary on the current state of the deep machine learning field and some perspective into how it may evolve. Convolutional Neural Networks (CNNs) and Deep Belief Networks (DBNs) (and their respective variations) are focused on primarily because they are well established in the deep learning field and show great promise for future work.",
            "referenceCount": 56,
            "citationCount": 1119,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2010-11-01",
            "journal": {
                "name": "IEEE Computational Intelligence Magazine",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Arel2010DeepML,\n author = {I. Arel and Derek C. Rose and T. Karnowski},\n booktitle = {IEEE Computational Intelligence Magazine},\n journal = {IEEE Computational Intelligence Magazine},\n pages = {13-18},\n title = {Deep Machine Learning - A New Frontier in Artificial Intelligence Research [Research Frontier]},\n volume = {5},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:729b18d8d91035f4bb84bf2e61b0517824e5d31b",
            "@type": "ScholarlyArticle",
            "paperId": "729b18d8d91035f4bb84bf2e61b0517824e5d31b",
            "corpusId": 1972072,
            "url": "https://www.semanticscholar.org/paper/729b18d8d91035f4bb84bf2e61b0517824e5d31b",
            "title": "Auxiliary Deep Generative Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2280377497",
                "DBLP": "conf/icml/MaaloeSSW16",
                "ArXiv": "1602.05473",
                "CorpusId": 1972072
            },
            "abstract": "Deep generative models parameterized by neural networks have recently achieved state-of-the-art performance in unsupervised and semi-supervised learning. We extend deep generative models with auxiliary variables which improves the variational approximation. The auxiliary variables leave the generative model unchanged but make the variational distribution more expressive. Inspired by the structure of the auxiliary variable we also propose a model with two stochastic layers and skip connections. Our findings suggest that more expressive and properly specified deep generative models converge faster with better results. We show state-of-the-art performance within semi-supervised learning on MNIST, SVHN and NORB datasets.",
            "referenceCount": 27,
            "citationCount": 430,
            "influentialCitationCount": 54,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-02-17",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Maal\u00f8e2016AuxiliaryDG,\n author = {Lars Maal\u00f8e and C. S\u00f8nderby and S\u00f8ren Kaae S\u00f8nderby and O. Winther},\n booktitle = {International Conference on Machine Learning},\n pages = {1445-1453},\n title = {Auxiliary Deep Generative Models},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5728b151bb5ab14d71ea05299b3f630fc64de31f",
            "@type": "ScholarlyArticle",
            "paperId": "5728b151bb5ab14d71ea05299b3f630fc64de31f",
            "corpusId": 43264878,
            "url": "https://www.semanticscholar.org/paper/5728b151bb5ab14d71ea05299b3f630fc64de31f",
            "title": "Deep hedging",
            "venue": "Quantitative finance (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1802.03042",
                "MAG": "2796124216",
                "DOI": "10.1080/14697688.2019.1571683",
                "CorpusId": 43264878
            },
            "abstract": "We present a framework for hedging a portfolio of derivatives in the presence of market frictions such as transaction costs, liquidity constraints or risk limits using modern deep reinforcement machine learning methods. We discuss how standard reinforcement learning methods can be applied to non-linear reward structures, i.e. in our case convex risk measures. As a general contribution to the use of deep learning for stochastic processes, we also show in Section 4 that the set of constrained trading strategies used by our algorithm is large enough to \u03b5-approximate any optimal solution. Our algorithm can be implemented efficiently even in high-dimensional situations using modern machine learning tools. Its structure does not depend on specific market dynamics, and generalizes across hedging instruments including the use of liquid derivatives. Its computational performance is largely invariant in the size of the portfolio as it depends mainly on the number of hedging instruments available. We illustrate our approach by an experiment on the S&P500 index and by showing the effect on hedging under transaction costs in a synthetic market driven by the Heston model, where we outperform the standard \u2018complete-market\u2019 solution.",
            "referenceCount": 46,
            "citationCount": 252,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Economics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Economics",
                    "source": "external"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-02-08",
            "journal": {
                "name": "Quantitative Finance",
                "volume": "19"
            },
            "citationStyles": {
                "bibtex": "@Article{Buehler2018DeepH,\n author = {Hans Buehler and Lukas Gonon and J. Teichmann and Ben Wood},\n booktitle = {Quantitative finance (Print)},\n journal = {Quantitative Finance},\n pages = {1271 - 1291},\n title = {Deep hedging},\n volume = {19},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:42a7f3e90aa4929d7f01b6124b87f82f7735aa88",
            "@type": "ScholarlyArticle",
            "paperId": "42a7f3e90aa4929d7f01b6124b87f82f7735aa88",
            "corpusId": 90259576,
            "url": "https://www.semanticscholar.org/paper/42a7f3e90aa4929d7f01b6124b87f82f7735aa88",
            "title": "Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1904-00310",
                "ArXiv": "1904.00310",
                "MAG": "2956135859",
                "CorpusId": 90259576
            },
            "abstract": "Addressing catastrophic forgetting is one of the key challenges in continual learning where machine learning systems are trained with sequential or streaming tasks. Despite recent remarkable progress in state-of-the-art deep learning, deep neural networks (DNNs) are still plagued with the catastrophic forgetting problem. This paper presents a conceptually simple yet general and effective framework for handling catastrophic forgetting in continual learning with DNNs. The proposed method consists of two components: a neural structure optimization component and a parameter learning and/or fine-tuning component. By separating the explicit neural structure learning and the parameter estimation, not only is the proposed method capable of evolving neural structures in an intuitively meaningful way, but also shows strong capabilities of alleviating catastrophic forgetting in experiments. Furthermore, the proposed method outperforms all other baselines on the permuted MNIST dataset, the split CIFAR100 dataset and the Visual Domain Decathlon dataset in continual learning setting.",
            "referenceCount": 31,
            "citationCount": 278,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-03-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1904.00310"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2019LearnTG,\n author = {Xilai Li and Yingbo Zhou and Tianfu Wu and R. Socher and Caiming Xiong},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting},\n volume = {abs/1904.00310},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ef2bc452812d6005ab0a66af6c3f97b6b0ba837e",
            "@type": "ScholarlyArticle",
            "paperId": "ef2bc452812d6005ab0a66af6c3f97b6b0ba837e",
            "corpusId": 54448010,
            "url": "https://www.semanticscholar.org/paper/ef2bc452812d6005ab0a66af6c3f97b6b0ba837e",
            "title": "Quantifying Generalization in Reinforcement Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2903181768",
                "ArXiv": "1812.02341",
                "DBLP": "conf/icml/CobbeKHKS19",
                "CorpusId": 54448010
            },
            "abstract": "In this paper, we investigate the problem of overfitting in deep reinforcement learning. Among the most common benchmarks in RL, it is customary to use the same environments for both training and testing. This practice offers relatively little insight into an agent's ability to generalize. We address this issue by using procedurally generated environments to construct distinct training and test sets. Most notably, we introduce a new environment called CoinRun, designed as a benchmark for generalization in RL. Using CoinRun, we find that agents overfit to surprisingly large training sets. We then show that deeper convolutional architectures improve generalization, as do methods traditionally found in supervised learning, including L2 regularization, dropout, data augmentation and batch normalization.",
            "referenceCount": 20,
            "citationCount": 497,
            "influentialCitationCount": 72,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-12-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cobbe2018QuantifyingGI,\n author = {Karl Cobbe and Oleg Klimov and Christopher Hesse and Taehoon Kim and J. Schulman},\n booktitle = {International Conference on Machine Learning},\n pages = {1282-1289},\n title = {Quantifying Generalization in Reinforcement Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7c616fe341381a4866135042dbb565d2eda415c3",
            "@type": "ScholarlyArticle",
            "paperId": "7c616fe341381a4866135042dbb565d2eda415c3",
            "corpusId": 10077891,
            "url": "https://www.semanticscholar.org/paper/7c616fe341381a4866135042dbb565d2eda415c3",
            "title": "Prediction as a candidate for learning deep hierarchical models of data",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2187281534",
                "CorpusId": 10077891
            },
            "abstract": "Recent findings [HOT06] have made possible the learning of deep layered hierarchical representations of data mimicking the brains working. It is hoped that this paradigm will unlock some of the power of the brain and lead to advances towards true AI. In this thesis I implement and evaluate state-of-the-art deep learning models and using these as building blocks I investigate the hypothesis that predicting the time-to-time sensory input is a good learning objective. I introduce the Predictive Encoder (PE) and show that a simple non-regularized learning rule, minimizing prediction error on natural video patches leads to receptive fields similar to those found in Macaque monkey visual area V1. I scale this model to video of natural scenes by introducing the Convolutional Predictive Encoder (CPE) and show similar results. Both models can be used in deep architectures as a deep learning module.",
            "referenceCount": 74,
            "citationCount": 433,
            "influentialCitationCount": 39,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Palm2012PredictionAA,\n author = {Rasmus Berg Palm},\n title = {Prediction as a candidate for learning deep hierarchical models of data},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:522e90b9fccfd3c1c0603359eb04757d770c1ab5",
            "@type": "ScholarlyArticle",
            "paperId": "522e90b9fccfd3c1c0603359eb04757d770c1ab5",
            "corpusId": 10808461,
            "url": "https://www.semanticscholar.org/paper/522e90b9fccfd3c1c0603359eb04757d770c1ab5",
            "title": "Practical Recommendations for Gradient-Based Training of Deep Architectures",
            "venue": "Neural Networks",
            "publicationVenue": {
                "id": "urn:research:a13f3cb8-2492-4ccb-9329-73a5ddcaab9b",
                "name": "Neural Networks",
                "alternate_names": [
                    "Neural Netw"
                ],
                "issn": "0893-6080",
                "url": "http://www.elsevier.com/locate/neunet"
            },
            "year": 2012,
            "externalIds": {
                "ArXiv": "1206.5533",
                "DBLP": "journals/corr/abs-1206-5533",
                "MAG": "2951650375",
                "DOI": "10.1007/978-3-642-35289-8_26",
                "CorpusId": 10808461
            },
            "abstract": null,
            "referenceCount": 125,
            "citationCount": 1980,
            "influentialCitationCount": 140,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1206.5533.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-06-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bengio2012PracticalRF,\n author = {Yoshua Bengio},\n booktitle = {Neural Networks},\n pages = {437-478},\n title = {Practical Recommendations for Gradient-Based Training of Deep Architectures},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6baaca1b6de31ac2a5b1f89e9b3baa61e41d52f9",
            "@type": "ScholarlyArticle",
            "paperId": "6baaca1b6de31ac2a5b1f89e9b3baa61e41d52f9",
            "corpusId": 64884,
            "url": "https://www.semanticscholar.org/paper/6baaca1b6de31ac2a5b1f89e9b3baa61e41d52f9",
            "title": "Deep Colorization",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/iccv/ChengYS15",
                "MAG": "2295537950",
                "ArXiv": "1605.00075",
                "DOI": "10.1109/ICCV.2015.55",
                "CorpusId": 64884
            },
            "abstract": "This paper investigates into the colorization problem which converts a grayscale image to a colorful version. This is a very difficult problem and normally requires manual adjustment to achieve artifact-free quality. For instance, it normally requires human-labelled color scribbles on the grayscale target image or a careful selection of colorful reference images (e.g., capturing the same scene in the grayscale target image). Unlike the previous methods, this paper aims at a high-quality fully-automatic colorization method. With the assumption of a perfect patch matching technique, the use of an extremely large-scale reference database (that contains sufficient color images) is the most reliable solution to the colorization problem. However, patch matching noise will increase with respect to the size of the reference database in practice. Inspired by the recent success in deep learning techniques which provide amazing modeling of large-scale data, this paper re-formulates the colorization problem so that deep learning techniques can be directly employed. To ensure artifact-free quality, a joint bilateral filtering based post-processing step is proposed. Numerous experiments demonstrate that our method outperforms the state-of-art algorithms both in terms of quality and speed.",
            "referenceCount": 39,
            "citationCount": 482,
            "influentialCitationCount": 30,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-12-07",
            "journal": {
                "name": "2015 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cheng2015DeepC,\n author = {Zezhou Cheng and Qingxiong Yang and Bin Sheng},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2015 IEEE International Conference on Computer Vision (ICCV)},\n pages = {415-423},\n title = {Deep Colorization},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:759b00cf35b397eab468935b5d90d04e9ed25549",
            "@type": "ScholarlyArticle",
            "paperId": "759b00cf35b397eab468935b5d90d04e9ed25549",
            "corpusId": 8558103,
            "url": "https://www.semanticscholar.org/paper/759b00cf35b397eab468935b5d90d04e9ed25549",
            "title": "Learning Representations for Counterfactual Inference",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2389937032",
                "DBLP": "conf/icml/JohanssonSS16",
                "ArXiv": "1605.03661",
                "CorpusId": 8558103
            },
            "abstract": "Observational studies are rising in importance due to the widespread accumulation of data in fields such as healthcare, education, employment and ecology. We consider the task of answering counterfactual questions such as, \"Would this patient have lower blood sugar had she received a different medication?\". We propose a new algorithmic framework for counterfactual inference which brings together ideas from domain adaptation and representation learning. In addition to a theoretical justification, we perform an empirical comparison with previous approaches to causal inference from observational data. Our deep learning algorithm significantly outperforms the previous state-of-the-art.",
            "referenceCount": 50,
            "citationCount": 566,
            "influentialCitationCount": 123,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-05-12",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1605.03661"
            },
            "citationStyles": {
                "bibtex": "@Article{Johansson2016LearningRF,\n author = {Fredrik D. Johansson and Uri Shalit and D. Sontag},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Learning Representations for Counterfactual Inference},\n volume = {abs/1605.03661},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d7bd6e3addd8bc8e2e154048300eea15f030ed33",
            "@type": "ScholarlyArticle",
            "paperId": "d7bd6e3addd8bc8e2e154048300eea15f030ed33",
            "corpusId": 14717992,
            "url": "https://www.semanticscholar.org/paper/d7bd6e3addd8bc8e2e154048300eea15f030ed33",
            "title": "Reinforcement Learning with Unsupervised Auxiliary Tasks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1611.05397",
                "DBLP": "conf/iclr/JaderbergMCSLSK17",
                "MAG": "2950872548",
                "CorpusId": 14717992
            },
            "abstract": "Deep reinforcement learning agents have achieved state-of-the-art results by directly maximising cumulative reward. However, environments contain a much wider variety of possible training signals. In this paper, we introduce an agent that also maximises many other pseudo-reward functions simultaneously by reinforcement learning. All of these tasks share a common representation that, like unsupervised learning, continues to develop in the absence of extrinsic rewards. We also introduce a novel mechanism for focusing this representation upon extrinsic rewards, so that learning can rapidly adapt to the most relevant aspects of the actual task. Our agent significantly outperforms the previous state-of-the-art on Atari, averaging 880\\% expert human performance, and a challenging suite of first-person, three-dimensional \\emph{Labyrinth} tasks leading to a mean speedup in learning of 10$\\times$ and averaging 87\\% expert human performance on Labyrinth.",
            "referenceCount": 34,
            "citationCount": 1123,
            "influentialCitationCount": 88,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-04",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1611.05397"
            },
            "citationStyles": {
                "bibtex": "@Article{Jaderberg2016ReinforcementLW,\n author = {Max Jaderberg and Volodymyr Mnih and Wojciech M. Czarnecki and T. Schaul and Joel Z. Leibo and David Silver and K. Kavukcuoglu},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Reinforcement Learning with Unsupervised Auxiliary Tasks},\n volume = {abs/1611.05397},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:21346e7fdffe3a388a62ef5edeb3a0a9736b903b",
            "@type": "ScholarlyArticle",
            "paperId": "21346e7fdffe3a388a62ef5edeb3a0a9736b903b",
            "corpusId": 206591781,
            "url": "https://www.semanticscholar.org/paper/21346e7fdffe3a388a62ef5edeb3a0a9736b903b",
            "title": "Learning hierarchical representations for face verification with convolutional deep belief networks",
            "venue": "2012 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2276144258",
                "DBLP": "conf/cvpr/HuangLL12",
                "DOI": "10.1109/CVPR.2012.6247968",
                "CorpusId": 206591781
            },
            "abstract": "Most modern face recognition systems rely on a feature representation given by a hand-crafted image descriptor, such as Local Binary Patterns (LBP), and achieve improved performance by combining several such representations. In this paper, we propose deep learning as a natural source for obtaining additional, complementary representations. To learn features in high-resolution images, we make use of convolutional deep belief networks. Moreover, to take advantage of global structure in an object class, we develop local convolutional restricted Boltzmann machines, a novel convolutional learning model that exploits the global structure by not assuming stationarity of features across the image, while maintaining scalability and robustness to small misalignments. We also present a novel application of deep learning to descriptors other than pixel intensity values, such as LBP. In addition, we compare performance of networks trained using unsupervised learning against networks with random filters, and empirically show that learning weights not only is necessary for obtaining good multilayer representations, but also provides robustness to the choice of the network architecture parameters. Finally, we show that a recognition system using only representations obtained from deep learning can achieve comparable accuracy with a system using a combination of hand-crafted image descriptors. Moreover, by combining these representations, we achieve state-of-the-art results on a real-world face verification database.",
            "referenceCount": 43,
            "citationCount": 417,
            "influentialCitationCount": 22,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cs.umass.edu/%7Eelm/papers/HuangCVPR12.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-06-16",
            "journal": {
                "name": "2012 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2012LearningHR,\n author = {Gary B. Huang and Honglak Lee and E. Learned-Miller},\n booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {2518-2525},\n title = {Learning hierarchical representations for face verification with convolutional deep belief networks},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cddf8a10c7f48df67a797808a615be0d4acf9a8e",
            "@type": "ScholarlyArticle",
            "paperId": "cddf8a10c7f48df67a797808a615be0d4acf9a8e",
            "corpusId": 5855183,
            "url": "https://www.semanticscholar.org/paper/cddf8a10c7f48df67a797808a615be0d4acf9a8e",
            "title": "Semi-supervised Learning with Ladder Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/nips/RasmusBHVR15",
                "ArXiv": "1507.02672",
                "MAG": "2952229419",
                "CorpusId": 5855183
            },
            "abstract": "We combine supervised learning with unsupervised learning in deep neural networks. The proposed model is trained to simultaneously minimize the sum of supervised and unsupervised cost functions by backpropagation, avoiding the need for layer-wise pre-training. Our work builds on top of the Ladder network proposed by Valpola [1] which we extend by combining the model with supervision. We show that the resulting model reaches state-of-the-art performance in semi-supervised MNIST and CIFAR-10 classification in addition to permutation-invariant MNIST classification with all labels.",
            "referenceCount": 45,
            "citationCount": 1241,
            "influentialCitationCount": 113,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-07-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Rasmus2015SemisupervisedLW,\n author = {Antti Rasmus and Mathias Berglund and M. Honkala and H. Valpola and T. Raiko},\n booktitle = {Neural Information Processing Systems},\n pages = {3546-3554},\n title = {Semi-supervised Learning with Ladder Networks},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5e2c4e7b3302549b3718601c44d9af6c7554efef",
            "@type": "ScholarlyArticle",
            "paperId": "5e2c4e7b3302549b3718601c44d9af6c7554efef",
            "corpusId": 21529792,
            "url": "https://www.semanticscholar.org/paper/5e2c4e7b3302549b3718601c44d9af6c7554efef",
            "title": "Learning Robust Rewards with Adversarial Inverse Reinforcement Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2766610320",
                "DBLP": "journals/corr/abs-1710-11248",
                "ArXiv": "1710.11248",
                "CorpusId": 21529792
            },
            "abstract": "Reinforcement learning provides a powerful and general framework for decision making and control, but its application in practice is often hindered by the need for extensive feature and reward engineering. Deep reinforcement learning methods can remove the need for explicit engineering of policy or value features, but still require a manually specified reward function. Inverse reinforcement learning holds the promise of automatic reward acquisition, but has proven exceptionally difficult to apply to large, high-dimensional problems with unknown dynamics. In this work, we propose adverserial inverse reinforcement learning (AIRL), a practical and scalable inverse reinforcement learning algorithm based on an adversarial reward learning formulation. We demonstrate that AIRL is able to recover reward functions that are robust to changes in dynamics, enabling us to learn policies even under significant variation in the environment seen during training. Our experiments show that AIRL greatly outperforms prior methods in these transfer settings.",
            "referenceCount": 26,
            "citationCount": 657,
            "influentialCitationCount": 158,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-30",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1710.11248"
            },
            "citationStyles": {
                "bibtex": "@Article{Fu2017LearningRR,\n author = {Justin Fu and Katie Luo and S. Levine},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},\n volume = {abs/1710.11248},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:282a380fb5ac26d99667224cef8c630f6882704f",
            "@type": "ScholarlyArticle",
            "paperId": "282a380fb5ac26d99667224cef8c630f6882704f",
            "corpusId": 13623631,
            "url": "https://www.semanticscholar.org/paper/282a380fb5ac26d99667224cef8c630f6882704f",
            "title": "Learning to reinforcement learn",
            "venue": "Annual Meeting of the Cognitive Science Society",
            "publicationVenue": {
                "id": "urn:research:9c06885c-ecb6-4a76-ba1e-fbad53521efd",
                "name": "Annual Meeting of the Cognitive Science Society",
                "alternate_names": [
                    "CogSci",
                    "Annu Meet Cogn Sci Soc"
                ],
                "issn": null,
                "url": "http://cognitivesciencesociety.org/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2550182557",
                "DBLP": "journals/corr/WangKTSLMBKB16",
                "ArXiv": "1611.05763",
                "CorpusId": 13623631
            },
            "abstract": "In recent years deep reinforcement learning (RL) systems have attained superhuman performance in a number of challenging task domains. However, a major limitation of such applications is their demand for massive amounts of training data. A critical present objective is thus to develop deep RL methods that can adapt rapidly to new tasks. In the present work we introduce a novel approach to this challenge, which we refer to as deep meta-reinforcement learning. Previous work has shown that recurrent networks can support meta-learning in a fully supervised context. We extend this approach to the RL setting. What emerges is a system that is trained using one RL algorithm, but whose recurrent dynamics implement a second, quite separate RL procedure. This second, learned RL algorithm can differ from the original one in arbitrary ways. Importantly, because it is learned, it is configured to exploit structure in the training domain. We unpack these points in a series of seven proof-of-concept experiments, each of which examines a key aspect of deep meta-RL. We consider prospects for extending and scaling up the approach, and also point out some potentially important implications for neuroscience.",
            "referenceCount": 52,
            "citationCount": 847,
            "influentialCitationCount": 104,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Psychology",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-17",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1611.05763"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2016LearningTR,\n author = {Jane X. Wang and Z. Kurth-Nelson and Hubert Soyer and Joel Z. Leibo and Dhruva Tirumala and R. Munos and C. Blundell and D. Kumaran and M. Botvinick},\n booktitle = {Annual Meeting of the Cognitive Science Society},\n journal = {ArXiv},\n title = {Learning to reinforcement learn},\n volume = {abs/1611.05763},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e3f8c8253767b6fe0891025cdf772cd286337921",
            "@type": "ScholarlyArticle",
            "paperId": "e3f8c8253767b6fe0891025cdf772cd286337921",
            "corpusId": 64849498,
            "url": "https://www.semanticscholar.org/paper/e3f8c8253767b6fe0891025cdf772cd286337921",
            "title": "A Proposal on Machine Learning via Dynamical Systems",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2600297185",
                "DOI": "10.1007/S40304-017-0103-Z",
                "CorpusId": 64849498
            },
            "abstract": null,
            "referenceCount": 11,
            "citationCount": 569,
            "influentialCitationCount": 33,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-03-22",
            "journal": {
                "name": "",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{E2017APO,\n author = {Weinan E},\n pages = {1-11},\n title = {A Proposal on Machine Learning via Dynamical Systems},\n volume = {5},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:df1769afbbf3904877629dd7e785f195361ec531",
            "@type": "ScholarlyArticle",
            "paperId": "df1769afbbf3904877629dd7e785f195361ec531",
            "corpusId": 3693512,
            "url": "https://www.semanticscholar.org/paper/df1769afbbf3904877629dd7e785f195361ec531",
            "title": "Lifelong Learning with Dynamically Expandable Networks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1708.01547",
                "DBLP": "journals/corr/abs-1708-01547",
                "MAG": "2744654301",
                "CorpusId": 3693512
            },
            "abstract": "We propose a novel deep network architecture for lifelong learning which we refer to as Dynamically Expandable Network (DEN), that can dynamically decide its network capacity as it trains on a sequence of tasks, to learn a compact overlapping knowledge sharing structure among tasks. DEN is efficiently trained in an online manner by performing selective retraining, dynamically expands network capacity upon arrival of each task with only the necessary number of units, and effectively prevents semantic drift by splitting/duplicating units and timestamping them. We validate DEN on multiple public datasets under lifelong learning scenarios, on which it not only significantly outperforms existing lifelong learning methods for deep networks, but also achieves the same level of performance as the batch counterparts with substantially fewer number of parameters. Further, the obtained network fine-tuned on all tasks obtained significantly better performance over the batch models, which shows that it can be used to estimate the optimal network structure even when all tasks are available in the first place.",
            "referenceCount": 17,
            "citationCount": 847,
            "influentialCitationCount": 77,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-08-04",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1708.01547"
            },
            "citationStyles": {
                "bibtex": "@Article{Yoon2017LifelongLW,\n author = {Jaehong Yoon and Eunho Yang and Jeongtae Lee and Sung Ju Hwang},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Lifelong Learning with Dynamically Expandable Networks},\n volume = {abs/1708.01547},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8a25c9403d8a0e2fb8ca362a1b26262afd57417f",
            "@type": "ScholarlyArticle",
            "paperId": "8a25c9403d8a0e2fb8ca362a1b26262afd57417f",
            "corpusId": 2906360,
            "url": "https://www.semanticscholar.org/paper/8a25c9403d8a0e2fb8ca362a1b26262afd57417f",
            "title": "DeepCoder: Learning to Write Programs",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2952842591",
                "DBLP": "conf/iclr/BalogGBNT17",
                "ArXiv": "1611.01989",
                "CorpusId": 2906360
            },
            "abstract": "We develop a first line of attack for solving programming competition-style problems from input-output examples using deep learning. The approach is to train a neural network to predict properties of the program that generated the outputs from the inputs. We use the neural network\u2019s predictions to augment search techniques from the programming languages community, including enumerative search and an SMT-based solver. Empirically, we show that our approach leads to an order of magnitude speedup over the strong non-augmented baselines and a Recurrent Neural Network approach, and that we are able to solve problems of difficulty comparable to the simplest problems on programming competition websites.",
            "referenceCount": 43,
            "citationCount": 496,
            "influentialCitationCount": 79,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-04",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1611.01989"
            },
            "citationStyles": {
                "bibtex": "@Article{Balog2016DeepCoderLT,\n author = {Matej Balog and Alexander L. Gaunt and Marc Brockschmidt and Sebastian Nowozin and Daniel Tarlow},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {DeepCoder: Learning to Write Programs},\n volume = {abs/1611.01989},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:82a262a2034b349abaa720c7f8229a0ef19e87cd",
            "@type": "ScholarlyArticle",
            "paperId": "82a262a2034b349abaa720c7f8229a0ef19e87cd",
            "corpusId": 49546141,
            "url": "https://www.semanticscholar.org/paper/82a262a2034b349abaa720c7f8229a0ef19e87cd",
            "title": "RLlib: Abstractions for Distributed Reinforcement Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2949532984",
                "DBLP": "conf/icml/LiangLNMFGGJS18",
                "CorpusId": 49546141
            },
            "abstract": "Reinforcement learning (RL) algorithms involve the deep nesting of highly irregular computation patterns, each of which typically exhibits opportunities for distributed computation. We argue for distributing RL components in a composable way by adapting algorithms for top-down hierarchical control, thereby encapsulating parallelism and resource requirements within short-running compute tasks. We demonstrate the benefits of this principle through RLlib: a library that provides scalable software primitives for RL. These primitives enable a broad range of algorithms to be implemented with high performance, scalability, and substantial code reuse. RLlib is available at this https URL.",
            "referenceCount": 42,
            "citationCount": 632,
            "influentialCitationCount": 89,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-12-26",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Liang2017RLlibAF,\n author = {Eric Liang and Richard Liaw and Robert Nishihara and Philipp Moritz and Roy Fox and Ken Goldberg and Joseph E. Gonzalez and Michael I. Jordan and I. Stoica},\n booktitle = {International Conference on Machine Learning},\n pages = {3059-3068},\n title = {RLlib: Abstractions for Distributed Reinforcement Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8de174ab5419b9d3127695405efd079808e956e8",
            "@type": "ScholarlyArticle",
            "paperId": "8de174ab5419b9d3127695405efd079808e956e8",
            "corpusId": 873046,
            "url": "https://www.semanticscholar.org/paper/8de174ab5419b9d3127695405efd079808e956e8",
            "title": "Curriculum learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2296073425",
                "DBLP": "conf/icml/BengioLCW09",
                "DOI": "10.1145/1553374.1553380",
                "CorpusId": 873046
            },
            "abstract": "Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them \"curriculum learning\". In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).",
            "referenceCount": 33,
            "citationCount": 4367,
            "influentialCitationCount": 353,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-06-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bengio2009CurriculumL,\n author = {Yoshua Bengio and J. Louradour and Ronan Collobert and J. Weston},\n booktitle = {International Conference on Machine Learning},\n pages = {41-48},\n title = {Curriculum learning},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d475f695dedd94e96771fdaa1e5c075fd01d11cf",
            "@type": "ScholarlyArticle",
            "paperId": "d475f695dedd94e96771fdaa1e5c075fd01d11cf",
            "corpusId": 13570924,
            "url": "https://www.semanticscholar.org/paper/d475f695dedd94e96771fdaa1e5c075fd01d11cf",
            "title": "Variational Continual Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1710.10628",
                "MAG": "2951799616",
                "DBLP": "conf/iclr/NguyenLBT18",
                "DOI": "10.17863/CAM.35471",
                "CorpusId": 13570924
            },
            "abstract": "This paper develops variational continual learning (VCL), a simple but general framework for continual learning that fuses online variational inference (VI) and recent advances in Monte Carlo VI for neural networks. The framework can successfully train both deep discriminative models and deep generative models in complex continual learning settings where existing tasks evolve over time and entirely new tasks emerge. Experimental results show that VCL outperforms state-of-the-art continual learning methods on a variety of tasks, avoiding catastrophic forgetting in a fully automatic way.",
            "referenceCount": 45,
            "citationCount": 592,
            "influentialCitationCount": 91,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-29",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1710.10628"
            },
            "citationStyles": {
                "bibtex": "@Article{Nguyen2017VariationalCL,\n author = {Cuong V Nguyen and Yingzhen Li and T. Bui and Richard E. Turner},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Variational Continual Learning},\n volume = {abs/1710.10628},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dd01dfa8e55eae8ffbbb168f0a4aa7911e594f8c",
            "@type": "ScholarlyArticle",
            "paperId": "dd01dfa8e55eae8ffbbb168f0a4aa7911e594f8c",
            "corpusId": 29551417,
            "url": "https://www.semanticscholar.org/paper/dd01dfa8e55eae8ffbbb168f0a4aa7911e594f8c",
            "title": "Deep IV: A Flexible Approach for Counterfactual Prediction",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/icml/HartfordLLT17",
                "MAG": "2740759698",
                "CorpusId": 29551417
            },
            "abstract": "Counterfactual prediction requires understanding causal relationships between so-called treatment and outcome variables. This paper provides a recipe for augmenting deep learning methods to accurately characterize such relationships in the presence of instrument variables (IVs)\u2014sources of treatment randomization that are conditionally independent from the outcomes. Our IV specification resolves into two prediction tasks that can be solved with deep neural nets: a first-stage network for treatment prediction and a second-stage network whose loss function involves integration over the conditional treatment distribution. This Deep IV framework allows us to take advantage of off-the-shelf supervised learning techniques to estimate causal effects by adapting the loss function. Experiments show that it outperforms existing machine learning approaches.",
            "referenceCount": 30,
            "citationCount": 235,
            "influentialCitationCount": 44,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-08-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hartford2017DeepIA,\n author = {Jason S. Hartford and Greg Lewis and Kevin Leyton-Brown and Matt Taddy},\n booktitle = {International Conference on Machine Learning},\n pages = {1414-1423},\n title = {Deep IV: A Flexible Approach for Counterfactual Prediction},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ddc45fad8d15771d9f1f8579331458785b2cdd93",
            "@type": "ScholarlyArticle",
            "paperId": "ddc45fad8d15771d9f1f8579331458785b2cdd93",
            "corpusId": 877639,
            "url": "https://www.semanticscholar.org/paper/ddc45fad8d15771d9f1f8579331458785b2cdd93",
            "title": "Deep Boltzmann Machines",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "MAG": "189596042",
                "DBLP": "journals/jmlr/SalakhutdinovH09",
                "CorpusId": 877639
            },
            "abstract": "We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent expectations are estimated using a variational approximation that tends to focus on a single mode, and dataindependent expectations are approximated using persistent Markov chains. The use of two quite different techniques for estimating the two types of expectation that enter into the gradient of the log-likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer \u201cpre-training\u201d phase that allows variational inference to be initialized with a single bottomup pass. We present results on the MNIST and NORB datasets showing that deep Boltzmann machines learn good generative models and perform well on handwritten digit and visual object recognition tasks.",
            "referenceCount": 22,
            "citationCount": 2198,
            "influentialCitationCount": 248,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-04-15",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Salakhutdinov2009DeepBM,\n author = {R. Salakhutdinov and Geoffrey E. Hinton},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n pages = {448-455},\n title = {Deep Boltzmann Machines},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:57fbd1841a7cf8582682da399d2811655f020c0a",
            "@type": "ScholarlyArticle",
            "paperId": "57fbd1841a7cf8582682da399d2811655f020c0a",
            "corpusId": 3537028,
            "url": "https://www.semanticscholar.org/paper/57fbd1841a7cf8582682da399d2811655f020c0a",
            "title": "UvA-DARE (Digital Academic Repository) Attention-based Deep Multiple Instance Learning Attention-based Deep Multiple Instance Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": null,
            "externalIds": {
                "CorpusId": 3537028
            },
            "abstract": "Multiple instance learning (MIL) is a variation of supervised learning where a single class label is assigned to a bag of instances. In this pa-per, we state the MIL problem as learning the Bernoulli distribution of the bag label where the bag label probability is fully parameterized by neural networks. Furthermore, we propose a neural network-based permutation-invariant aggregation operator that corresponds to the attention mechanism. Notably, an application of the proposed attention-based operator provides insight into the contribution of each instance to the bag label. We show empirically that our approach achieves comparable performance to the best MIL methods on benchmark MIL datasets and it outperforms other methods on a MNIST-based MIL dataset and two real-life histopathology datasets without sacri\ufb01cing interpretability.",
            "referenceCount": 50,
            "citationCount": 1119,
            "influentialCitationCount": 290,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Misc{None,\n author = {Maximilian Ilse and Jakub M. Tomczak and M. Welling},\n title = {UvA-DARE (Digital Academic Repository) Attention-based Deep Multiple Instance Learning Attention-based Deep Multiple Instance Learning}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ccee800244908d2960830967e70ead7dd8266f7a",
            "@type": "ScholarlyArticle",
            "paperId": "ccee800244908d2960830967e70ead7dd8266f7a",
            "corpusId": 2835189,
            "url": "https://www.semanticscholar.org/paper/ccee800244908d2960830967e70ead7dd8266f7a",
            "title": "Deep Rewiring: Training very sparse deep networks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/iclr/BellecK0L18",
                "MAG": "2964125494",
                "ArXiv": "1711.05136",
                "CorpusId": 2835189
            },
            "abstract": "Neuromorphic hardware tends to pose limits on the connectivity of deep networks that one can run on them. But also generic hardware and software implementations of deep learning run more efficiently for sparse networks. Several methods exist for pruning connections of a neural network after it was trained without connectivity constraints. We present an algorithm, DEEP R, that enables us to train directly a sparsely connected neural network. DEEP R automatically rewires the network during supervised training so that connections are there where they are most needed for the task, while its total number is all the time strictly bounded. We demonstrate that DEEP R can be used to train very sparse feedforward and recurrent neural networks on standard benchmark tasks with just a minor loss in performance. DEEP R is based on a rigorous theoretical foundation that views rewiring as stochastic sampling of network configurations from a posterior.",
            "referenceCount": 39,
            "citationCount": 230,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-14",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1711.05136"
            },
            "citationStyles": {
                "bibtex": "@Article{Bellec2017DeepRT,\n author = {G. Bellec and D. Kappel and W. Maass and R. Legenstein},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Deep Rewiring: Training very sparse deep networks},\n volume = {abs/1711.05136},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ece016d98b66d21489169cc4c7bbb5973d658e79",
            "@type": "ScholarlyArticle",
            "paperId": "ece016d98b66d21489169cc4c7bbb5973d658e79",
            "corpusId": 3332579,
            "url": "https://www.semanticscholar.org/paper/ece016d98b66d21489169cc4c7bbb5973d658e79",
            "title": "Deep Collaborative Filtering via Marginalized Denoising Auto-encoder",
            "venue": "International Conference on Information and Knowledge Management",
            "publicationVenue": {
                "id": "urn:research:7431ff67-91dc-41fa-b322-1b1ca657025f",
                "name": "International Conference on Information and Knowledge Management",
                "alternate_names": [
                    "Conference on Information and Knowledge Management",
                    "Conf Inf Knowl Manag",
                    "Int Conf Inf Knowl Manag",
                    "CIKM"
                ],
                "issn": null,
                "url": "http://www.cikm.org/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2038585576",
                "DBLP": "conf/cikm/LiKF15",
                "DOI": "10.1145/2806416.2806527",
                "CorpusId": 3332579
            },
            "abstract": "Collaborative filtering (CF) has been widely employed within recommender systems to solve many real-world problems. Learning effective latent factors plays the most important role in collaborative filtering. Traditional CF methods based upon matrix factorization techniques learn the latent factors from the user-item ratings and suffer from the cold start problem as well as the sparsity problem. Some improved CF methods enrich the priors on the latent factors by incorporating side information as regularization. However, the learned latent factors may not be very effective due to the sparse nature of the ratings and the side information. To tackle this problem, we learn effective latent representations via deep learning. Deep learning models have emerged as very appealing in learning effective representations in many applications. In particular, we propose a general deep architecture for CF by integrating matrix factorization with deep feature learning. We provide a natural instantiations of our architecture by combining probabilistic matrix factorization with marginalized denoising stacked auto-encoders. The combined framework leads to a parsimonious fit over the latent features as indicated by its improved performance in comparison to prior state-of-art models over four large datasets for the tasks of movie/book recommendation and response prediction.",
            "referenceCount": 44,
            "citationCount": 440,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-10-17",
            "journal": {
                "name": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Li2015DeepCF,\n author = {Sheng Li and Jaya Kawale and Y. Fu},\n booktitle = {International Conference on Information and Knowledge Management},\n journal = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management},\n title = {Deep Collaborative Filtering via Marginalized Denoising Auto-encoder},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:544998db166c047c70a61c5a5c54d10c5879ecf1",
            "@type": "ScholarlyArticle",
            "paperId": "544998db166c047c70a61c5a5c54d10c5879ecf1",
            "corpusId": 10738438,
            "url": "https://www.semanticscholar.org/paper/544998db166c047c70a61c5a5c54d10c5879ecf1",
            "title": "Deep Neural Decision Forests",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/ijcai/KontschiederFCB16",
                "MAG": "2578395343",
                "DOI": "10.1109/ICCV.2015.172",
                "CorpusId": 10738438
            },
            "abstract": "We present Deep Neural Decision Forests - a novel approach that unifies classification trees with the representation learning functionality known from deep convolutional networks, by training them in an end-to-end manner. To combine these two worlds, we introduce a stochastic and differentiable decision tree model, which steers the representation learning usually conducted in the initial layers of a (deep) convolutional network. Our model differs from conventional deep networks because a decision forest provides the final predictions and it differs from conventional decision forests since we propose a principled, joint and global optimization of split and leaf node parameters. We show experimental results on benchmark machine learning datasets like MNIST and ImageNet and find on-par or superior results when compared to state-of-the-art deep models. Most remarkably, we obtain Top5-Errors of only 7.84%/6.38% on ImageNet validation data when integrating our forests in a single-crop, single/seven model GoogLeNet architecture, respectively. Thus, even without any form of training data set augmentation we are improving on the 6.67% error obtained by the best GoogLeNet architecture (7 models, 144 crops).",
            "referenceCount": 47,
            "citationCount": 458,
            "influentialCitationCount": 70,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-12-07",
            "journal": {
                "name": "2015 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kontschieder2015DeepND,\n author = {P. Kontschieder and M. Fiterau and A. Criminisi and S. R. Bul\u00f2},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2015 IEEE International Conference on Computer Vision (ICCV)},\n pages = {1467-1475},\n title = {Deep Neural Decision Forests},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:622727f595542afa3caf8802927d880818ddb17a",
            "@type": "ScholarlyArticle",
            "paperId": "622727f595542afa3caf8802927d880818ddb17a",
            "corpusId": 46980528,
            "url": "https://www.semanticscholar.org/paper/622727f595542afa3caf8802927d880818ddb17a",
            "title": "Dimensionality-Driven Learning with Noisy Labels",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2963789034",
                "ArXiv": "1806.02612",
                "DBLP": "journals/corr/abs-1806-02612",
                "CorpusId": 46980528
            },
            "abstract": "Datasets with significant proportions of noisy (incorrect) class labels present challenges for training accurate Deep Neural Networks (DNNs). We propose a new perspective for understanding DNN generalization for such datasets, by investigating the dimensionality of the deep representation subspace of training samples. We show that from a dimensionality perspective, DNNs exhibit quite distinctive learning styles when trained with clean labels versus when trained with a proportion of noisy labels. Based on this finding, we develop a new dimensionality-driven learning strategy, which monitors the dimensionality of subspaces during training and adapts the loss function accordingly. We empirically demonstrate that our approach is highly tolerant to significant proportions of noisy labels, and can effectively learn low-dimensional local subspaces that capture the data distribution.",
            "referenceCount": 49,
            "citationCount": 351,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-06-07",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1806.02612"
            },
            "citationStyles": {
                "bibtex": "@Article{Ma2018DimensionalityDrivenLW,\n author = {Xingjun Ma and Yisen Wang and M. Houle and Shuo Zhou and S. Erfani and Shutao Xia and S. Wijewickrema and J. Bailey},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Dimensionality-Driven Learning with Noisy Labels},\n volume = {abs/1806.02612},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:63be611dc8cf09ed081b4ad2b1756420b782b0be",
            "@type": "ScholarlyArticle",
            "paperId": "63be611dc8cf09ed081b4ad2b1756420b782b0be",
            "corpusId": 7558574,
            "url": "https://www.semanticscholar.org/paper/63be611dc8cf09ed081b4ad2b1756420b782b0be",
            "title": "A Perspective on Deep Imaging",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/Wang16r",
                "MAG": "2950292967",
                "ArXiv": "1609.04375",
                "DOI": "10.1109/ACCESS.2016.2624938",
                "CorpusId": 7558574
            },
            "abstract": "The combination of tomographic imaging and deep learning, or machine learning in general, promises to empower not only image analysis but also image reconstruction. The latter aspect is considered in this perspective article with an emphasis on medical imaging to develop a new generation of image reconstruction theories and techniques. This direction might lead to intelligent utilization of domain knowledge from big data, innovative approaches for image reconstruction, and superior performance in clinical and preclinical applications. To realize the full impact of machine learning for tomographic imaging, major theoretical, technical and translational efforts are immediately needed.",
            "referenceCount": 51,
            "citationCount": 358,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-10",
            "journal": {
                "name": "IEEE Access",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2016APO,\n author = {Ge Wang},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {8914-8924},\n title = {A Perspective on Deep Imaging},\n volume = {4},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e2c477de72bb7718f5304c6f38457fda9c8334b1",
            "@type": "ScholarlyArticle",
            "paperId": "e2c477de72bb7718f5304c6f38457fda9c8334b1",
            "corpusId": 1883779,
            "url": "https://www.semanticscholar.org/paper/e2c477de72bb7718f5304c6f38457fda9c8334b1",
            "title": "Deep learning from temporal coherence in video",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2145038566",
                "DBLP": "conf/icml/MobahiCW09",
                "DOI": "10.1145/1553374.1553469",
                "CorpusId": 1883779
            },
            "abstract": "This work proposes a learning method for deep architectures that takes advantage of sequential data, in particular from the temporal coherence that naturally exists in unlabeled video recordings. That is, two successive frames are likely to contain the same object or objects. This coherence is used as a supervisory signal over the unlabeled data, and is used to improve the performance on a supervised task of interest. We demonstrate the effectiveness of this method on some pose invariant object and face recognition tasks.",
            "referenceCount": 35,
            "citationCount": 352,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-06-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mobahi2009DeepLF,\n author = {H. Mobahi and Ronan Collobert and J. Weston},\n booktitle = {International Conference on Machine Learning},\n pages = {737-744},\n title = {Deep learning from temporal coherence in video},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a441728f9fd6af1946368240162a72c2028c8cb1",
            "@type": "ScholarlyArticle",
            "paperId": "a441728f9fd6af1946368240162a72c2028c8cb1",
            "corpusId": 15264404,
            "url": "https://www.semanticscholar.org/paper/a441728f9fd6af1946368240162a72c2028c8cb1",
            "title": "Deep Exploration via Randomized Value Functions",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2974778612",
                "ArXiv": "1703.07608",
                "DBLP": "journals/jmlr/OsbandRRW19",
                "CorpusId": 15264404
            },
            "abstract": "We study the use of randomized value functions to guide deep exploration in reinforcement learning. This offers an elegant means for synthesizing statistically and computationally efficient exploration with common practical approaches to value function learning. We present several reinforcement learning algorithms that leverage randomized value functions and demonstrate their efficacy through computational studies. We also prove a regret bound that establishes statistical efficiency with a tabular representation.",
            "referenceCount": 83,
            "citationCount": 256,
            "influentialCitationCount": 30,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-22",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.07608"
            },
            "citationStyles": {
                "bibtex": "@Article{Osband2017DeepEV,\n author = {Ian Osband and Daniel Russo and Zheng Wen and Benjamin Van Roy},\n booktitle = {Journal of machine learning research},\n journal = {ArXiv},\n title = {Deep Exploration via Randomized Value Functions},\n volume = {abs/1703.07608},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4423357dd21cc59662c6fabaf9839b15ef0fb8a8",
            "@type": "ScholarlyArticle",
            "paperId": "4423357dd21cc59662c6fabaf9839b15ef0fb8a8",
            "corpusId": 2169827,
            "url": "https://www.semanticscholar.org/paper/4423357dd21cc59662c6fabaf9839b15ef0fb8a8",
            "title": "Learning feed-forward one-shot learners",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/nips/BertinettoHVTV16",
                "MAG": "2435450765",
                "ArXiv": "1606.05233",
                "CorpusId": 2169827
            },
            "abstract": "One-shot learning is usually tackled by using generative models or discriminative embeddings. Discriminative methods based on deep learning, which are very effective in other learning scenarios, are ill-suited for one-shot learning as they need large amounts of training data. In this paper, we propose a method to learn the parameters of a deep model in one shot. We construct the learner as a second deep network, called a learnet, which predicts the parameters of a pupil network from a single exemplar. In this manner we obtain an efficient feed-forward one-shot learner, trained end-to-end by minimizing a one-shot classification objective in a learning to learn formulation. In order to make the construction feasible, we propose a number of factorizations of the parameters of the pupil network. We demonstrate encouraging results by learning characters from single exemplars in Omniglot, and by tracking visual objects from a single initial exemplar in the Visual Object Tracking benchmark.",
            "referenceCount": 28,
            "citationCount": 426,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bertinetto2016LearningFO,\n author = {Luca Bertinetto and Jo\u00e3o F. Henriques and Jack Valmadre and Philip H. S. Torr and A. Vedaldi},\n booktitle = {Neural Information Processing Systems},\n pages = {523-531},\n title = {Learning feed-forward one-shot learners},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde",
            "@type": "ScholarlyArticle",
            "paperId": "ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde",
            "corpusId": 485828,
            "url": "https://www.semanticscholar.org/paper/ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde",
            "title": "Delving Deeper into Convolutional Networks for Learning Video Representations",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/BallasYPC15",
                "MAG": "2952433999",
                "ArXiv": "1511.06432",
                "CorpusId": 485828
            },
            "abstract": "We propose an approach to learn spatio-temporal features in videos from intermediate visual representations we call \"percepts\" using Gated-Recurrent-Unit Recurrent Networks (GRUs).Our method relies on percepts that are extracted from all level of a deep convolutional network trained on the large ImageNet dataset. While high-level percepts contain highly discriminative information, they tend to have a low-spatial resolution. Low-level percepts, on the other hand, preserve a higher spatial resolution from which we can model finer motion patterns. Using low-level percepts can leads to high-dimensionality video representations. To mitigate this effect and control the model number of parameters, we introduce a variant of the GRU model that leverages the convolution operations to enforce sparse connectivity of the model units and share parameters across the input spatial locations. \nWe empirically validate our approach on both Human Action Recognition and Video Captioning tasks. In particular, we achieve results equivalent to state-of-art on the YouTube2Text dataset using a simpler text-decoder model and without extra 3D CNN features.",
            "referenceCount": 43,
            "citationCount": 588,
            "influentialCitationCount": 98,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-11-19",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1511.06432"
            },
            "citationStyles": {
                "bibtex": "@Article{Ballas2015DelvingDI,\n author = {Nicolas Ballas and L. Yao and C. Pal and Aaron C. Courville},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Delving Deeper into Convolutional Networks for Learning Video Representations},\n volume = {abs/1511.06432},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:76473802cd427a8efcc9958ef86f897eccf3af58",
            "@type": "ScholarlyArticle",
            "paperId": "76473802cd427a8efcc9958ef86f897eccf3af58",
            "corpusId": 37364431,
            "url": "https://www.semanticscholar.org/paper/76473802cd427a8efcc9958ef86f897eccf3af58",
            "title": "Introduction to Machine Learning",
            "venue": "Advanced Topics in Artificial Intelligence",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1992,
            "externalIds": {
                "MAG": "2753433505",
                "DBLP": "conf/ac/Kubat92",
                "DOI": "10.1007/3-540-55681-8_33",
                "CorpusId": 37364431,
                "PubMed": "37142356"
            },
            "abstract": null,
            "referenceCount": 160,
            "citationCount": 3046,
            "influentialCitationCount": 231,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.intechopen.com/citation-pdf-url/10703",
                "status": "CLOSED"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Editorial"
            ],
            "publicationDate": "1992-07-01",
            "journal": {
                "name": "American journal of orthodontics and dentofacial orthopedics : official publication of the American Association of Orthodontists, its constituent societies, and the American Board of Orthodontics",
                "volume": "163 5"
            },
            "citationStyles": {
                "bibtex": "@Article{Alpaydin1992IntroductionTM,\n author = {Ethem Alpaydin},\n booktitle = {Advanced Topics in Artificial Intelligence},\n journal = {American journal of orthodontics and dentofacial orthopedics : official publication of the American Association of Orthodontists, its constituent societies, and the American Board of Orthodontics},\n pages = {\n          732-734\n        },\n title = {Introduction to Machine Learning},\n volume = {163 5},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cf8ed2793bc6aec88da5306fe2de560dc0be9b15",
            "@type": "ScholarlyArticle",
            "paperId": "cf8ed2793bc6aec88da5306fe2de560dc0be9b15",
            "corpusId": 12529428,
            "url": "https://www.semanticscholar.org/paper/cf8ed2793bc6aec88da5306fe2de560dc0be9b15",
            "title": "Delving into adversarial attacks on deep policies",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/iclr/KosS17",
                "MAG": "2952471392",
                "ArXiv": "1705.06452",
                "CorpusId": 12529428
            },
            "abstract": "Adversarial examples have been shown to exist for a variety of deep learning architectures. Deep reinforcement learning has shown promising results on training agent policies directly on raw inputs such as image pixels. In this paper we present a novel study into adversarial attacks on deep reinforcement learning polices. We compare the effectiveness of the attacks using adversarial examples vs. random noise. We present a novel method for reducing the number of times adversarial examples need to be injected for a successful attack, based on the value function. We further explore how re-training on random noise and FGSM perturbations affects the resilience against adversarial examples.",
            "referenceCount": 4,
            "citationCount": 188,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-02-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1705.06452"
            },
            "citationStyles": {
                "bibtex": "@Article{Kos2017DelvingIA,\n author = {Jernej Kos and D. Song},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Delving into adversarial attacks on deep policies},\n volume = {abs/1705.06452},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:505808c55b2d96ad72f4b7bca04572655742b87d",
            "@type": "ScholarlyArticle",
            "paperId": "505808c55b2d96ad72f4b7bca04572655742b87d",
            "corpusId": 876231,
            "url": "https://www.semanticscholar.org/paper/505808c55b2d96ad72f4b7bca04572655742b87d",
            "title": "Sim-to-Real Robot Learning from Pixels with Progressive Nets",
            "venue": "Conference on Robot Learning",
            "publicationVenue": {
                "id": "urn:research:fbfbf10a-faa4-4d2a-85be-3ac660454ce3",
                "name": "Conference on Robot Learning",
                "alternate_names": [
                    "CoRL",
                    "Conf Robot Learn"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1610.04286",
                "MAG": "2534269850",
                "DBLP": "journals/corr/RusuVRHPH16",
                "CorpusId": 876231
            },
            "abstract": "Applying end-to-end learning to solve complex, interactive, pixel-driven control tasks on a robot is an unsolved problem. Deep Reinforcement Learning algorithms are too slow to achieve performance on a real robot, but their potential has been demonstrated in simulated environments. We propose using progressive networks to bridge the reality gap and transfer learned policies from simulation to the real world. The progressive net approach is a general framework that enables reuse of everything from low-level visual features to high-level policies for transfer to new tasks, enabling a compositional, yet simple, approach to building complex skills. We present an early demonstration of this approach with a number of experiments in the domain of robot manipulation that focus on bridging the reality gap. Unlike other proposed approaches, our real-world experiments demonstrate successful task learning from raw visual input on a fully actuated robot manipulator. Moreover, rather than relying on model-based trajectory optimisation, the task learning is accomplished using only deep reinforcement learning and sparse rewards.",
            "referenceCount": 26,
            "citationCount": 478,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-10-13",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1610.04286"
            },
            "citationStyles": {
                "bibtex": "@Article{Rusu2016SimtoRealRL,\n author = {Andrei A. Rusu and Matej Vecer\u00edk and Thomas Roth\u00f6rl and N. Heess and Razvan Pascanu and R. Hadsell},\n booktitle = {Conference on Robot Learning},\n journal = {ArXiv},\n title = {Sim-to-Real Robot Learning from Pixels with Progressive Nets},\n volume = {abs/1610.04286},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f5ce3abf942cdd685fb0f290f3e741f7b4749f0a",
            "@type": "ScholarlyArticle",
            "paperId": "f5ce3abf942cdd685fb0f290f3e741f7b4749f0a",
            "corpusId": 7480530,
            "url": "https://www.semanticscholar.org/paper/f5ce3abf942cdd685fb0f290f3e741f7b4749f0a",
            "title": "Deep Image: Scaling up Image Recognition",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/WuYSDS15",
                "MAG": "1563686443",
                "ArXiv": "1501.02876",
                "CorpusId": 7480530
            },
            "abstract": "We present a state-of-the-art image recognition system, Deep Image, developed using end-to-end deep learning. The key components are a custom-built supercomputer dedicated to deep learning, a highly optimized parallel algorithm using new strategies for data partitioning and communication, larger deep neural network models, novel data augmentation approaches, and usage of multi-scale high-resolution images. Our method achieves excellent results on multiple challenging computer vision benchmarks.",
            "referenceCount": 54,
            "citationCount": 351,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-01-12",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1501.02876"
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2015DeepIS,\n author = {Ren Wu and Shengen Yan and Yi Shan and Qingqing Dang and Gang Sun},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Image: Scaling up Image Recognition},\n volume = {abs/1501.02876},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:29092f0deaac3898e43b3f094bf15d82b6a99afd",
            "@type": "ScholarlyArticle",
            "paperId": "29092f0deaac3898e43b3f094bf15d82b6a99afd",
            "corpusId": 12122362,
            "url": "https://www.semanticscholar.org/paper/29092f0deaac3898e43b3f094bf15d82b6a99afd",
            "title": "Learning to Remember Rare Events",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1703.03129",
                "DBLP": "journals/corr/KaiserNRB17",
                "MAG": "2583010282",
                "CorpusId": 12122362
            },
            "abstract": "Despite recent advances, memory-augmented deep neural networks are still limited when it comes to life-long and one-shot learning, especially in remembering rare events. We present a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training. \nOur memory module can be easily added to any part of a supervised neural network. To show its versatility we add it to a number of networks, from simple convolutional ones tested on image classification to deep sequence-to-sequence and recurrent-convolutional models. In all cases, the enhanced network gains the ability to remember and do life-long one-shot learning. Our module remembers training examples shown many thousands of steps in the past and it can successfully generalize from them. We set new state-of-the-art for one-shot learning on the Omniglot dataset and demonstrate, for the first time, life-long one-shot learning in recurrent neural networks on a large-scale machine translation task.",
            "referenceCount": 35,
            "citationCount": 332,
            "influentialCitationCount": 45,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-09",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.03129"
            },
            "citationStyles": {
                "bibtex": "@Article{Kaiser2017LearningTR,\n author = {Lukasz Kaiser and Ofir Nachum and Aurko Roy and Samy Bengio},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Learning to Remember Rare Events},\n volume = {abs/1703.03129},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a2017ec2c60d542af5e9993176ba68f89529dbce",
            "@type": "ScholarlyArticle",
            "paperId": "a2017ec2c60d542af5e9993176ba68f89529dbce",
            "corpusId": 13852540,
            "url": "https://www.semanticscholar.org/paper/a2017ec2c60d542af5e9993176ba68f89529dbce",
            "title": "Image Denoising and Inpainting with Deep Neural Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "conf/nips/XieXC12",
                "MAG": "2146337213",
                "CorpusId": 13852540
            },
            "abstract": "We present a novel approach to low-level vision problems that combines sparse coding and deep networks pre-trained with denoising auto-encoder (DA). We propose an alternative training scheme that successfully adapts DA, originally designed for unsupervised feature learning, to the tasks of image denoising and blind inpainting. Our method's performance in the image denoising task is comparable to that of KSVD which is a widely used sparse coding technique. More importantly, in blind image inpainting task, the proposed method provides solutions to some complex problems that have not been tackled before. Specifically, we can automatically remove complex patterns like superimposed text from an image, rather than simple patterns like pixels missing at random. Moreover, the proposed method does not need the information regarding the region that requires inpainting to be given a priori. Experimental results demonstrate the effectiveness of the proposed method in the tasks of image denoising and blind inpainting. We also show that our new training scheme for DA is more effective and can improve the performance of unsupervised feature learning.",
            "referenceCount": 23,
            "citationCount": 1361,
            "influentialCitationCount": 44,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-12-03",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Xie2012ImageDA,\n author = {Junyuan Xie and Linli Xu and Enhong Chen},\n booktitle = {Neural Information Processing Systems},\n pages = {350-358},\n title = {Image Denoising and Inpainting with Deep Neural Networks},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bb1d6215f0cfd84b5efc7173247b016ade4c976e",
            "@type": "ScholarlyArticle",
            "paperId": "bb1d6215f0cfd84b5efc7173247b016ade4c976e",
            "corpusId": 10921035,
            "url": "https://www.semanticscholar.org/paper/bb1d6215f0cfd84b5efc7173247b016ade4c976e",
            "title": "Workshop on Unsupervised and Transfer Learning Autoencoders, Unsupervised Learning, and Deep Architectures",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": null,
            "externalIds": {
                "CorpusId": 10921035
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 1315,
            "influentialCitationCount": 66,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Misc{None,\n title = {Workshop on Unsupervised and Transfer Learning Autoencoders, Unsupervised Learning, and Deep Architectures}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8e9df3ce0862dadce778529ea7e6f8f9e975fdb3",
            "@type": "ScholarlyArticle",
            "paperId": "8e9df3ce0862dadce778529ea7e6f8f9e975fdb3",
            "corpusId": 3912890,
            "url": "https://www.semanticscholar.org/paper/8e9df3ce0862dadce778529ea7e6f8f9e975fdb3",
            "title": "Problem\u2010based learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2103895361",
                "DOI": "10.1002/TL.465",
                "CorpusId": 3912890
            },
            "abstract": "In problem-based learning, students working in collaborative groups learn by resolving complex, realistic problems under the guidance of faculty. In this chapter, we examine the evidence for effectiveness of the method to achieve its goals of fostering deep understandings of content and discuss the potential for developing process skills: research, negotiation and teamwork, writing, and verbal communication.",
            "referenceCount": 43,
            "citationCount": 2004,
            "influentialCitationCount": 128,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2011-12-01",
            "journal": {
                "name": "New Directions for Teaching and Learning",
                "volume": "2011"
            },
            "citationStyles": {
                "bibtex": "@Article{Allen2011ProblembasedL,\n author = {D. Allen and R. Donham and S. Bernhardt},\n journal = {New Directions for Teaching and Learning},\n pages = {21-29},\n title = {Problem\u2010based learning},\n volume = {2011},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:905c3604a774337cb5f7267f7a40f87dfefb8cd7",
            "@type": "ScholarlyArticle",
            "paperId": "905c3604a774337cb5f7267f7a40f87dfefb8cd7",
            "corpusId": 143719481,
            "url": "https://www.semanticscholar.org/paper/905c3604a774337cb5f7267f7a40f87dfefb8cd7",
            "title": "ON QUALITATIVE DIFFERENCES IN LEARNING: I\u2014OUTCOME AND PROCESS*",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1976,
            "externalIds": {
                "MAG": "1975912968",
                "DOI": "10.1111/J.2044-8279.1976.TB02980.X",
                "CorpusId": 143719481
            },
            "abstract": "Summary. This paper describes an attempt to identify different levels of processing of information among groups of Swedish university students who were asked to read substantial passages of prose. Students were asked questions about the meaning of the passages and also about how they set about reading the passages. This approach allows processes and strategies of learning to be examined, as well as the outcomes in terms of what is understood and remembered. The starting point of this research was that learning has to be described in terms of its content. From this point differences in what is learned, rather than differences in how much is learned, are described. It was found that in each study a number of categories (levels of outcome) containing basically different conceptions of the content of the learning task could be identified. The corresponding differences in level of processing are described in terms of whether the learner is engaged in surface-level or deep-level processing.",
            "referenceCount": 2,
            "citationCount": 4416,
            "influentialCitationCount": 166,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1976-02-01",
            "journal": {
                "name": "British Journal of Educational Psychology",
                "volume": "46"
            },
            "citationStyles": {
                "bibtex": "@Article{Marton1976ONQD,\n author = {F. Marton and R. S\u00e4lj\u00f6},\n journal = {British Journal of Educational Psychology},\n pages = {4-11},\n title = {ON QUALITATIVE DIFFERENCES IN LEARNING: I\u2014OUTCOME AND PROCESS*},\n volume = {46},\n year = {1976}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ab692936c78931926ad5126b97991667cea4dee7",
            "@type": "ScholarlyArticle",
            "paperId": "ab692936c78931926ad5126b97991667cea4dee7",
            "corpusId": 9834980,
            "url": "https://www.semanticscholar.org/paper/ab692936c78931926ad5126b97991667cea4dee7",
            "title": "Learning strategies: a synthesis and conceptual model",
            "venue": "npj Science of Learning",
            "publicationVenue": {
                "id": "urn:research:765b2860-3056-40da-b032-f5fe34d375c1",
                "name": "npj Science of Learning",
                "alternate_names": [
                    "npj Sci Learn"
                ],
                "issn": "2056-7936",
                "url": "http://www.nature.com/npjscilearn/"
            },
            "year": 2016,
            "externalIds": {
                "PubMedCentral": "6380372",
                "MAG": "2594485304",
                "DOI": "10.1038/npjscilearn.2016.13",
                "CorpusId": 9834980,
                "PubMed": "30792898"
            },
            "abstract": null,
            "referenceCount": 107,
            "citationCount": 310,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/npjscilearn201613.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2016-08-10",
            "journal": {
                "name": "NPJ Science of Learning",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Hattie2016LearningSA,\n author = {J. Hattie and Gregory M. Donoghue},\n booktitle = {npj Science of Learning},\n journal = {NPJ Science of Learning},\n title = {Learning strategies: a synthesis and conceptual model},\n volume = {1},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:28d2503b0f86dd3947bf745efdd609dee7975cd8",
            "@type": "ScholarlyArticle",
            "paperId": "28d2503b0f86dd3947bf745efdd609dee7975cd8",
            "corpusId": 1104773,
            "url": "https://www.semanticscholar.org/paper/28d2503b0f86dd3947bf745efdd609dee7975cd8",
            "title": "TensorLy: Tensor Learning in Python",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/KossaifiPP16",
                "MAG": "2952198983",
                "ArXiv": "1610.09555",
                "CorpusId": 1104773
            },
            "abstract": "Tensors are higher-order extensions of matrices. While matrix methods form the cornerstone of traditional machine learning and data analysis, tensor methods have been gaining increasing traction. However, software support for tensor operations is not on the same footing. In order to bridge this gap, we have developed TensorLy, a Python library that provides a high-level API for tensor methods and deep tensorized neural networks. TensorLy aims to follow the same standards adopted by the main projects of the Python scientific community, and to seamlessly integrate with them. Its BSD license makes it suitable for both academic and commercial applications. TensorLy's backend system allows users to perform computations with several libraries such as NumPy or PyTorch to name but a few. They can be scaled on multiple CPU or GPU machines. In addition, using the deep-learning frameworks as backend allows to easily design and train deep tensorized neural networks. TensorLy is available at https://github.com/tensorly/tensorly",
            "referenceCount": 45,
            "citationCount": 282,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-10-29",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1610.09555"
            },
            "citationStyles": {
                "bibtex": "@Article{Kossaifi2016TensorLyTL,\n author = {Jean Kossaifi and Yannis Panagakis and M. Pantic},\n booktitle = {Journal of machine learning research},\n journal = {ArXiv},\n title = {TensorLy: Tensor Learning in Python},\n volume = {abs/1610.09555},\n year = {2016}\n}\n"
            }
        }
    }
]