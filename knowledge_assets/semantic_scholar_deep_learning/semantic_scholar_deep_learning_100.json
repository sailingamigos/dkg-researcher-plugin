[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:42d3ae61ca296558cba61446bd95b8a6e5b1082d",
            "@type": "ScholarlyArticle",
            "paperId": "42d3ae61ca296558cba61446bd95b8a6e5b1082d",
            "corpusId": 3204652,
            "url": "https://www.semanticscholar.org/paper/42d3ae61ca296558cba61446bd95b8a6e5b1082d",
            "title": "Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning",
            "venue": "Nature Biotechnology",
            "publicationVenue": {
                "id": "urn:research:458166b3-de17-4bf3-bbbb-e53782de2f0f",
                "name": "Nature Biotechnology",
                "alternate_names": [
                    "Nat Biotechnol"
                ],
                "issn": "1087-0156",
                "url": "http://www.nature.com/nbt/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1019830208",
                "DOI": "10.1038/nbt.3300",
                "CorpusId": 3204652,
                "PubMed": "26213851"
            },
            "abstract": null,
            "referenceCount": 51,
            "citationCount": 2148,
            "influentialCitationCount": 190,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/nbt.3300.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-07-27",
            "journal": {
                "name": "Nature Biotechnology",
                "volume": "33"
            },
            "citationStyles": {
                "bibtex": "@Article{Alipanahi2015PredictingTS,\n author = {B. Alipanahi and Andrew Delong and M. Weirauch and B. Frey},\n booktitle = {Nature Biotechnology},\n journal = {Nature Biotechnology},\n pages = {831-838},\n title = {Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning},\n volume = {33},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f58ea68448a584b8c8540c86bb9965d746b767a9",
            "@type": "ScholarlyArticle",
            "paperId": "f58ea68448a584b8c8540c86bb9965d746b767a9",
            "corpusId": 53304118,
            "url": "https://www.semanticscholar.org/paper/f58ea68448a584b8c8540c86bb9965d746b767a9",
            "title": "Deep Learning: Methods and Applications",
            "venue": "Foundations and Trends\u00ae in Signal Processing",
            "publicationVenue": {
                "id": "urn:research:a30697a9-2a04-4a33-ae2f-03ea5fbb71f8",
                "name": "Foundations and Trends\u00ae in Signal Processing",
                "alternate_names": [
                    "Found Trends Signal Process",
                    "Found Trends\u00ae Signal Process",
                    "Foundations and Trends in Signal Processing"
                ],
                "issn": "1932-8346",
                "url": "https://www.nowpublishers.com/sig"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2150341604",
                "DBLP": "journals/ftsig/DengY14",
                "DOI": "10.1561/2000000039",
                "CorpusId": 53304118
            },
            "abstract": "This monograph provides an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria in mind: (1) expertise or knowledge of the authors; (2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and (3) the application areas that have the potential to be impacted significantly by deep learning and that have been experiencing research growth, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.",
            "referenceCount": 454,
            "citationCount": 3183,
            "influentialCitationCount": 143,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.ped-perinatology.ru/jour/article/download/586/570",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2014-06-12",
            "journal": {
                "name": "Found. Trends Signal Process.",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Deng2014DeepLM,\n author = {L. Deng and Dong Yu},\n booktitle = {Foundations and Trends\u00ae in Signal Processing},\n journal = {Found. Trends Signal Process.},\n pages = {197-387},\n title = {Deep Learning: Methods and Applications},\n volume = {7},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7340f090f8a0df5b109682e9f6d57e4b8ca1a2f7",
            "@type": "ScholarlyArticle",
            "paperId": "7340f090f8a0df5b109682e9f6d57e4b8ca1a2f7",
            "corpusId": 556999,
            "url": "https://www.semanticscholar.org/paper/7340f090f8a0df5b109682e9f6d57e4b8ca1a2f7",
            "title": "Learning Transferable Features with Deep Adaptation Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1502.02791",
                "DBLP": "journals/corr/Long015",
                "MAG": "2951670162",
                "CorpusId": 556999
            },
            "abstract": "Recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation. However, as deep features eventually transition from general to specific along the network, the feature transferability drops significantly in higher layers with increasing domain discrepancy. Hence, it is important to formally reduce the dataset bias and enhance the transferability in task-specific layers. In this paper, we propose a new Deep Adaptation Network (DAN) architecture, which generalizes deep convolutional neural network to the domain adaptation scenario. In DAN, hidden representations of all task-specific layers are embedded in a reproducing kernel Hilbert space where the mean embeddings of different domain distributions can be explicitly matched. The domain discrepancy is further reduced using an optimal multikernel selection method for mean embedding matching. DAN can learn transferable features with statistical guarantees, and can scale linearly by unbiased estimate of kernel embedding. Extensive empirical evidence shows that the proposed architecture yields state-of-the-art image classification error rates on standard domain adaptation benchmarks.",
            "referenceCount": 36,
            "citationCount": 4174,
            "influentialCitationCount": 747,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-02-09",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1502.02791"
            },
            "citationStyles": {
                "bibtex": "@Article{Long2015LearningTF,\n author = {Mingsheng Long and Yue Cao and Jianmin Wang and Michael I. Jordan},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Learning Transferable Features with Deep Adaptation Networks},\n volume = {abs/1502.02791},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:75ea299834d6949e89e91d006677343ddab44e49",
            "@type": "ScholarlyArticle",
            "paperId": "75ea299834d6949e89e91d006677343ddab44e49",
            "corpusId": 215869380,
            "url": "https://www.semanticscholar.org/paper/75ea299834d6949e89e91d006677343ddab44e49",
            "title": "Deep Learning-based Detection for COVID-19 from Chest CT using Weak Label",
            "venue": "medRxiv",
            "publicationVenue": {
                "id": "urn:research:d5e5b5e7-54b1-4f53-82fc-4853f3e71c58",
                "name": "medRxiv",
                "alternate_names": null,
                "issn": null,
                "url": "https://www.medrxiv.org/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3011414569",
                "DOI": "10.1101/2020.03.12.20027185",
                "CorpusId": 215869380
            },
            "abstract": "Accurate and rapid diagnosis of COVID-19 suspected cases plays a crucial role in timely quarantine and medical treatment. Developing a deep learning-based model for automatic COVID-19 detection on chest CT is helpful to counter the outbreak of SARS-CoV-2. A weakly-supervised deep learning-based software system was developed using 3D CT volumes to detect COVID-19. For each patient, the lung region was segmented using a pre-trained UNet; then the segmented 3D lung region was fed into a 3D deep neural network to predict the probability of COVID-19 infectious. 499 CT volumes collected from Dec. 13, 2019, to Jan. 23, 2020, were used for training and 131 CT volumes collected from Jan 24, 2020, to Feb 6, 2020, were used for testing. The deep learning algorithm obtained 0.959 ROC AUC and 0.976 PR AUC. There was an operating point with 0.907 sensitivity and 0.911 specificity in the ROC curve. When using a probability threshold of 0.5 to classify COVID-positive and COVID-negative, the algorithm obtained an accuracy of 0.901, a positive predictive value of 0.840 and a very high negative predictive value of 0.982. The algorithm took only 1.93 seconds to process a single patient's CT volume using a dedicated GPU. Our weakly-supervised deep learning model can accurately predict the COVID-19 infectious probability in chest CT volumes without the need for annotating the lesions for training. The easily-trained and high-performance deep learning algorithm provides a fast way to identify COVID-19 patients, which is beneficial to control the outbreak of SARS-CoV-2. The developed deep learning software is available at \\url{https://github.com/sydney0zq/covid-19-detection}.",
            "referenceCount": 24,
            "citationCount": 564,
            "influentialCitationCount": 34,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.medrxiv.org/content/medrxiv/early/2020/03/26/2020.03.12.20027185.full.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2020-03-17",
            "journal": {
                "name": "medRxiv",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Zheng2020DeepLD,\n author = {C. Zheng and Xianbo Deng and Qing Fu and Qiang-feng Zhou and Jiapei Feng and Hui Ma and Wenyu Liu and Xinggang Wang},\n booktitle = {medRxiv},\n journal = {medRxiv},\n title = {Deep Learning-based Detection for COVID-19 from Chest CT using Weak Label},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e30d9b8ce108d982169621b88a5e3fb69fec70e1",
            "@type": "ScholarlyArticle",
            "paperId": "e30d9b8ce108d982169621b88a5e3fb69fec70e1",
            "corpusId": 2528492,
            "url": "https://www.semanticscholar.org/paper/e30d9b8ce108d982169621b88a5e3fb69fec70e1",
            "title": "Using Deep Learning for Image-Based Plant Disease Detection",
            "venue": "Frontiers in Plant Science",
            "publicationVenue": {
                "id": "urn:research:e110cc75-cd00-4b7f-968c-fd70b464a553",
                "name": "Frontiers in Plant Science",
                "alternate_names": [
                    "Front Plant Sci"
                ],
                "issn": "1664-462X",
                "url": "http://www.frontiersin.org/about/journalseries"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/MohantyHS16",
                "MAG": "2473156356",
                "ArXiv": "1604.03169",
                "PubMedCentral": "5032846",
                "DOI": "10.3389/fpls.2016.01419",
                "CorpusId": 2528492,
                "PubMed": "27713752"
            },
            "abstract": "Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.",
            "referenceCount": 39,
            "citationCount": 2163,
            "influentialCitationCount": 107,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.frontiersin.org/articles/10.3389/fpls.2016.01419/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-04-11",
            "journal": {
                "name": "Frontiers in Plant Science",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Mohanty2016UsingDL,\n author = {S. Mohanty and David P. Hughes and M. Salath\u00e9},\n booktitle = {Frontiers in Plant Science},\n journal = {Frontiers in Plant Science},\n title = {Using Deep Learning for Image-Based Plant Disease Detection},\n volume = {7},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9eebd3c7971a239cf69a0358563f397bd8a8f99c",
            "@type": "ScholarlyArticle",
            "paperId": "9eebd3c7971a239cf69a0358563f397bd8a8f99c",
            "corpusId": 220514248,
            "url": "https://www.semanticscholar.org/paper/9eebd3c7971a239cf69a0358563f397bd8a8f99c",
            "title": "Hands-On Bayesian Neural Networks\u2014A Tutorial for Deep Learning Users",
            "venue": "IEEE Computational Intelligence Magazine",
            "publicationVenue": {
                "id": "urn:research:ee372de7-efda-4907-a03f-359292ea27f6",
                "name": "IEEE Computational Intelligence Magazine",
                "alternate_names": [
                    "IEEE Comput Intell Mag"
                ],
                "issn": "1556-603X",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=10207"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3043426275",
                "DBLP": "journals/cim/JospinLBBB22",
                "ArXiv": "2007.06823",
                "DOI": "10.1109/MCI.2022.3155327",
                "CorpusId": 220514248
            },
            "abstract": "Modern deep learning methods constitute incredibly powerful tools to tackle a myriad of challenging problems. However, since deep learning methods operate as black boxes, the uncertainty associated with their predictions is often challenging to quantify. Bayesian statistics offer a formalism to understand and quantify the uncertainty associated with deep neural network predictions. This tutorial provides deep learning practitioners with an overview of the relevant literature and a complete toolset to design, implement, train, use and evaluate Bayesian neural networks, i.e., stochastic artificial neural networks trained using Bayesian methods.",
            "referenceCount": 130,
            "citationCount": 331,
            "influentialCitationCount": 28,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2007.06823",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-07-14",
            "journal": {
                "name": "IEEE Computational Intelligence Magazine",
                "volume": "17"
            },
            "citationStyles": {
                "bibtex": "@Article{Jospin2020HandsOnBN,\n author = {Laurent Valentin Jospin and Wray L. Buntine and F. Boussaid and Hamid Laga and Bennamoun},\n booktitle = {IEEE Computational Intelligence Magazine},\n journal = {IEEE Computational Intelligence Magazine},\n pages = {29-48},\n title = {Hands-On Bayesian Neural Networks\u2014A Tutorial for Deep Learning Users},\n volume = {17},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f0c5991dbb130fa6b5de011cf7a04f6ed815ef68",
            "@type": "ScholarlyArticle",
            "paperId": "f0c5991dbb130fa6b5de011cf7a04f6ed815ef68",
            "corpusId": 29162614,
            "url": "https://www.semanticscholar.org/paper/f0c5991dbb130fa6b5de011cf7a04f6ed815ef68",
            "title": "Robust Physical-World Attacks on Deep Learning Visual Classification",
            "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2798302089",
                "DBLP": "conf/cvpr/EykholtEF0RXPKS18",
                "DOI": "10.1109/CVPR.2018.00175",
                "CorpusId": 29162614
            },
            "abstract": "Recent studies show that the state-of-the-art deep neural networks (DNNs) are vulnerable to adversarial examples, resulting from small-magnitude perturbations added to the input. Given that that emerging physical systems are using DNNs in safety-critical situations, adversarial examples could mislead these systems and cause dangerous situations. Therefore, understanding adversarial examples in the physical world is an important step towards developing resilient learning algorithms. We propose a general attack algorithm, Robust Physical Perturbations (RP2), to generate robust visual adversarial perturbations under different physical conditions. Using the real-world case of road sign classification, we show that adversarial examples generated using RP2 achieve high targeted misclassification rates against standard-architecture road sign classifiers in the physical world under various environmental conditions, including viewpoints. Due to the current lack of a standardized testing method, we propose a two-stage evaluation methodology for robust physical adversarial examples consisting of lab and field tests. Using this methodology, we evaluate the efficacy of physical adversarial manipulations on real objects. With a perturbation in the form of only black and white stickers, we attack a real stop sign, causing targeted misclassification in 100% of the images obtained in lab settings, and in 84.8% of the captured video frames obtained on a moving vehicle (field test) for the target classifier.",
            "referenceCount": 38,
            "citationCount": 1463,
            "influentialCitationCount": 85,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Eykholt2018RobustPA,\n author = {Kevin Eykholt and I. Evtimov and Earlence Fernandes and Bo Li and Amir Rahmati and Chaowei Xiao and Atul Prakash and Tadayoshi Kohno and D. Song},\n booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n pages = {1625-1634},\n title = {Robust Physical-World Attacks on Deep Learning Visual Classification},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2d8d74c7fd9375b17e9d6123773919b2aa512c56",
            "@type": "ScholarlyArticle",
            "paperId": "2d8d74c7fd9375b17e9d6123773919b2aa512c56",
            "corpusId": 56177573,
            "url": "https://www.semanticscholar.org/paper/2d8d74c7fd9375b17e9d6123773919b2aa512c56",
            "title": "U-Net: deep learning for cell counting, detection, and morphometry",
            "venue": "Nature Methods",
            "publicationVenue": {
                "id": "urn:research:099483df-e8f2-4bee-805d-8a69f07b6cbf",
                "name": "Nature Methods",
                "alternate_names": [
                    "Nat Method"
                ],
                "issn": "1548-7091",
                "url": "http://www.nature.com/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2900936384",
                "DOI": "10.1038/s41592-018-0261-2",
                "CorpusId": 56177573,
                "PubMed": "30559429"
            },
            "abstract": null,
            "referenceCount": 14,
            "citationCount": 1186,
            "influentialCitationCount": 64,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-12-17",
            "journal": {
                "name": "Nature Methods",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Falk2018UNetDL,\n author = {Thorsten Falk and Dominic Mai and R. Bensch and \u00d6zg\u00fcn \u00c7i\u00e7ek and A. Abdulkadir and Yassine Marrakchi and Anton B\u00f6hm and Jan Deubner and Zoe J\u00e4ckel and Katharina Seiwald and A. Dovzhenko and O. Tietz and C. Dal Bosco and Sean Walsh and Deniz Saltukoglu and Tuan Leng Tay and M. Prinz and K. Palme and M. Simons and I. Diester and T. Brox and O. Ronneberger},\n booktitle = {Nature Methods},\n journal = {Nature Methods},\n pages = {67 - 70},\n title = {U-Net: deep learning for cell counting, detection, and morphometry},\n volume = {16},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7fa30c8af436b7df513ef41e2cccd8a2404f37f8",
            "@type": "ScholarlyArticle",
            "paperId": "7fa30c8af436b7df513ef41e2cccd8a2404f37f8",
            "corpusId": 58598011,
            "url": "https://www.semanticscholar.org/paper/7fa30c8af436b7df513ef41e2cccd8a2404f37f8",
            "title": "Predicting Splicing from Primary Sequence with Deep Learning",
            "venue": "Cell",
            "publicationVenue": {
                "id": "urn:research:e4782337-db2d-4ab2-8eda-a71d1c60709b",
                "name": "Cell",
                "alternate_names": [
                    "La Cellule"
                ],
                "issn": "0092-8674",
                "url": "https://www.cell.com/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2909194804",
                "DOI": "10.1016/j.cell.2018.12.015",
                "CorpusId": 58598011,
                "PubMed": "30661751"
            },
            "abstract": null,
            "referenceCount": 54,
            "citationCount": 1110,
            "influentialCitationCount": 91,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cell.com/article/S0092867418316295/pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-01-24",
            "journal": {
                "name": "Cell",
                "volume": "176"
            },
            "citationStyles": {
                "bibtex": "@Article{Jaganathan2019PredictingSF,\n author = {K. Jaganathan and Sofia Panagiotopoulou and J. McRae and S. Darbandi and David G. Knowles and Yang I. Li and J. Kosmicki and Juan Arbelaez and Wenwu Cui and Grace B. Schwartz and E. Chow and E. Kanterakis and Hong Gao and Amirali Kia and S. Batzoglou and Stephan J Sanders and K. Farh},\n booktitle = {Cell},\n journal = {Cell},\n pages = {535-548.e24},\n title = {Predicting Splicing from Primary Sequence with Deep Learning},\n volume = {176},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8df72c48a7ce4418c683c4dd9bb300558ac71d47",
            "@type": "ScholarlyArticle",
            "paperId": "8df72c48a7ce4418c683c4dd9bb300558ac71d47",
            "corpusId": 2740197,
            "url": "https://www.semanticscholar.org/paper/8df72c48a7ce4418c683c4dd9bb300558ac71d47",
            "title": "Deep learning for healthcare: review, opportunities and challenges",
            "venue": "Briefings Bioinform.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2610332124",
                "DBLP": "journals/bib/MiottoWWJD18",
                "DOI": "10.1093/bib/bbx044",
                "CorpusId": 2740197,
                "PubMed": "28481991"
            },
            "abstract": "Gaining knowledge and actionable insights from complex, high-dimensional and heterogeneous biomedical data remains a key challenge in transforming health care. Various types of data have been emerging in modern biomedical research, including electronic health records, imaging, -omics, sensor data and text, which are complex, heterogeneous, poorly annotated and generally unstructured. Traditional data mining and statistical learning approaches typically need to first perform feature engineering to obtain effective and more robust features from those data, and then build prediction or clustering models on top of them. There are lots of challenges on both steps in a scenario of complicated data and lacking of sufficient domain knowledge. The latest advances in deep learning technologies provide new effective paradigms to obtain end-to-end learning models from complex data. In this article, we review the recent literature on applying deep learning technologies to advance the health care domain. Based on the analyzed work, we suggest that deep learning approaches could be the vehicle for translating big biomedical data into improved human health. However, we also note limitations and needs for improved methods development and applications, especially in terms of ease-of-understanding for domain experts and citizen scientists. We discuss such challenges and suggest developing holistic and meaningful interpretable architectures to bridge deep learning models and human interpretability.",
            "referenceCount": 120,
            "citationCount": 1562,
            "influentialCitationCount": 29,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc6455466?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-11-27",
            "journal": {
                "name": "Briefings in bioinformatics",
                "volume": "19 6"
            },
            "citationStyles": {
                "bibtex": "@Article{Miotto2018DeepLF,\n author = {Riccardo Miotto and Fei Wang and Shuang Wang and Xiaoqian Jiang and J. Dudley},\n booktitle = {Briefings Bioinform.},\n journal = {Briefings in bioinformatics},\n pages = {\n          1236-1246\n        },\n title = {Deep learning for healthcare: review, opportunities and challenges},\n volume = {19 6},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b2d952fbd6951cbed68ea13003a045300970731a",
            "@type": "ScholarlyArticle",
            "paperId": "b2d952fbd6951cbed68ea13003a045300970731a",
            "corpusId": 51974607,
            "url": "https://www.semanticscholar.org/paper/b2d952fbd6951cbed68ea13003a045300970731a",
            "title": "Clinically applicable deep learning for diagnosis and referral in retinal disease",
            "venue": "Nature Network Boston",
            "publicationVenue": {
                "id": "urn:research:9e995b6d-f30b-4ab4-a13b-3dc2cc992f47",
                "name": "Nature Network Boston",
                "alternate_names": [
                    "Nat Netw Boston",
                    "Nat Med",
                    "Nature Medicine"
                ],
                "issn": "1744-7933",
                "url": "https://www.nature.com/nature/articles?code=archive_news"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2886281300",
                "DOI": "10.1038/s41591-018-0107-6",
                "CorpusId": 51974607,
                "PubMed": "30104768"
            },
            "abstract": null,
            "referenceCount": 45,
            "citationCount": 1651,
            "influentialCitationCount": 29,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://discovery.ucl.ac.uk/10056194/1/Diagnosis%20and%20referral%20in%20retinal%20disease%20-%20updated.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-08-13",
            "journal": {
                "name": "Nature Medicine",
                "volume": "24"
            },
            "citationStyles": {
                "bibtex": "@Article{Fauw2018ClinicallyAD,\n author = {Jeffrey De Fauw and J. Ledsam and Bernardino Romera-Paredes and Stanislav Nikolov and Nenad Toma\u0161ev and Sam Blackwell and Harry Askham and Xavier Glorot and Brendan O'Donoghue and D. Visentin and George Van Den Driessche and Balaji Lakshminarayanan and Clemens Meyer and Faith Mackinder and Simon Bouton and K. Ayoub and Reena Chopra and Dominic King and A. Karthikesalingam and C\u00edan O. Hughes and R. Raine and J. Hughes and D. Sim and C. Egan and A. Tufail and Hugh Montgomery and D. Hassabis and G. Rees and T. Back and P. Khaw and Mustafa Suleyman and Julien Cornebise and P. Keane and O. Ronneberger},\n booktitle = {Nature Network Boston},\n journal = {Nature Medicine},\n pages = {1342 - 1350},\n title = {Clinically applicable deep learning for diagnosis and referral in retinal disease},\n volume = {24},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2b91a2cbcd9cce902cbc8da78fec5f18f4bffc98",
            "@type": "ScholarlyArticle",
            "paperId": "2b91a2cbcd9cce902cbc8da78fec5f18f4bffc98",
            "corpusId": 10694510,
            "url": "https://www.semanticscholar.org/paper/2b91a2cbcd9cce902cbc8da78fec5f18f4bffc98",
            "title": "Deep learning for sentiment analysis: A survey",
            "venue": "WIREs Data Mining Knowl. Discov.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2784772534",
                "DBLP": "journals/corr/abs-1801-07883",
                "ArXiv": "1801.07883",
                "DOI": "10.1002/widm.1253",
                "CorpusId": 10694510
            },
            "abstract": "Deep learning has emerged as a powerful machine learning technique that learns multiple layers of representations or features of the data and produces state\u2010of\u2010the\u2010art prediction results. Along with the success of deep learning in many application domains, deep learning is also used in sentiment analysis in recent years. This paper gives an overview of deep learning and then provides a comprehensive survey of its current applications in sentiment analysis.",
            "referenceCount": 149,
            "citationCount": 1268,
            "influentialCitationCount": 48,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/widm.1253",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-01-24",
            "journal": {
                "name": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018DeepLF,\n author = {Lei Zhang and Shuai Wang and B. Liu},\n booktitle = {WIREs Data Mining Knowl. Discov.},\n journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},\n title = {Deep learning for sentiment analysis: A survey},\n volume = {8},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:94deb62af3054c49e7d80bd7eb3ed5efe990fc0b",
            "@type": "ScholarlyArticle",
            "paperId": "94deb62af3054c49e7d80bd7eb3ed5efe990fc0b",
            "corpusId": 7079419,
            "url": "https://www.semanticscholar.org/paper/94deb62af3054c49e7d80bd7eb3ed5efe990fc0b",
            "title": "Traffic Flow Prediction With Big Data: A Deep Learning Approach",
            "venue": "IEEE transactions on intelligent transportation systems (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2036785686",
                "DBLP": "journals/tits/LvDKLW15",
                "DOI": "10.1109/TITS.2014.2345663",
                "CorpusId": 7079419
            },
            "abstract": "Accurate and timely traffic flow information is important for the successful deployment of intelligent transportation systems. Over the last few years, traffic data have been exploding, and we have truly entered the era of big data for transportation. Existing traffic flow prediction methods mainly use shallow traffic prediction models and are still unsatisfying for many real-world applications. This situation inspires us to rethink the traffic flow prediction problem based on deep architecture models with big traffic data. In this paper, a novel deep-learning-based traffic flow prediction method is proposed, which considers the spatial and temporal correlations inherently. A stacked autoencoder model is used to learn generic traffic flow features, and it is trained in a greedy layerwise fashion. To the best of our knowledge, this is the first time that a deep architecture model is applied using autoencoders as building blocks to represent traffic flow features for prediction. Moreover, experiments demonstrate that the proposed method for traffic flow prediction has superior performance.",
            "referenceCount": 63,
            "citationCount": 2416,
            "influentialCitationCount": 123,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-04-01",
            "journal": {
                "name": "IEEE Transactions on Intelligent Transportation Systems",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Lv2015TrafficFP,\n author = {Yisheng Lv and Y. Duan and Wenwen Kang and Z. Li and Feiyue Wang},\n booktitle = {IEEE transactions on intelligent transportation systems (Print)},\n journal = {IEEE Transactions on Intelligent Transportation Systems},\n pages = {865-873},\n title = {Traffic Flow Prediction With Big Data: A Deep Learning Approach},\n volume = {16},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:36aa6c01c9683783499395953c6bc856d6101feb",
            "@type": "ScholarlyArticle",
            "paperId": "36aa6c01c9683783499395953c6bc856d6101feb",
            "corpusId": 59608823,
            "url": "https://www.semanticscholar.org/paper/36aa6c01c9683783499395953c6bc856d6101feb",
            "title": "A Simple Baseline for Bayesian Uncertainty in Deep Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1902.02476",
                "DBLP": "journals/corr/abs-1902-02476",
                "MAG": "2971130081",
                "CorpusId": 59608823
            },
            "abstract": "We propose SWA-Gaussian (SWAG), a simple, scalable, and general purpose approach for uncertainty representation and calibration in deep learning. Stochastic Weight Averaging (SWA), which computes the first moment of stochastic gradient descent (SGD) iterates with a modified learning rate schedule, has recently been shown to improve generalization in deep learning. With SWAG, we fit a Gaussian using the SWA solution as the first moment and a low rank plus diagonal covariance also derived from the SGD iterates, forming an approximate posterior distribution over neural network weights; we then sample from this Gaussian distribution to perform Bayesian model averaging. We empirically find that SWAG approximates the shape of the true posterior, in accordance with results describing the stationary distribution of SGD iterates. Moreover, we demonstrate that SWAG performs well on a wide variety of tasks, including out of sample detection, calibration, and transfer learning, in comparison to many popular alternatives including MC dropout, KFAC Laplace, SGLD, and temperature scaling.",
            "referenceCount": 73,
            "citationCount": 605,
            "influentialCitationCount": 100,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-02-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Maddox2019ASB,\n author = {Wesley J. Maddox and T. Garipov and Pavel Izmailov and D. Vetrov and A. Wilson},\n booktitle = {Neural Information Processing Systems},\n pages = {13132-13143},\n title = {A Simple Baseline for Bayesian Uncertainty in Deep Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6e13e111e85d499d781386b182fd855fbb053771",
            "@type": "ScholarlyArticle",
            "paperId": "6e13e111e85d499d781386b182fd855fbb053771",
            "corpusId": 173990641,
            "url": "https://www.semanticscholar.org/paper/6e13e111e85d499d781386b182fd855fbb053771",
            "title": "Deep Learning Recommendation Model for Personalization and Recommendation Systems",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1906-00091",
                "ArXiv": "1906.00091",
                "MAG": "2947737663",
                "CorpusId": 173990641
            },
            "abstract": "With the advent of deep learning, neural network-based recommendation models have emerged as an important tool for tackling personalization and recommendation tasks. These networks differ significantly from other deep learning networks due to their need to handle categorical features and are not well studied or understood. In this paper, we develop a state-of-the-art deep learning recommendation model (DLRM) and provide its implementation in both PyTorch and Caffe2 frameworks. In addition, we design a specialized parallelization scheme utilizing model parallelism on the embedding tables to mitigate memory constraints while exploiting data parallelism to scale-out compute from the fully-connected layers. We compare DLRM against existing recommendation models and characterize its performance on the Big Basin AI platform, demonstrating its usefulness as a benchmark for future algorithmic experimentation and system co-design.",
            "referenceCount": 30,
            "citationCount": 489,
            "influentialCitationCount": 107,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-05-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1906.00091"
            },
            "citationStyles": {
                "bibtex": "@Article{Naumov2019DeepLR,\n author = {M. Naumov and Dheevatsa Mudigere and H. Shi and Jianyu Huang and Narayanan Sundaraman and Jongsoo Park and Xiaodong Wang and Udit Gupta and Carole-Jean Wu and A. Azzolini and Dmytro Dzhulgakov and Andrey Mallevich and I. Cherniavskii and Yinghai Lu and Raghuraman Krishnamoorthi and Ansha Yu and Volodymyr Kondratenko and Stephanie Pereira and Xianjie Chen and Wenlin Chen and Vijay Rao and Bill Jia and Liang Xiong and M. Smelyanskiy},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Learning Recommendation Model for Personalization and Recommendation Systems},\n volume = {abs/1906.00091},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e6c71df73d6a77f6fd88a0c70454fff46a32702d",
            "@type": "ScholarlyArticle",
            "paperId": "e6c71df73d6a77f6fd88a0c70454fff46a32702d",
            "corpusId": 220546516,
            "url": "https://www.semanticscholar.org/paper/e6c71df73d6a77f6fd88a0c70454fff46a32702d",
            "title": "Accelerating 3D deep learning with PyTorch3D",
            "venue": "SIGGRAPH Asia 2020 Courses",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3042719542",
                "ArXiv": "2007.08501",
                "DBLP": "journals/corr/abs-2007-08501",
                "DOI": "10.1145/3415263.3419160",
                "CorpusId": 220546516
            },
            "abstract": "1. Accelerating 3D Deep Learning with PyTorch3D, arXiv 2007.08501 2. Mesh R-CNN, ICCV 2019 3. SynSin: End-to-end View Synthesis from a Single Image, CVPR 2020 4. Fast Differentiable Raycasting for Neural Rendering using Sphere-based Representations, arXiv 2004.07484",
            "referenceCount": 67,
            "citationCount": 580,
            "influentialCitationCount": 59,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://authors.library.caltech.edu/records/9qbyh-hp680/files/2007.08501.pdf?download=1",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book"
            ],
            "publicationDate": "2019-11-17",
            "journal": {
                "name": "SIGGRAPH Asia 2020 Courses",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ravi2019Accelerating3D,\n author = {Nikhila Ravi and Jeremy Reizenstein and David Novotn\u00fd and Taylor Gordon and Wan-Yen Lo and Justin Johnson and Georgia Gkioxari},\n booktitle = {SIGGRAPH Asia 2020 Courses},\n journal = {SIGGRAPH Asia 2020 Courses},\n title = {Accelerating 3D deep learning with PyTorch3D},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fdde9a63877db44c1b6a7f5cff5d47f01465e793",
            "@type": "ScholarlyArticle",
            "paperId": "fdde9a63877db44c1b6a7f5cff5d47f01465e793",
            "corpusId": 195833620,
            "url": "https://www.semanticscholar.org/paper/fdde9a63877db44c1b6a7f5cff5d47f01465e793",
            "title": "Point-Voxel CNN for Efficient 3D Deep Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2996167479",
                "DBLP": "conf/nips/LiuTLH19",
                "ArXiv": "1907.03739",
                "CorpusId": 195833620
            },
            "abstract": "We present Point-Voxel CNN (PVCNN) for efficient, fast 3D deep learning. Previous work processes 3D data using either voxel-based or point-based NN models. However, both approaches are computationally inefficient. The computation cost and memory footprints of the voxel-based models grow cubically with the input resolution, making it memory-prohibitive to scale up the resolution. As for point-based networks, up to 80% of the time is wasted on structuring the irregular data which have rather poor memory locality, not on the actual feature extraction. In this paper, we propose PVCNN that represents the 3D input data in points to reduce the memory consumption, while performing the convolutions in voxels to largely reduce the irregular data access and improve the locality. Our PVCNN model is both memory and computation efficient. Evaluated on semantic and part segmentation datasets, it achieves much higher accuracy than the voxel-based baseline with 10x GPU memory reduction; it also outperforms the state-of-the-art point-based models with 7x measured speedup on average. Remarkably, narrower version of PVCNN achieves 2x speedup over PointNet (an extremely efficient model) on part and scene segmentation benchmarks with much higher accuracy. We validate the general effectiveness of our PVCNN on 3D object detection: by replacing the primitives in Frustrum PointNet with PVConv, it outperforms Frustrum PointNet++ by 2.4% mAP on average with 1.5x measured speedup and GPU memory reduction.",
            "referenceCount": 55,
            "citationCount": 454,
            "influentialCitationCount": 59,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-07-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1907.03739"
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2019PointVoxelCF,\n author = {Zhijian Liu and Haotian Tang and Yujun Lin and Song Han},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Point-Voxel CNN for Efficient 3D Deep Learning},\n volume = {abs/1907.03739},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:656bd33ebf7acd8887d3598e1513e53e8fb69d41",
            "@type": "ScholarlyArticle",
            "paperId": "656bd33ebf7acd8887d3598e1513e53e8fb69d41",
            "corpusId": 58014179,
            "url": "https://www.semanticscholar.org/paper/656bd33ebf7acd8887d3598e1513e53e8fb69d41",
            "title": "Deep learning-based electroencephalography analysis: a systematic review",
            "venue": "Journal of Neural Engineering",
            "publicationVenue": {
                "id": "urn:research:aa06d038-4db2-4d34-a660-be35ff62d392",
                "name": "Journal of Neural Engineering",
                "alternate_names": [
                    "J Neural Eng"
                ],
                "issn": "1741-2552",
                "url": "http://iopscience.iop.org/1741-2552/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2952243461",
                "ArXiv": "1901.05498",
                "DBLP": "journals/corr/abs-1901-05498",
                "DOI": "10.1088/1741-2552/ab260c",
                "CorpusId": 58014179,
                "PubMed": "31151119"
            },
            "abstract": "Context. Electroencephalography (EEG) is a complex signal and can require several years of training, as well as advanced signal processing and feature extraction methodologies to be correctly interpreted. Recently, deep learning (DL) has shown great promise in helping make sense of EEG signals due to its capacity to learn good feature representations from raw data. Whether DL truly presents advantages as compared to more traditional EEG processing approaches, however, remains an open question. Objective. In this work, we review 154 papers that apply DL to EEG, published between January 2010 and July 2018, and spanning different application domains such as epilepsy, sleep, brain\u2013computer interfacing, and cognitive and affective monitoring. We extract trends and highlight interesting approaches from this large body of literature in order to inform future research and formulate recommendations. Methods. Major databases spanning the fields of science and engineering were queried to identify relevant studies published in scientific journals, conferences, and electronic preprint repositories. Various data items were extracted for each study pertaining to (1) the data, (2) the preprocessing methodology, (3) the DL design choices, (4) the results, and (5) the reproducibility of the experiments. These items were then analyzed one by one to uncover trends. Results. Our analysis reveals that the amount of EEG data used across studies varies from less than ten minutes to thousands of hours, while the number of samples seen during training by a network varies from a few dozens to several millions, depending on how epochs are extracted. Interestingly, we saw that more than half the studies used publicly available data and that there has also been a clear shift from intra-subject to inter-subject approaches over the last few years. About of the studies used convolutional neural networks (CNNs), while used recurrent neural networks (RNNs), most often with a total of 3\u201310 layers. Moreover, almost one-half of the studies trained their models on raw or preprocessed EEG time series. Finally, the median gain in accuracy of DL approaches over traditional baselines was across all relevant studies. More importantly, however, we noticed studies often suffer from poor reproducibility: a majority of papers would be hard or impossible to reproduce given the unavailability of their data and code. Significance. To help the community progress and share work more effectively, we provide a list of recommendations for future studies and emphasize the need for more reproducible research. We also make our summary table of DL and EEG papers available and invite authors of published work to contribute to it directly. A planned follow-up to this work will be an online public benchmarking portal listing reproducible results.",
            "referenceCount": 270,
            "citationCount": 680,
            "influentialCitationCount": 49,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics",
                "Medicine",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-01-16",
            "journal": {
                "name": "Journal of Neural Engineering",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Roy2019DeepLE,\n author = {Yannick Roy and Hubert J. Banville and Isabela Albuquerque and Alexandre Gramfort and T. Falk and J. Faubert},\n booktitle = {Journal of Neural Engineering},\n journal = {Journal of Neural Engineering},\n title = {Deep learning-based electroencephalography analysis: a systematic review},\n volume = {16},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:77cec64cdf0581ff4e7b70aa595a4d6e39b70ce4",
            "@type": "ScholarlyArticle",
            "paperId": "77cec64cdf0581ff4e7b70aa595a4d6e39b70ce4",
            "corpusId": 215844202,
            "url": "https://www.semanticscholar.org/paper/77cec64cdf0581ff4e7b70aa595a4d6e39b70ce4",
            "title": "Keras: The Python Deep Learning library",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2996489182",
                "CorpusId": 215844202
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 1272,
            "influentialCitationCount": 99,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Chollet2018KerasTP,\n author = {Fran\u00e7ois Chollet},\n title = {Keras: The Python Deep Learning library},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4cd03cd34e7e94d1b1ee293d5dead8efc24c1a6d",
            "@type": "ScholarlyArticle",
            "paperId": "4cd03cd34e7e94d1b1ee293d5dead8efc24c1a6d",
            "corpusId": 197935335,
            "url": "https://www.semanticscholar.org/paper/4cd03cd34e7e94d1b1ee293d5dead8efc24c1a6d",
            "title": "Convergence of Edge Computing and Deep Learning: A Comprehensive Survey",
            "venue": "IEEE Communications Surveys and Tutorials",
            "publicationVenue": {
                "id": "urn:research:95d0dda7-5d58-4afd-b59f-315447b81992",
                "name": "IEEE Communications Surveys and Tutorials",
                "alternate_names": [
                    "IEEE Commun Surv Tutor"
                ],
                "issn": "1553-877X",
                "url": "http://www.comsoc.org/cst"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1907.08349",
                "DBLP": "journals/corr/abs-1907-08349",
                "MAG": "2962814013",
                "DOI": "10.1109/COMST.2020.2970550",
                "CorpusId": 197935335
            },
            "abstract": "Ubiquitous sensors and smart devices from factories and communities are generating massive amounts of data, and ever-increasing computing power is driving the core of computation and services from the cloud to the edge of the network. As an important enabler broadly changing people\u2019s lives, from face recognition to ambitious smart factories and cities, developments of artificial intelligence (especially deep learning, DL) based applications and services are thriving. However, due to efficiency and latency issues, the current cloud computing service architecture hinders the vision of \u201cproviding artificial intelligence for every person and every organization at everywhere\u201d. Thus, unleashing DL services using resources at the network edge near the data sources has emerged as a desirable solution. Therefore, edge intelligence, aiming to facilitate the deployment of DL services by edge computing, has received significant attention. In addition, DL, as the representative technique of artificial intelligence, can be integrated into edge computing frameworks to build intelligent edge for dynamic, adaptive edge maintenance and management. With regard to mutually beneficial edge intelligence and intelligent edge, this paper introduces and discusses: 1) the application scenarios of both; 2) the practical implementation methods and enabling technologies, namely DL training and inference in the customized edge computing framework; 3) challenges and future trends of more pervasive and fine-grained intelligence. We believe that by consolidating information scattered across the communication, networking, and DL areas, this survey can help readers to understand the connections between enabling technologies while promoting further discussions on the fusion of edge intelligence and intelligent edge, i.e., Edge DL.",
            "referenceCount": 314,
            "citationCount": 725,
            "influentialCitationCount": 42,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1907.08349",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-07-19",
            "journal": {
                "name": "IEEE Communications Surveys & Tutorials",
                "volume": "22"
            },
            "citationStyles": {
                "bibtex": "@Article{Han2019ConvergenceOE,\n author = {Yiwen Han and Xiaofei Wang and Victor C. M. Leung and D. Niyato and Xueqiang Yan and Xu Chen},\n booktitle = {IEEE Communications Surveys and Tutorials},\n journal = {IEEE Communications Surveys & Tutorials},\n pages = {869-904},\n title = {Convergence of Edge Computing and Deep Learning: A Comprehensive Survey},\n volume = {22},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3f611458b84ca8756c863916b33d12c704687127",
            "@type": "ScholarlyArticle",
            "paperId": "3f611458b84ca8756c863916b33d12c704687127",
            "corpusId": 46781358,
            "url": "https://www.semanticscholar.org/paper/3f611458b84ca8756c863916b33d12c704687127",
            "title": "Deep learning models for plant disease detection and diagnosis",
            "venue": "Computers and Electronics in Agriculture",
            "publicationVenue": {
                "id": "urn:research:80fdf70e-8520-4bb7-b387-3abebc9970b7",
                "name": "Computers and Electronics in Agriculture",
                "alternate_names": [
                    "Comput Electron Agric"
                ],
                "issn": "0168-1699",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/503304/description#description"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2789255992",
                "DBLP": "journals/cea/Ferentinos18",
                "DOI": "10.1016/j.compag.2018.01.009",
                "CorpusId": 46781358
            },
            "abstract": null,
            "referenceCount": 11,
            "citationCount": 1426,
            "influentialCitationCount": 76,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-01",
            "journal": {
                "name": "Comput. Electron. Agric.",
                "volume": "145"
            },
            "citationStyles": {
                "bibtex": "@Article{Ferentinos2018DeepLM,\n author = {K. P. Ferentinos},\n booktitle = {Computers and Electronics in Agriculture},\n journal = {Comput. Electron. Agric.},\n pages = {311-318},\n title = {Deep learning models for plant disease detection and diagnosis},\n volume = {145},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:18056fcac6fc744b940a8d10ff36d42269006f3c",
            "@type": "ScholarlyArticle",
            "paperId": "18056fcac6fc744b940a8d10ff36d42269006f3c",
            "corpusId": 3212989,
            "url": "https://www.semanticscholar.org/paper/18056fcac6fc744b940a8d10ff36d42269006f3c",
            "title": "Spectral\u2013Spatial Residual Network for Hyperspectral Image Classification: A 3-D Deep Learning Framework",
            "venue": "IEEE Transactions on Geoscience and Remote Sensing",
            "publicationVenue": {
                "id": "urn:research:70628d6a-97aa-4571-9701-bc0eb3989c32",
                "name": "IEEE Transactions on Geoscience and Remote Sensing",
                "alternate_names": [
                    "IEEE Trans Geosci Remote Sens"
                ],
                "issn": "0196-2892",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/tgrs/ZhongLLC18",
                "MAG": "2764276316",
                "DOI": "10.1109/TGRS.2017.2755542",
                "CorpusId": 3212989
            },
            "abstract": "In this paper, we designed an end-to-end spectral\u2013spatial residual network (SSRN) that takes raw 3-D cubes as input data without feature engineering for hyperspectral image classification. In this network, the spectral and spatial residual blocks consecutively learn discriminative features from abundant spectral signatures and spatial contexts in hyperspectral imagery (HSI). The proposed SSRN is a supervised deep learning framework that alleviates the declining-accuracy phenomenon of other deep learning models. Specifically, the residual blocks connect every other 3-D convolutional layer through identity mapping, which facilitates the backpropagation of gradients. Furthermore, we impose batch normalization on every convolutional layer to regularize the learning process and improve the classification performance of trained models. Quantitative and qualitative results demonstrate that the SSRN achieved the state-of-the-art HSI classification accuracy in agricultural, rural\u2013urban, and urban data sets: Indian Pines, Kennedy Space Center, and University of Pavia.",
            "referenceCount": 29,
            "citationCount": 927,
            "influentialCitationCount": 231,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-01",
            "journal": {
                "name": "IEEE Transactions on Geoscience and Remote Sensing",
                "volume": "56"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhong2018SpectralSpatialRN,\n author = {Zilong Zhong and Jonathan Li and Zhiming Luo and M. Chapman},\n booktitle = {IEEE Transactions on Geoscience and Remote Sensing},\n journal = {IEEE Transactions on Geoscience and Remote Sensing},\n pages = {847-858},\n title = {Spectral\u2013Spatial Residual Network for Hyperspectral Image Classification: A 3-D Deep Learning Framework},\n volume = {56},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8dd53f10ca5fa14faeed2bd2951d247f1ac60f40",
            "@type": "ScholarlyArticle",
            "paperId": "8dd53f10ca5fa14faeed2bd2951d247f1ac60f40",
            "corpusId": 115606413,
            "url": "https://www.semanticscholar.org/paper/8dd53f10ca5fa14faeed2bd2951d247f1ac60f40",
            "title": "A State-of-the-Art Survey on Deep Learning Theory and Architectures",
            "venue": "Electronics",
            "publicationVenue": {
                "id": "urn:research:ccd8e532-73c6-414f-bc91-271bbb2933e2",
                "name": "Electronics",
                "alternate_names": null,
                "issn": "1450-5843",
                "url": "http://www.electronics.etfbl.net/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2919358988",
                "DOI": "10.3390/ELECTRONICS8030292",
                "CorpusId": 115606413
            },
            "abstract": "In recent years, deep learning has garnered tremendous success in a variety of application domains. This new field of machine learning has been growing rapidly and has been applied to most traditional application domains, as well as some new areas that present more opportunities. Different methods have been proposed based on different categories of learning, including supervised, semi-supervised, and un-supervised learning. Experimental results show state-of-the-art performance using deep learning when compared to traditional machine learning approaches in the fields of image processing, computer vision, speech recognition, machine translation, art, medical imaging, medical information processing, robotics and control, bioinformatics, natural language processing, cybersecurity, and many others. This survey presents a brief survey on the advances that have occurred in the area of Deep Learning (DL), starting with the Deep Neural Network (DNN). The survey goes on to cover Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), including Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). Additionally, we have discussed recent developments, such as advanced variant DL techniques based on these DL approaches. This work considers most of the papers published after 2012 from when the history of deep learning began. Furthermore, DL approaches that have been explored and evaluated in different application domains are also included in this survey. We also included recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys that have been published on DL using neural networks and a survey on Reinforcement Learning (RL). However, those papers have not discussed individual advanced techniques for training large-scale deep learning models and the recently developed method of generative models.",
            "referenceCount": 272,
            "citationCount": 944,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/2079-9292/8/3/292/pdf?version=1552274432",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2019-03-05",
            "journal": {
                "name": "Electronics",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Alom2019ASS,\n author = {Md. Zahangir Alom and T. Taha and C. Yakopcic and Stefan Westberg and P. Sidike and M. S. Nasrin and Mahmudul Hasan and B. V. Van Essen and A. Awwal and V. Asari},\n booktitle = {Electronics},\n journal = {Electronics},\n title = {A State-of-the-Art Survey on Deep Learning Theory and Architectures},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7f002c2059f0714b5423f084913e54a50fe1ac58",
            "@type": "ScholarlyArticle",
            "paperId": "7f002c2059f0714b5423f084913e54a50fe1ac58",
            "corpusId": 73508614,
            "url": "https://www.semanticscholar.org/paper/7f002c2059f0714b5423f084913e54a50fe1ac58",
            "title": "Deep learning for electroencephalogram (EEG) classification tasks: a review",
            "venue": "Journal of Neural Engineering",
            "publicationVenue": {
                "id": "urn:research:aa06d038-4db2-4d34-a660-be35ff62d392",
                "name": "Journal of Neural Engineering",
                "alternate_names": [
                    "J Neural Eng"
                ],
                "issn": "1741-2552",
                "url": "http://iopscience.iop.org/1741-2552/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2915893085",
                "DOI": "10.1088/1741-2552/ab0ab5",
                "CorpusId": 73508614,
                "PubMed": "30808014"
            },
            "abstract": "Objective. Electroencephalography (EEG) analysis has been an important tool in neuroscience with applications in neuroscience, neural engineering (e.g. Brain\u2013computer interfaces, BCI\u2019s), and even commercial applications. Many of the analytical tools used in EEG studies have used machine learning to uncover relevant information for neural classification and neuroimaging. Recently, the availability of large EEG data sets and advances in machine learning have both led to the deployment of deep learning architectures, especially in the analysis of EEG signals and in understanding the information it may contain for brain functionality. The robust automatic classification of these signals is an important step towards making the use of EEG more practical in many applications and less reliant on trained professionals. Towards this goal, a systematic review of the literature on deep learning applications to EEG classification was performed to address the following critical questions: (1) Which EEG classification tasks have been explored with deep learning? (2) What input formulations have been used for training the deep networks? (3) Are there specific deep learning network structures suitable for specific types of tasks? Approach. A systematic literature review of EEG classification using deep learning was performed on Web of Science and PubMed databases, resulting in 90 identified studies. Those studies were analyzed based on type of task, EEG preprocessing methods, input type, and deep learning architecture. Main results. For EEG classification tasks, convolutional neural networks, recurrent neural networks, deep belief networks outperform stacked auto-encoders and multi-layer perceptron neural networks in classification accuracy. The tasks that used deep learning fell into five general groups: emotion recognition, motor imagery, mental workload, seizure detection, event related potential detection, and sleep scoring. For each type of task, we describe the specific input formulation, major characteristics, and end classifier recommendations found through this review. Significance. This review summarizes the current practices and performance outcomes in the use of deep learning for EEG classification. Practical suggestions on the selection of many hyperparameters are provided in the hope that they will promote or guide the deployment of deep learning to EEG datasets in future research.",
            "referenceCount": 129,
            "citationCount": 798,
            "influentialCitationCount": 40,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Physics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-02-26",
            "journal": {
                "name": "Journal of Neural Engineering",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Craik2019DeepLF,\n author = {Alexander Craik and Yongtian He and J. Contreras-Vidal},\n booktitle = {Journal of Neural Engineering},\n journal = {Journal of Neural Engineering},\n title = {Deep learning for electroencephalogram (EEG) classification tasks: a review},\n volume = {16},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dfbeb3ca7a01fe80c49b76baa50bf092f71eef4a",
            "@type": "ScholarlyArticle",
            "paperId": "dfbeb3ca7a01fe80c49b76baa50bf092f71eef4a",
            "corpusId": 198147317,
            "url": "https://www.semanticscholar.org/paper/dfbeb3ca7a01fe80c49b76baa50bf092f71eef4a",
            "title": "A Survey of Deep Learning-Based Object Detection",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1907-09408",
                "MAG": "2972006294",
                "ArXiv": "1907.09408",
                "DOI": "10.1109/ACCESS.2019.2939201",
                "CorpusId": 198147317
            },
            "abstract": "Object detection is one of the most important and challenging branches of computer vision, which has been widely applied in people\u2019s life, such as monitoring security, autonomous driving and so on, with the purpose of locating instances of semantic objects of a certain class. With the rapid development of deep learning algorithms for detection tasks, the performance of object detectors has been greatly improved. In order to understand the main development status of object detection pipeline thoroughly and deeply, in this survey, we analyze the methods of existing typical detection models and describe the benchmark datasets at first. Afterwards and primarily, we provide a comprehensive overview of a variety of object detection methods in a systematic manner, covering the one-stage and two-stage detectors. Moreover, we list the traditional and new applications. Some representative branches of object detection are analyzed as well. Finally, we discuss the architecture of exploiting these object detection methods to build an effective and efficient system and point out a set of development trends to better follow the state-of-the-art algorithms and further research.",
            "referenceCount": 319,
            "citationCount": 693,
            "influentialCitationCount": 40,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08825470.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-07-11",
            "journal": {
                "name": "IEEE Access",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Jiao2019ASO,\n author = {L. Jiao and Fan Zhang and Fang Liu and Shuyuan Yang and Lingling Li and Zhixi Feng and Rong Qu},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {128837-128868},\n title = {A Survey of Deep Learning-Based Object Detection},\n volume = {7},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bc789aef715498e79a74f857fa090ece9e383bf1",
            "@type": "ScholarlyArticle",
            "paperId": "bc789aef715498e79a74f857fa090ece9e383bf1",
            "corpusId": 165163737,
            "url": "https://www.semanticscholar.org/paper/bc789aef715498e79a74f857fa090ece9e383bf1",
            "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/iclr/YouLRHKBSDKH20",
                "ArXiv": "1904.00962",
                "MAG": "2995435108",
                "CorpusId": 165163737
            },
            "abstract": "Training large deep neural networks on massive datasets is computationally very challenging. There has been recent surge in interest in using large batch stochastic optimization methods to tackle this issue. The most prominent algorithm in this line of research is LARS, which by employing layerwise adaptive learning rates trains ResNet on ImageNet in a few minutes. However, LARS performs poorly for attention models like BERT, indicating that its performance gains are not consistent across tasks. In this paper, we first study a principled layerwise adaptation strategy to accelerate training of deep neural networks using large mini-batches. Using this strategy, we develop a new layerwise adaptive large batch optimization technique called LAMB; we then provide convergence analysis of LAMB as well as LARS, showing convergence to a stationary point in general nonconvex settings. Our empirical results demonstrate the superior performance of LAMB across various tasks such as BERT and ResNet-50 training with very little hyperparameter tuning. In particular, for BERT training, our optimizer enables use of very large batch sizes of 32868 without any degradation of performance. By increasing the batch size to the memory limit of a TPUv3 Pod, BERT training time can be reduced from 3 days to just 76 minutes (Table 1). The LAMB implementation is available at this https URL",
            "referenceCount": 39,
            "citationCount": 743,
            "influentialCitationCount": 104,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-04-01",
            "journal": {
                "name": "arXiv: Learning",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{You2019LargeBO,\n author = {Yang You and Jing Li and Sashank J. Reddi and Jonathan Hseu and Sanjiv Kumar and Srinadh Bhojanapalli and Xiaodan Song and J. Demmel and K. Keutzer and Cho-Jui Hsieh},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Learning},\n title = {Large Batch Optimization for Deep Learning: Training BERT in 76 minutes},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:df013a17ab84d5403361da4538a04d574f58be83",
            "@type": "ScholarlyArticle",
            "paperId": "df013a17ab84d5403361da4538a04d574f58be83",
            "corpusId": 52939079,
            "url": "https://www.semanticscholar.org/paper/df013a17ab84d5403361da4538a04d574f58be83",
            "title": "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning",
            "venue": "USENIX Symposium on Operating Systems Design and Implementation",
            "publicationVenue": {
                "id": "urn:research:86c43745-31d9-4c1a-b33f-ce3aa0042dbb",
                "name": "USENIX Symposium on Operating Systems Design and Implementation",
                "alternate_names": [
                    "Oper Syst Des Implement",
                    "Operating Systems Design and Implementation",
                    "OSDI",
                    "USENIX Symp Oper Syst Des Implement"
                ],
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1802.04799",
                "MAG": "2804032941",
                "DBLP": "conf/osdi/ChenMJZYSCWHCGK18",
                "CorpusId": 52939079
            },
            "abstract": "There is an increasing need to bring machine learning to a wide diversity of hardware devices. Current frameworks rely on vendor-specific operator libraries and optimize for a narrow range of server-class GPUs. Deploying workloads to new platforms -- such as mobile phones, embedded devices, and accelerators (e.g., FPGAs, ASICs) -- requires significant manual effort. We propose TVM, a compiler that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends. TVM solves optimization challenges specific to deep learning, such as high-level operator fusion, mapping to arbitrary hardware primitives, and memory latency hiding. It also automates optimization of low-level programs to hardware characteristics by employing a novel, learning-based cost modeling method for rapid exploration of code optimizations. Experimental results show that TVM delivers performance across hardware back-ends that are competitive with state-of-the-art, hand-tuned libraries for low-power CPU, mobile GPU, and server-class GPUs. We also demonstrate TVM's ability to target new accelerator back-ends, such as the FPGA-based generic deep learning accelerator. The system is open sourced and in production use inside several major companies.",
            "referenceCount": 50,
            "citationCount": 885,
            "influentialCitationCount": 229,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-02-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2018TVMAA,\n author = {Tianqi Chen and T. Moreau and Ziheng Jiang and Lianmin Zheng and Eddie Q. Yan and Haichen Shen and M. Cowan and Leyuan Wang and Yuwei Hu and L. Ceze and Carlos Guestrin and A. Krishnamurthy},\n booktitle = {USENIX Symposium on Operating Systems Design and Implementation},\n pages = {578-594},\n title = {TVM: An Automated End-to-End Optimizing Compiler for Deep Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3fea7ba9490c306484a8fdfe94323ff4e009e1c7",
            "@type": "ScholarlyArticle",
            "paperId": "3fea7ba9490c306484a8fdfe94323ff4e009e1c7",
            "corpusId": 1348207,
            "url": "https://www.semanticscholar.org/paper/3fea7ba9490c306484a8fdfe94323ff4e009e1c7",
            "title": "Supplementary for: Deep learning with convolutional neural networks for EEG decoding and visualization",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "CorpusId": 1348207
            },
            "abstract": "Translational Neurotechnology Lab, Epilepsy Center, Medical Center \u2013 University of Freiburg, Engelberger Str. 21, 79106 Freiburg, Germany BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Georges-K\u00f6hler-Allee 79, 79110 Freiburg, Germany Machine Learning Lab, Computer Science Dept., University of Freiburg, Georges-K\u00f6hler-Allee 79, 79110 Freiburg, Germany Neurobiology and Biophysics, Faculty of Biology, University of Freiburg, Hansastr. 9a, 79104 Freiburg, Germany Machine Learning for Automated Algorithm Design Lab, Computer Science Dept., University of Freiburg, Georges-K\u00f6hler-Allee 52, 79110 Freiburg im Breisgau, Germany Brain State Decoding Lab, Computer Science Dept., University of Freiburg, Albertstr. 23, 79104 Freiburg, Germany Autonomous Intelligent Systems Lab, Computer Science Dept., University of Freiburg, Georges-K\u00f6hler-Allee 79, 79110 Freiburg, Germany",
            "referenceCount": 37,
            "citationCount": 1600,
            "influentialCitationCount": 289,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Schirrmeister2017SupplementaryFD,\n author = {R. Schirrmeister and J. T. Springenberg and L. Fiederer and Martin Glasstetter and Katharina Eggensperger and M. Tangermann and F. Hutter and Wolfram Burgard and T. Ball},\n title = {Supplementary for: Deep learning with convolutional neural networks for EEG decoding and visualization},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fd075bcdf2d7e13d23f7c249a8eded343d5bbe3b",
            "@type": "ScholarlyArticle",
            "paperId": "fd075bcdf2d7e13d23f7c249a8eded343d5bbe3b",
            "corpusId": 202539732,
            "url": "https://www.semanticscholar.org/paper/fd075bcdf2d7e13d23f7c249a8eded343d5bbe3b",
            "title": "Deep Graph Library: Towards Efficient and Scalable Deep Learning on Graphs",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1909-01315",
                "ArXiv": "1909.01315",
                "MAG": "2971933740",
                "CorpusId": 202539732
            },
            "abstract": "Accelerating research in the emerging field of deep graph learning requires new tools. Such systems should support graph as the core abstraction and take care to maintain both forward (i.e. supporting new research ideas) and backward (i.e. integration with existing components) compatibility. In this paper, we present Deep Graph Library (DGL). DGL enables arbitrary message handling and mutation operators, flexible propagation rules, and is framework agnostic so as to leverage high-performance tensor, autograd operations, and other feature extraction modules already available in existing frameworks. DGL carefully handles the sparse and irregular graph structure, deals with graphs big and small which may change dynamically, fuses operations, and performs auto-batching, all to take advantages of modern hardware. DGL has been tested on a variety of models, including but not limited to the popular Graph Neural Networks (GNN) and its variants, with promising speed, memory footprint and scalability.",
            "referenceCount": 34,
            "citationCount": 562,
            "influentialCitationCount": 84,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-09-03",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1909.01315"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2019DeepGL,\n author = {Minjie Wang and Lingfan Yu and Da Zheng and Quan Gan and Yujie Gai and Zihao Ye and Mufei Li and Jinjing Zhou and Qi Huang and Chao Ma and Ziyue Huang and Qipeng Guo and Haotong Zhang and Haibin Lin and J. Zhao and Jinyang Li and Alex Smola and Zheng Zhang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Graph Library: Towards Efficient and Scalable Deep Learning on Graphs},\n volume = {abs/1909.01315},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e2c8726d092aea573e69f5b0a2654225883cfacf",
            "@type": "ScholarlyArticle",
            "paperId": "e2c8726d092aea573e69f5b0a2654225883cfacf",
            "corpusId": 3398835,
            "url": "https://www.semanticscholar.org/paper/e2c8726d092aea573e69f5b0a2654225883cfacf",
            "title": "Horovod: fast and easy distributed deep learning in TensorFlow",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2787998955",
                "DBLP": "journals/corr/abs-1802-05799",
                "ArXiv": "1802.05799",
                "CorpusId": 3398835
            },
            "abstract": "Training modern deep learning models requires large amounts of computation, often provided by GPUs. Scaling computation from one GPU to many can enable much faster training and research progress but entails two complications. First, the training library must support inter-GPU communication. Depending on the particular methods employed, this communication may entail anywhere from negligible to significant overhead. Second, the user must modify his or her training code to take advantage of inter-GPU communication. Depending on the training library's API, the modification required may be either significant or minimal. \nExisting methods for enabling multi-GPU training under the TensorFlow library entail non-negligible communication overhead and require users to heavily modify their model-building code, leading many researchers to avoid the whole mess and stick with slower single-GPU training. In this paper we introduce Horovod, an open source library that improves on both obstructions to scaling: it employs efficient inter-GPU communication via ring reduction and requires only a few lines of modification to user code, enabling faster, easier distributed training in TensorFlow. Horovod is available under the Apache 2.0 license at this https URL",
            "referenceCount": 16,
            "citationCount": 1003,
            "influentialCitationCount": 186,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1802.05799"
            },
            "citationStyles": {
                "bibtex": "@Article{Sergeev2018HorovodFA,\n author = {Alexander Sergeev and Mike Del Balso},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Horovod: fast and easy distributed deep learning in TensorFlow},\n volume = {abs/1802.05799},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba",
            "@type": "ScholarlyArticle",
            "paperId": "ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba",
            "corpusId": 205086555,
            "url": "https://www.semanticscholar.org/paper/ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba",
            "title": "Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer",
            "venue": "Journal of the American Medical Association (JAMA)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2772723798",
                "DOI": "10.1001/jama.2017.14585",
                "CorpusId": 205086555,
                "PubMed": "29234806"
            },
            "abstract": "Importance Application of deep learning algorithms to whole-slide pathology images can potentially improve diagnostic accuracy and efficiency. Objective Assess the performance of automated deep learning algorithms at detecting metastases in hematoxylin and eosin\u2013stained tissue sections of lymph nodes of women with breast cancer and compare it with pathologists\u2019 diagnoses in a diagnostic setting. Design, Setting, and Participants Researcher challenge competition (CAMELYON16) to develop automated solutions for detecting lymph node metastases (November 2015-November 2016). A training data set of whole-slide images from 2 centers in the Netherlands with (n\u2009=\u2009110) and without (n\u2009=\u2009160) nodal metastases verified by immunohistochemical staining were provided to challenge participants to build algorithms. Algorithm performance was evaluated in an independent test set of 129 whole-slide images (49 with and 80 without metastases). The same test set of corresponding glass slides was also evaluated by a panel of 11 pathologists with time constraint (WTC) from the Netherlands to ascertain likelihood of nodal metastases for each slide in a flexible 2-hour session, simulating routine pathology workflow, and by 1 pathologist without time constraint (WOTC). Exposures Deep learning algorithms submitted as part of a challenge competition or pathologist interpretation. Main Outcomes and Measures The presence of specific metastatic foci and the absence vs presence of lymph node metastasis in a slide or image using receiver operating characteristic curve analysis. The 11 pathologists participating in the simulation exercise rated their diagnostic confidence as definitely normal, probably normal, equivocal, probably tumor, or definitely tumor. Results The area under the receiver operating characteristic curve (AUC) for the algorithms ranged from 0.556 to 0.994. The top-performing algorithm achieved a lesion-level, true-positive fraction comparable with that of the pathologist WOTC (72.4% [95% CI, 64.3%-80.4%]) at a mean of 0.0125 false-positives per normal whole-slide image. For the whole-slide image classification task, the best algorithm (AUC, 0.994 [95% CI, 0.983-0.999]) performed significantly better than the pathologists WTC in a diagnostic simulation (mean AUC, 0.810 [range, 0.738-0.884]; P\u2009<\u2009.001). The top 5 algorithms had a mean AUC that was comparable with the pathologist interpreting the slides in the absence of time constraints (mean AUC, 0.960 [range, 0.923-0.994] for the top 5 algorithms vs 0.966 [95% CI, 0.927-0.998] for the pathologist WOTC). Conclusions and Relevance In the setting of a challenge competition, some deep learning algorithms achieved better diagnostic performance than a panel of 11 pathologists participating in a simulation exercise designed to mimic routine pathology workflow; algorithm performance was comparable with an expert pathologist interpreting whole-slide images without time constraints. Whether this approach has clinical utility will require evaluation in a clinical setting.",
            "referenceCount": 71,
            "citationCount": 2089,
            "influentialCitationCount": 74,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://jamanetwork.com/journals/jama/articlepdf/2665774/jama_ehteshami_bejnordi_2017_oi_170113.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study"
            ],
            "publicationDate": "2017-12-12",
            "journal": {
                "name": "JAMA",
                "volume": "318"
            },
            "citationStyles": {
                "bibtex": "@Article{Bejnordi2017DiagnosticAO,\n author = {Babak Ehteshami Bejnordi and M. Veta and Paul Johannes van Diest and B. van Ginneken and N. Karssemeijer and G. Litjens and J. A. van der Laak and M. Hermsen and Quirine F. Manson and M. Balkenhol and Oscar G. F. Geessink and N. Stathonikos and M. V. van Dijk and P. Bult and F. Beca and Andrew H. Beck and Dayong Wang and A. Khosla and Rishab Gargeya and H. Irshad and Aoxiao Zhong and Q. Dou and Quanzheng Li and Hao Chen and Huangjing Lin and P. Heng and C. Hass and Elia Bruni and Q. Wong and U. Halici and Mustafa \u00dcmit \u00d6ner and R. Cetin-Atalay and Matt Berseth and V. Khvatkov and A. Vylegzhanin and Oren Z. Kraus and M. Shaban and N. Rajpoot and Ruqayya Awan and K. Sirinukunwattana and Talha Qaiser and Y. Tsang and David Tellez and Jonas Annuscheit and P. Hufnagl and Mira Valkonen and K. Kartasalo and Leena Latonen and P. Ruusuvuori and Kaisa Liimatainen and Shadi Albarqouni and Bharti Mungal and A. George and S. Demirci and N. Navab and Seiryo Watanabe and S. Seno and Y. Takenaka and H. Matsuda and Hady Ahmady Phoulady and V. Kovalev and A. Kalinovsky and V. Liauchuk and G. Bueno and M. Fern\u00e1ndez-Carrobles and I. Serrano and O. Deniz and Daniel Racoceanu and Rui Ven\u00e2ncio},\n booktitle = {Journal of the American Medical Association (JAMA)},\n journal = {JAMA},\n pages = {2199\u20132210},\n title = {Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer},\n volume = {318},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:91bdaf3f1226e4065c4296d5c362906ceadfc631",
            "@type": "ScholarlyArticle",
            "paperId": "91bdaf3f1226e4065c4296d5c362906ceadfc631",
            "corpusId": 1395439,
            "url": "https://www.semanticscholar.org/paper/91bdaf3f1226e4065c4296d5c362906ceadfc631",
            "title": "Deep Learning Face Representation by Joint Identification-Verification",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/nips/SunCWT14",
                "MAG": "2144172034",
                "ArXiv": "1406.4773",
                "CorpusId": 1395439
            },
            "abstract": "The key challenge of face recognition is to develop effective feature representations for reducing intra-personal variations while enlarging inter-personal differences. In this paper, we show that it can be well solved with deep learning and using both face identification and verification signals as supervision. The Deep IDentification-verification features (DeepID2) are learned with carefully designed deep convolutional networks. The face identification task increases the inter-personal variations by drawing DeepID2 features extracted from different identities apart, while the face verification task reduces the intra-personal variations by pulling DeepID2 features extracted from the same identity together, both of which are essential to face recognition. The learned DeepID2 features can be well generalized to new identities unseen in the training data. On the challenging LFW dataset [11], 99.15% face verification accuracy is achieved. Compared with the best previous deep learning result [20] on LFW, the error rate has been significantly reduced by 67%.",
            "referenceCount": 30,
            "citationCount": 2135,
            "influentialCitationCount": 174,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-06-18",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1406.4773"
            },
            "citationStyles": {
                "bibtex": "@Article{Sun2014DeepLF,\n author = {Yi Sun and Yuheng Chen and Xiaogang Wang and Xiaoou Tang},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Deep Learning Face Representation by Joint Identification-Verification},\n volume = {abs/1406.4773},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3b656bba99dbcf6c6d8fd764d53ea64cd38c7050",
            "@type": "ScholarlyArticle",
            "paperId": "3b656bba99dbcf6c6d8fd764d53ea64cd38c7050",
            "corpusId": 102486060,
            "url": "https://www.semanticscholar.org/paper/3b656bba99dbcf6c6d8fd764d53ea64cd38c7050",
            "title": "Measuring Calibration in Deep Learning",
            "venue": "CVPR Workshops",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2933254221",
                "ArXiv": "1904.01685",
                "DBLP": "conf/cvpr/NixonDZJT19",
                "CorpusId": 102486060
            },
            "abstract": "Overconfidence and underconfidence in machine learning classifiers is measured by calibration: the degree to which the probabilities predicted for each class match the accuracy of the classifier on that prediction. \nHow one measures calibration remains a challenge: expected calibration error, the most popular metric, has numerous flaws which we outline, and there is no clear empirical understanding of how its choices affect conclusions in practice, and what recommendations there are to counteract its flaws. \nIn this paper, we perform a comprehensive empirical study of choices in calibration measures including measuring all probabilities rather than just the maximum prediction, thresholding probability values, class conditionality, number of bins, bins that are adaptive to the datapoint density, and the norm used to compare accuracies to confidences. To analyze the sensitivity of calibration measures, we study the impact of optimizing directly for each variant with recalibration techniques. Across MNIST, Fashion MNIST, CIFAR-10/100, and ImageNet, we find that conclusions on the rank ordering of recalibration methods is drastically impacted by the choice of calibration measure. We find that conditioning on the class leads to more effective calibration evaluations, and that using the L2 norm rather than the L1 norm improves both optimization for calibration metrics and the rank correlation measuring metric consistency. Adaptive binning schemes lead to more stablity of metric rank ordering when the number of bins vary, and is also recommended. We open source a library for the use of our calibration measures.",
            "referenceCount": 33,
            "citationCount": 311,
            "influentialCitationCount": 48,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-04-02",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1904.01685"
            },
            "citationStyles": {
                "bibtex": "@Article{Nixon2019MeasuringCI,\n author = {Jeremy Nixon and Michael W. Dusenberry and Linchuan Zhang and Ghassen Jerfel and Dustin Tran},\n booktitle = {CVPR Workshops},\n journal = {ArXiv},\n title = {Measuring Calibration in Deep Learning},\n volume = {abs/1904.01685},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c5420ef59d7508d82e53671b0d623027eb58e6ed",
            "@type": "ScholarlyArticle",
            "paperId": "c5420ef59d7508d82e53671b0d623027eb58e6ed",
            "corpusId": 4321928,
            "url": "https://www.semanticscholar.org/paper/c5420ef59d7508d82e53671b0d623027eb58e6ed",
            "title": "Learning to Reweight Examples for Robust Deep Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2795282075",
                "ArXiv": "1803.09050",
                "DBLP": "conf/icml/RenZYU18",
                "CorpusId": 4321928
            },
            "abstract": "Deep neural networks have been shown to be very powerful modeling tools for many supervised learning tasks involving complex input patterns. However, they can also easily overfit to training set biases and label noises. In addition to various regularizers, example reweighting algorithms are popular solutions to these problems, but they require careful tuning of additional hyperparameters, such as example mining schedules and regularization hyperparameters. In contrast to past reweighting methods, which typically consist of functions of the cost value of each example, in this work we propose a novel meta-learning algorithm that learns to assign weights to training examples based on their gradient directions. To determine the example weights, our method performs a meta gradient descent step on the current mini-batch example weights (which are initialized from zero) to minimize the loss on a clean unbiased validation set. Our proposed method can be easily implemented on any type of deep network, does not require any additional hyperparameter tuning, and achieves impressive performance on class imbalance and corrupted label problems where only a small amount of clean validation data is available.",
            "referenceCount": 46,
            "citationCount": 1135,
            "influentialCitationCount": 165,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-03-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ren2018LearningTR,\n author = {Mengye Ren and Wenyuan Zeng and Binh Yang and R. Urtasun},\n booktitle = {International Conference on Machine Learning},\n pages = {4331-4340},\n title = {Learning to Reweight Examples for Robust Deep Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:594a91fe54eb44f0e5fffd35ab015a8456419d11",
            "@type": "ScholarlyArticle",
            "paperId": "594a91fe54eb44f0e5fffd35ab015a8456419d11",
            "corpusId": 53208763,
            "url": "https://www.semanticscholar.org/paper/594a91fe54eb44f0e5fffd35ab015a8456419d11",
            "title": "Activation Functions: Comparison of trends in Practice and Research for Deep Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1811-03378",
                "ArXiv": "1811.03378",
                "MAG": "2899675781",
                "CorpusId": 53208763
            },
            "abstract": "Deep neural networks have been successfully used in diverse emerging domains to solve real world complex problems with may more deep learning(DL) architectures, being developed to date. To achieve these state-of-the-art performances, the DL architectures use activation functions (AFs), to perform diverse computations between the hidden layers and the output layers of any given DL architecture. This paper presents a survey on the existing AFs used in deep learning applications and highlights the recent trends in the use of the activation functions for deep learning applications. The novelty of this paper is that it compiles majority of the AFs used in DL and outlines the current trends in the applications and usage of these functions in practical deep learning deployments against the state-of-the-art research results. This compilation will aid in making effective decisions in the choice of the most suitable and appropriate activation function for any given application, ready for deployment. This paper is timely because most research papers on AF highlights similar works and results while this paper will be the first, to compile the trends in AF applications in practice against the research results from literature, found in deep learning research to date.",
            "referenceCount": 90,
            "citationCount": 1062,
            "influentialCitationCount": 83,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-11-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1811.03378"
            },
            "citationStyles": {
                "bibtex": "@Article{Nwankpa2018ActivationFC,\n author = {Chigozie Nwankpa and W. Ijomah and A. Gachagan and Stephen Marshall},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Activation Functions: Comparison of trends in Practice and Research for Deep Learning},\n volume = {abs/1811.03378},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f",
            "@type": "ScholarlyArticle",
            "paperId": "a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f",
            "corpusId": 3333267,
            "url": "https://www.semanticscholar.org/paper/a29b7a000e6e1a2907ce6ae24a03aba5d9ef873f",
            "title": "Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning",
            "venue": "IEEE Transactions on Medical Imaging",
            "publicationVenue": {
                "id": "urn:research:e0cda45d-3074-4ac0-80b8-e5250df00b89",
                "name": "IEEE Transactions on Medical Imaging",
                "alternate_names": [
                    "IEEE Trans Med Imaging"
                ],
                "issn": "0278-0062",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=42"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2952539962",
                "PubMedCentral": "4890616",
                "DBLP": "journals/tmi/ShinRGLXNYMS16",
                "ArXiv": "1602.03409",
                "DOI": "10.1109/TMI.2016.2528162",
                "CorpusId": 3333267,
                "PubMed": "26886976"
            },
            "abstract": "Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and deep convolutional neural networks (CNNs). CNNs enable learning data-driven, highly representative, hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.",
            "referenceCount": 77,
            "citationCount": 4004,
            "influentialCitationCount": 87,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-02-10",
            "journal": {
                "name": "Ieee Transactions on Medical Imaging",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Shin2016DeepCN,\n author = {Hoo-Chang Shin and H. Roth and Mingchen Gao and Le Lu and Ziyue Xu and Isabella Nogues and Jianhua Yao and D. Mollura and R. Summers},\n booktitle = {IEEE Transactions on Medical Imaging},\n journal = {Ieee Transactions on Medical Imaging},\n pages = {1285 - 1298},\n title = {Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning},\n volume = {35},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9954ec0a95fc0840f7712d7b0c67b242bb536a9e",
            "@type": "ScholarlyArticle",
            "paperId": "9954ec0a95fc0840f7712d7b0c67b242bb536a9e",
            "corpusId": 216464080,
            "url": "https://www.semanticscholar.org/paper/9954ec0a95fc0840f7712d7b0c67b242bb536a9e",
            "title": "A fully automatic deep learning system for COVID-19 diagnostic and prognostic analysis",
            "venue": "European Respiratory Journal",
            "publicationVenue": {
                "id": "urn:research:20a67aab-0b87-48dd-a3ef-b1d379147b9b",
                "name": "European Respiratory Journal",
                "alternate_names": [
                    "Eur Respir J"
                ],
                "issn": "0903-1936",
                "url": "https://erj.ersjournals.com/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3013128190",
                "PubMedCentral": "7243395",
                "DOI": "10.1101/2020.03.24.20042317",
                "CorpusId": 216464080,
                "PubMed": "32444412"
            },
            "abstract": "Coronavirus disease 2019 (COVID-19) has spread globally, and medical resources become insufficient in many regions. Fast diagnosis of COVID-19 and finding high-risk patients with worse prognosis for early prevention and medical resource optimisation is important. Here, we proposed a fully automatic deep learning system for COVID-19 diagnostic and prognostic analysis by routinely used computed tomography. We retrospectively collected 5372 patients with computed tomography images from seven cities or provinces. Firstly, 4106 patients with computed tomography images were used to pre-train the deep learning system, making it learn lung features. Following this, 1266 patients (924 with COVID-19 (471 had follow-up for >5\u2005days) and 342 with other pneumonia) from six cities or provinces were enrolled to train and externally validate the performance of the deep learning system. In the four external validation sets, the deep learning system achieved good performance in identifying COVID-19 from other pneumonia (AUC 0.87 and 0.88, respectively) and viral pneumonia (AUC 0.86). Moreover, the deep learning system succeeded to stratify patients into high- and low-risk groups whose hospital-stay time had significant difference (p=0.013 and p=0.014, respectively). Without human assistance, the deep learning system automatically focused on abnormal areas that showed consistent characteristics with reported radiological findings. Deep learning provides a convenient tool for fast screening of COVID-19 and identifying potential high-risk patients, which may be helpful for medical resource optimisation and early prevention before patients show severe symptoms. A fully automatic deep learning system provides a convenient method for COVID-19 diagnostic and prognostic analysis, which can help COVID-19 screening and finding potential high-risk patients with worse prognosis https://bit.ly/3bRaxGw",
            "referenceCount": 36,
            "citationCount": 382,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://erj.ersjournals.com/content/erj/56/2/2000775.full.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-03-26",
            "journal": {
                "name": "The European Respiratory Journal",
                "volume": "56"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2020AFA,\n author = {Shuo Wang and Y. Zha and Wei-min Li and Qingxia Wu and Xiaohu Li and M. Niu and Meiyun Wang and Xiaoming Qiu and Hongjun Li and He Yu and Wei Gong and Yan Bai and Li Li and Yongbei Zhu and Liusu Wang and Jie Tian},\n booktitle = {European Respiratory Journal},\n journal = {The European Respiratory Journal},\n title = {A fully automatic deep learning system for COVID-19 diagnostic and prognostic analysis},\n volume = {56},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e67121cd31e95fba6c892724e619323ad7564b03",
            "@type": "ScholarlyArticle",
            "paperId": "e67121cd31e95fba6c892724e619323ad7564b03",
            "corpusId": 191166260,
            "url": "https://www.semanticscholar.org/paper/e67121cd31e95fba6c892724e619323ad7564b03",
            "title": "A Survey of Deep Learning and Its Applications: A New Paradigm to Machine Learning",
            "venue": "Archives of Computational Methods in Engineering",
            "publicationVenue": {
                "id": "urn:research:f9c1272f-e8c2-4e8c-bdae-fc9c2bb2cb85",
                "name": "Archives of Computational Methods in Engineering",
                "alternate_names": [
                    "Arch Comput Method Eng"
                ],
                "issn": "1134-3060",
                "url": "http://www.cimne.com/arcme/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "2947411064",
                "DOI": "10.1007/S11831-019-09344-W",
                "CorpusId": 191166260
            },
            "abstract": null,
            "referenceCount": 81,
            "citationCount": 525,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2020-09-01",
            "journal": {
                "name": "Archives of Computational Methods in Engineering",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Dargan2020ASO,\n author = {Shaveta Dargan and Munish Kumar and M. Ayyagari and G. Kumar},\n booktitle = {Archives of Computational Methods in Engineering},\n journal = {Archives of Computational Methods in Engineering},\n pages = {1-22},\n title = {A Survey of Deep Learning and Its Applications: A New Paradigm to Machine Learning},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:728e0cdfdd5bb14b6eb74e7038ebcf5e975a4743",
            "@type": "ScholarlyArticle",
            "paperId": "728e0cdfdd5bb14b6eb74e7038ebcf5e975a4743",
            "corpusId": 218486791,
            "url": "https://www.semanticscholar.org/paper/728e0cdfdd5bb14b6eb74e7038ebcf5e975a4743",
            "title": "Remote Sensing Image Scene Classification Meets Deep Learning: Challenges, Methods, Benchmarks, and Opportunities",
            "venue": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
            "publicationVenue": {
                "id": "urn:research:849b6687-df71-4d12-9c46-59f45d5ce951",
                "name": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
                "alternate_names": [
                    "IEEE J Sel Top Appl Earth Obs Remote Sens"
                ],
                "issn": "1939-1404",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=4609443"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3022140654",
                "ArXiv": "2005.01094",
                "DBLP": "journals/staeors/ChengXHGX20",
                "DOI": "10.1109/JSTARS.2020.3005403",
                "CorpusId": 218486791
            },
            "abstract": "Remote sensing image scene classification, which aims at labeling remote sensing images with a set of semantic categories based on their contents, has broad applications in a range of fields. Propelled by the powerful feature learning capabilities of deep neural networks, remote sensing image scene classification driven by deep learning has drawn remarkable attention and achieved significant breakthroughs. However, to the best of our knowledge, a comprehensive review of recent achievements regarding deep learning for scene classification of remote sensing images is still lacking. Considering the rapid evolution of this field, this article provides a systematic survey of deep learning methods for remote sensing image scene classification by covering more than 160 papers. To be specific, we discuss the main challenges of remote sensing image scene classification and survey: first, autoencoder-based remote sensing image scene classification methods; second, convolutional neural network-based remote sensing image scene classification methods; and third, generative adversarial network-based remote sensing image scene classification methods. In addition, we introduce the benchmarks used for remote sensing image scene classification and summarize the performance of more than two dozen of representative algorithms on three commonly used benchmark datasets. Finally, we discuss the promising opportunities for further research.",
            "referenceCount": 171,
            "citationCount": 374,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/4609443/8994817/09127795.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-05-03",
            "journal": {
                "name": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Cheng2020RemoteSI,\n author = {Gong Cheng and Xingxing Xie and Junwei Han and Lei Guo and Guisong Xia},\n booktitle = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},\n journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},\n pages = {3735-3756},\n title = {Remote Sensing Image Scene Classification Meets Deep Learning: Challenges, Methods, Benchmarks, and Opportunities},\n volume = {13},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:02d49b4dbaf8c093034918a76648fea53961753d",
            "@type": "ScholarlyArticle",
            "paperId": "02d49b4dbaf8c093034918a76648fea53961753d",
            "corpusId": 216562380,
            "url": "https://www.semanticscholar.org/paper/02d49b4dbaf8c093034918a76648fea53961753d",
            "title": "Time-series forecasting with deep learning: a survey",
            "venue": "Philosophical Transactions of the Royal Society A",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3022643593",
                "DBLP": "journals/corr/abs-2004-13408",
                "ArXiv": "2004.13408",
                "DOI": "10.1098/rsta.2020.0209",
                "CorpusId": 216562380,
                "PubMed": "33583273"
            },
            "abstract": "Numerous deep learning architectures have been developed to accommodate the diversity of time-series datasets across different domains. In this article, we survey common encoder and decoder designs used in both one-step-ahead and multi-horizon time-series forecasting\u2014describing how temporal information is incorporated into predictions by each model. Next, we highlight recent developments in hybrid deep learning models, which combine well-studied statistical models with neural network components to improve pure methods in either category. Lastly, we outline some ways in which deep learning can also facilitate decision support with time-series data. This article is part of the theme issue \u2018Machine learning for weather and climate modelling\u2019.",
            "referenceCount": 90,
            "citationCount": 537,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2020.0209",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-04-28",
            "journal": {
                "name": "Philosophical Transactions of the Royal Society A",
                "volume": "379"
            },
            "citationStyles": {
                "bibtex": "@Article{Lim2020TimeseriesFW,\n author = {Bryan Lim and S. Zohren},\n booktitle = {Philosophical Transactions of the Royal Society A},\n journal = {Philosophical Transactions of the Royal Society A},\n title = {Time-series forecasting with deep learning: a survey},\n volume = {379},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e3e08c64cfe155e1061e8ef235491efed35eb37f",
            "@type": "ScholarlyArticle",
            "paperId": "e3e08c64cfe155e1061e8ef235491efed35eb37f",
            "corpusId": 210838728,
            "url": "https://www.semanticscholar.org/paper/e3e08c64cfe155e1061e8ef235491efed35eb37f",
            "title": "Deep Learning for Sensor-based Human Activity Recognition",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3001316388",
                "DBLP": "journals/corr/abs-2001-07416",
                "ArXiv": "2001.07416",
                "DOI": "10.1145/3447744",
                "CorpusId": 210838728
            },
            "abstract": "The vast proliferation of sensor devices and Internet of Things enables the applications of sensor-based activity recognition. However, there exist substantial challenges that could influence the performance of the recognition system in practical scenarios. Recently, as deep learning has demonstrated its effectiveness in many areas, plenty of deep methods have been investigated to address the challenges in activity recognition. In this study, we present a survey of the state-of-the-art deep learning methods for sensor-based human activity recognition. We first introduce the multi-modality of the sensory data and provide information for public datasets that can be used for evaluation in different challenge tasks. We then propose a new taxonomy to structure the deep methods by challenges. Challenges and challenge-related deep methods are summarized and analyzed to form an overview of the current research progress. At the end of this work, we discuss the open issues and provide some insights for future directions.",
            "referenceCount": 210,
            "citationCount": 365,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-01-21",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "54"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2020DeepLF,\n author = {Kaixuan Chen and Dalin Zhang and Lina Yao and Bin Guo and Zhiwen Yu and Yunhao Liu},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 40},\n title = {Deep Learning for Sensor-based Human Activity Recognition},\n volume = {54},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6d2d78d2015e6057b99691ae097a7362ec4e3bb6",
            "@type": "ScholarlyArticle",
            "paperId": "6d2d78d2015e6057b99691ae097a7362ec4e3bb6",
            "corpusId": 211572503,
            "url": "https://www.semanticscholar.org/paper/6d2d78d2015e6057b99691ae097a7362ec4e3bb6",
            "title": "Time Series Data Augmentation for Deep Learning: A Survey",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2002-12478",
                "MAG": "3008872739",
                "ArXiv": "2002.12478",
                "DOI": "10.24963/ijcai.2021/631",
                "CorpusId": 211572503
            },
            "abstract": "Deep learning performs remarkably well on many time series analysis tasks recently. The superior performance of deep neural networks relies heavily on a large number of training data to avoid overfitting. However, the labeled data of many real-world time series applications may be limited such as classification in medical time series and anomaly detection in AIOps. As an effective way to enhance the size and quality of the training data, data augmentation is crucial to the successful application of deep learning models on time series data. In this paper, we systematically review different data augmentation methods for time series. We propose a taxonomy for the reviewed methods, and then provide a structured review for these methods by highlighting their strengths and limitations. We also empirically compare different data augmentation methods for different tasks including time series classification, anomaly detection, and forecasting. Finally, we discuss and highlight five future directions to provide useful research guidance.",
            "referenceCount": 78,
            "citationCount": 370,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.ijcai.org/proceedings/2021/0631.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2020-02-27",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wen2020TimeSD,\n author = {Qingsong Wen and Liang Sun and Xiaomin Song and Jing Gao and Xue Wang and Huan Xu},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {4653-4660},\n title = {Time Series Data Augmentation for Deep Learning: A Survey},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6303bac53abd725c3b458190a6abe389a4a1e72d",
            "@type": "ScholarlyArticle",
            "paperId": "6303bac53abd725c3b458190a6abe389a4a1e72d",
            "corpusId": 67856425,
            "url": "https://www.semanticscholar.org/paper/6303bac53abd725c3b458190a6abe389a4a1e72d",
            "title": "Deep High-Resolution Representation Learning for Human Pose Estimation",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/cvpr/0009XLW19",
                "MAG": "2916798096",
                "ArXiv": "1902.09212",
                "DOI": "10.1109/CVPR.2019.00584",
                "CorpusId": 67856425
            },
            "abstract": "In this paper, we are interested in the human pose estimation problem with a focus on learning reliable high-resolution representations. Most existing methods recover high-resolution representations from low-resolution representations produced by a high-to-low resolution network. Instead, our proposed network maintains high-resolution representations through the whole process. We start from a high-resolution subnetwork as the first stage, gradually add high-to-low resolution subnetworks one by one to form more stages, and connect the mutli-resolution subnetworks in parallel. We conduct repeated multi-scale fusions such that each of the high-to-low resolution representations receives information from other parallel representations over and over, leading to rich high-resolution representations. As a result, the predicted keypoint heatmap is potentially more accurate and spatially more precise. We empirically demonstrate the effectiveness of our network through the superior pose estimation results over two benchmark datasets: the COCO keypoint detection dataset and the MPII Human Pose dataset. In addition, we show the superiority of our network in pose tracking on the PoseTrack dataset. The code and models have been publicly available at https://github.com/leoxiaobin/deep-high-resolution-net.pytorch.",
            "referenceCount": 87,
            "citationCount": 2759,
            "influentialCitationCount": 609,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1902.09212",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-02-25",
            "journal": {
                "name": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sun2019DeepHR,\n author = {Ke Sun and Bin Xiao and Dong Liu and Jingdong Wang},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {5686-5696},\n title = {Deep High-Resolution Representation Learning for Human Pose Estimation},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:af6af40155860ac2fd36680e63686473803b5f52",
            "@type": "ScholarlyArticle",
            "paperId": "af6af40155860ac2fd36680e63686473803b5f52",
            "corpusId": 218972018,
            "url": "https://www.semanticscholar.org/paper/af6af40155860ac2fd36680e63686473803b5f52",
            "title": "Explainable Deep Learning Models in Medical Image Analysis",
            "venue": "Journal of Imaging",
            "publicationVenue": {
                "id": "urn:research:c0fc53c7-b0ed-487d-9191-1262c8322621",
                "name": "Journal of Imaging",
                "alternate_names": [
                    "J Imaging"
                ],
                "issn": "2313-433X",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-556372"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/jimaging/SinghSL20",
                "MAG": "3031116957",
                "ArXiv": "2005.13799",
                "PubMedCentral": "8321083",
                "DOI": "10.3390/jimaging6060052",
                "CorpusId": 218972018,
                "PubMed": "34460598"
            },
            "abstract": "Deep learning methods have been very effective for a variety of medical diagnostic tasks and have even outperformed human experts on some of those. However, the black-box nature of the algorithms has restricted their clinical use. Recent explainability studies aim to show the features that influence the decision of a model the most. The majority of literature reviews of this area have focused on taxonomy, ethics, and the need for explanations. A review of the current applications of explainable deep learning for different medical imaging tasks is presented here. The various approaches, challenges for clinical deployment, and the areas requiring further research are discussed here from a practical standpoint of a deep learning researcher designing a system for the clinical end-users.",
            "referenceCount": 78,
            "citationCount": 324,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/2313-433X/6/6/52/pdf?version=1592748384",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2020-05-28",
            "journal": {
                "name": "Journal of Imaging",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Singh2020ExplainableDL,\n author = {Amitojdeep Singh and S. Sengupta and V. Lakshminarayanan},\n booktitle = {Journal of Imaging},\n journal = {Journal of Imaging},\n title = {Explainable Deep Learning Models in Medical Image Analysis},\n volume = {6},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:91cfd15b587c5ed604e7e49326db6d045276c2a5",
            "@type": "ScholarlyArticle",
            "paperId": "91cfd15b587c5ed604e7e49326db6d045276c2a5",
            "corpusId": 220496063,
            "url": "https://www.semanticscholar.org/paper/91cfd15b587c5ed604e7e49326db6d045276c2a5",
            "title": "The Computational Limits of Deep Learning",
            "venue": "Ninth Computing within Limits 2023",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3041148953",
                "ArXiv": "2007.05558",
                "DBLP": "journals/corr/abs-2007-05558",
                "DOI": "10.21428/bf6fb269.1f033948",
                "CorpusId": 220496063
            },
            "abstract": "Deep learning's recent history has been one of achievement: from triumphing over humans in the game of Go to world-leading performance in image recognition, voice recognition, translation, and other tasks. But this progress has come with a voracious appetite for computing power. This article reports on the computational demands of Deep Learning applications in five prominent application areas and shows that progress in all five is strongly reliant on increases in computing power. Extrapolating forward this reliance reveals that progress along current lines is rapidly becoming economically, technically, and environmentally unsustainable. Thus, continued progress in these applications will require dramatically more computationally-efficient methods, which will either have to come from changes to deep learning or from moving to other machine learning methods.",
            "referenceCount": 183,
            "citationCount": 322,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://limits.pubpub.org/pub/wm1lwjce/download/pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-07-10",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2007.05558"
            },
            "citationStyles": {
                "bibtex": "@Article{Thompson2020TheCL,\n author = {Neil C. Thompson and Kristjan H. Greenewald and Keeheon Lee and Gabriel F. Manso},\n booktitle = {Ninth Computing within Limits 2023},\n journal = {ArXiv},\n title = {The Computational Limits of Deep Learning},\n volume = {abs/2007.05558},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a0d18dddaa995b126ad373e33767b9b881d16b2f",
            "@type": "ScholarlyArticle",
            "paperId": "a0d18dddaa995b126ad373e33767b9b881d16b2f",
            "corpusId": 211554002,
            "url": "https://www.semanticscholar.org/paper/a0d18dddaa995b126ad373e33767b9b881d16b2f",
            "title": "An Introductory Review of Deep Learning for Prediction Models With Big Data",
            "venue": "Frontiers in Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:6a8c0041-d0b7-4e32-b52c-33adef005c7e",
                "name": "Frontiers in Artificial Intelligence",
                "alternate_names": [
                    "Front Artif Intell"
                ],
                "issn": "2624-8212",
                "url": "https://www.frontiersin.org/journals/artificial-intelligence#"
            },
            "year": 2020,
            "externalIds": {
                "PubMedCentral": "7861305",
                "DBLP": "journals/frai/Emmert-StreibYF20",
                "MAG": "3006781240",
                "DOI": "10.3389/frai.2020.00004",
                "CorpusId": 211554002,
                "PubMed": "33733124"
            },
            "abstract": "Deep learning models stand for a new learning paradigm in artificial intelligence (AI) and machine learning. Recent breakthrough results in image analysis and speech recognition have generated a massive interest in this field because also applications in many other domains providing big data seem possible. On a downside, the mathematical and computational methodology underlying deep learning models is very challenging, especially for interdisciplinary scientists. For this reason, we present in this paper an introductory review of deep learning approaches including Deep Feedforward Neural Networks (D-FFNN), Convolutional Neural Networks (CNNs), Deep Belief Networks (DBNs), Autoencoders (AEs), and Long Short-Term Memory (LSTM) networks. These models form the major core architectures of deep learning models currently used and should belong in any data scientist's toolbox. Importantly, those core architectural building blocks can be composed flexibly\u2014in an almost Lego-like manner\u2014to build new application-specific network architectures. Hence, a basic understanding of these network architectures is important to be prepared for future developments in AI.",
            "referenceCount": 158,
            "citationCount": 294,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.frontiersin.org/articles/10.3389/frai.2020.00004/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2020-02-28",
            "journal": {
                "name": "Frontiers in Artificial Intelligence",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Emmert-Streib2020AnIR,\n author = {F. Emmert-Streib and Zhenyi Yang and Han Feng and S. Tripathi and M. Dehmer},\n booktitle = {Frontiers in Artificial Intelligence},\n journal = {Frontiers in Artificial Intelligence},\n title = {An Introductory Review of Deep Learning for Prediction Models With Big Data},\n volume = {3},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9ebb28851b253817f9a0ea5ddc22b0fd9a934a2f",
            "@type": "ScholarlyArticle",
            "paperId": "9ebb28851b253817f9a0ea5ddc22b0fd9a934a2f",
            "corpusId": 215416034,
            "url": "https://www.semanticscholar.org/paper/9ebb28851b253817f9a0ea5ddc22b0fd9a934a2f",
            "title": "Deep Learning--based Text Classification",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3015777882",
                "DBLP": "journals/csur/MinaeeKCNCG21",
                "ArXiv": "2004.03705",
                "DOI": "10.1145/3439726",
                "CorpusId": 215416034
            },
            "abstract": "Deep learning--based models have surpassed classical machine learning--based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this article, we provide a comprehensive review of more than 150 deep learning--based models for text classification developed in recent years, and we discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and we discuss future research directions.",
            "referenceCount": 241,
            "citationCount": 436,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-04-06",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "54"
            },
            "citationStyles": {
                "bibtex": "@Article{Minaee2020DeepLT,\n author = {Shervin Minaee and Nal Kalchbrenner and E. Cambria and Narjes Nikzad and M. Chenaghlu and Jianfeng Gao},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 40},\n title = {Deep Learning--based Text Classification},\n volume = {54},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8a5d0579590465494c9aba58a857af43b190b6a6",
            "@type": "ScholarlyArticle",
            "paperId": "8a5d0579590465494c9aba58a857af43b190b6a6",
            "corpusId": 3887658,
            "url": "https://www.semanticscholar.org/paper/8a5d0579590465494c9aba58a857af43b190b6a6",
            "title": "Deep Learning in Mobile and Wireless Networking: A Survey",
            "venue": "IEEE Communications Surveys and Tutorials",
            "publicationVenue": {
                "id": "urn:research:95d0dda7-5d58-4afd-b59f-315447b81992",
                "name": "IEEE Communications Surveys and Tutorials",
                "alternate_names": [
                    "IEEE Commun Surv Tutor"
                ],
                "issn": "1553-877X",
                "url": "http://www.comsoc.org/cst"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2793198093",
                "DBLP": "journals/corr/abs-1803-04311",
                "ArXiv": "1803.04311",
                "DOI": "10.1109/COMST.2019.2904897",
                "CorpusId": 3887658
            },
            "abstract": "The rapid uptake of mobile devices and the rising popularity of mobile applications and services pose unprecedented demands on mobile and wireless networking infrastructure. Upcoming 5G systems are evolving to support exploding mobile traffic volumes, real-time extraction of fine-grained analytics, and agile management of network resources, so as to maximize user experience. Fulfilling these tasks is challenging, as mobile environments are increasingly complex, heterogeneous, and evolving. One potential solution is to resort to advanced machine learning techniques, in order to help manage the rise in data volumes and algorithm-driven applications. The recent success of deep learning underpins new and powerful tools that tackle problems in this space. In this paper, we bridge the gap between deep learning and mobile and wireless networking research, by presenting a comprehensive survey of the crossovers between the two areas. We first briefly introduce essential background and state-of-the-art in deep learning techniques with potential applications to networking. We then discuss several techniques and platforms that facilitate the efficient deployment of deep learning onto mobile systems. Subsequently, we provide an encyclopedic review of mobile and wireless networking research based on deep learning, which we categorize by different domains. Drawing from our experience, we discuss how to tailor deep learning to mobile environments. We complete this survey by pinpointing current challenges and open future directions for research.",
            "referenceCount": 581,
            "citationCount": 1084,
            "influentialCitationCount": 55,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pure.ed.ac.uk/ws/files/81194497/comst19.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-03-12",
            "journal": {
                "name": "IEEE Communications Surveys & Tutorials",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018DeepLI,\n author = {Chaoyun Zhang and P. Patras and H. Haddadi},\n booktitle = {IEEE Communications Surveys and Tutorials},\n journal = {IEEE Communications Surveys & Tutorials},\n pages = {2224-2287},\n title = {Deep Learning in Mobile and Wireless Networking: A Survey},\n volume = {21},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:516e2710083c20762711d3f5a6cbc1657f625ca0",
            "@type": "ScholarlyArticle",
            "paperId": "516e2710083c20762711d3f5a6cbc1657f625ca0",
            "corpusId": 230617617,
            "url": "https://www.semanticscholar.org/paper/516e2710083c20762711d3f5a6cbc1657f625ca0",
            "title": "Deep learning for tomographic image reconstruction",
            "venue": "Nature Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:6457124b-39bf-4d02-bff4-73752ff21562",
                "name": "Nature Machine Intelligence",
                "alternate_names": [
                    "Nat Mach Intell"
                ],
                "issn": "2522-5839",
                "url": "https://www.nature.com/natmachintell/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/natmi/WangYM20",
                "MAG": "3112965401",
                "DOI": "10.1038/s42256-020-00273-z",
                "CorpusId": 230617617
            },
            "abstract": null,
            "referenceCount": 150,
            "citationCount": 237,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-12-01",
            "journal": {
                "name": "Nature Machine Intelligence",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2020DeepLF,\n author = {Ge Wang and J. C. Ye and B. D. Man},\n booktitle = {Nature Machine Intelligence},\n journal = {Nature Machine Intelligence},\n pages = {737 - 748},\n title = {Deep learning for tomographic image reconstruction},\n volume = {2},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4c7c70760029e813ef76ea5a578174d2d3ec1490",
            "@type": "ScholarlyArticle",
            "paperId": "4c7c70760029e813ef76ea5a578174d2d3ec1490",
            "corpusId": 212748233,
            "url": "https://www.semanticscholar.org/paper/4c7c70760029e813ef76ea5a578174d2d3ec1490",
            "title": "A Survey on Deep Learning for Multimodal Data Fusion",
            "venue": "Neural Computation",
            "publicationVenue": {
                "id": "urn:research:69b9bcdd-8229-4a00-a6e0-00f0e99a2bf3",
                "name": "Neural Computation",
                "alternate_names": [
                    "Neural Comput"
                ],
                "issn": "0899-7667",
                "url": "http://cognet.mit.edu/library/journals/journal?issn=08997667"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3011727199",
                "DBLP": "journals/neco/GaoLCZ20",
                "DOI": "10.1162/neco_a_01273",
                "CorpusId": 212748233,
                "PubMed": "32186998"
            },
            "abstract": "With the wide deployments of heterogeneous networks, huge amounts of data with characteristics of high volume, high variety, high velocity, and high veracity are generated. These data, referred to multimodal big data, contain abundant intermodality and cross-modality information and pose vast challenges on traditional data fusion methods. In this review, we present some pioneering deep learning models to fuse these multimodal big data. With the increasing exploration of the multimodal big data, there are still some challenges to be addressed. Thus, this review presents a survey on deep learning for multimodal data fusion to provide readers, regardless of their original community, with the fundamentals of multimodal deep learning fusion method and to motivate new multimodal data fusion techniques of deep learning. Specifically, representative architectures that are widely used are summarized as fundamental to the understanding of multimodal deep learning. Then the current pioneering multimodal data fusion deep learning models are summarized. Finally, some challenges and future topics of multimodal data fusion deep learning models are described.",
            "referenceCount": 96,
            "citationCount": 255,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://direct.mit.edu/neco/article-pdf/32/5/829/1865303/neco_a_01273.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-03-18",
            "journal": {
                "name": "Neural Computation",
                "volume": "32"
            },
            "citationStyles": {
                "bibtex": "@Article{Gao2020ASO,\n author = {Jing Gao and Peng Li and Zhikui Chen and Jianing Zhang},\n booktitle = {Neural Computation},\n journal = {Neural Computation},\n pages = {829-864},\n title = {A Survey on Deep Learning for Multimodal Data Fusion},\n volume = {32},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d12fd94337ac804470dc78911e74b5b6480eef8e",
            "@type": "ScholarlyArticle",
            "paperId": "d12fd94337ac804470dc78911e74b5b6480eef8e",
            "corpusId": 209314627,
            "url": "https://www.semanticscholar.org/paper/d12fd94337ac804470dc78911e74b5b6480eef8e",
            "title": "Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "2995464762",
                "ArXiv": "2002.06470",
                "DBLP": "conf/iclr/AshukhaLMV20",
                "CorpusId": 209314627
            },
            "abstract": "Uncertainty estimation and ensembling methods go hand-in-hand. Uncertainty estimation is one of the main benchmarks for assessment of ensembling performance. At the same time, deep learning ensembles have provided state-of-the-art results in uncertainty estimation. In this work, we focus on in-domain uncertainty for image classification. We explore the standards for its quantification and point out pitfalls of existing metrics. Avoiding these pitfalls, we perform a broad study of different ensembling techniques. To provide more insight in the broad comparison, we introduce the deep ensemble equivalent (DEE) and show that many sophisticated ensembling techniques are equivalent to an ensemble of very few independently trained networks in terms of the test log-likelihood.",
            "referenceCount": 60,
            "citationCount": 243,
            "influentialCitationCount": 25,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-02-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2002.06470"
            },
            "citationStyles": {
                "bibtex": "@Article{Ashukha2020PitfallsOI,\n author = {Arsenii Ashukha and Alexander Lyzhov and Dmitry Molchanov and D. Vetrov},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning},\n volume = {abs/2002.06470},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:59e0095a68dcd03192b39e29ab6a3dfc6fd0b7c3",
            "@type": "ScholarlyArticle",
            "paperId": "59e0095a68dcd03192b39e29ab6a3dfc6fd0b7c3",
            "corpusId": 223773845,
            "url": "https://www.semanticscholar.org/paper/59e0095a68dcd03192b39e29ab6a3dfc6fd0b7c3",
            "title": "Deep learning for the design of photonic structures",
            "venue": "Nature Photonics",
            "publicationVenue": {
                "id": "urn:research:0c0297e9-ab23-460d-9958-1bf4b91dcf34",
                "name": "Nature Photonics",
                "alternate_names": [
                    "Nat Photonics"
                ],
                "issn": "1749-4885",
                "url": "http://www.nature.com/naturephotonics"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3092323705",
                "DOI": "10.1038/s41566-020-0685-y",
                "CorpusId": 223773845
            },
            "abstract": null,
            "referenceCount": 114,
            "citationCount": 425,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2020-10-05",
            "journal": {
                "name": "Nature Photonics",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Ma2020DeepLF,\n author = {Wei Ma and Zhaocheng Liu and Z. Kudyshev and A. Boltasseva and W. Cai and Yongmin Liu},\n booktitle = {Nature Photonics},\n journal = {Nature Photonics},\n pages = {1-14},\n title = {Deep learning for the design of photonic structures},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:78989616eeeac55b202e3e4205225e7135054185",
            "@type": "ScholarlyArticle",
            "paperId": "78989616eeeac55b202e3e4205225e7135054185",
            "corpusId": 5224205,
            "url": "https://www.semanticscholar.org/paper/78989616eeeac55b202e3e4205225e7135054185",
            "title": "An Introduction to Deep Learning for the Physical Layer",
            "venue": "IEEE Transactions on Cognitive Communications and Networking",
            "publicationVenue": {
                "id": "urn:research:65e58b80-9699-4da6-bd60-929b57b8533d",
                "name": "IEEE Transactions on Cognitive Communications and Networking",
                "alternate_names": [
                    "IEEE Trans Cogn Commun Netw"
                ],
                "issn": "2332-7731",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6687307"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1702.00832",
                "MAG": "2950937143",
                "DBLP": "journals/tccn/OSheaH17",
                "DOI": "10.1109/TCCN.2017.2758370",
                "CorpusId": 5224205
            },
            "abstract": "We present and discuss several novel applications of deep learning for the physical layer. By interpreting a communications system as an autoencoder, we develop a fundamental new way to think about communications system design as an end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver components in a single process. We show how this idea can be extended to networks of multiple transmitters and receivers and present the concept of radio transformer networks as a means to incorporate expert domain knowledge in the machine learning model. Lastly, we demonstrate the application of convolutional neural networks on raw IQ samples for modulation classification which achieves competitive accuracy with respect to traditional schemes relying on expert features. This paper is concluded with a discussion of open challenges and areas for future investigation.",
            "referenceCount": 78,
            "citationCount": 1807,
            "influentialCitationCount": 166,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1702.00832",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-02-02",
            "journal": {
                "name": "IEEE Transactions on Cognitive Communications and Networking",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{O'Shea2017AnIT,\n author = {Tim O'Shea and J. Hoydis},\n booktitle = {IEEE Transactions on Cognitive Communications and Networking},\n journal = {IEEE Transactions on Cognitive Communications and Networking},\n pages = {563-575},\n title = {An Introduction to Deep Learning for the Physical Layer},\n volume = {3},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6b67e38e488cdb6a5af8ae44fdbb2c069c9cea0e",
            "@type": "ScholarlyArticle",
            "paperId": "6b67e38e488cdb6a5af8ae44fdbb2c069c9cea0e",
            "corpusId": 216022295,
            "url": "https://www.semanticscholar.org/paper/6b67e38e488cdb6a5af8ae44fdbb2c069c9cea0e",
            "title": "Introduction to Machine Learning, Neural Networks, and Deep Learning",
            "venue": "Translational Vision Science & Technology",
            "publicationVenue": {
                "id": "urn:research:faac363d-9835-4bf0-a7a6-38b1a494b1aa",
                "name": "Translational Vision Science & Technology",
                "alternate_names": [
                    "Transl Vis Sci  Technol"
                ],
                "issn": "2164-2591",
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "PubMedCentral": "7347027",
                "MAG": "3009207988",
                "DOI": "10.1167/tvst.9.2.14",
                "CorpusId": 216022295,
                "PubMed": "32704420"
            },
            "abstract": "Purpose To present an overview of current machine learning methods and their use in medical research, focusing on select machine learning techniques, best practices, and deep learning. Methods A systematic literature search in PubMed was performed for articles pertinent to the topic of artificial intelligence methods used in medicine with an emphasis on ophthalmology. Results A review of machine learning and deep learning methodology for the audience without an extensive technical computer programming background. Conclusions Artificial intelligence has a promising future in medicine; however, many challenges remain. Translational Relevance The aim of this review article is to provide the nontechnical readers a layman's explanation of the machine learning methods being used in medicine today. The goal is to provide the reader a better understanding of the potential and challenges of artificial intelligence within the field of medicine.",
            "referenceCount": 34,
            "citationCount": 225,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2020-01-28",
            "journal": {
                "name": "Translational Vision Science & Technology",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Choi2020IntroductionTM,\n author = {Rene Y. Choi and Aaron S. Coyner and Jayashree Kalpathy-Cramer and M. Chiang and J. Campbell},\n booktitle = {Translational Vision Science & Technology},\n journal = {Translational Vision Science & Technology},\n title = {Introduction to Machine Learning, Neural Networks, and Deep Learning},\n volume = {9},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4f2e84f1c5ea7a0d5d8ebfa12a78a869f13d7b59",
            "@type": "ScholarlyArticle",
            "paperId": "4f2e84f1c5ea7a0d5d8ebfa12a78a869f13d7b59",
            "corpusId": 69301183,
            "url": "https://www.semanticscholar.org/paper/4f2e84f1c5ea7a0d5d8ebfa12a78a869f13d7b59",
            "title": "Deep Learning, Neural Networks",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2888906421",
                "DOI": "10.1007/978-3-319-72347-1_23",
                "CorpusId": 69301183
            },
            "abstract": null,
            "referenceCount": 4,
            "citationCount": 1229,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Dinov2018DeepLN,\n author = {I. Dinov},\n pages = {765-817},\n title = {Deep Learning, Neural Networks},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:775247047d0b56950ba5ea77d4a29772eca95c1b",
            "@type": "ScholarlyArticle",
            "paperId": "775247047d0b56950ba5ea77d4a29772eca95c1b",
            "corpusId": 220363945,
            "url": "https://www.semanticscholar.org/paper/775247047d0b56950ba5ea77d4a29772eca95c1b",
            "title": "Deep Learning for Anomaly Detection",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3040266635",
                "ArXiv": "2007.02500",
                "DBLP": "journals/csur/PangSCH21",
                "DOI": "10.1145/3439950",
                "CorpusId": 220363945
            },
            "abstract": "Anomaly detection, a.k.a. outlier detection or novelty detection, has been a lasting yet active research area in various research communities for several decades. There are still some unique problem complexities and challenges that require advanced approaches. In recent years, deep learning enabled anomaly detection, i.e., deep anomaly detection, has emerged as a critical direction. This article surveys the research of deep anomaly detection with a comprehensive taxonomy, covering advancements in 3 high-level categories and 11 fine-grained categories of the methods. We review their key intuitions, objective functions, underlying assumptions, advantages, and disadvantages and discuss how they address the aforementioned challenges. We further discuss a set of possible future opportunities and new perspectives on addressing the challenges.",
            "referenceCount": 183,
            "citationCount": 445,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-07-06",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "54"
            },
            "citationStyles": {
                "bibtex": "@Article{Pang2020DeepLF,\n author = {Guansong Pang and Chunhua Shen and Longbing Cao and A. Hengel},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 38},\n title = {Deep Learning for Anomaly Detection},\n volume = {54},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3087b58cbfc6eb4a3076a180e21d6b872293f9a8",
            "@type": "ScholarlyArticle",
            "paperId": "3087b58cbfc6eb4a3076a180e21d6b872293f9a8",
            "corpusId": 38948903,
            "url": "https://www.semanticscholar.org/paper/3087b58cbfc6eb4a3076a180e21d6b872293f9a8",
            "title": "Deep Learning with Python",
            "venue": "Apress",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2605516844",
                "DOI": "10.1007/978-1-4842-2766-4",
                "CorpusId": 38948903
            },
            "abstract": null,
            "referenceCount": 1,
            "citationCount": 1705,
            "influentialCitationCount": 171,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Ketkar2017DeepLW,\n author = {Nikhil S. Ketkar},\n booktitle = {Apress},\n title = {Deep Learning with Python},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:340712391e245e245a76cd74523c1d6443035b62",
            "@type": "ScholarlyArticle",
            "paperId": "340712391e245e245a76cd74523c1d6443035b62",
            "corpusId": 210948532,
            "url": "https://www.semanticscholar.org/paper/340712391e245e245a76cd74523c1d6443035b62",
            "title": "The unreasonable effectiveness of deep learning in artificial intelligence",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2002.04806",
                "DBLP": "journals/corr/abs-2002-04806",
                "MAG": "3004368638",
                "DOI": "10.1073/pnas.1907373117",
                "CorpusId": 210948532,
                "PubMed": "31992643"
            },
            "abstract": "Deep learning networks have been trained to recognize speech, caption photographs, and translate text between languages at high levels of performance. Although applications of deep learning networks to real-world problems have become ubiquitous, our understanding of why they are so effective is lacking. These empirical results should not be possible according to sample complexity in statistics and nonconvex optimization theory. However, paradoxes in the training and effectiveness of deep learning networks are being investigated and insights are being found in the geometry of high-dimensional spaces. A mathematical theory of deep learning would illuminate how they function, allow us to assess the strengths and weaknesses of different network architectures, and lead to major improvements. Deep learning has provided natural ways for humans to communicate with digital devices and is foundational for building artificial general intelligence. Deep learning was inspired by the architecture of the cerebral cortex and insights into autonomy and general intelligence may be found in other brain regions that are essential for planning and survival, but major breakthroughs will be needed to achieve these goals.",
            "referenceCount": 46,
            "citationCount": 230,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pnas.org/content/pnas/117/48/30033.full.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Biology",
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-01-28",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences",
                "volume": "117"
            },
            "citationStyles": {
                "bibtex": "@Article{Sejnowski2020TheUE,\n author = {T. Sejnowski},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {30033 - 30038},\n title = {The unreasonable effectiveness of deep learning in artificial intelligence},\n volume = {117},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:60df2f3598ea7d56ae24a649121907a6769eb444",
            "@type": "ScholarlyArticle",
            "paperId": "60df2f3598ea7d56ae24a649121907a6769eb444",
            "corpusId": 213929373,
            "url": "https://www.semanticscholar.org/paper/60df2f3598ea7d56ae24a649121907a6769eb444",
            "title": "Deep learning enabled inverse design in nanophotonics",
            "venue": "Nanophotonics",
            "publicationVenue": {
                "id": "urn:research:f925d1c5-6d57-49be-b903-c0ea27de720c",
                "name": "Nanophotonics",
                "alternate_names": null,
                "issn": "2192-8614",
                "url": "https://www.degruyter.com/view/j/nanoph"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3008967825",
                "DOI": "10.1515/nanoph-2019-0474",
                "CorpusId": 213929373
            },
            "abstract": "Abstract Deep learning has become the dominant approach in artificial intelligence to solve complex data-driven problems. Originally applied almost exclusively in computer-science areas such as image analysis and nature language processing, deep learning has rapidly entered a wide variety of scientific fields including physics, chemistry and material science. Very recently, deep neural networks have been introduced in the field of nanophotonics as a powerful way of obtaining the nonlinear mapping between the topology and composition of arbitrary nanophotonic structures and their associated functional properties. In this paper, we have discussed the recent progress in the application of deep learning to the inverse design of nanophotonic devices, mainly focusing on the three existing learning paradigms of supervised-, unsupervised-, and reinforcement learning. Deep learning forward modelling i.e. how artificial intelligence learns how to solve Maxwell\u2019s equations, is also discussed, along with an outlook of this rapidly evolving research area.",
            "referenceCount": 100,
            "citationCount": 252,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.degruyter.com/document/doi/10.1515/nanoph-2019-0474/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2020-02-17",
            "journal": {
                "name": "Nanophotonics",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{So2020DeepLE,\n author = {Sunae So and Trevon Badloe and Jae-Kyo Noh and J. Bravo-Abad and J. Rho},\n booktitle = {Nanophotonics},\n journal = {Nanophotonics},\n pages = {1041 - 1057},\n title = {Deep learning enabled inverse design in nanophotonics},\n volume = {9},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:441555b5cd09703e55c03e70bd2c9f82c0ffcf9b",
            "@type": "ScholarlyArticle",
            "paperId": "441555b5cd09703e55c03e70bd2c9f82c0ffcf9b",
            "corpusId": 201124533,
            "url": "https://www.semanticscholar.org/paper/441555b5cd09703e55c03e70bd2c9f82c0ffcf9b",
            "title": "Deep High-Resolution Representation Learning for Visual Recognition",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3014641072",
                "ArXiv": "1908.07919",
                "DBLP": "journals/pami/00010CJDZ0MTW0X21",
                "DOI": "10.1109/TPAMI.2020.2983686",
                "CorpusId": 201124533,
                "PubMed": "32248092"
            },
            "abstract": "High-resolution representations are essential for position-sensitive vision problems, such as human pose estimation, semantic segmentation, and object detection. Existing state-of-the-art frameworks first encode the input image as a low-resolution representation through a subnetwork that is formed by connecting high-to-low resolution convolutions in series (e.g., ResNet, VGGNet), and then recover the high-resolution representation from the encoded low-resolution representation. Instead, our proposed network, named as High-Resolution Network (HRNet), maintains high-resolution representations through the whole process. There are two key characteristics: (i) Connect the high-to-low resolution convolution streams in parallel and (ii) repeatedly exchange the information across resolutions. The benefit is that the resulting representation is semantically richer and spatially more precise. We show the superiority of the proposed HRNet in a wide range of applications, including human pose estimation, semantic segmentation, and object detection, suggesting that the HRNet is a stronger backbone for computer vision problems. All the codes are available at https://github.com/HRNet.",
            "referenceCount": 195,
            "citationCount": 2128,
            "influentialCitationCount": 393,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://research-repository.griffith.edu.au/bitstream/10072/400575/2/Zhao457045-Accepted.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-08-20",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "43"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2019DeepHR,\n author = {Jingdong Wang and Ke Sun and Tianheng Cheng and Borui Jiang and Chaorui Deng and Yang Zhao and Dong Liu and Yadong Mu and Mingkui Tan and Xinggang Wang and Wenyu Liu and Bin Xiao},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {3349-3364},\n title = {Deep High-Resolution Representation Learning for Visual Recognition},\n volume = {43},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:09e48adf1a3f012ec56fbb4f92acae975ee43d87",
            "@type": "ScholarlyArticle",
            "paperId": "09e48adf1a3f012ec56fbb4f92acae975ee43d87",
            "corpusId": 211198747,
            "url": "https://www.semanticscholar.org/paper/09e48adf1a3f012ec56fbb4f92acae975ee43d87",
            "title": "A Deep Learning Approach to Antibiotic Discovery",
            "venue": "Cell",
            "publicationVenue": {
                "id": "urn:research:e4782337-db2d-4ab2-8eda-a71d1c60709b",
                "name": "Cell",
                "alternate_names": [
                    "La Cellule"
                ],
                "issn": "0092-8674",
                "url": "https://www.cell.com/"
            },
            "year": 2020,
            "externalIds": {
                "DOI": "10.1016/j.cell.2020.04.001",
                "CorpusId": 211198747,
                "PubMed": "32302574"
            },
            "abstract": null,
            "referenceCount": 72,
            "citationCount": 976,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cell.com/article/S0092867420303962/pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2020-04-01",
            "journal": {
                "name": "Cell",
                "volume": "181"
            },
            "citationStyles": {
                "bibtex": "@Article{Stokes2020ADL,\n author = {Jonathan M Stokes and Kevin Yang and Kyle Swanson and Wengong Jin and Andre\u0301s Cubillos-Ruiz and Nina M. Donghia and C. MacNair and S. French and L. Carfrae and Zohar Bloom-Ackermann and Victoria M. Tran and Anush Chiappino-Pepe and A. Badran and Ian W. Andrews and Emma J. Chory and G. Church and E. Brown and T. Jaakkola and R. Barzilay and J. Collins},\n booktitle = {Cell},\n journal = {Cell},\n pages = {475-483},\n title = {A Deep Learning Approach to Antibiotic Discovery},\n volume = {181},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2d6b4e247070db1b9b890705802e4f1e58476baf",
            "@type": "ScholarlyArticle",
            "paperId": "2d6b4e247070db1b9b890705802e4f1e58476baf",
            "corpusId": 219608083,
            "url": "https://www.semanticscholar.org/paper/2d6b4e247070db1b9b890705802e4f1e58476baf",
            "title": "A review of object detection based on deep learning",
            "venue": "Multimedia tools and applications",
            "publicationVenue": {
                "id": "urn:research:477368e9-7a8e-475a-8c93-6d623797fd06",
                "name": "Multimedia tools and applications",
                "alternate_names": [
                    "Multimedia Tools and Applications",
                    "Multimedia Tool Appl",
                    "Multimedia tool appl"
                ],
                "issn": "1380-7501",
                "url": "https://www.springer.com/computer/information+systems+and+applications/journal/11042"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3034745255",
                "DBLP": "journals/mta/XiaoTYZLDL20",
                "DOI": "10.1007/s11042-020-08976-6",
                "CorpusId": 219608083
            },
            "abstract": null,
            "referenceCount": 297,
            "citationCount": 205,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-06-12",
            "journal": {
                "name": "Multimedia Tools and Applications",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Xiao2020ARO,\n author = {Youzi Xiao and Zhiqiang Tian and Jiachen Yu and Yinshu Zhang and Shuai Liu and S. Du and Xuguang Lan},\n booktitle = {Multimedia tools and applications},\n journal = {Multimedia Tools and Applications},\n pages = {1-63},\n title = {A review of object detection based on deep learning},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f49f37c23158f8b698545e6f0a25877b39601ce8",
            "@type": "ScholarlyArticle",
            "paperId": "f49f37c23158f8b698545e6f0a25877b39601ce8",
            "corpusId": 139164978,
            "url": "https://www.semanticscholar.org/paper/f49f37c23158f8b698545e6f0a25877b39601ce8",
            "title": "Review of Deep Learning Algorithms and Architectures",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/access/ShresthaM19",
                "MAG": "2942231644",
                "DOI": "10.1109/ACCESS.2019.2912200",
                "CorpusId": 139164978
            },
            "abstract": "Deep learning (DL) is playing an increasingly important role in our lives. It has already made a huge impact in areas, such as cancer diagnosis, precision medicine, self-driving cars, predictive forecasting, and speech recognition. The painstakingly handcrafted feature extractors used in traditional learning, classification, and pattern recognition systems are not scalable for large-sized data sets. In many cases, depending on the problem complexity, DL can also overcome the limitations of earlier shallow networks that prevented efficient training and abstractions of hierarchical representations of multi-dimensional training data. Deep neural network (DNN) uses multiple (deep) layers of units with highly optimized algorithms and architectures. This paper reviews several optimization methods to improve the accuracy of the training and to reduce training time. We delve into the math behind training algorithms used in recent deep networks. We describe current shortcomings, enhancements, and implementations. The review also covers different types of deep architectures, such as deep convolution networks, deep residual networks, recurrent neural networks, reinforcement learning, variational autoencoders, and others.",
            "referenceCount": 84,
            "citationCount": 833,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08694781.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-04-22",
            "journal": {
                "name": "IEEE Access",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Shrestha2019ReviewOD,\n author = {A. Shrestha and A. Mahmood},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {53040-53065},\n title = {Review of Deep Learning Algorithms and Architectures},\n volume = {7},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:40f56e1c57bdefb22a8b4a635ea40f7d37c72d27",
            "@type": "ScholarlyArticle",
            "paperId": "40f56e1c57bdefb22a8b4a635ea40f7d37c72d27",
            "corpusId": 169033851,
            "url": "https://www.semanticscholar.org/paper/40f56e1c57bdefb22a8b4a635ea40f7d37c72d27",
            "title": "Deep Learning Techniques for Medical Image Segmentation: Achievements and Challenges",
            "venue": "Journal of digital imaging",
            "publicationVenue": {
                "id": "urn:research:d97d3d34-0bc5-4a81-9542-b39361ecf3aa",
                "name": "Journal of digital imaging",
                "alternate_names": [
                    "Journal of Digital Imaging",
                    "J digit imaging",
                    "J Digit Imaging"
                ],
                "issn": "0897-1889",
                "url": "https://link.springer.com/journal/10278"
            },
            "year": 2019,
            "externalIds": {
                "PubMedCentral": "6646484",
                "DBLP": "journals/jdi/HesamianJHK19",
                "MAG": "2947263797",
                "DOI": "10.1007/s10278-019-00227-x",
                "CorpusId": 169033851,
                "PubMed": "31144149"
            },
            "abstract": null,
            "referenceCount": 96,
            "citationCount": 965,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s10278-019-00227-x.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-05-29",
            "journal": {
                "name": "Journal of Digital Imaging",
                "volume": "32"
            },
            "citationStyles": {
                "bibtex": "@Article{Hesamian2019DeepLT,\n author = {M. H. Hesamian and W. Jia and Xiangjian He and Paul J. Kennedy},\n booktitle = {Journal of digital imaging},\n journal = {Journal of Digital Imaging},\n pages = {582 - 596},\n title = {Deep Learning Techniques for Medical Image Segmentation: Achievements and Challenges},\n volume = {32},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a595767fa35bcc84362f629fbc4d2d9b05d7342a",
            "@type": "ScholarlyArticle",
            "paperId": "a595767fa35bcc84362f629fbc4d2d9b05d7342a",
            "corpusId": 204744017,
            "url": "https://www.semanticscholar.org/paper/a595767fa35bcc84362f629fbc4d2d9b05d7342a",
            "title": "A survey of deep learning techniques for autonomous driving",
            "venue": "J. Field Robotics",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/jfr/GrigorescuTCM20",
                "MAG": "2981207549",
                "ArXiv": "1910.07738",
                "DOI": "10.1002/rob.21918",
                "CorpusId": 204744017
            },
            "abstract": "The last decade witnessed increasingly rapid progress in self\u2010driving vehicle technology, mainly backed up by advances in the area of deep learning and artificial intelligence (AI). The objective of this paper is to survey the current state\u2010of\u2010the\u2010art on deep learning technologies used in autonomous driving. We start by presenting AI\u2010based self\u2010driving architectures, convolutional and recurrent neural networks, as well as the deep reinforcement learning paradigm. These methodologies form a base for the surveyed driving scene perception, path planning, behavior arbitration, and motion control algorithms. We investigate both the modular perception\u2010planning\u2010action pipeline, where each module is built using deep learning methods, as well as End2End systems, which directly map sensory information to steering commands. Additionally, we tackle current challenges encountered in designing AI architectures for autonomous driving, such as their safety, training data sources, and computational hardware. The comparison presented in this survey helps gain insight into the strengths and limitations of deep learning and AI approaches for autonomous driving and assist with design choices.",
            "referenceCount": 172,
            "citationCount": 888,
            "influentialCitationCount": 20,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1910.07738",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-10-17",
            "journal": {
                "name": "Journal of Field Robotics",
                "volume": "37"
            },
            "citationStyles": {
                "bibtex": "@Article{Grigorescu2019ASO,\n author = {S. Grigorescu and Bogdan Trasnea and Tiberiu T. Cocias and G. Macesanu},\n booktitle = {J. Field Robotics},\n journal = {Journal of Field Robotics},\n pages = {362 - 386},\n title = {A survey of deep learning techniques for autonomous driving},\n volume = {37},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d05d86db86a4ac0d95e6dcd951b42a9651939793",
            "@type": "ScholarlyArticle",
            "paperId": "d05d86db86a4ac0d95e6dcd951b42a9651939793",
            "corpusId": 115196194,
            "url": "https://www.semanticscholar.org/paper/d05d86db86a4ac0d95e6dcd951b42a9651939793",
            "title": "Deep Learning Approach for Intelligent Intrusion Detection System",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2926701059",
                "DBLP": "journals/access/VinayakumarASPA19",
                "DOI": "10.1109/ACCESS.2019.2895334",
                "CorpusId": 115196194
            },
            "abstract": "Machine learning techniques are being widely used to develop an intrusion detection system (IDS) for detecting and classifying cyberattacks at the network-level and the host-level in a timely and automatic manner. However, many challenges arise since malicious attacks are continually changing and are occurring in very large volumes requiring a scalable solution. There are different malware datasets available publicly for further research by cyber security community. However, no existing study has shown the detailed analysis of the performance of various machine learning algorithms on various publicly available datasets. Due to the dynamic nature of malware with continuously changing attacking methods, the malware datasets available publicly are to be updated systematically and benchmarked. In this paper, a deep neural network (DNN), a type of deep learning model, is explored to develop a flexible and effective IDS to detect and classify unforeseen and unpredictable cyberattacks. The continuous change in network behavior and rapid evolution of attacks makes it necessary to evaluate various datasets which are generated over the years through static and dynamic approaches. This type of study facilitates to identify the best algorithm which can effectively work in detecting future cyberattacks. A comprehensive evaluation of experiments of DNNs and other classical machine learning classifiers are shown on various publicly available benchmark malware datasets. The optimal network parameters and network topologies for DNNs are chosen through the following hyperparameter selection methods with KDDCup 99 dataset. All the experiments of DNNs are run till 1,000 epochs with the learning rate varying in the range [0.01\u20130.5]. The DNN model which performed well on KDDCup 99 is applied on other datasets, such as NSL-KDD, UNSW-NB15, Kyoto, WSN-DS, and CICIDS 2017, to conduct the benchmark. Our DNN model learns the abstract and high-dimensional feature representation of the IDS data by passing them into many hidden layers. Through a rigorous experimental testing, it is confirmed that DNNs perform well in comparison with the classical machine learning classifiers. Finally, we propose a highly scalable and hybrid DNNs framework called scale-hybrid-IDS-AlertNet which can be used in real-time to effectively monitor the network traffic and host-level events to proactively alert possible cyberattacks.",
            "referenceCount": 84,
            "citationCount": 795,
            "influentialCitationCount": 38,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08681044.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-04-03",
            "journal": {
                "name": "IEEE Access",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Vinayakumar2019DeepLA,\n author = {R. Vinayakumar and M. Alazab and K. Soman and P. Poornachandran and Ameer Al-Nemrat and S. Venkatraman},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {41525-41550},\n title = {Deep Learning Approach for Intelligent Intrusion Detection System},\n volume = {7},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5027a03ff0330ae12db99c30db9e1fe907af6faf",
            "@type": "ScholarlyArticle",
            "paperId": "5027a03ff0330ae12db99c30db9e1fe907af6faf",
            "corpusId": 202671983,
            "url": "https://www.semanticscholar.org/paper/5027a03ff0330ae12db99c30db9e1fe907af6faf",
            "title": "Deep learning for multi-year ENSO forecasts",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/nature/HamKL19",
                "MAG": "2973731563",
                "DOI": "10.1038/s41586-019-1559-7",
                "CorpusId": 202671983,
                "PubMed": "31534218"
            },
            "abstract": null,
            "referenceCount": 38,
            "citationCount": 529,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-09-01",
            "journal": {
                "name": "Nature",
                "volume": "573"
            },
            "citationStyles": {
                "bibtex": "@Article{Ham2019DeepLF,\n author = {Y. Ham and Jeong-Hwan Kim and Jing Luo},\n booktitle = {Nature},\n journal = {Nature},\n pages = {568 - 572},\n title = {Deep learning for multi-year ENSO forecasts},\n volume = {573},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b77b1fc188f3834541efbb75add8f1ea80fd6225",
            "@type": "ScholarlyArticle",
            "paperId": "b77b1fc188f3834541efbb75add8f1ea80fd6225",
            "corpusId": 207172033,
            "url": "https://www.semanticscholar.org/paper/b77b1fc188f3834541efbb75add8f1ea80fd6225",
            "title": "Segmentation-based deep-learning approach for surface-defect detection",
            "venue": "Journal of Intelligent Manufacturing",
            "publicationVenue": {
                "id": "urn:research:9c5296b3-9225-4538-9b2d-f8f178534aad",
                "name": "Journal of Intelligent Manufacturing",
                "alternate_names": [
                    "J Intell Manuf"
                ],
                "issn": "0956-5515",
                "url": "http://www.springer.com/business+&+management/production/journal/10845?changeHeader="
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1903.08536",
                "DBLP": "journals/corr/abs-1903-08536",
                "MAG": "2923486253",
                "DOI": "10.1007/s10845-019-01476-x",
                "CorpusId": 207172033
            },
            "abstract": null,
            "referenceCount": 28,
            "citationCount": 410,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1903.08536",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-20",
            "journal": {
                "name": "Journal of Intelligent Manufacturing",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Tabernik2019SegmentationbasedDA,\n author = {Domen Tabernik and Samo Sela and J. Skvarc and D. Sko\u010daj},\n booktitle = {Journal of Intelligent Manufacturing},\n journal = {Journal of Intelligent Manufacturing},\n pages = {759 - 776},\n title = {Segmentation-based deep-learning approach for surface-defect detection},\n volume = {31},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0ebc300c16f01a4e94c8551997922fdb67ac1951",
            "@type": "ScholarlyArticle",
            "paperId": "0ebc300c16f01a4e94c8551997922fdb67ac1951",
            "corpusId": 53753063,
            "url": "https://www.semanticscholar.org/paper/0ebc300c16f01a4e94c8551997922fdb67ac1951",
            "title": "An overview of deep learning in medical imaging focusing on MRI",
            "venue": "Zeitschrift f\u00fcr Medizinische Physik",
            "publicationVenue": {
                "id": "urn:research:40e28789-22d5-4089-a401-73cae0726cc1",
                "name": "Zeitschrift f\u00fcr Medizinische Physik",
                "alternate_names": [
                    "Z Med Phys",
                    "Z Fur Med Phys",
                    "Zeitschrift Fur Medizinische Physik"
                ],
                "issn": "0040-5973",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/701805/description#description"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "3105282616",
                "ArXiv": "1811.10052",
                "DBLP": "journals/corr/abs-1811-10052",
                "DOI": "10.1016/j.zemedi.2018.11.002",
                "CorpusId": 53753063,
                "PubMed": "30553609"
            },
            "abstract": null,
            "referenceCount": 367,
            "citationCount": 1262,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-11-25",
            "journal": {
                "name": "Zeitschrift fur medizinische Physik",
                "volume": "29 2"
            },
            "citationStyles": {
                "bibtex": "@Article{Lundervold2018AnOO,\n author = {A. Lundervold and A. Lundervold},\n booktitle = {Zeitschrift f\u00fcr Medizinische Physik},\n journal = {Zeitschrift fur medizinische Physik},\n pages = {\n          102-127\n        },\n title = {An overview of deep learning in medical imaging focusing on MRI},\n volume = {29 2},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:17750e76d4d3a33b1eada72f39238acd0246bd37",
            "@type": "ScholarlyArticle",
            "paperId": "17750e76d4d3a33b1eada72f39238acd0246bd37",
            "corpusId": 174797734,
            "url": "https://www.semanticscholar.org/paper/17750e76d4d3a33b1eada72f39238acd0246bd37",
            "title": "A comprehensive study on deep learning bug characteristics",
            "venue": "ESEC/SIGSOFT FSE",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1906.01388",
                "MAG": "2948096068",
                "DBLP": "conf/sigsoft/IslamNPR19",
                "DOI": "10.1145/3338906.3338955",
                "CorpusId": 174797734
            },
            "abstract": "Deep learning has gained substantial popularity in recent years. Developers mainly rely on libraries and tools to add deep learning capabilities to their software. What kinds of bugs are frequently found in such software? What are the root causes of such bugs? What impacts do such bugs have? Which stages of deep learning pipeline are more bug prone? Are there any antipatterns? Understanding such characteristics of bugs in deep learning software has the potential to foster the development of better deep learning platforms, debugging mechanisms, development practices, and encourage the development of analysis and verification frameworks. Therefore, we study 2716 high-quality posts from Stack Overflow and 500 bug fix commits from Github about five popular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch to understand the types of bugs, root causes of bugs, impacts of bugs, bug-prone stage of deep learning pipeline as well as whether there are some common antipatterns found in this buggy software. The key findings of our study include: data bug and logic bug are the most severe bug types in deep learning software appearing more than 48% of the times, major root causes of these bugs are Incorrect Model Parameter (IPS) and Structural Inefficiency (SI) showing up more than 43% of the times.We have also found that the bugs in the usage of deep learning libraries have some common antipatterns.",
            "referenceCount": 30,
            "citationCount": 199,
            "influentialCitationCount": 43,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3338906.3338955",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book"
            ],
            "publicationDate": "2019-06-03",
            "journal": {
                "name": "Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Islam2019ACS,\n author = {Md Johirul Islam and Giang Nguyen and Rangeet Pan and Hridesh Rajan},\n booktitle = {ESEC/SIGSOFT FSE},\n journal = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},\n title = {A comprehensive study on deep learning bug characteristics},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:af3825437b627db1a99f946f7aa773ba8b03befd",
            "@type": "ScholarlyArticle",
            "paperId": "af3825437b627db1a99f946f7aa773ba8b03befd",
            "corpusId": 52055130,
            "url": "https://www.semanticscholar.org/paper/af3825437b627db1a99f946f7aa773ba8b03befd",
            "title": "Learning deep representations by mutual information estimation and maximization",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2951873722",
                "DBLP": "conf/iclr/HjelmFLGBTB19",
                "ArXiv": "1808.06670",
                "CorpusId": 52055130
            },
            "abstract": "This work investigates unsupervised learning of representations by maximizing mutual information between an input and the output of a deep neural network encoder. Importantly, we show that structure matters: incorporating knowledge about locality in the input into the objective can significantly improve a representation\u2019s suitability for downstream tasks. We further control characteristics of the representation by matching to a prior distribution adversarially. Our method, which we call Deep InfoMax (DIM), outperforms a number of popular unsupervised learning methods and compares favorably with fully-supervised learning on several classification tasks in with some standard architectures. DIM opens new avenues for unsupervised learning of representations and is an important step towards flexible formulations of representation learning objectives for specific end-goals.",
            "referenceCount": 80,
            "citationCount": 2104,
            "influentialCitationCount": 295,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-08-20",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1808.06670"
            },
            "citationStyles": {
                "bibtex": "@Article{Hjelm2018LearningDR,\n author = {R. Devon Hjelm and A. Fedorov and Samuel Lavoie-Marchildon and Karan Grewal and A. Trischler and Yoshua Bengio},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Learning deep representations by mutual information estimation and maximization},\n volume = {abs/1808.06670},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e129e344083b307e005c5342ba49524d9981a420",
            "@type": "ScholarlyArticle",
            "paperId": "e129e344083b307e005c5342ba49524d9981a420",
            "corpusId": 53366105,
            "url": "https://www.semanticscholar.org/paper/e129e344083b307e005c5342ba49524d9981a420",
            "title": "Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2909962969",
                "ArXiv": "1907.04490",
                "DBLP": "journals/corr/abs-1907-04490",
                "CorpusId": 53366105
            },
            "abstract": "Deep learning has achieved astonishing results on many tasks with large amounts of data and generalization within the proximity of training data. For many important real-world applications, these requirements are unfeasible and additional prior knowledge on the task domain is required to overcome the resulting problems. In particular, learning physics models for model-based control requires robust extrapolation from fewer samples - often collected online in real-time - and model errors may lead to drastic damages of the system. Directly incorporating physical insight has enabled us to obtain a novel deep model learning approach that extrapolates well while requiring fewer samples. As a first example, we propose Deep Lagrangian Networks (DeLaN) as a deep network structure upon which Lagrangian Mechanics have been imposed. DeLaN can learn the equations of motion of a mechanical system (i.e., system dynamics) with a deep network efficiently while ensuring physical plausibility. The resulting DeLaN network performs very well at robot tracking control. The proposed method did not only outperform previous model learning approaches at learning speed but exhibits substantially improved and more robust extrapolation to novel trajectories and learns online in real-time",
            "referenceCount": 49,
            "citationCount": 289,
            "influentialCitationCount": 30,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-07-10",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1907.04490"
            },
            "citationStyles": {
                "bibtex": "@Article{Lutter2019DeepLN,\n author = {M. Lutter and Christian Ritter and Jan Peters},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning},\n volume = {abs/1907.04490},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8760bc7631c0cb04e7138254e9fd6451b7def8ca",
            "@type": "ScholarlyArticle",
            "paperId": "8760bc7631c0cb04e7138254e9fd6451b7def8ca",
            "corpusId": 6842201,
            "url": "https://www.semanticscholar.org/paper/8760bc7631c0cb04e7138254e9fd6451b7def8ca",
            "title": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/SunSSG17",
                "MAG": "2734663976",
                "ArXiv": "1707.02968",
                "DOI": "10.1109/ICCV.2017.97",
                "CorpusId": 6842201
            },
            "abstract": "The success of deep learning in vision can be attributed to: (a) models with high capacity; (b) increased computational power; and (c) availability of large-scale labeled data. Since 2012, there have been significant advances in representation capabilities of the models and computational capabilities of GPUs. But the size of the biggest dataset has surprisingly remained constant. What will happen if we increase the dataset size by 10 \u00d7 or 100 \u00d7 ? This paper takes a step towards clearing the clouds of mystery surrounding the relationship between \u2018enormous data\u2019 and visual deep learning. By exploiting the JFT-300M dataset which has more than 375M noisy labels for 300M images, we investigate how the performance of current vision tasks would change if this data was used for representation learning. Our paper delivers some surprising (and some expected) findings. First, we find that the performance on vision tasks increases logarithmically based on volume of training data size. Second, we show that representation learning (or pre-training) still holds a lot of promise. One can improve performance on many vision tasks by just training a better base model. Finally, as expected, we present new state-of-the-art results for different vision tasks including image classification, object detection, semantic segmentation and human pose estimation. Our sincere hope is that this inspires vision community to not undervalue the data and develop collective efforts in building larger datasets.",
            "referenceCount": 43,
            "citationCount": 1929,
            "influentialCitationCount": 103,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1707.02968",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-07-10",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sun2017RevisitingUE,\n author = {Chen Sun and Abhinav Shrivastava and Saurabh Singh and A. Gupta},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2017 IEEE International Conference on Computer Vision (ICCV)},\n pages = {843-852},\n title = {Revisiting Unreasonable Effectiveness of Data in Deep Learning Era},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fd9541fe4317904b9a0637b6505fb0bea0979491",
            "@type": "ScholarlyArticle",
            "paperId": "fd9541fe4317904b9a0637b6505fb0bea0979491",
            "corpusId": 133091488,
            "url": "https://www.semanticscholar.org/paper/fd9541fe4317904b9a0637b6505fb0bea0979491",
            "title": "Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning",
            "venue": "IEEE Symposium on Security and Privacy",
            "publicationVenue": {
                "id": "urn:research:29b9c461-963e-4d11-b2ab-92c182243942",
                "name": "IEEE Symposium on Security and Privacy",
                "alternate_names": [
                    "S&P",
                    "IEEE Symp Secur Priv"
                ],
                "issn": null,
                "url": "http://www.ieee-security.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "3103245149",
                "DBLP": "conf/sp/NasrSH19",
                "DOI": "10.1109/SP.2019.00065",
                "CorpusId": 133091488
            },
            "abstract": "Deep neural networks are susceptible to various inference attacks as they remember information about their training data. We design white-box inference attacks to perform a comprehensive privacy analysis of deep learning models. We measure the privacy leakage through parameters of fully trained models as well as the parameter updates of models during training. We design inference algorithms for both centralized and federated learning, with respect to passive and active inference attackers, and assuming different adversary prior knowledge. We evaluate our novel white-box membership inference attacks against deep learning algorithms to trace their training data records. We show that a straightforward extension of the known black-box attacks to the white-box setting (through analyzing the outputs of activation functions) is ineffective. We therefore design new algorithms tailored to the white-box setting by exploiting the privacy vulnerabilities of the stochastic gradient descent algorithm, which is the algorithm used to train deep neural networks. We investigate the reasons why deep learning models may leak information about their training data. We then show that even well-generalized models are significantly susceptible to white-box membership inference attacks, by analyzing state-of-the-art pre-trained and publicly available models for the CIFAR dataset. We also show how adversarial participants, in the federated learning setting, can successfully run active membership inference attacks against other participants, even when the global model achieves high prediction accuracies.",
            "referenceCount": 40,
            "citationCount": 985,
            "influentialCitationCount": 111,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/8826229/8835208/08835245.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-12-03",
            "journal": {
                "name": "2019 IEEE Symposium on Security and Privacy (SP)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Nasr2018ComprehensivePA,\n author = {Milad Nasr and R. Shokri and A. Houmansadr},\n booktitle = {IEEE Symposium on Security and Privacy},\n journal = {2019 IEEE Symposium on Security and Privacy (SP)},\n pages = {739-753},\n title = {Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0e1f153576c7f9f2628cdd34a1067c4d26bdc096",
            "@type": "ScholarlyArticle",
            "paperId": "0e1f153576c7f9f2628cdd34a1067c4d26bdc096",
            "corpusId": 202160253,
            "url": "https://www.semanticscholar.org/paper/0e1f153576c7f9f2628cdd34a1067c4d26bdc096",
            "title": "Explainable AI: Interpreting, Explaining and Visualizing Deep Learning",
            "venue": "Explainable AI",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "series/lncs/11700",
                "MAG": "3000716014",
                "DOI": "10.1007/978-3-030-28954-6",
                "CorpusId": 202160253
            },
            "abstract": null,
            "referenceCount": 131,
            "citationCount": 834,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Explainable AI: Interpreting, Explaining and Visualizing Deep Learning",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Samek2019ExplainableAI,\n author = {W. Samek and G. Montavon and A. Vedaldi and L. K. Hansen and Klaus M\u00fcller},\n booktitle = {Explainable AI},\n journal = {Explainable AI: Interpreting, Explaining and Visualizing Deep Learning},\n title = {Explainable AI: Interpreting, Explaining and Visualizing Deep Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cb4c2a2d7e50667914d1a648f1a9134056724780",
            "@type": "ScholarlyArticle",
            "paperId": "cb4c2a2d7e50667914d1a648f1a9134056724780",
            "corpusId": 36122023,
            "url": "https://www.semanticscholar.org/paper/cb4c2a2d7e50667914d1a648f1a9134056724780",
            "title": "Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/abs-1712-05526",
                "MAG": "2774423163",
                "ArXiv": "1712.05526",
                "CorpusId": 36122023
            },
            "abstract": "Deep learning models have achieved high performance on many tasks, and thus have been applied to many security-critical scenarios. For example, deep learning-based face recognition systems have been used to authenticate users to access many security-sensitive applications like payment apps. Such usages of deep learning systems provide the adversaries with sufficient incentives to perform attacks against these systems for their adversarial purposes. In this work, we consider a new type of attacks, called backdoor attacks, where the attacker's goal is to create a backdoor into a learning-based authentication system, so that he can easily circumvent the system by leveraging the backdoor. Specifically, the adversary aims at creating backdoor instances, so that the victim learning system will be misled to classify the backdoor instances as a target label specified by the adversary. In particular, we study backdoor poisoning attacks, which achieve backdoor attacks using poisoning strategies. Different from all existing work, our studied poisoning strategies can apply under a very weak threat model: (1) the adversary has no knowledge of the model and the training set used by the victim system; (2) the attacker is allowed to inject only a small amount of poisoning samples; (3) the backdoor key is hard to notice even by human beings to achieve stealthiness. We conduct evaluation to demonstrate that a backdoor adversary can inject only around 50 poisoning samples, while achieving an attack success rate of above 90%. We are also the first work to show that a data poisoning attack can create physically implementable backdoors without touching the training process. Our work demonstrates that backdoor poisoning attacks pose real threats to a learning system, and thus highlights the importance of further investigation and proposing defense strategies against them.",
            "referenceCount": 67,
            "citationCount": 1193,
            "influentialCitationCount": 216,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-12-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1712.05526"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2017TargetedBA,\n author = {Xinyun Chen and Chang Liu and Bo Li and Kimberly Lu and D. Song},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning},\n volume = {abs/1712.05526},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:00c4632d2d926acabc18574c9c5b870709ae9450",
            "@type": "ScholarlyArticle",
            "paperId": "00c4632d2d926acabc18574c9c5b870709ae9450",
            "corpusId": 42367028,
            "url": "https://www.semanticscholar.org/paper/00c4632d2d926acabc18574c9c5b870709ae9450",
            "title": "Learning IoT in Edge: Deep Learning for the Internet of Things with Edge Computing",
            "venue": "IEEE Network",
            "publicationVenue": {
                "id": "urn:research:3b4e0d11-3211-4ead-848c-99928b5ef30e",
                "name": "IEEE Network",
                "alternate_names": [
                    "IEEE Netw"
                ],
                "issn": "0890-8044",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=65"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2786070938",
                "DBLP": "journals/network/LiOD18",
                "DOI": "10.1109/MNET.2018.1700202",
                "CorpusId": 42367028
            },
            "abstract": "Deep learning is a promising approach for extracting accurate information from raw sensor data from IoT devices deployed in complex environments. Because of its multilayer structure, deep learning is also appropriate for the edge computing environment. Therefore, in this article, we first introduce deep learning for IoTs into the edge computing environment. Since existing edge nodes have limited processing capability, we also design a novel offloading strategy to optimize the performance of IoT deep learning applications with edge computing. In the performance evaluation, we test the performance of executing multiple deep learning tasks in an edge computing environment with our strategy. The evaluation results show that our method outperforms other optimization solutions on deep learning for IoT.",
            "referenceCount": 17,
            "citationCount": 1150,
            "influentialCitationCount": 38,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-01-26",
            "journal": {
                "name": "IEEE Network",
                "volume": "32"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2018LearningII,\n author = {He Li and K. Ota and M. Dong},\n booktitle = {IEEE Network},\n journal = {IEEE Network},\n pages = {96-101},\n title = {Learning IoT in Edge: Deep Learning for the Internet of Things with Edge Computing},\n volume = {32},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1e03bdf8b86d2969fff11277f9e3dcbfac132e28",
            "@type": "ScholarlyArticle",
            "paperId": "1e03bdf8b86d2969fff11277f9e3dcbfac132e28",
            "corpusId": 213463573,
            "url": "https://www.semanticscholar.org/paper/1e03bdf8b86d2969fff11277f9e3dcbfac132e28",
            "title": "Deep learning in environmental remote sensing: Achievements and challenges",
            "venue": "Remote Sensing of Environment",
            "publicationVenue": {
                "id": "urn:research:2544009c-f3cc-45f2-b79b-aff3d09cfc34",
                "name": "Remote Sensing of Environment",
                "alternate_names": [
                    "Remote Sens Environ"
                ],
                "issn": "0034-4257",
                "url": "https://www.journals.elsevier.com/remote-sensing-of-environment"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3008439211",
                "DOI": "10.1016/j.rse.2020.111716",
                "CorpusId": 213463573
            },
            "abstract": null,
            "referenceCount": 300,
            "citationCount": 621,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2020-05-01",
            "journal": {
                "name": "Remote Sensing of Environment",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yuan2020DeepLI,\n author = {Q. Yuan and Huanfeng Shen and Tongwen Li and Zhiwei Li and Shuwen Li and Yun Jiang and Hongzhang Xu and Weiwei Tan and Qianqian Yang and Jiwen Wang and Jianhao Gao and Liangpei Zhang},\n booktitle = {Remote Sensing of Environment},\n journal = {Remote Sensing of Environment},\n title = {Deep learning in environmental remote sensing: Achievements and challenges},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fbf32abd431c70293f1ad1a9b85d4ecbe4e5d6ed",
            "@type": "ScholarlyArticle",
            "paperId": "fbf32abd431c70293f1ad1a9b85d4ecbe4e5d6ed",
            "corpusId": 214317858,
            "url": "https://www.semanticscholar.org/paper/fbf32abd431c70293f1ad1a9b85d4ecbe4e5d6ed",
            "title": "Adversarial Attacks and Defenses in Deep Learning",
            "venue": "Engineering",
            "publicationVenue": {
                "id": "urn:research:349a6ffc-3527-4d3d-aef4-8372fbc1a084",
                "name": "Engineering",
                "alternate_names": null,
                "issn": "1947-394X",
                "url": "https://www.scirp.org/journal/eng/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "2997532515",
                "DOI": "10.1016/j.eng.2019.12.012",
                "CorpusId": 214317858
            },
            "abstract": null,
            "referenceCount": 114,
            "citationCount": 381,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2020-03-01",
            "journal": {
                "name": "Engineering",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ren2020AdversarialAA,\n author = {K. Ren and Tianhang Zheng and Zhan Qin and Xue Liu},\n booktitle = {Engineering},\n journal = {Engineering},\n title = {Adversarial Attacks and Defenses in Deep Learning},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bd17620c6cb5ca97ef773499223d1509d123745f",
            "@type": "ScholarlyArticle",
            "paperId": "bd17620c6cb5ca97ef773499223d1509d123745f",
            "corpusId": 212622911,
            "url": "https://www.semanticscholar.org/paper/bd17620c6cb5ca97ef773499223d1509d123745f",
            "title": "Dive into Deep Learning",
            "venue": "Journal of the American College of Radiology",
            "publicationVenue": {
                "id": "urn:research:f80195fb-14b8-48fd-a5e4-c1ff01b01410",
                "name": "Journal of the American College of Radiology",
                "alternate_names": [
                    "J Am Coll Radiol",
                    "Journal of The American College of Radiology"
                ],
                "issn": "1546-1440",
                "url": "http://www.sciencedirect.com/science/journal/15461440"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2106-11342",
                "MAG": "3176906074",
                "ArXiv": "2106.11342",
                "DOI": "10.1016/j.jacr.2020.02.005",
                "CorpusId": 212622911,
                "PubMed": "32142636"
            },
            "abstract": null,
            "referenceCount": 184,
            "citationCount": 372,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-03-03",
            "journal": {
                "name": "Journal of the American College of Radiology : JACR",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2020DiveID,\n author = {Aston Zhang and Zachary Chase Lipton and Mu Li and Alexander J. Smola},\n booktitle = {Journal of the American College of Radiology},\n journal = {Journal of the American College of Radiology : JACR},\n title = {Dive into Deep Learning},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2d8edc4e38bf9907170238726ec902cb3739393b",
            "@type": "ScholarlyArticle",
            "paperId": "2d8edc4e38bf9907170238726ec902cb3739393b",
            "corpusId": 21957663,
            "url": "https://www.semanticscholar.org/paper/2d8edc4e38bf9907170238726ec902cb3739393b",
            "title": "Generalised Dice overlap as a deep learning loss function for highly unbalanced segmentations",
            "venue": "DLMIA/ML-CDS@MICCAI",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/miccai/SudreLVOC17",
                "MAG": "3098298104",
                "ArXiv": "1707.03237",
                "DOI": "10.1007/978-3-319-67558-9_28",
                "CorpusId": 21957663,
                "PubMed": "34104926"
            },
            "abstract": null,
            "referenceCount": 9,
            "citationCount": 1569,
            "influentialCitationCount": 87,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-11",
            "journal": {
                "name": "Deep learning in medical image analysis and multimodal learning for clinical decision support : Third International Workshop, DLMIA 2017, and 7th International Workshop, ML-CDS 2017, held in conjunction with MICCAI 2017 Quebec City, QC,...",
                "volume": "2017"
            },
            "citationStyles": {
                "bibtex": "@Article{Sudre2017GeneralisedDO,\n author = {C. Sudre and Wenqi Li and Tom Kamiel Magda Vercauteren and S. Ourselin and M. Jorge Cardoso},\n booktitle = {DLMIA/ML-CDS@MICCAI},\n journal = {Deep learning in medical image analysis and multimodal learning for clinical decision support : Third International Workshop, DLMIA 2017, and 7th International Workshop, ML-CDS 2017, held in conjunction with MICCAI 2017 Quebec City, QC,...},\n pages = {\n          240-248\n        },\n title = {Generalised Dice overlap as a deep learning loss function for highly unbalanced segmentations},\n volume = {2017},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cc145f046788029322835979a14459652da7247e",
            "@type": "ScholarlyArticle",
            "paperId": "cc145f046788029322835979a14459652da7247e",
            "corpusId": 49482223,
            "url": "https://www.semanticscholar.org/paper/cc145f046788029322835979a14459652da7247e",
            "title": "This looks like that: deep learning for interpretable image recognition",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/nips/ChenLTBRS19",
                "ArXiv": "1806.10574",
                "MAG": "2971048680",
                "CorpusId": 49482223
            },
            "abstract": "When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture -- prototypical part network (ProtoPNet), that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The model thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training without any annotations for parts of images. We demonstrate our method on the CUB-200-2011 dataset and the Stanford Cars dataset. Our experiments show that ProtoPNet can achieve comparable accuracy with its analogous non-interpretable counterpart, and when several ProtoPNets are combined into a larger network, it can achieve an accuracy that is on par with some of the best-performing deep models. Moreover, ProtoPNet provides a level of interpretability that is absent in other interpretable deep models.",
            "referenceCount": 72,
            "citationCount": 788,
            "influentialCitationCount": 149,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-06-27",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2018ThisLL,\n author = {Chaofan Chen and Oscar Li and A. Barnett and Jonathan Su and C. Rudin},\n booktitle = {Neural Information Processing Systems},\n pages = {8928-8939},\n title = {This looks like that: deep learning for interpretable image recognition},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:78f7c6818c97383b5ae4b61664ffc6cde7974466",
            "@type": "ScholarlyArticle",
            "paperId": "78f7c6818c97383b5ae4b61664ffc6cde7974466",
            "corpusId": 3306364,
            "url": "https://www.semanticscholar.org/paper/78f7c6818c97383b5ae4b61664ffc6cde7974466",
            "title": "A Deep Learning Approach to Network Intrusion Detection",
            "venue": "IEEE Transactions on Emerging Topics in Computational Intelligence",
            "publicationVenue": {
                "id": "urn:research:544cddb9-1149-469a-8377-d8c34f08d8b1",
                "name": "IEEE Transactions on Emerging Topics in Computational Intelligence",
                "alternate_names": [
                    "IEEE Trans Emerg Top Comput Intell"
                ],
                "issn": "2471-285X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=7433297"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/tetci/ShoneTPS18",
                "MAG": "2783741806",
                "DOI": "10.1109/TETCI.2017.2772792",
                "CorpusId": 3306364
            },
            "abstract": "Network intrusion detection systems (NIDSs) play a crucial role in defending computer networks. However, there are concerns regarding the feasibility and sustainability of current approaches when faced with the demands of modern networks. More specifically, these concerns relate to the increasing levels of required human interaction and the decreasing levels of detection accuracy. This paper presents a novel deep learning technique for intrusion detection, which addresses these concerns. We detail our proposed nonsymmetric deep autoencoder (NDAE) for unsupervised feature learning. Furthermore, we also propose our novel deep learning classification model constructed using stacked NDAEs. Our proposed classifier has been implemented in graphics processing unit (GPU)-enabled TensorFlow and evaluated using the benchmark KDD Cup \u201999 and NSL-KDD datasets. Promising results have been obtained from our model thus far, demonstrating improvements over existing approaches and the strong potential for use in modern NIDSs.",
            "referenceCount": 39,
            "citationCount": 901,
            "influentialCitationCount": 63,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://researchonline.ljmu.ac.uk/id/eprint/7479/1/A_Deep_Learning_Approach_to_Network_Intrusion_Detection_FINAL.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-01-23",
            "journal": {
                "name": "IEEE Transactions on Emerging Topics in Computational Intelligence",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Shone2018ADL,\n author = {Nathan Shone and T. N. Ng\u1ecdc and Vu Dinh Phai and Qi Shi},\n booktitle = {IEEE Transactions on Emerging Topics in Computational Intelligence},\n journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},\n pages = {41-50},\n title = {A Deep Learning Approach to Network Intrusion Detection},\n volume = {2},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f09f7888aa5aeaf88a2a44aea768d9a8747e97d2",
            "@type": "ScholarlyArticle",
            "paperId": "f09f7888aa5aeaf88a2a44aea768d9a8747e97d2",
            "corpusId": 301319,
            "url": "https://www.semanticscholar.org/paper/f09f7888aa5aeaf88a2a44aea768d9a8747e97d2",
            "title": "Geometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2949755136",
                "DBLP": "conf/cvpr/MontiBMRSB17",
                "ArXiv": "1611.08402",
                "DOI": "10.1109/CVPR.2017.576",
                "CorpusId": 301319
            },
            "abstract": "Deep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclidean-structured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graph-and 3D shape analysis and show that it consistently outperforms previous approaches.",
            "referenceCount": 67,
            "citationCount": 1589,
            "influentialCitationCount": 152,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1611.08402",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-11-25",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Monti2016GeometricDL,\n author = {Federico Monti and D. Boscaini and Jonathan Masci and E. Rodol\u00e0 and Jan Svoboda and M. Bronstein},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {5425-5434},\n title = {Geometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "@type": "ScholarlyArticle",
            "paperId": "f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "corpusId": 20714,
            "url": "https://www.semanticscholar.org/paper/f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef",
            "title": "Privacy-preserving deep learning",
            "venue": "Allerton Conference on Communication, Control, and Computing",
            "publicationVenue": {
                "id": "urn:research:e3e363b2-60f3-46d7-9067-5deaddc3f3f2",
                "name": "Allerton Conference on Communication, Control, and Computing",
                "alternate_names": [
                    "Allerton",
                    "T Conf Commun Control Comput"
                ],
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2053637704",
                "DBLP": "conf/ccs/ShokriS15",
                "DOI": "10.1145/2810103.2813687",
                "CorpusId": 20714
            },
            "abstract": "Deep learning based on artificial neural networks is a very popular approach to modeling, classifying, and recognizing complex data such as images, speech, and text. The unprecedented accuracy of deep learning methods has turned them into the foundation of new AI-based services on the Internet. Commercial companies that collect user data on a large scale have been the main beneficiaries of this trend since the success of deep learning techniques is directly proportional to the amount of data available for training. Massive data collection required for deep learning presents obvious privacy issues. Users' personal, highly sensitive data such as photos and voice recordings is kept indefinitely by the companies that collect it. Users can neither delete it, nor restrict the purposes for which it is used. Furthermore, centrally kept data is subject to legal subpoenas and extrajudicial surveillance. Many data owners-for example, medical institutions that may want to apply deep learning methods to clinical records-are prevented by privacy and confidentiality concerns from sharing the data and thus benefitting from large-scale deep learning. In this paper, we present a practical system that enables multiple parties to jointly learn an accurate neural-network model for a given objective without sharing their input datasets. We exploit the fact that the optimization algorithms used in modern deep learning, namely, those based on stochastic gradient descent, can be parallelized and executed asynchronously. Our system lets participants train independently on their own datasets and selectively share small subsets of their models' key parameters during training. This offers an attractive point in the utility/privacy tradeoff space: participants preserve the privacy of their respective data while still benefitting from other participants' models and thus boosting their learning accuracy beyond what is achievable solely on their own inputs. We demonstrate the accuracy of our privacy-preserving deep learning on benchmark datasets.",
            "referenceCount": 60,
            "citationCount": 1860,
            "influentialCitationCount": 195,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-09-01",
            "journal": {
                "name": "2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Shokri2015PrivacypreservingDL,\n author = {R. Shokri and Vitaly Shmatikov},\n booktitle = {Allerton Conference on Communication, Control, and Computing},\n journal = {2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)},\n pages = {909-910},\n title = {Privacy-preserving deep learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0f78ad40306f7e6bb4d609fa9463a085cfba6f02",
            "@type": "ScholarlyArticle",
            "paperId": "0f78ad40306f7e6bb4d609fa9463a085cfba6f02",
            "corpusId": 5085777,
            "url": "https://www.semanticscholar.org/paper/0f78ad40306f7e6bb4d609fa9463a085cfba6f02",
            "title": "When Deep Learning Meets Metric Learning: Remote Sensing Image Scene Classification via Learning Discriminative CNNs",
            "venue": "IEEE Transactions on Geoscience and Remote Sensing",
            "publicationVenue": {
                "id": "urn:research:70628d6a-97aa-4571-9701-bc0eb3989c32",
                "name": "IEEE Transactions on Geoscience and Remote Sensing",
                "alternate_names": [
                    "IEEE Trans Geosci Remote Sens"
                ],
                "issn": "0196-2892",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2783165089",
                "DBLP": "journals/tgrs/ChengYYGH18",
                "DOI": "10.1109/TGRS.2017.2783902",
                "CorpusId": 5085777
            },
            "abstract": "Remote sensing image scene classification is an active and challenging task driven by many applications. More recently, with the advances of deep learning models especially convolutional neural networks (CNNs), the performance of remote sensing image scene classification has been significantly improved due to the powerful feature representations learnt through CNNs. Although great success has been obtained so far, the problems of within-class diversity and between-class similarity are still two big challenges. To address these problems, in this paper, we propose a simple but effective method to learn discriminative CNNs (D-CNNs) to boost the performance of remote sensing image scene classification. Different from the traditional CNN models that minimize only the cross entropy loss, our proposed D-CNN models are trained by optimizing a new discriminative objective function. To this end, apart from minimizing the classification error, we also explicitly impose a metric learning regularization term on the CNN features. The metric learning regularization enforces the D-CNN models to be more discriminative so that, in the new D-CNN feature spaces, the images from the same scene class are mapped closely to each other and the images of different classes are mapped as farther apart as possible. In the experiments, we comprehensively evaluate the proposed method on three publicly available benchmark data sets using three off-the-shelf CNN models. Experimental results demonstrate that our proposed D-CNN methods outperform the existing baseline methods and achieve state-of-the-art results on all three data sets.",
            "referenceCount": 61,
            "citationCount": 856,
            "influentialCitationCount": 60,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-01-09",
            "journal": {
                "name": "IEEE Transactions on Geoscience and Remote Sensing",
                "volume": "56"
            },
            "citationStyles": {
                "bibtex": "@Article{Cheng2018WhenDL,\n author = {Gong Cheng and Ceyuan Yang and Xiwen Yao and Lei Guo and Junwei Han},\n booktitle = {IEEE Transactions on Geoscience and Remote Sensing},\n journal = {IEEE Transactions on Geoscience and Remote Sensing},\n pages = {2811-2821},\n title = {When Deep Learning Meets Metric Learning: Remote Sensing Image Scene Classification via Learning Discriminative CNNs},\n volume = {56},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0ff8b16931a5fb1141a866e04941f8e9409e00e1",
            "@type": "ScholarlyArticle",
            "paperId": "0ff8b16931a5fb1141a866e04941f8e9409e00e1",
            "corpusId": 173994116,
            "url": "https://www.semanticscholar.org/paper/0ff8b16931a5fb1141a866e04941f8e9409e00e1",
            "title": "Deep learning can predict microsatellite instability directly from histology in gastrointestinal cancer",
            "venue": "Nature Network Boston",
            "publicationVenue": {
                "id": "urn:research:9e995b6d-f30b-4ab4-a13b-3dc2cc992f47",
                "name": "Nature Network Boston",
                "alternate_names": [
                    "Nat Netw Boston",
                    "Nat Med",
                    "Nature Medicine"
                ],
                "issn": "1744-7933",
                "url": "https://www.nature.com/nature/articles?code=archive_news"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2948930564",
                "DOI": "10.1038/s41591-019-0462-y",
                "CorpusId": 173994116,
                "PubMed": "31160815"
            },
            "abstract": null,
            "referenceCount": 30,
            "citationCount": 699,
            "influentialCitationCount": 32,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://eprints.whiterose.ac.uk/154681/8/NMED-BC95936B_Manuscript_nofields.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-04-19",
            "journal": {
                "name": "Nature Medicine",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{Kather2019DeepLC,\n author = {Jakob Nikolas Kather and A. Pearson and N. Halama and D. J\u00e4ger and Jeremias Krause and S. Loosen and A. Marx and P. Boor and F. Tacke and U. Neumann and H. Grabsch and T. Yoshikawa and H. Brenner and J. Chang-Claude and M. Hoffmeister and C. Trautwein and T. Luedde},\n booktitle = {Nature Network Boston},\n journal = {Nature Medicine},\n pages = {1054 - 1056},\n title = {Deep learning can predict microsatellite instability directly from histology in gastrointestinal cancer},\n volume = {25},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:89365ef9f61a62ea610f210083d14f70b8ee2972",
            "@type": "ScholarlyArticle",
            "paperId": "89365ef9f61a62ea610f210083d14f70b8ee2972",
            "corpusId": 36051782,
            "url": "https://www.semanticscholar.org/paper/89365ef9f61a62ea610f210083d14f70b8ee2972",
            "title": "VulDeePecker: A Deep Learning-Based System for Vulnerability Detection",
            "venue": "Network and Distributed System Security Symposium",
            "publicationVenue": {
                "id": "urn:research:e6904c24-9546-4135-8344-e3999e375558",
                "name": "Network and Distributed System Security Symposium",
                "alternate_names": [
                    "Netw Distrib Syst Secur Symp",
                    "NDSS"
                ],
                "issn": null,
                "url": "http://www.isoc.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2781491433",
                "DBLP": "conf/ndss/LiZXO0WDZ18",
                "ArXiv": "1801.01681",
                "DOI": "10.14722/ndss.2018.23158",
                "CorpusId": 36051782
            },
            "abstract": "The automatic detection of software vulnerabilities is an important research problem. However, existing solutions to this problem rely on human experts to define features and often miss many vulnerabilities (i.e., incurring high false negative rate). In this paper, we initiate the study of using deep learning-based vulnerability detection to relieve human experts from the tedious and subjective task of manually defining features. Since deep learning is motivated to deal with problems that are very different from the problem of vulnerability detection, we need some guiding principles for applying deep learning to vulnerability detection. In particular, we need to find representations of software programs that are suitable for deep learning. For this purpose, we propose using code gadgets to represent programs and then transform them into vectors, where a code gadget is a number of (not necessarily consecutive) lines of code that are semantically related to each other. This leads to the design and implementation of a deep learning-based vulnerability detection system, called Vulnerability Deep Pecker (VulDeePecker). In order to evaluate VulDeePecker, we present the first vulnerability dataset for deep learning approaches. Experimental results show that VulDeePecker can achieve much fewer false negatives (with reasonable false positives) than other approaches. We further apply VulDeePecker to 3 software products (namely Xen, Seamonkey, and Libav) and detect 4 vulnerabilities, which are not reported in the National Vulnerability Database but were \"silently\" patched by the vendors when releasing later versions of these products; in contrast, these vulnerabilities are almost entirely missed by the other vulnerability detection systems we experimented with.",
            "referenceCount": 57,
            "citationCount": 606,
            "influentialCitationCount": 112,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-01-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1801.01681"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2018VulDeePeckerAD,\n author = {Z. Li and Deqing Zou and Shouhuai Xu and Xinyu Ou and Hai Jin and Sujuan Wang and Zhijun Deng and Yuyi Zhong},\n booktitle = {Network and Distributed System Security Symposium},\n journal = {ArXiv},\n title = {VulDeePecker: A Deep Learning-Based System for Vulnerability Detection},\n volume = {abs/1801.01681},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ec3071fb918ad69ec80df1ca9cf1fdeb386a9603",
            "@type": "ScholarlyArticle",
            "paperId": "ec3071fb918ad69ec80df1ca9cf1fdeb386a9603",
            "corpusId": 3296374,
            "url": "https://www.semanticscholar.org/paper/ec3071fb918ad69ec80df1ca9cf1fdeb386a9603",
            "title": "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "CorpusId": 3296374
            },
            "abstract": "There is an increasing need to bring machine learning to a wide diversity of hardware devices. Current frameworks rely on vendor-speci\ufb01c operator libraries and optimize for a narrow range of server-class GPUs. Deploying workloads to new platforms such as mobile phones, embedded devices, and accelerators (e.g., FPGAs, ASICs) requires signi\ufb01cant manual effort. We propose TVM, a compiler that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends. TVM solves optimization challenges speci\ufb01c to deep learning such as high-level operator fusion, mapping to arbitrary hardware primitives, and memory latency hiding. TVM also offers automated optimization of low-level programs to hardware characteristics by employing a novel learning-based cost modeling method for rapid exploration of code optimizations. Experimental results demonstrate that TVM delivers performance across hardware back-ends that are competitive with state-of-the-art hand tuned libraries for low-power CPU, mobile GPU, and server-class GPUs. We also demonstrate TVM\u2019s ability to target new accelerator back-ends by targeting an FPGA-based generic deep learning accelerator. The system is open sourced and in production use inside several major companies.",
            "referenceCount": 42,
            "citationCount": 475,
            "influentialCitationCount": 100,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Chen2018TVMAA,\n author = {Tianqi Chen and T. Moreau and Ziheng Jiang and Haichen Shen and Eddie Q. Yan and Leyuan Wang and Yuwei Hu and L. Ceze and Carlos Guestrin and A. Krishnamurthy},\n title = {TVM: An Automated End-to-End Optimizing Compiler for Deep Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:530a4ab0308bc98995ffd64207135ca0ae36db7f",
            "@type": "ScholarlyArticle",
            "paperId": "530a4ab0308bc98995ffd64207135ca0ae36db7f",
            "corpusId": 289366,
            "url": "https://www.semanticscholar.org/paper/530a4ab0308bc98995ffd64207135ca0ae36db7f",
            "title": "Privacy-Preserving Deep Learning via Additively Homomorphic Encryption",
            "venue": "IEEE Transactions on Information Forensics and Security",
            "publicationVenue": {
                "id": "urn:research:d406a3f4-dc05-43be-b1f6-812f29de9c0e",
                "name": "IEEE Transactions on Information Forensics and Security",
                "alternate_names": [
                    "IEEE Trans Inf Forensics Secur"
                ],
                "issn": "1556-6013",
                "url": "http://www.ieee.org/organizations/society/sp/tifs.html"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2781091734",
                "DBLP": "journals/iacr/PhongAHWM17",
                "DOI": "10.1109/TIFS.2017.2787987",
                "CorpusId": 289366
            },
            "abstract": "We present a privacy-preserving deep learning system in which many learning participants perform neural network-based deep learning over a combined dataset of all, without revealing the participants\u2019 local data to a central server. To that end, we revisit the previous work by Shokri and Shmatikov (ACM CCS 2015) and show that, with their method, local data information may be leaked to an honest-but-curious server. We then fix that problem by building an enhanced system with the following properties: 1) no information is leaked to the server and 2) accuracy is kept intact, compared with that of the ordinary deep learning system also over the combined dataset. Our system bridges deep learning and cryptography: we utilize asynchronous stochastic gradient descent as applied to neural networks, in combination with additively homomorphic encryption. We show that our usage of encryption adds tolerable overhead to the ordinary deep learning system.",
            "referenceCount": 34,
            "citationCount": 817,
            "influentialCitationCount": 74,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-05-01",
            "journal": {
                "name": "IEEE Transactions on Information Forensics and Security",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Phong2018PrivacyPreservingDL,\n author = {L. T. Phong and Yoshinori Aono and Takuya Hayashi and Lihua Wang and S. Moriai},\n booktitle = {IEEE Transactions on Information Forensics and Security},\n journal = {IEEE Transactions on Information Forensics and Security},\n pages = {1333-1345},\n title = {Privacy-Preserving Deep Learning via Additively Homomorphic Encryption},\n volume = {13},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c0a29cb35c2965930566d6a407da043e18431eaa",
            "@type": "ScholarlyArticle",
            "paperId": "c0a29cb35c2965930566d6a407da043e18431eaa",
            "corpusId": 44063437,
            "url": "https://www.semanticscholar.org/paper/c0a29cb35c2965930566d6a407da043e18431eaa",
            "title": "Deep Learning for Entity Matching: A Design Space Exploration",
            "venue": "SIGMOD Conference",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2798649495",
                "DBLP": "conf/sigmod/MudgalLRDPKDAR18",
                "DOI": "10.1145/3183713.3196926",
                "CorpusId": 44063437
            },
            "abstract": "Entity matching (EM) finds data instances that refer to the same real-world entity. In this paper we examine applying deep learning (DL) to EM, to understand DL's benefits and limitations. We review many DL solutions that have been developed for related matching tasks in text processing (e.g., entity linking, textual entailment, etc.). We categorize these solutions and define a space of DL solutions for EM, as embodied by four solutions with varying representational power: SIF, RNN, Attention, and Hybrid. Next, we investigate the types of EM problems for which DL can be helpful. We consider three such problem types, which match structured data instances, textual instances, and dirty instances, respectively. We empirically compare the above four DL solutions with Magellan, a state-of-the-art learning-based EM solution. The results show that DL does not outperform current solutions on structured EM, but it can significantly outperform them on textual and dirty EM. For practitioners, this suggests that they should seriously consider using DL for textual and dirty EM problems. Finally, we analyze DL's performance and discuss future research directions.",
            "referenceCount": 85,
            "citationCount": 427,
            "influentialCitationCount": 104,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2018-05-27",
            "journal": {
                "name": "Proceedings of the 2018 International Conference on Management of Data",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Mudgal2018DeepLF,\n author = {Sidharth Mudgal and Han Li and Theodoros Rekatsinas and A. Doan and Youngchoon Park and Ganesh Krishnan and Rohit Deep and Esteban Arcaute and V. Raghavendra},\n booktitle = {SIGMOD Conference},\n journal = {Proceedings of the 2018 International Conference on Management of Data},\n title = {Deep Learning for Entity Matching: A Design Space Exploration},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4f71dc75896529d8653d8ef0ccc72bcce2c80e18",
            "@type": "ScholarlyArticle",
            "paperId": "4f71dc75896529d8653d8ef0ccc72bcce2c80e18",
            "corpusId": 209444725,
            "url": "https://www.semanticscholar.org/paper/4f71dc75896529d8653d8ef0ccc72bcce2c80e18",
            "title": "Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal and Image Processing",
            "venue": "IEEE Signal Processing Magazine",
            "publicationVenue": {
                "id": "urn:research:f62e5eab-173a-4e0a-a963-ed8de9835d22",
                "name": "IEEE Signal Processing Magazine",
                "alternate_names": [
                    "IEEE Signal Process Mag"
                ],
                "issn": "1053-5888",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=79"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1912.10557",
                "DBLP": "journals/spm/MongaLE21",
                "MAG": "2995038946",
                "DOI": "10.1109/MSP.2020.3016905",
                "CorpusId": 209444725
            },
            "abstract": "Deep neural networks provide unprecedented performance gains in many real-world problems in signal and image processing. Despite these gains, the future development and practical deployment of deep networks are hindered by their black-box nature, i.e., a lack of interpretability and the need for very large training sets. An emerging technique called algorithm unrolling, or unfolding, offers promise in eliminating these issues by providing a concrete and systematic connection between iterative algorithms that are widely used in signal processing and deep neural networks. Unrolling methods were first proposed to develop fast neural network approximations for sparse coding. More recently, this direction has attracted enormous attention, and it is rapidly growing in both theoretic investigations and practical applications. The increasing popularity of unrolled deep networks is due, in part, to their potential in developing efficient, high-performance (yet interpretable) network architectures from reasonably sized training sets.",
            "referenceCount": 110,
            "citationCount": 634,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1912.10557",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-12-22",
            "journal": {
                "name": "IEEE Signal Processing Magazine",
                "volume": "38"
            },
            "citationStyles": {
                "bibtex": "@Article{Monga2019AlgorithmUI,\n author = {V. Monga and Yuelong Li and Yonina C. Eldar},\n booktitle = {IEEE Signal Processing Magazine},\n journal = {IEEE Signal Processing Magazine},\n pages = {18-44},\n title = {Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal and Image Processing},\n volume = {38},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:43054544c4ff2e25513de8b1a655593b8ff89338",
            "@type": "ScholarlyArticle",
            "paperId": "43054544c4ff2e25513de8b1a655593b8ff89338",
            "corpusId": 54458639,
            "url": "https://www.semanticscholar.org/paper/43054544c4ff2e25513de8b1a655593b8ff89338",
            "title": "Deep Learning for Classical Japanese Literature",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2902986194",
                "ArXiv": "1812.01718",
                "DBLP": "journals/corr/abs-1812-01718",
                "DOI": "10.20676/00000341",
                "CorpusId": 54458639
            },
            "abstract": "Much of machine learning research focuses on producing models which perform well on benchmark tasks, in turn improving our understanding of the challenges associated with those tasks. From the perspective of ML researchers, the content of the task itself is largely irrelevant, and thus there have increasingly been calls for benchmark tasks to more heavily focus on problems which are of social or cultural relevance. In this work, we introduce Kuzushiji-MNIST, a dataset which focuses on Kuzushiji (cursive Japanese), as well as two larger, more challenging datasets, Kuzushiji-49 and Kuzushiji-Kanji. Through these datasets, we wish to engage the machine learning community into the world of classical Japanese literature. Dataset available at this https URL",
            "referenceCount": 27,
            "citationCount": 551,
            "influentialCitationCount": 122,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/1812.01718",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-12-03",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1812.01718"
            },
            "citationStyles": {
                "bibtex": "@Article{Clanuwat2018DeepLF,\n author = {Tarin Clanuwat and Mikel Bober-Irizar and A. Kitamoto and Alex Lamb and Kazuaki Yamamoto and David Ha},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Learning for Classical Japanese Literature},\n volume = {abs/1812.01718},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:30b38ca8151bbd5a5ff45bce94297d1248ff58b5",
            "@type": "ScholarlyArticle",
            "paperId": "30b38ca8151bbd5a5ff45bce94297d1248ff58b5",
            "corpusId": 54559476,
            "url": "https://www.semanticscholar.org/paper/30b38ca8151bbd5a5ff45bce94297d1248ff58b5",
            "title": "Deep Learning on Graphs: A Survey",
            "venue": "IEEE Transactions on Knowledge and Data Engineering",
            "publicationVenue": {
                "id": "urn:research:c6840156-ee10-4d78-8832-7f8909811576",
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "alternate_names": [
                    "IEEE Trans Knowl Data Eng"
                ],
                "issn": "1041-4347",
                "url": "https://www.computer.org/web/tkde"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2904900486",
                "DBLP": "journals/corr/abs-1812-04202",
                "ArXiv": "1812.04202",
                "DOI": "10.1109/tkde.2020.2981333",
                "CorpusId": 54559476
            },
            "abstract": "Deep learning has been shown to be successful in a number of domains, ranging from acoustics, images, to natural language processing. However, applying deep learning to the ubiquitous graph data is non-trivial because of the unique characteristics of graphs. Recently, substantial research efforts have been devoted to applying deep learning methods to graphs, resulting in beneficial advances in graph analysis techniques. In this survey, we comprehensively review the different types of deep learning methods on graphs. We divide the existing methods into five categories based on their model architectures and training strategies: graph recurrent neural networks, graph convolutional networks, graph autoencoders, graph reinforcement learning, and graph adversarial methods. We then provide a comprehensive overview of these methods in a systematic manner mainly by following their development history. We also analyze the differences and compositions of different methods. Finally, we briefly outline the applications in which they have been used and discuss potential future research directions.",
            "referenceCount": 201,
            "citationCount": 989,
            "influentialCitationCount": 41,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/1812.04202",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-12-11",
            "journal": {
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "volume": "34"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018DeepLO,\n author = {Ziwei Zhang and Peng Cui and Wenwu Zhu},\n booktitle = {IEEE Transactions on Knowledge and Data Engineering},\n journal = {IEEE Transactions on Knowledge and Data Engineering},\n pages = {249-270},\n title = {Deep Learning on Graphs: A Survey},\n volume = {34},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fd62a4d907ff9a98cd69926b7dd72cb980713715",
            "@type": "ScholarlyArticle",
            "paperId": "fd62a4d907ff9a98cd69926b7dd72cb980713715",
            "corpusId": 35132623,
            "url": "https://www.semanticscholar.org/paper/fd62a4d907ff9a98cd69926b7dd72cb980713715",
            "title": "Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources",
            "venue": "IEEE Geoscience and Remote Sensing Magazine",
            "publicationVenue": {
                "id": "urn:research:f3b9cfef-ea93-4f7f-a14f-95fbf796875e",
                "name": "IEEE Geoscience and Remote Sensing Magazine",
                "alternate_names": [
                    "IEEE Geosci Remote Sens Mag"
                ],
                "issn": "2168-6831",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6245518"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2782522152",
                "DOI": "10.1109/MGRS.2017.2762307",
                "CorpusId": 35132623
            },
            "abstract": "Central to the looming paradigm shift toward data-intensive science, machine-learning techniques are becoming increasingly important. In particular, deep learning has proven to be both a major breakthrough and an extremely powerful tool in many fields. Shall we embrace deep learning as the key to everything? Or should we resist a black-box solution? These are controversial issues within the remote-sensing community. In this article, we analyze the challenges of using deep learning for remote-sensing data analysis, review recent advances, and provide resources we hope will make deep learning in remote sensing seem ridiculously simple. More importantly, we encourage remote-sensing scientists to bring their expertise into deep learning and use it as an implicit general model to tackle unprecedented, large-scale, influential challenges, such as climate change and urbanization.",
            "referenceCount": 188,
            "citationCount": 1650,
            "influentialCitationCount": 46,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://cdr.lib.unc.edu/downloads/6969z593j",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2017-12-01",
            "journal": {
                "name": "IEEE Geoscience and Remote Sensing Magazine",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhu2017DeepLI,\n author = {Xiaoxiang Zhu and D. Tuia and Lichao Mou and Gui-Song Xia and Liangpei Zhang and Feng Xu and F. Fraundorfer},\n booktitle = {IEEE Geoscience and Remote Sensing Magazine},\n journal = {IEEE Geoscience and Remote Sensing Magazine},\n pages = {8-36},\n title = {Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources},\n volume = {5},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b57e6468740d9320f3f14c6079168b8e21366416",
            "@type": "ScholarlyArticle",
            "paperId": "b57e6468740d9320f3f14c6079168b8e21366416",
            "corpusId": 3680335,
            "url": "https://www.semanticscholar.org/paper/b57e6468740d9320f3f14c6079168b8e21366416",
            "title": "The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2793022090",
                "DBLP": "journals/corr/abs-1803-01164",
                "ArXiv": "1803.01164",
                "CorpusId": 3680335
            },
            "abstract": "Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of machine learning has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional machine learning approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing (NLP), Cyber security, and many more. This report presents a brief survey on development of DL approaches, including Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In addition, we have included recent development of proposed advanced variant DL techniques based on the mentioned DL approaches. Furthermore, DL approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on RL [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1].",
            "referenceCount": 284,
            "citationCount": 661,
            "influentialCitationCount": 73,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-03-03",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1803.01164"
            },
            "citationStyles": {
                "bibtex": "@Article{Alom2018TheHB,\n author = {Md. Zahangir Alom and T. Taha and C. Yakopcic and Stefan Westberg and P. Sidike and M. S. Nasrin and B. V. Essen and A. Awwal and V. Asari},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches},\n volume = {abs/1803.01164},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3c623c08329e129e784a5d03f7606ec8feba3a28",
            "@type": "ScholarlyArticle",
            "paperId": "3c623c08329e129e784a5d03f7606ec8feba3a28",
            "corpusId": 86522127,
            "url": "https://www.semanticscholar.org/paper/3c623c08329e129e784a5d03f7606ec8feba3a28",
            "title": "Uncertainty in Deep Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2914487714",
                "CorpusId": 86522127
            },
            "abstract": "Deep learning has attracted tremendous attention from researchers in various fields of information engineering such as AI, computer vision, and language processing [Kalchbrenner and Blunsom, 2013; Krizhevsky et al., 2012; Mnih et al., 2013], but also from more traditional sciences such as physics, biology, and manufacturing [Anjos et al., 2015; Baldi et al., 2014; Bergmann et al., 2014]. Neural networks, image processing tools such as convolutional neural networks, sequence processing models such as recurrent neural networks, and regularisation tools such as dropout, are used extensively. However, fields such as physics, biology, and manufacturing are ones in which representing model uncertainty is of crucial importance [Ghahramani, 2015; Krzywinski and Altman, 2013]. With the recent shift in many of these fields towards the use of Bayesian uncertainty [Herzog and Ostwald, 2013; Nuzzo, 2014; Trafimow and Marks, 2015], new needs arise from deep learning. In this work we develop tools to obtain practical uncertainty estimates in deep learning, casting recent deep learning tools as Bayesian models without changing either the models or the optimisation. In the first part of this thesis we develop the theory for such tools, providing applications and illustrative examples. We tie approximate inference in Bayesian models to dropout and other stochastic regularisation techniques, and assess the approximations empirically. We give example applications arising from this connection between modern deep learning and Bayesian modelling such as active learning of image data and data efficient deep reinforcement learning. We further demonstrate the method\u2019s practicality through a survey of recent applications making use of the suggested tools in language applications, medical diagnostics, bioinformatics, image processing, and autonomous driving. In the second part of the thesis we explore its theoretical implications, and the insights stemming from the link between Bayesian modelling and deep learning. We discuss what determines model uncertainty properties, analyse the approximate inference analytically in the linear case, and theoretically examine various priors such as spike and slab priors.",
            "referenceCount": 140,
            "citationCount": 1312,
            "influentialCitationCount": 201,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Gal2016UncertaintyID,\n author = {Y. Gal},\n title = {Uncertainty in Deep Learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9235d511dea04aa563a577ab236506b8eb8242ff",
            "@type": "ScholarlyArticle",
            "paperId": "9235d511dea04aa563a577ab236506b8eb8242ff",
            "corpusId": 51929263,
            "url": "https://www.semanticscholar.org/paper/9235d511dea04aa563a577ab236506b8eb8242ff",
            "title": "A Survey on Deep Transfer Learning",
            "venue": "International Conference on Artificial Neural Networks",
            "publicationVenue": {
                "id": "urn:research:3e64b1c1-745f-4edf-bd92-b8ef122bb49c",
                "name": "International Conference on Artificial Neural Networks",
                "alternate_names": [
                    "Int Conf Artif Neural Netw",
                    "ICANN"
                ],
                "issn": null,
                "url": "http://www.e-nns.org/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1808.01974",
                "MAG": "2887280559",
                "DBLP": "journals/corr/abs-1808-01974",
                "DOI": "10.1007/978-3-030-01424-7_27",
                "CorpusId": 51929263
            },
            "abstract": null,
            "referenceCount": 29,
            "citationCount": 2050,
            "influentialCitationCount": 64,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1808.01974",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2018-08-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tan2018ASO,\n author = {Chuanqi Tan and F. Sun and Tao Kong and Wenchang Zhang and Chao Yang and Chunfang Liu},\n booktitle = {International Conference on Artificial Neural Networks},\n pages = {270-279},\n title = {A Survey on Deep Transfer Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5e2bb96c47ccaa16a4e7192e8fadb3b3e1c3acdc",
            "@type": "ScholarlyArticle",
            "paperId": "5e2bb96c47ccaa16a4e7192e8fadb3b3e1c3acdc",
            "corpusId": 1872638,
            "url": "https://www.semanticscholar.org/paper/5e2bb96c47ccaa16a4e7192e8fadb3b3e1c3acdc",
            "title": "Deep Learning: A Critical Appraisal",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1801-00631",
                "MAG": "2781474777",
                "ArXiv": "1801.00631",
                "CorpusId": 1872638
            },
            "abstract": "Although deep learning has historical roots going back decades, neither the term \"deep learning\" nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.",
            "referenceCount": 80,
            "citationCount": 902,
            "influentialCitationCount": 39,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-01-02",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1801.00631"
            },
            "citationStyles": {
                "bibtex": "@Article{Marcus2018DeepLA,\n author = {G. Marcus},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Learning: A Critical Appraisal},\n volume = {abs/1801.00631},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:16c0ef924da1f6b510c9c783ac764156f5a3d631",
            "@type": "ScholarlyArticle",
            "paperId": "16c0ef924da1f6b510c9c783ac764156f5a3d631",
            "corpusId": 56895382,
            "url": "https://www.semanticscholar.org/paper/16c0ef924da1f6b510c9c783ac764156f5a3d631",
            "title": "A Survey on Deep Learning for Named Entity Recognition",
            "venue": "IEEE Transactions on Knowledge and Data Engineering",
            "publicationVenue": {
                "id": "urn:research:c6840156-ee10-4d78-8832-7f8909811576",
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "alternate_names": [
                    "IEEE Trans Knowl Data Eng"
                ],
                "issn": "1041-4347",
                "url": "https://www.computer.org/web/tkde"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1812-09449",
                "ArXiv": "1812.09449",
                "MAG": "2906635035",
                "DOI": "10.1109/TKDE.2020.2981314",
                "CorpusId": 56895382
            },
            "abstract": "Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc. NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.",
            "referenceCount": 213,
            "citationCount": 746,
            "influentialCitationCount": 62,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1812.09449",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-12-22",
            "journal": {
                "name": "IEEE Transactions on Knowledge and Data Engineering",
                "volume": "34"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2018ASO,\n author = {J. Li and Aixin Sun and Jianglei Han and Chenliang Li},\n booktitle = {IEEE Transactions on Knowledge and Data Engineering},\n journal = {IEEE Transactions on Knowledge and Data Engineering},\n pages = {50-70},\n title = {A Survey on Deep Learning for Named Entity Recognition},\n volume = {34},\n year = {2018}\n}\n"
            }
        }
    }
]