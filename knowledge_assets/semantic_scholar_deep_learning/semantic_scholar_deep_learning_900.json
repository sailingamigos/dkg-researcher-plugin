[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:455fd8cd7759548af6c01c2a838a9d8597559000",
            "@type": "ScholarlyArticle",
            "paperId": "455fd8cd7759548af6c01c2a838a9d8597559000",
            "corpusId": 143501939,
            "url": "https://www.semanticscholar.org/paper/455fd8cd7759548af6c01c2a838a9d8597559000",
            "title": "Deep learning and education for sustainability",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "2018951189",
                "DOI": "10.1108/14676370310455332",
                "CorpusId": 143501939
            },
            "abstract": "Deep learning is a key strategy by which students extract meaning and understanding from course materials and experiences. Because of the range and interconnectedness of environmental, social and economic issues, and the importance of interdisciplinary thinking and holistic insight, deep learning is particularly relevant in the context of education for sustainability. However, deep learning can be inhibited if the existing interests or backgrounds of students have a strong disciplinary focus. This paper reviews factors that influence deep learning and discusses some ways in which environmental educators can encourage students to use deep learning strategies. Such strategies are seen to be necessary to maximise the benefits from environmental courses and are likely to foster creative interdisciplinary approaches to sustainability beyond the institution.",
            "referenceCount": 27,
            "citationCount": 489,
            "influentialCitationCount": 56,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Sociology",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2003-03-01",
            "journal": {
                "name": "International Journal of Sustainability in Higher Education",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Warburton2003DeepLA,\n author = {K. Warburton},\n journal = {International Journal of Sustainability in Higher Education},\n pages = {44-56},\n title = {Deep learning and education for sustainability},\n volume = {4},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:41fef1a197fab9684a4608b725d3ae72e1ab4b39",
            "@type": "ScholarlyArticle",
            "paperId": "41fef1a197fab9684a4608b725d3ae72e1ab4b39",
            "corpusId": 5867279,
            "url": "https://www.semanticscholar.org/paper/41fef1a197fab9684a4608b725d3ae72e1ab4b39",
            "title": "Sparse Feature Learning for Deep Belief Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2007,
            "externalIds": {
                "DBLP": "conf/nips/RanzatoBL07",
                "MAG": "2108665656",
                "CorpusId": 5867279
            },
            "abstract": "Unsupervised learning algorithms aim to discover the structure hidden in the data, and to learn representations that are more suitable as input to a supervised machine than the raw input. Many unsupervised methods are based on reconstructing the input from the representation, while constraining the representation to have certain desirable properties (e.g. low dimension, sparsity, etc). Others are based on approximating density by stochastically reconstructing the input from the representation. We describe a novel and efficient algorithm to learn sparse representations, and compare it theoretically and experimentally with a similar machine trained probabilistically, namely a Restricted Boltzmann Machine. We propose a simple criterion to compare and select different unsupervised machines based on the trade-off between the reconstruction error and the information content of the representation. We demonstrate this method by extracting features from a dataset of handwritten numerals, and from a dataset of natural image patches. We show that by stacking multiple levels of such machines and by training sequentially, high-order dependencies between the input observed variables can be captured.",
            "referenceCount": 19,
            "citationCount": 881,
            "influentialCitationCount": 37,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2007-12-03",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ranzato2007SparseFL,\n author = {Marc'Aurelio Ranzato and Y-Lan Boureau and Yann LeCun},\n booktitle = {Neural Information Processing Systems},\n pages = {1185-1192},\n title = {Sparse Feature Learning for Deep Belief Networks},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:575a0e97702edcb0621a47b574949bac50e34200",
            "@type": "ScholarlyArticle",
            "paperId": "575a0e97702edcb0621a47b574949bac50e34200",
            "corpusId": 2168245,
            "url": "https://www.semanticscholar.org/paper/575a0e97702edcb0621a47b574949bac50e34200",
            "title": "Unsupervised Learning by Predicting Noise",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2952776917",
                "DBLP": "journals/corr/BojanowskiJ17",
                "ArXiv": "1704.05310",
                "CorpusId": 2168245
            },
            "abstract": "Convolutional neural networks provide visual features that perform remarkably well in many computer vision applications. However, training these networks requires significant amounts of supervision. This paper introduces a generic framework to train deep networks, end-to-end, with no supervision. We propose to fix a set of target representations, called Noise As Targets (NAT), and to constrain the deep features to align to them. This domain agnostic approach avoids the standard unsupervised learning issues of trivial solutions and collapsing of features. Thanks to a stochastic batch reassignment strategy and a separable square loss function, it scales to millions of images. The proposed approach produces representations that perform on par with state-of-the-art unsupervised methods on ImageNet and Pascal VOC.",
            "referenceCount": 57,
            "citationCount": 260,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-04-18",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bojanowski2017UnsupervisedLB,\n author = {Piotr Bojanowski and Armand Joulin},\n booktitle = {International Conference on Machine Learning},\n pages = {517-526},\n title = {Unsupervised Learning by Predicting Noise},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e337c5e4c23999c36f64bcb33ebe6b284e1bcbf1",
            "@type": "ScholarlyArticle",
            "paperId": "e337c5e4c23999c36f64bcb33ebe6b284e1bcbf1",
            "corpusId": 392458,
            "url": "https://www.semanticscholar.org/paper/e337c5e4c23999c36f64bcb33ebe6b284e1bcbf1",
            "title": "Large-scale deep unsupervised learning using graphics processors",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2120432001",
                "DBLP": "conf/icml/RainaMN09",
                "DOI": "10.1145/1553374.1553486",
                "CorpusId": 392458
            },
            "abstract": "The promise of unsupervised learning methods lies in their potential to use vast amounts of unlabeled data to learn complex, highly nonlinear models with millions of free parameters. We consider two well-known unsupervised learning models, deep belief networks (DBNs) and sparse coding, that have recently been applied to a flurry of machine learning applications (Hinton & Salakhutdinov, 2006; Raina et al., 2007). Unfortunately, current learning algorithms for both models are too slow for large-scale applications, forcing researchers to focus on smaller-scale models, or to use fewer training examples.\n In this paper, we suggest massively parallel methods to help resolve these problems. We argue that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods. We develop general principles for massively parallelizing unsupervised learning tasks using graphics processors. We show that these principles can be applied to successfully scaling up learning algorithms for both DBNs and sparse coding. Our implementation of DBN learning is up to 70 times faster than a dual-core CPU implementation for large models. For example, we are able to reduce the time required to learn a four-layer DBN with 100 million free parameters from several weeks to around a single day. For sparse coding, we develop a simple, inherently parallel algorithm, that leads to a 5 to 15-fold speedup over previous methods.",
            "referenceCount": 37,
            "citationCount": 693,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.robotics.stanford.edu/~ang/papers/icml09-LargeScaleUnsupervisedDeepLearningGPU.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-06-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Raina2009LargescaleDU,\n author = {Rajat Raina and Anand Madhavan and A. Ng},\n booktitle = {International Conference on Machine Learning},\n pages = {873-880},\n title = {Large-scale deep unsupervised learning using graphics processors},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b68c34c55925a75804f97491b745de66b1ffc4be",
            "@type": "ScholarlyArticle",
            "paperId": "b68c34c55925a75804f97491b745de66b1ffc4be",
            "corpusId": 15310495,
            "url": "https://www.semanticscholar.org/paper/b68c34c55925a75804f97491b745de66b1ffc4be",
            "title": "Learning Deep Energy Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2185528074",
                "DBLP": "conf/icml/NgiamCKN11",
                "CorpusId": 15310495
            },
            "abstract": "Deep generative models with multiple hidden layers have been shown to be able to learn meaningful and compact representations of data. In this work we propose deep energy models, which use deep feedforward neural networks to model the energy landscapes that define probabilistic models. We are able to efficiently train all layers of our model simultaneously, allowing the lower layers of the model to adapt to the training of the higher layers, and thereby producing better generative models. We evaluate the generative performance of our models on natural images and demonstrate that this joint training of multiple layers yields qualitative and quantitative improvements over greedy layerwise training. We further generalize our models beyond the commonly used sigmoidal neural networks and show how a deep extension of the product of Student-t distributions model achieves good generative performance. Finally, we introduce a discriminative extension of our model and demonstrate that it outperforms other fully-connected models on object recognition on the NORB dataset.",
            "referenceCount": 31,
            "citationCount": 185,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2011-06-28",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ngiam2011LearningDE,\n author = {Jiquan Ngiam and Zhenghao Chen and Pang Wei Koh and A. Ng},\n booktitle = {International Conference on Machine Learning},\n pages = {1105-1112},\n title = {Learning Deep Energy Models},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:00cd1dab559a9671b692f39f14c1573ab2d1416b",
            "@type": "ScholarlyArticle",
            "paperId": "00cd1dab559a9671b692f39f14c1573ab2d1416b",
            "corpusId": 9383489,
            "url": "https://www.semanticscholar.org/paper/00cd1dab559a9671b692f39f14c1573ab2d1416b",
            "title": "Efficient Learning of Deep Boltzmann Machines",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "MAG": "177847060",
                "DBLP": "journals/jmlr/SalakhutdinovL10",
                "CorpusId": 9383489
            },
            "abstract": "We present a new approximate inference algorithm for Deep Boltzmann Machines (DBM\u2019s), a generative model with many layers of hidden variables. The algorithm learns a separate \u201crecognition\u201d model that is used to quickly initialize, in a single bottom-up pass, the values of the latent variables in all hidden layers. We show that using such a recognition model, followed by a combined top-down and bottom-up pass, it is possible to efficiently learn a good generative model of high-dimensional highly-structured sensory input. We show that the additional computations required by incorporating a top-down feedback plays a critical role in the performance of a DBM, both as a generative and discriminative model. Moreover, inference is only at most three times slower compared to the approximate inference in a Deep Belief Network (DBN), making large-scale learning of DBM\u2019s practical. Finally, we demonstrate that the DBM\u2019s trained using the proposed approximate inference algorithm perform well compared to DBN\u2019s and SVM\u2019s on the MNIST handwritten digit, OCR English letters, and NORB visual object recognition tasks.",
            "referenceCount": 18,
            "citationCount": 393,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-03-31",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Salakhutdinov2010EfficientLO,\n author = {R. Salakhutdinov and H. Larochelle},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n pages = {693-700},\n title = {Efficient Learning of Deep Boltzmann Machines},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:49a434126cd565739612af33acdded2b603f1725",
            "@type": "ScholarlyArticle",
            "paperId": "49a434126cd565739612af33acdded2b603f1725",
            "corpusId": 154862646,
            "url": "https://www.semanticscholar.org/paper/49a434126cd565739612af33acdded2b603f1725",
            "title": "Deep learning? What deep learning?",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "2090079425",
                "DOI": "10.4314/SAJHE.V17I1.25201",
                "CorpusId": 154862646
            },
            "abstract": "In teaching generally over the past twenty years, there has been a move towards teaching methods that encourage deep, rather than surface approaches to learning. The reason for this being that students, who adopt a deep approach to learning are considered to have learning outcomes of a better quality and desirability than those who adopt a surface approach to learning. However, how students approach their learning is still undervalued in Higher Education, as it is assumed that by the time a student enters higher education, he or she has already learned how to study. The purpose of this research is, therefore, to discuss the extent to which a South African Higher Education institute promotes and develops a deep approach to learning in its undergraduates, and to describe any changes in students' approaches to learning as they progress through their studies. \n(South African Journal of Higher Education: 2003 17 (1): 123-131)",
            "referenceCount": 0,
            "citationCount": 25,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "South African journal of higher education",
                "volume": "17"
            },
            "citationStyles": {
                "bibtex": "@Article{Fourie2003DeepLW,\n author = {C. Fourie},\n journal = {South African journal of higher education},\n pages = {123-131},\n title = {Deep learning? What deep learning?},\n volume = {17},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:22d6d9c1b7ac2738b51d93be45ac8f753f81867c",
            "@type": "ScholarlyArticle",
            "paperId": "22d6d9c1b7ac2738b51d93be45ac8f753f81867c",
            "corpusId": 8772285,
            "url": "https://www.semanticscholar.org/paper/22d6d9c1b7ac2738b51d93be45ac8f753f81867c",
            "title": "Stacked Autoencoders for Unsupervised Feature Learning and Multiple Organ Detection in a Pilot Study Using 4D Patient Data",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2036109700",
                "DBLP": "journals/pami/ShinOCDL13",
                "DOI": "10.1109/TPAMI.2012.277",
                "CorpusId": 8772285,
                "PubMed": "23787345"
            },
            "abstract": "Medical image analysis remains a challenging application area for artificial intelligence. When applying machine learning, obtaining ground-truth labels for supervised learning is more difficult than in many more common applications of machine learning. This is especially so for datasets with abnormalities, as tissue types and the shapes of the organs in these datasets differ widely. However, organ detection in such an abnormal dataset may have many promising potential real-world applications, such as automatic diagnosis, automated radiotherapy planning, and medical image retrieval, where new multimodal medical images provide more information about the imaged tissues for diagnosis. Here, we test the application of deep learning methods to organ identification in magnetic resonance medical images, with visual and temporal hierarchical features learned to categorize object classes from an unlabeled multimodal DCE-MRI dataset so that only a weakly supervised training is required for a classifier. A probabilistic patch-based method was employed for multiple organ detection, with the features learned from the deep learning model. This shows the potential of the deep learning model for application to medical images, despite the difficulty of obtaining libraries of correctly labeled training datasets and despite the intrinsic abnormalities present in patient datasets.",
            "referenceCount": 63,
            "citationCount": 476,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-08-01",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Shin2013StackedAF,\n author = {Hoo-Chang Shin and M. Orton and D. Collins and S. Doran and M. Leach},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {1930-1943},\n title = {Stacked Autoencoders for Unsupervised Feature Learning and Multiple Organ Detection in a Pilot Study Using 4D Patient Data},\n volume = {35},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:923d8dd5d36dd5ab68aadbe2e3eecb57de88d859",
            "@type": "ScholarlyArticle",
            "paperId": "923d8dd5d36dd5ab68aadbe2e3eecb57de88d859",
            "corpusId": 5569557,
            "url": "https://www.semanticscholar.org/paper/923d8dd5d36dd5ab68aadbe2e3eecb57de88d859",
            "title": "Learning Deep Generative Models",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "DBLP": "phd/ca/Salakhutdinov10",
                "MAG": "2164700406",
                "DOI": "10.1146/ANNUREV-STATISTICS-010814-020120",
                "CorpusId": 5569557
            },
            "abstract": "Building intelligent systems that are capable of extracting high-level representations from high-dimensional sensory data lies at the core of solving many AI related tasks, including object recognition, speech perception, and language understanding. Theoretical and biological arguments strongly suggest that building such systems requires models with deep architectures that involve many layers of nonlinear processing. \nThe aim of the thesis is to demonstrate that deep generative models that contain many layers of latent variables and millions of parameters can be learned efficiently, and that the learned high-level feature representations can be successfully applied in a wide spectrum of application domains, including visual object recognition, information retrieval, and classification and regression tasks. In addition, similar methods can be used for nonlinear dimensionality reduction. \nThe first part of the thesis focuses on analysis and applications of probabilistic generative models called Deep Belief Networks. We show that these deep hierarchical models can learn useful feature representations from a large supply of unlabeled sensory inputs. The learned high-level representations capture a lot of structure in the input data, which is useful for subsequent problem-specific tasks, such as classification, regression or information retrieval, even though these tasks are unknown when the generative model is being trained. \nIn the second part of the thesis, we introduce a new learning algorithm for a different type of hierarchical probabilistic model, which we call a Deep Boltzmann Machine. Like Deep Belief Networks, Deep Boltzmann Machines have the potential of learning internal representations that become increasingly complex at higher layers, which is a promising way of solving object and speech recognition problems. Unlike Deep Belief Networks and many existing models with deep architectures, the approximate inference procedure, in addition to a fast bottom-up pass, can incorporate top-down feedback. This allows Deep Boltzmann Machines to better propagate uncertainty about ambiguous inputs.",
            "referenceCount": 119,
            "citationCount": 373,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-statistics-010814-020120",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Salakhutdinov2009LearningDG,\n author = {R. Salakhutdinov},\n pages = {361-385},\n title = {Learning Deep Generative Models},\n volume = {2},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cfb1872aabc15580491998ed502c4735a437d140",
            "@type": "ScholarlyArticle",
            "paperId": "cfb1872aabc15580491998ed502c4735a437d140",
            "corpusId": 14251504,
            "url": "https://www.semanticscholar.org/paper/cfb1872aabc15580491998ed502c4735a437d140",
            "title": "The Cambridge Handbook of the Learning Sciences: Knowledge Building",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "327314475",
                "DOI": "10.1017/CBO9780511816833.008",
                "CorpusId": 14251504
            },
            "abstract": "There are substantial similarities between deep learning and the processes by which knowledge advances in the disciplines. During the 1960s efforts to exploit these similarities gave rise to learning by discovery, guided discovery, inquiry learning",
            "referenceCount": 58,
            "citationCount": 1440,
            "influentialCitationCount": 150,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Scardamalia2005TheCH,\n author = {M. Scardamalia and C. Bereiter},\n title = {The Cambridge Handbook of the Learning Sciences: Knowledge Building},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:451dd3ff83b981fe81499ff02fa11988a3c9c80b",
            "@type": "ScholarlyArticle",
            "paperId": "451dd3ff83b981fe81499ff02fa11988a3c9c80b",
            "corpusId": 145145010,
            "url": "https://www.semanticscholar.org/paper/451dd3ff83b981fe81499ff02fa11988a3c9c80b",
            "title": "The Effects of Discipline on Deep Approaches to Student Learning and College Outcomes",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2090305479",
                "DOI": "10.1007/S11162-008-9088-5",
                "CorpusId": 145145010
            },
            "abstract": null,
            "referenceCount": 63,
            "citationCount": 375,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2008-02-12",
            "journal": {
                "name": "Research in Higher Education",
                "volume": "49"
            },
            "citationStyles": {
                "bibtex": "@Article{Laird2008TheEO,\n author = {Thomas F. Nelson Laird and R. Shoup and George D. Kuh and Michael J. Schwarz},\n journal = {Research in Higher Education},\n pages = {469-494},\n title = {The Effects of Discipline on Deep Approaches to Student Learning and College Outcomes},\n volume = {49},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b8012351bc5ebce4a4b3039bbbba3ce393bc3315",
            "@type": "ScholarlyArticle",
            "paperId": "b8012351bc5ebce4a4b3039bbbba3ce393bc3315",
            "corpusId": 14805281,
            "url": "https://www.semanticscholar.org/paper/b8012351bc5ebce4a4b3039bbbba3ce393bc3315",
            "title": "An empirical evaluation of deep architectures on problems with many factors of variation",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2007,
            "externalIds": {
                "MAG": "1994197834",
                "DBLP": "conf/icml/LarochelleECBB07",
                "DOI": "10.1145/1273496.1273556",
                "CorpusId": 14805281
            },
            "abstract": "Recently, several learning algorithms relying on models with deep architectures have been proposed. Though they have demonstrated impressive performance, to date, they have only been evaluated on relatively simple problems such as digit recognition in a controlled environment, for which many machine learning algorithms already report reasonable results. Here, we present a series of experiments which indicate that these models show promise in solving harder learning problems that exhibit many factors of variation. These models are compared with well-established algorithms such as Support Vector Machines and single hidden-layer feed-forward neural networks.",
            "referenceCount": 13,
            "citationCount": 1121,
            "influentialCitationCount": 116,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2007-06-20",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Larochelle2007AnEE,\n author = {H. Larochelle and D. Erhan and Aaron C. Courville and J. Bergstra and Yoshua Bengio},\n booktitle = {International Conference on Machine Learning},\n pages = {473-480},\n title = {An empirical evaluation of deep architectures on problems with many factors of variation},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2d87f789a5b223f1285131c93bbaca0d65b96fe4",
            "@type": "ScholarlyArticle",
            "paperId": "2d87f789a5b223f1285131c93bbaca0d65b96fe4",
            "corpusId": 17106930,
            "url": "https://www.semanticscholar.org/paper/2d87f789a5b223f1285131c93bbaca0d65b96fe4",
            "title": "Facilitating Cognitive Presence in Online Learning: Interaction Is Not Enough",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2170486810",
                "DOI": "10.1207/s15389286ajde1903_2",
                "CorpusId": 17106930
            },
            "abstract": "This study assessed the depth of online learning, with a focus on the nature of online interaction in four distance education course designs. The Study Process Questionnaire was used to measure the shift in students' approach to learning from the beginning to the end of the courses. Design had a significant impact on the nature of the interaction and whether students approached learning in a deep and meaningful manner. Structure and leadership were found to be crucial for online learners to take a deep and meaningful approach to learning.",
            "referenceCount": 28,
            "citationCount": 1336,
            "influentialCitationCount": 86,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2005-09-01",
            "journal": {
                "name": "American Journal of Distance Education",
                "volume": "19"
            },
            "citationStyles": {
                "bibtex": "@Article{Garrison2005FacilitatingCP,\n author = {D. Garrison and M. Cleveland-Innes},\n journal = {American Journal of Distance Education},\n pages = {133 - 148},\n title = {Facilitating Cognitive Presence in Online Learning: Interaction Is Not Enough},\n volume = {19},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d3c37c9533528c68dfe50035656da226e8196121",
            "@type": "ScholarlyArticle",
            "paperId": "d3c37c9533528c68dfe50035656da226e8196121",
            "corpusId": 143714967,
            "url": "https://www.semanticscholar.org/paper/d3c37c9533528c68dfe50035656da226e8196121",
            "title": "Learning in Science: A Comparison of Deep and Surface Approaches.",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2000,
            "externalIds": {
                "MAG": "1996339163",
                "DOI": "10.1002/(SICI)1098-2736(200002)37:2<109::AID-TEA3>3.0.CO;2-7",
                "CorpusId": 143714967
            },
            "abstract": "The purpose of this study was to explore in greater depth what has been called by previous researchers, a deep versus surface approach to learning science. Six Grade 8 students judged as typically using learning approaches ranging from deep to surface were observed and taped during class group laboratory activities in a chemistry unit. They were also interviewed individually before and after instruction about related science concepts. On analysis of the students' discourse and actions during the activities and their interview responses, several differences in learning approaches seemed apparent. These differences fell into five emergent categories: generative thinking, nature of explanations, asking questions, metacognitive activity, and approach to tasks. When students used a deep approach, they ventured their ideas more spontaneously; gave more elaborate explanations which described mechanisms and cause\u2013effect relationships or referred to personal experiences; asked questions which focused on explanations and causes, predictions, or resolving discrepancies in knowledge; and engaged in \u201con-line theorizing.\u201d Students using a surface approach gave explanations that were reformulations of the questions, a \u201cblack box\u201d variety which did not refer to a mechanism, or macroscopic descriptions which referred only to what was visible. Their questions also referred to more basic factual or procedural information. The findings also suggest that to encourage a deep learning approach, teachers could provide prompts and contextualized scaffolding and encourage students to ask questions, predict, and explain during activities. \u00a9 2000 John Wiley & Sons, Inc. J Res Sci Teach 37: 109\u2013138, 2000",
            "referenceCount": 74,
            "citationCount": 515,
            "influentialCitationCount": 32,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2000-02-01",
            "journal": {
                "name": "Journal of Research in Science Teaching",
                "volume": "37"
            },
            "citationStyles": {
                "bibtex": "@Article{Chin2000LearningIS,\n author = {Christine Chin and David E. Brown},\n journal = {Journal of Research in Science Teaching},\n pages = {109-138},\n title = {Learning in Science: A Comparison of Deep and Surface Approaches.},\n volume = {37},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5aa26299435bdf7db874ef1640a6c3b5a4a2c394",
            "@type": "ScholarlyArticle",
            "paperId": "5aa26299435bdf7db874ef1640a6c3b5a4a2c394",
            "corpusId": 206592766,
            "url": "https://www.semanticscholar.org/paper/5aa26299435bdf7db874ef1640a6c3b5a4a2c394",
            "title": "FaceNet: A unified embedding for face recognition and clustering",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/SchroffKP15",
                "MAG": "2096733369",
                "ArXiv": "1503.03832",
                "DOI": "10.1109/CVPR.2015.7298682",
                "CorpusId": 206592766
            },
            "abstract": "Despite significant recent advances in the field of face recognition [10, 14, 15, 17], implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure offace similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings asfeature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-artface recognition performance using only 128-bytes perface. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result [15] by 30% on both datasets.",
            "referenceCount": 24,
            "citationCount": 11082,
            "influentialCitationCount": 1644,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1503.03832",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-03-12",
            "journal": {
                "name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Schroff2015FaceNetAU,\n author = {Florian Schroff and Dmitry Kalenichenko and James Philbin},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {815-823},\n title = {FaceNet: A unified embedding for face recognition and clustering},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3c106b928addca208e6f2aa2eff5c6a75d38faae",
            "@type": "ScholarlyArticle",
            "paperId": "3c106b928addca208e6f2aa2eff5c6a75d38faae",
            "corpusId": 49578337,
            "url": "https://www.semanticscholar.org/paper/3c106b928addca208e6f2aa2eff5c6a75d38faae",
            "title": "Systematic Literature Review",
            "venue": "Literature Reviews",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3107023352",
                "DOI": "10.1007/978-1-4020-5614-7_3433",
                "CorpusId": 49578337
            },
            "abstract": null,
            "referenceCount": 111,
            "citationCount": 3182,
            "influentialCitationCount": 191,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.research.ed.ac.uk/portal/files/15148534/Declerck_Karklina_Daly_2013_IJARE_Review.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Law",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2020-02-01",
            "journal": {
                "name": "Literature Reviews",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Attia2020SystematicLR,\n author = {S. Attia},\n booktitle = {Literature Reviews},\n journal = {Literature Reviews},\n title = {Systematic Literature Review},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:13bc4e683075bdd6a3f0155241c276a772d4aa06",
            "@type": "ScholarlyArticle",
            "paperId": "13bc4e683075bdd6a3f0155241c276a772d4aa06",
            "corpusId": 1033682,
            "url": "https://www.semanticscholar.org/paper/13bc4e683075bdd6a3f0155241c276a772d4aa06",
            "title": "Generative adversarial networks",
            "venue": "Communications of the ACM",
            "publicationVenue": {
                "id": "urn:research:4d9ce1c4-dc84-46b9-903e-e3751c00c7dd",
                "name": "Communications of the ACM",
                "alternate_names": [
                    "Commun ACM",
                    "Communications of The ACM"
                ],
                "issn": "0001-0782",
                "url": "http://www.acm.org/pubs/cacm/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "3093962121",
                "DBLP": "journals/corr/GoodfellowPMXWOCB14",
                "DOI": "10.1145/3422622",
                "CorpusId": 1033682
            },
            "abstract": "Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.",
            "referenceCount": 156,
            "citationCount": 39089,
            "influentialCitationCount": 5941,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3422622",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-06-10",
            "journal": {
                "name": "Communications of the ACM",
                "volume": "63"
            },
            "citationStyles": {
                "bibtex": "@Article{Goodfellow2014GenerativeAN,\n author = {I. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron C. Courville and Yoshua Bengio},\n booktitle = {Communications of the ACM},\n journal = {Communications of the ACM},\n pages = {139 - 144},\n title = {Generative adversarial networks},\n volume = {63},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6bdb186ec4726e00a8051119636d4df3b94043b5",
            "@type": "ScholarlyArticle",
            "paperId": "6bdb186ec4726e00a8051119636d4df3b94043b5",
            "corpusId": 1799558,
            "url": "https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5",
            "title": "Caffe: Convolutional Architecture for Fast Feature Embedding",
            "venue": "ACM Multimedia",
            "publicationVenue": {
                "id": "urn:research:f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                "name": "ACM Multimedia",
                "alternate_names": [
                    "MM"
                ],
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2950094539",
                "DBLP": "journals/corr/JiaSDKLGGD14",
                "ArXiv": "1408.5093",
                "DOI": "10.1145/2647868.2654889",
                "CorpusId": 1799558
            },
            "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.",
            "referenceCount": 12,
            "citationCount": 14456,
            "influentialCitationCount": 1745,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book"
            ],
            "publicationDate": "2014-06-20",
            "journal": {
                "name": "Proceedings of the 22nd ACM international conference on Multimedia",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Jia2014CaffeCA,\n author = {Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross B. Girshick and S. Guadarrama and Trevor Darrell},\n booktitle = {ACM Multimedia},\n journal = {Proceedings of the 22nd ACM international conference on Multimedia},\n title = {Caffe: Convolutional Architecture for Fast Feature Embedding},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c41eb895616e453dcba1a70c9b942c5063cc656c",
            "@type": "ScholarlyArticle",
            "paperId": "c41eb895616e453dcba1a70c9b942c5063cc656c",
            "corpusId": 3016223,
            "url": "https://www.semanticscholar.org/paper/c41eb895616e453dcba1a70c9b942c5063cc656c",
            "title": "Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2468907370",
                "ArXiv": "1606.09375",
                "DBLP": "conf/nips/DefferrardBV16",
                "CorpusId": 3016223
            },
            "abstract": "In this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words' embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs.",
            "referenceCount": 47,
            "citationCount": 6234,
            "influentialCitationCount": 766,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-30",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Defferrard2016ConvolutionalNN,\n author = {M. Defferrard and X. Bresson and P. Vandergheynst},\n booktitle = {Neural Information Processing Systems},\n pages = {3837-3845},\n title = {Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:51a55df1f023571a7e07e338ee45a3e3d66ef73e",
            "@type": "ScholarlyArticle",
            "paperId": "51a55df1f023571a7e07e338ee45a3e3d66ef73e",
            "corpusId": 368182,
            "url": "https://www.semanticscholar.org/paper/51a55df1f023571a7e07e338ee45a3e3d66ef73e",
            "title": "Character-level Convolutional Networks for Text Classification",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/ZhangZL15",
                "MAG": "2963012544",
                "ArXiv": "1509.01626",
                "CorpusId": 368182
            },
            "abstract": "This article offers an empirical exploration on the use of character-level convolutional networks (ConvNets) for text classification. We constructed several large-scale datasets to show that character-level convolutional networks could achieve state-of-the-art or competitive results. Comparisons are offered against traditional models such as bag of words, n-grams and their TFIDF variants, and deep learning models such as word-based ConvNets and recurrent neural networks.",
            "referenceCount": 33,
            "citationCount": 4841,
            "influentialCitationCount": 806,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-09-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2015CharacterlevelCN,\n author = {Xiang Zhang and J. Zhao and Yann LeCun},\n booktitle = {Neural Information Processing Systems},\n pages = {649-657},\n title = {Character-level Convolutional Networks for Text Classification},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b36a5bb1707bb9c70025294b3a310138aae8327a",
            "@type": "ScholarlyArticle",
            "paperId": "b36a5bb1707bb9c70025294b3a310138aae8327a",
            "corpusId": 40027675,
            "url": "https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a",
            "title": "Automatic differentiation in PyTorch",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2899771611",
                "CorpusId": 40027675
            },
            "abstract": "In this article, we describe an automatic differentiation module of PyTorch \u2014 a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd [4], and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features.",
            "referenceCount": 6,
            "citationCount": 13156,
            "influentialCitationCount": 1468,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-10-28",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Paszke2017AutomaticDI,\n author = {Adam Paszke and Sam Gross and Soumith Chintala and Gregory Chanan and E. Yang and Zach DeVito and Zeming Lin and Alban Desmaison and L. Antiga and Adam Lerer},\n title = {Automatic differentiation in PyTorch},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4a6e74d4bf4fd0106891e5518692a77c7aa8811d",
            "@type": "ScholarlyArticle",
            "paperId": "4a6e74d4bf4fd0106891e5518692a77c7aa8811d",
            "corpusId": 1929844,
            "url": "https://www.semanticscholar.org/paper/4a6e74d4bf4fd0106891e5518692a77c7aa8811d",
            "title": "Outlier Detection in High Dimensional Data",
            "venue": "Regular Issue",
            "publicationVenue": {
                "id": "urn:research:b3c3187d-18c6-4d52-8596-9c4f882f647a",
                "name": "Regular Issue",
                "alternate_names": [
                    "Regular issue",
                    "Regul Issue",
                    "Regul issue"
                ],
                "issn": "2319-6378",
                "url": "https://www.ijese.org/"
            },
            "year": 2021,
            "externalIds": {
                "MAG": "3176919784",
                "DOI": "10.35940/ijeat.e2675.0610521",
                "CorpusId": 1929844
            },
            "abstract": "Artificial intelligence (AI) is the science that allows\ncomputers to replicate human intelligence in areas such as\ndecision-making, text processing, visual perception. Artificial\nIntelligence is the broader field that contains several subfields\nsuch as machine learning, robotics, and computer vision.\nMachine Learning is a branch of Artificial Intelligence that\nallows a machine to learn and improve at a task over time. Deep\nLearning is a subset of machine learning that makes use of deep\nartificial neural networks for training. The paper proposed on\noutlier detection for multivariate high dimensional data for\nAutoencoder unsupervised model.",
            "referenceCount": 6,
            "citationCount": 1057,
            "influentialCitationCount": 64,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2021-06-30",
            "journal": {
                "name": "Regular issue",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Aggarwal2021OutlierDI,\n author = {C. Aggarwal and Philip S. Yu},\n booktitle = {Regular Issue},\n journal = {Regular issue},\n title = {Outlier Detection in High Dimensional Data},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:81a4fd3004df0eb05d6c1cef96ad33d5407820df",
            "@type": "ScholarlyArticle",
            "paperId": "81a4fd3004df0eb05d6c1cef96ad33d5407820df",
            "corpusId": 57375753,
            "url": "https://www.semanticscholar.org/paper/81a4fd3004df0eb05d6c1cef96ad33d5407820df",
            "title": "A Comprehensive Survey on Graph Neural Networks",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1901-00596",
                "ArXiv": "1901.00596",
                "MAG": "2907492528",
                "DOI": "10.1109/TNNLS.2020.2978386",
                "CorpusId": 57375753,
                "PubMed": "32217482"
            },
            "abstract": "Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial\u2013temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field.",
            "referenceCount": 193,
            "citationCount": 5537,
            "influentialCitationCount": 377,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "32"
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2019ACS,\n author = {Zonghan Wu and Shirui Pan and Fengwen Chen and Guodong Long and Chengqi Zhang and Philip S. Yu},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {4-24},\n title = {A Comprehensive Survey on Graph Neural Networks},\n volume = {32},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:892e53fe5cd39f037cb2a961499f42f3002595dd",
            "@type": "ScholarlyArticle",
            "paperId": "892e53fe5cd39f037cb2a961499f42f3002595dd",
            "corpusId": 1210515,
            "url": "https://www.semanticscholar.org/paper/892e53fe5cd39f037cb2a961499f42f3002595dd",
            "title": "Bag of Tricks for Efficient Text Classification",
            "venue": "Conference of the European Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:8de18c35-6785-4e54-99f2-21ee961302c6",
                "name": "Conference of the European Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "Conf Eur Chapter Assoc Comput Linguistics",
                    "EACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/eacl/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2468328197",
                "ArXiv": "1607.01759",
                "DBLP": "journals/corr/JoulinGBM16",
                "ACL": "E17-2068",
                "DOI": "10.18653/V1/E17-2068",
                "CorpusId": 1210515
            },
            "abstract": "This paper explores a simple and efficient baseline for text classification. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore CPU, and classify half a million sentences among 312K classes in less than a minute.",
            "referenceCount": 30,
            "citationCount": 4014,
            "influentialCitationCount": 430,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/E17-2068.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-07-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1607.01759"
            },
            "citationStyles": {
                "bibtex": "@Article{Joulin2016BagOT,\n author = {Armand Joulin and Edouard Grave and Piotr Bojanowski and Tomas Mikolov},\n booktitle = {Conference of the European Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Bag of Tricks for Efficient Text Classification},\n volume = {abs/1607.01759},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9e60942aa15670ed9ee03af3c0ae011fa4966b7c",
            "@type": "ScholarlyArticle",
            "paperId": "9e60942aa15670ed9ee03af3c0ae011fa4966b7c",
            "corpusId": 10585115,
            "url": "https://www.semanticscholar.org/paper/9e60942aa15670ed9ee03af3c0ae011fa4966b7c",
            "title": "Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks",
            "venue": "IEEE Signal Processing Letters",
            "publicationVenue": {
                "id": "urn:research:d5da7004-7b61-450a-9c7d-a39500de7acf",
                "name": "IEEE Signal Processing Letters",
                "alternate_names": [
                    "IEEE Signal Process Lett"
                ],
                "issn": "1070-9908",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=97"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/spl/ZhangZLQ16",
                "MAG": "2341528187",
                "ArXiv": "1604.02878",
                "DOI": "10.1109/LSP.2016.2603342",
                "CorpusId": 10585115
            },
            "abstract": "Face detection and alignment in unconstrained environment are challenging due to various poses, illuminations, and occlusions. Recent studies show that deep learning approaches can achieve impressive performance on these two tasks. In this letter, we propose a deep cascaded multitask framework that exploits the inherent correlation between detection and alignment to boost up their performance. In particular, our framework leverages a cascaded architecture with three stages of carefully designed deep convolutional networks to predict face and landmark location in a coarse-to-fine manner. In addition, we propose a new online hard sample mining strategy that further improves the performance in practice. Our method achieves superior accuracy over the state-of-the-art techniques on the challenging face detection dataset and benchmark and WIDER FACE benchmarks for face detection, and annotated facial landmarks in the wild benchmark for face alignment, while keeps real-time performance.",
            "referenceCount": 31,
            "citationCount": 4178,
            "influentialCitationCount": 549,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1604.02878",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-04-11",
            "journal": {
                "name": "IEEE Signal Processing Letters",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2016JointFD,\n author = {Kaipeng Zhang and Zhanpeng Zhang and Zhifeng Li and Y. Qiao},\n booktitle = {IEEE Signal Processing Letters},\n journal = {IEEE Signal Processing Letters},\n pages = {1499-1503},\n title = {Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks},\n volume = {23},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0686123607d78eac745f884309b421681dc70197",
            "@type": "ScholarlyArticle",
            "paperId": "0686123607d78eac745f884309b421681dc70197",
            "corpusId": 145247182,
            "url": "https://www.semanticscholar.org/paper/0686123607d78eac745f884309b421681dc70197",
            "title": "Deep and surface learning: a simple or simplistic dichotomy?",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1997,
            "externalIds": {
                "MAG": "2153783196",
                "DOI": "10.1080/096392897331587",
                "CorpusId": 145247182
            },
            "abstract": "In recent years, broad evaluations of higher education in several countries have called for a greater degree of deep learning (i.e. learning with understanding) relative to surface learning (i.e. rote learning). These concepts, having been developed in the 1970s and 1980s, are now well established in the higher education literature. However, to a large extent, exploration and discussion of these concepts is missing from the accounting education literature. The present paper aims to fill this gap in the accounting education literature by introducing the full complexity of this important education literature on deep and surface learning. We show that the use of this dichotomy, which is often used as a convenient shorthand, generally oversimplifies in two key respects. First, the deep- surface distinction is relevant in analysing the following aspects of learning: student learning intentions, learning styles, learning approaches adopted and learning outcomes. The specific context in which the distinction is ...",
            "referenceCount": 30,
            "citationCount": 274,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1997-03-01",
            "journal": {
                "name": "Accounting Education",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Beattie1997DeepAS,\n author = {V. Beattie and Bill Collins and B. McInnes},\n journal = {Accounting Education},\n pages = {1-12},\n title = {Deep and surface learning: a simple or simplistic dichotomy?},\n volume = {6},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1109b663453e78a59e4f66446d71720ac58cec25",
            "@type": "ScholarlyArticle",
            "paperId": "1109b663453e78a59e4f66446d71720ac58cec25",
            "corpusId": 4071727,
            "url": "https://www.semanticscholar.org/paper/1109b663453e78a59e4f66446d71720ac58cec25",
            "title": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "1487583988",
                "DBLP": "journals/corr/SermanetEZMFL13",
                "ArXiv": "1312.6229",
                "CorpusId": 4071727
            },
            "abstract": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.",
            "referenceCount": 37,
            "citationCount": 4820,
            "influentialCitationCount": 358,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-12-21",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1312.6229"
            },
            "citationStyles": {
                "bibtex": "@Article{Sermanet2013OverFeatIR,\n author = {P. Sermanet and D. Eigen and Xiang Zhang and Micha\u00ebl Mathieu and R. Fergus and Yann LeCun},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks},\n volume = {abs/1312.6229},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7e71eedb078181873a56f2adcfef9dddaeb95602",
            "@type": "ScholarlyArticle",
            "paperId": "7e71eedb078181873a56f2adcfef9dddaeb95602",
            "corpusId": 67752026,
            "url": "https://www.semanticscholar.org/paper/7e71eedb078181873a56f2adcfef9dddaeb95602",
            "title": "Simplifying Graph Convolutional Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2950619419",
                "ArXiv": "1902.07153",
                "DBLP": "journals/corr/abs-1902-07153",
                "CorpusId": 67752026
            },
            "abstract": "Graph Convolutional Networks (GCNs) and their variants have experienced significant attention and have become the de facto methods for learning graph representations. GCNs derive inspiration primarily from recent deep learning approaches, and as a result, may inherit unnecessary complexity and redundant computation. In this paper, we reduce this excess complexity through successively removing nonlinearities and collapsing weight matrices between consecutive layers. We theoretically analyze the resulting linear model and show that it corresponds to a fixed low-pass filter followed by a linear classifier. Notably, our experimental evaluation demonstrates that these simplifications do not negatively impact accuracy in many downstream applications. Moreover, the resulting model scales to larger datasets, is naturally interpretable, and yields up to two orders of magnitude speedup over FastGCN.",
            "referenceCount": 62,
            "citationCount": 2181,
            "influentialCitationCount": 592,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-02-19",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2019SimplifyingGC,\n author = {Felix Wu and Tianyi Zhang and A. Souza and Christopher Fifty and Tao Yu and Kilian Q. Weinberger},\n booktitle = {International Conference on Machine Learning},\n pages = {6861-6871},\n title = {Simplifying Graph Convolutional Networks},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f216444d4f2959b4520c61d20003fa30a199670a",
            "@type": "ScholarlyArticle",
            "paperId": "f216444d4f2959b4520c61d20003fa30a199670a",
            "corpusId": 13874643,
            "url": "https://www.semanticscholar.org/paper/f216444d4f2959b4520c61d20003fa30a199670a",
            "title": "Siamese Neural Networks for One-Shot Image Recognition",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "3091905774",
                "CorpusId": 13874643
            },
            "abstract": "The process of learning good features for machine learning applications can be very computationally expensive and may prove difficult in cases where little data is available. A prototypical example of this is the one-shot learning setting, in which we must correctly make predictions given only a single example of each new class. In this paper, we explore a method for learning siamese neural networks which employ a unique structure to naturally rank similarity between inputs. Once a network has been tuned, we can then capitalize on powerful discriminative features to generalize the predictive power of the network not just to new data, but to entirely new classes from unknown distributions. Using a convolutional architecture, we are able to achieve strong results which exceed those of other deep learning models with near state-of-the-art performance on one-shot classification tasks.",
            "referenceCount": 31,
            "citationCount": 3498,
            "influentialCitationCount": 304,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Koch2015SiameseNN,\n author = {Gregory R. Koch},\n title = {Siamese Neural Networks for One-Shot Image Recognition},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8da55e685a7bef9c897788ab519a8710c695c419",
            "@type": "ScholarlyArticle",
            "paperId": "8da55e685a7bef9c897788ab519a8710c695c419",
            "corpusId": 6423078,
            "url": "https://www.semanticscholar.org/paper/8da55e685a7bef9c897788ab519a8710c695c419",
            "title": "Holistically-Nested Edge Detection",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/XieT15",
                "ArXiv": "1504.06375",
                "MAG": "845365781",
                "DOI": "10.1007/s11263-017-1004-z",
                "CorpusId": 6423078
            },
            "abstract": null,
            "referenceCount": 59,
            "citationCount": 2947,
            "influentialCitationCount": 516,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/1504.06375",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-04-23",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "125"
            },
            "citationStyles": {
                "bibtex": "@Article{Xie2015HolisticallyNestedED,\n author = {Saining Xie and Z. Tu},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {3 - 18},\n title = {Holistically-Nested Edge Detection},\n volume = {125},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8f1a8b82c7be223f195b4f03ffa1943391fd428b",
            "@type": "ScholarlyArticle",
            "paperId": "8f1a8b82c7be223f195b4f03ffa1943391fd428b",
            "corpusId": 212408681,
            "url": "https://www.semanticscholar.org/paper/8f1a8b82c7be223f195b4f03ffa1943391fd428b",
            "title": "Cellpose: a generalist algorithm for cellular segmentation",
            "venue": "Nature Methods",
            "publicationVenue": {
                "id": "urn:research:099483df-e8f2-4bee-805d-8a69f07b6cbf",
                "name": "Nature Methods",
                "alternate_names": [
                    "Nat Method"
                ],
                "issn": "1548-7091",
                "url": "http://www.nature.com/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3003623648",
                "DOI": "10.1038/s41592-020-01018-x",
                "CorpusId": 212408681,
                "PubMed": "33318659"
            },
            "abstract": null,
            "referenceCount": 72,
            "citationCount": 1066,
            "influentialCitationCount": 107,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-02-03",
            "journal": {
                "name": "Nature Methods",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Stringer2020CellposeAG,\n author = {C. Stringer and Tim Wang and Michalis Michaelos and Marius Pachitariu},\n booktitle = {Nature Methods},\n journal = {Nature Methods},\n pages = {100 - 106},\n title = {Cellpose: a generalist algorithm for cellular segmentation},\n volume = {18},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca5c766b2d31a1f5ce8896a0a42b40a2bff9323a",
            "@type": "ScholarlyArticle",
            "paperId": "ca5c766b2d31a1f5ce8896a0a42b40a2bff9323a",
            "corpusId": 1318262,
            "url": "https://www.semanticscholar.org/paper/ca5c766b2d31a1f5ce8896a0a42b40a2bff9323a",
            "title": "Conditional Random Fields as Recurrent Neural Networks",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1502.03240",
                "MAG": "3100332847",
                "DBLP": "journals/corr/ZhengJRVSDHT15",
                "DOI": "10.1109/ICCV.2015.179",
                "CorpusId": 1318262
            },
            "abstract": "Pixel-level labelling tasks, such as semantic segmentation, play a central role in image understanding. Recent approaches have attempted to harness the capabilities of deep learning techniques for image recognition to tackle pixel-level labelling tasks. One central issue in this methodology is the limited capacity of deep learning techniques to delineate visual objects. To solve this problem, we introduce a new form of convolutional neural network that combines the strengths of Convolutional Neural Networks (CNNs) and Conditional Random Fields (CRFs)-based probabilistic graphical modelling. To this end, we formulate Conditional Random Fields with Gaussian pairwise potentials and mean-field approximate inference as Recurrent Neural Networks. This network, called CRF-RNN, is then plugged in as a part of a CNN to obtain a deep network that has desirable properties of both CNNs and CRFs. Importantly, our system fully integrates CRF modelling with CNNs, making it possible to train the whole deep network end-to-end with the usual back-propagation algorithm, avoiding offline post-processing methods for object delineation. We apply the proposed method to the problem of semantic image segmentation, obtaining top results on the challenging Pascal VOC 2012 segmentation benchmark.",
            "referenceCount": 71,
            "citationCount": 2433,
            "influentialCitationCount": 306,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1502.03240",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-02-11",
            "journal": {
                "name": "2015 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zheng2015ConditionalRF,\n author = {Shuai Zheng and Sadeep Jayasumana and Bernardino Romera-Paredes and Vibhav Vineet and Zhizhong Su and Dalong Du and Chang Huang and Philip H. S. Torr},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2015 IEEE International Conference on Computer Vision (ICCV)},\n pages = {1529-1537},\n title = {Conditional Random Fields as Recurrent Neural Networks},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3e358c3033908a9506e7f1e3cf29283e359f43d6",
            "@type": "ScholarlyArticle",
            "paperId": "3e358c3033908a9506e7f1e3cf29283e359f43d6",
            "corpusId": 216036034,
            "url": "https://www.semanticscholar.org/paper/3e358c3033908a9506e7f1e3cf29283e359f43d6",
            "title": "Data-efficient and weakly supervised computational pathology on whole-slide images",
            "venue": "Nature Biomedical Engineering",
            "publicationVenue": {
                "id": "urn:research:5619586e-de5a-4bc3-ac80-04dd8530d80c",
                "name": "Nature Biomedical Engineering",
                "alternate_names": [
                    "Nat Biomed Eng"
                ],
                "issn": "2157-846X",
                "url": "http://www.nature.com/natbiomedeng/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2004-09666",
                "ArXiv": "2004.09666",
                "MAG": "3018295606",
                "DOI": "10.1038/s41551-020-00682-w",
                "CorpusId": 216036034,
                "PubMed": "33649564"
            },
            "abstract": null,
            "referenceCount": 56,
            "citationCount": 592,
            "influentialCitationCount": 95,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-04-20",
            "journal": {
                "name": "Nature Biomedical Engineering",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Lu2020DataefficientAW,\n author = {Ming Y. Lu and Drew F. K. Williamson and Tiffany Y. Chen and Richard J. Chen and Matteo Barbieri and Faisal Mahmood},\n booktitle = {Nature Biomedical Engineering},\n journal = {Nature Biomedical Engineering},\n pages = {555 - 570},\n title = {Data-efficient and weakly supervised computational pathology on whole-slide images},\n volume = {5},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3a84214cb69ea0b34352285029f368b75718c32b",
            "@type": "ScholarlyArticle",
            "paperId": "3a84214cb69ea0b34352285029f368b75718c32b",
            "corpusId": 3819513,
            "url": "https://www.semanticscholar.org/paper/3a84214cb69ea0b34352285029f368b75718c32b",
            "title": "Understanding of a convolutional neural network",
            "venue": "International Conference on Emerging Technologies",
            "publicationVenue": {
                "id": "urn:research:12b499eb-56c9-4d88-b792-6d90ceff3485",
                "name": "International Conference on Emerging Technologies",
                "alternate_names": [
                    "ICET",
                    "Int Conf Emerg Technol"
                ],
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2789876780",
                "DOI": "10.1109/ICENGTECHNOL.2017.8308186",
                "CorpusId": 3819513
            },
            "abstract": "The term Deep Learning or Deep Neural Network refers to Artificial Neural Networks (ANN) with multi layers. Over the last few decades, it has been considered to be one of the most powerful tools, and has become very popular in the literature as it is able to handle a huge amount of data. The interest in having deeper hidden layers has recently begun to surpass classical methods performance in different fields; especially in pattern recognition. One of the most popular deep neural networks is the Convolutional Neural Network (CNN). It take this name from mathematical linear operation between matrixes called convolution. CNN have multiple layers; including convolutional layer, non-linearity layer, pooling layer and fully-connected layer. The convolutional and fully-connected layers have parameters but pooling and non-linearity layers don't have parameters. The CNN has an excellent performance in machine learning problems. Specially the applications that deal with image data, such as largest image classification data set (Image Net), computer vision, and in natural language processing (NLP) and the results achieved were very amazing. In this paper we will explain and define all the elements and important issues related to CNN, and how these elements work. In addition, we will also state the parameters that effect CNN efficiency. This paper assumes that the readers have adequate knowledge about both machine learning and artificial neural network.",
            "referenceCount": 13,
            "citationCount": 2137,
            "influentialCitationCount": 150,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference"
            ],
            "publicationDate": "2017-08-01",
            "journal": {
                "name": "2017 International Conference on Engineering and Technology (ICET)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Albawi2017UnderstandingOA,\n author = {Saad Albawi and T. Mohammed and Saad Al-Zawi},\n booktitle = {International Conference on Emerging Technologies},\n journal = {2017 International Conference on Engineering and Technology (ICET)},\n pages = {1-6},\n title = {Understanding of a convolutional neural network},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1d122a074c936fcfd95faf44608e377a9d1799c8",
            "@type": "ScholarlyArticle",
            "paperId": "1d122a074c936fcfd95faf44608e377a9d1799c8",
            "corpusId": 970388,
            "url": "https://www.semanticscholar.org/paper/1d122a074c936fcfd95faf44608e377a9d1799c8",
            "title": "DeepFM: A Factorization-Machine based Neural Network for CTR Prediction",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/ijcai/GuoTYLH17",
                "ArXiv": "1703.04247",
                "MAG": "2951001079",
                "DOI": "10.24963/ijcai.2017/239",
                "CorpusId": 970388
            },
            "abstract": "Learning sophisticated feature interactions behind user behaviors is critical in maximizing CTR for recommender systems. Despite great progress, existing methods seem to have a strong bias towards low- or high-order interactions, or require expertise feature engineering. In this paper, we show that it is possible to derive an end-to-end learning model that emphasizes both low- and high-order feature interactions. The proposed model, DeepFM, combines the power of factorization machines for recommendation and deep learning for feature learning in a new neural network architecture. Compared to the latest Wide & Deep model from Google, DeepFM has a shared input to its \"wide\" and \"deep\" parts, with no need of feature engineering besides raw features. Comprehensive experiments are conducted to demonstrate the effectiveness and efficiency of DeepFM over the existing models for CTR prediction, on both benchmark data and commercial data.",
            "referenceCount": 33,
            "citationCount": 2024,
            "influentialCitationCount": 385,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.ijcai.org/proceedings/2017/0239.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-13",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.04247"
            },
            "citationStyles": {
                "bibtex": "@Article{Guo2017DeepFMAF,\n author = {Huifeng Guo and Ruiming Tang and Yunming Ye and Zhenguo Li and Xiuqiang He},\n booktitle = {International Joint Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {DeepFM: A Factorization-Machine based Neural Network for CTR Prediction},\n volume = {abs/1703.04247},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:90a99fb11720ad5977f9195c8edbb217744b0f67",
            "@type": "ScholarlyArticle",
            "paperId": "90a99fb11720ad5977f9195c8edbb217744b0f67",
            "corpusId": 320049,
            "url": "https://www.semanticscholar.org/paper/90a99fb11720ad5977f9195c8edbb217744b0f67",
            "title": "On the Expressive Power of Deep Architectures",
            "venue": "International Conference on Algorithmic Learning Theory",
            "publicationVenue": {
                "id": "urn:research:595ab61a-e207-4f43-b0fd-46f575477e98",
                "name": "International Conference on Algorithmic Learning Theory",
                "alternate_names": [
                    "ALT",
                    "Algorithmic Learning Theory",
                    "Int Conf Algorithmic Learn Theory",
                    "Algorithmic Learn Theory"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=143"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2584401907",
                "DBLP": "conf/dis/BengioD11",
                "DOI": "10.1007/978-3-642-24412-4_3",
                "CorpusId": 320049
            },
            "abstract": null,
            "referenceCount": 72,
            "citationCount": 287,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2F978-3-642-24477-3_1.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2011-10-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bengio2011OnTE,\n author = {Yoshua Bengio and Olivier Delalleau},\n booktitle = {International Conference on Algorithmic Learning Theory},\n pages = {18-36},\n title = {On the Expressive Power of Deep Architectures},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1eb7f46b1a0a7df823194d86543e5554aa21021a",
            "@type": "ScholarlyArticle",
            "paperId": "1eb7f46b1a0a7df823194d86543e5554aa21021a",
            "corpusId": 174803437,
            "url": "https://www.semanticscholar.org/paper/1eb7f46b1a0a7df823194d86543e5554aa21021a",
            "title": "Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1906.02530",
                "DBLP": "conf/nips/SnoekOFLNSDRN19",
                "MAG": "2970859221",
                "CorpusId": 174803437
            },
            "abstract": "Modern machine learning methods including deep learning have achieved great success in predictive accuracy for supervised learning tasks, but may still fall short in giving useful estimates of their predictive {\\em uncertainty}. Quantifying uncertainty is especially critical in real-world settings, which often involve input distributions that are shifted from the training distribution due to a variety of factors including sample bias and non-stationarity. In such settings, well calibrated uncertainty estimates convey information about when a model's output should (or should not) be trusted. Many probabilistic deep learning methods, including Bayesian-and non-Bayesian methods, have been proposed in the literature for quantifying predictive uncertainty, but to our knowledge there has not previously been a rigorous large-scale empirical comparison of these methods under dataset shift. We present a large-scale benchmark of existing state-of-the-art methods on classification problems and investigate the effect of dataset shift on accuracy and calibration. We find that traditional post-hoc calibration does indeed fall short, as do several other previous methods. However, some methods that marginalize over models give surprisingly strong results across a broad spectrum of tasks.",
            "referenceCount": 59,
            "citationCount": 1222,
            "influentialCitationCount": 128,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ovadia2019CanYT,\n author = {Yaniv Ovadia and Emily Fertig and Jie Jessie Ren and Zachary Nado and D. Sculley and Sebastian Nowozin and Joshua V. Dillon and Balaji Lakshminarayanan and Jasper Snoek},\n booktitle = {Neural Information Processing Systems},\n pages = {13969-13980},\n title = {Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9ba0186ed40656329c421f55ada7313293e13f17",
            "@type": "ScholarlyArticle",
            "paperId": "9ba0186ed40656329c421f55ada7313293e13f17",
            "corpusId": 3508727,
            "url": "https://www.semanticscholar.org/paper/9ba0186ed40656329c421f55ada7313293e13f17",
            "title": "Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963358464",
                "DBLP": "conf/iclr/LiYS018",
                "CorpusId": 3508727
            },
            "abstract": "Spatiotemporal forecasting has various applications in neuroscience, climate and transportation domain. Traffic forecasting is one canonical example of such learning task. The task is challenging due to (1) complex spatial dependency on road networks, (2) non-linear temporal dynamics with changing road conditions and (3) inherent difficulty of long-term forecasting. To address these challenges, we propose to model the traffic flow as a diffusion process on a directed graph and introduce Diffusion Convolutional Recurrent Neural Network (DCRNN), a deep learning framework for traffic forecasting that incorporates both spatial and temporal dependency in the traffic flow. Specifically, DCRNN captures the spatial dependency using bidirectional random walks on the graph, and the temporal dependency using the encoder-decoder architecture with scheduled sampling. We evaluate the framework on two real-world large scale road network traffic datasets and observe consistent improvement of 12% - 15% over state-of-the-art baselines.",
            "referenceCount": 41,
            "citationCount": 1963,
            "influentialCitationCount": 530,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-06",
            "journal": {
                "name": "arXiv: Learning",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Li2017DiffusionCR,\n author = {Yaguang Li and Rose Yu and C. Shahabi and Yan Liu},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Learning},\n title = {Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad",
            "@type": "ScholarlyArticle",
            "paperId": "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad",
            "corpusId": 604334,
            "url": "https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad",
            "title": "Intriguing properties of neural networks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2013,
            "externalIds": {
                "ArXiv": "1312.6199",
                "MAG": "2964153729",
                "DBLP": "journals/corr/SzegedyZSBEGF13",
                "CorpusId": 604334
            },
            "abstract": "Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. \nFirst, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. \nSecond, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.",
            "referenceCount": 14,
            "citationCount": 12238,
            "influentialCitationCount": 1230,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-12-20",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1312.6199"
            },
            "citationStyles": {
                "bibtex": "@Article{Szegedy2013IntriguingPO,\n author = {Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and D. Erhan and I. Goodfellow and R. Fergus},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Intriguing properties of neural networks},\n volume = {abs/1312.6199},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:892f9a2f69241feec647856cd26bed37e04fd747",
            "@type": "ScholarlyArticle",
            "paperId": "892f9a2f69241feec647856cd26bed37e04fd747",
            "corpusId": 11971778,
            "url": "https://www.semanticscholar.org/paper/892f9a2f69241feec647856cd26bed37e04fd747",
            "title": "Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2963815651",
                "DBLP": "journals/jmlr/LiJDRT17",
                "ArXiv": "1603.06560",
                "CorpusId": 11971778
            },
            "abstract": "Performance of machine learning algorithms depends critically on identifying a good set of hyperparameters. While recent approaches use Bayesian optimization to adaptively select configurations, we focus on speeding up random search through adaptive resource allocation and early-stopping. We formulate hyperparameter optimization as a pure-exploration non-stochastic infinite-armed bandit problem where a predefined resource like iterations, data samples, or features is allocated to randomly sampled configurations. We introduce a novel algorithm, Hyperband, for this framework and analyze its theoretical properties, providing several desirable guarantees. Furthermore, we compare Hyperband with popular Bayesian optimization methods on a suite of hyperparameter optimization problems. We observe that Hyperband can provide over an order-of-magnitude speedup over our competitor set on a variety of deep-learning and kernel-based learning problems.",
            "referenceCount": 58,
            "citationCount": 1730,
            "influentialCitationCount": 223,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-03-21",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2016HyperbandAN,\n author = {Lisha Li and Kevin G. Jamieson and Giulia DeSalvo and Afshin Rostamizadeh and Ameet Talwalkar},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {185:1-185:52},\n title = {Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization},\n volume = {18},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0c1f9ca23f4f09ecfc44bcc8ca1c2736624f4652",
            "@type": "ScholarlyArticle",
            "paperId": "0c1f9ca23f4f09ecfc44bcc8ca1c2736624f4652",
            "corpusId": 15953218,
            "url": "https://www.semanticscholar.org/paper/0c1f9ca23f4f09ecfc44bcc8ca1c2736624f4652",
            "title": "A Theoretically Grounded Application of Dropout in Recurrent Neural Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2963266340",
                "DBLP": "conf/nips/GalG16",
                "ArXiv": "1512.05287",
                "CorpusId": 15953218
            },
            "abstract": "Recurrent neural networks (RNNs) stand at the forefront of many recent developments in deep learning. Yet a major difficulty with these models is their tendency to overfit, with dropout shown to fail when applied to recurrent layers. Recent results at the intersection of Bayesian modelling and deep learning offer a Bayesian interpretation of common deep learning techniques such as dropout. This grounding of dropout in approximate Bayesian inference suggests an extension of the theoretical results, offering insights into the use of dropout with RNN models. We apply this new variational inference based dropout technique in LSTM and GRU models, assessing it on language modelling and sentiment analysis tasks. The new approach outperforms existing techniques, and to the best of our knowledge improves on the single model state-of-the-art in language modelling with the Penn Treebank (73.4 test perplexity). This extends our arsenal of variational tools in deep learning.",
            "referenceCount": 36,
            "citationCount": 1538,
            "influentialCitationCount": 193,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-12-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gal2015ATG,\n author = {Y. Gal and Zoubin Ghahramani},\n booktitle = {Neural Information Processing Systems},\n pages = {1019-1027},\n title = {A Theoretically Grounded Application of Dropout in Recurrent Neural Networks},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b1e7f07965a53491690bd31fdab626bfac606eae",
            "@type": "ScholarlyArticle",
            "paperId": "b1e7f07965a53491690bd31fdab626bfac606eae",
            "corpusId": 6037691,
            "url": "https://www.semanticscholar.org/paper/b1e7f07965a53491690bd31fdab626bfac606eae",
            "title": "Deeper, Broader and Artier Domain Generalization",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/abs-1710-03077",
                "MAG": "2763549966",
                "ArXiv": "1710.03077",
                "DOI": "10.1109/ICCV.2017.591",
                "CorpusId": 6037691
            },
            "abstract": "The problem of domain generalization is to learn from multiple training domains, and extract a domain-agnostic model that can then be applied to an unseen domain. Domain generalization (DG) has a clear motivation in contexts where there are target domains with distinct characteristics, yet sparse data for training. For example recognition in sketch images, which are distinctly more abstract and rarer than photos. Nevertheless, DG methods have primarily been evaluated on photo-only benchmarks focusing on alleviating the dataset bias where both problems of domain distinctiveness and data sparsity can be minimal. We argue that these benchmarks are overly straightforward, and show that simple deep learning baselines perform surprisingly well on them. In this paper, we make two main contributions: Firstly, we build upon the favorable domain shift-robust properties of deep learning methods, and develop a low-rank parameterized CNN model for end-to-end DG learning. Secondly, we develop a DG benchmark dataset covering photo, sketch, cartoon and painting domains. This is both more practically relevant, and harder (bigger domain shift) than existing benchmarks. The results show that our method outperforms existing DG alternatives, and our dataset provides a more significant DG challenge to drive future research.",
            "referenceCount": 34,
            "citationCount": 1023,
            "influentialCitationCount": 325,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pure.ed.ac.uk/ws/files/41072820/li2017dg.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-10-09",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Li2017DeeperBA,\n author = {Da Li and Yongxin Yang and Yi-Zhe Song and Timothy M. Hospedales},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2017 IEEE International Conference on Computer Vision (ICCV)},\n pages = {5543-5551},\n title = {Deeper, Broader and Artier Domain Generalization},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dc8301b67f98accbb331190dd7bd987952a692af",
            "@type": "ScholarlyArticle",
            "paperId": "dc8301b67f98accbb331190dd7bd987952a692af",
            "corpusId": 13995862,
            "url": "https://www.semanticscholar.org/paper/dc8301b67f98accbb331190dd7bd987952a692af",
            "title": "NICE: Non-linear Independent Components Estimation",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2964020555",
                "DBLP": "journals/corr/DinhKB14",
                "ArXiv": "1410.8516",
                "CorpusId": 13995862
            },
            "abstract": "We propose a deep learning framework for modeling complex high-dimensional densities called Non-linear Independent Component Estimation (NICE). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model. For this purpose, a non-linear deterministic transformation of the data is learned that maps it to a latent space so as to make the transformed data conform to a factorized distribution, i.e., resulting in independent latent variables. We parametrize this transformation so that computing the Jacobian determinant and inverse transform is trivial, yet we maintain the ability to learn complex non-linear transformations, via a composition of simple building blocks, each based on a deep neural network. The training criterion is simply the exact log-likelihood, which is tractable. Unbiased ancestral sampling is also easy. We show that this approach yields good generative models on four image datasets and can be used for inpainting.",
            "referenceCount": 35,
            "citationCount": 1779,
            "influentialCitationCount": 268,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-10-30",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1410.8516"
            },
            "citationStyles": {
                "bibtex": "@Article{Dinh2014NICENI,\n author = {Laurent Dinh and David Krueger and Yoshua Bengio},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {NICE: Non-linear Independent Components Estimation},\n volume = {abs/1410.8516},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:424a6e62084d919bfc2e39a507c263e5991ebdad",
            "@type": "ScholarlyArticle",
            "paperId": "424a6e62084d919bfc2e39a507c263e5991ebdad",
            "corpusId": 13713980,
            "url": "https://www.semanticscholar.org/paper/424a6e62084d919bfc2e39a507c263e5991ebdad",
            "title": "Self-Normalizing Neural Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2624413595",
                "DBLP": "journals/corr/KlambauerUMH17",
                "ArXiv": "1706.02515",
                "CorpusId": 13713980
            },
            "abstract": "Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are \"scaled exponential linear units\" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance -- even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: this http URL.",
            "referenceCount": 42,
            "citationCount": 1881,
            "influentialCitationCount": 203,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-06-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1706.02515"
            },
            "citationStyles": {
                "bibtex": "@Article{Klambauer2017SelfNormalizingNN,\n author = {G. Klambauer and Thomas Unterthiner and Andreas Mayr and S. Hochreiter},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Self-Normalizing Neural Networks},\n volume = {abs/1706.02515},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bef8694328016889a4b87761984046e1d9cf79b9",
            "@type": "ScholarlyArticle",
            "paperId": "bef8694328016889a4b87761984046e1d9cf79b9",
            "corpusId": 4710341,
            "url": "https://www.semanticscholar.org/paper/bef8694328016889a4b87761984046e1d9cf79b9",
            "title": "Fast, Accurate, and, Lightweight Super-Resolution with Cascading Residual Network",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2790610275",
                "DBLP": "journals/corr/abs-1803-08664",
                "ArXiv": "1803.08664",
                "DOI": "10.1007/978-3-030-01249-6_16",
                "CorpusId": 4710341
            },
            "abstract": null,
            "referenceCount": 39,
            "citationCount": 842,
            "influentialCitationCount": 246,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1803.08664",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-03-23",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1803.08664"
            },
            "citationStyles": {
                "bibtex": "@Article{Ahn2018FastAA,\n author = {Namhyuk Ahn and Byungkon Kang and Kyung-ah Sohn},\n booktitle = {European Conference on Computer Vision},\n journal = {ArXiv},\n title = {Fast, Accurate, and, Lightweight Super-Resolution with Cascading Residual Network},\n volume = {abs/1803.08664},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:efb5032e6199c80f83309fd866b25be9545831fd",
            "@type": "ScholarlyArticle",
            "paperId": "efb5032e6199c80f83309fd866b25be9545831fd",
            "corpusId": 543597,
            "url": "https://www.semanticscholar.org/paper/efb5032e6199c80f83309fd866b25be9545831fd",
            "title": "Compressing Neural Networks with the Hashing Trick",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1504.04788",
                "DBLP": "journals/corr/ChenWTWC15",
                "MAG": "2952432176",
                "CorpusId": 543597
            },
            "abstract": "As deep nets are increasingly used in applications suited for mobile devices, a fundamental dilemma becomes apparent: the trend in deep learning is to grow models to absorb ever-increasing data set sizes; however mobile devices are designed with very little memory and cannot store such large models. We present a novel network architecture, HashedNets, that exploits inherent redundancy in neural networks to achieve drastic reductions in model sizes. HashedNets uses a low-cost hash function to randomly group connection weights into hash buckets, and all connections within the same hash bucket share a single parameter value. These parameters are tuned to adjust to the HashedNets weight sharing architecture with standard backprop during training. Our hashing procedure introduces no additional memory overhead, and we demonstrate on several benchmark data sets that HashedNets shrink the storage requirements of neural networks substantially while mostly preserving generalization performance.",
            "referenceCount": 56,
            "citationCount": 1119,
            "influentialCitationCount": 70,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-04-18",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1504.04788"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2015CompressingNN,\n author = {Wenlin Chen and James T. Wilson and Stephen Tyree and Kilian Q. Weinberger and Yixin Chen},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Compressing Neural Networks with the Hashing Trick},\n volume = {abs/1504.04788},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:13c185b8c461034af2634f25dd8a85889e8ee135",
            "@type": "ScholarlyArticle",
            "paperId": "13c185b8c461034af2634f25dd8a85889e8ee135",
            "corpusId": 166228758,
            "url": "https://www.semanticscholar.org/paper/13c185b8c461034af2634f25dd8a85889e8ee135",
            "title": "N-BEATS: Neural basis expansion analysis for interpretable time series forecasting",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/iclr/OreshkinCCB20",
                "MAG": "2996552856",
                "ArXiv": "1905.10437",
                "CorpusId": 166228758
            },
            "abstract": "We focus on solving the univariate times series point forecasting problem using deep learning. We propose a deep neural architecture based on backward and forward residual links and a very deep stack of fully-connected layers. The architecture has a number of desirable properties, being interpretable, applicable without modification to a wide array of target domains, and fast to train. We test the proposed architecture on several well-known datasets, including M3, M4 and TOURISM competition datasets containing time series from diverse domains. We demonstrate state-of-the-art performance for two configurations of N-BEATS for all the datasets, improving forecast accuracy by 11% over a statistical benchmark and by 3% over last year's winner of the M4 competition, a domain-adjusted hand-crafted hybrid between neural network and statistical time series models. The first configuration of our model does not employ any time-series-specific components and its performance on heterogeneous datasets strongly suggests that, contrarily to received wisdom, deep learning primitives such as residual blocks are by themselves sufficient to solve a wide range of forecasting problems. Finally, we demonstrate how the proposed architecture can be augmented to provide outputs that are interpretable without considerable loss in accuracy.",
            "referenceCount": 45,
            "citationCount": 538,
            "influentialCitationCount": 127,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-05-24",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1905.10437"
            },
            "citationStyles": {
                "bibtex": "@Article{Oreshkin2019NBEATSNB,\n author = {Boris N. Oreshkin and Dmitri Carpov and Nicolas Chapados and Yoshua Bengio},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {N-BEATS: Neural basis expansion analysis for interpretable time series forecasting},\n volume = {abs/1905.10437},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:869fdb53a40290a3941fd6ab808835e9b5184d62",
            "@type": "ScholarlyArticle",
            "paperId": "869fdb53a40290a3941fd6ab808835e9b5184d62",
            "corpusId": 52901134,
            "url": "https://www.semanticscholar.org/paper/869fdb53a40290a3941fd6ab808835e9b5184d62",
            "title": "Adversarial Attacks and Defences: A Survey",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2893554781",
                "DBLP": "journals/corr/abs-1810-00069",
                "ArXiv": "1810.00069",
                "CorpusId": 52901134
            },
            "abstract": "Deep learning has emerged as a strong and efficient framework that can be applied to a broad spectrum of complex learning problems which were difficult to solve using the traditional machine learning techniques in the past. In the last few years, deep learning has advanced radically in such a way that it can surpass human-level performance on a number of tasks. As a consequence, deep learning is being extensively used in most of the recent day-to-day applications. However, security of deep learning systems are vulnerable to crafted adversarial examples, which may be imperceptible to the human eye, but can lead the model to misclassify the output. In recent times, different types of adversaries based on their threat model leverage these vulnerabilities to compromise a deep learning system where adversaries have high incentives. Hence, it is extremely important to provide robustness to deep learning algorithms against these adversaries. However, there are only a few strong countermeasures which can be used in all types of attack scenarios to design a robust deep learning system. In this paper, we attempt to provide a detailed discussion on different types of adversarial attacks with various threat models and also elaborate the efficiency and challenges of recent countermeasures against them.",
            "referenceCount": 75,
            "citationCount": 533,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-09-28",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1810.00069"
            },
            "citationStyles": {
                "bibtex": "@Article{Chakraborty2018AdversarialAA,\n author = {Anirban Chakraborty and Manaar Alam and Vishal Dey and A. Chattopadhyay and Debdeep Mukhopadhyay},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Adversarial Attacks and Defences: A Survey},\n volume = {abs/1810.00069},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3df05017006ae30d9414ebf08b2bd7211451e3e8",
            "@type": "ScholarlyArticle",
            "paperId": "3df05017006ae30d9414ebf08b2bd7211451e3e8",
            "corpusId": 26370837,
            "url": "https://www.semanticscholar.org/paper/3df05017006ae30d9414ebf08b2bd7211451e3e8",
            "title": "Using LSTM and GRU neural network methods for traffic flow prediction",
            "venue": "Youth Academic Annual Conference of Chinese Association of Automation",
            "publicationVenue": {
                "id": "urn:research:7e280d98-c90c-428c-baba-a46e4abde912",
                "name": "Youth Academic Annual Conference of Chinese Association of Automation",
                "alternate_names": [
                    "YAC",
                    "Youth Acad Annu Conf Chin Assoc Autom"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2572939427",
                "DOI": "10.1109/YAC.2016.7804912",
                "CorpusId": 26370837
            },
            "abstract": "Accurate and real-time traffic flow prediction is important in Intelligent Transportation System (ITS), especially for traffic control. Existing models such as ARMA, ARIMA are mainly linear models and cannot describe the stochastic and nonlinear nature of traffic flow. In recent years, deep-learning-based methods have been applied as novel alternatives for traffic flow prediction. However, which kind of deep neural networks is the most appropriate model for traffic flow prediction remains unsolved. In this paper, we use Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU) neural network (NN) methods to predict short-term traffic flow, and experiments demonstrate that Recurrent Neural Network (RNN) based deep learning methods such as LSTM and GRU perform better than auto regressive integrated moving average (ARIMA) model. To the best of our knowledge, this is the first time that GRU is applied to traffic flow prediction.",
            "referenceCount": 15,
            "citationCount": 819,
            "influentialCitationCount": 65,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference"
            ],
            "publicationDate": "2016-11-01",
            "journal": {
                "name": "2016 31st Youth Academic Annual Conference of Chinese Association of Automation (YAC)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Fu2016UsingLA,\n author = {Rui Fu and Zuo Zhang and Li Li},\n booktitle = {Youth Academic Annual Conference of Chinese Association of Automation},\n journal = {2016 31st Youth Academic Annual Conference of Chinese Association of Automation (YAC)},\n pages = {324-328},\n title = {Using LSTM and GRU neural network methods for traffic flow prediction},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3c5f1ab37f70db503636075e15b3173f86eea00b",
            "@type": "ScholarlyArticle",
            "paperId": "3c5f1ab37f70db503636075e15b3173f86eea00b",
            "corpusId": 198229505,
            "url": "https://www.semanticscholar.org/paper/3c5f1ab37f70db503636075e15b3173f86eea00b",
            "title": "Green AI",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1907.10597",
                "CorpusId": 198229505
            },
            "abstract": "The computations required for deep learning research have been doubling every few months, resulting in an estimated 300,000x increase from 2012 to 2018 [2]. These computations have a surprisingly large carbon footprint [38]. Ironically, deep learning was inspired by the human brain, which is remarkably energy efficient. Moreover, the financial cost of the computations can make it difficult for academics, students, and researchers, in particular those from emerging economies, to engage in deep learning research. This position paper advocates a practical solution by making efficiency an evaluation criterion for research alongside accuracy and related measures. In addition, we propose reporting the financial cost or\"price tag\"of developing, training, and running models to provide baselines for the investigation of increasingly efficient methods. Our goal is to make AI both greener and more inclusive---enabling any inspired undergraduate with a laptop to write high-quality research papers. Green AI is an emerging focus at the Allen Institute for AI.",
            "referenceCount": 48,
            "citationCount": 685,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-07-22",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Schwartz2019GreenA,\n author = {Roy Schwartz and Jesse Dodge and Noah A. Smith and Oren Etzioni},\n title = {Green AI},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:34f25a8704614163c4095b3ee2fc969b60de4698",
            "@type": "ScholarlyArticle",
            "paperId": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "corpusId": 6844431,
            "url": "https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698",
            "title": "Dropout: a simple way to prevent neural networks from overfitting",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/jmlr/SrivastavaHKSS14",
                "MAG": "2095705004",
                "DOI": "10.5555/2627435.2670313",
                "CorpusId": 6844431
            },
            "abstract": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.",
            "referenceCount": 38,
            "citationCount": 35201,
            "influentialCitationCount": 2748,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Srivastava2014DropoutAS,\n author = {Nitish Srivastava and Geoffrey E. Hinton and A. Krizhevsky and Ilya Sutskever and R. Salakhutdinov},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {1929-1958},\n title = {Dropout: a simple way to prevent neural networks from overfitting},\n volume = {15},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4feef0fd284feb1233399b400eb897f59ec92755",
            "@type": "ScholarlyArticle",
            "paperId": "4feef0fd284feb1233399b400eb897f59ec92755",
            "corpusId": 3162051,
            "url": "https://www.semanticscholar.org/paper/4feef0fd284feb1233399b400eb897f59ec92755",
            "title": "mixup: Beyond Empirical Risk Minimization",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2950225141",
                "DBLP": "journals/corr/abs-1710-09412",
                "ArXiv": "1710.09412",
                "CorpusId": 3162051
            },
            "abstract": "Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.",
            "referenceCount": 39,
            "citationCount": 6763,
            "influentialCitationCount": 1351,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1710.09412"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2017mixupBE,\n author = {Hongyi Zhang and Moustapha Ciss\u00e9 and Yann Dauphin and David Lopez-Paz},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {mixup: Beyond Empirical Risk Minimization},\n volume = {abs/1710.09412},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:acd87843a451d18b4dc6474ddce1ae946429eaf1",
            "@type": "ScholarlyArticle",
            "paperId": "acd87843a451d18b4dc6474ddce1ae946429eaf1",
            "corpusId": 2057420,
            "url": "https://www.semanticscholar.org/paper/acd87843a451d18b4dc6474ddce1ae946429eaf1",
            "title": "Wasserstein Generative Adversarial Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2739748921",
                "DBLP": "conf/icml/ArjovskyCB17",
                "CorpusId": 2057420
            },
            "abstract": "We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.",
            "referenceCount": 26,
            "citationCount": 6226,
            "influentialCitationCount": 1149,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-07-17",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Arjovsky2017WassersteinGA,\n author = {Mart\u00edn Arjovsky and Soumith Chintala and L. Bottou},\n booktitle = {International Conference on Machine Learning},\n pages = {214-223},\n title = {Wasserstein Generative Adversarial Networks},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4debb99c0c63bfaa97dd433bc2828e4dac81c48b",
            "@type": "ScholarlyArticle",
            "paperId": "4debb99c0c63bfaa97dd433bc2828e4dac81c48b",
            "corpusId": 3544558,
            "url": "https://www.semanticscholar.org/paper/4debb99c0c63bfaa97dd433bc2828e4dac81c48b",
            "title": "Addressing Function Approximation Error in Actor-Critic Methods",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2963923407",
                "DBLP": "journals/corr/abs-1802-09477",
                "ArXiv": "1802.09477",
                "CorpusId": 3544558
            },
            "abstract": "In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.",
            "referenceCount": 49,
            "citationCount": 3254,
            "influentialCitationCount": 833,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-02-26",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Fujimoto2018AddressingFA,\n author = {Scott Fujimoto and H. V. Hoof and D. Meger},\n booktitle = {International Conference on Machine Learning},\n pages = {1582-1591},\n title = {Addressing Function Approximation Error in Actor-Critic Methods},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:329b84a919bfd1771be5bd14fa81e7b3f74cc961",
            "@type": "ScholarlyArticle",
            "paperId": "329b84a919bfd1771be5bd14fa81e7b3f74cc961",
            "corpusId": 174802445,
            "url": "https://www.semanticscholar.org/paper/329b84a919bfd1771be5bd14fa81e7b3f74cc961",
            "title": "An Introduction to Variational Autoencoders",
            "venue": "Found. Trends Mach. Learn.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2948978827",
                "ArXiv": "1906.02691",
                "DBLP": "journals/corr/abs-1906-02691",
                "DOI": "10.1561/2200000056",
                "CorpusId": 174802445
            },
            "abstract": "Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.",
            "referenceCount": 148,
            "citationCount": 1440,
            "influentialCitationCount": 119,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1906.02691",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1906.02691"
            },
            "citationStyles": {
                "bibtex": "@Article{Kingma2019AnIT,\n author = {Diederik P. Kingma and M. Welling},\n booktitle = {Found. Trends Mach. Learn.},\n journal = {ArXiv},\n title = {An Introduction to Variational Autoencoders},\n volume = {abs/1906.02691},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f01fc808592ea7c473a69a6e7484040a435f36d9",
            "@type": "ScholarlyArticle",
            "paperId": "f01fc808592ea7c473a69a6e7484040a435f36d9",
            "corpusId": 5736847,
            "url": "https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9",
            "title": "Long-term recurrent convolutional networks for visual recognition and description",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1947481528",
                "DBLP": "journals/pami/DonahueHRVGSD17",
                "ArXiv": "1411.4389",
                "DOI": "10.1109/CVPR.2015.7298878",
                "CorpusId": 5736847,
                "PubMed": "27608449"
            },
            "abstract": "Models based on deep convolutional networks have dominated recent image interpretation tasks; we investigate whether models which are also recurrent, or \u201ctemporally deep\u201d, are effective for tasks involving sequences, visual and otherwise. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image description and retrieval problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are \u201cdoubly deep\u201d in that they can be compositional in spatial and temporal \u201clayers\u201d. Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable-length inputs (e.g., video frames) to variable length outputs (e.g., natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to modern visual convnet models and can be jointly trained to simultaneously learn temporal dynamics and convolutional perceptual representations. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.",
            "referenceCount": 89,
            "citationCount": 5628,
            "influentialCitationCount": 571,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-11-17",
            "journal": {
                "name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Donahue2014LongtermRC,\n author = {Jeff Donahue and Lisa Anne Hendricks and Marcus Rohrbach and Subhashini Venugopalan and S. Guadarrama and Kate Saenko and Trevor Darrell},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {2625-2634},\n title = {Long-term recurrent convolutional networks for visual recognition and description},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:67dccc9a856b60bdc4d058d83657a089b8ad4486",
            "@type": "ScholarlyArticle",
            "paperId": "67dccc9a856b60bdc4d058d83657a089b8ad4486",
            "corpusId": 11797475,
            "url": "https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486",
            "title": "Two-Stream Convolutional Networks for Action Recognition in Videos",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2952186347",
                "DBLP": "conf/nips/SimonyanZ14",
                "ArXiv": "1406.2199",
                "CorpusId": 11797475
            },
            "abstract": "We investigate architectures of discriminatively trained deep Convolutional Networks (ConvNets) for action recognition in video. The challenge is to capture the complementary information on appearance from still frames and motion between frames. We also aim to generalise the best performing hand-crafted features within a data-driven learning framework. \n \nOur contribution is three-fold. First, we propose a two-stream ConvNet architecture which incorporates spatial and temporal networks. Second, we demonstrate that a ConvNet trained on multi-frame dense optical flow is able to achieve very good performance in spite of limited training data. Finally, we show that multitask learning, applied to two different action classification datasets, can be used to increase the amount of training data and improve the performance on both. Our architecture is trained and evaluated on the standard video actions benchmarks of UCF-101 and HMDB-51, where it is competitive with the state of the art. It also exceeds by a large margin previous attempts to use deep nets for video classification.",
            "referenceCount": 33,
            "citationCount": 6756,
            "influentialCitationCount": 976,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-06-09",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1406.2199"
            },
            "citationStyles": {
                "bibtex": "@Article{Simonyan2014TwoStreamCN,\n author = {K. Simonyan and Andrew Zisserman},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Two-Stream Convolutional Networks for Action Recognition in Videos},\n volume = {abs/1406.2199},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2e55ba6c97ce5eb55abd959909403fe8da7e9fe9",
            "@type": "ScholarlyArticle",
            "paperId": "2e55ba6c97ce5eb55abd959909403fe8da7e9fe9",
            "corpusId": 4704285,
            "url": "https://www.semanticscholar.org/paper/2e55ba6c97ce5eb55abd959909403fe8da7e9fe9",
            "title": "Overcoming catastrophic forgetting in neural networks",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1612.00796",
                "MAG": "2560647685",
                "DBLP": "journals/corr/KirkpatrickPRVD16",
                "DOI": "10.1073/pnas.1611835114",
                "CorpusId": 4704285,
                "PubMed": "28292907"
            },
            "abstract": "Significance Deep neural networks are currently the most successful machine-learning technique for solving a variety of tasks, including language translation, image classification, and image generation. One weakness of such models is that, unlike humans, they are unable to learn multiple tasks sequentially. In this work we propose a practical solution to train such models sequentially by protecting the weights important for previous tasks. This approach, inspired by synaptic consolidation in neuroscience, enables state of the art results on multiple reinforcement learning problems experienced sequentially. The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Until now neural networks have not been capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks that they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on a hand-written digit dataset and by learning several Atari 2600 games sequentially.",
            "referenceCount": 48,
            "citationCount": 4745,
            "influentialCitationCount": 945,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pnas.org/content/pnas/114/13/3521.full.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-12-02",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences",
                "volume": "114"
            },
            "citationStyles": {
                "bibtex": "@Article{Kirkpatrick2016OvercomingCF,\n author = {J. Kirkpatrick and Razvan Pascanu and Neil C. Rabinowitz and J. Veness and Guillaume Desjardins and Andrei A. Rusu and Kieran Milan and John Quan and Tiago Ramalho and A. Grabska-Barwinska and D. Hassabis and C. Clopath and D. Kumaran and R. Hadsell},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {3521 - 3526},\n title = {Overcoming catastrophic forgetting in neural networks},\n volume = {114},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2530cfc7764bda1330c48c0c8e2cd0e0c671d7e1",
            "@type": "ScholarlyArticle",
            "paperId": "2530cfc7764bda1330c48c0c8e2cd0e0c671d7e1",
            "corpusId": 6755881,
            "url": "https://www.semanticscholar.org/paper/2530cfc7764bda1330c48c0c8e2cd0e0c671d7e1",
            "title": "Unsupervised Domain Adaptation by Backpropagation",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2014,
            "externalIds": {
                "ArXiv": "1409.7495",
                "MAG": "2951688345",
                "DBLP": "conf/icml/GaninL15",
                "CorpusId": 6755881
            },
            "abstract": "Top-performing deep architectures are trained on massive amounts of labeled data. In the absence of labeled data for a certain task, domain adaptation often provides an attractive option given that labeled data of similar nature but from a different domain (e.g. synthetic images) are available. Here, we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain (no labeled target-domain data is necessary). \nAs the training progresses, the approach promotes the emergence of \"deep\" features that are (i) discriminative for the main learning task on the source domain and (ii) invariant with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a simple new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation. \nOverall, the approach can be implemented with little effort using any of the deep-learning packages. The method performs very well in a series of image classification experiments, achieving adaptation effect in the presence of big domain shifts and outperforming previous state-of-the-art on Office datasets.",
            "referenceCount": 44,
            "citationCount": 4713,
            "influentialCitationCount": 1059,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-09-26",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ganin2014UnsupervisedDA,\n author = {Yaroslav Ganin and V. Lempitsky},\n booktitle = {International Conference on Machine Learning},\n pages = {1180-1189},\n title = {Unsupervised Domain Adaptation by Backpropagation},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:843959ffdccf31c6694d135fad07425924f785b1",
            "@type": "ScholarlyArticle",
            "paperId": "843959ffdccf31c6694d135fad07425924f785b1",
            "corpusId": 207168299,
            "url": "https://www.semanticscholar.org/paper/843959ffdccf31c6694d135fad07425924f785b1",
            "title": "Extracting and composing robust features with denoising autoencoders",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2025768430",
                "DBLP": "conf/icml/VincentLBM08",
                "DOI": "10.1145/1390156.1390294",
                "CorpusId": 207168299
            },
            "abstract": "Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.",
            "referenceCount": 30,
            "citationCount": 6660,
            "influentialCitationCount": 520,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.iro.umontreal.ca/~vincentp/Publications/denoising_autoencoders_tr1316.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-07-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Vincent2008ExtractingAC,\n author = {Pascal Vincent and H. Larochelle and Yoshua Bengio and Pierre-Antoine Manzagol},\n booktitle = {International Conference on Machine Learning},\n pages = {1096-1103},\n title = {Extracting and composing robust features with denoising autoencoders},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4cb3fd057949624aa4f0bbe7a6dcc8777ff04758",
            "@type": "ScholarlyArticle",
            "paperId": "4cb3fd057949624aa4f0bbe7a6dcc8777ff04758",
            "corpusId": 53115163,
            "url": "https://www.semanticscholar.org/paper/4cb3fd057949624aa4f0bbe7a6dcc8777ff04758",
            "title": "Exploration by Random Network Distillation",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1810-12894",
                "MAG": "2964067469",
                "ArXiv": "1810.12894",
                "CorpusId": 53115163
            },
            "abstract": "We introduce an exploration bonus for deep reinforcement learning methods that is easy to implement and adds minimal overhead to the computation performed. The bonus is the error of a neural network predicting features of the observations given by a fixed randomly initialized neural network. We also introduce a method to flexibly combine intrinsic and extrinsic rewards. We find that the random network distillation (RND) bonus combined with this increased flexibility enables significant progress on several hard exploration Atari games. In particular we establish state of the art performance on Montezuma's Revenge, a game famously difficult for deep reinforcement learning methods. To the best of our knowledge, this is the first method that achieves better than average human performance on this game without using demonstrations or having access to the underlying state of the game, and occasionally completes the first level.",
            "referenceCount": 55,
            "citationCount": 969,
            "influentialCitationCount": 296,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1810.12894"
            },
            "citationStyles": {
                "bibtex": "@Article{Burda2018ExplorationBR,\n author = {Yuri Burda and Harrison Edwards and A. Storkey and Oleg Klimov},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Exploration by Random Network Distillation},\n volume = {abs/1810.12894},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2f85b7376769473d2bed56f855f115e23d727094",
            "@type": "ScholarlyArticle",
            "paperId": "2f85b7376769473d2bed56f855f115e23d727094",
            "corpusId": 13943041,
            "url": "https://www.semanticscholar.org/paper/2f85b7376769473d2bed56f855f115e23d727094",
            "title": "Wasserstein GAN",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1701.07875",
                "DBLP": "journals/corr/ArjovskyCB17",
                "CorpusId": 13943041
            },
            "abstract": "We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.",
            "referenceCount": 26,
            "citationCount": 3904,
            "influentialCitationCount": 725,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-01-26",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1701.07875"
            },
            "citationStyles": {
                "bibtex": "@Article{Arjovsky2017WassersteinG,\n author = {Mart\u00edn Arjovsky and Soumith Chintala and L\u00e9on Bottou},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Wasserstein GAN},\n volume = {abs/1701.07875},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c27db32efa8137cbf654902f8f728f338e55cd1c",
            "@type": "ScholarlyArticle",
            "paperId": "c27db32efa8137cbf654902f8f728f338e55cd1c",
            "corpusId": 205261034,
            "url": "https://www.semanticscholar.org/paper/c27db32efa8137cbf654902f8f728f338e55cd1c",
            "title": "Mastering the game of Go without human knowledge",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2766447205",
                "DBLP": "journals/nature/SilverSSAHGHBLB17",
                "DOI": "10.1038/nature24270",
                "CorpusId": 205261034,
                "PubMed": "29052630"
            },
            "abstract": null,
            "referenceCount": 67,
            "citationCount": 7851,
            "influentialCitationCount": 363,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://discovery.ucl.ac.uk/10045895/1/agz_unformatted_nature.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-19",
            "journal": {
                "name": "Nature",
                "volume": "550"
            },
            "citationStyles": {
                "bibtex": "@Article{Silver2017MasteringTG,\n author = {David Silver and Julian Schrittwieser and K. Simonyan and Ioannis Antonoglou and Aja Huang and A. Guez and T. Hubert and Lucas baker and Matthew Lai and A. Bolton and Yutian Chen and T. Lillicrap and Fan Hui and L. Sifre and George van den Driessche and T. Graepel and D. Hassabis},\n booktitle = {Nature},\n journal = {Nature},\n pages = {354-359},\n title = {Mastering the game of Go without human knowledge},\n volume = {550},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:06c06885fd53b2cbd407704cf14f658842ed48e5",
            "@type": "ScholarlyArticle",
            "paperId": "06c06885fd53b2cbd407704cf14f658842ed48e5",
            "corpusId": 206593506,
            "url": "https://www.semanticscholar.org/paper/06c06885fd53b2cbd407704cf14f658842ed48e5",
            "title": "Deeply-Recursive Convolutional Network for Image Super-Resolution",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2214802144",
                "ArXiv": "1511.04491",
                "DBLP": "journals/corr/KimLL15a",
                "DOI": "10.1109/CVPR.2016.181",
                "CorpusId": 206593506
            },
            "abstract": "We propose an image super-resolution method (SR) using a deeply-recursive convolutional network (DRCN). Our network has a very deep recursive layer (up to 16 recursions). Increasing recursion depth can improve performance without introducing new parameters for additional convolutions. Albeit advantages, learning a DRCN is very hard with a standard gradient descent method due to exploding/ vanishing gradients. To ease the difficulty of training, we propose two extensions: recursive-supervision and skip-connection. Our method outperforms previous methods by a large margin.",
            "referenceCount": 32,
            "citationCount": 2193,
            "influentialCitationCount": 333,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1511.04491",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-11-14",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kim2015DeeplyRecursiveCN,\n author = {Jiwon Kim and Jung Kwon Lee and Kyoung Mu Lee},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1637-1645},\n title = {Deeply-Recursive Convolutional Network for Image Super-Resolution},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c6170fa90d3b2efede5a2e1660cb23e1c824f2ca",
            "@type": "ScholarlyArticle",
            "paperId": "c6170fa90d3b2efede5a2e1660cb23e1c824f2ca",
            "corpusId": 13022595,
            "url": "https://www.semanticscholar.org/paper/c6170fa90d3b2efede5a2e1660cb23e1c824f2ca",
            "title": "Prioritized Experience Replay",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2963477884",
                "ArXiv": "1511.05952",
                "DBLP": "journals/corr/SchaulQAS15",
                "CorpusId": 13022595
            },
            "abstract": "Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 41 out of 49 games.",
            "referenceCount": 43,
            "citationCount": 3025,
            "influentialCitationCount": 419,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-11-18",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1511.05952"
            },
            "citationStyles": {
                "bibtex": "@Article{Schaul2015PrioritizedER,\n author = {T. Schaul and John Quan and Ioannis Antonoglou and David Silver},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Prioritized Experience Replay},\n volume = {abs/1511.05952},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fb91db6aa4f710814f8aec28a7f3ecbc4e5ad4fd",
            "@type": "ScholarlyArticle",
            "paperId": "fb91db6aa4f710814f8aec28a7f3ecbc4e5ad4fd",
            "corpusId": 1289873,
            "url": "https://www.semanticscholar.org/paper/fb91db6aa4f710814f8aec28a7f3ecbc4e5ad4fd",
            "title": "Deeply-Supervised Nets",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/corr/LeeXGZT14",
                "ArXiv": "1409.5185",
                "MAG": "2168894214",
                "CorpusId": 1289873
            },
            "abstract": "Our proposed deeply-supervised nets (DSN) method simultaneously minimizes classification error while making the learning process of hidden layers direct and transparent. We make an attempt to boost the classification performance by studying a new formulation in deep networks. Three aspects in convolutional neural networks (CNN) style architectures are being looked at: (1) transparency of the intermediate layers to the overall classification; (2) discriminativeness and robustness of learned features, especially in the early layers; (3) effectiveness in training due to the presence of the exploding and vanishing gradients. We introduce \"companion objective\" to the individual hidden layers, in addition to the overall objective at the output layer (a different strategy to layer-wise pre-training). We extend techniques from stochastic gradient methods to analyze our algorithm. The advantage of our method is evident and our experimental result on benchmark datasets shows significant performance gain over existing methods (e.g. all state-of-the-art results on MNIST, CIFAR-10, CIFAR-100, and SVHN).",
            "referenceCount": 40,
            "citationCount": 1916,
            "influentialCitationCount": 128,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-09-17",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1409.5185"
            },
            "citationStyles": {
                "bibtex": "@Article{Lee2014DeeplySupervisedN,\n author = {Chen-Yu Lee and Saining Xie and Patrick W. Gallagher and Zhengyou Zhang and Z. Tu},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n journal = {ArXiv},\n title = {Deeply-Supervised Nets},\n volume = {abs/1409.5185},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:41f1d50c85d3180476c4c7b3eea121278b0d8474",
            "@type": "ScholarlyArticle",
            "paperId": "41f1d50c85d3180476c4c7b3eea121278b0d8474",
            "corpusId": 8142135,
            "url": "https://www.semanticscholar.org/paper/41f1d50c85d3180476c4c7b3eea121278b0d8474",
            "title": "Pixel Recurrent Neural Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2953318193",
                "DBLP": "journals/corr/OordKK16",
                "ArXiv": "1601.06759",
                "CorpusId": 8142135
            },
            "abstract": "Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two-dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNet dataset. Samples generated from the model appear crisp, varied and globally coherent.",
            "referenceCount": 34,
            "citationCount": 2184,
            "influentialCitationCount": 220,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-01-25",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Oord2016PixelRN,\n author = {A\u00e4ron van den Oord and Nal Kalchbrenner and K. Kavukcuoglu},\n booktitle = {International Conference on Machine Learning},\n pages = {1747-1756},\n title = {Pixel Recurrent Neural Networks},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a42758b4943c7599925e8c8415ee9b8078ff57ad",
            "@type": "ScholarlyArticle",
            "paperId": "a42758b4943c7599925e8c8415ee9b8078ff57ad",
            "corpusId": 1396647,
            "url": "https://www.semanticscholar.org/paper/a42758b4943c7599925e8c8415ee9b8078ff57ad",
            "title": "In Defense of the Triplet Loss for Person Re-Identification",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/HermansBL17",
                "ArXiv": "1703.07737",
                "MAG": "2598634450",
                "CorpusId": 1396647
            },
            "abstract": "In the past few years, the field of computer vision has gone through a revolution fueled mainly by the advent of large datasets and the adoption of deep convolutional neural networks for end-to-end learning. The person re-identification subfield is no exception to this. Unfortunately, a prevailing belief in the community seems to be that the triplet loss is inferior to using surrogate losses (classification, verification) followed by a separate metric learning step. We show that, for models trained from scratch as well as pretrained ones, using a variant of the triplet loss to perform end-to-end deep metric learning outperforms most other published methods by a large margin.",
            "referenceCount": 55,
            "citationCount": 2719,
            "influentialCitationCount": 321,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-22",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.07737"
            },
            "citationStyles": {
                "bibtex": "@Article{Hermans2017InDO,\n author = {Alexander Hermans and Lucas Beyer and B. Leibe},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {In Defense of the Triplet Loss for Person Re-Identification},\n volume = {abs/1703.07737},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a55f5434724bc5ff3d9b4d37f52e9b8a6fb05d4f",
            "@type": "ScholarlyArticle",
            "paperId": "a55f5434724bc5ff3d9b4d37f52e9b8a6fb05d4f",
            "corpusId": 61371942,
            "url": "https://www.semanticscholar.org/paper/a55f5434724bc5ff3d9b4d37f52e9b8a6fb05d4f",
            "title": "Medical Image Computing and Computer-Assisted Intervention \u2212 MICCAI 2017: 20th International Conference, Quebec City, QC, Canada, September 11-13, 2017, Proceedings, Part II",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/miccai/2017-1",
                "MAG": "2751796963",
                "DOI": "10.1007/978-3-319-66185-8",
                "CorpusId": 61371942
            },
            "abstract": null,
            "referenceCount": 75,
            "citationCount": 2010,
            "influentialCitationCount": 207,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-319-66182-7/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Medical Image Computing and Computer-Assisted Intervention \u2212 MICCAI 2017",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Descoteaux2017MedicalIC,\n author = {Maxime Descoteaux and Lena Maier-Hein and A. Franz and Pierre Jannin and D. Collins and Simon Duchesne},\n booktitle = {Lecture Notes in Computer Science},\n journal = {Medical Image Computing and Computer-Assisted Intervention \u2212 MICCAI 2017},\n title = {Medical Image Computing and Computer-Assisted Intervention \u2212 MICCAI 2017: 20th International Conference, Quebec City, QC, Canada, September 11-13, 2017, Proceedings, Part II},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9632ccce538e1120e48665ae7d288f10b652fec7",
            "@type": "ScholarlyArticle",
            "paperId": "9632ccce538e1120e48665ae7d288f10b652fec7",
            "corpusId": 17952092,
            "url": "https://www.semanticscholar.org/paper/9632ccce538e1120e48665ae7d288f10b652fec7",
            "title": "The revised two-factor Study Process Questionnaire: R-SPQ-2F.",
            "venue": "British Journal of Educational Psychology",
            "publicationVenue": {
                "id": "urn:research:509dffcb-ddaa-49f4-8b2a-8f6c617abc19",
                "name": "British Journal of Educational Psychology",
                "alternate_names": [
                    "Br J Educ Psychol"
                ],
                "issn": "0007-0998",
                "url": "http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)2044-8279"
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2026539857",
                "DOI": "10.1348/000709901158433",
                "CorpusId": 17952092,
                "PubMed": "11307705"
            },
            "abstract": "AIM\nTo produce a revised two-factor version of the Study Process Questionnaire (R-SPQ-2F) suitable for use by teachers in evaluating the learning approaches of their students. The revised instrument assesses deep and surface approaches only, using fewer items.\n\n\nMETHOD\nA set of 43 items was drawn up for the initial tests. These were derived from: the original version of the SPQ, modified items from the SPQ, and new items. A process of testing and refinement eventuated in deep and surface motive and strategy scales each with 5 items, 10 items per approach score. The final version was tested using reliability procedures and confirmatory factor analysis.\n\n\nSAMPLE\nThe sample for the testing and refinement process consisted of 229 students from the health sciences faculty of a university in Hong Kong. A fresh sample of 495 undergraduate students from a variety of departments of the same university was used for the test of the final version.\n\n\nRESULTS\nThe final version of the questionnaire had acceptable Cronbach alpha values for scale reliability. Confirmatory factor analysis indicated a good fit to the intended two-factor structure. Both deep and surface approach scales had well identified motive and strategy subscales.\n\n\nCONCLUSION\nThe revision process has resulted in a simple questionnaire which teachers can use to evaluate their own teaching and the learning approaches of their students.",
            "referenceCount": 50,
            "citationCount": 1916,
            "influentialCitationCount": 285,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2001-03-01",
            "journal": {
                "name": "The British journal of educational psychology",
                "volume": "71 Pt 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Biggs2001TheRT,\n author = {J. Biggs and D. Kember and D. Leung},\n booktitle = {British Journal of Educational Psychology},\n journal = {The British journal of educational psychology},\n pages = {\n          133-49\n        },\n title = {The revised two-factor Study Process Questionnaire: R-SPQ-2F.},\n volume = {71 Pt 1},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a6401e102c03a441992b3e45f7b63eec09d4b89d",
            "@type": "ScholarlyArticle",
            "paperId": "a6401e102c03a441992b3e45f7b63eec09d4b89d",
            "corpusId": 5523008,
            "url": "https://www.semanticscholar.org/paper/a6401e102c03a441992b3e45f7b63eec09d4b89d",
            "title": "A Survey on Dialogue Systems: Recent Advances and New Frontiers",
            "venue": "SKDD",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2953126480",
                "ArXiv": "1711.01731",
                "DBLP": "journals/corr/abs-1711-01731",
                "DOI": "10.1145/3166054.3166058",
                "CorpusId": 5523008
            },
            "abstract": "Dialogue systems have attracted more and more attention. Recent advances on dialogue systems are overwhelmingly contributed by deep learning techniques, which have been employed to enhance a wide range of big data applications such as computer vision, natural language processing, and recommender systems. For dialogue systems, deep learning can leverage a massive amount of data to learn meaningful feature representations and response generation strategies, while requiring a minimum amount of hand-crafting. In this article, we give an overview to these recent advances on dialogue systems from various perspectives and discuss some possible research directions. In particular, we generally divide existing dialogue systems into task-oriented and nontask- oriented models, then detail how deep learning techniques help them with representative algorithms and finally discuss some appealing research directions that can bring the dialogue system research into a new frontier",
            "referenceCount": 133,
            "citationCount": 574,
            "influentialCitationCount": 38,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1711.01731",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-11-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1711.01731"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2017ASO,\n author = {Hongshen Chen and Xiaorui Liu and Dawei Yin and Jiliang Tang},\n booktitle = {SKDD},\n journal = {ArXiv},\n title = {A Survey on Dialogue Systems: Recent Advances and New Frontiers},\n volume = {abs/1711.01731},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b0bf946ae8f735514317ef117a3b3dc3c58eb496",
            "@type": "ScholarlyArticle",
            "paperId": "b0bf946ae8f735514317ef117a3b3dc3c58eb496",
            "corpusId": 6938011,
            "url": "https://www.semanticscholar.org/paper/b0bf946ae8f735514317ef117a3b3dc3c58eb496",
            "title": "Understanding Student Differences",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2130183563",
                "DOI": "10.1002/j.2168-9830.2005.tb00829.x",
                "CorpusId": 6938011
            },
            "abstract": "Students have different levels of motivation, different attitudes about teaching and learning, and different responses to specific classroom environments and instructional practices. The more thoroughly instructors understand the differences, the better chance they have of meeting the diverse learning needs of all of their students. Three categories of diversity that have been shown to have important implications for teaching and learning are differences in students' learning styles (characteristic ways of taking in and processing information), approaches to learning (surface, deep, and strategic), and intellectual development levels (attitudes about the nature of knowledge and how it should be acquired and evaluated). This article reviews models that have been developed for each of these categories, outlines their pedagogical implications, and suggests areas for further study.",
            "referenceCount": 115,
            "citationCount": 1714,
            "influentialCitationCount": 136,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2005-01-01",
            "journal": {
                "name": "Journal of Engineering Education",
                "volume": "94"
            },
            "citationStyles": {
                "bibtex": "@Article{Felder2005UnderstandingSD,\n author = {R. Felder and R. Brent},\n journal = {Journal of Engineering Education},\n title = {Understanding Student Differences},\n volume = {94},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7e9c1e0d247b20a0683f4797d9ea248c3b53d424",
            "@type": "ScholarlyArticle",
            "paperId": "7e9c1e0d247b20a0683f4797d9ea248c3b53d424",
            "corpusId": 3503426,
            "url": "https://www.semanticscholar.org/paper/7e9c1e0d247b20a0683f4797d9ea248c3b53d424",
            "title": "A Simple Neural Attentive Meta-Learner",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2951881474",
                "DBLP": "conf/iclr/MishraR0A18",
                "CorpusId": 3503426
            },
            "abstract": "Deep neural networks excel in regimes with large amounts of data, but tend to struggle when data is scarce or when they need to adapt quickly to changes in the task. In response, recent work in meta-learning proposes training a meta-learner on a distribution of similar tasks, in the hopes of generalization to novel but related tasks by learning a high-level strategy that captures the essence of the problem it is asked to solve. However, many recent meta-learning approaches are extensively hand-designed, either using architectures specialized to a particular application, or hard-coding algorithmic components that constrain how the meta-learner solves the task. We propose a class of simple and generic meta-learner architectures that use a novel combination of temporal convolutions and soft attention; the former to aggregate information from past experience and the latter to pinpoint specific pieces of information. In the most extensive set of meta-learning experiments to date, we evaluate the resulting Simple Neural AttentIve Learner (or SNAIL) on several heavily-benchmarked tasks. On all tasks, in both supervised and reinforcement learning, SNAIL attains state-of-the-art performance by significant margins.",
            "referenceCount": 32,
            "citationCount": 1120,
            "influentialCitationCount": 115,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-11",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Mishra2017ASN,\n author = {Nikhil Mishra and Mostafa Rohaninejad and Xi Chen and P. Abbeel},\n booktitle = {International Conference on Learning Representations},\n title = {A Simple Neural Attentive Meta-Learner},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b5007972c6f5a2294f83357c73e12664dd7c85b3",
            "@type": "ScholarlyArticle",
            "paperId": "b5007972c6f5a2294f83357c73e12664dd7c85b3",
            "corpusId": 10544801,
            "url": "https://www.semanticscholar.org/paper/b5007972c6f5a2294f83357c73e12664dd7c85b3",
            "title": "CayleyNets: Graph Convolutional Neural Networks With Complex Rational Spectral Filters",
            "venue": "IEEE Transactions on Signal Processing",
            "publicationVenue": {
                "id": "urn:research:1f6f3f05-6a23-42f0-8d31-98ab8089c1f2",
                "name": "IEEE Transactions on Signal Processing",
                "alternate_names": [
                    "IEEE Trans Signal Process"
                ],
                "issn": "1053-587X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=78"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2949203253",
                "ArXiv": "1705.07664",
                "DBLP": "journals/tsp/LevieMBB19",
                "DOI": "10.1109/TSP.2018.2879624",
                "CorpusId": 10544801
            },
            "abstract": "The rise of graph-structured data such as social networks, regulatory networks, citation graphs, and functional brain networks, in combination with resounding success of deep learning in various applications, has brought the interest in generalizing deep learning models to non-Euclidean domains. In this paper, we introduce a new spectral domain convolutional architecture for deep learning on graphs. The core ingredient of our model is a new class of parametric rational complex functions (Cayley polynomials) allowing to efficiently compute spectral filters on graphs that specialize on frequency bands of interest. Our model generates rich spectral filters that are localized in space, scales linearly with the size of the input data for sparsely connected graphs, and can handle different constructions of Laplacian operators. Extensive experimental results show the superior performance of our approach, in comparison to other spectral domain convolutional architectures, on spectral image classification, community detection, vertex classification, and matrix completion tasks.",
            "referenceCount": 43,
            "citationCount": 548,
            "influentialCitationCount": 29,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dr.ntu.edu.sg/bitstream/10356/139445/2/CayleyNets-Graph%20Convolutional%20Neural%20Networks%20With%20Complex%20Rational%20Spectral%20Filters.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-05-22",
            "journal": {
                "name": "IEEE Transactions on Signal Processing",
                "volume": "67"
            },
            "citationStyles": {
                "bibtex": "@Article{Levie2017CayleyNetsGC,\n author = {R. Levie and Federico Monti and X. Bresson and M. Bronstein},\n booktitle = {IEEE Transactions on Signal Processing},\n journal = {IEEE Transactions on Signal Processing},\n pages = {97-109},\n title = {CayleyNets: Graph Convolutional Neural Networks With Complex Rational Spectral Filters},\n volume = {67},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:601a2d349fc26d7b82f905e924e2f91b0ac4b310",
            "@type": "ScholarlyArticle",
            "paperId": "601a2d349fc26d7b82f905e924e2f91b0ac4b310",
            "corpusId": 3463260,
            "url": "https://www.semanticscholar.org/paper/601a2d349fc26d7b82f905e924e2f91b0ac4b310",
            "title": "Distributed Prioritized Experience Replay",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2963296584",
                "DBLP": "conf/iclr/HorganQBBHHS18",
                "ArXiv": "1803.00933",
                "CorpusId": 3463260
            },
            "abstract": "We propose a distributed architecture for deep reinforcement learning at scale, that enables agents to learn effectively from orders of magnitude more data than previously possible. The algorithm decouples acting from learning: the actors interact with their own instances of the environment by selecting actions according to a shared neural network, and accumulate the resulting experience in a shared experience replay memory; the learner replays samples of experience and updates the neural network. The architecture relies on prioritized experience replay to focus only on the most significant data generated by the actors. Our architecture substantially improves the state of the art on the Arcade Learning Environment, achieving better final performance in a fraction of the wall-clock training time.",
            "referenceCount": 41,
            "citationCount": 609,
            "influentialCitationCount": 90,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1803.00933"
            },
            "citationStyles": {
                "bibtex": "@Article{Horgan2018DistributedPE,\n author = {Dan Horgan and John Quan and D. Budden and Gabriel Barth-Maron and Matteo Hessel and H. V. Hasselt and David Silver},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Distributed Prioritized Experience Replay},\n volume = {abs/1803.00933},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:08d0ea90b53aba0008d25811268fe46562cfb38c",
            "@type": "ScholarlyArticle",
            "paperId": "08d0ea90b53aba0008d25811268fe46562cfb38c",
            "corpusId": 458722,
            "url": "https://www.semanticscholar.org/paper/08d0ea90b53aba0008d25811268fe46562cfb38c",
            "title": "On the quantitative analysis of deep belief networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2096192494",
                "DBLP": "conf/icml/SalakhutdinovM08",
                "DOI": "10.1145/1390156.1390266",
                "CorpusId": 458722
            },
            "abstract": "Deep Belief Networks (DBN's) are generative models that contain many layers of hidden variables. Efficient greedy algorithms for learning and approximate inference have allowed these models to be applied successfully in many application domains. The main building block of a DBN is a bipartite undirected graphical model called a restricted Boltzmann machine (RBM). Due to the presence of the partition function, model selection, complexity control, and exact maximum likelihood learning in RBM's are intractable. We show that Annealed Importance Sampling (AIS) can be used to efficiently estimate the partition function of an RBM, and we present a novel AIS scheme for comparing RBM's with different architectures. We further show how an AIS estimator, along with approximate inference, can be used to estimate a lower bound on the log-probability that a DBN model with multiple hidden layers assigns to the test data. This is, to our knowledge, the first step towards obtaining quantitative results that would allow us to directly assess the performance of Deep Belief Networks as generative models of data.",
            "referenceCount": 18,
            "citationCount": 492,
            "influentialCitationCount": 84,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cs.toronto.edu/~rsalakhu/papers/dbn_ais.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-07-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Salakhutdinov2008OnTQ,\n author = {R. Salakhutdinov and Iain Murray},\n booktitle = {International Conference on Machine Learning},\n pages = {872-879},\n title = {On the quantitative analysis of deep belief networks},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4ec06dda674cd5f93351f0ab5871391671f9b974",
            "@type": "ScholarlyArticle",
            "paperId": "4ec06dda674cd5f93351f0ab5871391671f9b974",
            "corpusId": 1315930,
            "url": "https://www.semanticscholar.org/paper/4ec06dda674cd5f93351f0ab5871391671f9b974",
            "title": "Medical Image Analysis using Convolutional Neural Networks: A Review",
            "venue": "Journal of medical systems",
            "publicationVenue": {
                "id": "urn:research:79c59592-820f-4ed1-87df-db795b4326be",
                "name": "Journal of medical systems",
                "alternate_names": [
                    "J Med Syst",
                    "Journal of Medical Systems",
                    "J med syst"
                ],
                "issn": "0148-5598",
                "url": "https://link.springer.com/journal/10916"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2752517284",
                "DBLP": "journals/corr/abs-1709-02250",
                "ArXiv": "1709.02250",
                "DOI": "10.1007/s10916-018-1088-1",
                "CorpusId": 1315930,
                "PubMed": "30298337"
            },
            "abstract": null,
            "referenceCount": 144,
            "citationCount": 736,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1709.02250",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-09-04",
            "journal": {
                "name": "Journal of Medical Systems",
                "volume": "42"
            },
            "citationStyles": {
                "bibtex": "@Article{Qayyum2017MedicalIA,\n author = {A. Qayyum and S. Anwar and Muhammad Majid and M. Awais and M. Alnowami},\n booktitle = {Journal of medical systems},\n journal = {Journal of Medical Systems},\n pages = {1-13},\n title = {Medical Image Analysis using Convolutional Neural Networks: A Review},\n volume = {42},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:79dc4da8f131ff26046d5564e5dedb1c5ce72c6a",
            "@type": "ScholarlyArticle",
            "paperId": "79dc4da8f131ff26046d5564e5dedb1c5ce72c6a",
            "corpusId": 7905652,
            "url": "https://www.semanticscholar.org/paper/79dc4da8f131ff26046d5564e5dedb1c5ce72c6a",
            "title": "Deep belief networks",
            "venue": "Scholarpedia",
            "publicationVenue": {
                "id": "urn:research:856e61df-ae80-4713-a1f1-6afd81e6e2b1",
                "name": "Scholarpedia",
                "alternate_names": null,
                "issn": "1941-6016",
                "url": "http://www.scholarpedia.org/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "1973445088",
                "DBLP": "journals/scholarpedia/Hinton09",
                "DOI": "10.4249/scholarpedia.5947",
                "CorpusId": 7905652
            },
            "abstract": "Recently, Hinton et al.[6] derived a way to perform fast, greedy learning of deep belief networks (DBN) one layer at a time, with the top two layers forming an undirected bipartite graph (associate memory). The learning procedure consists of training a stack of Restricted Boltzmann Machines (RBM\u2019s) each having only one layer of latent (hidden) feature detectors. The learned feature activations of one RBM are used as the \u201cdata\u201d for training the next RBM in the stack. The important aspect of this layer-wise training procedure is that, provided the number of features per layer does not decrease, [6] showed that each extra layer increases a variational lower bound on the log probability of data. So layer-by-layer training can be repeated several times 1 to learn a deep, hierarchical model in which each layer of features captures strong high-order correlations between the activities of features in the layer below. We will discuss three ideas based on greedily learning a hierarchy of features: Nonlinear Dimensionality Reduction. The DBN framework allows us to make nonlinear autoencoders work considerably better [7] than widely used methods such as PCA, SVD, and LLE. The standard way to train autoencoders is to use backpropagation to reduce the reconstruction error. It is dif\ufb01cult, however, to optimize the weights in non-linear autoencoders that have multiple hidden layers with many million parameters [3, 5]. We use our greedy learning algorithm to pretrain autoencoders. This pretraining stage discovers useful features ef\ufb01ciently. After the pretraining stage, the model is \u201cunfolded\u201d to produce encoder and decoder networks that initially use the same weights. The global \ufb01ne-tuning stage then uses backpropagation through the whole autoencoder to \ufb01ne-tune the weights for optimal reconstruction. The key idea is that the greedy learning algorithm",
            "referenceCount": 8,
            "citationCount": 448,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-05-31",
            "journal": {
                "name": "Scholarpedia",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Hinton2009DeepBN,\n author = {Geoffrey E. Hinton},\n booktitle = {Scholarpedia},\n journal = {Scholarpedia},\n pages = {5947},\n title = {Deep belief networks},\n volume = {4},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:56ba6dfa111a3308ff5311997bb83a481953540e",
            "@type": "ScholarlyArticle",
            "paperId": "56ba6dfa111a3308ff5311997bb83a481953540e",
            "corpusId": 4001530,
            "url": "https://www.semanticscholar.org/paper/56ba6dfa111a3308ff5311997bb83a481953540e",
            "title": "DSAC \u2014 Differentiable RANSAC for Camera Localization",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2556455135",
                "ArXiv": "1611.05705",
                "DBLP": "conf/cvpr/BrachmannKNSMGR17",
                "DOI": "10.1109/CVPR.2017.267",
                "CorpusId": 4001530
            },
            "abstract": "RANSAC is an important algorithm in robust optimization and a central building block for many computer vision applications. In recent years, traditionally hand-crafted pipelines have been replaced by deep learning pipelines, which can be trained in an end-to-end fashion. However, RANSAC has so far not been used as part of such deep learning pipelines, because its hypothesis selection procedure is non-differentiable. In this work, we present two different ways to overcome this limitation. The most promising approach is inspired by reinforcement learning, namely to replace the deterministic hypothesis selection by a probabilistic selection for which we can derive the expected loss w.r.t. to all learnable parameters. We call this approach DSAC, the differentiable counterpart of RANSAC. We apply DSAC to the problem of camera localization, where deep learning has so far failed to improve on traditional approaches. We demonstrate that by directly minimizing the expected loss of the output camera poses, robustly estimated by RANSAC, we achieve an increase in accuracy. In the future, any deep learning pipeline can use DSAC as a robust optimization component.",
            "referenceCount": 42,
            "citationCount": 471,
            "influentialCitationCount": 79,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1611.05705",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-11-17",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Brachmann2016DSACD,\n author = {Eric Brachmann and Alexander Krull and Sebastian Nowozin and J. Shotton and Frank Michel and S. Gumhold and C. Rother},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {2492-2500},\n title = {DSAC \u2014 Differentiable RANSAC for Camera Localization},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fbfc91615651f9b547fe2a8d2f9fa6e35a898996",
            "@type": "ScholarlyArticle",
            "paperId": "fbfc91615651f9b547fe2a8d2f9fa6e35a898996",
            "corpusId": 227243204,
            "url": "https://www.semanticscholar.org/paper/fbfc91615651f9b547fe2a8d2f9fa6e35a898996",
            "title": "\u2018It will change everything\u2019: DeepMind\u2019s AI makes gigantic leap in solving protein structures",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3108943181",
                "DOI": "10.1038/d41586-020-03348-4",
                "CorpusId": 227243204,
                "PubMed": "33257889"
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 288,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "News"
            ],
            "publicationDate": "2020-11-30",
            "journal": {
                "name": "Nature",
                "volume": "588"
            },
            "citationStyles": {
                "bibtex": "@Article{Callaway2020ItWC,\n author = {E. Callaway},\n booktitle = {Nature},\n journal = {Nature},\n pages = {203 - 204},\n title = {\u2018It will change everything\u2019: DeepMind\u2019s AI makes gigantic leap in solving protein structures},\n volume = {588},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:36cd89332d305d01605d6d08cd8452c8a752138a",
            "@type": "ScholarlyArticle",
            "paperId": "36cd89332d305d01605d6d08cd8452c8a752138a",
            "corpusId": 59597264,
            "url": "https://www.semanticscholar.org/paper/36cd89332d305d01605d6d08cd8452c8a752138a",
            "title": "Designing neural networks through neuroevolution",
            "venue": "Nature Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:6457124b-39bf-4d02-bff4-73752ff21562",
                "name": "Nature Machine Intelligence",
                "alternate_names": [
                    "Nat Mach Intell"
                ],
                "issn": "2522-5839",
                "url": "https://www.nature.com/natmachintell/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/natmi/StanleyCLM19",
                "MAG": "2906697496",
                "DOI": "10.1038/S42256-018-0006-Z",
                "CorpusId": 59597264
            },
            "abstract": null,
            "referenceCount": 161,
            "citationCount": 502,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s42256-018-0006-z.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-01-01",
            "journal": {
                "name": "Nature Machine Intelligence",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Stanley2019DesigningNN,\n author = {Kenneth O. Stanley and J. Clune and J. Lehman and R. Miikkulainen},\n booktitle = {Nature Machine Intelligence},\n journal = {Nature Machine Intelligence},\n pages = {24-35},\n title = {Designing neural networks through neuroevolution},\n volume = {1},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e35338965b359217c3c8360f4c5d3e79beb5f9bc",
            "@type": "ScholarlyArticle",
            "paperId": "e35338965b359217c3c8360f4c5d3e79beb5f9bc",
            "corpusId": 58671842,
            "url": "https://www.semanticscholar.org/paper/e35338965b359217c3c8360f4c5d3e79beb5f9bc",
            "title": "A Comparison of ARIMA and LSTM in Forecasting Time Series",
            "venue": "International Conference on Machine Learning and Applications",
            "publicationVenue": {
                "id": "urn:research:f6752838-f268-4a1b-87e7-c5f30a36713c",
                "name": "International Conference on Machine Learning and Applications",
                "alternate_names": [
                    "Int Conf Mach Learn Appl",
                    "ICMLA"
                ],
                "issn": null,
                "url": "http://www.icmla-conference.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2909877301",
                "DBLP": "conf/icmla/Siami-NaminiTN18",
                "DOI": "10.1109/ICMLA.2018.00227",
                "CorpusId": 58671842
            },
            "abstract": "Forecasting time series data is an important subject in economics, business, and finance. Traditionally, there are several techniques to effectively forecast the next lag of time series data such as univariate Autoregressive (AR), univariate Moving Average (MA), Simple Exponential Smoothing (SES), and more notably Autoregressive Integrated Moving Average (ARIMA) with its many variations. In particular, ARIMA model has demonstrated its outperformance in precision and accuracy of predicting the next lags of time series. With the recent advancement in computational power of computers and more importantly development of more advanced machine learning algorithms and approaches such as deep learning, new algorithms are developed to analyze and forecast time series data. The research question investigated in this article is that whether and how the newly developed deep learning-based algorithms for forecasting time series data, such as \"Long Short-Term Memory (LSTM)\", are superior to the traditional algorithms. The empirical studies conducted and reported in this article show that deep learning-based algorithms such as LSTM outperform traditional-based algorithms such as ARIMA model. More specifically, the average reduction in error rates obtained by LSTM was between 84 - 87 percent when compared to ARIMA indicating the superiority of LSTM to ARIMA. Furthermore, it was noticed that the number of training times, known as \"epoch\" in deep learning, had no effect on the performance of the trained forecast model and it exhibited a truly random behavior.",
            "referenceCount": 21,
            "citationCount": 511,
            "influentialCitationCount": 25,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-12-01",
            "journal": {
                "name": "2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Siami\u2010Namini2018ACO,\n author = {Sima Siami\u2010Namini and Neda Tavakoli and A. Namin},\n booktitle = {International Conference on Machine Learning and Applications},\n journal = {2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)},\n pages = {1394-1401},\n title = {A Comparison of ARIMA and LSTM in Forecasting Time Series},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:97dc8df45972e4ed7423fc992a5092ba25b33411",
            "@type": "ScholarlyArticle",
            "paperId": "97dc8df45972e4ed7423fc992a5092ba25b33411",
            "corpusId": 2780493,
            "url": "https://www.semanticscholar.org/paper/97dc8df45972e4ed7423fc992a5092ba25b33411",
            "title": "All you need is a good init",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2178237821",
                "ArXiv": "1511.06422",
                "DBLP": "journals/corr/MishkinM15",
                "CorpusId": 2780493
            },
            "abstract": "Layer-sequential unit-variance (LSUV) initialization - a simple method for weight initialization for deep net learning - is proposed. The method consists of the two steps. First, pre-initialize weights of each convolution or inner-product layer with orthonormal matrices. Second, proceed from the first to the final layer, normalizing the variance of the output of each layer to be equal to one. \nExperiment with different activation functions (maxout, ReLU-family, tanh) show that the proposed initialization leads to learning of very deep nets that (i) produces networks with test accuracy better or equal to standard methods and (ii) is at least as fast as the complex schemes proposed specifically for very deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastava et al. (2015)). \nPerformance is evaluated on GoogLeNet, CaffeNet, FitNets and Residual nets and the state-of-the-art, or very close to it, is achieved on the MNIST, CIFAR-10/100 and ImageNet datasets.",
            "referenceCount": 35,
            "citationCount": 568,
            "influentialCitationCount": 48,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-11-19",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1511.06422"
            },
            "citationStyles": {
                "bibtex": "@Article{Mishkin2015AllYN,\n author = {Dmytro Mishkin and Jiri Matas},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {All you need is a good init},\n volume = {abs/1511.06422},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1c4927af526d5c28f7c2cfa492ece192d80a61d4",
            "@type": "ScholarlyArticle",
            "paperId": "1c4927af526d5c28f7c2cfa492ece192d80a61d4",
            "corpusId": 1923568,
            "url": "https://www.semanticscholar.org/paper/1c4927af526d5c28f7c2cfa492ece192d80a61d4",
            "title": "Policy Distillation",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1511.06295",
                "MAG": "3038067716",
                "DBLP": "journals/corr/RusuCGDKPMKH15",
                "CorpusId": 1923568
            },
            "abstract": "Abstract: Policies for complex visual tasks have been successfully learned with deep reinforcement learning, using an approach called deep Q-networks (DQN), but relatively large (task-specific) networks and extensive training are needed to achieve good performance. In this work, we present a novel method called policy distillation that can be used to extract the policy of a reinforcement learning agent and train a new network that performs at the expert level while being dramatically smaller and more efficient. Furthermore, the same method can be used to consolidate multiple task-specific policies into a single policy. We demonstrate these claims using the Atari domain and show that the multi-task distilled agent outperforms the single-task teachers as well as a jointly-trained DQN agent.",
            "referenceCount": 28,
            "citationCount": 557,
            "influentialCitationCount": 58,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-11-19",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1511.06295"
            },
            "citationStyles": {
                "bibtex": "@Article{Rusu2015PolicyD,\n author = {Andrei A. Rusu and Sergio Gomez Colmenarejo and \u00c7aglar G\u00fcl\u00e7ehre and Guillaume Desjardins and J. Kirkpatrick and Razvan Pascanu and Volodymyr Mnih and K. Kavukcuoglu and R. Hadsell},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Policy Distillation},\n volume = {abs/1511.06295},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:27dfecb6bb0308c7484e13dcaefd5eeebba677d3",
            "@type": "ScholarlyArticle",
            "paperId": "27dfecb6bb0308c7484e13dcaefd5eeebba677d3",
            "corpusId": 3536221,
            "url": "https://www.semanticscholar.org/paper/27dfecb6bb0308c7484e13dcaefd5eeebba677d3",
            "title": "Model-Ensemble Trust-Region Policy Optimization",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2952152670",
                "DBLP": "journals/corr/abs-1802-10592",
                "ArXiv": "1802.10592",
                "CorpusId": 3536221
            },
            "abstract": "Model-free reinforcement learning (RL) methods are succeeding in a growing number of tasks, aided by recent advances in deep learning. However, they tend to suffer from high sample complexity, which hinders their use in real-world domains. Alternatively, model-based reinforcement learning promises to reduce sample complexity, but tends to require careful tuning and to date have succeeded mainly in restrictive domains where simple models are sufficient for learning. In this paper, we analyze the behavior of vanilla model-based reinforcement learning methods when deep neural networks are used to learn both the model and the policy, and show that the learned policy tends to exploit regions where insufficient data is available for the model to be learned, causing instability in training. To overcome this issue, we propose to use an ensemble of models to maintain the model uncertainty and regularize the learning process. We further show that the use of likelihood ratio derivatives yields much more stable learning than backpropagation through time. Altogether, our approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO) significantly reduces the sample complexity compared to model-free deep RL methods on challenging continuous control benchmark tasks.",
            "referenceCount": 47,
            "citationCount": 381,
            "influentialCitationCount": 45,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1802.10592"
            },
            "citationStyles": {
                "bibtex": "@Article{Kurutach2018ModelEnsembleTP,\n author = {Thanard Kurutach and I. Clavera and Yan Duan and Aviv Tamar and P. Abbeel},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Model-Ensemble Trust-Region Policy Optimization},\n volume = {abs/1802.10592},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9b82c6e78ceaa5e540862849defc818f7c8a47df",
            "@type": "ScholarlyArticle",
            "paperId": "9b82c6e78ceaa5e540862849defc818f7c8a47df",
            "corpusId": 5775306,
            "url": "https://www.semanticscholar.org/paper/9b82c6e78ceaa5e540862849defc818f7c8a47df",
            "title": "Multi-Domain Joint Semantic Frame Parsing Using Bi-Directional RNN-LSTM",
            "venue": "Interspeech",
            "publicationVenue": {
                "id": "urn:research:af90489e-312f-4514-bea2-bcb399cb8ece",
                "name": "Interspeech",
                "alternate_names": [
                    "Conf Int Speech Commun Assoc",
                    "INTERSPEECH",
                    "Conference of the International Speech Communication Association"
                ],
                "issn": "2308-457X",
                "url": "https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/interspeech/Hakkani-TurTCCG16",
                "MAG": "2473329891",
                "DOI": "10.21437/Interspeech.2016-402",
                "CorpusId": 5775306
            },
            "abstract": "Sequence-to-sequence deep learning has recently emerged as a new paradigm in supervised learning for spoken language understanding. However, most of the previous studies explored this framework for building single domain models for each task, such as slot filling or domain classification, comparing deep learning based approaches with conventional ones like conditional random fields. This paper proposes a holistic multi-domain, multi-task (i.e. slot filling, domain and intent detection) modeling approach to estimate complete semantic frames for all user utterances addressed to a conversational system, demonstrating the distinctive power of deep learning methods, namely bi-directional recurrent neural network (RNN) with long-short term memory (LSTM) cells (RNN-LSTM) to handle such complexity. The contributions of the presented work are three-fold: (i) we propose an RNN-LSTM architecture for joint modeling of slot filling, intent determination, and domain classification; (ii) we build a joint multi-domain model enabling multi-task deep learning where the data from each domain reinforces each other; (iii) we investigate alternative architectures for modeling lexical context in spoken language understanding. In addition to the simplicity of the single model framework, experimental results show the power of such an approach on Microsoft Cortana real user data over alternative methods based on single domain/task deep learning.",
            "referenceCount": 39,
            "citationCount": 423,
            "influentialCitationCount": 58,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hakkani-T\u00fcr2016MultiDomainJS,\n author = {Dilek Z. Hakkani-T\u00fcr and G\u00f6khan T\u00fcr and Asli Celikyilmaz and Yun-Nung (Vivian) Chen and Jianfeng Gao and L. Deng and Ye-Yi Wang},\n booktitle = {Interspeech},\n pages = {715-719},\n title = {Multi-Domain Joint Semantic Frame Parsing Using Bi-Directional RNN-LSTM},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1ca5bb12c0d46f9e074e74bd7e08845ebfebf3d5",
            "@type": "ScholarlyArticle",
            "paperId": "1ca5bb12c0d46f9e074e74bd7e08845ebfebf3d5",
            "corpusId": 209429095,
            "url": "https://www.semanticscholar.org/paper/1ca5bb12c0d46f9e074e74bd7e08845ebfebf3d5",
            "title": "Convolutional neural network: a review of models, methodologies and applications to object detection",
            "venue": "Progress in Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bf10e3a8-46ea-4a2b-bba2-b93db1412e7c",
                "name": "Progress in Artificial Intelligence",
                "alternate_names": [
                    "Prog Artif Intell"
                ],
                "issn": "2192-6352",
                "url": "https://link.springer.com/journal/13748"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2996367417",
                "DBLP": "journals/pai/DhillonV20",
                "DOI": "10.1007/s13748-019-00203-0",
                "CorpusId": 209429095
            },
            "abstract": null,
            "referenceCount": 134,
            "citationCount": 436,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-12-20",
            "journal": {
                "name": "Progress in Artificial Intelligence",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Dhillon2019ConvolutionalNN,\n author = {Anamika Dhillon and G. Verma},\n booktitle = {Progress in Artificial Intelligence},\n journal = {Progress in Artificial Intelligence},\n pages = {85 - 112},\n title = {Convolutional neural network: a review of models, methodologies and applications to object detection},\n volume = {9},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:be00809a8b848eb8605f01d21296443a3761efb7",
            "@type": "ScholarlyArticle",
            "paperId": "be00809a8b848eb8605f01d21296443a3761efb7",
            "corpusId": 144230956,
            "url": "https://www.semanticscholar.org/paper/be00809a8b848eb8605f01d21296443a3761efb7",
            "title": "Improving the quality of student learning: the influence of learning context and student approaches to learning on learning outcomes",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1991,
            "externalIds": {
                "MAG": "2046131241",
                "DOI": "10.1007/BF00132290",
                "CorpusId": 144230956
            },
            "abstract": null,
            "referenceCount": 21,
            "citationCount": 779,
            "influentialCitationCount": 41,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1991-10-01",
            "journal": {
                "name": "Higher Education",
                "volume": "22"
            },
            "citationStyles": {
                "bibtex": "@Article{Trigwell1991ImprovingTQ,\n author = {K. Trigwell and M. Prosser},\n journal = {Higher Education},\n pages = {251-266},\n title = {Improving the quality of student learning: the influence of learning context and student approaches to learning on learning outcomes},\n volume = {22},\n year = {1991}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:37088dec26231bc5a4937054ebc862bb83a3db4d",
            "@type": "ScholarlyArticle",
            "paperId": "37088dec26231bc5a4937054ebc862bb83a3db4d",
            "corpusId": 15938338,
            "url": "https://www.semanticscholar.org/paper/37088dec26231bc5a4937054ebc862bb83a3db4d",
            "title": "Neural Episodic Control",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/PritzelUSBVHWB17",
                "MAG": "2594466397",
                "ArXiv": "1703.01988",
                "CorpusId": 15938338
            },
            "abstract": "Deep reinforcement learning methods attain super-human performance in a wide range of environments. Such methods are grossly inefficient, often taking orders of magnitudes more data than humans to achieve reasonable performance. We propose Neural Episodic Control: a deep reinforcement learning agent that is able to rapidly assimilate new experiences and act upon them. Our agent uses a semi-tabular representation of the value function: a buffer of past experience containing slowly changing state representations and rapidly updated estimates of the value function. We show across a wide range of environments that our agent learns significantly faster than other state-of-the-art, general purpose deep reinforcement learning agents.",
            "referenceCount": 47,
            "citationCount": 284,
            "influentialCitationCount": 45,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.01988"
            },
            "citationStyles": {
                "bibtex": "@Article{Pritzel2017NeuralEC,\n author = {Alexander Pritzel and Benigno Uria and Sriram Srinivasan and A. Badia and Oriol Vinyals and Demis Hassabis and Daan Wierstra and Charles Blundell},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Neural Episodic Control},\n volume = {abs/1703.01988},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b4e669bae43216cb0e77836a411b88dea4bb6034",
            "@type": "ScholarlyArticle",
            "paperId": "b4e669bae43216cb0e77836a411b88dea4bb6034",
            "corpusId": 27585435,
            "url": "https://www.semanticscholar.org/paper/b4e669bae43216cb0e77836a411b88dea4bb6034",
            "title": "Visualizing and Understanding Atari Agents",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2765615734",
                "DBLP": "journals/corr/abs-1711-00138",
                "ArXiv": "1711.00138",
                "CorpusId": 27585435
            },
            "abstract": "While deep reinforcement learning (deep RL) agents are effective at maximizing rewards, it is often unclear what strategies they use to do so. In this paper, we take a step toward explaining deep RL agents through a case study using Atari 2600 environments. In particular, we focus on using saliency maps to understand how an agent learns and executes a policy. We introduce a method for generating useful saliency maps and use it to show 1) what strong agents attend to, 2) whether agents are making decisions for the right or wrong reasons, and 3) how agents evolve during learning. We also test our method on non-expert human subjects and find that it improves their ability to reason about these agents. Overall, our results show that saliency information can provide significant insight into an RL agent's decisions and learning behavior.",
            "referenceCount": 30,
            "citationCount": 267,
            "influentialCitationCount": 41,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-10-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1711.00138"
            },
            "citationStyles": {
                "bibtex": "@Article{Greydanus2017VisualizingAU,\n author = {S. Greydanus and Anurag Koul and Jonathan Dodge and Alan Fern},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Visualizing and Understanding Atari Agents},\n volume = {abs/1711.00138},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:11d10dbe0802afa19525aaa137d56f2832e38d1e",
            "@type": "ScholarlyArticle",
            "paperId": "11d10dbe0802afa19525aaa137d56f2832e38d1e",
            "corpusId": 317248,
            "url": "https://www.semanticscholar.org/paper/11d10dbe0802afa19525aaa137d56f2832e38d1e",
            "title": "Deep transfer via second-order Markov logic",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2600815393",
                "DBLP": "conf/icml/DavisD09",
                "DOI": "10.1145/1553374.1553402",
                "CorpusId": 317248
            },
            "abstract": "Standard inductive learning requires that training and test instances come from the same distribution. Transfer learning seeks to remove this restriction. In shallow transfer, test instances are from the same domain, but have a different distribution. In deep transfer, test instances are from a different domain entirely (i.e., described by different predicates). Humans routinely perform deep transfer, but few learning systems, if any, are capable of it. In this paper we propose an approach based on a form of second-order Markov logic. Our algorithm discovers structural regularities in the source domain in the form of Markov logic formulas with predicate variables, and instantiates these formulas with predicates from the target domain. Using this approach, we have successfully transferred learned knowledge among molecular biology, social network and Web domains. The discovered patterns include broadly useful properties of predicates, like symmetry and transitivity, and relations among predicates, such as various forms of homophily.",
            "referenceCount": 24,
            "citationCount": 238,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://lirias.kuleuven.be/bitstream/123456789/291026/1/davisICML09.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-06-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Davis2009DeepTV,\n author = {Jesse Davis and Pedro M. Domingos},\n booktitle = {International Conference on Machine Learning},\n pages = {217-224},\n title = {Deep transfer via second-order Markov logic},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a13efb90f0b56417bf5dd5b6219681c4259ff355",
            "@type": "ScholarlyArticle",
            "paperId": "a13efb90f0b56417bf5dd5b6219681c4259ff355",
            "corpusId": 41155462,
            "url": "https://www.semanticscholar.org/paper/a13efb90f0b56417bf5dd5b6219681c4259ff355",
            "title": "The Cerebellum: A Neuronal Learning Machine?",
            "venue": "Science",
            "publicationVenue": {
                "id": "urn:research:f59506a8-d8bb-4101-b3d4-c4ac3ed03dad",
                "name": "Science",
                "alternate_names": null,
                "issn": "0193-4511",
                "url": "https://www.jstor.org/journal/science"
            },
            "year": 1996,
            "externalIds": {
                "MAG": "2072802414",
                "DOI": "10.1126/science.272.5265.1126",
                "CorpusId": 41155462,
                "PubMed": "8638157"
            },
            "abstract": "Comparison of two seemingly quite different behaviors yields a surprisingly consistent picture of the role of the cerebellum in motor learning. Behavioral and physiological data about classical conditioning of the eyelid response and motor learning in the vestibulo-ocular reflex suggest that (i) plasticity is distributed between the cerebellar cortex and the deep cerebellar nuclei; (ii) the cerebellar cortex plays a special role in learning the timing of movement; and (iii) the cerebellar cortex guides learning in the deep nuclei, which may allow learning to be transferred from the cortex to the deep nuclei. Because many of the similarities in the data from the two systems typify general features of cerebellar organization, the cerebellar mechanisms of learning in these two systems may represent principles that apply to many motor systems.",
            "referenceCount": 67,
            "citationCount": 618,
            "influentialCitationCount": 25,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "1996-05-24",
            "journal": {
                "name": "Science",
                "volume": "272"
            },
            "citationStyles": {
                "bibtex": "@Article{Raymond1996TheCA,\n author = {J. Raymond and S. Lisberger and M. Mauk},\n booktitle = {Science},\n journal = {Science},\n pages = {1126 - 1131},\n title = {The Cerebellum: A Neuronal Learning Machine?},\n volume = {272},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8df9c71f09eb0dabf5adf17bee0f6b36190b52b2",
            "@type": "ScholarlyArticle",
            "paperId": "8df9c71f09eb0dabf5adf17bee0f6b36190b52b2",
            "corpusId": 12996116,
            "url": "https://www.semanticscholar.org/paper/8df9c71f09eb0dabf5adf17bee0f6b36190b52b2",
            "title": "Representational Learning with Extreme Learning Machine for Big Data Liyanaarachchi",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": null,
            "externalIds": {
                "CorpusId": 12996116
            },
            "abstract": "Restricted Boltzmann Machines (RBM) and auto encoders, learns to represent features in a dataset meaningfully and used as the basic building blocks to create deep networks. This paper introduces Extreme Learning Machine based Auto Encoder (ELM-AE), which learns feature representations using singular values and is used as the basic building block for Multi Layer Extreme Learning Machine (ML-ELM). ML-ELM performance is better than auto encoders based deep networks and Deep Belief Networks (DBN), while in par with Deep Boltzmann Machines (DBM) for MNIST dataset. However MLELM is significantly faster than any state\u2212of\u2212the\u2212art deep networks.",
            "referenceCount": 9,
            "citationCount": 290,
            "influentialCitationCount": 39,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Misc{None,\n author = {L. C. Kasun and Hongming Zhou and G. Huang and C. Vong},\n title = {Representational Learning with Extreme Learning Machine for Big Data Liyanaarachchi}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7200969d70cf6f3fd343f48e97b8ebf7d563a584",
            "@type": "ScholarlyArticle",
            "paperId": "7200969d70cf6f3fd343f48e97b8ebf7d563a584",
            "corpusId": 7292590,
            "url": "https://www.semanticscholar.org/paper/7200969d70cf6f3fd343f48e97b8ebf7d563a584",
            "title": "Graying the black box: Understanding DQNs",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1602.02658",
                "MAG": "2270696664",
                "DBLP": "conf/icml/ZahavyBM16",
                "CorpusId": 7292590
            },
            "abstract": "In recent years there is a growing interest in using deep representations for reinforcement learning. In this paper, we present a methodology and tools to analyze Deep Q-networks (DQNs) in a non-blind matter. Using our tools we reveal that the features learned by DQNs aggregate the state space in a hierarchical fashion, explaining its success. Moreover we are able to understand and describe the policies learned by DQNs for three different Atari2600 games and suggest ways to interpret, debug and optimize deep neural networks in reinforcement learning.",
            "referenceCount": 57,
            "citationCount": 237,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-02-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1602.02658"
            },
            "citationStyles": {
                "bibtex": "@Article{Zahavy2016GrayingTB,\n author = {Tom Zahavy and Nir Ben-Zrihem and Shie Mannor},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Graying the black box: Understanding DQNs},\n volume = {abs/1602.02658},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7a6d31b2da99752d8b215c59fff55791404bdf87",
            "@type": "ScholarlyArticle",
            "paperId": "7a6d31b2da99752d8b215c59fff55791404bdf87",
            "corpusId": 144404415,
            "url": "https://www.semanticscholar.org/paper/7a6d31b2da99752d8b215c59fff55791404bdf87",
            "title": "The Relationship between Learning Conception, Study Strategy and Learning Outcome.",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1984,
            "externalIds": {
                "MAG": "2062020436",
                "DOI": "10.1111/J.2044-8279.1984.TB00846.X",
                "CorpusId": 144404415
            },
            "abstract": "Summary. The essential point of the present study is that human learning should be studied from a second-order perspective. This means that the emphasis is on how people see and understand the world around them. Attention is given to the ways in which students tackle the studying of a text, using the distinction introduced by Marton and Saljo between a deep-level and a surface-level approach. Also investigated is the extent to which these study strategies can be related to the views of students on learning itself (learning conceptions) and the quality of the learning outcome. It turned out that a learning outcome of relatively high quality must be especially associated with deep-level approach and a constructive learning conception.",
            "referenceCount": 0,
            "citationCount": 617,
            "influentialCitationCount": 33,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1984-02-01",
            "journal": {
                "name": "British Journal of Educational Psychology",
                "volume": "54"
            },
            "citationStyles": {
                "bibtex": "@Article{Rossum1984TheRB,\n author = {E. J. Rossum and Simone M. Schenk},\n journal = {British Journal of Educational Psychology},\n pages = {73-83},\n title = {The Relationship between Learning Conception, Study Strategy and Learning Outcome.},\n volume = {54},\n year = {1984}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f93c0111e86c12a0db856e0b681d8d7b13cfd871",
            "@type": "ScholarlyArticle",
            "paperId": "f93c0111e86c12a0db856e0b681d8d7b13cfd871",
            "corpusId": 207573597,
            "url": "https://www.semanticscholar.org/paper/f93c0111e86c12a0db856e0b681d8d7b13cfd871",
            "title": "Expert Systems With Applications",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": null,
            "externalIds": {
                "CorpusId": 207573597
            },
            "abstract": "We offer a systematic analysis of the use of deep learning networks for stock market analysis and pre- diction. Its ability to extract features from a large set of raw data without relying on prior knowledge of predictors makes deep learning potentially attractive for stock market prediction at high frequencies. Deep learning algorithms vary considerably in the choice of network structure, activation function, and other model parameters, and their performance is known to depend heavily on the method of data repre- sentation. Our study attempts to provides a comprehensive and objective assessment of both the advantages and drawbacks of deep learning algorithms for stock market analysis and prediction. Using high- frequency intraday stock returns as input data, we examine the effects of three unsupervised feature extraction methods\u2014principal component analysis, autoencoder, and the restricted Boltzmann machine\u2014 on the network\u2019s overall ability to predict future market behavior. Empirical results suggest that deep neural networks can extract additional information from the residuals of the autoregressive model and improve prediction performance; the same cannot be said when the autoregressive model is applied to the residuals of the network. Covariance estimation is also noticeably improved when the predictive net- work is applied to covariance-based market structure analysis. Our study offers practical insights and potentially useful directions for further investigation into how deep learning networks can be effectively used for stock market analysis and prediction.",
            "referenceCount": 0,
            "citationCount": 543,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Misc{None,\n author = {Eunsuk Chong and Chulwoo Han and Frank C. Park},\n title = {Expert Systems With Applications}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7c8a51d04522496c43db68f2582efd45eaf59fea",
            "@type": "ScholarlyArticle",
            "paperId": "7c8a51d04522496c43db68f2582efd45eaf59fea",
            "corpusId": 206592833,
            "url": "https://www.semanticscholar.org/paper/7c8a51d04522496c43db68f2582efd45eaf59fea",
            "title": "3D ShapeNets: A deep representation for volumetric shapes",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2951755740",
                "DBLP": "conf/cvpr/WuSKYZTX15",
                "DOI": "10.1109/CVPR.2015.7298801",
                "CorpusId": 206592833
            },
            "abstract": "3D shape is a crucial but heavily underutilized cue in today's computer vision systems, mostly due to the lack of a good generic shape representation. With the recent availability of inexpensive 2.5D depth sensors (e.g. Microsoft Kinect), it is becoming increasingly important to have a powerful 3D shape representation in the loop. Apart from category recognition, recovering full 3D shapes from view-based 2.5D depth maps is also a critical part of visual understanding. To this end, we propose to represent a geometric 3D shape as a probability distribution of binary variables on a 3D voxel grid, using a Convolutional Deep Belief Network. Our model, 3D ShapeNets, learns the distribution of complex 3D shapes across different object categories and arbitrary poses from raw CAD data, and discovers hierarchical compositional part representation automatically. It naturally supports joint object recognition and shape completion from 2.5D depth maps, and it enables active object recognition through view planning. To train our 3D deep learning model, we construct ModelNet - a large-scale 3D CAD model dataset. Extensive experiments show that our 3D deep representation enables significant performance improvement over the-state-of-the-arts in a variety of tasks.",
            "referenceCount": 43,
            "citationCount": 4412,
            "influentialCitationCount": 1162,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1406.5670",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-06-22",
            "journal": {
                "name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wu20143DSA,\n author = {Zhirong Wu and Shuran Song and A. Khosla and F. Yu and Linguang Zhang and Xiaoou Tang and Jianxiong Xiao},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1912-1920},\n title = {3D ShapeNets: A deep representation for volumetric shapes},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649",
            "@type": "ScholarlyArticle",
            "paperId": "ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649",
            "corpusId": 5575601,
            "url": "https://www.semanticscholar.org/paper/ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649",
            "title": "Understanding the difficulty of training deep feedforward neural networks",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "journals/jmlr/GlorotB10",
                "MAG": "1533861849",
                "CorpusId": 5575601
            },
            "abstract": "Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence. 1 Deep Neural Networks Deep learning methods aim at learning feature hierarchies with features from higher levels of the hierarchy formed by the composition of lower level features. They include Appearing in Proceedings of the 13 International Conference on Artificial Intelligence and Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: WC Weston et al., 2008). Much attention has recently been devoted to them (see (Bengio, 2009) for a review), because of their theoretical appeal, inspiration from biology and human cognition, and because of empirical success in vision (Ranzato et al., 2007; Larochelle et al., 2007; Vincent et al., 2008) and natural language processing (NLP) (Collobert & Weston, 2008; Mnih & Hinton, 2009). Theoretical results reviewed and discussed by Bengio (2009), suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one may need deep architectures. Most of the recent experimental results with deep architecture are obtained with models that can be turned into deep supervised neural networks, but with initialization or training schemes different from the classical feedforward neural networks (Rumelhart et al., 1986). Why are these new algorithms working so much better than the standard random initialization and gradient-based optimization of a supervised training criterion? Part of the answer may be found in recent analyses of the effect of unsupervised pretraining (Erhan et al., 2009), showing that it acts as a regularizer that initializes the parameters in a \u201cbetter\u201d basin of attraction of the optimization procedure, corresponding to an apparent local minimum associated with better generalization. But earlier work (Bengio et al., 2007) had shown that even a purely supervised but greedy layer-wise procedure would give better results. So here instead of focusing on what unsupervised pre-training or semi-supervised criteria bring to deep architectures, we focus on analyzing what may be going wrong with good old (but deep) multilayer neural networks. Our analysis is driven by investigative experiments to monitor activations (watching for saturation of hidden units) and gradients, across layers and across training iterations. We also evaluate the effects on these of choices of activation function (with the idea that it might affect saturation) and initialization procedure (since unsupervised pretraining is a particular form of initialization and it has a drastic impact).",
            "referenceCount": 22,
            "citationCount": 15609,
            "influentialCitationCount": 798,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2010-03-31",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Glorot2010UnderstandingTD,\n author = {Xavier Glorot and Yoshua Bengio},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n pages = {249-256},\n title = {Understanding the difficulty of training deep feedforward neural networks},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:21539eefc1589f5a66465e090b489f272ef007f3",
            "@type": "ScholarlyArticle",
            "paperId": "21539eefc1589f5a66465e090b489f272ef007f3",
            "corpusId": 246833971,
            "url": "https://www.semanticscholar.org/paper/21539eefc1589f5a66465e090b489f272ef007f3",
            "title": "Deeper Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2022,
            "externalIds": {
                "DOI": "10.4324/9781003278702",
                "CorpusId": 246833971
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2022-02-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Hu2022DeeperL,\n author = {Hang Hu},\n title = {Deeper Learning},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:efca2a32ce9c7a808c2c3efcc2c3dac032dfc8ea",
            "@type": "ScholarlyArticle",
            "paperId": "efca2a32ce9c7a808c2c3efcc2c3dac032dfc8ea",
            "corpusId": 45552660,
            "url": "https://www.semanticscholar.org/paper/efca2a32ce9c7a808c2c3efcc2c3dac032dfc8ea",
            "title": "Big Data and Machine Learning in Health Care.",
            "venue": "Journal of the American Medical Association (JAMA)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2789894922",
                "DOI": "10.1001/jama.2017.18391",
                "CorpusId": 45552660,
                "PubMed": "29532063"
            },
            "abstract": "Nearly all aspects of modern life are in some way being changed by big data and machine learning. Netflix knows what movies people like to watch and Google knows what people want to know based on their search histories. Indeed, Google has recently begun to replace much of its existing non\u2013machine learning technology with machine learning algorithms, and there is great optimism that these techniques can provide similar improvements across many sectors. It isnosurprisethenthatmedicineisawashwithclaims of revolution from the application of machine learning to big health care data. Recent examples have demonstrated that big data and machine learning can create algorithms that perform on par with human physicians.1 Though machine learning and big data may seem mysterious at first, they are in fact deeply related to traditional statistical models that are recognizable to most clinicians. It is our hope that elucidating these connections will demystify these techniques and provide a set of reasonable expectations for the role of machine learning and big data in health care. Machine learning was originally described as a program that learns to perform a task or make a decision automatically from data, rather than having the behavior explicitlyprogrammed.However,thisdefinitionisverybroad and could cover nearly any form of data-driven approach. For instance, consider the Framingham cardiovascular risk score,whichassignspointstovariousfactorsandproduces a number that predicts 10-year cardiovascular risk. Should this be considered an example of machine learning? The answer might obviously seem to be no. Closer inspection oftheFraminghamriskscorerevealsthattheanswermight not be as obvious as it first seems. The score was originally created2 by fitting a proportional hazards model to data frommorethan5300patients,andsothe\u201crule\u201dwasinfact learnedentirelyfromdata.Designatingariskscoreasamachine learning algorithm might seem a strange notion, but this example reveals the uncertain nature of the original definition of machine learning. It is perhaps more useful to imagine an algorithm as existing along a continuum between fully human-guided vs fully machine-guided data analysis. To understand the degree to which a predictive or diagnostic algorithm can said to be an instance of machine learning requires understanding how much of its structure or parameters were predetermined by humans. The trade-off between human specificationofapredictivealgorithm\u2019spropertiesvslearning those properties from data is what is known as the machine learning spectrum. Returning to the Framingham study, to create the original risk score statisticians and clinical experts worked together to make many important decisions, such as which variables to include in the model, therelationshipbetweenthedependentandindependent variables, and variable transformations and interactions. Since considerable human effort was used to define these properties, it would place low on the machine learning spectrum (#19 in the Figure and Supplement). Many evidence-based clinical practices are based on a statistical model of this sort, and so many clinical decisions in fact exist on the machine learning spectrum (middle left of Figure). On the extreme low end of the machine learning spectrum would be heuristics and rules of thumb that do not directly involve the use of any rules or models explicitly derived from data (bottom left of Figure). Suppose a new cardiovascular risk score is created that includes possible extensions to the original model. For example, it could be that risk factors should not be added but instead should be multiplied or divided, or perhaps a particularly important risk factor should square the entire score if it is present. Moreover, if it is not known in advance which variables will be important, but thousands of individual measurements have been collected, how should a good model be identified from among the infinite possibilities? This is precisely what a machine learning algorithm attempts to do. As humans impose fewer assumptions on the algorithm, it moves further up the machine learning spectrum. However, there is never a specific threshold wherein a model suddenly becomes \u201cmachine learning\u201d; rather, all of these approaches exist along a continuum, determined by how many human assumptions are placed onto the algorithm. An example of an approach high on the machine learning spectrum has recently emerged in the form of so-called deep learning models. Deep learning models are stunningly complex networks of artificial neurons that were designed expressly to create accurate models directly from raw data. Researchers recently demonstrated a deep learning algorithm capable of detecting diabetic retinopathy (#4 in the Figure, top center) from retinal photographs at a sensitivity equal to or greater than that of ophthalmologists.1 This model learned the diagnosis procedure directly from the raw pixels of the images with no human intervention outside of a team of ophthalmologists who annotated each image with the correct diagnosis. Because they are able to learn the task with little human instruction or prior assumptions, these deep learning algorithms rank very high on the machine learning spectrum (Figure, light blue circles). Though they require less human guidance, deep learning algorithms for image recognition require enormous amounts of data to capture the full complexity, variety, and nuance inherent to real-world images. Consequently, these algorithms often require hundreds of thousands of examples to extract the salient image features that are correlated with the outcome of interest. Higher placement on the machine learning spectrum does not imply superiority, because different tasks require different levels of human involvement. While algorithms high on the spectrum are often very flexible and can learn many tasks, they are often uninterpretable VIEWPOINT",
            "referenceCount": 3,
            "citationCount": 975,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-03",
            "journal": {
                "name": "JAMA",
                "volume": "319 13"
            },
            "citationStyles": {
                "bibtex": "@Article{Beam2018BigDA,\n author = {Andrew Beam and I. Kohane},\n booktitle = {Journal of the American Medical Association (JAMA)},\n journal = {JAMA},\n pages = {\n          1317-1318\n        },\n title = {Big Data and Machine Learning in Health Care.},\n volume = {319 13},\n year = {2018}\n}\n"
            }
        }
    }
]