[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca9f84c3922004ec6133aa9c2048ceeb17702fee",
            "@type": "ScholarlyArticle",
            "paperId": "ca9f84c3922004ec6133aa9c2048ceeb17702fee",
            "corpusId": 6128905,
            "url": "https://www.semanticscholar.org/paper/ca9f84c3922004ec6133aa9c2048ceeb17702fee",
            "title": "Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1610.04794",
                "DBLP": "journals/corr/YangFSH16",
                "MAG": "2950803263",
                "CorpusId": 6128905
            },
            "abstract": "Most learning approaches treat dimensionality reduction (DR) and clustering separately (i.e., sequentially), but recent research has shown that optimizing the two tasks jointly can substantially improve the performance of both. The premise behind the latter genre is that the data samples are obtained via linear transformation of latent representations that are easy to cluster; but in practice, the transformation from the latent space to the data can be more complicated. In this work, we assume that this transformation is an unknown and possibly nonlinear function. To recover the 'clustering-friendly' latent representations and to better cluster the data, we propose a joint DR and K-means clustering approach in which DR is accomplished via learning a deep neural network (DNN). The motivation is to keep the advantages of jointly optimizing the two tasks, while exploiting the deep neural network's ability to approximate any nonlinear function. This way, the proposed approach can work well for a broad class of generative models. Towards this end, we carefully design the DNN structure and the associated joint optimization criterion, and propose an effective and scalable algorithm to handle the formulated optimization problem. Experiments using different real datasets are employed to showcase the effectiveness of the proposed approach.",
            "referenceCount": 47,
            "citationCount": 705,
            "influentialCitationCount": 125,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-10-15",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2016TowardsKS,\n author = {Bo Yang and Xiao Fu and N. Sidiropoulos and Mingyi Hong},\n booktitle = {International Conference on Machine Learning},\n pages = {3861-3870},\n title = {Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:32ef8fb03197c0dd19b2b01ef6172a845e56a272",
            "@type": "ScholarlyArticle",
            "paperId": "32ef8fb03197c0dd19b2b01ef6172a845e56a272",
            "corpusId": 3633346,
            "url": "https://www.semanticscholar.org/paper/32ef8fb03197c0dd19b2b01ef6172a845e56a272",
            "title": "Deep learning with convolutional neural network in radiology",
            "venue": "Japanese Journal of Radiology",
            "publicationVenue": {
                "id": "urn:research:c4ba8fc8-e8c0-4eb3-bee0-b61f85830814",
                "name": "Japanese Journal of Radiology",
                "alternate_names": [
                    "Jpn J Radiol"
                ],
                "issn": "1867-1071",
                "url": "http://www.radiology.jp/modules/english/index.php?id=3"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2789956930",
                "DOI": "10.1007/s11604-018-0726-3",
                "CorpusId": 3633346,
                "PubMed": "29498017"
            },
            "abstract": null,
            "referenceCount": 75,
            "citationCount": 234,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-03-01",
            "journal": {
                "name": "Japanese Journal of Radiology",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{Yasaka2018DeepLW,\n author = {K. Yasaka and H. Akai and A. Kunimatsu and Shigeru Kiryu and O. Abe},\n booktitle = {Japanese Journal of Radiology},\n journal = {Japanese Journal of Radiology},\n pages = {257-272},\n title = {Deep learning with convolutional neural network in radiology},\n volume = {36},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2dd476f88bd51acb9f7f4ba7adefb10322028425",
            "@type": "ScholarlyArticle",
            "paperId": "2dd476f88bd51acb9f7f4ba7adefb10322028425",
            "corpusId": 52197024,
            "url": "https://www.semanticscholar.org/paper/2dd476f88bd51acb9f7f4ba7adefb10322028425",
            "title": "Deep Learning for Plant Diseases: Detection and Saliency Map Visualisation",
            "venue": "Human and Machine Learning",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2805764882",
                "DBLP": "series/hci/BrahimiALSBM18",
                "DOI": "10.1007/978-3-319-90403-0_6",
                "CorpusId": 52197024
            },
            "abstract": null,
            "referenceCount": 39,
            "citationCount": 145,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-06-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Brahimi2018DeepLF,\n author = {Mohammed Brahimi and M. Arsenovic and S. Laraba and S. Sladojevic and K. Boukhalfa and A. Moussaoui},\n booktitle = {Human and Machine Learning},\n pages = {93-117},\n title = {Deep Learning for Plant Diseases: Detection and Saliency Map Visualisation},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:265644f1b6740ca34bfbe9762b90b33021adde62",
            "@type": "ScholarlyArticle",
            "paperId": "265644f1b6740ca34bfbe9762b90b33021adde62",
            "corpusId": 4345827,
            "url": "https://www.semanticscholar.org/paper/265644f1b6740ca34bfbe9762b90b33021adde62",
            "title": "Deep Learning in Medical Imaging: General Overview",
            "venue": "Korean Journal of Radiology",
            "publicationVenue": {
                "id": "urn:research:8f35a116-5553-4e6a-8c69-58abf9971707",
                "name": "Korean Journal of Radiology",
                "alternate_names": [
                    "Korean J Radiol"
                ],
                "issn": "1229-6929",
                "url": "http://www.radiology.or.kr/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2617669016",
                "PubMedCentral": "5447633",
                "DOI": "10.3348/kjr.2017.18.4.570",
                "CorpusId": 4345827,
                "PubMed": "28670152"
            },
            "abstract": "The artificial neural network (ANN)\u2013a machine learning technique inspired by the human neuronal synapse system\u2013was introduced in the 1950s. However, the ANN was previously limited in its ability to solve actual problems, due to the vanishing gradient and overfitting problems with training of deep architecture, lack of computing power, and primarily the absence of sufficient data to train the computer system. Interest in this concept has lately resurfaced, due to the availability of big data, enhanced computing power with the current graphics processing units, and novel algorithms to train the deep neural network. Recent studies on this technology suggest its potentially to perform better than humans in some visual and auditory recognition tasks, which may portend its applications in medicine and healthcare, especially in medical imaging, in the foreseeable future. This review article offers perspectives on the history, development, and applications of deep learning technology, particularly regarding its applications in medical imaging.",
            "referenceCount": 104,
            "citationCount": 827,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc5447633?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-05-19",
            "journal": {
                "name": "Korean Journal of Radiology",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Lee2017DeepLI,\n author = {June-Goo Lee and Sanghoon Jun and Younghoon Cho and Hyunna Lee and G. Kim and J. Seo and Namkug Kim},\n booktitle = {Korean Journal of Radiology},\n journal = {Korean Journal of Radiology},\n pages = {570 - 584},\n title = {Deep Learning in Medical Imaging: General Overview},\n volume = {18},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a63fd82a35c41b9a07f72b696623da9e33ca075a",
            "@type": "ScholarlyArticle",
            "paperId": "a63fd82a35c41b9a07f72b696623da9e33ca075a",
            "corpusId": 46765510,
            "url": "https://www.semanticscholar.org/paper/a63fd82a35c41b9a07f72b696623da9e33ca075a",
            "title": "Deep Learning in Neuroradiology",
            "venue": "American Journal of Neuroradiology",
            "publicationVenue": {
                "id": "urn:research:f1ea2acf-ea92-4727-abc2-b707defad005",
                "name": "American Journal of Neuroradiology",
                "alternate_names": [
                    "Am J Neuroradiol"
                ],
                "issn": "0195-6108",
                "url": "http://www.ajnr.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2786907498",
                "DOI": "10.3174/ajnr.A5543",
                "CorpusId": 46765510,
                "PubMed": "29419402"
            },
            "abstract": "SUMMARY: Deep learning is a form of machine learning using a convolutional neural network architecture that shows tremendous promise for imaging applications. It is increasingly being adapted from its original demonstration in computer vision applications to medical imaging. Because of the high volume and wealth of multimodal imaging information acquired in typical studies, neuroradiology is poised to be an early adopter of deep learning. Compelling deep learning research applications have been demonstrated, and their use is likely to grow rapidly. This review article describes the reasons, outlines the basic methods used to train and test deep learning models, and presents a brief overview of current and potential clinical applications with an emphasis on how they are likely to change future neuroradiology practice. Facility with these methods among neuroimaging researchers and clinicians will be important to channel and harness the vast potential of this new method.",
            "referenceCount": 44,
            "citationCount": 191,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.ajnr.org/content/ajnr/39/10/1776.full.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-10-01",
            "journal": {
                "name": "American Journal of Neuroradiology",
                "volume": "39"
            },
            "citationStyles": {
                "bibtex": "@Article{Zaharchuk2018DeepLI,\n author = {G. Zaharchuk and E. Gong and M. Wintermark and D. Rubin and C. Langlotz},\n booktitle = {American Journal of Neuroradiology},\n journal = {American Journal of Neuroradiology},\n pages = {1776 - 1784},\n title = {Deep Learning in Neuroradiology},\n volume = {39},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4016403a62b587a675198415b93b903e2a66264a",
            "@type": "ScholarlyArticle",
            "paperId": "4016403a62b587a675198415b93b903e2a66264a",
            "corpusId": 2098713,
            "url": "https://www.semanticscholar.org/paper/4016403a62b587a675198415b93b903e2a66264a",
            "title": "CSI-Based Fingerprinting for Indoor Localization: A Deep Learning Approach",
            "venue": "IEEE Transactions on Vehicular Technology",
            "publicationVenue": {
                "id": "urn:research:983b0731-eddf-4f05-9c9b-81059a9f9c51",
                "name": "IEEE Transactions on Vehicular Technology",
                "alternate_names": [
                    "IEEE Trans Veh Technol"
                ],
                "issn": "0018-9545",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=25"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/WangGMP16",
                "ArXiv": "1603.07080",
                "MAG": "2952796274",
                "DOI": "10.1109/TVT.2016.2545523",
                "CorpusId": 2098713
            },
            "abstract": "With the fast-growing demand of location-based services in indoor environments, indoor positioning based on fingerprinting has attracted significant interest due to its high accuracy. In this paper, we present a novel deep-learning-based indoor fingerprinting system using channel state information (CSI), which is termed DeepFi. Based on three hypotheses on CSI, the DeepFi system architecture includes an offline training phase and an online localization phase. In the offline training phase, deep learning is utilized to train all the weights of a deep network as fingerprints. Moreover, a greedy learning algorithm is used to train the weights layer by layer to reduce complexity. In the online localization phase, we use a probabilistic method based on the radial basis function to obtain the estimated location. Experimental results are presented to confirm that DeepFi can effectively reduce location error, compared with three existing methods in two representative indoor environments.",
            "referenceCount": 60,
            "citationCount": 830,
            "influentialCitationCount": 61,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-03-23",
            "journal": {
                "name": "IEEE Transactions on Vehicular Technology",
                "volume": "66"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2016CSIBasedFF,\n author = {Xuyu Wang and Lingjun Gao and S. Mao and S. Pandey},\n booktitle = {IEEE Transactions on Vehicular Technology},\n journal = {IEEE Transactions on Vehicular Technology},\n pages = {763-776},\n title = {CSI-Based Fingerprinting for Indoor Localization: A Deep Learning Approach},\n volume = {66},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:21ba757bf394720e0b66b86e7638ae28742d6570",
            "@type": "ScholarlyArticle",
            "paperId": "21ba757bf394720e0b66b86e7638ae28742d6570",
            "corpusId": 6645229,
            "url": "https://www.semanticscholar.org/paper/21ba757bf394720e0b66b86e7638ae28742d6570",
            "title": "Deep Learning for Identifying Metastatic Breast Cancer",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2474421929",
                "ArXiv": "1606.05718",
                "DBLP": "journals/corr/WangKGIB16",
                "CorpusId": 6645229
            },
            "abstract": "The International Symposium on Biomedical Imaging (ISBI) held a grand challenge to evaluate computational systems for the automated detection of metastatic breast cancer in whole slide images of sentinel lymph node biopsies. Our team won both competitions in the grand challenge, obtaining an area under the receiver operating curve (AUC) of 0.925 for the task of whole slide image classification and a score of 0.7051 for the tumor localization task. A pathologist independently reviewed the same images, obtaining a whole slide image classification AUC of 0.966 and a tumor localization score of 0.733. Combining our deep learning system's predictions with the human pathologist's diagnoses increased the pathologist's AUC to 0.995, representing an approximately 85 percent reduction in human error rate. These results demonstrate the power of using deep learning to produce significant improvements in the accuracy of pathological diagnoses.",
            "referenceCount": 26,
            "citationCount": 825,
            "influentialCitationCount": 51,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-06-18",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1606.05718"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2016DeepLF,\n author = {Dayong Wang and A. Khosla and Rishab Gargeya and H. Irshad and Andrew H. Beck},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Learning for Identifying Metastatic Breast Cancer},\n volume = {abs/1606.05718},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a191715b2e3e51cc08114e759b7bf7fdf9f2c206",
            "@type": "ScholarlyArticle",
            "paperId": "a191715b2e3e51cc08114e759b7bf7fdf9f2c206",
            "corpusId": 65080459,
            "url": "https://www.semanticscholar.org/paper/a191715b2e3e51cc08114e759b7bf7fdf9f2c206",
            "title": "Deep Learning with Python",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2784570262",
                "CorpusId": 65080459
            },
            "abstract": "Summary Deep Learning with Python introduces the field of deep learning using the Python language and the powerful Keras library. Written by Keras creator and Google AI researcher Franois Chollet, this book builds your understanding through intuitive explanations and practical examples. Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications. About the Technology Machine learning has made remarkable progress in recent years. We went from near-unusable speech and image recognition, to near-human accuracy. We went from machines that couldn't beat a serious Go player, to defeating a world champion. Behind this progress is deep learninga combination of engineering advances, best practices, and theory that enables a wealth of previously impossible smart applications. About the Book Deep Learning with Python introduces the field of deep learning using the Python language and the powerful Keras library. Written by Keras creator and Google AI researcher Franois Chollet, this book builds your understanding through intuitive explanations and practical examples. You'll explore challenging concepts and practice with applications in computer vision, natural-language processing, and generative models. By the time you finish, you'll have the knowledge and hands-on skills to apply deep learning in your own projects. What's Inside Deep learning from first principles Setting up your own deep-learning environment Image-classification models Deep learning for text and sequences Neural style transfer, text generation, and image generation About the Reader Readers need intermediate Python skills. No previous experience with Keras, TensorFlow, or machine learning is required. About the Author Franois Chollet works on deep learning at Google in Mountain View, CA. He is the creator of the Keras deep-learning library, as well as a contributor to the TensorFlow machine-learning framework. He also does deep-learning research, with a focus on computer vision and the application of machine learning to formal reasoning. His papers have been published at major conferences in the field, including the Conference on Computer Vision and Pattern Recognition (CVPR), the Conference and Workshop on Neural Information Processing Systems (NIPS), the International Conference on Learning Representations (ICLR), and others.",
            "referenceCount": 0,
            "citationCount": 426,
            "influentialCitationCount": 37,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-12-22",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Chollet2017DeepLW,\n author = {Fran\u00e7ois Chollet},\n title = {Deep Learning with Python},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:45ac4f5d3c66461b21fe8a8de2bdaeaf38bc86e9",
            "@type": "ScholarlyArticle",
            "paperId": "45ac4f5d3c66461b21fe8a8de2bdaeaf38bc86e9",
            "corpusId": 3499915,
            "url": "https://www.semanticscholar.org/paper/45ac4f5d3c66461b21fe8a8de2bdaeaf38bc86e9",
            "title": "Deep Learning Based Communication Over the Air",
            "venue": "IEEE Journal on Selected Topics in Signal Processing",
            "publicationVenue": {
                "id": "urn:research:e93ebb7d-cfa6-4361-8051-3c6dff3eed1f",
                "name": "IEEE Journal on Selected Topics in Signal Processing",
                "alternate_names": [
                    "IEEE J Sel Top Signal Process",
                    "IEEE Journal of Selected Topics in Signal Processing"
                ],
                "issn": "1932-4553",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=4200690"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1707.03384",
                "DBLP": "journals/corr/DornerCHB17",
                "MAG": "2736068844",
                "DOI": "10.1109/JSTSP.2017.2784180",
                "CorpusId": 3499915
            },
            "abstract": "End-to-end learning of communications systems is a fascinating novel concept that has so far only been validated by simulations for block-based transmissions. It allows learning of transmitter and receiver implementations as deep neural networks (NNs) that are optimized for an arbitrary differentiable end-to-end performance metric, e.g., block error rate (BLER). In this paper, we demonstrate that over-the-air transmissions are possible: We build, train, and run a complete communications system solely composed of NNs using unsynchronized off-the-shelf software-defined radios and open-source deep learning software libraries. We extend the existing ideas toward continuous data transmission, which eases their current restriction to short block lengths but also entails the issue of receiver synchronization. We overcome this problem by introducing a frame synchronization module based on another NN. A comparison of the BLER performance of the \u201clearned\u201d system with that of a practical baseline shows competitive performance close to $\\text{1}$ \u00a0dB, even without extensive hyperparameter tuning. We identify several practical challenges of training such a system over actual channels, in particular, the missing channel gradient, and propose a two-step learning procedure based on the idea of transfer learning that circumvents this issue.",
            "referenceCount": 35,
            "citationCount": 604,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1707.03384",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-11",
            "journal": {
                "name": "IEEE Journal of Selected Topics in Signal Processing",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{D\u00f6rner2017DeepLB,\n author = {Sebastian D\u00f6rner and Sebastian Cammerer and J. Hoydis and S. Brink},\n booktitle = {IEEE Journal on Selected Topics in Signal Processing},\n journal = {IEEE Journal of Selected Topics in Signal Processing},\n pages = {132-143},\n title = {Deep Learning Based Communication Over the Air},\n volume = {12},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a1c922be467d1c0c64b963e65dae41778b81b2a0",
            "@type": "ScholarlyArticle",
            "paperId": "a1c922be467d1c0c64b963e65dae41778b81b2a0",
            "corpusId": 2222076,
            "url": "https://www.semanticscholar.org/paper/a1c922be467d1c0c64b963e65dae41778b81b2a0",
            "title": "Deep Learning Scaling is Predictable, Empirically",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/abs-1712-00409",
                "ArXiv": "1712.00409",
                "MAG": "2775461895",
                "CorpusId": 2222076
            },
            "abstract": "Deep learning (DL) creates impactful advances following a virtuous recipe: model architecture search, creating large training data sets, and scaling computation. It is widely believed that growing training sets and models should improve accuracy and result in better products. As DL application domains grow, we would like a deeper understanding of the relationships between training set size, computational scale, and model accuracy improvements to advance the state-of-the-art. \nThis paper presents a large scale empirical characterization of generalization error and model size growth as training sets grow. We introduce a methodology for this measurement and test four machine learning domains: machine translation, language modeling, image processing, and speech recognition. Our empirical results show power-law generalization error scaling across a breadth of factors, resulting in power-law exponents---the \"steepness\" of the learning curve---yet to be explained by theoretical work. Further, model improvements only shift the error but do not appear to affect the power-law exponent. We also show that model size scales sublinearly with data size. These scaling relationships have significant implications on deep learning research, practice, and systems. They can assist model debugging, setting accuracy targets, and decisions about data set growth. They can also guide computing system design and underscore the importance of continued computational scaling.",
            "referenceCount": 38,
            "citationCount": 471,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-12-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1712.00409"
            },
            "citationStyles": {
                "bibtex": "@Article{Hestness2017DeepLS,\n author = {Joel Hestness and Sharan Narang and Newsha Ardalani and G. Diamos and Heewoo Jun and Hassan Kianinejad and Md. Mostofa Ali Patwary and Yang Yang and Yanqi Zhou},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Learning Scaling is Predictable, Empirically},\n volume = {abs/1712.00409},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8755a46d48a1054ce9fecaf155f5c0066f5e20c1",
            "@type": "ScholarlyArticle",
            "paperId": "8755a46d48a1054ce9fecaf155f5c0066f5e20c1",
            "corpusId": 4578542,
            "url": "https://www.semanticscholar.org/paper/8755a46d48a1054ce9fecaf155f5c0066f5e20c1",
            "title": "Deep Learning for Brain MRI Segmentation: State of the Art and Future Directions",
            "venue": "Journal of digital imaging",
            "publicationVenue": {
                "id": "urn:research:d97d3d34-0bc5-4a81-9542-b39361ecf3aa",
                "name": "Journal of digital imaging",
                "alternate_names": [
                    "Journal of Digital Imaging",
                    "J digit imaging",
                    "J Digit Imaging"
                ],
                "issn": "0897-1889",
                "url": "https://link.springer.com/journal/10278"
            },
            "year": 2017,
            "externalIds": {
                "PubMedCentral": "5537095",
                "MAG": "2621028221",
                "DBLP": "journals/jdi/AkkusGHRE17",
                "DOI": "10.1007/s10278-017-9983-4",
                "CorpusId": 4578542,
                "PubMed": "28577131"
            },
            "abstract": null,
            "referenceCount": 64,
            "citationCount": 765,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s10278-017-9983-4.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-06-02",
            "journal": {
                "name": "Journal of Digital Imaging",
                "volume": "30"
            },
            "citationStyles": {
                "bibtex": "@Article{Akkus2017DeepLF,\n author = {Z. Akkus and A. Galimzianova and A. Hoogi and D. Rubin and B. Erickson},\n booktitle = {Journal of digital imaging},\n journal = {Journal of Digital Imaging},\n pages = {449 - 459},\n title = {Deep Learning for Brain MRI Segmentation: State of the Art and Future Directions},\n volume = {30},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e0ea008f23921d5d25dd150352b64e0c0c8cdd97",
            "@type": "ScholarlyArticle",
            "paperId": "e0ea008f23921d5d25dd150352b64e0c0c8cdd97",
            "corpusId": 4108581,
            "url": "https://www.semanticscholar.org/paper/e0ea008f23921d5d25dd150352b64e0c0c8cdd97",
            "title": "Overview of deep learning in medical imaging",
            "venue": "Radiological Physics and Technology",
            "publicationVenue": {
                "id": "urn:research:4cbad1bb-6e24-4b1f-b853-c1469a3bba45",
                "name": "Radiological Physics and Technology",
                "alternate_names": [
                    "Radiol Phys Technol"
                ],
                "issn": "1865-0333",
                "url": "https://www.springer.com/medicine/radiology/journal/12194"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2731899572",
                "DOI": "10.1007/s12194-017-0406-5",
                "CorpusId": 4108581,
                "PubMed": "28689314"
            },
            "abstract": null,
            "referenceCount": 106,
            "citationCount": 667,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-07-08",
            "journal": {
                "name": "Radiological Physics and Technology",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Suzuki2017OverviewOD,\n author = {Kenji Suzuki},\n booktitle = {Radiological Physics and Technology},\n journal = {Radiological Physics and Technology},\n pages = {257-273},\n title = {Overview of deep learning in medical imaging},\n volume = {10},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d8df8e2c10fce631173aae694f017dd136226284",
            "@type": "ScholarlyArticle",
            "paperId": "d8df8e2c10fce631173aae694f017dd136226284",
            "corpusId": 28072318,
            "url": "https://www.semanticscholar.org/paper/d8df8e2c10fce631173aae694f017dd136226284",
            "title": "Phase recovery and holographic image reconstruction using deep learning in neural networks",
            "venue": "Light: Science & Applications",
            "publicationVenue": {
                "id": "urn:research:d4a5e814-e8a0-4c10-aaa6-ebdc39421fec",
                "name": "Light: Science & Applications",
                "alternate_names": [
                    "Light-Science & Applications",
                    "Light Sci  Appl",
                    "Light  Appl"
                ],
                "issn": "2047-7538",
                "url": "http://www.nature.com/lsa/"
            },
            "year": 2017,
            "externalIds": {
                "PubMedCentral": "6060068",
                "MAG": "2612688942",
                "DBLP": "journals/corr/RivensonZGTO17",
                "ArXiv": "1705.04286",
                "DOI": "10.1038/lsa.2017.141",
                "CorpusId": 28072318,
                "PubMed": "30839514"
            },
            "abstract": null,
            "referenceCount": 70,
            "citationCount": 680,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/lsa2017141.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-05-10",
            "journal": {
                "name": "Light, Science & Applications",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Rivenson2017PhaseRA,\n author = {Y. Rivenson and Yibo Zhang and H. Gunaydin and Da Teng and A. Ozcan},\n booktitle = {Light: Science & Applications},\n journal = {Light, Science & Applications},\n title = {Phase recovery and holographic image reconstruction using deep learning in neural networks},\n volume = {7},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:571f4226cb7fbaf2f771fe32c0e4f02b010a223a",
            "@type": "ScholarlyArticle",
            "paperId": "571f4226cb7fbaf2f771fe32c0e4f02b010a223a",
            "corpusId": 6736412,
            "url": "https://www.semanticscholar.org/paper/571f4226cb7fbaf2f771fe32c0e4f02b010a223a",
            "title": "Deep Learning for Medical Image Processing: Overview, Challenges and Future",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/RazzakNZ17",
                "MAG": "2607941059",
                "ArXiv": "1704.06825",
                "DOI": "10.1007/978-3-319-65981-7_12",
                "CorpusId": 6736412
            },
            "abstract": null,
            "referenceCount": 58,
            "citationCount": 780,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1704.06825",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-04-22",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1704.06825"
            },
            "citationStyles": {
                "bibtex": "@Article{Razzak2017DeepLF,\n author = {M. I. Razzak and S. Naz and Ahmad Zaib},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Learning for Medical Image Processing: Overview, Challenges and Future},\n volume = {abs/1704.06825},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1242d79573397094c5670f55e58c8333cced0beb",
            "@type": "ScholarlyArticle",
            "paperId": "1242d79573397094c5670f55e58c8333cced0beb",
            "corpusId": 5005167,
            "url": "https://www.semanticscholar.org/paper/1242d79573397094c5670f55e58c8333cced0beb",
            "title": "Deep Learning: A Primer for Radiologists.",
            "venue": "Radiographics",
            "publicationVenue": {
                "id": "urn:research:6a469aed-f8e3-456a-92e6-53237e43d3da",
                "name": "Radiographics",
                "alternate_names": null,
                "issn": "0271-5333",
                "url": "https://pubs.rsna.org/loi/radiographics"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2767236661",
                "DOI": "10.1148/rg.2017170077",
                "CorpusId": 5005167,
                "PubMed": "29131760"
            },
            "abstract": "Deep learning is a class of machine learning methods that are gaining success and attracting interest in many domains, including computer vision, speech recognition, natural language processing, and playing games. Deep learning methods produce a mapping from raw inputs to desired outputs (eg, image classes). Unlike traditional machine learning methods, which require hand-engineered feature extraction from inputs, deep learning methods learn these features directly from data. With the advent of large datasets and increased computing power, these methods can produce models with exceptional performance. These models are multilayer artificial neural networks, loosely inspired by biologic neural systems. Weighted connections between nodes (neurons) in the network are iteratively adjusted based on example pairs of inputs and target outputs by back-propagating a corrective error signal through the network. For computer vision tasks, convolutional neural networks (CNNs) have proven to be effective. Recently, several clinical applications of CNNs have been proposed and studied in radiology for classification, detection, and segmentation tasks. This article reviews the key concepts of deep learning for clinical radiologists, discusses technical requirements, describes emerging applications in clinical radiology, and outlines limitations and future directions in this field. Radiologists should become familiar with the principles and potential applications of deep learning in medical imaging. \u00a9RSNA, 2017.",
            "referenceCount": 28,
            "citationCount": 716,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-11-13",
            "journal": {
                "name": "Radiographics : a review publication of the Radiological Society of North America, Inc",
                "volume": "37 7"
            },
            "citationStyles": {
                "bibtex": "@Article{Chartrand2017DeepLA,\n author = {G. Chartrand and P. Cheng and Eugene Vorontsov and M. Drozdzal and S. Turcotte and C. Pal and S. Kadoury and A. Tang},\n booktitle = {Radiographics},\n journal = {Radiographics : a review publication of the Radiological Society of North America, Inc},\n pages = {\n          2113-2131\n        },\n title = {Deep Learning: A Primer for Radiologists.},\n volume = {37 7},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3f2c353d5fc36f945cf5146d884a1d79391759ac",
            "@type": "ScholarlyArticle",
            "paperId": "3f2c353d5fc36f945cf5146d884a1d79391759ac",
            "corpusId": 23668684,
            "url": "https://www.semanticscholar.org/paper/3f2c353d5fc36f945cf5146d884a1d79391759ac",
            "title": "State-of-the-Art Deep Learning: Evolving Machine Intelligence Toward Tomorrow\u2019s Intelligent Network Traffic Control Systems",
            "venue": "IEEE Communications Surveys and Tutorials",
            "publicationVenue": {
                "id": "urn:research:95d0dda7-5d58-4afd-b59f-315447b81992",
                "name": "IEEE Communications Surveys and Tutorials",
                "alternate_names": [
                    "IEEE Commun Surv Tutor"
                ],
                "issn": "1553-877X",
                "url": "http://www.comsoc.org/cst"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2617931713",
                "DBLP": "journals/comsur/FadlullahTMKAIM17",
                "DOI": "10.1109/COMST.2017.2707140",
                "CorpusId": 23668684
            },
            "abstract": "Currently, the network traffic control systems are mainly composed of the Internet core and wired/wireless heterogeneous backbone networks. Recently, these packet-switched systems are experiencing an explosive network traffic growth due to the rapid development of communication technologies. The existing network policies are not sophisticated enough to cope with the continually varying network conditions arising from the tremendous traffic growth. Deep learning, with the recent breakthrough in the machine learning/intelligence area, appears to be a viable approach for the network operators to configure and manage their networks in a more intelligent and autonomous fashion. While deep learning has received a significant research attention in a number of other domains such as computer vision, speech recognition, robotics, and so forth, its applications in network traffic control systems are relatively recent and garnered rather little attention. In this paper, we address this point and indicate the necessity of surveying the scattered works on deep learning applications for various network traffic control aspects. In this vein, we provide an overview of the state-of-the-art deep learning architectures and algorithms relevant to the network traffic control systems. Also, we discuss the deep learning enablers for network systems. In addition, we discuss, in detail, a new use case, i.e., deep learning based intelligent routing. We demonstrate the effectiveness of the deep learning-based routing approach in contrast with the conventional routing strategy. Furthermore, we discuss a number of open research issues, which researchers may find useful in the future.",
            "referenceCount": 260,
            "citationCount": 611,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-05-23",
            "journal": {
                "name": "IEEE Communications Surveys & Tutorials",
                "volume": "19"
            },
            "citationStyles": {
                "bibtex": "@Article{Fadlullah2017StateoftheArtDL,\n author = {Z. Fadlullah and Fengxiao Tang and Bomin Mao and N. Kato and Osamu Akashi and Takeru Inoue and Kimihiro Mizutani},\n booktitle = {IEEE Communications Surveys and Tutorials},\n journal = {IEEE Communications Surveys & Tutorials},\n pages = {2432-2455},\n title = {State-of-the-Art Deep Learning: Evolving Machine Intelligence Toward Tomorrow\u2019s Intelligent Network Traffic Control Systems},\n volume = {19},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4bf76588122827157c43a59e656dccc6b6a22e90",
            "@type": "ScholarlyArticle",
            "paperId": "4bf76588122827157c43a59e656dccc6b6a22e90",
            "corpusId": 219531264,
            "url": "https://www.semanticscholar.org/paper/4bf76588122827157c43a59e656dccc6b6a22e90",
            "title": "Deep Graph Contrastive Representation Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2006.04131",
                "MAG": "3033039844",
                "DBLP": "journals/corr/abs-2006-04131",
                "CorpusId": 219531264
            },
            "abstract": "Graph representation learning nowadays becomes fundamental in analyzing graph-structured data. Inspired by recent success of contrastive methods, in this paper, we propose a novel framework for unsupervised graph representation learning by leveraging a contrastive objective at the node level. Specifically, we generate two graph views by corruption and learn node representations by maximizing the agreement of node representations in these two views. To provide diverse node contexts for the contrastive objective, we propose a hybrid scheme for generating graph views on both structure and attribute levels. Besides, we provide theoretical justification behind our motivation from two perspectives, mutual information and the classical triplet loss. We perform empirical experiments on both transductive and inductive learning tasks using a variety of real-world datasets. Experimental experiments demonstrate that despite its simplicity, our proposed method consistently outperforms existing state-of-the-art methods by large margins. Moreover, our unsupervised method even surpasses its supervised counterparts on transductive tasks, demonstrating its great potential in real-world applications.",
            "referenceCount": 49,
            "citationCount": 449,
            "influentialCitationCount": 154,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-06-07",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2006.04131"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhu2020DeepGC,\n author = {Yanqiao Zhu and Yichen Xu and Feng Yu and Q. Liu and Shu Wu and Liang Wang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Graph Contrastive Representation Learning},\n volume = {abs/2006.04131},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:36ef340614ca97bdc2a55839b9529b204887eda6",
            "@type": "ScholarlyArticle",
            "paperId": "36ef340614ca97bdc2a55839b9529b204887eda6",
            "corpusId": 3451592,
            "url": "https://www.semanticscholar.org/paper/36ef340614ca97bdc2a55839b9529b204887eda6",
            "title": "Deep Learning Methods for Improved Decoding of Linear Codes",
            "venue": "IEEE Journal on Selected Topics in Signal Processing",
            "publicationVenue": {
                "id": "urn:research:e93ebb7d-cfa6-4361-8051-3c6dff3eed1f",
                "name": "IEEE Journal on Selected Topics in Signal Processing",
                "alternate_names": [
                    "IEEE J Sel Top Signal Process",
                    "IEEE Journal of Selected Topics in Signal Processing"
                ],
                "issn": "1932-4553",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=4200690"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/jstsp/NachmaniMLGBB18",
                "ArXiv": "1706.07043",
                "MAG": "2666368276",
                "DOI": "10.1109/JSTSP.2017.2788405",
                "CorpusId": 3451592
            },
            "abstract": "The problem of low complexity, close to optimal, channel decoding of linear codes with short to moderate block length is considered. It is shown that deep learning methods can be used to improve a standard belief propagation decoder, despite the large example space. Similar improvements are obtained for the min-sum algorithm. It is also shown that tying the parameters of the decoders across iterations, so as to form a recurrent neural network architecture, can be implemented with comparable results. The advantage is that significantly less parameters are required. We also introduce a recurrent neural decoder architecture based on the method of successive relaxation. Improvements over standard belief propagation are also observed on sparser Tanner graph representations of the codes. Furthermore, we demonstrate that the neural belief propagation decoder can be used to improve the performance, or alternatively reduce the computational complexity, of a close to optimal decoder of short BCH codes.",
            "referenceCount": 48,
            "citationCount": 403,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1706.07043",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-06-21",
            "journal": {
                "name": "IEEE Journal of Selected Topics in Signal Processing",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Nachmani2017DeepLM,\n author = {Eliya Nachmani and Elad Marciano and Loren Lugosch and W. Gross and D. Burshtein and Yair Be\u2019ery},\n booktitle = {IEEE Journal on Selected Topics in Signal Processing},\n journal = {IEEE Journal of Selected Topics in Signal Processing},\n pages = {119-131},\n title = {Deep Learning Methods for Improved Decoding of Linear Codes},\n volume = {12},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6cc42aaf638c351a27fa052d9a5aff05de4806c6",
            "@type": "ScholarlyArticle",
            "paperId": "6cc42aaf638c351a27fa052d9a5aff05de4806c6",
            "corpusId": 4779759,
            "url": "https://www.semanticscholar.org/paper/6cc42aaf638c351a27fa052d9a5aff05de4806c6",
            "title": "Automatic Image-Based Plant Disease Severity Estimation Using Deep Learning",
            "venue": "Computational Intelligence and Neuroscience",
            "publicationVenue": {
                "id": "urn:research:f32b7322-b69c-4e63-801d-8f50784ef778",
                "name": "Computational Intelligence and Neuroscience",
                "alternate_names": [
                    "Comput Intell Neurosci"
                ],
                "issn": "1687-5265",
                "url": "https://www.hindawi.com/journals/cin/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/cin/WangSW17",
                "MAG": "2733343268",
                "PubMedCentral": "5516765",
                "DOI": "10.1155/2017/2917536",
                "CorpusId": 4779759,
                "PubMed": "28757863"
            },
            "abstract": "Automatic and accurate estimation of disease severity is essential for food security, disease management, and yield loss prediction. Deep learning, the latest breakthrough in computer vision, is promising for fine-grained disease severity classification, as the method avoids the labor-intensive feature engineering and threshold-based segmentation. Using the apple black rot images in the PlantVillage dataset, which are further annotated by botanists with four severity stages as ground truth, a series of deep convolutional neural networks are trained to diagnose the severity of the disease. The performances of shallow networks trained from scratch and deep models fine-tuned by transfer learning are evaluated systemically in this paper. The best model is the deep VGG16 model trained with transfer learning, which yields an overall accuracy of 90.4% on the hold-out test set. The proposed deep learning model may have great potential in disease control for modern agriculture.",
            "referenceCount": 32,
            "citationCount": 413,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://downloads.hindawi.com/journals/cin/2017/2917536.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-05",
            "journal": {
                "name": "Computational Intelligence and Neuroscience",
                "volume": "2017"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2017AutomaticIP,\n author = {Guan Wang and Yu Sun and Jianxin Wang},\n booktitle = {Computational Intelligence and Neuroscience},\n journal = {Computational Intelligence and Neuroscience},\n title = {Automatic Image-Based Plant Disease Severity Estimation Using Deep Learning},\n volume = {2017},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:82bbf69ede840a8604d153ff23dcd95b8e5ff317",
            "@type": "ScholarlyArticle",
            "paperId": "82bbf69ede840a8604d153ff23dcd95b8e5ff317",
            "corpusId": 3043873,
            "url": "https://www.semanticscholar.org/paper/82bbf69ede840a8604d153ff23dcd95b8e5ff317",
            "title": "A Survey on Deep Learning in Big Data",
            "venue": "22017 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2744241569",
                "DBLP": "conf/cse/GheisariWB17",
                "DOI": "10.1109/CSE-EUC.2017.215",
                "CorpusId": 3043873
            },
            "abstract": "Big Data means extremely huge large data sets that can be analyzed to find patterns, trends. One technique that can be used for data analysis so that able to help us find abstract patterns in Big Data is Deep Learning. If we apply Deep Learning to Big Data, we can find unknown and useful patterns that were impossible so far. With the help of Deep Learning, AI is getting smart. There is a hypothesis in this regard, the more data, the more abstract knowledge. So a handy survey of Big Data, Deep Learning and its application in Big Data is necessary. In this paper, we provide a comprehensive survey on what is Big Data, comparing methods, its research problems, and trends. Then a survey of Deep Learning, its methods, comparison of frameworks, and algorithms is presented. And at last, application of Deep Learning in Big Data, its challenges, open research problems and future trends are presented.",
            "referenceCount": 43,
            "citationCount": 422,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2017-07-01",
            "journal": {
                "name": "22017 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC)",
                "volume": "02"
            },
            "citationStyles": {
                "bibtex": "@Article{Gheisari2017ASO,\n author = {M. Gheisari and Guojun Wang and Md. Zakirul Alam Bhuiyan},\n booktitle = {22017 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC)},\n journal = {22017 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC)},\n pages = {173-180},\n title = {A Survey on Deep Learning in Big Data},\n volume = {02},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:58912e2c2aaa77d1448d51e9d9460e06a5b924b9",
            "@type": "ScholarlyArticle",
            "paperId": "58912e2c2aaa77d1448d51e9d9460e06a5b924b9",
            "corpusId": 3325643,
            "url": "https://www.semanticscholar.org/paper/58912e2c2aaa77d1448d51e9d9460e06a5b924b9",
            "title": "VAMPnets for deep learning of molecular kinetics",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1710.06012",
                "MAG": "2765372792",
                "PubMedCentral": "5750224",
                "DOI": "10.1038/s41467-017-02388-1",
                "CorpusId": 3325643,
                "PubMed": "29295994"
            },
            "abstract": null,
            "referenceCount": 95,
            "citationCount": 418,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41467-017-02388-1.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-16",
            "journal": {
                "name": "Nature Communications",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Mardt2017VAMPnetsFD,\n author = {Andreas Mardt and Luca Pasquali and Hao Wu and F. No\u00e9},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {VAMPnets for deep learning of molecular kinetics},\n volume = {9},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6568423cfaca7e24c88ea208cb0e67129e43aa9b",
            "@type": "ScholarlyArticle",
            "paperId": "6568423cfaca7e24c88ea208cb0e67129e43aa9b",
            "corpusId": 216562627,
            "url": "https://www.semanticscholar.org/paper/6568423cfaca7e24c88ea208cb0e67129e43aa9b",
            "title": "Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3023640063",
                "ArXiv": "2004.13649",
                "DBLP": "journals/corr/abs-2004-13649",
                "CorpusId": 216562627
            },
            "abstract": "We propose a simple data augmentation technique that can be applied to standard model-free reinforcement learning algorithms, enabling robust learning directly from pixels without the need for auxiliary losses or pre-training. The approach leverages input perturbations commonly used in computer vision tasks to regularize the value function. Existing model-free approaches, such as Soft Actor-Critic (SAC), are not able to train deep networks effectively from image pixels. However, the addition of our augmentation method dramatically improves SAC's performance, enabling it to reach state-of-the-art performance on the DeepMind control suite, surpassing model-based (Dreamer, PlaNet, and SLAC) methods and recently proposed contrastive learning (CURL). Our approach can be combined with any model-free reinforcement learning algorithm, requiring only minor modifications. An implementation can be found at this https URL.",
            "referenceCount": 71,
            "citationCount": 529,
            "influentialCitationCount": 122,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-04-28",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2004.13649"
            },
            "citationStyles": {
                "bibtex": "@Article{Kostrikov2020ImageAI,\n author = {Ilya Kostrikov and Denis Yarats and R. Fergus},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels},\n volume = {abs/2004.13649},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4b2536eb8e48f40a51d76f026bc72f57b0ff330f",
            "@type": "ScholarlyArticle",
            "paperId": "4b2536eb8e48f40a51d76f026bc72f57b0ff330f",
            "corpusId": 59158795,
            "url": "https://www.semanticscholar.org/paper/4b2536eb8e48f40a51d76f026bc72f57b0ff330f",
            "title": "A First Look at Deep Learning Apps on Smartphones",
            "venue": "The Web Conference",
            "publicationVenue": {
                "id": "urn:research:e07422f9-c065-40c3-a37b-75e98dce79fe",
                "name": "The Web Conference",
                "alternate_names": [
                    "Web Conf",
                    "WWW"
                ],
                "issn": null,
                "url": "http://www.iw3c2.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2903650079",
                "DBLP": "conf/www/XuLLLLL19",
                "ArXiv": "1812.05448",
                "DOI": "10.1145/3308558.3313591",
                "CorpusId": 59158795
            },
            "abstract": "To bridge the knowledge gap between research and practice, we present the first empirical study on 16,500 the most popular Android apps, demystifying how smartphone apps exploit deep learning in the wild. To this end, we build a new static tool that dissects apps and analyzes their deep learning functions. Our study answers threefold questions: what are the early adopter apps of deep learning, what do they use deep learning for, and how do their deep learning models look like. Our study has strong implications for app developers, smartphone vendors, and deep learning R&D. On one hand, our findings paint a promising picture of deep learning for smartphones, showing the prosperity of mobile deep learning frameworks as well as the prosperity of apps building their cores atop deep learning. On the other hand, our findings urge optimizations on deep learning models deployed on smartphones, protection of these models, and validation of research ideas on these models.",
            "referenceCount": 97,
            "citationCount": 135,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1812.05448",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-11-08",
            "journal": {
                "name": "The World Wide Web Conference",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Xu2018AFL,\n author = {Mengwei Xu and Jiawei Liu and Yuanqiang Liu and F. Lin and Yunxin Liu and Xuanzhe Liu},\n booktitle = {The Web Conference},\n journal = {The World Wide Web Conference},\n title = {A First Look at Deep Learning Apps on Smartphones},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1071cf2e59793862cb5cedb21ae99f1356aff26c",
            "@type": "ScholarlyArticle",
            "paperId": "1071cf2e59793862cb5cedb21ae99f1356aff26c",
            "corpusId": 47001577,
            "url": "https://www.semanticscholar.org/paper/1071cf2e59793862cb5cedb21ae99f1356aff26c",
            "title": "Deep learning in fluid dynamics",
            "venue": "Journal of Fluid Mechanics",
            "publicationVenue": {
                "id": "urn:research:fb1aca4e-2d42-48af-83dc-f5b1a3651a36",
                "name": "Journal of Fluid Mechanics",
                "alternate_names": [
                    "J Fluid Mech"
                ],
                "issn": "0022-1120",
                "url": "https://www.cambridge.org/core/journals/journal-of-fluid-mechanics"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2585298970",
                "DOI": "10.1017/jfm.2016.803",
                "CorpusId": 47001577
            },
            "abstract": "It was only a matter of time before deep neural networks (DNNs) \u2013 deep learning \u2013 made their mark in turbulence modelling, or more broadly, in the general area of high-dimensional, complex dynamical systems. In the last decade, DNNs have become a dominant data mining tool for big data applications. Although neural networks have been applied previously to complex fluid flows, the article featured here (Ling et al., J. Fluid Mech., vol. 807, 2016, pp. 155\u2013166) is the first to apply a true DNN architecture, specifically to Reynolds averaged Navier Stokes turbulence models. As one often expects with modern DNNs, performance gains are achieved over competing state-of-the-art methods, suggesting that DNNs may play a critically enabling role in the future of modelling complex flows.",
            "referenceCount": 14,
            "citationCount": 567,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/F2EDDAB89563DE5157FC4B8342AD9C70/S002211201600803Xa.pdf/div-class-title-deep-learning-in-fluid-dynamics-div.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-01-31",
            "journal": {
                "name": "Journal of Fluid Mechanics",
                "volume": "814"
            },
            "citationStyles": {
                "bibtex": "@Article{Kutz2017DeepLI,\n author = {J. Kutz},\n booktitle = {Journal of Fluid Mechanics},\n journal = {Journal of Fluid Mechanics},\n pages = {1 - 4},\n title = {Deep learning in fluid dynamics},\n volume = {814},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:40552a2dcac643ed57fa7e5448448ba24ba2e09f",
            "@type": "ScholarlyArticle",
            "paperId": "40552a2dcac643ed57fa7e5448448ba24ba2e09f",
            "corpusId": 6831636,
            "url": "https://www.semanticscholar.org/paper/40552a2dcac643ed57fa7e5448448ba24ba2e09f",
            "title": "Deep learning for computational chemistry",
            "venue": "Journal of Computational Chemistry",
            "publicationVenue": {
                "id": "urn:research:da025a2f-daa1-4351-92a7-3ebbe15ebd9b",
                "name": "Journal of Computational Chemistry",
                "alternate_names": [
                    "J Comput Chem"
                ],
                "issn": "0192-8651",
                "url": "http://eu.wiley.com/WileyCDA/WileyTitle/productCd-JCC.html"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2582187633",
                "ArXiv": "1701.04503",
                "DBLP": "journals/corr/abs-1701-04503",
                "DOI": "10.1002/jcc.24764",
                "CorpusId": 6831636,
                "PubMed": "28272810"
            },
            "abstract": "The rise and fall of artificial neural networks is well documented in the scientific literature of both computer science and computational chemistry. Yet almost two decades later, we are now seeing a resurgence of interest in deep learning, a machine learning algorithm based on multilayer neural networks. Within the last few years, we have seen the transformative impact of deep learning in many domains, particularly in speech recognition and computer vision, to the extent that the majority of expert practitioners in those field are now regularly eschewing prior established models in favor of deep learning models. In this review, we provide an introductory overview into the theory of deep neural networks and their unique properties that distinguish them from traditional machine learning algorithms used in cheminformatics. By providing an overview of the variety of emerging applications of deep neural networks, we highlight its ubiquity and broad applicability to a wide range of challenges in the field, including quantitative structure activity relationship, virtual screening, protein structure prediction, quantum chemistry, materials design, and property prediction. In reviewing the performance of deep neural networks, we observed a consistent outperformance against non\u2010neural networks state\u2010of\u2010the\u2010art models across disparate research topics, and deep neural network\u2010based models often exceeded the \u201cglass ceiling\u201d expectations of their respective tasks. Coupled with the maturity of GPU\u2010accelerated computing for training deep neural networks and the exponential growth of chemical data on which to train these networks on, we anticipate that deep learning algorithms will be a valuable tool for computational chemistry. \u00a9 2017 Wiley Periodicals, Inc.",
            "referenceCount": 185,
            "citationCount": 558,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/1701.04503",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Physics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-01-17",
            "journal": {
                "name": "Journal of Computational Chemistry",
                "volume": "38"
            },
            "citationStyles": {
                "bibtex": "@Article{Goh2017DeepLF,\n author = {Garrett B. Goh and Nathan Oken Hodas and Abhinav Vishnu},\n booktitle = {Journal of Computational Chemistry},\n journal = {Journal of Computational Chemistry},\n pages = {1291 - 1307},\n title = {Deep learning for computational chemistry},\n volume = {38},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1605d856f4502c2ddd234b8c61bbbe1fc22af3ef",
            "@type": "ScholarlyArticle",
            "paperId": "1605d856f4502c2ddd234b8c61bbbe1fc22af3ef",
            "corpusId": 4505261,
            "url": "https://www.semanticscholar.org/paper/1605d856f4502c2ddd234b8c61bbbe1fc22af3ef",
            "title": "A survey of deep learning-based network anomaly detection",
            "venue": "Cluster Computing",
            "publicationVenue": {
                "id": "urn:research:f1d0ef3d-4e90-41e9-b454-f589a933654f",
                "name": "Cluster Computing",
                "alternate_names": [
                    "Clust Comput"
                ],
                "issn": "1386-7857",
                "url": "https://www.springer.com/computer/communication+networks/journal/10586"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2756489700",
                "DBLP": "journals/cluster/KwonKKSKK19",
                "DOI": "10.1007/s10586-017-1117-8",
                "CorpusId": 4505261
            },
            "abstract": null,
            "referenceCount": 42,
            "citationCount": 523,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Cluster Computing",
                "volume": "22"
            },
            "citationStyles": {
                "bibtex": "@Article{Kwon2017ASO,\n author = {Donghwoon Kwon and Hyunjoo Kim and Jinoh Kim and S. Suh and Ikkyun Kim and Kuinam J. Kim},\n booktitle = {Cluster Computing},\n journal = {Cluster Computing},\n pages = {949-961},\n title = {A survey of deep learning-based network anomaly detection},\n volume = {22},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d8bf4cac5e5984457e5c8570cfa35f79ebfddd57",
            "@type": "ScholarlyArticle",
            "paperId": "d8bf4cac5e5984457e5c8570cfa35f79ebfddd57",
            "corpusId": 5547941,
            "url": "https://www.semanticscholar.org/paper/d8bf4cac5e5984457e5c8570cfa35f79ebfddd57",
            "title": "Lensless computational imaging through deep learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2593966629",
                "DBLP": "journals/corr/SinhaLLB17",
                "ArXiv": "1702.08516",
                "DOI": "10.1364/OPTICA.4.001117",
                "CorpusId": 5547941
            },
            "abstract": "Deep learning has been proven to yield reliably generalizable solutions to numerous classification and decision tasks. Here, we demonstrate for the first time to our knowledge that deep neural networks (DNNs) can be trained to solve end-to-end inverse problems in computational imaging. We experimentally built and tested a lensless imaging system where a DNN was trained to recover phase objects given their propagated intensity diffraction patterns.",
            "referenceCount": 52,
            "citationCount": 450,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-02-22",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1702.08516"
            },
            "citationStyles": {
                "bibtex": "@Article{Sinha2017LenslessCI,\n author = {Ayan Sinha and Justin Lee and Shuai Li and G. Barbastathis},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Lensless computational imaging through deep learning},\n volume = {abs/1702.08516},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:430de87a0a8996bc93b1998f9a6261f7558a5679",
            "@type": "ScholarlyArticle",
            "paperId": "430de87a0a8996bc93b1998f9a6261f7558a5679",
            "corpusId": 3520119,
            "url": "https://www.semanticscholar.org/paper/430de87a0a8996bc93b1998f9a6261f7558a5679",
            "title": "Generalization in Deep Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2766196653",
                "DBLP": "journals/corr/abs-1710-05468",
                "ArXiv": "1710.05468",
                "DOI": "10.1017/9781009025096.003",
                "CorpusId": 3520119
            },
            "abstract": "This paper provides non-vacuous and numerically-tight generalization guarantees for deep learning, as well as theoretical insights into why and how deep learning can generalize well, despite its large capacity, complexity, possible algorithmic instability, nonrobustness, and sharp minima, responding to an open question in the literature. We also propose new open problems and discuss the limitations of our results.",
            "referenceCount": 62,
            "citationCount": 393,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1710.05468",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1710.05468"
            },
            "citationStyles": {
                "bibtex": "@Article{Kawaguchi2017GeneralizationID,\n author = {Kenji Kawaguchi and L. Kaelbling and Yoshua Bengio},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Generalization in Deep Learning},\n volume = {abs/1710.05468},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a11fca45e2758ddb6c2a2f312a732f71e10eb9ca",
            "@type": "ScholarlyArticle",
            "paperId": "a11fca45e2758ddb6c2a2f312a732f71e10eb9ca",
            "corpusId": 1428880,
            "url": "https://www.semanticscholar.org/paper/a11fca45e2758ddb6c2a2f312a732f71e10eb9ca",
            "title": "Deep Learning for Image-Based Cassava Disease Detection",
            "venue": "Frontiers in Plant Science",
            "publicationVenue": {
                "id": "urn:research:e110cc75-cd00-4b7f-968c-fd70b464a553",
                "name": "Frontiers in Plant Science",
                "alternate_names": [
                    "Front Plant Sci"
                ],
                "issn": "1664-462X",
                "url": "http://www.frontiersin.org/about/journalseries"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "3100931193",
                "PubMedCentral": "5663696",
                "ArXiv": "1707.03717",
                "DBLP": "journals/corr/RamcharanBMALH17",
                "DOI": "10.3389/fpls.2017.01852",
                "CorpusId": 1428880,
                "PubMed": "29163582"
            },
            "abstract": "Cassava is the third largest source of carbohydrates for human food in the world but is vulnerable to virus diseases, which threaten to destabilize food security in sub-Saharan Africa. Novel methods of cassava disease detection are needed to support improved control which will prevent this crisis. Image recognition offers both a cost effective and scalable technology for disease detection. New deep learning models offer an avenue for this technology to be easily deployed on mobile devices. Using a dataset of cassava disease images taken in the field in Tanzania, we applied transfer learning to train a deep convolutional neural network to identify three diseases and two types of pest damage (or lack thereof). The best trained model accuracies were 98% for brown leaf spot (BLS), 96% for red mite damage (RMD), 95% for green mite damage (GMD), 98% for cassava brown streak disease (CBSD), and 96% for cassava mosaic disease (CMD). The best model achieved an overall accuracy of 93% for data not used in the training process. Our results show that the transfer learning approach for image recognition of field images offers a fast, affordable, and easily deployable strategy for digital plant disease detection.",
            "referenceCount": 28,
            "citationCount": 396,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.frontiersin.org/articles/10.3389/fpls.2017.01852/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-06-19",
            "journal": {
                "name": "Frontiers in Plant Science",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Ramcharan2017DeepLF,\n author = {Amanda Ramcharan and Kelsee Baranowski and Peter McClowsky and Babuali Ahmed and J. Legg and David P. Hughes},\n booktitle = {Frontiers in Plant Science},\n journal = {Frontiers in Plant Science},\n title = {Deep Learning for Image-Based Cassava Disease Detection},\n volume = {8},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:25b30093834462c40d96ba0d61c23922af39910f",
            "@type": "ScholarlyArticle",
            "paperId": "25b30093834462c40d96ba0d61c23922af39910f",
            "corpusId": 10652042,
            "url": "https://www.semanticscholar.org/paper/25b30093834462c40d96ba0d61c23922af39910f",
            "title": "Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/miccai/2017dlmia",
                "MAG": "2754328732",
                "ArXiv": "1707.06183",
                "DOI": "10.1007/978-3-319-67558-9",
                "CorpusId": 10652042
            },
            "abstract": null,
            "referenceCount": 36,
            "citationCount": 400,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-319-67558-9/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-19",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1707.06183"
            },
            "citationStyles": {
                "bibtex": "@Article{Cardoso2017DeepLI,\n author = {M. Jorge Cardoso and T. Arbel and G. Carneiro and T. Syeda-Mahmood and J. Tavares and M. Moradi and A. Bradley and H. Greenspan and J. Papa and A. Madabhushi and J. Nascimento and Jaime S. Cardoso and Vasileios Belagiannis and Zhi Lu and F. Engenharia},\n booktitle = {Lecture Notes in Computer Science},\n journal = {ArXiv},\n title = {Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support},\n volume = {abs/1707.06183},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8978cf7574ceb35f4c3096be768c7547b28a35d0",
            "@type": "ScholarlyArticle",
            "paperId": "8978cf7574ceb35f4c3096be768c7547b28a35d0",
            "corpusId": 2309950,
            "url": "https://www.semanticscholar.org/paper/8978cf7574ceb35f4c3096be768c7547b28a35d0",
            "title": "A Fast Learning Algorithm for Deep Belief Nets",
            "venue": "Neural Computation",
            "publicationVenue": {
                "id": "urn:research:69b9bcdd-8229-4a00-a6e0-00f0e99a2bf3",
                "name": "Neural Computation",
                "alternate_names": [
                    "Neural Comput"
                ],
                "issn": "0899-7667",
                "url": "http://cognet.mit.edu/library/journals/journal?issn=08997667"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "journals/neco/HintonOT06",
                "MAG": "2136922672",
                "DOI": "10.1162/neco.2006.18.7.1527",
                "CorpusId": 2309950,
                "PubMed": "16764513"
            },
            "abstract": "We show how to use complementary priors to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.",
            "referenceCount": 32,
            "citationCount": 15154,
            "influentialCitationCount": 1269,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-07-01",
            "journal": {
                "name": "Neural Computation",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Hinton2006AFL,\n author = {Geoffrey E. Hinton and Simon Osindero and Y. Teh},\n booktitle = {Neural Computation},\n journal = {Neural Computation},\n pages = {1527-1554},\n title = {A Fast Learning Algorithm for Deep Belief Nets},\n volume = {18},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cdae8e9cc9d605856cf5709b2fdf61f722d450c1",
            "@type": "ScholarlyArticle",
            "paperId": "cdae8e9cc9d605856cf5709b2fdf61f722d450c1",
            "corpusId": 46928941,
            "url": "https://www.semanticscholar.org/paper/cdae8e9cc9d605856cf5709b2fdf61f722d450c1",
            "title": "Deep Learning for Biometrics",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/csur/SundararajanW18",
                "MAG": "2803380720",
                "DOI": "10.1145/3190618",
                "CorpusId": 46928941
            },
            "abstract": "In the recent past, deep learning methods have demonstrated remarkable success for supervised learning tasks in multiple domains including computer vision, natural language processing, and speech processing. In this article, we investigate the impact of deep learning in the field of biometrics, given its success in other domains. Since biometrics deals with identifying people by using their characteristics, it primarily involves supervised learning and can leverage the success of deep learning in other related domains. In this article, we survey 100 different approaches that explore deep learning for recognizing individuals using various biometric modalities. We find that most deep learning research in biometrics has been focused on face and speaker recognition. Based on inferences from these approaches, we discuss how deep learning methods can benefit the field of biometrics and the potential gaps that deep learning approaches need to address for real-world biometric applications.",
            "referenceCount": 177,
            "citationCount": 152,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-05-23",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "51"
            },
            "citationStyles": {
                "bibtex": "@Article{Sundararajan2018DeepLF,\n author = {Kalaivani Sundararajan and D. Woodard},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 34},\n title = {Deep Learning for Biometrics},\n volume = {51},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0526e714f286dd4140a789a03b6d77c2267520e8",
            "@type": "ScholarlyArticle",
            "paperId": "0526e714f286dd4140a789a03b6d77c2267520e8",
            "corpusId": 12424035,
            "url": "https://www.semanticscholar.org/paper/0526e714f286dd4140a789a03b6d77c2267520e8",
            "title": "Towards Poisoning of Deep Learning Algorithms with Back-gradient Optimization",
            "venue": "AISec@CCS",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/abs-1708-08689",
                "MAG": "2951269678",
                "ArXiv": "1708.08689",
                "DOI": "10.1145/3128572.3140451",
                "CorpusId": 12424035
            },
            "abstract": "A number of online services nowadays rely upon machine learning to extract valuable information from data collected in the wild. This exposes learning algorithms to the threat of data poisoning, i.e., a coordinate attack in which a fraction of the training data is controlled by the attacker and manipulated to subvert the learning process. To date, these attacks have been devised only against a limited class of binary learning algorithms, due to the inherent complexity of the gradient-based procedure used to optimize the poisoning points (a.k.a. adversarial training examples). In this work, we first extend the definition of poisoning attacks to multiclass problems. We then propose a novel poisoning algorithm based on the idea of back-gradient optimization, i.e., to compute the gradient of interest through automatic differentiation, while also reversing the learning procedure to drastically reduce the attack complexity. Compared to current poisoning strategies, our approach is able to target a wider class of learning algorithms, trained with gradient-based procedures, including neural networks and deep learning architectures. We empirically evaluate its effectiveness on several application examples, including spam filtering, malware detection, and handwritten digit recognition. We finally show that, similarly to adversarial test examples, adversarial training examples can also be transferred across different learning algorithms.",
            "referenceCount": 40,
            "citationCount": 484,
            "influentialCitationCount": 44,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1708.08689",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book"
            ],
            "publicationDate": "2017-08-29",
            "journal": {
                "name": "Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mu\u00f1oz-Gonz\u00e1lez2017TowardsPO,\n author = {Luis Mu\u00f1oz-Gonz\u00e1lez and B. Biggio and Ambra Demontis and Andrea Paudice and Vasin Wongrassamee and Emil C. Lupu and F. Roli},\n booktitle = {AISec@CCS},\n journal = {Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},\n title = {Towards Poisoning of Deep Learning Algorithms with Back-gradient Optimization},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:07925910d45761d96269fc3bdfdc21b1d20d84ad",
            "@type": "ScholarlyArticle",
            "paperId": "07925910d45761d96269fc3bdfdc21b1d20d84ad",
            "corpusId": 1605269,
            "url": "https://www.semanticscholar.org/paper/07925910d45761d96269fc3bdfdc21b1d20d84ad",
            "title": "Deep Learning without Poor Local Minima",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/Kawaguchi16a",
                "MAG": "2963446085",
                "ArXiv": "1605.07110",
                "CorpusId": 1605269
            },
            "abstract": "In this paper, we prove a conjecture published in 1989 and also partially address an open problem announced at the Conference on Learning Theory (COLT) 2015. With no unrealistic assumption, we first prove the following statements for the squared loss function of deep linear neural networks with any depth and any widths: 1) the function is non-convex and non-concave, 2) every local minimum is a global minimum, 3) every critical point that is not a global minimum is a saddle point, and 4) there exist \"bad\" saddle points (where the Hessian has no negative eigenvalue) for the deeper networks (with more than three layers), whereas there is no bad saddle point for the shallow networks (with three layers). Moreover, for deep nonlinear neural networks, we prove the same four statements via a reduction to a deep linear model under the independence assumption adopted from recent work. As a result, we present an instance, for which we can answer the following question: how difficult is it to directly train a deep model in theory? It is more difficult than the classical machine learning models (because of the non-convexity), but not too difficult (because of the nonexistence of poor local minima). Furthermore, the mathematically proven existence of bad saddle points for deeper models would suggest a possible open problem. We note that even though we have advanced the theoretical foundations of deep learning and non-convex optimization, there is still a gap between theory and practice.",
            "referenceCount": 19,
            "citationCount": 845,
            "influentialCitationCount": 86,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-05-23",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1605.07110"
            },
            "citationStyles": {
                "bibtex": "@Article{Kawaguchi2016DeepLW,\n author = {Kenji Kawaguchi},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Deep Learning without Poor Local Minima},\n volume = {abs/1605.07110},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:088592bc2ecfe04f0feab1a446402cd6578a0fdb",
            "@type": "ScholarlyArticle",
            "paperId": "088592bc2ecfe04f0feab1a446402cd6578a0fdb",
            "corpusId": 24390528,
            "url": "https://www.semanticscholar.org/paper/088592bc2ecfe04f0feab1a446402cd6578a0fdb",
            "title": "Deep learning for wireless physical layer: Opportunities and challenges",
            "venue": "China Communications",
            "publicationVenue": {
                "id": "urn:research:f458edd1-14b3-4f2b-b448-3e80df57e1d8",
                "name": "China Communications",
                "alternate_names": [
                    "China Commun"
                ],
                "issn": "1673-5447",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=6245522"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2949925394",
                "ArXiv": "1710.05312",
                "DBLP": "journals/corr/abs-1710-05312",
                "DOI": "10.1109/CC.2017.8233654",
                "CorpusId": 24390528
            },
            "abstract": "Machine learning (ML) has been widely applied to the upper layers of wireless communication systems for various purposes, such as deployment of cognitive radio and communication network. However, its application to the physical layer is hampered by sophisticated channel environments and limited learning ability of conventional ML algorithms. Deep learning (DL) has been recently applied for many fields, such as computer vision and natural language processing, given its expressive capacity and convenient optimization capability. The potential application of DL to the physical layer has also been increasingly recognized because of the new features for future communications, such as complex scenarios with unknown channel models, high speed and accurate processing requirements; these features challenge conventional communication theories. This paper presents a comprehensive overview of the emerging studies on DL-based physical layer processing, including leveraging DL to redesign a module of the conventional communication system (for modulation recognition, channel decoding, and detection) and replace the communication system with a radically new architecture based on an autoencoder. These DL-based methods show promising performance improvements but have certain limitations, such as lack of solid analytical tools and use of architectures that are specifically designed for communication and implementation research, thereby motivating future research in this field.",
            "referenceCount": 50,
            "citationCount": 442,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1710.05312",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-10-15",
            "journal": {
                "name": "China Communications",
                "volume": "14"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2017DeepLF,\n author = {Tianqi Wang and Chao-Kai Wen and Hanqing Wang and F. Gao and Tao Jiang and Shi Jin},\n booktitle = {China Communications},\n journal = {China Communications},\n pages = {92-111},\n title = {Deep learning for wireless physical layer: Opportunities and challenges},\n volume = {14},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5f3a79e184d4e4ebaee7fb5cd9a0304dd26a43b6",
            "@type": "ScholarlyArticle",
            "paperId": "5f3a79e184d4e4ebaee7fb5cd9a0304dd26a43b6",
            "corpusId": 2200306,
            "url": "https://www.semanticscholar.org/paper/5f3a79e184d4e4ebaee7fb5cd9a0304dd26a43b6",
            "title": "Deep Learning for Time-Series Analysis",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1701.01887",
                "MAG": "2576201845",
                "DBLP": "journals/corr/Gamboa17",
                "CorpusId": 2200306
            },
            "abstract": "In many real-world application, e.g., speech recognition or sleep stage classification, data are captured over the course of time, constituting a Time-Series. Time-Series often contain temporal dependencies that cause two otherwise identical points of time to belong to different classes or predict different behavior. This characteristic generally increases the difficulty of analysing them. Existing techniques often depended on hand-crafted features that were expensive to create and required expert knowledge of the field. With the advent of Deep Learning new models of unsupervised learning of features for Time-series analysis and forecast have been developed. Such new developments are the topic of this paper: a review of the main Deep Learning techniques is presented, and some applications on Time-Series analysis are summaried. The results make it clear that Deep Learning has a lot to contribute to the field.",
            "referenceCount": 60,
            "citationCount": 373,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-01-07",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1701.01887"
            },
            "citationStyles": {
                "bibtex": "@Article{Gamboa2017DeepLF,\n author = {J. Gamboa},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Learning for Time-Series Analysis},\n volume = {abs/1701.01887},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f3b944046602765fc1efc94264d291e4052a1a84",
            "@type": "ScholarlyArticle",
            "paperId": "f3b944046602765fc1efc94264d291e4052a1a84",
            "corpusId": 6990534,
            "url": "https://www.semanticscholar.org/paper/f3b944046602765fc1efc94264d291e4052a1a84",
            "title": "On deep learning-based channel decoding",
            "venue": "Annual Conference on Information Sciences and Systems",
            "publicationVenue": {
                "id": "urn:research:af806702-8820-45ae-9a4e-2073e928bdef",
                "name": "Annual Conference on Information Sciences and Systems",
                "alternate_names": [
                    "CISS",
                    "Annu Conf Inf Sci Syst",
                    "Conference on Information Sciences and Systems",
                    "Conf Inf Sci Syst"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=476"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1701.07738",
                "MAG": "2584943905",
                "DBLP": "journals/corr/GruberCHB17",
                "DOI": "10.1109/CISS.2017.7926071",
                "CorpusId": 6990534
            },
            "abstract": "We revisit the idea of using deep neural networks for one-shot decoding of random and structured codes, such as polar codes. Although it is possible to achieve maximum a posteriori (MAP) bit error rate (BER) performance for both code families and for short codeword lengths, we observe that (i) structured codes are easier to learn and (ii) the neural network is able to generalize to codewords that it has never seen during training for structured, but not for random codes. These results provide some evidence that neural networks can learn a form of decoding algorithm, rather than only a simple classifier. We introduce the metric normalized validation error (NVE) in order to further investigate the potential and limitations of deep learning-based decoding with respect to performance and complexity.",
            "referenceCount": 24,
            "citationCount": 361,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1701.07738",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-01-26",
            "journal": {
                "name": "2017 51st Annual Conference on Information Sciences and Systems (CISS)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gruber2017OnDL,\n author = {Tobias Gruber and Sebastian Cammerer and J. Hoydis and S. Brink},\n booktitle = {Annual Conference on Information Sciences and Systems},\n journal = {2017 51st Annual Conference on Information Sciences and Systems (CISS)},\n pages = {1-6},\n title = {On deep learning-based channel decoding},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:67ebfc6a6013fcc4b64035994ad80ddfbdd6bc5e",
            "@type": "ScholarlyArticle",
            "paperId": "67ebfc6a6013fcc4b64035994ad80ddfbdd6bc5e",
            "corpusId": 9447921,
            "url": "https://www.semanticscholar.org/paper/67ebfc6a6013fcc4b64035994ad80ddfbdd6bc5e",
            "title": "Deep learning for undersampled MRI reconstruction",
            "venue": "Physics in Medicine and Biology",
            "publicationVenue": {
                "id": "urn:research:d5594aad-095f-4587-802a-b011732c7100",
                "name": "Physics in Medicine and Biology",
                "alternate_names": [
                    "Phys Med Biology"
                ],
                "issn": "0031-9155",
                "url": "http://www.iop.org/EJ/journal/0031-9155"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/abs-1709-02576",
                "MAG": "2753305843",
                "ArXiv": "1709.02576",
                "DOI": "10.1088/1361-6560/aac71a",
                "CorpusId": 9447921,
                "PubMed": "29787383"
            },
            "abstract": "This paper presents a deep learning method for faster magnetic resonance imaging (MRI) by reducing k-space data with sub-Nyquist sampling strategies and provides a rationale for why the proposed approach works well. Uniform subsampling is used in the time-consuming phase-encoding direction to capture high-resolution image information, while permitting the image-folding problem dictated by the Poisson summation formula. To deal with the localization uncertainty due to image folding, a small number of low-frequency k-space data are added. Training the deep learning net involves input and output images that are pairs of the Fourier transforms of the subsampled and fully sampled k-space data. Our experiments show the remarkable performance of the proposed method; only 29 of the k-space data can generate images of high quality as effectively as standard MRI reconstruction with the fully sampled data.",
            "referenceCount": 28,
            "citationCount": 362,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-09-08",
            "journal": {
                "name": "Physics in Medicine & Biology",
                "volume": "63"
            },
            "citationStyles": {
                "bibtex": "@Article{Hyun2017DeepLF,\n author = {Chang Min Hyun and Hwa Pyung Kim and S. Lee and S. Lee and J.K. Seo},\n booktitle = {Physics in Medicine and Biology},\n journal = {Physics in Medicine & Biology},\n title = {Deep learning for undersampled MRI reconstruction},\n volume = {63},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:39f1cbef12f64dcdb3a7683f9e70f436a7742328",
            "@type": "ScholarlyArticle",
            "paperId": "39f1cbef12f64dcdb3a7683f9e70f436a7742328",
            "corpusId": 9823884,
            "url": "https://www.semanticscholar.org/paper/39f1cbef12f64dcdb3a7683f9e70f436a7742328",
            "title": "Applications of Deep Learning and Reinforcement Learning to Biological Data",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2768956845",
                "DBLP": "journals/tnn/MahmudKHV18",
                "ArXiv": "1711.03985",
                "DOI": "10.1109/TNNLS.2018.2790388",
                "CorpusId": 9823884,
                "PubMed": "29771663"
            },
            "abstract": "Rapid advances in hardware-based technologies during the past decades have opened up new possibilities for life scientists to gather multimodal data in various application domains, such as omics, bioimaging, medical imaging, and (brain/body)\u2013machine interfaces. These have generated novel opportunities for development of dedicated data-intensive machine learning techniques. In particular, recent research in deep learning (DL), reinforcement learning (RL), and their combination (deep RL) promise to revolutionize the future of artificial intelligence. The growth in computational power accompanied by faster and increased data storage, and declining computing costs have already allowed scientists in various fields to apply these techniques on data sets that were previously intractable owing to their size and complexity. This paper provides a comprehensive survey on the application of DL, RL, and deep RL techniques in mining biological data. In addition, we compare the performances of DL techniques when applied to different data sets across various application domains. Finally, we outline open issues in this challenging research area and discuss future development perspectives.",
            "referenceCount": 213,
            "citationCount": 565,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dspace.stir.ac.uk/bitstream/1893/26814/1/1711.03985.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-11-10",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "29"
            },
            "citationStyles": {
                "bibtex": "@Article{Mahmud2017ApplicationsOD,\n author = {M. Mahmud and M. S. Kaiser and A. Hussain and S. Vassanelli},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {2063-2079},\n title = {Applications of Deep Learning and Reinforcement Learning to Biological Data},\n volume = {29},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:260b98e772c4785fa06a5e8fe1c205eb05ec01e2",
            "@type": "ScholarlyArticle",
            "paperId": "260b98e772c4785fa06a5e8fe1c205eb05ec01e2",
            "corpusId": 5240721,
            "url": "https://www.semanticscholar.org/paper/260b98e772c4785fa06a5e8fe1c205eb05ec01e2",
            "title": "Deep learning for detecting robotic grasps",
            "venue": "Int. J. Robotics Res.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "MAG": "1999156278",
                "DBLP": "conf/rss/LenzLS13",
                "ArXiv": "1301.3592",
                "DOI": "10.1177/0278364914549607",
                "CorpusId": 5240721
            },
            "abstract": "We consider the problem of detecting robotic grasps in an RGB-D view of a scene containing objects. In this work, we apply a deep learning approach to solve this problem, which avoids time-consuming hand-design of features. This presents two main challenges. First, we need to evaluate a huge number of candidate grasps. In order to make detection fast and robust, we present a two-step cascaded system with two deep networks, where the top detections from the first are re-evaluated by the second. The first network has fewer features, is faster to run, and can effectively prune out unlikely candidate grasps. The second, with more features, is slower but has to run only on the top few detections. Second, we need to handle multimodal inputs effectively, for which we present a method that applies structured regularization on the weights based on multimodal group regularization. We show that our method improves performance on an RGBD robotic grasping dataset, and can be used to successfully execute grasps on two different robotic platforms.",
            "referenceCount": 88,
            "citationCount": 1423,
            "influentialCitationCount": 154,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1301.3592",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-01-15",
            "journal": {
                "name": "The International Journal of Robotics Research",
                "volume": "34"
            },
            "citationStyles": {
                "bibtex": "@Article{Lenz2013DeepLF,\n author = {Ian Lenz and Honglak Lee and Ashutosh Saxena},\n booktitle = {Int. J. Robotics Res.},\n journal = {The International Journal of Robotics Research},\n pages = {705 - 724},\n title = {Deep learning for detecting robotic grasps},\n volume = {34},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2eea41136efeea6e1426c631fa1ac0a221fe6978",
            "@type": "ScholarlyArticle",
            "paperId": "2eea41136efeea6e1426c631fa1ac0a221fe6978",
            "corpusId": 15987982,
            "url": "https://www.semanticscholar.org/paper/2eea41136efeea6e1426c631fa1ac0a221fe6978",
            "title": "Deep learning approach for Network Intrusion Detection in Software Defined Networking",
            "venue": "International Conference on Wireless Networks and Mobile Communications",
            "publicationVenue": {
                "id": "urn:research:bba62a83-8840-4aed-8d34-3443b9843c56",
                "name": "International Conference on Wireless Networks and Mobile Communications",
                "alternate_names": [
                    "WINCOM",
                    "Int Conf Wirel Netw Mob Commun"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2560162835",
                "DBLP": "conf/wincom/TangMMZG16",
                "DOI": "10.1109/WINCOM.2016.7777224",
                "CorpusId": 15987982
            },
            "abstract": "Software Defined Networking (SDN) has recently emerged to become one of the promising solutions for the future Internet. With the logical centralization of controllers and a global network overview, SDN brings us a chance to strengthen our network security. However, SDN also brings us a dangerous increase in potential threats. In this paper, we apply a deep learning approach for flow-based anomaly detection in an SDN environment. We build a Deep Neural Network (DNN) model for an intrusion detection system and train the model with the NSL-KDD Dataset. In this work, we just use six basic features (that can be easily obtained in an SDN environment) taken from the forty-one features of NSL-KDD Dataset. Through experiments, we confirm that the deep learning approach shows strong potential to be used for flow-based anomaly detection in SDN environments.",
            "referenceCount": 17,
            "citationCount": 550,
            "influentialCitationCount": 42,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://eprints.whiterose.ac.uk/106836/8/Tuan%20Tang_WINCOM16.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2016-10-01",
            "journal": {
                "name": "2016 International Conference on Wireless Networks and Mobile Communications (WINCOM)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tang2016DeepLA,\n author = {Tuan A. Tang and L. Mhamdi and D. McLernon and Syed Ali Raza Zaidi and M. Ghogho},\n booktitle = {International Conference on Wireless Networks and Mobile Communications},\n journal = {2016 International Conference on Wireless Networks and Mobile Communications (WINCOM)},\n pages = {258-263},\n title = {Deep learning approach for Network Intrusion Detection in Software Defined Networking},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:775dd65fd70c13bc4144c28b25aa3376bbab3254",
            "@type": "ScholarlyArticle",
            "paperId": "775dd65fd70c13bc4144c28b25aa3376bbab3254",
            "corpusId": 14867364,
            "url": "https://www.semanticscholar.org/paper/775dd65fd70c13bc4144c28b25aa3376bbab3254",
            "title": "Deep learning code fragments for code clone detection",
            "venue": "International Conference on Automated Software Engineering",
            "publicationVenue": {
                "id": "urn:research:1c2ab05c-7d69-465e-929d-0920857aedce",
                "name": "International Conference on Automated Software Engineering",
                "alternate_names": [
                    "Autom Softw Eng",
                    "ASE",
                    "Automated Software Engineering",
                    "Int Conf Autom Softw Eng"
                ],
                "issn": null,
                "url": "http://ase.informatik.uni-essen.de/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/kbse/WhiteTVP16",
                "MAG": "2511803001",
                "DOI": "10.1145/2970276.2970326",
                "CorpusId": 14867364
            },
            "abstract": "Code clone detection is an important problem for software maintenance and evolution. Many approaches consider either structure or identifiers, but none of the existing detection techniques model both sources of information. These techniques also depend on generic, handcrafted features to represent code fragments. We introduce learning-based detection techniques where everything for representing terms and fragments in source code is mined from the repository. Our code analysis supports a framework, which relies on deep learning, for automatically linking patterns mined at the lexical level with patterns mined at the syntactic level. We evaluated our novel learning-based approach for code clone detection with respect to feasibility from the point of view of software maintainers. We sampled and manually evaluated 398 file- and 480 method-level pairs across eight real-world Java systems; 93% of the file- and method-level samples were evaluated to be true positives. Among the true positives, we found pairs mapping to all four clone types. We compared our approach to a traditional structure-oriented technique and found that our learning-based approach detected clones that were either undetected or suboptimally reported by the prominent tool Deckard. Our results affirm that our learning-based approach is suitable for clone detection and a tenable technique for researchers.",
            "referenceCount": 118,
            "citationCount": 514,
            "influentialCitationCount": 43,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-08-25",
            "journal": {
                "name": "2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{White2016DeepLC,\n author = {Martin White and Michele Tufano and Christopher Vendome and D. Poshyvanyk},\n booktitle = {International Conference on Automated Software Engineering},\n journal = {2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)},\n pages = {87-98},\n title = {Deep learning code fragments for code clone detection},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:441fbfdcc77187c9f9c41166b5fd42de04de1427",
            "@type": "ScholarlyArticle",
            "paperId": "441fbfdcc77187c9f9c41166b5fd42de04de1427",
            "corpusId": 37280525,
            "url": "https://www.semanticscholar.org/paper/441fbfdcc77187c9f9c41166b5fd42de04de1427",
            "title": "Deep learning in remote sensing: a review",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2951514713",
                "DBLP": "journals/corr/abs-1710-03959",
                "ArXiv": "1710.03959",
                "DOI": "10.1109/MGRS.2017.2762307",
                "CorpusId": 37280525
            },
            "abstract": "Standing at the paradigm shift towards data-intensive science, machine learning techniques are becoming increasingly important. In particular, as a major breakthrough in the field, deep learning has proven as an extremely powerful tool in many fields. Shall we embrace deep learning as the key to all? Or, should we resist a 'black-box' solution? There are controversial opinions in the remote sensing community. In this article, we analyze the challenges of using deep learning for remote sensing data analysis, review the recent advances, and provide resources to make deep learning in remote sensing ridiculously simple to start with. More importantly, we advocate remote sensing scientists to bring their expertise into deep learning, and use it as an implicit general model to tackle unprecedented large-scale influential challenges, such as climate change and urbanization.",
            "referenceCount": 190,
            "citationCount": 376,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://cdr.lib.unc.edu/downloads/6969z593j",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-10-11",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1710.03959"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhu2017DeepLI,\n author = {Xiaoxiang Zhu and D. Tuia and Lichao Mou and Gui-Song Xia and Liangpei Zhang and Feng Xu and F. Fraundorfer},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep learning in remote sensing: a review},\n volume = {abs/1710.03959},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:44e1ee7a63a01a76371d7070c132361a5ddd54a0",
            "@type": "ScholarlyArticle",
            "paperId": "44e1ee7a63a01a76371d7070c132361a5ddd54a0",
            "corpusId": 563473,
            "url": "https://www.semanticscholar.org/paper/44e1ee7a63a01a76371d7070c132361a5ddd54a0",
            "title": "Structural-RNN: Deep Learning on Spatio-Temporal Graphs",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2949318071",
                "DBLP": "journals/corr/JainZSS15",
                "ArXiv": "1511.05298",
                "DOI": "10.1109/CVPR.2016.573",
                "CorpusId": 563473
            },
            "abstract": "Deep Recurrent Neural Network architectures, though remarkably capable at modeling sequences, lack an intuitive high-level spatio-temporal structure. That is while many problems in computer vision inherently have an underlying high-level structure and can benefit from it. Spatiotemporal graphs are a popular tool for imposing such high-level intuitions in the formulation of real world problems. In this paper, we propose an approach for combining the power of high-level spatio-temporal graphs and sequence learning success of Recurrent Neural Networks (RNNs). We develop a scalable method for casting an arbitrary spatio-temporal graph as a rich RNN mixture that is feedforward, fully differentiable, and jointly trainable. The proposed method is generic and principled as it can be used for transforming any spatio-temporal graph through employing a certain set of well defined steps. The evaluations of the proposed approach on a diverse set of problems, ranging from modeling human motion to object interactions, shows improvement over the state-of-the-art with a large margin. We expect this method to empower new approaches to problem formulation through high-level spatio-temporal graphs and Recurrent Neural Networks.",
            "referenceCount": 68,
            "citationCount": 944,
            "influentialCitationCount": 148,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1511.05298",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-11-17",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Jain2015StructuralRNNDL,\n author = {Ashesh Jain and A. Zamir and S. Savarese and Ashutosh Saxena},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {5308-5317},\n title = {Structural-RNN: Deep Learning on Spatio-Temporal Graphs},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:25deaf0adeb9ea455a2f2d211ee86890eb64b69b",
            "@type": "ScholarlyArticle",
            "paperId": "25deaf0adeb9ea455a2f2d211ee86890eb64b69b",
            "corpusId": 31835902,
            "url": "https://www.semanticscholar.org/paper/25deaf0adeb9ea455a2f2d211ee86890eb64b69b",
            "title": "A Deep Learning Approach for Network Intrusion Detection System",
            "venue": "EAI Endorsed Trans. Security Safety",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/sesa/JavaidNSA16",
                "MAG": "2584770732",
                "DOI": "10.4108/eai.3-12-2015.2262516",
                "CorpusId": 31835902
            },
            "abstract": "A Network Intrusion Detection System (NIDS) helps system administrators to detect network security breaches in \n \ntheir organizations. However, many challenges arise while \n \ndeveloping a flexible and efficient NIDS for unforeseen and unpredictable attacks. We propose a deep learning based approach for developing such an efficient and flexible NIDS. \n \nWe use Self-taught Learning (STL), a deep learning based technique, on NSL-KDD - a benchmark dataset for network \n \nintrusion. We present the performance of our approach and compare it with a few previous work. Compared metrics include accuracy, precision, recall, and f-measure values.",
            "referenceCount": 19,
            "citationCount": 847,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://eudl.eu/pdf/10.4108/eai.3-12-2015.2262516",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-05-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Javaid2016ADL,\n author = {A. Javaid and Quamar Niyaz and Weiqing Sun and Mansoor Alam},\n booktitle = {EAI Endorsed Trans. Security Safety},\n pages = {21-26},\n title = {A Deep Learning Approach for Network Intrusion Detection System},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d594839932b3ec17b2f0e30f00d1095937eabf74",
            "@type": "ScholarlyArticle",
            "paperId": "d594839932b3ec17b2f0e30f00d1095937eabf74",
            "corpusId": 15599732,
            "url": "https://www.semanticscholar.org/paper/d594839932b3ec17b2f0e30f00d1095937eabf74",
            "title": "DeepX: A Software Accelerator for Low-Power Deep Learning Inference on Mobile Devices",
            "venue": "International Symposium on Information Processing in Sensor Networks",
            "publicationVenue": {
                "id": "urn:research:b300807f-6476-4e69-a350-d76f379e27eb",
                "name": "International Symposium on Information Processing in Sensor Networks",
                "alternate_names": [
                    "Information Processing in Sensor Networks",
                    "IPSN",
                    "Inf Process Sens Netw",
                    "Int Symp Inf Process Sens Netw"
                ],
                "issn": null,
                "url": "http://ipsn.acm.org/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2297325673",
                "DBLP": "conf/ipsn/LaneBGFJQK16",
                "DOI": "10.1109/IPSN.2016.7460664",
                "CorpusId": 15599732
            },
            "abstract": "Breakthroughs from the field of deep learning are radically changing how sensor data are interpreted to extract the high-level information needed by mobile apps. It is critical that the gains in inference accuracy that deep models afford become embedded in future generations of mobile apps. In this work, we present the design and implementation of DeepX, a software accelerator for deep learning execution. DeepX signif- icantly lowers the device resources (viz. memory, computation, energy) required by deep learning that currently act as a severe bottleneck to mobile adoption. The foundation of DeepX is a pair of resource control algorithms, designed for the inference stage of deep learning, that: (1) decompose monolithic deep model network architectures into unit- blocks of various types, that are then more efficiently executed by heterogeneous local device processors (e.g., GPUs, CPUs); and (2), perform principled resource scaling that adjusts the architecture of deep models to shape the overhead each unit-blocks introduces. Experiments show, DeepX can allow even large-scale deep learning models to execute efficently on modern mobile processors and significantly outperform existing solutions, such as cloud-based offloading.",
            "referenceCount": 47,
            "citationCount": 462,
            "influentialCitationCount": 42,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://discovery.ucl.ac.uk/1503670/1/deepx_ipsn.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-04-11",
            "journal": {
                "name": "2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lane2016DeepXAS,\n author = {N. Lane and S. Bhattacharya and Petko Georgiev and Claudio Forlivesi and Lei Jiao and Lorena Qendro and F. Kawsar},\n booktitle = {International Symposium on Information Processing in Sensor Networks},\n journal = {2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)},\n pages = {1-12},\n title = {DeepX: A Software Accelerator for Low-Power Deep Learning Inference on Mobile Devices},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:36e1e30f0cb8749cf7a50a46078ea2f7fa7867c8",
            "@type": "ScholarlyArticle",
            "paperId": "36e1e30f0cb8749cf7a50a46078ea2f7fa7867c8",
            "corpusId": 4570680,
            "url": "https://www.semanticscholar.org/paper/36e1e30f0cb8749cf7a50a46078ea2f7fa7867c8",
            "title": "Deep Learning in Radiology.",
            "venue": "Academic Radiology",
            "publicationVenue": {
                "id": "urn:research:122c0867-01c1-4ac7-b8a5-998cc5a278e2",
                "name": "Academic Radiology",
                "alternate_names": [
                    "Acad Radiol"
                ],
                "issn": "1076-6332",
                "url": "http://www.academicradiology.com/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2794518994",
                "DOI": "10.1016/j.acra.2018.02.018",
                "CorpusId": 4570680,
                "PubMed": "29606338"
            },
            "abstract": null,
            "referenceCount": 52,
            "citationCount": 288,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.academicradiology.org/article/S1076633218301041/pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-03-30",
            "journal": {
                "name": "Academic radiology",
                "volume": "25 11"
            },
            "citationStyles": {
                "bibtex": "@Article{McBee2018DeepLI,\n author = {Morgan P. McBee and O. Awan and Andrew T Colucci and Comeron W. Ghobadi and N. Kadom and A. Kansagra and S. Tridandapani and W. Auffermann},\n booktitle = {Academic Radiology},\n journal = {Academic radiology},\n pages = {\n          1472-1480\n        },\n title = {Deep Learning in Radiology.},\n volume = {25 11},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cd126c7db89f1a66b17a6ef1152412876f4c0cbe",
            "@type": "ScholarlyArticle",
            "paperId": "cd126c7db89f1a66b17a6ef1152412876f4c0cbe",
            "corpusId": 14102203,
            "url": "https://www.semanticscholar.org/paper/cd126c7db89f1a66b17a6ef1152412876f4c0cbe",
            "title": "Saliency detection by multi-context deep learning",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1942214758",
                "DBLP": "conf/cvpr/ZhaoOLW15",
                "DOI": "10.1109/CVPR.2015.7298731",
                "CorpusId": 14102203
            },
            "abstract": "Low-level saliency cues or priors do not produce good enough saliency detection results especially when the salient object presents in a low-contrast background with confusing visual appearance. This issue raises a serious problem for conventional approaches. In this paper, we tackle this problem by proposing a multi-context deep learning framework for salient object detection. We employ deep Convolutional Neural Networks to model saliency of objects in images. Global context and local context are both taken into account, and are jointly modeled in a unified multi-context deep learning framework. To provide a better initialization for training the deep neural networks, we investigate different pre-training strategies, and a task-specific pre-training scheme is designed to make the multi-context modeling suited for saliency detection. Furthermore, recently proposed contemporary deep models in the ImageNet Image Classification Challenge are tested, and their effectiveness in saliency detection are investigated. Our approach is extensively evaluated on five public datasets, and experimental results show significant and consistent improvements over the state-of-the-art methods.",
            "referenceCount": 64,
            "citationCount": 857,
            "influentialCitationCount": 104,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.ee.cuhk.edu.hk/%7Exgwang/papers/zhaoOHWcvpr15.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-06-07",
            "journal": {
                "name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhao2015SaliencyDB,\n author = {Rui Zhao and Wanli Ouyang and Hongsheng Li and Xiaogang Wang},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1265-1274},\n title = {Saliency detection by multi-context deep learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cf9118297d21ac23b5c12eb1991b90ebc1648d2a",
            "@type": "ScholarlyArticle",
            "paperId": "cf9118297d21ac23b5c12eb1991b90ebc1648d2a",
            "corpusId": 150889993,
            "url": "https://www.semanticscholar.org/paper/cf9118297d21ac23b5c12eb1991b90ebc1648d2a",
            "title": "The Deep Learning Revolution",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2930789748",
                "DOI": "10.7551/mitpress/11474.001.0001",
                "CorpusId": 150889993
            },
            "abstract": "To a greater or lesser extent, we business, finance and real estate researchers are all empiricists, making a presumption that knowledge is based on experience and that data is essential to prove any hypothesis we might form about the way the world works. Of course, we know that this is flawed. Journals are full of papers that claim generalisations, formed from samples of data or experiences that are very specific to locations or time periods. We will use the present tense and claim that A causes B with 87% explanatory power, when we should say that A appears to have caused B over the past 15 years in the USA. Most of us will feel much better about making such generalisations if the finding supports, or is supported by, a normative theory to the effect that A should cause B. Usually, empirical tests are used to prove or disprove a prior (hence a priori) theory. Theory precedes empirical tests.",
            "referenceCount": 0,
            "citationCount": 222,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Sociology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-10-23",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Sejnowski2018TheDL,\n author = {T. Sejnowski},\n title = {The Deep Learning Revolution},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5cdfbb95a0ff42171b03493f5c59772b47ef3385",
            "@type": "ScholarlyArticle",
            "paperId": "5cdfbb95a0ff42171b03493f5c59772b47ef3385",
            "corpusId": 5156963,
            "url": "https://www.semanticscholar.org/paper/5cdfbb95a0ff42171b03493f5c59772b47ef3385",
            "title": "Automated Identification of Diabetic Retinopathy Using Deep Learning.",
            "venue": "Ophthalmology (Rochester, Minn.)",
            "publicationVenue": {
                "id": "urn:research:b79026fc-02f6-45a6-868c-48196bfd74b3",
                "name": "Ophthalmology (Rochester, Minn.)",
                "alternate_names": [
                    "Ophthalmology",
                    "Ophthalmol (rochester Minn"
                ],
                "issn": "0161-6420",
                "url": "http://www.sciencedirect.com/science/journal/01616420"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2598442119",
                "DOI": "10.1016/j.ophtha.2017.02.008",
                "CorpusId": 5156963,
                "PubMed": "28359545"
            },
            "abstract": null,
            "referenceCount": 34,
            "citationCount": 889,
            "influentialCitationCount": 31,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-07-01",
            "journal": {
                "name": "Ophthalmology",
                "volume": "124 7"
            },
            "citationStyles": {
                "bibtex": "@Article{Gargeya2017AutomatedIO,\n author = {Rishab Gargeya and T. Leng},\n booktitle = {Ophthalmology (Rochester, Minn.)},\n journal = {Ophthalmology},\n pages = {\n          962-969\n        },\n title = {Automated Identification of Diabetic Retinopathy Using Deep Learning.},\n volume = {124 7},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d295a620fc10a7a656dc693e1b1bf668d1508a8e",
            "@type": "ScholarlyArticle",
            "paperId": "d295a620fc10a7a656dc693e1b1bf668d1508a8e",
            "corpusId": 4730292,
            "url": "https://www.semanticscholar.org/paper/d295a620fc10a7a656dc693e1b1bf668d1508a8e",
            "title": "Robust Physical-World Attacks on Deep Learning Models",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2759471388",
                "ArXiv": "1707.08945",
                "CorpusId": 4730292
            },
            "abstract": "Recent studies show that the state-of-the-art deep neural networks (DNNs) are vulnerable to adversarial examples, resulting from small-magnitude perturbations added to the input. Given that that emerging physical systems are using DNNs in safety-critical situations, adversarial examples could mislead these systems and cause dangerous situations.Therefore, understanding adversarial examples in the physical world is an important step towards developing resilient learning algorithms. We propose a general attack algorithm,Robust Physical Perturbations (RP2), to generate robust visual adversarial perturbations under different physical conditions. Using the real-world case of road sign classification, we show that adversarial examples generated using RP2 achieve high targeted misclassification rates against standard-architecture road sign classifiers in the physical world under various environmental conditions, including viewpoints. Due to the current lack of a standardized testing method, we propose a two-stage evaluation methodology for robust physical adversarial examples consisting of lab and field tests. Using this methodology, we evaluate the efficacy of physical adversarial manipulations on real objects. Witha perturbation in the form of only black and white stickers,we attack a real stop sign, causing targeted misclassification in 100% of the images obtained in lab settings, and in 84.8%of the captured video frames obtained on a moving vehicle(field test) for the target classifier.",
            "referenceCount": 55,
            "citationCount": 540,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-07-27",
            "journal": {
                "name": "arXiv: Cryptography and Security",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Evtimov2017RobustPA,\n author = {I. Evtimov and Kevin Eykholt and Earlence Fernandes and Tadayoshi Kohno and Bo Li and Atul Prakash and Amir Rahmati and D. Song},\n journal = {arXiv: Cryptography and Security},\n title = {Robust Physical-World Attacks on Deep Learning Models},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cea2cf0a4305fd7dde80ba589349a8484374fc53",
            "@type": "ScholarlyArticle",
            "paperId": "cea2cf0a4305fd7dde80ba589349a8484374fc53",
            "corpusId": 38080909,
            "url": "https://www.semanticscholar.org/paper/cea2cf0a4305fd7dde80ba589349a8484374fc53",
            "title": "Deep Learning for Tomato Diseases: Classification and Symptoms Visualization",
            "venue": "Applied Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:c1ed9251-6b49-4b2d-90c8-7a997accddab",
                "name": "Applied Artificial Intelligence",
                "alternate_names": [
                    "Appl Artif Intell"
                ],
                "issn": "0883-9514",
                "url": "http://www.catchword.com/rpsv/catchword/tandf/08839514/contp1-1.htm"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/aai/BrahimiBM17",
                "MAG": "2614850301",
                "DOI": "10.1080/08839514.2017.1315516",
                "CorpusId": 38080909
            },
            "abstract": "ABSTRACT Several studies have invested in machine learning classifiers to protect plants from diseases by processing leaf images. Most of the proposed classifiers are trained and evaluated with small datasets, focusing on the extraction of hand-crafted features from image to classify the leaves. In this study, we have used a large dataset compared to the state-of-the art. Here, the dataset contains 14,828 images of tomato leaves infected with nine diseases. To train our classifier, we have introduced the Convolutional Neural Network (CNN) as a learning algorithm. One of the biggest advantages of CNN is the automatic extraction of features by processing directly the raw images. To analyze the proposed deep model, we have used visualization methods to understand symptoms and to localize disease regions in leaf. The obtained results are encouraging, reaching 99.18% of accuracy, which ourperforms dramatically shallow models, and they can be used as a practical tool for farmers to protect tomato against disease.",
            "referenceCount": 26,
            "citationCount": 477,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-04-21",
            "journal": {
                "name": "Applied Artificial Intelligence",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Brahimi2017DeepLF,\n author = {Mohammed Brahimi and K. Boukhalfa and A. Moussaoui},\n booktitle = {Applied Artificial Intelligence},\n journal = {Applied Artificial Intelligence},\n pages = {299 - 315},\n title = {Deep Learning for Tomato Diseases: Classification and Symptoms Visualization},\n volume = {31},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e2b7f37cd97a7907b1b8a41138721ed06a0b76cd",
            "@type": "ScholarlyArticle",
            "paperId": "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd",
            "corpusId": 17804904,
            "url": "https://www.semanticscholar.org/paper/e2b7f37cd97a7907b1b8a41138721ed06a0b76cd",
            "title": "Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2997574889",
                "DBLP": "journals/jmlr/VincentLLBM10",
                "DOI": "10.5555/1756006.1953039",
                "CorpusId": 17804904
            },
            "abstract": "We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations.",
            "referenceCount": 59,
            "citationCount": 6628,
            "influentialCitationCount": 632,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-03-01",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Vincent2010StackedDA,\n author = {Pascal Vincent and H. Larochelle and Isabelle Lajoie and Yoshua Bengio and Pierre-Antoine Manzagol},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {3371-3408},\n title = {Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion},\n volume = {11},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:17ebe1eb19655543a6b876f91d41917488e70f55",
            "@type": "ScholarlyArticle",
            "paperId": "17ebe1eb19655543a6b876f91d41917488e70f55",
            "corpusId": 10050777,
            "url": "https://www.semanticscholar.org/paper/17ebe1eb19655543a6b876f91d41917488e70f55",
            "title": "Random synaptic feedback weights support error backpropagation for deep learning",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2552737632",
                "PubMedCentral": "5105169",
                "DOI": "10.1038/ncomms13276",
                "CorpusId": 10050777,
                "PubMed": "27824044"
            },
            "abstract": null,
            "referenceCount": 88,
            "citationCount": 661,
            "influentialCitationCount": 78,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-08",
            "journal": {
                "name": "Nature Communications",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Lillicrap2016RandomSF,\n author = {T. Lillicrap and D. Cownden and D. Tweed and C. Akerman},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {Random synaptic feedback weights support error backpropagation for deep learning},\n volume = {7},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b0c065cd43aa7280e766b5dcbcc7e26abce59330",
            "@type": "ScholarlyArticle",
            "paperId": "b0c065cd43aa7280e766b5dcbcc7e26abce59330",
            "corpusId": 60814714,
            "url": "https://www.semanticscholar.org/paper/b0c065cd43aa7280e766b5dcbcc7e26abce59330",
            "title": "SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2963881378",
                "DBLP": "journals/pami/BadrinarayananK17",
                "ArXiv": "1511.00561",
                "DOI": "10.1109/TPAMI.2016.2644615",
                "CorpusId": 60814714,
                "PubMed": "28060704"
            },
            "abstract": "We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the VGG16 network [1] . The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN [2] and also with the well known DeepLab-LargeFOV [3] , DeconvNet [4] architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. SegNet was primarily motivated by scene understanding applications. Hence, it is designed to be efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than other competing architectures and can be trained end-to-end using stochastic gradient descent. We also performed a controlled benchmark of SegNet and other architectures on both road scenes and SUN RGB-D indoor scene segmentation tasks. These quantitative assessments show that SegNet provides good performance with competitive inference time and most efficient inference memory-wise as compared to other architectures. We also provide a Caffe implementation of SegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.",
            "referenceCount": 74,
            "citationCount": 12505,
            "influentialCitationCount": 1702,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-11-02",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "39"
            },
            "citationStyles": {
                "bibtex": "@Article{Badrinarayanan2015SegNetAD,\n author = {Vijay Badrinarayanan and Alex Kendall and R. Cipolla},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {2481-2495},\n title = {SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation},\n volume = {39},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:995c5f5e62614fcb4d2796ad2faab969da51713e",
            "@type": "ScholarlyArticle",
            "paperId": "995c5f5e62614fcb4d2796ad2faab969da51713e",
            "corpusId": 5808102,
            "url": "https://www.semanticscholar.org/paper/995c5f5e62614fcb4d2796ad2faab969da51713e",
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1502.03167",
                "DBLP": "conf/icml/IoffeS15",
                "MAG": "1836465849",
                "CorpusId": 5808102
            },
            "abstract": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.",
            "referenceCount": 34,
            "citationCount": 38052,
            "influentialCitationCount": 1986,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-02-10",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1502.03167"
            },
            "citationStyles": {
                "bibtex": "@Article{Ioffe2015BatchNA,\n author = {Sergey Ioffe and Christian Szegedy},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},\n volume = {abs/1502.03167},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6bb558052ba9f3288983e6ace964cf9ce52c1afd",
            "@type": "ScholarlyArticle",
            "paperId": "6bb558052ba9f3288983e6ace964cf9ce52c1afd",
            "corpusId": 6159201,
            "url": "https://www.semanticscholar.org/paper/6bb558052ba9f3288983e6ace964cf9ce52c1afd",
            "title": "Improving Deep Learning using Generic Data Augmentation",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2953167514",
                "DBLP": "journals/corr/abs-1708-06020",
                "ArXiv": "1708.06020",
                "CorpusId": 6159201
            },
            "abstract": "Deep artificial neural networks require a large corpus of training data in order to effectively learn, where collection of such training data is often expensive and laborious. Data augmentation overcomes this issue by artificially inflating the training set with label preserving transformations. Recently there has been extensive use of generic data augmentation to improve Convolutional Neural Network (CNN) task performance. This study benchmarks various popular data augmentation schemes to allow researchers to make informed decisions as to which training methods are most appropriate for their data sets. Various geometric and photometric schemes are evaluated on a coarse-grained data set using a relatively simple CNN. Experimental results, run using 4-fold cross-validation and reported in terms of Top-1 and Top-5 accuracy, indicate that cropping in geometric augmentation significantly increases CNN task performance.",
            "referenceCount": 29,
            "citationCount": 474,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-08-20",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1708.06020"
            },
            "citationStyles": {
                "bibtex": "@Article{Taylor2017ImprovingDL,\n author = {Luke Taylor and G. Nitschke},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Improving Deep Learning using Generic Data Augmentation},\n volume = {abs/1708.06020},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2e6c3557cb90f472e6798fcaa8ecc9dff3557f11",
            "@type": "ScholarlyArticle",
            "paperId": "2e6c3557cb90f472e6798fcaa8ecc9dff3557f11",
            "corpusId": 40499053,
            "url": "https://www.semanticscholar.org/paper/2e6c3557cb90f472e6798fcaa8ecc9dff3557f11",
            "title": "Towards Perspective-Free Object Counting with Deep Learning",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2519281173",
                "DBLP": "conf/eccv/Onoro-RubioL16",
                "DOI": "10.1007/978-3-319-46478-7_38",
                "CorpusId": 40499053
            },
            "abstract": null,
            "referenceCount": 26,
            "citationCount": 566,
            "influentialCitationCount": 86,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-10-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{O\u00f1oro-Rubio2016TowardsPO,\n author = {Daniel O\u00f1oro-Rubio and R. L\u00f3pez-Sastre},\n booktitle = {European Conference on Computer Vision},\n pages = {615-629},\n title = {Towards Perspective-Free Object Counting with Deep Learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1a305e806f3d9b966c302831073b70946d4231da",
            "@type": "ScholarlyArticle",
            "paperId": "1a305e806f3d9b966c302831073b70946d4231da",
            "corpusId": 20184898,
            "url": "https://www.semanticscholar.org/paper/1a305e806f3d9b966c302831073b70946d4231da",
            "title": "Improved Automated Detection of Diabetic Retinopathy on a Publicly Available Dataset Through Integration of Deep Learning.",
            "venue": "Investigative Ophthalmology and Visual Science",
            "publicationVenue": {
                "id": "urn:research:e52aeb8d-b929-43a2-b584-f0f5fbcfd9f4",
                "name": "Investigative Ophthalmology and Visual Science",
                "alternate_names": [
                    "Investigative Ophthalmology & Visual Science",
                    "Investig Ophthalmol Vis Sci",
                    "Investig Ophthalmol  Vis Sci"
                ],
                "issn": "0146-0404",
                "url": "http://www.iovs.org/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2529153069",
                "DOI": "10.1167/iovs.16-19964",
                "CorpusId": 20184898,
                "PubMed": "27701631"
            },
            "abstract": "Purpose\nTo compare performance of a deep-learning enhanced algorithm for automated detection of diabetic retinopathy (DR), to the previously published performance of that algorithm, the Iowa Detection Program (IDP)-without deep learning components-on the same publicly available set of fundus images and previously reported consensus reference standard set, by three US Board certified retinal specialists.\n\n\nMethods\nWe used the previously reported consensus reference standard of referable DR (rDR), defined as International Clinical Classification of Diabetic Retinopathy moderate, severe nonproliferative (NPDR), proliferative DR, and/or macular edema (ME). Neither Messidor-2 images, nor the three retinal specialists setting the Messidor-2 reference standard were used for training IDx-DR version X2.1. Sensitivity, specificity, negative predictive value, area under the curve (AUC), and their confidence intervals (CIs) were calculated.\n\n\nResults\nSensitivity was 96.8% (95% CI: 93.3%-98.8%), specificity was 87.0% (95% CI: 84.2%-89.4%), with 6/874 false negatives, resulting in a negative predictive value of 99.0% (95% CI: 97.8%-99.6%). No cases of severe NPDR, PDR, or ME were missed. The AUC was 0.980 (95% CI: 0.968-0.992). Sensitivity was not statistically different from published IDP sensitivity, which had a CI of 94.4% to 99.3%, but specificity was significantly better than the published IDP specificity CI of 55.7% to 63.0%.\n\n\nConclusions\nA deep-learning enhanced algorithm for the automated detection of DR, achieves significantly better performance than a previously reported, otherwise essentially identical, algorithm that does not employ deep learning. Deep learning enhanced algorithms have the potential to improve the efficiency of DR screening, and thereby to prevent visual loss and blindness from this devastating disease.",
            "referenceCount": 39,
            "citationCount": 774,
            "influentialCitationCount": 33,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://iovs.arvojournals.org/arvo/content_public/journal/iovs/935768/i1552-5783-57-13-5200.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Study",
                "JournalArticle"
            ],
            "publicationDate": "2016-10-01",
            "journal": {
                "name": "Investigative ophthalmology & visual science",
                "volume": "57 13"
            },
            "citationStyles": {
                "bibtex": "@Article{Abr\u00e0moff2016ImprovedAD,\n author = {M. Abr\u00e0moff and Y. Lou and A. Erginay and Warren Clarida and R. Amelon and J. Folk and M. Niemeijer},\n booktitle = {Investigative Ophthalmology and Visual Science},\n journal = {Investigative ophthalmology & visual science},\n pages = {\n          5200-5206\n        },\n title = {Improved Automated Detection of Diabetic Retinopathy on a Publicly Available Dataset Through Integration of Deep Learning.},\n volume = {57 13},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:47262a72c9c7bf5070b97e70b55c6190d1079260",
            "@type": "ScholarlyArticle",
            "paperId": "47262a72c9c7bf5070b97e70b55c6190d1079260",
            "corpusId": 237132,
            "url": "https://www.semanticscholar.org/paper/47262a72c9c7bf5070b97e70b55c6190d1079260",
            "title": "Deep learning as a tool for increased accuracy and efficiency of histopathological diagnosis",
            "venue": "Scientific Reports",
            "publicationVenue": {
                "id": "urn:research:f99f77b7-b1b6-44d3-984a-f288e9884b9b",
                "name": "Scientific Reports",
                "alternate_names": [
                    "Sci Rep"
                ],
                "issn": "2045-2322",
                "url": "http://www.nature.com/srep/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2401520370",
                "PubMedCentral": "4876324",
                "DOI": "10.1038/srep26286",
                "CorpusId": 237132,
                "PubMed": "27212078"
            },
            "abstract": null,
            "referenceCount": 29,
            "citationCount": 810,
            "influentialCitationCount": 22,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/srep26286.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-05-23",
            "journal": {
                "name": "Scientific Reports",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Litjens2016DeepLA,\n author = {G. Litjens and C. S\u00e1nchez and N. Timofeeva and M. Hermsen and I. Nagtegaal and Iringo Kovacs and Christina Hulsbergen - van de Kaa and P. Bult and B. van Ginneken and J. A. van der Laak},\n booktitle = {Scientific Reports},\n journal = {Scientific Reports},\n title = {Deep learning as a tool for increased accuracy and efficiency of histopathological diagnosis},\n volume = {6},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5e39ec7bb7fbf77fc15224ee0dc71bb4f2c44174",
            "@type": "ScholarlyArticle",
            "paperId": "5e39ec7bb7fbf77fc15224ee0dc71bb4f2c44174",
            "corpusId": 211475964,
            "url": "https://www.semanticscholar.org/paper/5e39ec7bb7fbf77fc15224ee0dc71bb4f2c44174",
            "title": "Deep learning for biology",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2790102940",
                "DOI": "10.1038/d41586-018-02174-z",
                "CorpusId": 211475964,
                "PubMed": "29469107"
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 269,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://media.nature.com/original/magazine-assets/d41586-018-02174-z/d41586-018-02174-z.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "News",
                "Review"
            ],
            "publicationDate": "2018-02-01",
            "journal": {
                "name": "Nature",
                "volume": "554"
            },
            "citationStyles": {
                "bibtex": "@Article{Webb2018DeepLF,\n author = {Sarah Webb},\n booktitle = {Nature},\n journal = {Nature},\n pages = {555-557},\n title = {Deep learning for biology},\n volume = {554},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:43162522aa88cfc89835b2368de6ea025366a73a",
            "@type": "ScholarlyArticle",
            "paperId": "43162522aa88cfc89835b2368de6ea025366a73a",
            "corpusId": 686320,
            "url": "https://www.semanticscholar.org/paper/43162522aa88cfc89835b2368de6ea025366a73a",
            "title": "Accelerating magnetic resonance imaging via deep learning",
            "venue": "IEEE International Symposium on Biomedical Imaging",
            "publicationVenue": {
                "id": "urn:research:a38e0d3d-6929-4868-b4e4-af8bbacf711e",
                "name": "IEEE International Symposium on Biomedical Imaging",
                "alternate_names": [
                    "ISBI",
                    "International Symposium on Biomedical Imaging",
                    "Int Symp Biomed Imaging",
                    "IEEE Int Symp Biomed Imaging"
                ],
                "issn": "1945-7928",
                "url": "http://www.biomedicalimaging.org/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/isbi/WangSYPZLFL16",
                "MAG": "2442117232",
                "DOI": "10.1109/ISBI.2016.7493320",
                "CorpusId": 686320,
                "PubMed": "31709031"
            },
            "abstract": "This paper proposes a deep learning approach for accelerating magnetic resonance imaging (MRI) using a large number of existing high quality MR images as the training datasets. An off-line convolutional neural network is designed and trained to identify the mapping relationship between the MR images obtained from zero-filled and fully-sampled k-space data. The network is not only capable of restoring fine structures and details but is also compatible with online constrained reconstruction methods. Experimental results on real MR data have shown encouraging performance of the proposed method for efficient and accurate imaging.",
            "referenceCount": 17,
            "citationCount": 660,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc6839781?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-04-01",
            "journal": {
                "name": "2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2016AcceleratingMR,\n author = {Shanshan Wang and Zhenghang Su and L. Ying and Xi Peng and Shun Zhu and Feng Liang and D. Feng and D. Liang},\n booktitle = {IEEE International Symposium on Biomedical Imaging},\n journal = {2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)},\n pages = {514-517},\n title = {Accelerating magnetic resonance imaging via deep learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1d298139fc73654db7d8d936b07fa9e85bba008c",
            "@type": "ScholarlyArticle",
            "paperId": "1d298139fc73654db7d8d936b07fa9e85bba008c",
            "corpusId": 16997263,
            "url": "https://www.semanticscholar.org/paper/1d298139fc73654db7d8d936b07fa9e85bba008c",
            "title": "DeepTox: Toxicity Prediction using Deep Learning",
            "venue": "Frontiers in Environmental Science",
            "publicationVenue": {
                "id": "urn:research:c0ded351-0e49-473e-816e-23b84c9f8dd3",
                "name": "Frontiers in Environmental Science",
                "alternate_names": [
                    "Front Environ Sci"
                ],
                "issn": "2296-665X",
                "url": "http://www.frontiersin.org/Environmental_Science"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2767147442",
                "DOI": "10.3389/fenvs.2015.00080",
                "CorpusId": 16997263
            },
            "abstract": "The Tox21 Data Challenge has been the largest effort of the scientific community to compare computational methods for toxicity prediction. This challenge comprised 12,000 environmental chemicals and drugs which were measured for 12 different toxic effects by specifically designed assays. We participated in this challenge to assess the performance of Deep Learning in computational toxicity prediction. Deep Learning has already revolutionized image processing, speech recognition, and language understanding but has not yet been applied to computational toxicity. Deep Learning is founded on novel algorithms and architectures for artificial neural networks together with the recent availability of very fast computers and massive datasets. It discovers multiple levels of distributed representations of the input, with higher levels representing more abstract concepts. We hypothesized that the construction of a hierarchy of chemical features gives Deep Learning the edge over other toxicity prediction methods. Furthermore, Deep Learning naturally enables multi-task learning, that is, learning of all toxic effects in one neural network and thereby learning of highly informative chemical features. In order to utilize Deep Learning for toxicity prediction, we have developed the DeepTox pipeline. First, DeepTox normalizes the chemical representations of the compounds. Then it computes a large number of chemical descriptors that are used as input to machine learning methods. In its next step, DeepTox trains models, evaluates them, and combines the best of them to ensembles. Finally, DeepTox predicts the toxicity of new compounds. In the Tox21 Data Challenge, DeepTox had the highest performance of all computational methods winning the grand challenge, the nuclear receptor panel, the stress response panel, and six single assays (teams ``Bioinf@JKU''). We found that Deep Learning excelled in toxicity prediction and outperformed many other computational approaches like naive Bayes, support vector machines, and random forests.",
            "referenceCount": 79,
            "citationCount": 617,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.frontiersin.org/articles/10.3389/fenvs.2015.00080/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2016-02-02",
            "journal": {
                "name": "Frontiers in Environmental Science",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Mayr2016DeepToxTP,\n author = {Andreas Mayr and G. Klambauer and Thomas Unterthiner and S. Hochreiter},\n booktitle = {Frontiers in Environmental Science},\n journal = {Frontiers in Environmental Science},\n title = {DeepTox: Toxicity Prediction using Deep Learning},\n volume = {3},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2ed575c344e23aa14989b270977b98cec9b39407",
            "@type": "ScholarlyArticle",
            "paperId": "2ed575c344e23aa14989b270977b98cec9b39407",
            "corpusId": 10306523,
            "url": "https://www.semanticscholar.org/paper/2ed575c344e23aa14989b270977b98cec9b39407",
            "title": "A Semantic Loss Function for Deep Learning with Symbolic Knowledge",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2772282934",
                "DBLP": "journals/corr/abs-1711-11157",
                "ArXiv": "1711.11157",
                "CorpusId": 10306523
            },
            "abstract": "This paper develops a novel methodology for using symbolic knowledge in deep learning. From first principles, we derive a semantic loss function that bridges between neural output vectors and logical constraints. This loss function captures how close the neural network is to satisfying the constraints on its output. An experimental evaluation shows that it effectively guides the learner to achieve (near-)state-of-the-art results on semi-supervised multi-class classification. Moreover, it significantly increases the ability of the neural network to predict structured objects, such as rankings and paths. These discrete concepts are tremendously difficult to learn, and benefit from a tight integration of deep learning and symbolic reasoning methods.",
            "referenceCount": 66,
            "citationCount": 325,
            "influentialCitationCount": 47,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-11-29",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Xu2017ASL,\n author = {Jingyi Xu and Zilu Zhang and Tal Friedman and Yitao Liang and Guy Van den Broeck},\n booktitle = {International Conference on Machine Learning},\n pages = {5498-5507},\n title = {A Semantic Loss Function for Deep Learning with Symbolic Knowledge},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:efd68f3724942c9de5dc804d3c7cb3f70f42234b",
            "@type": "ScholarlyArticle",
            "paperId": "efd68f3724942c9de5dc804d3c7cb3f70f42234b",
            "corpusId": 263954836,
            "url": "https://www.semanticscholar.org/paper/efd68f3724942c9de5dc804d3c7cb3f70f42234b",
            "title": "Deep learning for computational biology",
            "venue": "Molecular Systems Biology",
            "publicationVenue": {
                "id": "urn:research:3bff011d-f05b-46ec-b123-beabcc2a1ba5",
                "name": "Molecular Systems Biology",
                "alternate_names": [
                    "Mol Syst Biology"
                ],
                "issn": "1744-4292",
                "url": "http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1744-4292"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2502949459",
                "PubMedCentral": "4965871",
                "DOI": "10.15252/msb.20156651",
                "CorpusId": 263954836,
                "PubMed": "27474269"
            },
            "abstract": "Technological advances in genomics and imaging have led to an explosion of molecular and cellular profiling data from large numbers of samples. This rapid increase in biological data dimension and acquisition rate is challenging conventional analysis strategies. Modern machine learning methods, such as deep learning, promise to leverage very large data sets for finding hidden structure within them, and for making accurate predictions. In this review, we discuss applications of this new breed of analysis approaches in regulatory genomics and cellular imaging. We provide background of what deep learning is, and the settings in which it can be successfully applied to derive biological insights. In addition to presenting specific applications and providing tips for practical use, we also highlight possible pitfalls and limitations to guide computational biologists when and how to make the most use of this new technology.",
            "referenceCount": 138,
            "citationCount": 637,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2016-07-01",
            "journal": {
                "name": "Molecular Systems Biology",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Angermueller2016DeepLF,\n author = {Christof Angermueller and Tanel P\u00e4rnamaa and Leopold Parts and O. Stegle},\n booktitle = {Molecular Systems Biology},\n journal = {Molecular Systems Biology},\n title = {Deep learning for computational biology},\n volume = {12},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:70ec156f7e6de0275c7e4e95e35f1bc1e92e29b3",
            "@type": "ScholarlyArticle",
            "paperId": "70ec156f7e6de0275c7e4e95e35f1bc1e92e29b3",
            "corpusId": 18421410,
            "url": "https://www.semanticscholar.org/paper/70ec156f7e6de0275c7e4e95e35f1bc1e92e29b3",
            "title": "Deep learning ensembles for melanoma recognition in dermoscopy images",
            "venue": "IBM Journal of Research and Development",
            "publicationVenue": {
                "id": "urn:research:555db9fd-8025-4984-8082-971e1e6bdb24",
                "name": "IBM Journal of Research and Development",
                "alternate_names": [
                    "IBM J Res Dev",
                    "Ibm J Res Dev",
                    "Ibm Journal of Research and Development"
                ],
                "issn": "0018-8646",
                "url": "http://www.research.ibm.com/journal/index.html"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1610.04662",
                "MAG": "2952662565",
                "DBLP": "journals/ibmrd/CodellaNPGHHS17",
                "DOI": "10.1147/JRD.2017.2708299",
                "CorpusId": 18421410
            },
            "abstract": "Melanoma is the deadliest form of skin cancer. While curable with early detection, only highly trained specialists are capable of accurately recognizing the disease. As expertise is in limited supply, automated systems capable of identifying disease could save lives, reduce unnecessary biopsies, and reduce costs. Toward this goal, we propose a system that combines recent developments in deep learning with established machine learning approaches, creating ensembles of methods that are capable of segmenting skin lesions, as well as analyzing the detected area and surrounding tissue for melanoma detection. The system is evaluated using the largest publicly available benchmark dataset of dermoscopic images, containing 900 training and 379 testing images. New state-of-the-art performance levels are demonstrated, leading to an improvement in the area under receiver operating characteristic curve of 7.5% (0.843 vs. 0.783), in average precision of 4% (0.649 vs. 0.624), and in specificity measured at the clinically relevant 95% sensitivity operating point 2.9 times higher than the previous state-of-the-art (36.8% specificity compared to 12.5%). Compared to the average of 8 expert dermatologists on a subset of 100 test images, the proposed system produces a higher accuracy (76% vs. 70.5%), and specificity (62% vs. 59%) evaluated at an equivalent sensitivity (82%).",
            "referenceCount": 52,
            "citationCount": 461,
            "influentialCitationCount": 26,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1610.04662",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-10-14",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1610.04662"
            },
            "citationStyles": {
                "bibtex": "@Article{Codella2016DeepLE,\n author = {N. Codella and Q. Nguyen and Sharath Pankanti and David Gutman and B. Helba and A. Halpern and John R. Smith},\n booktitle = {IBM Journal of Research and Development},\n journal = {ArXiv},\n title = {Deep learning ensembles for melanoma recognition in dermoscopy images},\n volume = {abs/1610.04662},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:846aedd869a00c09b40f1f1f35673cb22bc87490",
            "@type": "ScholarlyArticle",
            "paperId": "846aedd869a00c09b40f1f1f35673cb22bc87490",
            "corpusId": 515925,
            "url": "https://www.semanticscholar.org/paper/846aedd869a00c09b40f1f1f35673cb22bc87490",
            "title": "Mastering the game of Go with deep neural networks and tree search",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/nature/SilverHMGSDSAPL16",
                "MAG": "2257979135",
                "DOI": "10.1038/nature16961",
                "CorpusId": 515925,
                "PubMed": "26819042"
            },
            "abstract": null,
            "referenceCount": 72,
            "citationCount": 14437,
            "influentialCitationCount": 516,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/nature16961.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-01-27",
            "journal": {
                "name": "Nature",
                "volume": "529"
            },
            "citationStyles": {
                "bibtex": "@Article{Silver2016MasteringTG,\n author = {David Silver and Aja Huang and Chris J. Maddison and A. Guez and L. Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Vedavyas Panneershelvam and Marc Lanctot and S. Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and T. Lillicrap and M. Leach and K. Kavukcuoglu and T. Graepel and D. Hassabis},\n booktitle = {Nature},\n journal = {Nature},\n pages = {484-489},\n title = {Mastering the game of Go with deep neural networks and tree search},\n volume = {529},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c3070ad9ebfe56cc7b2833e353c66392f5b7afb9",
            "@type": "ScholarlyArticle",
            "paperId": "c3070ad9ebfe56cc7b2833e353c66392f5b7afb9",
            "corpusId": 20824247,
            "url": "https://www.semanticscholar.org/paper/c3070ad9ebfe56cc7b2833e353c66392f5b7afb9",
            "title": "Deep Learning for solar power forecasting \u2014 An approach using AutoEncoder and LSTM Neural Networks",
            "venue": "IEEE International Conference on Systems, Man and Cybernetics",
            "publicationVenue": {
                "id": "urn:research:e84bb5a1-8f79-42cc-8eb1-3a52f7c73d63",
                "name": "IEEE International Conference on Systems, Man and Cybernetics",
                "alternate_names": [
                    "Smoky Mountains Computational Sciences and Engineering Conference",
                    "Smoky Mt Comput Sci Eng Conf",
                    "IEEE Int Conf Syst Man Cybern",
                    "SMC",
                    "Syst Man Cybern",
                    "Systems, Man and Cybernetics"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2587586954",
                "DBLP": "conf/smc/GenslerHSR16",
                "DOI": "10.1109/SMC.2016.7844673",
                "CorpusId": 20824247
            },
            "abstract": "Power forecasting of renewable energy power plants is a very active research field, as reliable information about the future power generation allow for a safe operation of the power grid and helps to minimize the operational costs of these energy sources. Deep Learning algorithms have shown to be very powerful in forecasting tasks, such as economic time series or speech recognition. Up to now, Deep Learning algorithms have only been applied sparsely for forecasting renewable energy power plants. By using different Deep Learning and Artificial Neural Network algorithms, such as Deep Belief Networks, AutoEncoder, and LSTM, we introduce these powerful algorithms in the field of renewable energy power forecasting. In our experiments, we used combinations of these algorithms to show their forecast strength compared to a standard MLP and a physical forecasting model in the forecasting the energy output of 21 solar power plants. Our results using Deep Learning algorithms show a superior forecasting performance compared to Artificial Neural Networks as well as other reference models such as physical models.",
            "referenceCount": 26,
            "citationCount": 435,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-10-01",
            "journal": {
                "name": "2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gensler2016DeepLF,\n author = {Andr\u00e9 Gensler and Janosch Henze and B. Sick and N. Raabe},\n booktitle = {IEEE International Conference on Systems, Man and Cybernetics},\n journal = {2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},\n pages = {002858-002865},\n title = {Deep Learning for solar power forecasting \u2014 An approach using AutoEncoder and LSTM Neural Networks},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:30501640908567ef13640d82c633b6ac6b265dfc",
            "@type": "ScholarlyArticle",
            "paperId": "30501640908567ef13640d82c633b6ac6b265dfc",
            "corpusId": 206685945,
            "url": "https://www.semanticscholar.org/paper/30501640908567ef13640d82c633b6ac6b265dfc",
            "title": "Applications of Deep Learning in Biomedicine.",
            "venue": "Molecular Pharmaceutics",
            "publicationVenue": {
                "id": "urn:research:bfba025f-b9ce-44b1-a200-eec39dd09964",
                "name": "Molecular Pharmaceutics",
                "alternate_names": [
                    "Mol Pharm"
                ],
                "issn": "1543-8384",
                "url": "https://pubs.acs.org/journal/mpohbp"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2306570595",
                "DOI": "10.1021/acs.molpharmaceut.5b00982",
                "CorpusId": 206685945,
                "PubMed": "27007977"
            },
            "abstract": "Increases in throughput and installed base of biomedical research equipment led to a massive accumulation of -omics data known to be highly variable, high-dimensional, and sourced from multiple often incompatible data platforms. While this data may be useful for biomarker identification and drug discovery, the bulk of it remains underutilized. Deep neural networks (DNNs) are efficient algorithms based on the use of compositional layers of neurons, with advantages well matched to the challenges -omics data presents. While achieving state-of-the-art results and even surpassing human accuracy in many challenging tasks, the adoption of deep learning in biomedicine has been comparatively slow. Here, we discuss key features of deep learning that may give this approach an edge over other machine learning methods. We then consider limitations and review a number of applications of deep learning in biomedical studies demonstrating proof of concept and practical utility.",
            "referenceCount": 50,
            "citationCount": 533,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2016-03-29",
            "journal": {
                "name": "Molecular pharmaceutics",
                "volume": "13 5"
            },
            "citationStyles": {
                "bibtex": "@Article{Mamoshina2016ApplicationsOD,\n author = {Polina Mamoshina and Armando Vieira and E. Putin and A. Zhavoronkov},\n booktitle = {Molecular Pharmaceutics},\n journal = {Molecular pharmaceutics},\n pages = {\n          1445-54\n        },\n title = {Applications of Deep Learning in Biomedicine.},\n volume = {13 5},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1ee88e64945503c93b68344e639a7ae085f6e37d",
            "@type": "ScholarlyArticle",
            "paperId": "1ee88e64945503c93b68344e639a7ae085f6e37d",
            "corpusId": 38063112,
            "url": "https://www.semanticscholar.org/paper/1ee88e64945503c93b68344e639a7ae085f6e37d",
            "title": "CNTK: Microsoft's Open-Source Deep-Learning Toolkit",
            "venue": "Knowledge Discovery and Data Mining",
            "publicationVenue": {
                "id": "urn:research:a0edb93b-1e95-4128-a295-6b1659149cef",
                "name": "Knowledge Discovery and Data Mining",
                "alternate_names": [
                    "KDD",
                    "Knowl Discov Data Min"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigkdd/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/kdd/SeideA16",
                "MAG": "2513383847",
                "DOI": "10.1145/2939672.2945397",
                "CorpusId": 38063112
            },
            "abstract": "This tutorial will introduce the Computational Network Toolkit, or CNTK, Microsoft's cutting-edge open-source deep-learning toolkit for Windows and Linux. CNTK is a powerful computation-graph based deep-learning toolkit for training and evaluating deep neural networks. Microsoft product groups use CNTK, for example to create the Cortana speech models and web ranking. CNTK supports feed-forward, convolutional, and recurrent networks for speech, image, and text workloads, also in combination. Popular network types are supported either natively (convolution) or can be described as a CNTK configuration (LSTM, sequence-to-sequence). CNTK scales to multiple GPU servers and is designed around efficiency. The tutorial will give an overview of CNTK's general architecture and describe the specific methods and algorithms used for automatic differentiation, recurrent-loop inference and execution, memory sharing, on-the-fly randomization of large corpora, and multi-server parallelization. We will then show how typical uses looks like for relevant tasks like image recognition, sequence-to-sequence modeling, and speech recognition.",
            "referenceCount": 1,
            "citationCount": 413,
            "influentialCitationCount": 36,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2016-08-13",
            "journal": {
                "name": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Seide2016CNTKMO,\n author = {F. Seide and Amit Agarwal},\n booktitle = {Knowledge Discovery and Data Mining},\n journal = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},\n title = {CNTK: Microsoft's Open-Source Deep-Learning Toolkit},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b5f3e5d2912bedbcd9458952d664b08db6aed962",
            "@type": "ScholarlyArticle",
            "paperId": "b5f3e5d2912bedbcd9458952d664b08db6aed962",
            "corpusId": 9971732,
            "url": "https://www.semanticscholar.org/paper/b5f3e5d2912bedbcd9458952d664b08db6aed962",
            "title": "Accurate Image Super-Resolution Using Very Deep Convolutional Networks",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2951997238",
                "DBLP": "conf/cvpr/KimLL16a",
                "ArXiv": "1511.04587",
                "DOI": "10.1109/CVPR.2016.182",
                "CorpusId": 9971732
            },
            "abstract": "We present a highly accurate single-image superresolution (SR) method. Our method uses a very deep convolutional network inspired by VGG-net used for ImageNet classification [19]. We find increasing our network depth shows a significant improvement in accuracy. Our final model uses 20 weight layers. By cascading small filters many times in a deep network structure, contextual information over large image regions is exploited in an efficient way. With very deep networks, however, convergence speed becomes a critical issue during training. We propose a simple yet effective training procedure. We learn residuals only and use extremely high learning rates (104 times higher than SRCNN [6]) enabled by adjustable gradient clipping. Our proposed method performs better than existing methods in accuracy and visual improvements in our results are easily noticeable.",
            "referenceCount": 27,
            "citationCount": 5084,
            "influentialCitationCount": 1126,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1511.04587",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-11-14",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kim2015AccurateIS,\n author = {Jiwon Kim and Jung Kwon Lee and Kyoung Mu Lee},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1646-1654},\n title = {Accurate Image Super-Resolution Using Very Deep Convolutional Networks},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e517a34dbacfba588e6480f110e4c27665686819",
            "@type": "ScholarlyArticle",
            "paperId": "e517a34dbacfba588e6480f110e4c27665686819",
            "corpusId": 10845625,
            "url": "https://www.semanticscholar.org/paper/e517a34dbacfba588e6480f110e4c27665686819",
            "title": "Efficient Deep Learning for Stereo Matching",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/cvpr/LuoSU16",
                "MAG": "2440384215",
                "DOI": "10.1109/CVPR.2016.614",
                "CorpusId": 10845625
            },
            "abstract": "In the past year, convolutional neural networks have been shown to perform extremely well for stereo estimation. However, current architectures rely on siamese networks which exploit concatenation followed by further processing layers, requiring a minute of GPU computation per image pair. In contrast, in this paper we propose a matching network which is able to produce very accurate results in less than a second of GPU computation. Towards this goal, we exploit a product layer which simply computes the inner product between the two representations of a siamese architecture. We train our network by treating the problem as multi-class classification, where the classes are all possible disparities. This allows us to get calibrated scores, which result in much better matching performance when compared to existing approaches.",
            "referenceCount": 32,
            "citationCount": 706,
            "influentialCitationCount": 62,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-27",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Luo2016EfficientDL,\n author = {Wenjie Luo and A. Schwing and R. Urtasun},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {5695-5703},\n title = {Efficient Deep Learning for Stereo Matching},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c0927ffb79810318daab8821068629975cab67ad",
            "@type": "ScholarlyArticle",
            "paperId": "c0927ffb79810318daab8821068629975cab67ad",
            "corpusId": 9413935,
            "url": "https://www.semanticscholar.org/paper/c0927ffb79810318daab8821068629975cab67ad",
            "title": "Deep Learning for Classification of Malware System Call Sequences",
            "venue": "Australasian Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/ausai/KolosnjajiZWE16",
                "MAG": "2557513839",
                "DOI": "10.1007/978-3-319-50127-7_11",
                "CorpusId": 9413935
            },
            "abstract": null,
            "referenceCount": 37,
            "citationCount": 425,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-12-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kolosnjaji2016DeepLF,\n author = {Bojan Kolosnjaji and Apostolis Zarras and George D. Webster and C. Eckert},\n booktitle = {Australasian Conference on Artificial Intelligence},\n pages = {137-149},\n title = {Deep Learning for Classification of Malware System Call Sequences},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9dfacffdae4527d01563814c804e410e4ca885e1",
            "@type": "ScholarlyArticle",
            "paperId": "9dfacffdae4527d01563814c804e410e4ca885e1",
            "corpusId": 393535,
            "url": "https://www.semanticscholar.org/paper/9dfacffdae4527d01563814c804e410e4ca885e1",
            "title": "HDLTex: Hierarchical Deep Learning for Text Classification",
            "venue": "International Conference on Machine Learning and Applications",
            "publicationVenue": {
                "id": "urn:research:f6752838-f268-4a1b-87e7-c5f30a36713c",
                "name": "International Conference on Machine Learning and Applications",
                "alternate_names": [
                    "Int Conf Mach Learn Appl",
                    "ICMLA"
                ],
                "issn": null,
                "url": "http://www.icmla-conference.org/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1709.08267",
                "DBLP": "journals/corr/abs-1709-08267",
                "MAG": "2759474451",
                "DOI": "10.1109/ICMLA.2017.0-134",
                "CorpusId": 393535
            },
            "abstract": "Increasingly large document collections require improved information processing methods for searching, retrieving, and organizing text. Central to these information processing methods is document classification, which has become an important application for supervised learning. Recently the performance of traditional supervised classifiers has degraded as the number of documents has increased. This is because along with growth in the number of documents has come an increase in the number of categories. This paper approaches this problem differently from current document classification methods that view the problem as multi-class classification. Instead we perform hierarchical classification using an approach we call Hierarchical Deep Learning for Text classification (HDLTex). HDLTex employs stacks of deep learning architectures to provide specialized understanding at each level of the document hierarchy.",
            "referenceCount": 54,
            "citationCount": 299,
            "influentialCitationCount": 39,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1709.08267",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-09-24",
            "journal": {
                "name": "2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kowsari2017HDLTexHD,\n author = {Kamran Kowsari and Donald E. Brown and Mojtaba Heidarysafa and K. Meimandi and M. Gerber and Laura E. Barnes},\n booktitle = {International Conference on Machine Learning and Applications},\n journal = {2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)},\n pages = {364-371},\n title = {HDLTex: Hierarchical Deep Learning for Text Classification},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6428684c0774325031d25535deb307653e82a003",
            "@type": "ScholarlyArticle",
            "paperId": "6428684c0774325031d25535deb307653e82a003",
            "corpusId": 10050878,
            "url": "https://www.semanticscholar.org/paper/6428684c0774325031d25535deb307653e82a003",
            "title": "A Deep Learning Approach to on-Node Sensor Data Analytics for Mobile or Wearable Devices",
            "venue": "IEEE journal of biomedical and health informatics",
            "publicationVenue": {
                "id": "urn:research:eac74c9c-a5c0-417d-8088-8164a6a8bfb3",
                "name": "IEEE journal of biomedical and health informatics",
                "alternate_names": [
                    "IEEE Journal of Biomedical and Health Informatics",
                    "IEEE j biomed health informatics",
                    "IEEE J Biomed Health Informatics"
                ],
                "issn": "2168-2194",
                "url": "https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6221020"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2563686712",
                "DBLP": "journals/titb/RaviWLY17",
                "DOI": "10.1109/JBHI.2016.2633287",
                "CorpusId": 10050878,
                "PubMed": "28026792"
            },
            "abstract": "The increasing popularity of wearable devices in recent years means that a diverse range of physiological and functional data can now be captured continuously for applications in sports, wellbeing, and healthcare. This wealth of information requires efficient methods of classification and analysis where deep learning is a promising technique for large-scale data analytics. While deep learning has been successful in implementations that utilize high-performance computing platforms, its use on low-power wearable devices is limited by resource constraints. In this paper, we propose a deep learning methodology, which combines features learned from inertial sensor data together with complementary information from a set of shallow features to enable accurate and real-time activity classification. The design of this combined method aims to overcome some of the limitations present in a typical deep learning framework where on-node computation is required. To optimize the proposed method for real-time on-node computation, spectral domain preprocessing is used before the data are passed onto the deep learning framework. The classification accuracy of our proposed deep learning approach is evaluated against state-of-the-art methods using both laboratory and real world activity datasets. Our results show the validity of the approach on different human activity datasets, outperforming other methods, including the two methods used within our combined pipeline. We also demonstrate that the computation times for the proposed method are consistent with the constraints of real-time on-node processing on smartphones and a wearable sensor platform.",
            "referenceCount": 34,
            "citationCount": 335,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Journal of Biomedical and Health Informatics",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Rav\u00ec2017ADL,\n author = {D. Rav\u00ec and Charence Wong and Benny P. L. Lo and Guang-Zhong Yang},\n booktitle = {IEEE journal of biomedical and health informatics},\n journal = {IEEE Journal of Biomedical and Health Informatics},\n pages = {56-64},\n title = {A Deep Learning Approach to on-Node Sensor Data Analytics for Mobile or Wearable Devices},\n volume = {21},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4286abc71594117f019a09d3505332ca83b4b6c8",
            "@type": "ScholarlyArticle",
            "paperId": "4286abc71594117f019a09d3505332ca83b4b6c8",
            "corpusId": 10574953,
            "url": "https://www.semanticscholar.org/paper/4286abc71594117f019a09d3505332ca83b4b6c8",
            "title": "Deep Learning in Drug Discovery",
            "venue": "Molecular Informatics",
            "publicationVenue": {
                "id": "urn:research:5b118ecf-59a2-431d-8c47-4656f9e92e08",
                "name": "Molecular Informatics",
                "alternate_names": [
                    "Mol Informatics"
                ],
                "issn": "1868-1743",
                "url": "http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1868-1751"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2213443318",
                "DOI": "10.1002/minf.201501008",
                "CorpusId": 10574953,
                "PubMed": "27491648"
            },
            "abstract": "Artificial neural networks had their first heyday in molecular informatics and drug discovery approximately two decades ago. Currently, we are witnessing renewed interest in adapting advanced neural network architectures for pharmaceutical research by borrowing from the field of \u201cdeep learning\u201d. Compared with some of the other life sciences, their application in drug discovery is still limited. Here, we provide an overview of this emerging field of molecular informatics, present the basic concepts of prominent deep learning methods and offer motivation to explore these techniques for their usefulness in computer\u2010assisted drug discovery and design. We specifically emphasize deep neural networks, restricted Boltzmann machine networks and convolutional networks.",
            "referenceCount": 131,
            "citationCount": 506,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/minf.201501008",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2016-01-01",
            "journal": {
                "name": "Molecular Informatics",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Gawehn2016DeepLI,\n author = {Erik Gawehn and J. A. Hiss and G. Schneider},\n booktitle = {Molecular Informatics},\n journal = {Molecular Informatics},\n title = {Deep Learning in Drug Discovery},\n volume = {35},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:49047883d555a536420faa0ac3c0684b70822643",
            "@type": "ScholarlyArticle",
            "paperId": "49047883d555a536420faa0ac3c0684b70822643",
            "corpusId": 195953,
            "url": "https://www.semanticscholar.org/paper/49047883d555a536420faa0ac3c0684b70822643",
            "title": "Searching for exotic particles in high-energy physics with deep learning",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2125621954",
                "ArXiv": "1402.4735",
                "DOI": "10.1038/ncomms5308",
                "CorpusId": 195953,
                "PubMed": "24986233"
            },
            "abstract": null,
            "referenceCount": 29,
            "citationCount": 1095,
            "influentialCitationCount": 92,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/ncomms5308.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Physics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-02-19",
            "journal": {
                "name": "Nature Communications",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Baldi2014SearchingFE,\n author = {P. Baldi and Peter Sadowski and D. Whiteson},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {Searching for exotic particles in high-energy physics with deep learning},\n volume = {5},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:162ea969d1929ed180cc6de9f0bf116993ff6e06",
            "@type": "ScholarlyArticle",
            "paperId": "162ea969d1929ed180cc6de9f0bf116993ff6e06",
            "corpusId": 4637184,
            "url": "https://www.semanticscholar.org/paper/162ea969d1929ed180cc6de9f0bf116993ff6e06",
            "title": "Deep Face Recognition",
            "venue": "British Machine Vision Conference",
            "publicationVenue": {
                "id": "urn:research:78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                "name": "British Machine Vision Conference",
                "alternate_names": [
                    "Br Mach Vis Conf",
                    "BMVC"
                ],
                "issn": null,
                "url": "http://www.bmva.org/bmvc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2325939864",
                "DBLP": "conf/bmvc/ParkhiVZ15",
                "DOI": "10.5244/C.29.41",
                "CorpusId": 4637184
            },
            "abstract": "The goal of this paper is face recognition \u2013 from either a single photograph or from a set of faces tracked in a video. Recent progress in this area has been due to two factors: (i) end to end learning for the task using a convolutional neural network (CNN), and (ii) the availability of very large scale training datasets. We make two contributions: first, we show how a very large scale dataset (2.6M images, over 2.6K people) can be assembled by a combination of automation and human in the loop, and discuss the trade off between data purity and time; second, we traverse through the complexities of deep network training and face recognition to present methods and procedures to achieve comparable state of the art results on the standard LFW and YTF face benchmarks.",
            "referenceCount": 32,
            "citationCount": 4854,
            "influentialCitationCount": 828,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.bmva.org/bmvc/2015/papers/paper041/abstract041.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Parkhi2015DeepFR,\n author = {Omkar M. Parkhi and A. Vedaldi and Andrew Zisserman},\n booktitle = {British Machine Vision Conference},\n pages = {41.1-41.12},\n title = {Deep Face Recognition},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:642d0f49b7826adcf986616f4af77e736229990f",
            "@type": "ScholarlyArticle",
            "paperId": "642d0f49b7826adcf986616f4af77e736229990f",
            "corpusId": 2134321,
            "url": "https://www.semanticscholar.org/paper/642d0f49b7826adcf986616f4af77e736229990f",
            "title": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2119144962",
                "ArXiv": "1510.00149",
                "DBLP": "journals/corr/HanMD15",
                "CorpusId": 2134321
            },
            "abstract": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency.",
            "referenceCount": 35,
            "citationCount": 7346,
            "influentialCitationCount": 781,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-10-01",
            "journal": {
                "name": "arXiv: Computer Vision and Pattern Recognition",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Han2015DeepCC,\n author = {Song Han and Huizi Mao and W. Dally},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Computer Vision and Pattern Recognition},\n title = {Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d289ce63055c10937e5715e940a4bb9d0af7a8c5",
            "@type": "ScholarlyArticle",
            "paperId": "d289ce63055c10937e5715e940a4bb9d0af7a8c5",
            "corpusId": 9948141,
            "url": "https://www.semanticscholar.org/paper/d289ce63055c10937e5715e940a4bb9d0af7a8c5",
            "title": "DeepMon: Mobile GPU-based Deep Learning Framework for Continuous Vision Applications",
            "venue": "ACM SIGMOBILE International Conference on Mobile Systems, Applications, and Services",
            "publicationVenue": {
                "id": "urn:research:41929b26-d887-42cf-97f1-1217a0a9e315",
                "name": "ACM SIGMOBILE International Conference on Mobile Systems, Applications, and Services",
                "alternate_names": [
                    "Int Conf Mob Syst Appl Serv",
                    "MobiSys",
                    "International Conference on Mobile Systems, Applications, and Services",
                    "ACM SIGMOBILE Int Conf Mob Syst Appl Serv"
                ],
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2626129225",
                "DBLP": "conf/mobisys/LocLB17",
                "DOI": "10.1145/3081333.3081360",
                "CorpusId": 9948141
            },
            "abstract": "The rapid emergence of head-mounted devices such as the Microsoft Holo-lens enables a wide variety of continuous vision applications. Such applications often adopt deep-learning algorithms such as CNN and RNN to extract rich contextual information from the first-person-view video streams. Despite the high accuracy, use of deep learning algorithms in mobile devices raises critical challenges, i.e., high processing latency and power consumption. In this paper, we propose DeepMon, a mobile deep learning inference system to run a variety of deep learning inferences purely on a mobile device in a fast and energy-efficient manner. For this, we designed a suite of optimization techniques to efficiently offload convolutional layers to mobile GPUs and accelerate the processing; note that the convolutional layers are the common performance bottleneck of many deep learning models. Our experimental results show that DeepMon can classify an image over the VGG-VeryDeep-16 deep learning model in 644ms on Samsung Galaxy S7, taking an important step towards continuous vision without imposing any privacy concerns nor networking cost.",
            "referenceCount": 44,
            "citationCount": 321,
            "influentialCitationCount": 26,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2017-06-16",
            "journal": {
                "name": "Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Loc2017DeepMonMG,\n author = {Huynh Nguyen Loc and Youngki Lee and R. Balan},\n booktitle = {ACM SIGMOBILE International Conference on Mobile Systems, Applications, and Services},\n journal = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},\n title = {DeepMon: Mobile GPU-based Deep Learning Framework for Continuous Vision Applications},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6",
            "@type": "ScholarlyArticle",
            "paperId": "be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6",
            "corpusId": 8909022,
            "url": "https://www.semanticscholar.org/paper/be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6",
            "title": "Matching Networks for One Shot Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2432717477",
                "DBLP": "journals/corr/VinyalsBLKW16",
                "ArXiv": "1606.04080",
                "CorpusId": 8909022
            },
            "abstract": "Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.",
            "referenceCount": 30,
            "citationCount": 5818,
            "influentialCitationCount": 1290,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-13",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Vinyals2016MatchingNF,\n author = {Oriol Vinyals and C. Blundell and T. Lillicrap and K. Kavukcuoglu and Daan Wierstra},\n booktitle = {Neural Information Processing Systems},\n pages = {3630-3638},\n title = {Matching Networks for One Shot Learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b245959da6bdaa0b711341844aeaa473b7706453",
            "@type": "ScholarlyArticle",
            "paperId": "b245959da6bdaa0b711341844aeaa473b7706453",
            "corpusId": 3758333,
            "url": "https://www.semanticscholar.org/paper/b245959da6bdaa0b711341844aeaa473b7706453",
            "title": "DAWNBench : An End-to-End Deep Learning Benchmark and Competition",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2909764952",
                "CorpusId": 3758333
            },
            "abstract": "Despite considerable research on systems, algorithms and hardware to speed up deep learning workloads, there is no standard means of evaluating end-to-end deep learning performance. Existing benchmarks measure proxy metrics, such as time to process one minibatch of data, that do not indicate whether the system as a whole will converge faster to a high-quality result. In this work, we introduce DAWNBench, a benchmark and competition focused on end-to-end training time to achieve a state-of-the-art accuracy level, as well as inference with that accuracy. We have seeded the benchmark with entries for image classification on CIFAR10 and ImageNet, and question answering on SQuAD, showing differences across models, software and hardware. We believe DAWNBench will provide a useful, reproducible means of evaluating the many tradeoffs in deep learning systems.",
            "referenceCount": 50,
            "citationCount": 293,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Coleman2017DAWNBenchA,\n author = {Cody A. Coleman and D. Narayanan and Daniel Kang and Tian Zhao and Jian Zhang and Luigi Nardi and Peter D. Bailis and K. Olukotun and C. R\u00e9 and M. Zaharia},\n title = {DAWNBench : An End-to-End Deep Learning Benchmark and Competition},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd",
            "@type": "ScholarlyArticle",
            "paperId": "f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd",
            "corpusId": 2665144,
            "url": "https://www.semanticscholar.org/paper/f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd",
            "title": "Variational Autoencoder for Deep Learning of Images, Labels and Captions",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/PuGHYLSC16",
                "MAG": "2527569769",
                "ArXiv": "1609.08976",
                "CorpusId": 2665144
            },
            "abstract": "A novel variational autoencoder is developed to model images, as well as associated labels or captions. The Deep Generative Deconvolutional Network (DGDN) is used as a decoder of the latent image features, and a deep Convolutional Neural Network (CNN) is used as an image encoder; the CNN is used to approximate a distribution for the latent DGDN features/code. The latent code is also linked to generative models for labels (Bayesian support vector machine) or captions (recurrent neural network). When predicting a label/caption for a new image at test, averaging is performed across the distribution of latent codes; this is computationally efficient as a consequence of the learned CNN-based encoder. Since the framework is capable of modeling the image in the presence/absence of associated labels/captions, a new semi-supervised setting is manifested for CNN learning with images; the framework even allows unsupervised CNN learning, based on images alone.",
            "referenceCount": 37,
            "citationCount": 636,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-09-28",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Pu2016VariationalAF,\n author = {Yunchen Pu and Zhe Gan and Ricardo Henao and Xin Yuan and Chunyuan Li and Andrew Stevens and L. Carin},\n booktitle = {Neural Information Processing Systems},\n pages = {2352-2360},\n title = {Variational Autoencoder for Deep Learning of Images, Labels and Captions},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a464e45d17da3e60bffb87290fab46f89607b7be",
            "@type": "ScholarlyArticle",
            "paperId": "a464e45d17da3e60bffb87290fab46f89607b7be",
            "corpusId": 19179988,
            "url": "https://www.semanticscholar.org/paper/a464e45d17da3e60bffb87290fab46f89607b7be",
            "title": "Deep learning from crowds",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/abs-1709-01779",
                "ArXiv": "1709.01779",
                "MAG": "2953287512",
                "DOI": "10.1609/aaai.v32i1.11506",
                "CorpusId": 19179988
            },
            "abstract": "\n \n Over the last few years, deep learning has revolutionized the field of machine learning by dramatically improving the state-of-the-art in various domains. However, as the size of supervised artificial neural networks grows, typically so does the need for larger labeled datasets. Recently, crowdsourcing has established itself as an efficient and cost-effective solution for labeling large sets of data in a scalable manner, but it often requires aggregating labels from multiple noisy contributors with different levels of expertise. In this paper, we address the problem of learning deep neural networks from crowds. We begin by describing an EM algorithm for jointly learning the parameters of the network and the reliabilities of the annotators. Then, a novel general-purpose crowd layer is proposed, which allows us to train deep neural networks end-to-end, directly from the noisy labels of multiple annotators, using only backpropagation. We empirically show that the proposed approach is able to internally capture the reliability and biases of different annotators and achieve new state-of-the-art results for various crowdsourced datasets across different settings, namely classification, regression and sequence labeling.\n \n",
            "referenceCount": 32,
            "citationCount": 185,
            "influentialCitationCount": 43,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/11506/11365",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-09-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Rodrigues2017DeepLF,\n author = {Filipe Rodrigues and Francisco C\u00e2mara Pereira},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {1611-1618},\n title = {Deep learning from crowds},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:94eb8e46767ae77e265b0a20dcc0d9f69d2d6e2b",
            "@type": "ScholarlyArticle",
            "paperId": "94eb8e46767ae77e265b0a20dcc0d9f69d2d6e2b",
            "corpusId": 221397441,
            "url": "https://www.semanticscholar.org/paper/94eb8e46767ae77e265b0a20dcc0d9f69d2d6e2b",
            "title": "A Survey of Deep Active Learning",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2009-00236",
                "MAG": "3082269314",
                "ArXiv": "2009.00236",
                "DOI": "10.1145/3472291",
                "CorpusId": 221397441
            },
            "abstract": "Active learning (AL) attempts to maximize a model\u2019s performance gain while annotating the fewest samples possible. Deep learning (DL) is greedy for data and requires a large amount of data supply to optimize a massive number of parameters if the model is to learn how to extract high-quality features. In recent years, due to the rapid development of internet technology, we have entered an era of information abundance characterized by massive amounts of available data. As a result, DL has attracted significant attention from researchers and has been rapidly developed. Compared with DL, however, researchers have a relatively low interest in AL. This is mainly because before the rise of DL, traditional machine learning requires relatively few labeled samples, meaning that early AL is rarely according the value it deserves. Although DL has made breakthroughs in various fields, most of this success is due to a large number of publicly available annotated datasets. However, the acquisition of a large number of high-quality annotated datasets consumes a lot of manpower, making it unfeasible in fields that require high levels of expertise (such as speech recognition, information extraction, medical images, etc.). Therefore, AL is gradually coming to receive the attention it is due. It is therefore natural to investigate whether AL can be used to reduce the cost of sample annotation while retaining the powerful learning capabilities of DL. As a result of such investigations, deep active learning (DeepAL) has emerged. Although research on this topic is quite abundant, there has not yet been a comprehensive survey of DeepAL-related works; accordingly, this article aims to fill this gap. We provide a formal classification method for the existing work, along with a comprehensive and systematic overview. In addition, we also analyze and summarize the development of DeepAL from an application perspective. Finally, we discuss the confusion and problems associated with DeepAL and provide some possible development directions.",
            "referenceCount": 270,
            "citationCount": 577,
            "influentialCitationCount": 38,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2009.00236",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-08-30",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "54"
            },
            "citationStyles": {
                "bibtex": "@Article{Ren2020ASO,\n author = {Pengzhen Ren and Yun Xiao and Xiaojun Chang and Po-Yao (Bernie) Huang and Zhihui Li and Xiaojiang Chen and Xin Wang},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 40},\n title = {A Survey of Deep Active Learning},\n volume = {54},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5ffe9b1d8219438f0343995ad3ea1a888e3d9f8e",
            "@type": "ScholarlyArticle",
            "paperId": "5ffe9b1d8219438f0343995ad3ea1a888e3d9f8e",
            "corpusId": 220546541,
            "url": "https://www.semanticscholar.org/paper/5ffe9b1d8219438f0343995ad3ea1a888e3d9f8e",
            "title": "Learning From Noisy Labels With Deep Neural Networks: A Survey",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2007-08199",
                "ArXiv": "2007.08199",
                "MAG": "3042609801",
                "DOI": "10.1109/TNNLS.2022.3152527",
                "CorpusId": 220546541,
                "PubMed": "35254993"
            },
            "abstract": "Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 62 state-of-the-art robust training methods, all of which are categorized into five groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we perform an in-depth analysis of noise rate estimation and summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies.",
            "referenceCount": 191,
            "citationCount": 556,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2007.08199",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-07-16",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "34"
            },
            "citationStyles": {
                "bibtex": "@Article{Song2020LearningFN,\n author = {Hwanjun Song and Minseok Kim and Dongmin Park and Yooju Shin and Jae-Gil Lee},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {8135-8153},\n title = {Learning From Noisy Labels With Deep Neural Networks: A Survey},\n volume = {34},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5ad0521b0ed5b144e4cb7ac4c14d45aa42ebd98c",
            "@type": "ScholarlyArticle",
            "paperId": "5ad0521b0ed5b144e4cb7ac4c14d45aa42ebd98c",
            "corpusId": 36765461,
            "url": "https://www.semanticscholar.org/paper/5ad0521b0ed5b144e4cb7ac4c14d45aa42ebd98c",
            "title": "Deep Convolutional Framelets: A General Deep Learning Framework for Inverse Problems",
            "venue": "SIAM Journal of Imaging Sciences",
            "publicationVenue": {
                "id": "urn:research:7de25fc2-ec8b-4d6c-b578-bbe232d8c8f6",
                "name": "SIAM Journal of Imaging Sciences",
                "alternate_names": [
                    "Siam Journal on Imaging Sciences",
                    "Siam J Imaging Sci",
                    "SIAM J Imaging Sci"
                ],
                "issn": "1936-4954",
                "url": "http://ejournals.ebsco.com/direct.asp?JournalID=714884"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2953368766",
                "DBLP": "journals/siamis/YeHC18",
                "DOI": "10.1137/17M1141771",
                "CorpusId": 36765461
            },
            "abstract": "Recently, deep learning approaches with various network architectures have achieved significant performance improvement over existing iterative reconstruction methods in various imaging problems. H...",
            "referenceCount": 77,
            "citationCount": 274,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1707.00372",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-03",
            "journal": {
                "name": "SIAM J. Imaging Sci.",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Ye2017DeepCF,\n author = {J. C. Ye and Yoseob Han and E. Cha},\n booktitle = {SIAM Journal of Imaging Sciences},\n journal = {SIAM J. Imaging Sci.},\n pages = {991-1048},\n title = {Deep Convolutional Framelets: A General Deep Learning Framework for Inverse Problems},\n volume = {11},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2581b3e44592b3b3741474c8d6f483a90c29f139",
            "@type": "ScholarlyArticle",
            "paperId": "2581b3e44592b3b3741474c8d6f483a90c29f139",
            "corpusId": 2808403,
            "url": "https://www.semanticscholar.org/paper/2581b3e44592b3b3741474c8d6f483a90c29f139",
            "title": "Deep learning for physical processes: incorporating prior scientific knowledge",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/abs-1711-07970",
                "MAG": "2951803385",
                "ArXiv": "1711.07970",
                "DOI": "10.1088/1742-5468/ab3195",
                "CorpusId": 2808403
            },
            "abstract": "We consider the use of deep learning methods for modeling complex phenomena like those occurring in natural physical processes. With the large amount of data gathered on these phenomena the data intensive paradigm could begin to challenge more traditional approaches elaborated over the years in fields like maths or physics. However, despite considerable successes in a variety of application domains, the machine learning field is not yet ready to handle the level of complexity required by such problems. Using an example application, namely sea surface temperature prediction, we show how general background knowledge gained from the physics could be used as a guideline for designing efficient deep learning models. In order to motivate the approach and to assess its generality we demonstrate a formal link between the solution of a class of differential equations underlying a large family of physical phenomena and the proposed model. Experiments and comparison with series of baselines including a state of the art numerical approach is then provided.",
            "referenceCount": 35,
            "citationCount": 243,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1711.07970",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Physics",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-21",
            "journal": {
                "name": "Journal of Statistical Mechanics: Theory and Experiment",
                "volume": "2019"
            },
            "citationStyles": {
                "bibtex": "@Article{B\u00e9zenac2017DeepLF,\n author = {Emmanuel de B\u00e9zenac and Arthur Pajot and P. Gallinari},\n booktitle = {International Conference on Learning Representations},\n journal = {Journal of Statistical Mechanics: Theory and Experiment},\n title = {Deep learning for physical processes: incorporating prior scientific knowledge},\n volume = {2019},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:50179f1fe04b63fce815f32c9a0150c3f9dc709e",
            "@type": "ScholarlyArticle",
            "paperId": "50179f1fe04b63fce815f32c9a0150c3f9dc709e",
            "corpusId": 28301202,
            "url": "https://www.semanticscholar.org/paper/50179f1fe04b63fce815f32c9a0150c3f9dc709e",
            "title": "Online Deep Learning: Learning Deep Neural Networks on the Fly",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/ijcai/SahooPLH18",
                "ArXiv": "1711.03705",
                "MAG": "2767677737",
                "DOI": "10.24963/ijcai.2018/369",
                "CorpusId": 28301202
            },
            "abstract": "Deep Neural Networks (DNNs) are typically trained by backpropagation in a batch setting, requiring the entire training data to be made available prior to the learning task. This is not scalable for many real-world scenarios where new data arrives sequentially in a stream. We aim to address an open challenge of ``Online Deep Learning\" (ODL) for learning DNNs on the fly in an online setting. Unlike traditional online learning that often optimizes some convex objective function with respect to a shallow model (e.g., a linear/kernel-based hypothesis), ODL is more challenging as the optimization objective is non-convex, and regular DNN with standard backpropagation does not work well in practice for online settings. We present a new ODL framework that attempts to tackle the challenges by learning DNN models which dynamically adapt depth from a sequence of training data in an online learning setting. Specifically, we propose a novel Hedge Backpropagation (HBP) method for online updating the parameters of DNN effectively, and validate the efficacy on large data sets (both stationary and concept drifting scenarios).",
            "referenceCount": 52,
            "citationCount": 241,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.ijcai.org/proceedings/2018/0369.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-11-10",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1711.03705"
            },
            "citationStyles": {
                "bibtex": "@Article{Sahoo2017OnlineDL,\n author = {Doyen Sahoo and Quang Pham and Jing Lu and S. Hoi},\n booktitle = {International Joint Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {Online Deep Learning: Learning Deep Neural Networks on the Fly},\n volume = {abs/1711.03705},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fea535fd5abce9b47ebeb5d73ac3d70325e6c686",
            "@type": "ScholarlyArticle",
            "paperId": "fea535fd5abce9b47ebeb5d73ac3d70325e6c686",
            "corpusId": 21288754,
            "url": "https://www.semanticscholar.org/paper/fea535fd5abce9b47ebeb5d73ac3d70325e6c686",
            "title": "Routing or Computing? The Paradigm Shift Towards Intelligent Computer Network Packet Transmission Based on Deep Learning",
            "venue": "IEEE transactions on computers",
            "publicationVenue": {
                "id": "urn:research:42cd70f7-45f1-4f5a-9723-42d222d6c56e",
                "name": "IEEE transactions on computers",
                "alternate_names": [
                    "IEEE Transactions on Computers",
                    "IEEE Trans Comput",
                    "IEEE trans comput"
                ],
                "issn": "0018-9340",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=12"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2620303912",
                "DBLP": "journals/tc/MaoFTKAIM17",
                "DOI": "10.1109/TC.2017.2709742",
                "CorpusId": 21288754
            },
            "abstract": "Recent years, Software Defined Routers (SDRs) (programmable routers) have emerged as a viable solution to provide a cost-effective packet processing platform with easy extensibility and programmability. Multi-core platforms significantly promote SDRs\u2019 parallel computing capacities, enabling them to adopt artificial intelligent techniques, i.e., deep learning, to manage routing paths. In this paper, we explore new opportunities in packet processing with deep learning to inexpensively shift the computing needs from rule-based route computation to deep learning based route estimation for high-throughput packet processing. Even though deep learning techniques have been extensively exploited in various computing areas, researchers have, to date, not been able to effectively utilize deep learning based route computation for high-speed core networks. We envision a supervised deep learning system to construct the routing tables and show how the proposed method can be integrated with programmable routers using both Central Processing Units (CPUs) and Graphics Processing Units (GPUs). We demonstrate how our uniquely characterized input and output traffic patterns can enhance the route computation of the deep learning based SDRs through both analysis and extensive computer simulations. In particular, the simulation results demonstrate that our proposal outperforms the benchmark method in terms of delay, throughput, and signaling overhead.",
            "referenceCount": 35,
            "citationCount": 262,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-01",
            "journal": {
                "name": "IEEE Transactions on Computers",
                "volume": "66"
            },
            "citationStyles": {
                "bibtex": "@Article{Mao2017RoutingOC,\n author = {Bomin Mao and Z. Fadlullah and Fengxiao Tang and N. Kato and Osamu Akashi and Takeru Inoue and Kimihiro Mizutani},\n booktitle = {IEEE transactions on computers},\n journal = {IEEE Transactions on Computers},\n pages = {1946-1960},\n title = {Routing or Computing? The Paradigm Shift Towards Intelligent Computer Network Packet Transmission Based on Deep Learning},\n volume = {66},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1ab4f6fc570b21756793cb286e8cdeb37736f858",
            "@type": "ScholarlyArticle",
            "paperId": "1ab4f6fc570b21756793cb286e8cdeb37736f858",
            "corpusId": 206757506,
            "url": "https://www.semanticscholar.org/paper/1ab4f6fc570b21756793cb286e8cdeb37736f858",
            "title": "On Deep Learning for Trust-Aware Recommendations in Social Networks",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2343644403",
                "DBLP": "journals/tnn/DengHXWW17",
                "DOI": "10.1109/TNNLS.2016.2514368",
                "CorpusId": 206757506,
                "PubMed": "26915135"
            },
            "abstract": "With the emergence of online social networks, the social network-based recommendation approach is popularly used. The major benefit of this approach is the ability of dealing with the problems with cold-start users. In addition to social networks, user trust information also plays an important role to obtain reliable recommendations. Although matrix factorization (MF) becomes dominant in recommender systems, the recommendation largely relies on the initialization of the user and item latent feature vectors. Aiming at addressing these challenges, we develop a novel trust-based approach for recommendation in social networks. In particular, we attempt to leverage deep learning to determinate the initialization in MF for trust-aware social recommendations and to differentiate the community effect in user\u2019s trusted friendships. A two-phase recommendation process is proposed to utilize deep learning in initialization and to synthesize the users\u2019 interests and their trusted friends\u2019 interests together with the impact of community effect for recommendations. We perform extensive experiments on real-world social network data to demonstrate the accuracy and effectiveness of our proposed approach in comparison with other state-of-the-art methods.",
            "referenceCount": 41,
            "citationCount": 262,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-05-01",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "28"
            },
            "citationStyles": {
                "bibtex": "@Article{Deng2017OnDL,\n author = {Shuiguang Deng and Longtao Huang and Guandong Xu and Xindong Wu and Zhaohui Wu},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {1164-1177},\n title = {On Deep Learning for Trust-Aware Recommendations in Social Networks},\n volume = {28},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9c11b1552748c697bbfd33c157f7b7875686eb10",
            "@type": "ScholarlyArticle",
            "paperId": "9c11b1552748c697bbfd33c157f7b7875686eb10",
            "corpusId": 4012493,
            "url": "https://www.semanticscholar.org/paper/9c11b1552748c697bbfd33c157f7b7875686eb10",
            "title": "Application of deep learning in object detection",
            "venue": "International Conference on Interaction Sciences",
            "publicationVenue": {
                "id": "urn:research:60c45ccc-5528-42eb-85a9-7606a3d9b220",
                "name": "International Conference on Interaction Sciences",
                "alternate_names": [
                    "Annual ACIS International Conference on Computer and Information Science",
                    "IEEE/ACIS International Conference on Computer and Information Science",
                    "International Conference on Intelligent Systems",
                    "Annu ACIS Int Conf Comput Inf Sci",
                    "International Conference on Information Systems",
                    "Int Conf Interact Sci",
                    "ICIS",
                    "Int Conf Internet Comput Inf Serv",
                    "Int Conf Intell Syst",
                    "IEEE/ACIS Int Conf Comput Inf Sci",
                    "Int Conf Inf Syst",
                    "International Conference on Internet Computing and Information Services"
                ],
                "issn": null,
                "url": "https://web.archive.org/web/*/http://www.aicit.org/icis/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/ACISicis/ZhouGFD17",
                "MAG": "2727887115",
                "DOI": "10.1109/ICIS.2017.7960069",
                "CorpusId": 4012493
            },
            "abstract": "This paper deals with the field of computer vision, mainly for the application of deep learning in object detection task. On the one hand, there is a simple summary of the datasets and deep learning algorithms commonly used in computer vision. On the other hand, a new dataset is built according to those commonly used datasets, and choose one of the network called faster r-cnn to work on this new dataset. Through the experiment to strengthen the understanding of these networks, and through the analysis of the results learn the importance of deep learning technology, and the importance of the dataset for deep learning.",
            "referenceCount": 13,
            "citationCount": 281,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-05-24",
            "journal": {
                "name": "2017 IEEE/ACIS 16th International Conference on Computer and Information Science (ICIS)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhou2017ApplicationOD,\n author = {Xinyi Zhou and Wei Gong and W. Fu and Fengtong Du},\n booktitle = {International Conference on Interaction Sciences},\n journal = {2017 IEEE/ACIS 16th International Conference on Computer and Information Science (ICIS)},\n pages = {631-634},\n title = {Application of deep learning in object detection},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ce2df898e84bd8815cc3b5a3bd079f069438393f",
            "@type": "ScholarlyArticle",
            "paperId": "ce2df898e84bd8815cc3b5a3bd079f069438393f",
            "corpusId": 39172764,
            "url": "https://www.semanticscholar.org/paper/ce2df898e84bd8815cc3b5a3bd079f069438393f",
            "title": "Disease detection on the leaves of the tomato plants by using deep learning",
            "venue": "International Conference on Agro-Geoinformatics",
            "publicationVenue": {
                "id": "urn:research:4bbf5bf8-63dd-44c7-a46b-00949c8026bd",
                "name": "International Conference on Agro-Geoinformatics",
                "alternate_names": [
                    "Int Conf Agro-geoinformatics",
                    "Agro-geoinformatics",
                    "Agro-Geoinformatics"
                ],
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2758893285",
                "DBLP": "conf/agro-geoinformatics/DurmusGK17",
                "DOI": "10.1109/AGRO-GEOINFORMATICS.2017.8047016",
                "CorpusId": 39172764
            },
            "abstract": "The aim of this work is to detect diseases that occur on plants in tomato fields or in their greenhouses. For this purpose, deep learning was used to detect the various diseases on the leaves of tomato plants. In the study, it was aimed that the deep learning algorithm should be run in real time on the robot. So the robot will be able to detect the diseases of the plants while wandering manually or autonomously on the field or in the greenhouse. Likewise, diseases can also be detected from close-up photographs taken from plants by sensors built in fabricated greenhouses. The examined diseases in this study cause physical changes in the leaves of the tomato plant. These changes on the leaves can be seen with RGB cameras. In the previous studies, standard feature extraction methods on plant leaf images to detect diseases have been used. In this study, deep learning methods were used to detect diseases. Deep learning architecture selection was the key issue for the implementation. So that, two different deep learning network architectures were tested first AlexNet and then SqueezeNet. For both of these deep learning networks training and validation were done on the Nvidia Jetson TX1. Tomato leaf images from the PlantVillage dataset has been used for the training. Ten different classes including healthy images are used. Trained networks are also tested on the images from the internet.",
            "referenceCount": 13,
            "citationCount": 260,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-08-01",
            "journal": {
                "name": "2017 6th International Conference on Agro-Geoinformatics",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Durmus2017DiseaseDO,\n author = {Halil Durmus and Ece Olcay G\u00fcnes and M. Kirci},\n booktitle = {International Conference on Agro-Geoinformatics},\n journal = {2017 6th International Conference on Agro-Geoinformatics},\n pages = {1-5},\n title = {Disease detection on the leaves of the tomato plants by using deep learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f152cfd441a52c9ceb2ae724d601fb4fb9ec77ea",
            "@type": "ScholarlyArticle",
            "paperId": "f152cfd441a52c9ceb2ae724d601fb4fb9ec77ea",
            "corpusId": 8689292,
            "url": "https://www.semanticscholar.org/paper/f152cfd441a52c9ceb2ae724d601fb4fb9ec77ea",
            "title": "Regularization for Deep Learning: A Taxonomy",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2766151966",
                "DBLP": "journals/corr/abs-1710-10686",
                "ArXiv": "1710.10686",
                "CorpusId": 8689292
            },
            "abstract": "Regularization is one of the crucial ingredients of deep learning, yet the term regularization has various definitions, and regularization methods are often studied separately from each other. In our work we present a systematic, unifying taxonomy to categorize existing methods. We distinguish methods that affect data, network architectures, error terms, regularization terms, and optimization procedures. We do not provide all details about the listed methods; instead, we present an overview of how the methods can be sorted into meaningful categories and sub-categories. This helps revealing links and fundamental similarities between them. Finally, we include practical recommendations both for users and for developers of new regularization methods.",
            "referenceCount": 123,
            "citationCount": 267,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-10-29",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1710.10686"
            },
            "citationStyles": {
                "bibtex": "@Article{Kuka\u010dka2017RegularizationFD,\n author = {J. Kuka\u010dka and Vladimir Golkov and D. Cremers},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Regularization for Deep Learning: A Taxonomy},\n volume = {abs/1710.10686},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:58eb6ed4667dd044698d70e127577655c227ba19",
            "@type": "ScholarlyArticle",
            "paperId": "58eb6ed4667dd044698d70e127577655c227ba19",
            "corpusId": 2958701,
            "url": "https://www.semanticscholar.org/paper/58eb6ed4667dd044698d70e127577655c227ba19",
            "title": "A Review of Deep Learning Methods and Applications for Unmanned Aerial Vehicles",
            "venue": "J. Sensors",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/js/CarrioSRC17",
                "MAG": "2746411854",
                "DOI": "10.1155/2017/3296874",
                "CorpusId": 2958701
            },
            "abstract": "Deep learning is recently showing outstanding results for solving a wide variety of robotic tasks in the areas of perception, planning, localization, and control. Its excellent capabilities for learning representations from the complex data acquired in real environments make it extremely suitable for many kinds of autonomous robotic applications. In parallel, Unmanned Aerial Vehicles (UAVs) are currently being extensively applied for several types of civilian tasks in applications going from security, surveillance, and disaster rescue to parcel delivery or warehouse management. In this paper, a thorough review has been performed on recent reported uses and applications of deep learning for UAVs, including the most relevant developments as well as their performances and limitations. In addition, a detailed explanation of the main deep learning techniques is provided. We conclude with a description of the main challenges for the application of deep learning for UAV-based solutions.",
            "referenceCount": 76,
            "citationCount": 266,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://downloads.hindawi.com/journals/js/2017/3296874.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-08-14",
            "journal": {
                "name": "J. Sensors",
                "volume": "2017"
            },
            "citationStyles": {
                "bibtex": "@Article{Carrio2017ARO,\n author = {Adrian Carrio and Carlos Sampedro and Alejandro Rodriguez-Ramos and P. Cervera},\n booktitle = {J. Sensors},\n journal = {J. Sensors},\n pages = {3296874:1-3296874:13},\n title = {A Review of Deep Learning Methods and Applications for Unmanned Aerial Vehicles},\n volume = {2017},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:82024003820d52ef344fb210d050f469f60ddf4b",
            "@type": "ScholarlyArticle",
            "paperId": "82024003820d52ef344fb210d050f469f60ddf4b",
            "corpusId": 31472276,
            "url": "https://www.semanticscholar.org/paper/82024003820d52ef344fb210d050f469f60ddf4b",
            "title": "Breaking Cryptographic Implementations Using Deep Learning Techniques",
            "venue": "SPACE",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2952249424",
                "DBLP": "journals/iacr/MaghrebiPP16",
                "DOI": "10.1007/978-3-319-49445-6_1",
                "CorpusId": 31472276
            },
            "abstract": null,
            "referenceCount": 55,
            "citationCount": 394,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-12-14",
            "journal": {
                "name": "IACR Cryptol. ePrint Arch.",
                "volume": "2016"
            },
            "citationStyles": {
                "bibtex": "@Article{Maghrebi2016BreakingCI,\n author = {Houssem Maghrebi and Thibault Portigliatti and E. Prouff},\n booktitle = {SPACE},\n journal = {IACR Cryptol. ePrint Arch.},\n pages = {921},\n title = {Breaking Cryptographic Implementations Using Deep Learning Techniques},\n volume = {2016},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5285cb8faada5de8a92a47622950f6cfd476ac1d",
            "@type": "ScholarlyArticle",
            "paperId": "5285cb8faada5de8a92a47622950f6cfd476ac1d",
            "corpusId": 54457299,
            "url": "https://www.semanticscholar.org/paper/5285cb8faada5de8a92a47622950f6cfd476ac1d",
            "title": "Off-Policy Deep Reinforcement Learning without Exploration",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1812.02900",
                "MAG": "2904453761",
                "DBLP": "conf/icml/FujimotoMP19",
                "CorpusId": 54457299
            },
            "abstract": "Many practical applications of reinforcement learning constrain agents to learn from a fixed batch of data which has already been gathered, without offering further possibility for data collection. In this paper, we demonstrate that due to errors introduced by extrapolation, standard off-policy deep reinforcement learning algorithms, such as DQN and DDPG, are incapable of learning with data uncorrelated to the distribution under the current policy, making them ineffective for this fixed batch setting. We introduce a novel class of off-policy algorithms, batch-constrained reinforcement learning, which restricts the action space in order to force the agent towards behaving close to on-policy with respect to a subset of the given data. We present the first continuous control deep reinforcement learning algorithm which can learn effectively from arbitrary, fixed batch data, and empirically demonstrate the quality of its behavior in several tasks.",
            "referenceCount": 88,
            "citationCount": 1038,
            "influentialCitationCount": 287,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-12-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Fujimoto2018OffPolicyDR,\n author = {Scott Fujimoto and D. Meger and Doina Precup},\n booktitle = {International Conference on Machine Learning},\n pages = {2052-2062},\n title = {Off-Policy Deep Reinforcement Learning without Exploration},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2dec4f52b1ce552b416f086d4ea1040626675dfa",
            "@type": "ScholarlyArticle",
            "paperId": "2dec4f52b1ce552b416f086d4ea1040626675dfa",
            "corpusId": 1994856,
            "url": "https://www.semanticscholar.org/paper/2dec4f52b1ce552b416f086d4ea1040626675dfa",
            "title": "Toward an Integration of Deep Learning and Neuroscience",
            "venue": "bioRxiv",
            "publicationVenue": {
                "id": "urn:research:027ffd21-ebb0-4af8-baf5-911124292fd0",
                "name": "bioRxiv",
                "alternate_names": null,
                "issn": null,
                "url": "http://biorxiv.org/"
            },
            "year": 2016,
            "externalIds": {
                "PubMedCentral": "5021692",
                "MAG": "2951261849",
                "DBLP": "journals/ficn/MarblestoneWK16",
                "ArXiv": "1606.03813",
                "DOI": "10.3389/fncom.2016.00094",
                "CorpusId": 1994856,
                "PubMed": "27683554"
            },
            "abstract": "Neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. In machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. Two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. First, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. Second, cost functions and training procedures have become more complex and are varied across layers and over time. Here we think about the brain in terms of these ideas. We hypothesize that (1) the brain optimizes cost functions, (2) the cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. In support of these hypotheses, we argue that a range of implementations of credit assignment through multiple layers of neurons are compatible with our current knowledge of neural circuitry, and that the brain\u2019s specialized systems can be interpreted as enabling efficient optimization for specific problem classes. Such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. We suggest directions by which neuroscience could seek to refine and test these hypotheses.",
            "referenceCount": 544,
            "citationCount": 553,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.frontiersin.org/articles/10.3389/fncom.2016.00094/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Biology",
                "Medicine",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-06-13",
            "journal": {
                "name": "Frontiers in Computational Neuroscience",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Marblestone2016TowardAI,\n author = {Adam H. Marblestone and Greg Wayne and Konrad Paul Kording},\n booktitle = {bioRxiv},\n journal = {Frontiers in Computational Neuroscience},\n title = {Toward an Integration of Deep Learning and Neuroscience},\n volume = {10},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:67156902beca9bc90b728c8d5dd4ac9d8b27d3a3",
            "@type": "ScholarlyArticle",
            "paperId": "67156902beca9bc90b728c8d5dd4ac9d8b27d3a3",
            "corpusId": 40821847,
            "url": "https://www.semanticscholar.org/paper/67156902beca9bc90b728c8d5dd4ac9d8b27d3a3",
            "title": "Chainer : a Next-Generation Open Source Framework for Deep Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2967745648",
                "CorpusId": 40821847
            },
            "abstract": "Software frameworks for neural networks play key roles in the development and application of deep learning methods. However, as new types of deep learning models are developed, existing frameworks designed for convolutional neural networks are becoming less useful. In this paper, we introduce Chainer, a Python-based, standalone open source framework for deep learning models. Chainer provides a \ufb02exible, intuitive, and high performance means of implementing a full range of deep learning models, including state-of-the-art models such as recurrent neural networks and variational autoencoders.",
            "referenceCount": 24,
            "citationCount": 779,
            "influentialCitationCount": 72,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Tokui2015ChainerA,\n author = {Seiya Tokui and Kenta Oono},\n title = {Chainer : a Next-Generation Open Source Framework for Deep Learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:54f83d9db83a87059e6ebde6304493a2953877a9",
            "@type": "ScholarlyArticle",
            "paperId": "54f83d9db83a87059e6ebde6304493a2953877a9",
            "corpusId": 3813318,
            "url": "https://www.semanticscholar.org/paper/54f83d9db83a87059e6ebde6304493a2953877a9",
            "title": "Deep learning approach for active classification of electrocardiogram signals",
            "venue": "Information Sciences",
            "publicationVenue": {
                "id": "urn:research:e46002a1-d7a6-4681-aae9-36bc3a6a1f93",
                "name": "Information Sciences",
                "alternate_names": [
                    "Information Scientist",
                    "Inf Sci"
                ],
                "issn": "0020-0255",
                "url": "http://www.sciencedirect.com/science/journal/00200255"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2289846183",
                "DBLP": "journals/isci/RahhalBAAMY16",
                "DOI": "10.1016/j.ins.2016.01.082",
                "CorpusId": 3813318
            },
            "abstract": null,
            "referenceCount": 65,
            "citationCount": 526,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://iris.unitn.it/bitstream/11572/154241/4/Deep%20learning...%20Postprint.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-06-01",
            "journal": {
                "name": "Inf. Sci.",
                "volume": "345"
            },
            "citationStyles": {
                "bibtex": "@Article{Rahhal2016DeepLA,\n author = {Mohamad Mahmoud Al Rahhal and Y. Bazi and H. Alhichri and N. Alajlan and F. Melgani and R. Yager},\n booktitle = {Information Sciences},\n journal = {Inf. Sci.},\n pages = {340-354},\n title = {Deep learning approach for active classification of electrocardiogram signals},\n volume = {345},\n year = {2016}\n}\n"
            }
        }
    }
]