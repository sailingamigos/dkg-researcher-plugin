[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c48e85a7a4ed7895096ae074a6c544415e6c4b85",
            "@type": "ScholarlyArticle",
            "paperId": "c48e85a7a4ed7895096ae074a6c544415e6c4b85",
            "corpusId": 3353375,
            "url": "https://www.semanticscholar.org/paper/c48e85a7a4ed7895096ae074a6c544415e6c4b85",
            "title": "RAPID: Rating Pictorial Aesthetics using Deep Learning",
            "venue": "ACM Multimedia",
            "publicationVenue": {
                "id": "urn:research:f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                "name": "ACM Multimedia",
                "alternate_names": [
                    "MM"
                ],
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/mm/LuLJYW14",
                "MAG": "2009678853",
                "DOI": "10.1145/2647868.2654927",
                "CorpusId": 3353375
            },
            "abstract": "Effective visual features are essential for computational aesthetic quality rating systems. Existing methods used machine learning and statistical modeling techniques on handcrafted features or generic image descriptors. A recently-published large-scale dataset, the AVA dataset, has further empowered machine learning based approaches. We present the RAPID (RAting PIctorial aesthetics using Deep learning) system, which adopts a novel deep neural network approach to enable automatic feature learning. The central idea is to incorporate heterogeneous inputs generated from the image, which include a global view and a local view, and to unify the feature learning and classifier training using a double-column deep convolutional neural network. In addition, we utilize the style attributes of images to help improve the aesthetic quality categorization accuracy. Experimental results show that our approach significantly outperforms the state of the art on the AVA dataset.",
            "referenceCount": 33,
            "citationCount": 349,
            "influentialCitationCount": 49,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Art",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2014-11-03",
            "journal": {
                "name": "Proceedings of the 22nd ACM international conference on Multimedia",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Lu2014RAPIDRP,\n author = {Xin Lu and Zhe L. Lin and Hailin Jin and Jianchao Yang and J. Z. Wang},\n booktitle = {ACM Multimedia},\n journal = {Proceedings of the 22nd ACM international conference on Multimedia},\n title = {RAPID: Rating Pictorial Aesthetics using Deep Learning},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6ff50528f3d7c72772f8c0e3f8398f9dd8e06575",
            "@type": "ScholarlyArticle",
            "paperId": "6ff50528f3d7c72772f8c0e3f8398f9dd8e06575",
            "corpusId": 166228022,
            "url": "https://www.semanticscholar.org/paper/6ff50528f3d7c72772f8c0e3f8398f9dd8e06575",
            "title": "Adversarial Policies: Attacking Deep Reinforcement Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1905.10615",
                "MAG": "2945924974",
                "DBLP": "conf/iclr/GleaveDWKLR20",
                "CorpusId": 166228022
            },
            "abstract": "Deep reinforcement learning (RL) policies are known to be vulnerable to adversarial perturbations to their observations, similar to adversarial examples for classifiers. However, an attacker is not usually able to directly modify another agent's observations. This might lead one to wonder: is it possible to attack an RL agent simply by choosing an adversarial policy acting in a multi-agent environment so as to create natural observations that are adversarial? We demonstrate the existence of adversarial policies in zero-sum games between simulated humanoid robots with proprioceptive observations, against state-of-the-art victims trained via self-play to be robust to opponents. The adversarial policies reliably win against the victims but generate seemingly random and uncoordinated behavior. We find that these policies are more successful in high-dimensional environments, and induce substantially different activations in the victim policy network than when the victim plays against a normal opponent. Videos are available at this https URL.",
            "referenceCount": 39,
            "citationCount": 275,
            "influentialCitationCount": 38,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-05-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1905.10615"
            },
            "citationStyles": {
                "bibtex": "@Article{Gleave2019AdversarialPA,\n author = {A. Gleave and Michael Dennis and Neel Kant and Cody Wild and S. Levine and Stuart J. Russell},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Adversarial Policies: Attacking Deep Reinforcement Learning},\n volume = {abs/1905.10615},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6a61b4967c161347525abc3ab5dba590c0cd99ca",
            "@type": "ScholarlyArticle",
            "paperId": "6a61b4967c161347525abc3ab5dba590c0cd99ca",
            "corpusId": 9909874,
            "url": "https://www.semanticscholar.org/paper/6a61b4967c161347525abc3ab5dba590c0cd99ca",
            "title": "Analysis of function of rectified linear unit used in deep learning",
            "venue": "IEEE International Joint Conference on Neural Network",
            "publicationVenue": {
                "id": "urn:research:f80ba4a3-7aed-4021-b4d8-e4f50668847a",
                "name": "IEEE International Joint Conference on Neural Network",
                "alternate_names": [
                    "IJCNN",
                    "IEEE Int Jt Conf Neural Netw",
                    "Int Jt Conf Neural Netw",
                    "International Joint Conference on Neural Network"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=1573"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/ijcnn/HaraSS15",
                "MAG": "1921848483",
                "DOI": "10.1109/IJCNN.2015.7280578",
                "CorpusId": 9909874
            },
            "abstract": "Deep Learning is attracting much attention in object recognition and speech processing. A benefit of using the deep learning is that it provides automatic pre-training. Several proposed methods that include auto-encoder are being successfully used in various applications. Moreover, deep learning uses a multilayer network that consists of many layers, a huge number of units, and huge amount of data. Thus, executing deep learning requires heavy computation, so deep learning is usually utilized with parallel computation with many cores or many machines. Deep learning employs the gradient algorithm, however this traps the learning into the saddle point or local minima. To avoid this difficulty, a rectified linear unit (ReLU) is proposed to speed up the learning convergence. However, the reasons the convergence is speeded up are not well understood. In this paper, we analyze the ReLU by a using simpler network called the soft-committee machine and clarify the reason for the speedup. We also train the network in an on-line manner. The soft-committee machine provides a good test bed to analyze deep learning. The results provide some reasons for the speedup of the convergence of the deep learning.",
            "referenceCount": 17,
            "citationCount": 264,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-07-12",
            "journal": {
                "name": "2015 International Joint Conference on Neural Networks (IJCNN)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hara2015AnalysisOF,\n author = {K. Hara and Daisuke Saitoh and Hayaru Shouno},\n booktitle = {IEEE International Joint Conference on Neural Network},\n journal = {2015 International Joint Conference on Neural Networks (IJCNN)},\n pages = {1-8},\n title = {Analysis of function of rectified linear unit used in deep learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c55c00a9f13b296a27c71d064639b64ef638bfca",
            "@type": "ScholarlyArticle",
            "paperId": "c55c00a9f13b296a27c71d064639b64ef638bfca",
            "corpusId": 7733262,
            "url": "https://www.semanticscholar.org/paper/c55c00a9f13b296a27c71d064639b64ef638bfca",
            "title": "A Deep Learning Network Approach to ab initio Protein Secondary Structure Prediction",
            "venue": "IEEE/ACM Transactions on Computational Biology & Bioinformatics",
            "publicationVenue": {
                "id": "urn:research:dc4a9aad-72db-4530-a183-eaa4bf1d4490",
                "name": "IEEE/ACM Transactions on Computational Biology & Bioinformatics",
                "alternate_names": [
                    "IEEE/ACM Trans Comput Biology  Bioinform",
                    "IEEE/ACM Trans Comput Biology Bioinform",
                    "IEEE/ACM Transactions on Computational Biology and Bioinformatics"
                ],
                "issn": "1545-5963",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=8857"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2059136964",
                "DBLP": "journals/tcbb/SpencerEC15",
                "DOI": "10.1109/TCBB.2014.2343960",
                "CorpusId": 7733262,
                "PubMed": "25750595"
            },
            "abstract": "Ab initio protein secondary structure (SS) predictions are utilized to generate tertiary structure predictions, which are increasingly demanded due to the rapid discovery of proteins. Although recent developments have slightly exceeded previous methods of SS prediction, accuracy has stagnated around 80 percent and many wonder if prediction cannot be advanced beyond this ceiling. Disciplines that have traditionally employed neural networks are experimenting with novel deep learning techniques in attempts to stimulate progress. Since neural networks have historically played an important role in SS prediction, we wanted to determine whether deep learning could contribute to the advancement of this field as well. We developed an SS predictor that makes use of the position-specific scoring matrix generated by PSI-BLAST and deep learning network architectures, which we call DNSS. Graphical processing units and CUDA software optimize the deep network architecture and efficiently train the deep networks. Optimal parameters for the training process were determined, and a workflow comprising three separately trained deep networks was constructed in order to make refined predictions. This deep learning network approach was used to predict SS for a fully independent test dataset of 198 proteins, achieving a Q3 accuracy of 80.7 percent and a Sov accuracy of 74.2 percent.",
            "referenceCount": 53,
            "citationCount": 263,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc4348072?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE/ACM Transactions on Computational Biology and Bioinformatics",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Spencer2015ADL,\n author = {Matthew Spencer and Jesse Eickholt and Jianlin Cheng},\n booktitle = {IEEE/ACM Transactions on Computational Biology & Bioinformatics},\n journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},\n pages = {103-112},\n title = {A Deep Learning Network Approach to ab initio Protein Secondary Structure Prediction},\n volume = {12},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fa54b47df8641dff1579b5e8e0f18f057de68e73",
            "@type": "ScholarlyArticle",
            "paperId": "fa54b47df8641dff1579b5e8e0f18f057de68e73",
            "corpusId": 4900548,
            "url": "https://www.semanticscholar.org/paper/fa54b47df8641dff1579b5e8e0f18f057de68e73",
            "title": "DRN: A Deep Reinforcement Learning Framework for News Recommendation",
            "venue": "The Web Conference",
            "publicationVenue": {
                "id": "urn:research:e07422f9-c065-40c3-a37b-75e98dce79fe",
                "name": "The Web Conference",
                "alternate_names": [
                    "Web Conf",
                    "WWW"
                ],
                "issn": null,
                "url": "http://www.iw3c2.org/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/www/ZhengZZXY0L18",
                "MAG": "2787933113",
                "DOI": "10.1145/3178876.3185994",
                "CorpusId": 4900548
            },
            "abstract": "In this paper, we propose a novel Deep Reinforcement Learning framework for news recommendation. Online personalized news recommendation is a highly challenging problem due to the dynamic nature of news features and user preferences. Although some online recommendation models have been proposed to address the dynamic nature of news recommendation, these methods have three major issues. First, they only try to model current reward (e.g., Click Through Rate). Second, very few studies consider to use user feedback other than click / no click labels (e.g., how frequent user returns) to help improve recommendation. Third, these methods tend to keep recommending similar news to users, which may cause users to get bored. Therefore, to address the aforementioned challenges, we propose a Deep Q-Learning based recommendation framework, which can model future reward explicitly. We further consider user return pattern as a supplement to click / no click label in order to capture more user feedback information. In addition, an effective exploration strategy is incorporated to find new attractive news for users. Extensive experiments are conducted on the offline dataset and online production environment of a commercial news recommendation application and have shown the superior performance of our methods.",
            "referenceCount": 53,
            "citationCount": 546,
            "influentialCitationCount": 46,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=3185994&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-04-10",
            "journal": {
                "name": "Proceedings of the 2018 World Wide Web Conference",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Zheng2018DRNAD,\n author = {Guanjie Zheng and Fuzheng Zhang and Zihan Zheng and Yang Xiang and Nicholas Jing Yuan and Xing Xie and Z. Li},\n booktitle = {The Web Conference},\n journal = {Proceedings of the 2018 World Wide Web Conference},\n title = {DRN: A Deep Reinforcement Learning Framework for News Recommendation},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca7f25ac119e2d706e51a63f6178f1547a863bcc",
            "@type": "ScholarlyArticle",
            "paperId": "ca7f25ac119e2d706e51a63f6178f1547a863bcc",
            "corpusId": 5621262,
            "url": "https://www.semanticscholar.org/paper/ca7f25ac119e2d706e51a63f6178f1547a863bcc",
            "title": "Deep learning for monaural speech separation",
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "publicationVenue": {
                "id": "urn:research:0d6f7fba-7092-46b3-8039-93458dba736b",
                "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                "alternate_names": [
                    "Int Conf Acoust Speech Signal Process",
                    "IEEE Int Conf Acoust Speech Signal Process",
                    "ICASSP",
                    "International Conference on Acoustics, Speech, and Signal Processing"
                ],
                "issn": null,
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2031647436",
                "DBLP": "conf/icassp/HuangKHS14",
                "DOI": "10.1109/ICASSP.2014.6853860",
                "CorpusId": 5621262
            },
            "abstract": "Monaural source separation is useful for many real-world applications though it is a challenging problem. In this paper, we study deep learning for monaural speech separation. We propose the joint optimization of the deep learning models (deep neural networks and recurrent neural networks) with an extra masking layer, which enforces a reconstruction constraint. Moreover, we explore a discriminative training criterion for the neural networks to further enhance the separation performance. We evaluate our approaches using the TIMIT speech corpus for a monaural speech separation task. Our proposed models achieve about 3.8~4.9 dB SIR gain compared to NMF models, while maintaining better SDRs and SARs.",
            "referenceCount": 16,
            "citationCount": 420,
            "influentialCitationCount": 36,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.isle.illinois.edu/sst/pubs/2014/huang14icassp.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-05-04",
            "journal": {
                "name": "2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2014DeepLF,\n author = {Po-Sen Huang and Minje Kim and M. Hasegawa-Johnson and P. Smaragdis},\n booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},\n journal = {2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n pages = {1562-1566},\n title = {Deep learning for monaural speech separation},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:86da68568ad3c22154f56f4f821ba7954109c11c",
            "@type": "ScholarlyArticle",
            "paperId": "86da68568ad3c22154f56f4f821ba7954109c11c",
            "corpusId": 15197911,
            "url": "https://www.semanticscholar.org/paper/86da68568ad3c22154f56f4f821ba7954109c11c",
            "title": "Pushing the Boundaries of Boundary Detection using Deep Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2286725469",
                "ArXiv": "1511.07386",
                "CorpusId": 15197911
            },
            "abstract": "In this work we show that adapting Deep Convolutional Neural Network training to the task of boundary detection can result in substantial improvements over the current state-of-the-art in boundary detection. \nOur contributions consist firstly in combining a careful design of the loss for boundary detection training, a multi-resolution architecture and training with external data to improve the detection accuracy of the current state of the art. When measured on the standard Berkeley Segmentation Dataset, we improve theoptimal dataset scale F-measure from 0.780 to 0.808 - while human performance is at 0.803. We further improve performance to 0.813 by combining deep learning with grouping, integrating the Normalized Cuts technique within a deep network. \nWe also examine the potential of our boundary detector in conjunction with the task of semantic segmentation and demonstrate clear improvements over state-of-the-art systems. Our detector is fully integrated in the popular Caffe framework and processes a 320x420 image in less than a second.",
            "referenceCount": 47,
            "citationCount": 212,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2015-11-23",
            "journal": {
                "name": "arXiv: Computer Vision and Pattern Recognition",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Kokkinos2015PushingTB,\n author = {Iasonas Kokkinos},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Computer Vision and Pattern Recognition},\n title = {Pushing the Boundaries of Boundary Detection using Deep Learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bca0ab6d69c820263865a17e183c952f3ff5aae7",
            "@type": "ScholarlyArticle",
            "paperId": "bca0ab6d69c820263865a17e183c952f3ff5aae7",
            "corpusId": 8094713,
            "url": "https://www.semanticscholar.org/paper/bca0ab6d69c820263865a17e183c952f3ff5aae7",
            "title": "Audio-visual speech recognition using deep learning",
            "venue": "Applied intelligence (Boston)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2076462394",
                "DBLP": "journals/apin/NodaYNOO15",
                "DOI": "10.1007/s10489-014-0629-7",
                "CorpusId": 8094713
            },
            "abstract": null,
            "referenceCount": 54,
            "citationCount": 473,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s10489-014-0629-7.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-12-20",
            "journal": {
                "name": "Applied Intelligence",
                "volume": "42"
            },
            "citationStyles": {
                "bibtex": "@Article{Noda2014AudiovisualSR,\n author = {K. Noda and Yuki Yamaguchi and K. Nakadai and HIroshi G. Okuno and T. Ogata},\n booktitle = {Applied intelligence (Boston)},\n journal = {Applied Intelligence},\n pages = {722 - 737},\n title = {Audio-visual speech recognition using deep learning},\n volume = {42},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f32f16ca3c27ff945198c6551a5d35fae3b1a660",
            "@type": "ScholarlyArticle",
            "paperId": "f32f16ca3c27ff945198c6551a5d35fae3b1a660",
            "corpusId": 3783953,
            "url": "https://www.semanticscholar.org/paper/f32f16ca3c27ff945198c6551a5d35fae3b1a660",
            "title": "Learning Deep Generative Models of Graphs",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1803-03324",
                "ArXiv": "1803.03324",
                "MAG": "2963555927",
                "CorpusId": 3783953
            },
            "abstract": "Graphs are fundamental data structures which concisely capture the relational structure in many important real-world domains, such as knowledge graphs, physical and social interactions, language, and chemistry. Here we introduce a powerful new approach for learning generative models over graphs, which can capture both their structure and attributes. Our approach uses graph neural networks to express probabilistic dependencies among a graph's nodes and edges, and can, in principle, learn distributions over any arbitrary graph. In a series of experiments our results show that once trained, our models can generate good quality samples of both synthetic graphs as well as real molecular graphs, both unconditionally and conditioned on data. Compared to baselines that do not use graph-structured representations, our models often perform far better. We also explore key challenges of learning generative models of graphs, such as how to handle symmetries and ordering of elements during the graph generation process, and offer possible solutions. Our work is the first and most general approach for learning generative models over arbitrary graphs, and opens new directions for moving away from restrictions of vector- and sequence-like knowledge representations, toward more expressive and flexible relational data structures.",
            "referenceCount": 43,
            "citationCount": 556,
            "influentialCitationCount": 63,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1803.03324"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2018LearningDG,\n author = {Yujia Li and Oriol Vinyals and Chris Dyer and Razvan Pascanu and P. Battaglia},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Learning Deep Generative Models of Graphs},\n volume = {abs/1803.03324},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0772905d40b9afa3dc087a88184f09f3b3e1464f",
            "@type": "ScholarlyArticle",
            "paperId": "0772905d40b9afa3dc087a88184f09f3b3e1464f",
            "corpusId": 53391180,
            "url": "https://www.semanticscholar.org/paper/0772905d40b9afa3dc087a88184f09f3b3e1464f",
            "title": "Learning to Communicate with Deep Multi-Agent Reinforcement Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/FoersterAFW16a",
                "ArXiv": "1605.06676",
                "MAG": "2951097037",
                "CorpusId": 53391180
            },
            "abstract": "We consider the problem of multiple agents sensing and acting in environments with the goal of maximising their shared utility. In these environments, agents must learn communication protocols in order to share information that is needed to solve the tasks. By embracing deep neural networks, we are able to demonstrate end-to-end learning of protocols in complex environments inspired by communication riddles and multi-agent computer vision problems with partial observability. We propose two approaches for learning in these domains: Reinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning (DIAL). The former uses deep Q-learning, while the latter exploits the fact that, during learning, agents can backpropagate error derivatives through (noisy) communication channels. Hence, this approach uses centralised learning but decentralised execution. Our experiments introduce new environments for studying the learning of communication protocols and present a set of engineering innovations that are essential for success in these domains.",
            "referenceCount": 28,
            "citationCount": 1306,
            "influentialCitationCount": 145,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-05-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1605.06676"
            },
            "citationStyles": {
                "bibtex": "@Article{Foerster2016LearningTC,\n author = {Jakob N. Foerster and Yannis Assael and Nando de Freitas and Shimon Whiteson},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Learning to Communicate with Deep Multi-Agent Reinforcement Learning},\n volume = {abs/1605.06676},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6ce9d1718f7c93f5bf9bcc4ccd928492d07cfb0d",
            "@type": "ScholarlyArticle",
            "paperId": "6ce9d1718f7c93f5bf9bcc4ccd928492d07cfb0d",
            "corpusId": 198342674,
            "url": "https://www.semanticscholar.org/paper/6ce9d1718f7c93f5bf9bcc4ccd928492d07cfb0d",
            "title": "Deep Learning",
            "venue": "Algorithms",
            "publicationVenue": {
                "id": "urn:research:e95c8d18-09be-464f-a3cf-5b2637f0eff6",
                "name": "Algorithms",
                "alternate_names": null,
                "issn": "1999-4893",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-150910"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2955409416",
                "DOI": "10.7551/mitpress/11884.003.0009",
                "CorpusId": 198342674
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-01-12",
            "journal": {
                "name": "Algorithms",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Nakamoto2018DeepL,\n author = {Pat Nakamoto},\n booktitle = {Algorithms},\n journal = {Algorithms},\n title = {Deep Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7a450675968d31b8363e21fb5d5b72474c128076",
            "@type": "ScholarlyArticle",
            "paperId": "7a450675968d31b8363e21fb5d5b72474c128076",
            "corpusId": 202750286,
            "url": "https://www.semanticscholar.org/paper/7a450675968d31b8363e21fb5d5b72474c128076",
            "title": "Deep Dynamics Models for Learning Dexterous Manipulation",
            "venue": "Conference on Robot Learning",
            "publicationVenue": {
                "id": "urn:research:fbfbf10a-faa4-4d2a-85be-3ac660454ce3",
                "name": "Conference on Robot Learning",
                "alternate_names": [
                    "CoRL",
                    "Conf Robot Learn"
                ],
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1909.11652",
                "DBLP": "journals/corr/abs-1909-11652",
                "MAG": "2975909688",
                "CorpusId": 202750286
            },
            "abstract": "Dexterous multi-fingered hands can provide robots with the ability to flexibly perform a wide range of manipulation skills. However, many of the more complex behaviors are also notoriously difficult to control: Performing in-hand object manipulation, executing finger gaits to move objects, and exhibiting precise fine motor skills such as writing, all require finely balancing contact forces, breaking and reestablishing contacts repeatedly, and maintaining control of unactuated objects. Learning-based techniques provide the appealing possibility of acquiring these skills directly from data, but current learning approaches either require large amounts of data and produce task-specific policies, or they have not yet been shown to scale up to more complex and realistic tasks requiring fine motor skills. In this work, we demonstrate that our method of online planning with deep dynamics models (PDDM) addresses both of these limitations; we show that improvements in learned dynamics models, together with improvements in online model-predictive control, can indeed enable efficient and effective learning of flexible contact-rich dexterous manipulation skills -- and that too, on a 24-DoF anthropomorphic hand in the real world, using just 4 hours of purely real-world data to learn to simultaneously coordinate multiple free-floating objects. Videos can be found at this https URL",
            "referenceCount": 40,
            "citationCount": 309,
            "influentialCitationCount": 27,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-09-25",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Nagabandi2019DeepDM,\n author = {Anusha Nagabandi and K. Konolige and S. Levine and Vikash Kumar},\n booktitle = {Conference on Robot Learning},\n pages = {1101-1112},\n title = {Deep Dynamics Models for Learning Dexterous Manipulation},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d1208ac421cf8ff67b27d93cd19ae42b8d596f95",
            "@type": "ScholarlyArticle",
            "paperId": "d1208ac421cf8ff67b27d93cd19ae42b8d596f95",
            "corpusId": 8604637,
            "url": "https://www.semanticscholar.org/paper/d1208ac421cf8ff67b27d93cd19ae42b8d596f95",
            "title": "Deep learning with COTS HPC systems",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/icml/CoatesHWWCN13",
                "MAG": "2162390675",
                "CorpusId": 8604637
            },
            "abstract": "Scaling up deep learning algorithms has been shown to lead to increased performance in benchmark tasks and to enable discovery of complex high-level features. Recent efforts to train extremely large networks (with over 1 billion parameters) have relied on cloudlike computing infrastructure and thousands of CPU cores. In this paper, we present technical details and results from our own system based on Commodity Off-The-Shelf High Performance Computing (COTS HPC) technology: a cluster of GPU servers with Infiniband interconnects and MPI. Our system is able to train 1 billion parameter networks on just 3 machines in a couple of days, and we show that it can scale to networks with over 11 billion parameters using just 16 machines. As this infrastructure is much more easily marshaled by others, the approach enables much wider-spread research with extremely large neural networks.",
            "referenceCount": 32,
            "citationCount": 719,
            "influentialCitationCount": 48,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-06-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Coates2013DeepLW,\n author = {Adam Coates and Brody Huval and Tao Wang and David J. Wu and Bryan Catanzaro and A. Ng},\n booktitle = {International Conference on Machine Learning},\n pages = {1337-1345},\n title = {Deep learning with COTS HPC systems},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3539f67ba7f9025e2695709814aef4864843473b",
            "@type": "ScholarlyArticle",
            "paperId": "3539f67ba7f9025e2695709814aef4864843473b",
            "corpusId": 5486202,
            "url": "https://www.semanticscholar.org/paper/3539f67ba7f9025e2695709814aef4864843473b",
            "title": "Early diagnosis of Alzheimer's disease with deep learning",
            "venue": "IEEE International Symposium on Biomedical Imaging",
            "publicationVenue": {
                "id": "urn:research:a38e0d3d-6929-4868-b4e4-af8bbacf711e",
                "name": "IEEE International Symposium on Biomedical Imaging",
                "alternate_names": [
                    "ISBI",
                    "International Symposium on Biomedical Imaging",
                    "Int Symp Biomed Imaging",
                    "IEEE Int Symp Biomed Imaging"
                ],
                "issn": "1945-7928",
                "url": "http://www.biomedicalimaging.org/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/isbi/LiuLCPKF14",
                "MAG": "2057536936",
                "DOI": "10.1109/ISBI.2014.6868045",
                "CorpusId": 5486202
            },
            "abstract": "The accurate diagnosis of Alzheimer's disease (AD) plays a significant role in patient care, especially at the early stage, because the consciousness of the severity and the progression risks allows the patients to take prevention measures before irreversible brain damages are shaped. Although many studies have applied machine learning methods for computer-aided-diagnosis (CAD) of AD recently, a bottleneck of the diagnosis performance was shown in most of the existing researches, mainly due to the congenital limitations of the chosen learning models. In this study, we design a deep learning architecture, which contains stacked auto-encoders and a softmax output layer, to overcome the bottleneck and aid the diagnosis of AD and its prodromal stage, Mild Cognitive Impairment (MCI). Compared to the previous workflows, our method is capable of analyzing multiple classes in one setting, and requires less labeled training samples and minimal domain prior knowledge. A significant performance gain on classification of all diagnosis groups was achieved in our experiments.",
            "referenceCount": 27,
            "citationCount": 405,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-07-31",
            "journal": {
                "name": "2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2014EarlyDO,\n author = {Siqi Liu and Sidong Liu and Weidong (Tom) Cai and Sonia Pujol and R. Kikinis and D. Feng},\n booktitle = {IEEE International Symposium on Biomedical Imaging},\n journal = {2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI)},\n pages = {1015-1018},\n title = {Early diagnosis of Alzheimer's disease with deep learning},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:72808bcd6e05de33261fc27bcafdb4d1855daf24",
            "@type": "ScholarlyArticle",
            "paperId": "72808bcd6e05de33261fc27bcafdb4d1855daf24",
            "corpusId": 18689272,
            "url": "https://www.semanticscholar.org/paper/72808bcd6e05de33261fc27bcafdb4d1855daf24",
            "title": "Blind Image Quality Assessment via Deep Learning",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2170947705",
                "DBLP": "journals/tnn/HouGTL15",
                "DOI": "10.1109/TNNLS.2014.2336852",
                "CorpusId": 18689272,
                "PubMed": "25122842"
            },
            "abstract": "This paper investigates how to blindly evaluate the visual quality of an image by learning rules from linguistic descriptions. Extensive psychological evidence shows that humans prefer to conduct evaluations qualitatively rather than numerically. The qualitative evaluations are then converted into the numerical scores to fairly benchmark objective image quality assessment (IQA) metrics. Recently, lots of learning-based IQA models are proposed by analyzing the mapping from the images to numerical ratings. However, the learnt mapping can hardly be accurate enough because some information has been lost in such an irreversible conversion from the linguistic descriptions to numerical scores. In this paper, we propose a blind IQA model, which learns qualitative evaluations directly and outputs numerical scores for general utilization and fair comparison. Images are represented by natural scene statistics features. A discriminative deep model is trained to classify the features into five grades, corresponding to five explicit mental concepts, i.e., excellent, good, fair, poor, and bad. A newly designed quality pooling is then applied to convert the qualitative labels into scores. The classification framework is not only much more natural than the regression-based models, but also robust to the small sample size problem. Thorough experiments are conducted on popular databases to verify the model's effectiveness, efficiency, and robustness.",
            "referenceCount": 42,
            "citationCount": 349,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-06-01",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "26"
            },
            "citationStyles": {
                "bibtex": "@Article{Hou2015BlindIQ,\n author = {Weilong Hou and Xinbo Gao and D. Tao and Xuelong Li},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {1275-1286},\n title = {Blind Image Quality Assessment via Deep Learning},\n volume = {26},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:511ff60d4aa5ab2660552f02ee85692425912b46",
            "@type": "ScholarlyArticle",
            "paperId": "511ff60d4aa5ab2660552f02ee85692425912b46",
            "corpusId": 206596552,
            "url": "https://www.semanticscholar.org/paper/511ff60d4aa5ab2660552f02ee85692425912b46",
            "title": "OctNet: Learning Deep 3D Representations at High Resolutions",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2952802612",
                "DBLP": "journals/corr/RieglerUG16",
                "ArXiv": "1611.05009",
                "DOI": "10.1109/CVPR.2017.701",
                "CorpusId": 206596552
            },
            "abstract": "We present OctNet, a representation for deep learning with sparse 3D data. In contrast to existing models, our representation enables 3D convolutional networks which are both deep and high resolution. Towards this goal, we exploit the sparsity in the input data to hierarchically partition the space using a set of unbalanced octrees where each leaf node stores a pooled feature representation. This allows to focus memory allocation and computation to the relevant dense regions and enables deeper networks without compromising resolution. We demonstrate the utility of our OctNet representation by analyzing the impact of resolution on several 3D tasks including 3D object classification, orientation estimation and point cloud labeling.",
            "referenceCount": 55,
            "citationCount": 1290,
            "influentialCitationCount": 78,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1611.05009",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-11-15",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Riegler2016OctNetLD,\n author = {Gernot Riegler and Ali O. Ulusoy and Andreas Geiger},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {6620-6629},\n title = {OctNet: Learning Deep 3D Representations at High Resolutions},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
            "@type": "ScholarlyArticle",
            "paperId": "9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
            "corpusId": 5707386,
            "url": "https://www.semanticscholar.org/paper/9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
            "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2271840356",
                "ArXiv": "1603.04467",
                "DBLP": "journals/corr/AbadiABBCCCDDDG16",
                "CorpusId": 5707386
            },
            "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
            "referenceCount": 60,
            "citationCount": 10166,
            "influentialCitationCount": 1042,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-03-14",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1603.04467"
            },
            "citationStyles": {
                "bibtex": "@Article{Abadi2016TensorFlowLM,\n author = {Mart\u00edn Abadi and Ashish Agarwal and P. Barham and E. Brevdo and Z. Chen and C. Citro and G. Corrado and Andy Davis and J. Dean and Matthieu Devin and S. Ghemawat and I. Goodfellow and A. Harp and G. Irving and M. Isard and Yangqing Jia and R. J\u00f3zefowicz and Lukasz Kaiser and M. Kudlur and J. Levenberg and Dandelion Man\u00e9 and R. Monga and Sherry Moore and D. Murray and C. Olah and M. Schuster and Jonathon Shlens and Benoit Steiner and Ilya Sutskever and Kunal Talwar and P. Tucker and Vincent Vanhoucke and Vijay Vasudevan and F. Vi\u00e9gas and Oriol Vinyals and P. Warden and M. Wattenberg and M. Wicke and Yuan Yu and Xiaoqiang Zheng},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems},\n volume = {abs/1603.04467},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8b9e0187c0a3850c9d0e6833640b6ab8a1623bfc",
            "@type": "ScholarlyArticle",
            "paperId": "8b9e0187c0a3850c9d0e6833640b6ab8a1623bfc",
            "corpusId": 14860163,
            "url": "https://www.semanticscholar.org/paper/8b9e0187c0a3850c9d0e6833640b6ab8a1623bfc",
            "title": "Joint Deep Learning for Pedestrian Detection",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2156547346",
                "DBLP": "conf/iccv/OuyangW13",
                "DOI": "10.1109/ICCV.2013.257",
                "CorpusId": 14860163
            },
            "abstract": "Feature extraction, deformation handling, occlusion handling, and classification are four important components in pedestrian detection. Existing methods learn or design these components either individually or sequentially. The interaction among these components is not yet well explored. This paper proposes that they should be jointly learned in order to maximize their strengths through cooperation. We formulate these four components into a joint deep learning framework and propose a new deep network architecture. By establishing automatic, mutual interaction among components, the deep model achieves a 9% reduction in the average miss rate compared with the current best-performing pedestrian detection approaches on the largest Caltech benchmark dataset.",
            "referenceCount": 58,
            "citationCount": 644,
            "influentialCitationCount": 46,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-12-01",
            "journal": {
                "name": "2013 IEEE International Conference on Computer Vision",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ouyang2013JointDL,\n author = {Wanli Ouyang and Xiaogang Wang},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2013 IEEE International Conference on Computer Vision},\n pages = {2056-2063},\n title = {Joint Deep Learning for Pedestrian Detection},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f5f323e62acb75f785e00b4c90ace16f1690076f",
            "@type": "ScholarlyArticle",
            "paperId": "f5f323e62acb75f785e00b4c90ace16f1690076f",
            "corpusId": 8696662,
            "url": "https://www.semanticscholar.org/paper/f5f323e62acb75f785e00b4c90ace16f1690076f",
            "title": "Deep Recurrent Q-Learning for Partially Observable MDPs",
            "venue": "AAAI Fall Symposia",
            "publicationVenue": {
                "id": "urn:research:5c1b6dba-7390-42e1-a873-2059f9f57ddd",
                "name": "AAAI Fall Symposia",
                "alternate_names": [
                    "AAAI Fall Symp"
                ],
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/HausknechtS15",
                "ArXiv": "1507.06527",
                "MAG": "2952684340",
                "CorpusId": 8696662
            },
            "abstract": "Deep Reinforcement Learning has yielded proficient controllers for complex tasks. However, these controllers have limited memory and rely on being able to perceive the complete game screen at each decision point. To address these shortcomings, this article investigates the effects of adding recurrency to a Deep Q-Network (DQN) by replacing the first post-convolutional fully-connected layer with a recurrent LSTM. The resulting \\textit{Deep Recurrent Q-Network} (DRQN), although capable of seeing only a single frame at each timestep, successfully integrates information through time and replicates DQN's performance on standard Atari games and partially observed equivalents featuring flickering game screens. Additionally, when trained with partial observations and evaluated with incrementally more complete observations, DRQN's performance scales as a function of observability. Conversely, when trained with full observations and evaluated with partial observations, DRQN's performance degrades less than DQN's. Thus, given the same length of history, recurrency is a viable alternative to stacking a history of frames in the DQN's input layer and while recurrency confers no systematic advantage when learning to play the game, the recurrent net can better adapt at evaluation time if the quality of observations changes.",
            "referenceCount": 17,
            "citationCount": 1396,
            "influentialCitationCount": 207,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-07-23",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1507.06527"
            },
            "citationStyles": {
                "bibtex": "@Article{Hausknecht2015DeepRQ,\n author = {Matthew J. Hausknecht and P. Stone},\n booktitle = {AAAI Fall Symposia},\n journal = {ArXiv},\n title = {Deep Recurrent Q-Learning for Partially Observable MDPs},\n volume = {abs/1507.06527},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b8de958fead0d8a9619b55c7299df3257c624a96",
            "@type": "ScholarlyArticle",
            "paperId": "b8de958fead0d8a9619b55c7299df3257c624a96",
            "corpusId": 6161478,
            "url": "https://www.semanticscholar.org/paper/b8de958fead0d8a9619b55c7299df3257c624a96",
            "title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "journals/corr/DonahueJVHZTD13",
                "MAG": "2155541015",
                "ArXiv": "1310.1531",
                "CorpusId": 6161478
            },
            "abstract": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be repurposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.",
            "referenceCount": 50,
            "citationCount": 4739,
            "influentialCitationCount": 332,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-10-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Donahue2013DeCAFAD,\n author = {Jeff Donahue and Yangqing Jia and Oriol Vinyals and Judy Hoffman and Ning Zhang and Eric Tzeng and Trevor Darrell},\n booktitle = {International Conference on Machine Learning},\n pages = {647-655},\n title = {DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c73b9b2393cc0136c9a7ad89e661107ba0ef73ca",
            "@type": "ScholarlyArticle",
            "paperId": "c73b9b2393cc0136c9a7ad89e661107ba0ef73ca",
            "corpusId": 14251247,
            "url": "https://www.semanticscholar.org/paper/c73b9b2393cc0136c9a7ad89e661107ba0ef73ca",
            "title": "Ensemble deep learning for regression and time series forecasting",
            "venue": "IEEE Symposium on Computational Intelligence and Ensemble Learning",
            "publicationVenue": {
                "id": "urn:research:82f4e449-547e-4a11-81f4-b6429f9afa60",
                "name": "IEEE Symposium on Computational Intelligence and Ensemble Learning",
                "alternate_names": [
                    "CIEL",
                    "IEEE Symp Comput Intell Ensemble Learn"
                ],
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/ciel/QiuZRSA14",
                "MAG": "2007272376",
                "DOI": "10.1109/CIEL.2014.7015739",
                "CorpusId": 14251247
            },
            "abstract": "In this paper, for the first time, an ensemble of deep learning belief networks (DBN) is proposed for regression and time series forecasting. Another novel contribution is to aggregate the outputs from various DBNs by a support vector regression (SVR) model. We show the advantage of the proposed method on three electricity load demand datasets, one artificial time series dataset and three regression datasets over other benchmark methods.",
            "referenceCount": 31,
            "citationCount": 310,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-01-20",
            "journal": {
                "name": "2014 IEEE Symposium on Computational Intelligence in Ensemble Learning (CIEL)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Qiu2014EnsembleDL,\n author = {Xueheng Qiu and Le Zhang and Ye Ren and P. Suganthan and G. Amaratunga},\n booktitle = {IEEE Symposium on Computational Intelligence and Ensemble Learning},\n journal = {2014 IEEE Symposium on Computational Intelligence in Ensemble Learning (CIEL)},\n pages = {1-6},\n title = {Ensemble deep learning for regression and time series forecasting},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cee24ab025bef317cc3268e8df933f5259ad521b",
            "@type": "ScholarlyArticle",
            "paperId": "cee24ab025bef317cc3268e8df933f5259ad521b",
            "corpusId": 215316,
            "url": "https://www.semanticscholar.org/paper/cee24ab025bef317cc3268e8df933f5259ad521b",
            "title": "An exact mapping between the Variational Renormalization Group and Deep Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/corr/MehtaS14",
                "MAG": "1890000358",
                "ArXiv": "1410.3831",
                "CorpusId": 215316
            },
            "abstract": "Deep learning is a broad set of techniques that uses multiple layers of representation to automatically learn relevant features directly from structured data. Recently, such techniques have yielded record-breaking results on a diverse set of difficult machine learning tasks in computer vision, speech recognition, and natural language processing. Despite the enormous success of deep learning, relatively little is understood theoretically about why these techniques are so successful at feature learning and compression. Here, we show that deep learning is intimately related to one of the most important and successful techniques in theoretical physics, the renormalization group (RG). RG is an iterative coarse-graining scheme that allows for the extraction of relevant features (i.e. operators) as a physical system is examined at different length scales. We construct an exact mapping from the variational renormalization group, first introduced by Kadanoff, and deep learning architectures based on Restricted Boltzmann Machines (RBMs). We illustrate these ideas using the nearest-neighbor Ising Model in one and two-dimensions. Our results suggests that deep learning algorithms may be employing a generalized RG-like scheme to learn relevant features from data.",
            "referenceCount": 17,
            "citationCount": 293,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-10-14",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1410.3831"
            },
            "citationStyles": {
                "bibtex": "@Article{Mehta2014AnEM,\n author = {Pankaj Mehta and D. Schwab},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {An exact mapping between the Variational Renormalization Group and Deep Learning},\n volume = {abs/1410.3831},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6bdccfe195bc49d218acc5be750aa49e41f408e4",
            "@type": "ScholarlyArticle",
            "paperId": "6bdccfe195bc49d218acc5be750aa49e41f408e4",
            "corpusId": 13412186,
            "url": "https://www.semanticscholar.org/paper/6bdccfe195bc49d218acc5be750aa49e41f408e4",
            "title": "Recent advances in deep learning for speech research at Microsoft",
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "publicationVenue": {
                "id": "urn:research:0d6f7fba-7092-46b3-8039-93458dba736b",
                "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                "alternate_names": [
                    "Int Conf Acoust Speech Signal Process",
                    "IEEE Int Conf Acoust Speech Signal Process",
                    "ICASSP",
                    "International Conference on Acoustics, Speech, and Signal Processing"
                ],
                "issn": null,
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/icassp/DengLHYYSSZHWGA13",
                "MAG": "1984541135",
                "DOI": "10.1109/ICASSP.2013.6639345",
                "CorpusId": 13412186
            },
            "abstract": "Deep learning is becoming a mainstream technology for speech recognition at industrial scale. In this paper, we provide an overview of the work by Microsoft speech researchers since 2009 in this area, focusing on more recent advances which shed light to the basic capabilities and limitations of the current deep learning technology. We organize this overview along the feature-domain and model-domain dimensions according to the conventional approach to analyzing speech systems. Selected experimental results, including speech recognition and related applications such as spoken dialogue and language modeling, are presented to demonstrate and analyze the strengths and weaknesses of the techniques described in the paper. Potential improvement of these techniques and future research directions are discussed.",
            "referenceCount": 61,
            "citationCount": 769,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2013-05-26",
            "journal": {
                "name": "2013 IEEE International Conference on Acoustics, Speech and Signal Processing",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Deng2013RecentAI,\n author = {L. Deng and Jinyu Li and J. Huang and K. Yao and Dong Yu and F. Seide and M. Seltzer and G. Zweig and Xiaodong He and J. Williams and Y. Gong and A. Acero},\n booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},\n journal = {2013 IEEE International Conference on Acoustics, Speech and Signal Processing},\n pages = {8604-8608},\n title = {Recent advances in deep learning for speech research at Microsoft},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1298dae5751fb06184f6b067d1503bde8037bdb7",
            "@type": "ScholarlyArticle",
            "paperId": "1298dae5751fb06184f6b067d1503bde8037bdb7",
            "corpusId": 3147007,
            "url": "https://www.semanticscholar.org/paper/1298dae5751fb06184f6b067d1503bde8037bdb7",
            "title": "Deep Reinforcement Learning for Dialogue Generation",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2016,
            "externalIds": {
                "ACL": "D16-1127",
                "ArXiv": "1606.01541",
                "DBLP": "conf/emnlp/LiMRJGG16",
                "MAG": "2951559297",
                "DOI": "10.18653/v1/D16-1127",
                "CorpusId": 3147007
            },
            "abstract": "Recent neural models of dialogue generation offer great promise for generating responses for conversational agents, but tend to be shortsighted, predicting utterances one at a time while ignoring their influence on future outcomes. Modeling the future direction of a dialogue is crucial to generating coherent, interesting dialogues, a need which led traditional NLP models of dialogue to draw on reinforcement learning. In this paper, we show how to integrate these goals, applying deep reinforcement learning to model future reward in chatbot dialogue. The model simulates dialogues between two virtual agents, using policy gradient methods to reward sequences that display three useful conversational properties: informativity (non-repetitive turns), coherence, and ease of answering (related to forward-looking function). We evaluate our model on diversity, length as well as with human judges, showing that the proposed algorithm generates more interactive responses and manages to foster a more sustained conversation in dialogue simulation. This work marks a first step towards learning a neural conversational model based on the long-term success of dialogues.",
            "referenceCount": 56,
            "citationCount": 1235,
            "influentialCitationCount": 166,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/D16-1127.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1606.01541"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2016DeepRL,\n author = {Jiwei Li and Will Monroe and Alan Ritter and Dan Jurafsky and Michel Galley and Jianfeng Gao},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Deep Reinforcement Learning for Dialogue Generation},\n volume = {abs/1606.01541},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4cfad7889dc12825309325cd4b4f3febed424e36",
            "@type": "ScholarlyArticle",
            "paperId": "4cfad7889dc12825309325cd4b4f3febed424e36",
            "corpusId": 12211448,
            "url": "https://www.semanticscholar.org/paper/4cfad7889dc12825309325cd4b4f3febed424e36",
            "title": "Deep Learning for Answer Sentence Selection",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2014,
            "externalIds": {
                "ArXiv": "1412.1632",
                "DBLP": "journals/corr/YuHBP14",
                "MAG": "1591825359",
                "CorpusId": 12211448
            },
            "abstract": "Answer sentence selection is the task of identifying sentences that contain the answer to a given question. This is an important problem in its own right as well as in the larger context of open domain question answering. We propose a novel approach to solving this task via means of distributed representations, and learn to match questions with answers by considering their semantic encoding. This contrasts prior work on this task, which typically relies on classifiers with large numbers of hand-crafted syntactic and semantic features and various external resources. Our approach does not require any feature engineering nor does it involve specialist linguistic data, making this model easily applicable to a wide range of domains and languages. Experimental results on a standard benchmark dataset from TREC demonstrate that---despite its simplicity---our model matches state of the art performance on the answer sentence selection task.",
            "referenceCount": 25,
            "citationCount": 401,
            "influentialCitationCount": 51,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-12-04",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1412.1632"
            },
            "citationStyles": {
                "bibtex": "@Article{Yu2014DeepLF,\n author = {Lei Yu and K. Hermann and Phil Blunsom and S. Pulman},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Learning for Answer Sentence Selection},\n volume = {abs/1412.1632},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a7897e61633a97e648057bee95c082c1aab40d41",
            "@type": "ScholarlyArticle",
            "paperId": "a7897e61633a97e648057bee95c082c1aab40d41",
            "corpusId": 10875300,
            "url": "https://www.semanticscholar.org/paper/a7897e61633a97e648057bee95c082c1aab40d41",
            "title": "Deep learning of feature representation with multiple instance learning for medical image analysis",
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "publicationVenue": {
                "id": "urn:research:0d6f7fba-7092-46b3-8039-93458dba736b",
                "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                "alternate_names": [
                    "Int Conf Acoust Speech Signal Process",
                    "IEEE Int Conf Acoust Speech Signal Process",
                    "ICASSP",
                    "International Conference on Acoustics, Speech, and Signal Processing"
                ],
                "issn": null,
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2050418754",
                "DBLP": "conf/icassp/XuMFZLC14",
                "DOI": "10.1109/ICASSP.2014.6853873",
                "CorpusId": 10875300
            },
            "abstract": "This paper studies the effectiveness of accomplishing high-level tasks with a minimum of manual annotation and good feature representations for medical images. In medical image analysis, objects like cells are characterized by significant clinical features. Previously developed features like SIFT and HARR are unable to comprehensively represent such objects. Therefore, feature representation is especially important. In this paper, we study automatic extraction of feature representation through deep learning (DNN). Furthermore, detailed annotation of objects is often an ambiguous and challenging task. We use multiple instance learning (MIL) framework in classification training with deep learning features. Several interesting conclusions can be drawn from our work: (1) automatic feature learning outperforms manual feature; (2) the unsupervised approach can achieve performance that's close to fully supervised approach (93.56%) vs. (94.52%); and (3) the MIL performance of coarse label (96.30%) outweighs the supervised performance of fine label (95.40%) in supervised deep learning features.",
            "referenceCount": 26,
            "citationCount": 355,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-05-04",
            "journal": {
                "name": "2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Xu2014DeepLO,\n author = {Yan Xu and Tao Mo and Qiwei Feng and Peilin Zhong and M. Lai and E. Chang},\n booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},\n journal = {2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n pages = {1626-1630},\n title = {Deep learning of feature representation with multiple instance learning for medical image analysis},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:72d32c986b47d6b880dad0c3f155fe23d2939038",
            "@type": "ScholarlyArticle",
            "paperId": "72d32c986b47d6b880dad0c3f155fe23d2939038",
            "corpusId": 1044293,
            "url": "https://www.semanticscholar.org/paper/72d32c986b47d6b880dad0c3f155fe23d2939038",
            "title": "Deep Learning of Representations: Looking Forward",
            "venue": "International Conference on Statistical Language and Speech Processing",
            "publicationVenue": {
                "id": "urn:research:df4d867b-b4ce-4d53-8c8c-e44bba7a0e0c",
                "name": "International Conference on Statistical Language and Speech Processing",
                "alternate_names": [
                    "SLSP",
                    "Int Conf Stat Lang Speech Process"
                ],
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "MAG": "1613249581",
                "DBLP": "conf/slsp/Bengio13",
                "ArXiv": "1305.0445",
                "DOI": "10.1007/978-3-642-39593-2_1",
                "CorpusId": 1044293
            },
            "abstract": null,
            "referenceCount": 167,
            "citationCount": 614,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1305.0445",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-05-02",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bengio2013DeepLO,\n author = {Yoshua Bengio},\n booktitle = {International Conference on Statistical Language and Speech Processing},\n pages = {1-37},\n title = {Deep Learning of Representations: Looking Forward},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7af7f2f539cd3479faae4c66bbef49b0f66202fa",
            "@type": "ScholarlyArticle",
            "paperId": "7af7f2f539cd3479faae4c66bbef49b0f66202fa",
            "corpusId": 2305273,
            "url": "https://www.semanticscholar.org/paper/7af7f2f539cd3479faae4c66bbef49b0f66202fa",
            "title": "Target-driven visual navigation in indoor scenes using deep reinforcement learning",
            "venue": "IEEE International Conference on Robotics and Automation",
            "publicationVenue": {
                "id": "urn:research:3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                "name": "IEEE International Conference on Robotics and Automation",
                "alternate_names": [
                    "International Conference on Robotics and Automation",
                    "Int Conf Robot Autom",
                    "ICRA",
                    "IEEE Int Conf Robot Autom"
                ],
                "issn": "2152-4092",
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/ZhuMKLGFF16",
                "MAG": "2522340145",
                "ArXiv": "1609.05143",
                "DOI": "10.1109/ICRA.2017.7989381",
                "CorpusId": 2305273
            },
            "abstract": "Two less addressed issues of deep reinforcement learning are (1) lack of generalization capability to new goals, and (2) data inefficiency, i.e., the model requires several (and often costly) episodes of trial and error to converge, which makes it impractical to be applied to real-world scenarios. In this paper, we address these two issues and apply our model to target-driven visual navigation. To address the first issue, we propose an actor-critic model whose policy is a function of the goal as well as the current state, which allows better generalization. To address the second issue, we propose the AI2-THOR framework, which provides an environment with high-quality 3D scenes and a physics engine. Our framework enables agents to take actions and interact with objects. Hence, we can collect a huge number of training samples efficiently. We show that our proposed method (1) converges faster than the state-of-the-art deep reinforcement learning methods, (2) generalizes across targets and scenes, (3) generalizes to a real robot scenario with a small amount of fine-tuning (although the model is trained in simulation), (4) is end-to-end trainable and does not need feature engineering, feature matching between frames or 3D reconstruction of the environment.",
            "referenceCount": 55,
            "citationCount": 1292,
            "influentialCitationCount": 104,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1609.05143",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-09-16",
            "journal": {
                "name": "2017 IEEE International Conference on Robotics and Automation (ICRA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhu2016TargetdrivenVN,\n author = {Yuke Zhu and Roozbeh Mottaghi and Eric Kolve and Joseph J. Lim and A. Gupta and Li Fei-Fei and Ali Farhadi},\n booktitle = {IEEE International Conference on Robotics and Automation},\n journal = {2017 IEEE International Conference on Robotics and Automation (ICRA)},\n pages = {3357-3364},\n title = {Target-driven visual navigation in indoor scenes using deep reinforcement learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:28c6b49c31e919434f3b62a084aa5c67bbd6d945",
            "@type": "ScholarlyArticle",
            "paperId": "28c6b49c31e919434f3b62a084aa5c67bbd6d945",
            "corpusId": 17245765,
            "url": "https://www.semanticscholar.org/paper/28c6b49c31e919434f3b62a084aa5c67bbd6d945",
            "title": "Deep learning for regulatory genomics",
            "venue": "Nature Biotechnology",
            "publicationVenue": {
                "id": "urn:research:458166b3-de17-4bf3-bbbb-e53782de2f0f",
                "name": "Nature Biotechnology",
                "alternate_names": [
                    "Nat Biotechnol"
                ],
                "issn": "1087-0156",
                "url": "http://www.nature.com/nbt/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1123205372",
                "DOI": "10.1038/nbt.3313",
                "CorpusId": 17245765,
                "PubMed": "26252139"
            },
            "abstract": null,
            "referenceCount": 15,
            "citationCount": 150,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "LettersAndComments",
                "JournalArticle"
            ],
            "publicationDate": "2015-08-01",
            "journal": {
                "name": "Nature Biotechnology",
                "volume": "33"
            },
            "citationStyles": {
                "bibtex": "@Article{Park2015DeepLF,\n author = {Yongjin P. Park and Manolis Kellis},\n booktitle = {Nature Biotechnology},\n journal = {Nature Biotechnology},\n pages = {825-826},\n title = {Deep learning for regulatory genomics},\n volume = {33},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9f5b82d9915d0752957602224c5056be7e749c83",
            "@type": "ScholarlyArticle",
            "paperId": "9f5b82d9915d0752957602224c5056be7e749c83",
            "corpusId": 38553870,
            "url": "https://www.semanticscholar.org/paper/9f5b82d9915d0752957602224c5056be7e749c83",
            "title": "Foundations of Machine Learning",
            "venue": "Introduction to AI Techniques for Renewable Energy Systems",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.2139/ssrn.3399990",
                "CorpusId": 38553870
            },
            "abstract": "Understanding Machine LearningProbabilistic Machine LearningHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlowFundamentals of Machine LearningReinforcement Learning, second editionDeep LearningIntroducing Machine LearningFoundations of Data ScienceFundamentals of Deep LearningIntelligent SystemsMachine Learning RefinedAn Introduction to Deep Reinforcement LearningDeep Learning: Fundamentals, Theory and ApplicationsDeep LearningDeep Learning for Coders with fastai and PyTorchMachine LearningA Brief Introduction to Machine Learning for EngineersElements of Causal InferenceFundamentals of Machine Learning for Predictive Data Analytics, second editionMachine Learning in Clinical NeuroscienceLearning Deep Architectures for AIArtificial IntelligenceStatistical Foundations of Data ScienceThe Mathematical Foundations of Learning MachinesFoundations of Machine LearningMachine Learning FoundationsBoostingThe Algorithmic Foundations of Differential PrivacyMathematics for Machine LearningFoundations of Rule LearningDeep Learning with PyTorchNeural Network LearningDeep Learning IllustratedFoundations of Deep Reinforcement LearningFoundations of Machine Learning, second editionImbalanced LearningFoundations of Knowledge AcquisitionOn the Path to AIMachine Learning: Theoretical Foundations and Practical ApplicationsArtificial Intelligence and Machine Learning Fundamentals",
            "referenceCount": 5,
            "citationCount": 2691,
            "influentialCitationCount": 392,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2021-10-07",
            "journal": {
                "name": "Introduction to AI Techniques for Renewable Energy Systems",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Nathani2021FoundationsOM,\n author = {N. Nathani and Abhishek Singh},\n booktitle = {Introduction to AI Techniques for Renewable Energy Systems},\n journal = {Introduction to AI Techniques for Renewable Energy Systems},\n title = {Foundations of Machine Learning},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:820155ecb57325503183253b8796de5f4535eb16",
            "@type": "ScholarlyArticle",
            "paperId": "820155ecb57325503183253b8796de5f4535eb16",
            "corpusId": 15641618,
            "url": "https://www.semanticscholar.org/paper/820155ecb57325503183253b8796de5f4535eb16",
            "title": "Ensemble deep learning for speech recognition",
            "venue": "Interspeech",
            "publicationVenue": {
                "id": "urn:research:af90489e-312f-4514-bea2-bcb399cb8ece",
                "name": "Interspeech",
                "alternate_names": [
                    "Conf Int Speech Commun Assoc",
                    "INTERSPEECH",
                    "Conference of the International Speech Communication Association"
                ],
                "issn": "2308-457X",
                "url": "https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/interspeech/DengP14",
                "MAG": "2395106899",
                "DOI": "10.21437/Interspeech.2014-433",
                "CorpusId": 15641618
            },
            "abstract": "Deep learning systems have dramatically improved the accuracy of speech recognition, and various deep architectures and learning methods have been developed with distinct strengths and weaknesses in recent years. How can ensemble learning be applied to these varying deep learning systems to achieve greater recognition accuracy is the focus of this paper. We develop and report linear and log-linear stacking methods for ensemble learning with applications specifically to speechclass posterior probabilities as computed by the convolutional, recurrent, and fully-connected deep neural networks. Convex optimization problems are formulated and solved, with analytical formulas derived for training the ensemble-learning parameters. Experimental results demonstrate a significant increase in phone recognition accuracy after stacking the deep learning subsystems that use different mechanisms for computing high-level, hierarchical features from the raw acoustic signals in speech.",
            "referenceCount": 39,
            "citationCount": 224,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-09-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Deng2014EnsembleDL,\n author = {L. Deng and John C. Platt},\n booktitle = {Interspeech},\n pages = {1915-1919},\n title = {Ensemble deep learning for speech recognition},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:17429d1f750c87ba9fc22b8ffa78665d99bae6df",
            "@type": "ScholarlyArticle",
            "paperId": "17429d1f750c87ba9fc22b8ffa78665d99bae6df",
            "corpusId": 13669025,
            "url": "https://www.semanticscholar.org/paper/17429d1f750c87ba9fc22b8ffa78665d99bae6df",
            "title": "Deep residual learning for image steganalysis",
            "venue": "Multimedia tools and applications",
            "publicationVenue": {
                "id": "urn:research:477368e9-7a8e-475a-8c93-6d623797fd06",
                "name": "Multimedia tools and applications",
                "alternate_names": [
                    "Multimedia Tools and Applications",
                    "Multimedia Tool Appl",
                    "Multimedia tool appl"
                ],
                "issn": "1380-7501",
                "url": "https://www.springer.com/computer/information+systems+and+applications/journal/11042"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2588463901",
                "DBLP": "journals/mta/WuZL18",
                "DOI": "10.1007/s11042-017-4440-4",
                "CorpusId": 13669025
            },
            "abstract": null,
            "referenceCount": 43,
            "citationCount": 356,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-05-01",
            "journal": {
                "name": "Multimedia Tools and Applications",
                "volume": "77"
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2018DeepRL,\n author = {Songtao Wu and S. Zhong and Yan Liu},\n booktitle = {Multimedia tools and applications},\n journal = {Multimedia Tools and Applications},\n pages = {10437-10453},\n title = {Deep residual learning for image steganalysis},\n volume = {77},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:09a740aca5510c8cd5dd5a7474d6c1dcae08eff6",
            "@type": "ScholarlyArticle",
            "paperId": "09a740aca5510c8cd5dd5a7474d6c1dcae08eff6",
            "corpusId": 219558952,
            "url": "https://www.semanticscholar.org/paper/09a740aca5510c8cd5dd5a7474d6c1dcae08eff6",
            "title": "An Overview of Deep Semi-Supervised Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3034749675",
                "DBLP": "journals/corr/abs-2006-05278",
                "ArXiv": "2006.05278",
                "CorpusId": 219558952
            },
            "abstract": "Deep neural networks demonstrated their ability to provide remarkable performances on a wide range of supervised learning tasks (e.g., image classification) when trained on extensive collections of labeled data (e.g., ImageNet). However, creating such large datasets requires a considerable amount of resources, time, and effort. Such resources may not be available in many practical cases, limiting the adoption and the application of many deep learning methods. In a search for more data-efficient deep learning methods to overcome the need for large annotated datasets, there is a rising research interest in semi-supervised learning and its applications to deep neural networks to reduce the amount of labeled data required, by either developing novel methods or adopting existing semi-supervised learning frameworks for a deep learning setting. In this paper, we provide a comprehensive overview of deep semi-supervised learning, starting with an introduction to the field, followed by a summarization of the dominant semi-supervised approaches in deep learning.",
            "referenceCount": 190,
            "citationCount": 165,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-06-09",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2006.05278"
            },
            "citationStyles": {
                "bibtex": "@Article{Ouali2020AnOO,\n author = {Yassine Ouali and C. Hudelot and Myriam Tami},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {An Overview of Deep Semi-Supervised Learning},\n volume = {abs/2006.05278},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a71503ac83cd62519c3e4004dc25c8f98764b184",
            "@type": "ScholarlyArticle",
            "paperId": "a71503ac83cd62519c3e4004dc25c8f98764b184",
            "corpusId": 201710040,
            "url": "https://www.semanticscholar.org/paper/a71503ac83cd62519c3e4004dc25c8f98764b184",
            "title": "Deep Metric Learning: A Survey",
            "venue": "Symmetry",
            "publicationVenue": {
                "id": "urn:research:1620da87-4387-4b9a-9bf4-22fdf74d4dc3",
                "name": "Symmetry",
                "alternate_names": null,
                "issn": "2073-8994",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-172134"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2969656782",
                "DBLP": "journals/symmetry/KayaB19",
                "DOI": "10.3390/SYM11091066",
                "CorpusId": 201710040
            },
            "abstract": "Metric learning aims to measure the similarity among samples while using an optimal distance metric for learning tasks. Metric learning methods, which generally use a linear projection, are limited in solving real-world problems demonstrating non-linear characteristics. Kernel approaches are utilized in metric learning to address this problem. In recent years, deep metric learning, which provides a better solution for nonlinear data through activation functions, has attracted researchers' attention in many different areas. This article aims to reveal the importance of deep metric learning and the problems dealt with in this field in the light of recent studies. As far as the research conducted in this field are concerned, most existing studies that are inspired by Siamese and Triplet networks are commonly used to correlate among samples while using shared weights in deep metric learning. The success of these networks is based on their capacity to understand the similarity relationship among samples. Moreover, sampling strategy, appropriate distance metric, and the structure of the network are the challenging factors for researchers to improve the performance of the network model. This article is considered to be important, as it is the first comprehensive study in which these factors are systematically analyzed and evaluated as a whole and supported by comparing the quantitative results of the methods.",
            "referenceCount": 113,
            "citationCount": 387,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/2073-8994/11/9/1066/pdf?version=1567244037",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-08-21",
            "journal": {
                "name": "Symmetry",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Kaya2019DeepML,\n author = {Mahmut Kaya and H. \u015e. Bilge},\n booktitle = {Symmetry},\n journal = {Symmetry},\n pages = {1066},\n title = {Deep Metric Learning: A Survey},\n volume = {11},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ea3d7de6c0880e14455b9acb28f1bc1234321456",
            "@type": "ScholarlyArticle",
            "paperId": "ea3d7de6c0880e14455b9acb28f1bc1234321456",
            "corpusId": 5711057,
            "url": "https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456",
            "title": "Temporal Segment Networks: Towards Good Practices for Deep Action Recognition",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/WangXW0LTG16",
                "MAG": "2507009361",
                "ArXiv": "1608.00859",
                "DOI": "10.1007/978-3-319-46484-8_2",
                "CorpusId": 5711057
            },
            "abstract": null,
            "referenceCount": 41,
            "citationCount": 3269,
            "influentialCitationCount": 625,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1608.00859",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-08-02",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2016TemporalSN,\n author = {Limin Wang and Yuanjun Xiong and Zhe Wang and Y. Qiao and Dahua Lin and Xiaoou Tang and L. Gool},\n booktitle = {European Conference on Computer Vision},\n pages = {20-36},\n title = {Temporal Segment Networks: Towards Good Practices for Deep Action Recognition},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3f43f08611cbcfba62bb9e0c5339c2a8f0cc3e4b",
            "@type": "ScholarlyArticle",
            "paperId": "3f43f08611cbcfba62bb9e0c5339c2a8f0cc3e4b",
            "corpusId": 202540003,
            "url": "https://www.semanticscholar.org/paper/3f43f08611cbcfba62bb9e0c5339c2a8f0cc3e4b",
            "title": "A survey and critique of multiagent deep reinforcement learning",
            "venue": "Autonomous Agents and Multi-Agent Systems",
            "publicationVenue": {
                "id": "urn:research:86b22730-8744-40a9-ae4d-d21830dfb282",
                "name": "Autonomous Agents and Multi-Agent Systems",
                "alternate_names": [
                    "Auton Agent Multi-agent Syst"
                ],
                "issn": "1387-2532",
                "url": "https://www.springer.com/computer/ai/journal/10458"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1810-05587",
                "MAG": "2981038142",
                "ArXiv": "1810.05587",
                "DOI": "10.1007/s10458-019-09421-1",
                "CorpusId": 202540003
            },
            "abstract": null,
            "referenceCount": 393,
            "citationCount": 420,
            "influentialCitationCount": 26,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1810.05587",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-10-12",
            "journal": {
                "name": "Autonomous Agents and Multi-Agent Systems",
                "volume": "33"
            },
            "citationStyles": {
                "bibtex": "@Article{Hernandez-Leal2018ASA,\n author = {Pablo Hernandez-Leal and Bilal Kartal and Matthew E. Taylor},\n booktitle = {Autonomous Agents and Multi-Agent Systems},\n journal = {Autonomous Agents and Multi-Agent Systems},\n pages = {750 - 797},\n title = {A survey and critique of multiagent deep reinforcement learning},\n volume = {33},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c192c7d1d94e7a64de7e18e2f2fdffbf2909fcff",
            "@type": "ScholarlyArticle",
            "paperId": "c192c7d1d94e7a64de7e18e2f2fdffbf2909fcff",
            "corpusId": 169032532,
            "url": "https://www.semanticscholar.org/paper/c192c7d1d94e7a64de7e18e2f2fdffbf2909fcff",
            "title": "Deep Multimodal Representation Learning: A Survey",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2946165673",
                "DBLP": "journals/access/GuoWW19",
                "DOI": "10.1109/ACCESS.2019.2916887",
                "CorpusId": 169032532
            },
            "abstract": "Multimodal representation learning, which aims to narrow the heterogeneity gap among different modalities, plays an indispensable role in the utilization of ubiquitous multimodal data. Due to the powerful representation ability with multiple levels of abstraction, deep learning-based multimodal representation learning has attracted much attention in recent years. In this paper, we provided a comprehensive survey on deep multimodal representation learning which has never been concentrated entirely. To facilitate the discussion on how the heterogeneity gap is narrowed, according to the underlying structures in which different modalities are integrated, we category deep multimodal representation learning methods into three frameworks: joint representation, coordinated representation, and encoder-decoder. Additionally, we review some typical models in this area ranging from conventional models to newly developed technologies. This paper highlights on the key issues of newly developed technologies, such as encoder-decoder model, generative adversarial networks, and attention mechanism in a multimodal representation learning perspective, which, to the best of our knowledge, have never been reviewed previously, even though they have become the major focuses of much contemporary research. For each framework or model, we discuss its basic structure, learning objective, application scenes, key issues, advantages, and disadvantages, such that both novel and experienced researchers can benefit from this survey. Finally, we suggest some important directions for future work.",
            "referenceCount": 167,
            "citationCount": 249,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08715409.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-05-15",
            "journal": {
                "name": "IEEE Access",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Guo2019DeepMR,\n author = {Wenzhong Guo and Jianwen Wang and Shiping Wang},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {63373-63394},\n title = {Deep Multimodal Representation Learning: A Survey},\n volume = {7},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5f0850ec47a17f22ba2611a5cb67a30cb02cf306",
            "@type": "ScholarlyArticle",
            "paperId": "5f0850ec47a17f22ba2611a5cb67a30cb02cf306",
            "corpusId": 15703426,
            "url": "https://www.semanticscholar.org/paper/5f0850ec47a17f22ba2611a5cb67a30cb02cf306",
            "title": "Learning to Track at 100 FPS with Deep Regression Networks",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2964253307",
                "ArXiv": "1604.01802",
                "DBLP": "conf/eccv/HeldTS16",
                "DOI": "10.1007/978-3-319-46448-0_45",
                "CorpusId": 15703426
            },
            "abstract": null,
            "referenceCount": 52,
            "citationCount": 1146,
            "influentialCitationCount": 177,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1604.01802",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-04-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1604.01802"
            },
            "citationStyles": {
                "bibtex": "@Article{Held2016LearningTT,\n author = {David Held and S. Thrun and S. Savarese},\n booktitle = {European Conference on Computer Vision},\n journal = {ArXiv},\n title = {Learning to Track at 100 FPS with Deep Regression Networks},\n volume = {abs/1604.01802},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3ac1a7d6630cd1c7b70c4c2c7bc92c40df1162ca",
            "@type": "ScholarlyArticle",
            "paperId": "3ac1a7d6630cd1c7b70c4c2c7bc92c40df1162ca",
            "corpusId": 2784676,
            "url": "https://www.semanticscholar.org/paper/3ac1a7d6630cd1c7b70c4c2c7bc92c40df1162ca",
            "title": "Deep Metric Learning Using Triplet Network",
            "venue": "International Workshop on Similarity-Based Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:acb6eb17-056d-4a50-a2c2-963a1ebe6020",
                "name": "International Workshop on Similarity-Based Pattern Recognition",
                "alternate_names": [
                    "SIMBAD",
                    "Int Workshop Similarity-based Pattern Recognit"
                ],
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/simbad/HofferA15",
                "MAG": "2950421152",
                "ArXiv": "1412.6622",
                "DOI": "10.1007/978-3-319-24261-3_7",
                "CorpusId": 2784676
            },
            "abstract": null,
            "referenceCount": 26,
            "citationCount": 1700,
            "influentialCitationCount": 110,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1412.6622",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-12-19",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hoffer2014DeepML,\n author = {Elad Hoffer and N. Ailon},\n booktitle = {International Workshop on Similarity-Based Pattern Recognition},\n pages = {84-92},\n title = {Deep Metric Learning Using Triplet Network},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cf71771f3f0ab8a22cdbd16977c1cc3a0bbc5987",
            "@type": "ScholarlyArticle",
            "paperId": "cf71771f3f0ab8a22cdbd16977c1cc3a0bbc5987",
            "corpusId": 2700333,
            "url": "https://www.semanticscholar.org/paper/cf71771f3f0ab8a22cdbd16977c1cc3a0bbc5987",
            "title": "Quantum deep learning",
            "venue": "Quantum information & computation",
            "publicationVenue": {
                "id": "urn:research:b211891f-0b6b-43bb-8223-5371034cd946",
                "name": "Quantum information & computation",
                "alternate_names": [
                    "Quantum Inf  Comput",
                    "Quantum Information & Computation",
                    "Quantum inf  comput"
                ],
                "issn": "1533-7146",
                "url": "http://www.rintonpress.com/journals/qic/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/corr/WiebeKS14",
                "MAG": "2951576479",
                "ArXiv": "1412.3489",
                "DOI": "10.26421/QIC16.7-8-1",
                "CorpusId": 2700333
            },
            "abstract": "In recent years, deep learning has had a profound impact on machine learning and artificial intelligence. At the same time, algorithms for quantum computers have been shown to efficiently solve some problems that are intractable on conventional, classical computers. We show that quantum computing not only reduces the time required to train a deep restricted Boltzmann machine, but also provides a richer and more comprehensive framework for deep learning than classical computing and leads to significant improvements in the optimization of the underlying objective function. Our quantum methods also permit efficient training of full Boltzmann machines and multi-layer, fully connected models and do not have well known classical counterparts.",
            "referenceCount": 54,
            "citationCount": 202,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Physics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-12-10",
            "journal": {
                "name": "Quantum Inf. Comput.",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Wiebe2014QuantumDL,\n author = {N. Wiebe and Ashish Kapoor and K. Svore},\n booktitle = {Quantum information & computation},\n journal = {Quantum Inf. Comput.},\n pages = {541-587},\n title = {Quantum deep learning},\n volume = {16},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9172cd6c253edf7c3a1568e03577db20648ad0c4",
            "@type": "ScholarlyArticle",
            "paperId": "9172cd6c253edf7c3a1568e03577db20648ad0c4",
            "corpusId": 11227891,
            "url": "https://www.semanticscholar.org/paper/9172cd6c253edf7c3a1568e03577db20648ad0c4",
            "title": "Reinforcement Learning with Deep Energy-Based Policies",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2594103415",
                "ArXiv": "1702.08165",
                "DBLP": "conf/icml/HaarnojaTAL17",
                "CorpusId": 11227891
            },
            "abstract": "We propose a method for learning expressive energy-based policies for continuous states and actions, which has been feasible only in tabular domains before. We apply our method to learning maximum entropy policies, resulting into a new algorithm, called soft Q-learning, that expresses the optimal policy via a Boltzmann distribution. We use the recently proposed amortized Stein variational gradient descent to learn a stochastic sampling network that approximates samples from this distribution. The benefits of the proposed algorithm include improved exploration and compositionality that allows transferring skills between tasks, which we confirm in simulated experiments with swimming and walking robots. We also draw a connection to actor-critic methods, which can be viewed performing approximate inference on the corresponding energy-based model.",
            "referenceCount": 52,
            "citationCount": 1031,
            "influentialCitationCount": 164,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-02-27",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Haarnoja2017ReinforcementLW,\n author = {Tuomas Haarnoja and Haoran Tang and P. Abbeel and S. Levine},\n booktitle = {International Conference on Machine Learning},\n pages = {1352-1361},\n title = {Reinforcement Learning with Deep Energy-Based Policies},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9f1e9e56d80146766bc2316efbc54d8b770a23df",
            "@type": "ScholarlyArticle",
            "paperId": "9f1e9e56d80146766bc2316efbc54d8b770a23df",
            "corpusId": 17540505,
            "url": "https://www.semanticscholar.org/paper/9f1e9e56d80146766bc2316efbc54d8b770a23df",
            "title": "Deep Reinforcement Learning: An Overview",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2580175322",
                "DBLP": "journals/corr/Li17b",
                "ArXiv": "1701.07274",
                "CorpusId": 17540505
            },
            "abstract": "We give an overview of recent exciting achievements of deep reinforcement learning (RL). We discuss six core elements, six important mechanisms, and twelve applications. We start with background of machine learning, deep learning and reinforcement learning. Next we discuss core RL elements, including value function, in particular, Deep Q-Network (DQN), policy, reward, model, planning, and exploration. After that, we discuss important mechanisms for RL, including attention and memory, unsupervised learning, transfer learning, multi-agent RL, hierarchical RL, and learning to learn. Then we discuss various applications of RL, including games, in particular, AlphaGo, robotics, natural language processing, including dialogue systems, machine translation, and text generation, computer vision, neural architecture design, business management, finance, healthcare, Industry 4.0, smart grid, intelligent transportation systems, and computer systems. We mention topics not reviewed yet, and list a collection of RL resources. After presenting a brief summary, we close with discussions. \nPlease see Deep Reinforcement Learning, arXiv:1810.06339, for a significant update.",
            "referenceCount": 578,
            "citationCount": 1131,
            "influentialCitationCount": 89,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-01-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1701.07274"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2017DeepRL,\n author = {Yuxi Li},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Reinforcement Learning: An Overview},\n volume = {abs/1701.07274},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d25c65d261ea0e6a458be4c50c40ffe5bc508f77",
            "@type": "ScholarlyArticle",
            "paperId": "d25c65d261ea0e6a458be4c50c40ffe5bc508f77",
            "corpusId": 1122604,
            "url": "https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77",
            "title": "Learning Spatiotemporal Features with 3D Convolutional Networks",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/iccv/TranBFTP15",
                "MAG": "1522734439",
                "DOI": "10.1109/ICCV.2015.510",
                "CorpusId": 1122604
            },
            "abstract": "We propose a simple, yet effective approach for spatiotemporal feature learning using deep 3-dimensional convolutional networks (3D ConvNets) trained on a large scale supervised video dataset. Our findings are three-fold: 1) 3D ConvNets are more suitable for spatiotemporal feature learning compared to 2D ConvNets, 2) A homogeneous architecture with small 3x3x3 convolution kernels in all layers is among the best performing architectures for 3D ConvNets, and 3) Our learned features, namely C3D (Convolutional 3D), with a simple linear classifier outperform state-of-the-art methods on 4 different benchmarks and are comparable with current best methods on the other 2 benchmarks. In addition, the features are compact: achieving 52.8% accuracy on UCF101 dataset with only 10 dimensions and also very efficient to compute due to the fast inference of ConvNets. Finally, they are conceptually very simple and easy to train and use.",
            "referenceCount": 62,
            "citationCount": 6992,
            "influentialCitationCount": 1348,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1412.0767",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-12-02",
            "journal": {
                "name": "2015 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tran2014LearningSF,\n author = {Du Tran and Lubomir D. Bourdev and R. Fergus and L. Torresani and Manohar Paluri},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2015 IEEE International Conference on Computer Vision (ICCV)},\n pages = {4489-4497},\n title = {Learning Spatiotemporal Features with 3D Convolutional Networks},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cea967b59209c6be22829699f05b8b1ac4dc092d",
            "@type": "ScholarlyArticle",
            "paperId": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "corpusId": 7961699,
            "url": "https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d",
            "title": "Sequence to Sequence Learning with Neural Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2130942839",
                "DBLP": "conf/nips/SutskeverVL14",
                "ArXiv": "1409.3215",
                "CorpusId": 7961699
            },
            "abstract": "Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.",
            "referenceCount": 40,
            "citationCount": 18140,
            "influentialCitationCount": 1525,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-09-10",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1409.3215"
            },
            "citationStyles": {
                "bibtex": "@Article{Sutskever2014SequenceTS,\n author = {Ilya Sutskever and Oriol Vinyals and Quoc V. Le},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Sequence to Sequence Learning with Neural Networks},\n volume = {abs/1409.3215},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fdb813d8b927bdd21ae1858cafa6c34b66a36268",
            "@type": "ScholarlyArticle",
            "paperId": "fdb813d8b927bdd21ae1858cafa6c34b66a36268",
            "corpusId": 8384258,
            "url": "https://www.semanticscholar.org/paper/fdb813d8b927bdd21ae1858cafa6c34b66a36268",
            "title": "Learning deep structured semantic models for web search using clickthrough data",
            "venue": "International Conference on Information and Knowledge Management",
            "publicationVenue": {
                "id": "urn:research:7431ff67-91dc-41fa-b322-1b1ca657025f",
                "name": "International Conference on Information and Knowledge Management",
                "alternate_names": [
                    "Conference on Information and Knowledge Management",
                    "Conf Inf Knowl Manag",
                    "Int Conf Inf Knowl Manag",
                    "CIKM"
                ],
                "issn": null,
                "url": "http://www.cikm.org/"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/cikm/HuangHGDAH13",
                "MAG": "2136189984",
                "DOI": "10.1145/2505515.2505665",
                "CorpusId": 8384258
            },
            "abstract": "Latent semantic models, such as LSA, intend to map a query to its relevant documents at the semantic level where keyword-based matching often fails. In this study we strive to develop a series of new latent semantic models with a deep structure that project queries and documents into a common low-dimensional space where the relevance of a document given a query is readily computed as the distance between them. The proposed deep structured semantic models are discriminatively trained by maximizing the conditional likelihood of the clicked documents given a query using the clickthrough data. To make our models applicable to large-scale Web search applications, we also use a technique called word hashing, which is shown to effectively scale up our semantic models to handle large vocabularies which are common in such tasks. The new models are evaluated on a Web document ranking task using a real-world data set. Results show that our best model significantly outperforms other latent semantic models, which were considered state-of-the-art in the performance prior to the work presented in this paper.",
            "referenceCount": 25,
            "citationCount": 1795,
            "influentialCitationCount": 261,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2013-10-27",
            "journal": {
                "name": "Proceedings of the 22nd ACM international conference on Information & Knowledge Management",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2013LearningDS,\n author = {Po-Sen Huang and Xiaodong He and Jianfeng Gao and L. Deng and A. Acero and Larry Heck},\n booktitle = {International Conference on Information and Knowledge Management},\n journal = {Proceedings of the 22nd ACM international conference on Information & Knowledge Management},\n title = {Learning deep structured semantic models for web search using clickthrough data},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b49425f78907fcc447d181eb713abffc74dd85e4",
            "@type": "ScholarlyArticle",
            "paperId": "b49425f78907fcc447d181eb713abffc74dd85e4",
            "corpusId": 24718057,
            "url": "https://www.semanticscholar.org/paper/b49425f78907fcc447d181eb713abffc74dd85e4",
            "title": "Sampling Matters in Deep Embedding Learning",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963350250",
                "DBLP": "journals/corr/WuMSK17",
                "ArXiv": "1706.07567",
                "DOI": "10.1109/ICCV.2017.309",
                "CorpusId": 24718057
            },
            "abstract": "Deep embeddings answer one simple question: How similar are two images? Learning these embeddings is the bedrock of verification, zero-shot learning, and visual search. The most prominent approaches optimize a deep convolutional network with a suitable loss function, such as contrastive loss or triplet loss. While a rich line of work focuses solely on the loss functions, we show in this paper that selecting training examples plays an equally important role. We propose distance weighted sampling, which selects more informative and stable examples than traditional approaches. In addition, we show that a simple margin based loss is sufficient to outperform all other loss functions. We evaluate our approach on the Stanford Online Products, CAR196, and the CUB200-2011 datasets for image retrieval and clustering, and on the LFW dataset for face verification. Our method achieves state-of-the-art performance on all of them.",
            "referenceCount": 48,
            "citationCount": 824,
            "influentialCitationCount": 144,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1706.07567",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-06-23",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Manmatha2017SamplingMI,\n author = {R. Manmatha and Chaoxia Wu and Alex Smola and Philipp Kr\u00e4henb\u00fchl},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2017 IEEE International Conference on Computer Vision (ICCV)},\n pages = {2859-2867},\n title = {Sampling Matters in Deep Embedding Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c79eff7de8ffc2436b59b33753c98aa9f67316f6",
            "@type": "ScholarlyArticle",
            "paperId": "c79eff7de8ffc2436b59b33753c98aa9f67316f6",
            "corpusId": 206952673,
            "url": "https://www.semanticscholar.org/paper/c79eff7de8ffc2436b59b33753c98aa9f67316f6",
            "title": "Deep Learning",
            "venue": "Informatik-Spektrum",
            "publicationVenue": {
                "id": "urn:research:518d38cf-179f-480b-b32a-c9d4e6bba46e",
                "name": "Informatik-Spektrum",
                "alternate_names": [
                    "Informatik Spektrum",
                    "Inform Spektrum"
                ],
                "issn": "0170-6012",
                "url": "https://link.springer.com/journal/287"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/insk/Wick17",
                "DOI": "10.1007/s00287-016-1013-2",
                "CorpusId": 206952673
            },
            "abstract": null,
            "referenceCount": 8,
            "citationCount": 10,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Informatik-Spektrum",
                "volume": "40"
            },
            "citationStyles": {
                "bibtex": "@Article{Wick2016DeepL,\n author = {C. Wick},\n booktitle = {Informatik-Spektrum},\n journal = {Informatik-Spektrum},\n pages = {103-107},\n title = {Deep Learning},\n volume = {40},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ad367b44f3434b9ba6b46b41ab083210f6827a9f",
            "@type": "ScholarlyArticle",
            "paperId": "ad367b44f3434b9ba6b46b41ab083210f6827a9f",
            "corpusId": 71638,
            "url": "https://www.semanticscholar.org/paper/ad367b44f3434b9ba6b46b41ab083210f6827a9f",
            "title": "Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2401640538",
                "DBLP": "conf/iclr/LotterKC17",
                "ArXiv": "1605.08104",
                "CorpusId": 71638
            },
            "abstract": "While great strides have been made in using deep learning algorithms to solve supervised learning tasks, the problem of unsupervised learning - leveraging unlabeled examples to learn about the structure of a domain - remains a difficult unsolved challenge. Here, we explore prediction of future frames in a video sequence as an unsupervised learning rule for learning about the structure of the visual world. We describe a predictive neural network (\"PredNet\") architecture that is inspired by the concept of \"predictive coding\" from the neuroscience literature. These networks learn to predict future frames in a video sequence, with each layer in the network making local predictions and only forwarding deviations from those predictions to subsequent network layers. We show that these networks are able to robustly learn to predict the movement of synthetic (rendered) objects, and that in doing so, the networks learn internal representations that are useful for decoding latent object parameters (e.g. pose) that support object recognition with fewer training views. We also show that these networks can scale to complex natural image streams (car-mounted camera videos), capturing key aspects of both egocentric movement and the movement of objects in the visual scene, and the representation learned in this setting is useful for estimating the steering angle. Altogether, these results suggest that prediction represents a powerful framework for unsupervised learning, allowing for implicit learning of object and scene structure.",
            "referenceCount": 70,
            "citationCount": 812,
            "influentialCitationCount": 118,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-05-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1605.08104"
            },
            "citationStyles": {
                "bibtex": "@Article{Lotter2016DeepPC,\n author = {William Lotter and Gabriel Kreiman and David D. Cox},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning},\n volume = {abs/1605.08104},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b20e117d5d05cba6dd070fe50afbb8a71d9a4618",
            "@type": "ScholarlyArticle",
            "paperId": "b20e117d5d05cba6dd070fe50afbb8a71d9a4618",
            "corpusId": 6394568,
            "url": "https://www.semanticscholar.org/paper/b20e117d5d05cba6dd070fe50afbb8a71d9a4618",
            "title": "Deep learning for neuroimaging: a validation study",
            "venue": "Frontiers in Neuroscience",
            "publicationVenue": {
                "id": "urn:research:2ca4279c-8ed7-4280-8022-09e577923a09",
                "name": "Frontiers in Neuroscience",
                "alternate_names": [
                    "Front Neurosci"
                ],
                "issn": "1662-453X",
                "url": "https://www.frontiersin.org/journals/neuroscience"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2974548700",
                "DBLP": "journals/corr/PlisHSC13",
                "PubMedCentral": "4138493",
                "ArXiv": "1312.5847",
                "DOI": "10.3389/fnins.2014.00229",
                "CorpusId": 6394568,
                "PubMed": "25191215"
            },
            "abstract": "Deep learning methods have recently made notable advances in the tasks of classification and representation learning. These tasks are important for brain imaging and neuroscience discovery, making the methods attractive for porting to a neuroimager's toolbox. Success of these methods is, in part, explained by the flexibility of deep learning models. However, this flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. These methods include deep belief networks and their building block the restricted Boltzmann machine. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.",
            "referenceCount": 48,
            "citationCount": 534,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.frontiersin.org/articles/10.3389/fnins.2014.00229/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-12-20",
            "journal": {
                "name": "Frontiers in Neuroscience",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Plis2013DeepLF,\n author = {S. Plis and R. Devon Hjelm and R. Salakhutdinov and V. Calhoun},\n booktitle = {Frontiers in Neuroscience},\n journal = {Frontiers in Neuroscience},\n title = {Deep learning for neuroimaging: a validation study},\n volume = {8},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:99c970348b8f70ce23d6641e201904ea49266b6e",
            "@type": "ScholarlyArticle",
            "paperId": "99c970348b8f70ce23d6641e201904ea49266b6e",
            "corpusId": 17272965,
            "url": "https://www.semanticscholar.org/paper/99c970348b8f70ce23d6641e201904ea49266b6e",
            "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2013,
            "externalIds": {
                "ArXiv": "1312.6120",
                "MAG": "2953334419",
                "DBLP": "journals/corr/SaxeMG13",
                "CorpusId": 17272965
            },
            "abstract": "Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.",
            "referenceCount": 26,
            "citationCount": 1596,
            "influentialCitationCount": 125,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Biology",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-12-20",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1312.6120"
            },
            "citationStyles": {
                "bibtex": "@Article{Saxe2013ExactST,\n author = {Andrew M. Saxe and James L. McClelland and S. Ganguli},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},\n volume = {abs/1312.6120},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e37b999f0c96d7136db07b0185b837d5decd599a",
            "@type": "ScholarlyArticle",
            "paperId": "e37b999f0c96d7136db07b0185b837d5decd599a",
            "corpusId": 18389147,
            "url": "https://www.semanticscholar.org/paper/e37b999f0c96d7136db07b0185b837d5decd599a",
            "title": "Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates",
            "venue": "IEEE International Conference on Robotics and Automation",
            "publicationVenue": {
                "id": "urn:research:3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                "name": "IEEE International Conference on Robotics and Automation",
                "alternate_names": [
                    "International Conference on Robotics and Automation",
                    "Int Conf Robot Autom",
                    "ICRA",
                    "IEEE Int Conf Robot Autom"
                ],
                "issn": "2152-4092",
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1610.00633",
                "MAG": "2575705757",
                "DBLP": "conf/icra/GuHLL17",
                "DOI": "10.1109/ICRA.2017.7989385",
                "CorpusId": 18389147
            },
            "abstract": "Reinforcement learning holds the promise of enabling autonomous robots to learn large repertoires of behavioral skills with minimal human intervention. However, robotic applications of reinforcement learning often compromise the autonomy of the learning process in favor of achieving training times that are practical for real physical systems. This typically involves introducing hand-engineered policy representations and human-supplied demonstrations. Deep reinforcement learning alleviates this limitation by training general-purpose neural network policies, but applications of direct deep reinforcement learning algorithms have so far been restricted to simulated settings and relatively simple tasks, due to their apparent high sample complexity. In this paper, we demonstrate that a recent deep reinforcement learning algorithm based on off-policy training of deep Q-functions can scale to complex 3D manipulation tasks and can learn deep neural network policies efficiently enough to train on real physical robots. We demonstrate that the training times can be further reduced by parallelizing the algorithm across multiple robots which pool their policy updates asynchronously. Our experimental evaluation shows that our method can learn a variety of 3D manipulation skills in simulation and a complex door opening skill on real robots without any prior demonstrations or manually designed representations.",
            "referenceCount": 43,
            "citationCount": 1281,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1610.00633",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-10-03",
            "journal": {
                "name": "2017 IEEE International Conference on Robotics and Automation (ICRA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gu2016DeepRL,\n author = {S. Gu and E. Holly and T. Lillicrap and S. Levine},\n booktitle = {IEEE International Conference on Robotics and Automation},\n journal = {2017 IEEE International Conference on Robotics and Automation (ICRA)},\n pages = {3389-3396},\n title = {Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f500b1a7df00f67c417673e0538d86abb8a333fa",
            "@type": "ScholarlyArticle",
            "paperId": "f500b1a7df00f67c417673e0538d86abb8a333fa",
            "corpusId": 14181993,
            "url": "https://www.semanticscholar.org/paper/f500b1a7df00f67c417673e0538d86abb8a333fa",
            "title": "Facial Landmark Detection by Deep Multi-task Learning",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/eccv/ZhangLLT14",
                "MAG": "1896424170",
                "DOI": "10.1007/978-3-319-10599-4_7",
                "CorpusId": 14181993
            },
            "abstract": null,
            "referenceCount": 37,
            "citationCount": 1359,
            "influentialCitationCount": 125,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-09-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2014FacialLD,\n author = {Zhanpeng Zhang and Ping Luo and Chen Change Loy and Xiaoou Tang},\n booktitle = {European Conference on Computer Vision},\n pages = {94-108},\n title = {Facial Landmark Detection by Deep Multi-task Learning},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c4e08cc529520db05618df152ca1adc1f35ef7e3",
            "@type": "ScholarlyArticle",
            "paperId": "c4e08cc529520db05618df152ca1adc1f35ef7e3",
            "corpusId": 196183153,
            "url": "https://www.semanticscholar.org/paper/c4e08cc529520db05618df152ca1adc1f35ef7e3",
            "title": "Deep Metric Learning to Rank",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/cvpr/Cakir0XKS19",
                "MAG": "2953271441",
                "DOI": "10.1109/CVPR.2019.00196",
                "CorpusId": 196183153
            },
            "abstract": "We propose a novel deep metric learning method by revisiting the learning to rank approach. Our method, named FastAP, optimizes the rank-based Average Precision measure, using an approximation derived from distance quantization. FastAP has a low complexity compared to existing methods, and is tailored for stochastic gradient descent. To fully exploit the benefits of the ranking formulation, we also propose a new minibatch sampling scheme, as well as a simple heuristic to enable large-batch training. On three few-shot image retrieval datasets, FastAP consistently outperforms competing methods, which often involve complex optimization heuristics or costly model ensembles.",
            "referenceCount": 45,
            "citationCount": 221,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-06-01",
            "journal": {
                "name": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{\u00c7akir2019DeepML,\n author = {Fatih \u00c7akir and Kun He and Xide Xia and B. Kulis and S. Sclaroff},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1861-1870},\n title = {Deep Metric Learning to Rank},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2ed619fbc7902155d54f6f21da16ad6c120eac63",
            "@type": "ScholarlyArticle",
            "paperId": "2ed619fbc7902155d54f6f21da16ad6c120eac63",
            "corpusId": 57189150,
            "url": "https://www.semanticscholar.org/paper/2ed619fbc7902155d54f6f21da16ad6c120eac63",
            "title": "Learning to Walk via Deep Reinforcement Learning",
            "venue": "Robotics: Science and Systems",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2963339188",
                "DBLP": "journals/corr/abs-1812-11103",
                "ArXiv": "1812.11103",
                "DOI": "10.15607/RSS.2019.XV.011",
                "CorpusId": 57189150
            },
            "abstract": "Deep reinforcement learning (deep RL) holds the promise of automating the acquisition of complex controllers that can map sensory inputs directly to low-level actions. In the domain of robotic locomotion, deep RL could enable learning locomotion skills with minimal engineering and without an explicit model of the robot dynamics. Unfortunately, applying deep RL to real-world robotic tasks is exceptionally difficult, primarily due to poor sample complexity and sensitivity to hyperparameters. While hyperparameters can be easily tuned in simulated domains, tuning may be prohibitively expensive on physical systems, such as legged robots, that can be damaged through extensive trial-and-error learning. In this paper, we propose a sample-efficient deep RL algorithm based on maximum entropy RL that requires minimal per-task tuning and only a modest number of trials to learn neural network policies. We apply this method to learning walking gaits on a real-world Minitaur robot. Our method can acquire a stable gait from scratch directly in the real world in about two hours, without relying on any model or simulation, and the resulting policy is robust to moderate variations in the environment. We further show that our algorithm achieves state-of-the-art performance on simulated benchmarks with a single set of hyperparameters. Videos of training and the learned policy can be found on the project website.",
            "referenceCount": 62,
            "citationCount": 354,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://doi.org/10.15607/rss.2019.xv.011",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-12-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1812.11103"
            },
            "citationStyles": {
                "bibtex": "@Article{Haarnoja2018LearningTW,\n author = {Tuomas Haarnoja and Aurick Zhou and Sehoon Ha and Jie Tan and G. Tucker and S. Levine},\n booktitle = {Robotics: Science and Systems},\n journal = {ArXiv},\n title = {Learning to Walk via Deep Reinforcement Learning},\n volume = {abs/1812.11103},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d8c35c2c39fdd2ec6af37ddc8c51deb396aefef8",
            "@type": "ScholarlyArticle",
            "paperId": "d8c35c2c39fdd2ec6af37ddc8c51deb396aefef8",
            "corpusId": 26450018,
            "url": "https://www.semanticscholar.org/paper/d8c35c2c39fdd2ec6af37ddc8c51deb396aefef8",
            "title": "Low precision arithmetic for deep learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2950769435",
                "DBLP": "journals/corr/CourbariauxBD14",
                "CorpusId": 26450018
            },
            "abstract": "We simulate the training of a set of state of the art neural networks, the Maxout networks (Goodfellow et al., 2013a), on three benchmark datasets: the MNIST, CIFAR10 and SVHN, with three distinct arithmetics: floating point, fixed point and dynamic fixed point. For each of those datasets and for each of those arithmetics, we assess the impact of the precision of the computations on the final error of the training. We find that very low precision computation is sufficient not just for running trained networks but also for training them. For example, almost state-of-the-art results were obtained on most datasets with 10 bits for computing activations and gradients, and 12 bits for storing updated parameters.",
            "referenceCount": 0,
            "citationCount": 170,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-12-22",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1412.7024"
            },
            "citationStyles": {
                "bibtex": "@Article{Courbariaux2014LowPA,\n author = {Matthieu Courbariaux and Yoshua Bengio and J. David},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Low precision arithmetic for deep learning},\n volume = {abs/1412.7024},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751",
            "@type": "ScholarlyArticle",
            "paperId": "f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751",
            "corpusId": 53111609,
            "url": "https://www.semanticscholar.org/paper/f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751",
            "title": "Deep Reinforcement Learning",
            "venue": "Reinforcement Learning for Cyber-Physical Systems",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2888561335",
                "ArXiv": "1810.06339",
                "DBLP": "journals/corr/abs-1810-06339",
                "DOI": "10.1007/978-3-319-94463-0_9",
                "CorpusId": 53111609
            },
            "abstract": null,
            "referenceCount": 936,
            "citationCount": 304,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1810.06339",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Art",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-10-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1810.06339"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2018DeepRL,\n author = {Yuxi Li},\n booktitle = {Reinforcement Learning for Cyber-Physical Systems},\n journal = {ArXiv},\n title = {Deep Reinforcement Learning},\n volume = {abs/1810.06339},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3ac0fea1e5395cfb0dc1f0ee2b921fe22b23fed0",
            "@type": "ScholarlyArticle",
            "paperId": "3ac0fea1e5395cfb0dc1f0ee2b921fe22b23fed0",
            "corpusId": 14631101,
            "url": "https://www.semanticscholar.org/paper/3ac0fea1e5395cfb0dc1f0ee2b921fe22b23fed0",
            "title": "Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/icml/FoersterNFATKW17",
                "MAG": "2949201811",
                "ArXiv": "1702.08887",
                "CorpusId": 14631101
            },
            "abstract": "Many real-world problems, such as network packet routing and urban traffic control, are naturally modeled as multi-agent reinforcement learning (RL) problems. However, existing multi-agent RL methods typically scale poorly in the problem size. Therefore, a key challenge is to translate the success of deep learning on single-agent RL to the multi-agent setting. A major stumbling block is that independent Q-learning, the most popular multi-agent RL method, introduces nonstationarity that makes it incompatible with the experience replay memory on which deep Q-learning relies. This paper proposes two methods that address this problem: 1) using a multi-agent variant of importance sampling to naturally decay obsolete data and 2) conditioning each agent's value function on a fingerprint that disambiguates the age of the data sampled from the replay memory. Results on a challenging decentralised variant of StarCraft unit micro-management confirm that these methods enable the successful combination of experience replay with multi-agent RL.",
            "referenceCount": 38,
            "citationCount": 516,
            "influentialCitationCount": 41,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-02-28",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Foerster2017StabilisingER,\n author = {Jakob N. Foerster and Nantas Nardelli and Gregory Farquhar and Triantafyllos Afouras and Philip H. S. Torr and Pushmeet Kohli and Shimon Whiteson},\n booktitle = {International Conference on Machine Learning},\n pages = {1146-1155},\n title = {Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1d81e7f428fea2b2e15ee3a96fe843ca603acc4c",
            "@type": "ScholarlyArticle",
            "paperId": "1d81e7f428fea2b2e15ee3a96fe843ca603acc4c",
            "corpusId": 220363476,
            "url": "https://www.semanticscholar.org/paper/1d81e7f428fea2b2e15ee3a96fe843ca603acc4c",
            "title": "Simple and Deep Graph Convolutional Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3039474590",
                "DBLP": "conf/icml/ChenWHDL20",
                "ArXiv": "2007.02133",
                "CorpusId": 220363476
            },
            "abstract": "Graph convolutional networks (GCNs) are a powerful deep learning approach for graph-structured data. Recently, GCNs and subsequent variants have shown superior performance in various application areas on real-world datasets. Despite their success, most of the current GCN models are shallow, due to the {\\em over-smoothing} problem. In this paper, we study the problem of designing and analyzing deep graph convolutional networks. We propose the GCNII, an extension of the vanilla GCN model with two simple yet effective techniques: {\\em Initial residual} and {\\em Identity mapping}. We provide theoretical and empirical evidence that the two techniques effectively relieves the problem of over-smoothing. Our experiments show that the deep GCNII model outperforms the state-of-the-art methods on various semi- and full-supervised tasks. Code is available at this https URL .",
            "referenceCount": 52,
            "citationCount": 895,
            "influentialCitationCount": 244,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-07-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2020SimpleAD,\n author = {Ming Chen and Zhewei Wei and Zengfeng Huang and Bolin Ding and Yaliang Li},\n booktitle = {International Conference on Machine Learning},\n pages = {1725-1735},\n title = {Simple and Deep Graph Convolutional Networks},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:207f85142c44efe3ef0bb13a12f3cc2973b68801",
            "@type": "ScholarlyArticle",
            "paperId": "207f85142c44efe3ef0bb13a12f3cc2973b68801",
            "corpusId": 6116678,
            "url": "https://www.semanticscholar.org/paper/207f85142c44efe3ef0bb13a12f3cc2973b68801",
            "title": "Deep Contrast Learning for Salient Object Detection",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/cvpr/LiY16",
                "ArXiv": "1603.01976",
                "MAG": "2293332611",
                "DOI": "10.1109/CVPR.2016.58",
                "CorpusId": 6116678
            },
            "abstract": "Salient object detection has recently witnessed substantial progress due to powerful features extracted using deep convolutional neural networks (CNNs). However, existing CNN-based methods operate at the patch level instead of the pixel level. Resulting saliency maps are typically blurry, especially near the boundary of salient objects. Furthermore, image patches are treated as independent samples even when they are overlapping, giving rise to significant redundancy in computation and storage. In this paper, we propose an end-to-end deep contrast network to overcome the aforementioned limitations. Our deep network consists of two complementary components, a pixel-level fully convolutional stream and a segment-wise spatial pooling stream. The first stream directly produces a saliency map with pixel-level accuracy from an input image. The second stream extracts segment-wise features very efficiently, and better models saliency discontinuities along object boundaries. Finally, a fully connected CRF model can be optionally incorporated to improve spatial coherence and contour localization in the fused result from these two streams. Experimental results demonstrate that our deep model significantly improves the state of the art.",
            "referenceCount": 52,
            "citationCount": 699,
            "influentialCitationCount": 139,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1603.01976",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-03-07",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Li2016DeepCL,\n author = {Guanbin Li and Yizhou Yu},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {478-487},\n title = {Deep Contrast Learning for Salient Object Detection},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:041d99f442dc22cf51118dc992095be9aa0972e0",
            "@type": "ScholarlyArticle",
            "paperId": "041d99f442dc22cf51118dc992095be9aa0972e0",
            "corpusId": 5011374,
            "url": "https://www.semanticscholar.org/paper/041d99f442dc22cf51118dc992095be9aa0972e0",
            "title": "A Study on Overfitting in Deep Reinforcement Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1804-06893",
                "ArXiv": "1804.06893",
                "MAG": "2797527950",
                "CorpusId": 5011374
            },
            "abstract": "Recent years have witnessed significant progresses in deep Reinforcement Learning (RL). Empowered with large scale neural networks, carefully designed architectures, novel training algorithms and massively parallel computing devices, researchers are able to attack many challenging RL problems. However, in machine learning, more training power comes with a potential risk of more overfitting. As deep RL techniques are being applied to critical problems such as healthcare and finance, it is important to understand the generalization behaviors of the trained agents. In this paper, we conduct a systematic study of standard RL agents and find that they could overfit in various ways. Moreover, overfitting could happen \"robustly\": commonly used techniques in RL that add stochasticity do not necessarily prevent or detect overfitting. In particular, the same agents and learning algorithms could have drastically different test performance, even when all of them achieve optimal rewards during training. The observations call for more principled and careful evaluation protocols in RL. We conclude with a general discussion on overfitting in RL and a study of the generalization behaviors from the perspective of inductive bias.",
            "referenceCount": 59,
            "citationCount": 321,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-18",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1804.06893"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018ASO,\n author = {Chiyuan Zhang and Oriol Vinyals and R. Munos and Samy Bengio},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A Study on Overfitting in Deep Reinforcement Learning},\n volume = {abs/1804.06893},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e3b0ea7209731c47b582215c6c67f9c691ad9863",
            "@type": "ScholarlyArticle",
            "paperId": "e3b0ea7209731c47b582215c6c67f9c691ad9863",
            "corpusId": 10208474,
            "url": "https://www.semanticscholar.org/paper/e3b0ea7209731c47b582215c6c67f9c691ad9863",
            "title": "Deep Q-learning From Demonstrations",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2950392377",
                "DBLP": "conf/aaai/HesterVPLSPHQSO18",
                "DOI": "10.1609/aaai.v32i1.11757",
                "CorpusId": 10208474
            },
            "abstract": "\n \n Deep reinforcement learning (RL) has achieved several high profile successes in difficult decision-making problems. However, these algorithms typically require a huge amount of data before they reach reasonable performance. In fact, their performance during learning can be extremely poor. This may be acceptable for a simulator, but it severely limits the applicability of deep RL to many real-world tasks, where the agent must learn in the real environment. In this paper we study a setting where the agent may access data from previous control of the system. We present an algorithm, Deep Q-learning from Demonstrations (DQfD), that leverages small sets of demonstration data to massively accelerate the learning process even from relatively small amounts of demonstration data and is able to automatically assess the necessary ratio of demonstration data while learning thanks to a prioritized replay mechanism. DQfD works by combining temporal difference updates with supervised classification of the demonstrator\u2019s actions. We show that DQfD has better initial performance than Prioritized Dueling Double Deep Q-Networks (PDD DQN) as it starts with better scores on the first million steps on 41 of 42 games and on average it takes PDD DQN 83 million steps to catch up to DQfD\u2019s performance. DQfD learns to out-perform the best demonstration given in 14 of 42 games. In addition, DQfD leverages human demonstrations to achieve state-of-the-art results for 11 games. Finally, we show that DQfD performs better than three related algorithms for incorporating demonstration data into DQN.\n \n",
            "referenceCount": 47,
            "citationCount": 830,
            "influentialCitationCount": 94,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/11757/11616",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-04-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hester2017DeepQF,\n author = {Todd Hester and Matej Vecer\u00edk and O. Pietquin and Marc Lanctot and T. Schaul and Bilal Piot and Dan Horgan and John Quan and A. Sendonaris and Ian Osband and Gabriel Dulac-Arnold and J. Agapiou and Joel Z. Leibo and A. Gruslys},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {3223-3230},\n title = {Deep Q-learning From Demonstrations},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:43ef6f1b1c0622a23bc62af5a05dd5c813eba00d",
            "@type": "ScholarlyArticle",
            "paperId": "43ef6f1b1c0622a23bc62af5a05dd5c813eba00d",
            "corpusId": 3278107,
            "url": "https://www.semanticscholar.org/paper/43ef6f1b1c0622a23bc62af5a05dd5c813eba00d",
            "title": "Deep Active Learning for Named Entity Recognition",
            "venue": "Rep4NLP@ACL",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2736885633",
                "DBLP": "conf/rep4nlp/ShenYLKA17",
                "ArXiv": "1707.05928",
                "ACL": "W17-2630",
                "DOI": "10.18653/v1/W17-2630",
                "CorpusId": 3278107
            },
            "abstract": "Deep neural networks have advanced the state of the art in named entity recognition. However, under typical training procedures, advantages over classical methods emerge only with large datasets. As a result, deep learning is employed only when large public datasets or a large budget for manually labeling data is available. In this work, we show otherwise: by combining deep learning with active learning, we can outperform classical methods even with a significantly smaller amount of training data.",
            "referenceCount": 56,
            "citationCount": 395,
            "influentialCitationCount": 52,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/W17-2630.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shen2017DeepAL,\n author = {Yanyao Shen and Hyokun Yun and Zachary Chase Lipton and Y. Kronrod and Anima Anandkumar},\n booktitle = {Rep4NLP@ACL},\n pages = {252-256},\n title = {Deep Active Learning for Named Entity Recognition},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:06ad6c93723fa1695fe01e0710ec6bfde2727f1b",
            "@type": "ScholarlyArticle",
            "paperId": "06ad6c93723fa1695fe01e0710ec6bfde2727f1b",
            "corpusId": 3732882,
            "url": "https://www.semanticscholar.org/paper/06ad6c93723fa1695fe01e0710ec6bfde2727f1b",
            "title": "Learning Fine-Grained Image Similarity with Deep Ranking",
            "venue": "2014 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "ArXiv": "1404.4661",
                "MAG": "2950096404",
                "DBLP": "journals/corr/WangSLRWPCW14",
                "DOI": "10.1109/CVPR.2014.180",
                "CorpusId": 3732882
            },
            "abstract": "Learning fine-grained image similarity is a challenging task. It needs to capture between-class and within-class image differences. This paper proposes a deep ranking model that employs deep learning techniques to learn similarity metric directly from images. It has higher learning capability than models based on hand-crafted features. A novel multiscale network structure has been developed to describe the images effectively. An efficient triplet sampling algorithm is also proposed to learn the model with distributed asynchronized stochastic gradient. Extensive experiments show that the proposed algorithm outperforms models based on hand-crafted visual features and deep classification models.",
            "referenceCount": 26,
            "citationCount": 1241,
            "influentialCitationCount": 90,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://authors.library.caltech.edu/61511/1/06909576.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-04-17",
            "journal": {
                "name": "2014 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2014LearningFI,\n author = {Jiang Wang and Yang Song and Thomas Leung and C. Rosenberg and Jingbin Wang and James Philbin and Bo Chen and Ying Wu},\n booktitle = {2014 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2014 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {1386-1393},\n title = {Learning Fine-Grained Image Similarity with Deep Ranking},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9f56bda06700297fe8a8aab4bb429451cee9a441",
            "@type": "ScholarlyArticle",
            "paperId": "9f56bda06700297fe8a8aab4bb429451cee9a441",
            "corpusId": 53015027,
            "url": "https://www.semanticscholar.org/paper/9f56bda06700297fe8a8aab4bb429451cee9a441",
            "title": "Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2895992958",
                "ArXiv": "1810.08033",
                "DBLP": "journals/corr/abs-1810-08033",
                "CorpusId": 53015027
            },
            "abstract": "Deep learning has shown high performances in various types of tasks from visual recognition to natural language processing, which indicates superior flexibility and adaptivity of deep learning. To understand this phenomenon theoretically, we develop a new approximation and estimation error analysis of deep learning with the ReLU activation for functions in a Besov space and its variant with mixed smoothness. The Besov space is a considerably general function space including the Holder space and Sobolev space, and especially can capture spatial inhomogeneity of smoothness. Through the analysis in the Besov space, it is shown that deep learning can achieve the minimax optimal rate and outperform any non-adaptive (linear) estimator such as kernel ridge regression, which shows that deep learning has higher adaptivity to the spatial inhomogeneity of the target function than other estimators such as linear ones. In addition to this, it is shown that deep learning can avoid the curse of dimensionality if the target function is in a mixed smooth Besov space. We also show that the dependency of the convergence rate on the dimensionality is tight due to its minimax optimality. These results support high adaptivity of deep learning and its superior ability as a feature extractor.",
            "referenceCount": 72,
            "citationCount": 195,
            "influentialCitationCount": 37,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1810.08033"
            },
            "citationStyles": {
                "bibtex": "@Article{Suzuki2018AdaptivityOD,\n author = {Taiji Suzuki},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Adaptivity of deep ReLU network for learning in Besov and mixed smooth Besov spaces: optimal rate and curse of dimensionality},\n volume = {abs/1810.08033},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f96478d0694f18384934fc19a2655170f32e2d8c",
            "@type": "ScholarlyArticle",
            "paperId": "f96478d0694f18384934fc19a2655170f32e2d8c",
            "corpusId": 9398383,
            "url": "https://www.semanticscholar.org/paper/f96478d0694f18384934fc19a2655170f32e2d8c",
            "title": "Deep Direct Reinforcement Learning for Financial Signal Representation and Trading",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/tnn/DengBKRD17",
                "MAG": "2344786740",
                "DOI": "10.1109/TNNLS.2016.2522401",
                "CorpusId": 9398383,
                "PubMed": "26890927"
            },
            "abstract": "Can we train the computer to beat experienced traders for financial assert trading? In this paper, we try to address this challenge by introducing a recurrent deep neural network (NN) for real-time financial signal representation and trading. Our model is inspired by two biological-related learning concepts of deep learning (DL) and reinforcement learning (RL). In the framework, the DL part automatically senses the dynamic market condition for informative feature learning. Then, the RL module interacts with deep representations and makes trading decisions to accumulate the ultimate rewards in an unknown environment. The learning system is implemented in a complex NN that exhibits both the deep and recurrent structures. Hence, we propose a task-aware backpropagation through time method to cope with the gradient vanishing issue in deep training. The robustness of the neural system is verified on both the stock and the commodity future markets under broad testing conditions.",
            "referenceCount": 46,
            "citationCount": 532,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-01",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "28"
            },
            "citationStyles": {
                "bibtex": "@Article{Deng2017DeepDR,\n author = {Yue Deng and Feng Bao and Youyong Kong and Zhiquan Ren and Qionghai Dai},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {653-664},\n title = {Deep Direct Reinforcement Learning for Financial Signal Representation and Trading},\n volume = {28},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1e80f755bcbf10479afd2338cec05211fdbd325c",
            "@type": "ScholarlyArticle",
            "paperId": "1e80f755bcbf10479afd2338cec05211fdbd325c",
            "corpusId": 12008458,
            "url": "https://www.semanticscholar.org/paper/1e80f755bcbf10479afd2338cec05211fdbd325c",
            "title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2130325614",
                "DBLP": "conf/icml/LeeGRN09",
                "DOI": "10.1145/1553374.1553453",
                "CorpusId": 12008458
            },
            "abstract": "There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.",
            "referenceCount": 30,
            "citationCount": 2638,
            "influentialCitationCount": 206,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-06-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lee2009ConvolutionalDB,\n author = {Honglak Lee and R. Grosse and R. Ranganath and A. Ng},\n booktitle = {International Conference on Machine Learning},\n pages = {609-616},\n title = {Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a45f78ca9f250b24cb82fd19614aa2cac9401583",
            "@type": "ScholarlyArticle",
            "paperId": "a45f78ca9f250b24cb82fd19614aa2cac9401583",
            "corpusId": 4234245,
            "url": "https://www.semanticscholar.org/paper/a45f78ca9f250b24cb82fd19614aa2cac9401583",
            "title": "Learning Deep Feature Representations with Domain Guided Dropout for Person Re-identification",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1604.07528",
                "DBLP": "conf/cvpr/XiaoLOW16",
                "MAG": "2342611082",
                "DOI": "10.1109/cvpr.2016.140",
                "CorpusId": 4234245
            },
            "abstract": "Learning generic and robust feature representations with data from multiple domains for the same problem is of great value, especially for the problems that have multiple datasets but none of them are large enough to provide abundant data variations. In this work, we present a pipeline for learning deep feature representations from multiple domains with Convolutional Neural Networks (CNNs). When training a CNN with data from all the domains, some neurons learn representations shared across several domains, while some others are effective only for a specific one. Based on this important observation, we propose a Domain Guided Dropout algorithm to improve the feature learning procedure. Experiments show the effectiveness of our pipeline and the proposed algorithm. Our methods on the person re-identification problem outperform stateof-the-art methods on multiple datasets by large margins.",
            "referenceCount": 51,
            "citationCount": 953,
            "influentialCitationCount": 89,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1604.07528",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-04-26",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Xiao2016LearningDF,\n author = {Tong Xiao and Hongsheng Li and Wanli Ouyang and Xiaogang Wang},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1249-1258},\n title = {Learning Deep Feature Representations with Domain Guided Dropout for Person Re-identification},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d37620e6f8fe678a43e12930743281cd8cca6a66",
            "@type": "ScholarlyArticle",
            "paperId": "d37620e6f8fe678a43e12930743281cd8cca6a66",
            "corpusId": 4669377,
            "url": "https://www.semanticscholar.org/paper/d37620e6f8fe678a43e12930743281cd8cca6a66",
            "title": "Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2950799402",
                "ArXiv": "1604.06057",
                "DBLP": "conf/nips/KulkarniNST16",
                "CorpusId": 4669377
            },
            "abstract": "Learning goal-directed behavior in environments with sparse feedback is a major challenge for reinforcement learning algorithms. The primary difficulty arises due to insufficient exploration, resulting in an agent being unable to learn robust value functions. Intrinsically motivated agents can explore new behavior for its own sake rather than to directly solve problems. Such intrinsic behaviors could eventually help the agent solve tasks posed by the environment. We present hierarchical-DQN (h-DQN), a framework to integrate hierarchical value functions, operating at different temporal scales, with intrinsically motivated deep reinforcement learning. A top-level value function learns a policy over intrinsic goals, and a lower-level function learns a policy over atomic actions to satisfy the given goals. h-DQN allows for flexible goal specifications, such as functions over entities and relations. This provides an efficient space for exploration in complicated environments. We demonstrate the strength of our approach on two problems with very sparse, delayed feedback: (1) a complex discrete stochastic decision process, and (2) the classic ATARI game `Montezuma's Revenge'.",
            "referenceCount": 56,
            "citationCount": 980,
            "influentialCitationCount": 87,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-04-20",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1604.06057"
            },
            "citationStyles": {
                "bibtex": "@Article{Kulkarni2016HierarchicalDR,\n author = {Tejas D. Kulkarni and Karthik Narasimhan and A. Saeedi and J. Tenenbaum},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation},\n volume = {abs/1604.06057},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1ab7aa767e1779c87d822325859e47fe2986e6b2",
            "@type": "ScholarlyArticle",
            "paperId": "1ab7aa767e1779c87d822325859e47fe2986e6b2",
            "corpusId": 207244918,
            "url": "https://www.semanticscholar.org/paper/1ab7aa767e1779c87d822325859e47fe2986e6b2",
            "title": "Resource Management with Deep Reinforcement Learning",
            "venue": "ACM Workshop on Hot Topics in Networks",
            "publicationVenue": {
                "id": "urn:research:89d61e17-5d06-4d45-a0d0-c7b62b0a35b4",
                "name": "ACM Workshop on Hot Topics in Networks",
                "alternate_names": [
                    "HotNets",
                    "ACM Workshop Hot Top Netw",
                    "Hot Top Netw",
                    "Hot Topics in Networks"
                ],
                "issn": null,
                "url": "http://www.sigcomm.org/events/hotnets-workshop"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/hotnets/MaoAMK16",
                "MAG": "2546571074",
                "DOI": "10.1145/3005745.3005750",
                "CorpusId": 207244918
            },
            "abstract": "Resource management problems in systems and networking often manifest as difficult online decision making tasks where appropriate solutions depend on understanding the workload and environment. Inspired by recent advances in deep reinforcement learning for AI problems, we consider building systems that learn to manage resources directly from experience. We present DeepRM, an example solution that translates the problem of packing tasks with multiple resource demands into a learning problem. Our initial results show that DeepRM performs comparably to state-of-the-art heuristics, adapts to different conditions, converges quickly, and learns strategies that are sensible in hindsight.",
            "referenceCount": 42,
            "citationCount": 909,
            "influentialCitationCount": 91,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2016-11-09",
            "journal": {
                "name": "Proceedings of the 15th ACM Workshop on Hot Topics in Networks",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Mao2016ResourceMW,\n author = {Hongzi Mao and Mohammad Alizadeh and Ishai Menache and Srikanth Kandula},\n booktitle = {ACM Workshop on Hot Topics in Networks},\n journal = {Proceedings of the 15th ACM Workshop on Hot Topics in Networks},\n title = {Resource Management with Deep Reinforcement Learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d358d41c69450b171327ebd99462b6afef687269",
            "@type": "ScholarlyArticle",
            "paperId": "d358d41c69450b171327ebd99462b6afef687269",
            "corpusId": 890737,
            "url": "https://www.semanticscholar.org/paper/d358d41c69450b171327ebd99462b6afef687269",
            "title": "Continuous Deep Q-Learning with Model-based Acceleration",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1603.00748",
                "DBLP": "journals/corr/GuLSL16",
                "MAG": "2290354866",
                "CorpusId": 890737
            },
            "abstract": "Model-free reinforcement learning has been successfully applied to a range of challenging problems, and has recently been extended to handle large neural network policies and value functions. However, the sample complexity of modelfree algorithms, particularly when using high-dimensional function approximators, tends to limit their applicability to physical systems. In this paper, we explore algorithms and representations to reduce the sample complexity of deep reinforcement learning for continuous control tasks. We propose two complementary techniques for improving the efficiency of such algorithms. First, we derive a continuous variant of the Q-learning algorithm, which we call normalized advantage functions (NAF), as an alternative to the more commonly used policy gradient and actor-critic methods. NAF representation allows us to apply Q-learning with experience replay to continuous tasks, and substantially improves performance on a set of simulated robotic control tasks. To further improve the efficiency of our approach, we explore the use of learned models for accelerating model-free reinforcement learning. We show that iteratively refitted local linear models are especially effective for this, and demonstrate substantially faster learning on domains where such models are applicable.",
            "referenceCount": 41,
            "citationCount": 894,
            "influentialCitationCount": 87,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-03-02",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gu2016ContinuousDQ,\n author = {S. Gu and T. Lillicrap and Ilya Sutskever and S. Levine},\n booktitle = {International Conference on Machine Learning},\n pages = {2829-2838},\n title = {Continuous Deep Q-Learning with Model-based Acceleration},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c88dbaa5d8f4c915e286be5e38b5599038220493",
            "@type": "ScholarlyArticle",
            "paperId": "c88dbaa5d8f4c915e286be5e38b5599038220493",
            "corpusId": 10726895,
            "url": "https://www.semanticscholar.org/paper/c88dbaa5d8f4c915e286be5e38b5599038220493",
            "title": "Learning Deep Representation for Imbalanced Classification",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/cvpr/HuangLLT16",
                "MAG": "2440599146",
                "DOI": "10.1109/CVPR.2016.580",
                "CorpusId": 10726895
            },
            "abstract": "Data in vision domain often exhibit highly-skewed class distribution, i.e., most data belong to a few majority classes, while the minority classes only contain a scarce amount of instances. To mitigate this issue, contemporary classification methods based on deep convolutional neural network (CNN) typically follow classic strategies such as class re-sampling or cost-sensitive training. In this paper, we conduct extensive and systematic experiments to validate the effectiveness of these classic schemes for representation learning on class-imbalanced data. We further demonstrate that more discriminative deep representation can be learned by enforcing a deep network to maintain both intercluster and inter-class margins. This tighter constraint effectively reduces the class imbalance inherent in the local data neighborhood. We show that the margins can be easily deployed in standard deep learning framework through quintuplet instance sampling and the associated triple-header hinge loss. The representation learned by our approach, when combined with a simple k-nearest neighbor (kNN) algorithm, shows significant improvements over existing methods on both high-and low-level vision classification tasks that exhibit imbalanced class distribution.",
            "referenceCount": 53,
            "citationCount": 785,
            "influentialCitationCount": 51,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-27",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2016LearningDR,\n author = {Chen Huang and Yining Li and Chen Change Loy and Xiaoou Tang},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {5375-5384},\n title = {Learning Deep Representation for Imbalanced Classification},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a9b901fcd68a3715d5ef186a398476bc1e762b0e",
            "@type": "ScholarlyArticle",
            "paperId": "a9b901fcd68a3715d5ef186a398476bc1e762b0e",
            "corpusId": 189762438,
            "url": "https://www.semanticscholar.org/paper/a9b901fcd68a3715d5ef186a398476bc1e762b0e",
            "title": "Deep Reinforcement Learning for Cyber Security",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1906-05799",
                "ArXiv": "1906.05799",
                "MAG": "2952298682",
                "DOI": "10.1109/TNNLS.2021.3121870",
                "CorpusId": 189762438,
                "PubMed": "34723814"
            },
            "abstract": "The scale of Internet-connected systems has increased considerably, and these systems are being exposed to cyberattacks more than ever. The complexity and dynamics of cyberattacks require protecting mechanisms to be responsive, adaptive, and scalable. Machine learning, or more specifically deep reinforcement learning (DRL), methods have been proposed widely to address these issues. By incorporating deep learning into traditional RL, DRL is highly capable of solving complex, dynamic, and especially high-dimensional cyber defense problems. This article presents a survey of DRL approaches developed for cyber security. We touch on different vital aspects, including DRL-based security methods for cyber\u2013physical systems, autonomous intrusion detection techniques, and multiagent DRL-based game theory simulations for defense strategies against cyberattacks. Extensive discussions and future research directions on DRL-based cyber security are also given. We expect that this comprehensive review provides the foundations for and facilitates future studies on exploring the potential of emerging DRL to cope with increasingly complex cyber security problems.",
            "referenceCount": 219,
            "citationCount": 172,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1906.05799",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-06-13",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "34"
            },
            "citationStyles": {
                "bibtex": "@Article{Nguyen2019DeepRL,\n author = {T. Nguyen and V. Reddi},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {3779-3795},\n title = {Deep Reinforcement Learning for Cyber Security},\n volume = {34},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e010ba3ff5744604cdbfe44a733e2a98649ee907",
            "@type": "ScholarlyArticle",
            "paperId": "e010ba3ff5744604cdbfe44a733e2a98649ee907",
            "corpusId": 4780901,
            "url": "https://www.semanticscholar.org/paper/e010ba3ff5744604cdbfe44a733e2a98649ee907",
            "title": "Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations",
            "venue": "Robotics: Science and Systems",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963411833",
                "DBLP": "journals/corr/abs-1709-10087",
                "ArXiv": "1709.10087",
                "DOI": "10.15607/RSS.2018.XIV.049",
                "CorpusId": 4780901
            },
            "abstract": "Dexterous multi-fingered hands are extremely versatile and provide a generic way to perform multiple tasks in human-centric environments. However, effectively controlling them remains challenging due to their high dimensionality and large number of potential contacts. Deep reinforcement learning (DRL) provides a model-agnostic approach to control complex dynamical systems, but has not been shown to scale to high-dimensional dexterous manipulation. Furthermore, deployment of DRL on physical systems remains challenging due to sample inefficiency. Thus, the success of DRL in robotics has thus far been limited to simpler manipulators and tasks. In this work, we show that model-free DRL with natural policy gradients can effectively scale up to complex manipulation tasks with a high-dimensional 24-DoF hand, and solve them from scratch in simulated experiments. Furthermore, with the use of a small number of human demonstrations, the sample complexity can be significantly reduced, and enable learning within the equivalent of a few hours of robot experience. We demonstrate successful policies for multiple complex tasks: object relocation, in-hand manipulation, tool use, and door opening.",
            "referenceCount": 62,
            "citationCount": 790,
            "influentialCitationCount": 81,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://doi.org/10.15607/rss.2018.xiv.049",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-09-28",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1709.10087"
            },
            "citationStyles": {
                "bibtex": "@Article{Rajeswaran2017LearningCD,\n author = {A. Rajeswaran and Vikash Kumar and Abhishek Gupta and J. Schulman and E. Todorov and S. Levine},\n booktitle = {Robotics: Science and Systems},\n journal = {ArXiv},\n title = {Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations},\n volume = {abs/1709.10087},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:faa98e73eeee551c40923c896817ab640925ce20",
            "@type": "ScholarlyArticle",
            "paperId": "faa98e73eeee551c40923c896817ab640925ce20",
            "corpusId": 4531078,
            "url": "https://www.semanticscholar.org/paper/faa98e73eeee551c40923c896817ab640925ce20",
            "title": "Deep Image Prior",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "3009780702",
                "DBLP": "conf/cvpr/UlyanovVL18",
                "ArXiv": "1711.10925",
                "DOI": "10.1007/s11263-020-01303-4",
                "CorpusId": 4531078
            },
            "abstract": null,
            "referenceCount": 69,
            "citationCount": 2317,
            "influentialCitationCount": 479,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1711.10925",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-29",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "128"
            },
            "citationStyles": {
                "bibtex": "@Article{Ulyanov2017DeepIP,\n author = {Dmitry Ulyanov and A. Vedaldi and V. Lempitsky},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {1867 - 1888},\n title = {Deep Image Prior},\n volume = {128},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0197f278e2dedd67ec5067f47037b8cdd3ae8509",
            "@type": "ScholarlyArticle",
            "paperId": "0197f278e2dedd67ec5067f47037b8cdd3ae8509",
            "corpusId": 38582742,
            "url": "https://www.semanticscholar.org/paper/0197f278e2dedd67ec5067f47037b8cdd3ae8509",
            "title": "Deep Multimodal Learning: A Survey on Recent Advances and Trends",
            "venue": "IEEE Signal Processing Magazine",
            "publicationVenue": {
                "id": "urn:research:f62e5eab-173a-4e0a-a963-ed8de9835d22",
                "name": "IEEE Signal Processing Magazine",
                "alternate_names": [
                    "IEEE Signal Process Mag"
                ],
                "issn": "1053-5888",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=79"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2767290858",
                "DBLP": "journals/spm/RamachandramT17",
                "DOI": "10.1109/MSP.2017.2738401",
                "CorpusId": 38582742
            },
            "abstract": "The success of deep learning has been a catalyst to solving increasingly complex machine-learning problems, which often involve multiple data modalities. We review recent advances in deep multimodal learning and highlight the state-of the art, as well as gaps and challenges in this active research field. We first classify deep multimodal learning architectures and then discuss methods to fuse learned multimodal representations in deep-learning architectures. We highlight two areas of research&#x02013;regularization strategies and methods that learn or optimize multimodal fusion structures&#x02013;as exciting areas for future work.",
            "referenceCount": 104,
            "citationCount": 521,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-11-09",
            "journal": {
                "name": "IEEE Signal Processing Magazine",
                "volume": "34"
            },
            "citationStyles": {
                "bibtex": "@Article{Ramachandram2017DeepML,\n author = {D. Ramachandram and Graham W. Taylor},\n booktitle = {IEEE Signal Processing Magazine},\n journal = {IEEE Signal Processing Magazine},\n pages = {96-108},\n title = {Deep Multimodal Learning: A Survey on Recent Advances and Trends},\n volume = {34},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3acff13163f51765bb36147f6107967765509d9b",
            "@type": "ScholarlyArticle",
            "paperId": "3acff13163f51765bb36147f6107967765509d9b",
            "corpusId": 238353897,
            "url": "https://www.semanticscholar.org/paper/3acff13163f51765bb36147f6107967765509d9b",
            "title": "Deep Neural Networks and Tabular Data: A Survey",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2110-01889",
                "ArXiv": "2110.01889",
                "DOI": "10.1109/TNNLS.2022.3229161",
                "CorpusId": 238353897,
                "PubMed": "37015381"
            },
            "abstract": "Heterogeneous tabular data are the most commonly used form of data and are essential for numerous critical and computationally demanding applications. On homogeneous datasets, deep neural networks have repeatedly shown excellent performance and have therefore been widely adopted. However, their adaptation to tabular data for inference or data generation tasks remains highly challenging. To facilitate further progress in the field, this work provides an overview of state-of-the-art deep learning methods for tabular data. We categorize these methods into three groups: data transformations, specialized architectures, and regularization models. For each of these groups, our work offers a comprehensive overview of the main approaches. Moreover, we discuss deep learning approaches for generating tabular data and also provide an overview over strategies for explaining deep models on tabular data. Thus, our first contribution is to address the main research streams and existing methodologies in the mentioned areas while highlighting relevant challenges and open research questions. Our second contribution is to provide an empirical comparison of traditional machine learning methods with 11 deep learning approaches across five popular real-world tabular datasets of different sizes and with different learning objectives. Our results, which we have made publicly available as competitive benchmarks, indicate that algorithms based on gradient-boosted tree ensembles still mostly outperform deep learning models on supervised learning tasks, suggesting that the research progress on competitive deep learning models for tabular data is stagnating. To the best of our knowledge, this is the first in-depth overview of deep learning approaches for tabular data; as such, this work can serve as a valuable starting point to guide researchers and practitioners interested in deep learning with tabular data.",
            "referenceCount": 228,
            "citationCount": 254,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2110.01889",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-10-05",
            "journal": {
                "name": "IEEE transactions on neural networks and learning systems",
                "volume": "PP"
            },
            "citationStyles": {
                "bibtex": "@Article{Borisov2021DeepNN,\n author = {V. Borisov and Tobias Leemann and Kathrin Se\u00dfler and Johannes Haug and Martin Pawelczyk and G. Kasneci},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE transactions on neural networks and learning systems},\n title = {Deep Neural Networks and Tabular Data: A Survey},\n volume = {PP},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b3e025049142be3d97d559cca12b027f16c6349e",
            "@type": "ScholarlyArticle",
            "paperId": "b3e025049142be3d97d559cca12b027f16c6349e",
            "corpusId": 6363483,
            "url": "https://www.semanticscholar.org/paper/b3e025049142be3d97d559cca12b027f16c6349e",
            "title": "Deep Architectures and Deep Learning in Chemoinformatics: The Prediction of Aqueous Solubility for Drug-Like Molecules",
            "venue": "Journal of Chemical Information and Modeling",
            "publicationVenue": {
                "id": "urn:research:3f16aef5-6b9f-4f87-baca-cbf8147e352f",
                "name": "Journal of Chemical Information and Modeling",
                "alternate_names": [
                    "J Chem Inf Model"
                ],
                "issn": "1549-9596",
                "url": "http://pubs.acs.org/jcim"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "journals/jcisd/LusciPB13",
                "MAG": "2046589863",
                "DOI": "10.1021/ci400187y",
                "CorpusId": 6363483,
                "PubMed": "23795551"
            },
            "abstract": "Shallow machine learning methods have been applied to chemoinformatics problems with some success. As more data becomes available and more complex problems are tackled, deep machine learning methods may also become useful. Here, we present a brief overview of deep learning methods and show in particular how recursive neural network approaches can be applied to the problem of predicting molecular properties. However, molecules are typically described by undirected cyclic graphs, while recursive approaches typically use directed acyclic graphs. Thus, we develop methods to address this discrepancy, essentially by considering an ensemble of recursive neural networks associated with all possible vertex-centered acyclic orientations of the molecular graph. One advantage of this approach is that it relies only minimally on the identification of suitable molecular descriptors because suitable representations are learned automatically from the data. Several variants of this approach are applied to the problem of predicting aqueous solubility and tested on four benchmark data sets. Experimental results show that the performance of the deep learning methods matches or exceeds the performance of other state-of-the-art methods according to several evaluation metrics and expose the fundamental limitations arising from training sets that are too small or too noisy. A Web-based predictor, AquaSol, is available online through the ChemDB portal ( cdb.ics.uci.edu ) together with additional material.",
            "referenceCount": 71,
            "citationCount": 419,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc3739985?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2013-07-02",
            "journal": {
                "name": "Journal of chemical information and modeling",
                "volume": "53 7"
            },
            "citationStyles": {
                "bibtex": "@Article{Lusci2013DeepAA,\n author = {A. Lusci and G. Pollastri and P. Baldi},\n booktitle = {Journal of Chemical Information and Modeling},\n journal = {Journal of chemical information and modeling},\n pages = {\n          1563-75\n        },\n title = {Deep Architectures and Deep Learning in Chemoinformatics: The Prediction of Aqueous Solubility for Drug-Like Molecules},\n volume = {53 7},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:47875832106e1ab8e0fdde96773fd043c9662ac8",
            "@type": "ScholarlyArticle",
            "paperId": "47875832106e1ab8e0fdde96773fd043c9662ac8",
            "corpusId": 9421360,
            "url": "https://www.semanticscholar.org/paper/47875832106e1ab8e0fdde96773fd043c9662ac8",
            "title": "Cooperative Multi-agent Control Using Deep Reinforcement Learning",
            "venue": "AAMAS Workshops",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/atal/GuptaEK17",
                "MAG": "2768629321",
                "DOI": "10.1007/978-3-319-71682-4_5",
                "CorpusId": 9421360
            },
            "abstract": null,
            "referenceCount": 45,
            "citationCount": 676,
            "influentialCitationCount": 53,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-05-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gupta2017CooperativeMC,\n author = {Jayesh K. Gupta and M. Egorov and Mykel J. Kochenderfer},\n booktitle = {AAMAS Workshops},\n pages = {66-83},\n title = {Cooperative Multi-agent Control Using Deep Reinforcement Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cce22bf6405042a965a86557684c46a441f2a736",
            "@type": "ScholarlyArticle",
            "paperId": "cce22bf6405042a965a86557684c46a441f2a736",
            "corpusId": 206853161,
            "url": "https://www.semanticscholar.org/paper/cce22bf6405042a965a86557684c46a441f2a736",
            "title": "Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning",
            "venue": "IEEE International Conference on Robotics and Automation",
            "publicationVenue": {
                "id": "urn:research:3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                "name": "IEEE International Conference on Robotics and Automation",
                "alternate_names": [
                    "International Conference on Robotics and Automation",
                    "Int Conf Robot Autom",
                    "ICRA",
                    "IEEE Int Conf Robot Autom"
                ],
                "issn": "2152-4092",
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/icra/NagabandiKFL18",
                "MAG": "2962872206",
                "ArXiv": "1708.02596",
                "DOI": "10.1109/ICRA.2018.8463189",
                "CorpusId": 206853161
            },
            "abstract": "Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of $3-5\\times$ on swimmer, cheetah, hopper, and ant agents. Videos can be found at https://sites.google.com/view/mbmf",
            "referenceCount": 46,
            "citationCount": 807,
            "influentialCitationCount": 50,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1708.02596",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-08-08",
            "journal": {
                "name": "2018 IEEE International Conference on Robotics and Automation (ICRA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Nagabandi2017NeuralND,\n author = {Anusha Nagabandi and G. Kahn and R. Fearing and S. Levine},\n booktitle = {IEEE International Conference on Robotics and Automation},\n journal = {2018 IEEE International Conference on Robotics and Automation (ICRA)},\n pages = {7559-7566},\n title = {Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1a37f07606d60df365d74752857e8ce909f700b3",
            "@type": "ScholarlyArticle",
            "paperId": "1a37f07606d60df365d74752857e8ce909f700b3",
            "corpusId": 14675158,
            "url": "https://www.semanticscholar.org/paper/1a37f07606d60df365d74752857e8ce909f700b3",
            "title": "Deep Neural Networks for Learning Graph Representations",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/aaai/CaoLX16",
                "MAG": "2415243320",
                "DOI": "10.1609/aaai.v30i1.10179",
                "CorpusId": 14675158
            },
            "abstract": "\n \n In this paper, we propose a novel model for learning graph representations, which generates a low-dimensional vector representation for each vertex by capturing the graph structural information. Different from other previous research efforts, we adopt a random surfing model to capture graph structural information directly, instead of using the sampling-based method for generating linear sequences proposed by Perozzi et al. (2014). The advantages of our approach will be illustrated from both theorical and empirical perspectives. We also give a new perspective for the matrix factorization method proposed by Levy and Goldberg (2014), in which the pointwise mutual information (PMI) matrix is considered as an analytical solution to the objective function of the skip-gram model with negative sampling proposed by Mikolov et al. (2013). Unlike their approach which involves the use of the SVD for finding the low-dimensitonal projections from the PMI matrix, however, the stacked denoising autoencoder is introduced in our model to extract complex features and model non-linearities. To demonstrate the effectiveness of our model, we conduct experiments on clustering and visualization tasks, employing the learned vertex representations as features. Empirical results on datasets of varying sizes show that our model outperforms other stat-of-the-art models in such tasks.\n \n",
            "referenceCount": 37,
            "citationCount": 848,
            "influentialCitationCount": 84,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/10179/10038",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-02-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cao2016DeepNN,\n author = {Shaosheng Cao and Wei Lu and Qiongkai Xu},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {1145-1152},\n title = {Deep Neural Networks for Learning Graph Representations},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b5bfb2776c33f8d5de8b812da7a7d5ad56cb84e3",
            "@type": "ScholarlyArticle",
            "paperId": "b5bfb2776c33f8d5de8b812da7a7d5ad56cb84e3",
            "corpusId": 206663375,
            "url": "https://www.semanticscholar.org/paper/b5bfb2776c33f8d5de8b812da7a7d5ad56cb84e3",
            "title": "Cost-Effective Active Learning for Deep Image Classification",
            "venue": "IEEE transactions on circuits and systems for video technology (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/WangZLZL17",
                "MAG": "2471138382",
                "ArXiv": "1701.03551",
                "DOI": "10.1109/TCSVT.2016.2589879",
                "CorpusId": 206663375
            },
            "abstract": "Recent successes in learning-based image classification, however, heavily rely on the large number of annotated training samples, which may require considerable human effort. In this paper, we propose a novel active learning (AL) framework, which is capable of building a competitive classifier with optimal feature representation via a limited amount of labeled training instances in an incremental learning manner. Our approach advances the existing AL methods in two aspects. First, we incorporate deep convolutional neural networks into AL. Through the properly designed framework, the feature representation and the classifier can be simultaneously updated with progressively annotated informative samples. Second, we present a cost-effective sample selection strategy to improve the classification performance with less manual annotations. Unlike traditional methods focusing on only the uncertain samples of low prediction confidence, we especially discover the large amount of high-confidence samples from the unlabeled set for feature learning. Specifically, these high-confidence samples are automatically selected and iteratively assigned pseudolabels. We thus call our framework cost-effective AL (CEAL) standing for the two advantages. Extensive experiments demonstrate that the proposed CEAL framework can achieve promising results on two challenging image classification data sets, i.e., face recognition on the cross-age celebrity face recognition data set database and object categorization on Caltech-256.",
            "referenceCount": 49,
            "citationCount": 564,
            "influentialCitationCount": 47,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1701.03551",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-01-13",
            "journal": {
                "name": "IEEE Transactions on Circuits and Systems for Video Technology",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2017CostEffectiveAL,\n author = {Keze Wang and Dongyu Zhang and Ya Li and Ruimao Zhang and Liang Lin},\n booktitle = {IEEE transactions on circuits and systems for video technology (Print)},\n journal = {IEEE Transactions on Circuits and Systems for Video Technology},\n pages = {2591-2600},\n title = {Cost-Effective Active Learning for Deep Image Classification},\n volume = {27},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:96dc41d3b004fd4c7f96b71b4e174beb3088b2bb",
            "@type": "ScholarlyArticle",
            "paperId": "96dc41d3b004fd4c7f96b71b4e174beb3088b2bb",
            "corpusId": 19219023,
            "url": "https://www.semanticscholar.org/paper/96dc41d3b004fd4c7f96b71b4e174beb3088b2bb",
            "title": "Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2738318237",
                "DBLP": "conf/cvpr/YunCYYC17",
                "DOI": "10.1109/CVPR.2017.148",
                "CorpusId": 19219023
            },
            "abstract": "This paper proposes a novel tracker which is controlled by sequentially pursuing actions learned by deep reinforcement learning. In contrast to the existing trackers using deep networks, the proposed tracker is designed to achieve a light computation as well as satisfactory tracking accuracy in both location and scale. The deep network to control actions is pre-trained using various training sequences and fine-tuned during tracking for online adaptation to target and background changes. The pre-training is done by utilizing deep reinforcement learning as well as supervised learning. The use of reinforcement learning enables even partially labeled data to be successfully utilized for semi-supervised learning. Through evaluation of the OTB dataset, the proposed tracker is validated to achieve a competitive performance that is three times faster than state-of-the-art, deep network&#x2013;based trackers. The fast version of the proposed method, which operates in real-time on GPU, outperforms the state-of-the-art real-time trackers.",
            "referenceCount": 42,
            "citationCount": 456,
            "influentialCitationCount": 60,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-07-01",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yun2017ActionDecisionNF,\n author = {Sangdoo Yun and Jongwon Choi and Y. Yoo and Kimin Yun and J. Choi},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1349-1358},\n title = {Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fe2ef22089712fcff33a77761860a10b7834da47",
            "@type": "ScholarlyArticle",
            "paperId": "fe2ef22089712fcff33a77761860a10b7834da47",
            "corpusId": 14149803,
            "url": "https://www.semanticscholar.org/paper/fe2ef22089712fcff33a77761860a10b7834da47",
            "title": "Socially aware motion planning with deep reinforcement learning",
            "venue": "IEEE/RJS International Conference on Intelligent RObots and Systems",
            "publicationVenue": {
                "id": "urn:research:37275deb-3fcf-4d16-ae77-95db9899b1f3",
                "name": "IEEE/RJS International Conference on Intelligent RObots and Systems",
                "alternate_names": [
                    "IROS",
                    "Intelligent Robots and Systems",
                    "Intell Robot Syst",
                    "IEEE/RJS Int Conf Intell Robot Syst"
                ],
                "issn": null,
                "url": "http://www.iros.org/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/ChenELH17",
                "MAG": "2604216058",
                "ArXiv": "1703.08862",
                "DOI": "10.1109/IROS.2017.8202312",
                "CorpusId": 14149803
            },
            "abstract": "For robotic vehicles to navigate safely and efficiently in pedestrian-rich environments, it is important to model subtle human behaviors and navigation rules (e.g., passing on the right). However, while instinctive to humans, socially compliant navigation is still difficult to quantify due to the stochasticity in people's behaviors. Existing works are mostly focused on using feature-matching techniques to describe and imitate human paths, but often do not generalize well since the feature values can vary from person to person, and even run to run. This work notes that while it is challenging to directly specify the details of what to do (precise mechanisms of human navigation), it is straightforward to specify what not to do (violations of social norms). Specifically, using deep reinforcement learning, this work develops a time-efficient navigation policy that respects common social norms. The proposed method is shown to enable fully autonomous navigation of a robotic vehicle moving at human walking speed in an environment with many pedestrians.",
            "referenceCount": 29,
            "citationCount": 550,
            "influentialCitationCount": 41,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dspace.mit.edu/bitstream/1721.1/114480/1/1703.08862.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-26",
            "journal": {
                "name": "2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2017SociallyAM,\n author = {Yu Fan Chen and Michael Everett and Miao Liu and J. How},\n booktitle = {IEEE/RJS International Conference on Intelligent RObots and Systems},\n journal = {2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},\n pages = {1343-1350},\n title = {Socially aware motion planning with deep reinforcement learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2eecf2a2788117b808b72321802731efc86526b2",
            "@type": "ScholarlyArticle",
            "paperId": "2eecf2a2788117b808b72321802731efc86526b2",
            "corpusId": 8105340,
            "url": "https://www.semanticscholar.org/paper/2eecf2a2788117b808b72321802731efc86526b2",
            "title": "Joint Unsupervised Learning of Deep Representations and Image Clusters",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2952918726",
                "ArXiv": "1604.03628",
                "DBLP": "conf/cvpr/YangPB16",
                "DOI": "10.1109/CVPR.2016.556",
                "CorpusId": 8105340
            },
            "abstract": "In this paper, we propose a recurrent framework for joint unsupervised learning of deep representations and image clusters. In our framework, successive operations in a clustering algorithm are expressed as steps in a recurrent process, stacked on top of representations output by a Convolutional Neural Network (CNN). During training, image clusters and representations are updated jointly: image clustering is conducted in the forward pass, while representation learning in the backward pass. Our key idea behind this framework is that good representations are beneficial to image clustering and clustering results provide supervisory signals to representation learning. By integrating two processes into a single model with a unified weighted triplet loss function and optimizing it end-to-end, we can obtain not only more powerful representations, but also more precise image clusters. Extensive experiments show that our method outperforms the state of-the-art on image clustering across a variety of image datasets. Moreover, the learned representations generalize well when transferred to other tasks. The source code can be downloaded from https://github.com/ jwyang/joint-unsupervised-learning.",
            "referenceCount": 73,
            "citationCount": 720,
            "influentialCitationCount": 95,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1604.03628",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-04-13",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2016JointUL,\n author = {Jianwei Yang and Devi Parikh and Dhruv Batra},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {5147-5156},\n title = {Joint Unsupervised Learning of Deep Representations and Image Clusters},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c4f67bb310ef9b5dca6623d3aa890182d9e828e7",
            "@type": "ScholarlyArticle",
            "paperId": "c4f67bb310ef9b5dca6623d3aa890182d9e828e7",
            "corpusId": 206595438,
            "url": "https://www.semanticscholar.org/paper/c4f67bb310ef9b5dca6623d3aa890182d9e828e7",
            "title": "Learning a Deep Embedding Model for Zero-Shot Learning",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1611.05088",
                "DBLP": "journals/corr/ZhangXG16a",
                "MAG": "2950652153",
                "DOI": "10.1109/CVPR.2017.321",
                "CorpusId": 206595438
            },
            "abstract": "Zero-shot learning (ZSL) models rely on learning a joint embedding space where both textual/semantic description of object classes and visual representation of object images can be projected to for nearest neighbour search. Despite the success of deep neural networks that learn an end-to-end model between text and images in other vision problems such as image captioning, very few deep ZSL model exists and they show little advantage over ZSL models that utilise deep feature representations but do not learn an end-to-end embedding. In this paper we argue that the key to make deep ZSL models succeed is to choose the right embedding space. Instead of embedding into a semantic space or an intermediate space, we propose to use the visual space as the embedding space. This is because that in this space, the subsequent nearest neighbour search would suffer much less from the hubness problem and thus become more effective. This model design also provides a natural mechanism for multiple semantic modalities (e.g.,~attributes and sentence descriptions) to be fused and optimised jointly in an end-to-end manner. Extensive experiments on four benchmarks show that our model significantly outperforms the existing models.",
            "referenceCount": 54,
            "citationCount": 606,
            "influentialCitationCount": 97,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1611.05088",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-11-15",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2016LearningAD,\n author = {Li Zhang and T. Xiang and S. Gong},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {3010-3019},\n title = {Learning a Deep Embedding Model for Zero-Shot Learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8b419080cd37bdc30872b76f405ef6a93eae3304",
            "@type": "ScholarlyArticle",
            "paperId": "8b419080cd37bdc30872b76f405ef6a93eae3304",
            "corpusId": 16861557,
            "url": "https://www.semanticscholar.org/paper/8b419080cd37bdc30872b76f405ef6a93eae3304",
            "title": "Federated Learning of Deep Networks using Model Averaging",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/McMahanMRA16",
                "MAG": "2283463896",
                "CorpusId": 16861557
            },
            "abstract": "Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data-center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. \nWe present a practical method for the federated learning of deep networks that proves robust to the unbalanced and non-IID data distributions that naturally arise. This method allows high-quality models to be trained in relatively few rounds of communication, the principal constraint for federated learning. The key insight is that despite the non-convex loss functions we optimize, parameter averaging over updates from multiple clients produces surprisingly good results, for example decreasing the communication needed to train an LSTM language model by two orders of magnitude.",
            "referenceCount": 38,
            "citationCount": 789,
            "influentialCitationCount": 111,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-02-17",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1602.05629"
            },
            "citationStyles": {
                "bibtex": "@Article{McMahan2016FederatedLO,\n author = {H. B. McMahan and Eider Moore and Daniel Ramage and B. A. Y. Arcas},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Federated Learning of Deep Networks using Model Averaging},\n volume = {abs/1602.05629},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dd656e5f21003a33b10eb3574a093774a7081d46",
            "@type": "ScholarlyArticle",
            "paperId": "dd656e5f21003a33b10eb3574a093774a7081d46",
            "corpusId": 539875,
            "url": "https://www.semanticscholar.org/paper/dd656e5f21003a33b10eb3574a093774a7081d46",
            "title": "Deep bilateral learning for real-time image enhancement",
            "venue": "ACM Transactions on Graphics",
            "publicationVenue": {
                "id": "urn:research:aab03e41-f80d-48b3-89bd-60eeeceafc7d",
                "name": "ACM Transactions on Graphics",
                "alternate_names": [
                    "ACM Trans Graph"
                ],
                "issn": "0730-0301",
                "url": "http://www.acm.org/tog/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "3100946661",
                "DBLP": "journals/tog/GharbiCBHD17",
                "ArXiv": "1707.02880",
                "DOI": "10.1145/3072959.3073592",
                "CorpusId": 539875
            },
            "abstract": "Performance is a critical challenge in mobile image processing. Given a reference imaging pipeline, or even human-adjusted pairs of images, we seek to reproduce the enhancements and enable real-time evaluation. For this, we introduce a new neural network architecture inspired by bilateral grid processing and local affine color transforms. Using pairs of input/output images, we train a convolutional neural network to predict the coefficients of a locally-affine model in bilateral space. Our architecture learns to make local, global, and content-dependent decisions to approximate the desired image transformation. At runtime, the neural network consumes a low-resolution version of the input image, produces a set of affine transformations in bilateral space, upsamples those transformations in an edge-preserving fashion using a new slicing node, and then applies those upsampled transformations to the full-resolution image. Our algorithm processes high-resolution images on a smartphone in milliseconds, provides a real-time viewfinder at 1080p resolution, and matches the quality of state-of-the-art approximation techniques on a large class of image operators. Unlike previous work, our model is trained off-line from data and therefore does not require access to the original operator at runtime. This allows our model to learn complex, scene-dependent transformations for which no reference implementation is available, such as the photographic edits of a human retoucher.",
            "referenceCount": 49,
            "citationCount": 599,
            "influentialCitationCount": 74,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://hal.inria.fr/hal-01676188/file/1707.02880%20%281%29.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-10",
            "journal": {
                "name": "ACM Transactions on Graphics (TOG)",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{Gharbi2017DeepBL,\n author = {Micha\u00ebl Gharbi and Jiawen Chen and J. Barron and S. Hasinoff and F. Durand},\n booktitle = {ACM Transactions on Graphics},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 12},\n title = {Deep bilateral learning for real-time image enhancement},\n volume = {36},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:51579a8a40aea8dc6b9cdea9499dc27c2797499d",
            "@type": "ScholarlyArticle",
            "paperId": "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
            "corpusId": 20299776,
            "url": "https://www.semanticscholar.org/paper/51579a8a40aea8dc6b9cdea9499dc27c2797499d",
            "title": "Deep Count: Fruit Counting Based on Deep Simulated Learning",
            "venue": "Italian National Conference on Sensors",
            "publicationVenue": {
                "id": "urn:research:3dbf084c-ef47-4b74-9919-047b40704538",
                "name": "Italian National Conference on Sensors",
                "alternate_names": [
                    "SENSORS",
                    "IEEE Sens",
                    "Ital National Conf Sens",
                    "IEEE Sensors",
                    "Sensors"
                ],
                "issn": "1424-8220",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001"
            },
            "year": 2017,
            "externalIds": {
                "PubMedCentral": "5426829",
                "DBLP": "journals/sensors/RahnemoonfarS17",
                "MAG": "2611227133",
                "DOI": "10.3390/s17040905",
                "CorpusId": 20299776,
                "PubMed": "28425947"
            },
            "abstract": "Recent years have witnessed significant advancement in computer vision research based on deep learning. Success of these tasks largely depends on the availability of a large amount of training samples. Labeling the training samples is an expensive process. In this paper, we present a simulated deep convolutional neural network for yield estimation. Knowing the exact number of fruits, flowers, and trees helps farmers to make better decisions on cultivation practices, plant disease prevention, and the size of harvest labor force. The current practice of yield estimation based on the manual counting of fruits or flowers by workers is a very time consuming and expensive process and it is not practical for big fields. Automatic yield estimation based on robotic agriculture provides a viable solution in this regard. Our network is trained entirely on synthetic data and tested on real data. To capture features on multiple scales, we used a modified version of the Inception-ResNet architecture. Our algorithm counts efficiently even if fruits are under shadow, occluded by foliage, branches, or if there is some degree of overlap amongst fruits. Experimental results show a 91% average test accuracy on real images and 93% on synthetic images.",
            "referenceCount": 47,
            "citationCount": 386,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/1424-8220/17/4/905/pdf?version=1492689357",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-04-01",
            "journal": {
                "name": "Sensors (Basel, Switzerland)",
                "volume": "17"
            },
            "citationStyles": {
                "bibtex": "@Article{Rahnemoonfar2017DeepCF,\n author = {M. Rahnemoonfar and Clay Sheppard},\n booktitle = {Italian National Conference on Sensors},\n journal = {Sensors (Basel, Switzerland)},\n title = {Deep Count: Fruit Counting Based on Deep Simulated Learning},\n volume = {17},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:65c47c35495f472bad1c088dfd1e15c304786634",
            "@type": "ScholarlyArticle",
            "paperId": "65c47c35495f472bad1c088dfd1e15c304786634",
            "corpusId": 57574627,
            "url": "https://www.semanticscholar.org/paper/65c47c35495f472bad1c088dfd1e15c304786634",
            "title": "Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network",
            "venue": "Nature Network Boston",
            "publicationVenue": {
                "id": "urn:research:9e995b6d-f30b-4ab4-a13b-3dc2cc992f47",
                "name": "Nature Network Boston",
                "alternate_names": [
                    "Nat Netw Boston",
                    "Nat Med",
                    "Nature Medicine"
                ],
                "issn": "1744-7933",
                "url": "https://www.nature.com/nature/articles?code=archive_news"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2902644322",
                "DOI": "10.1038/s41591-018-0268-3",
                "CorpusId": 57574627,
                "PubMed": "30617320"
            },
            "abstract": null,
            "referenceCount": 48,
            "citationCount": 1567,
            "influentialCitationCount": 84,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc6784839?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-01-01",
            "journal": {
                "name": "Nature Medicine",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{Hannun2019CardiologistlevelAD,\n author = {Awni Y. Hannun and Pranav Rajpurkar and Masoumeh Haghpanahi and G. Tison and Codie Bourn and M. Turakhia and A. Ng},\n booktitle = {Nature Network Boston},\n journal = {Nature Medicine},\n pages = {65 - 69},\n title = {Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network},\n volume = {25},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e4a323a3a1ca5ff4cc2dd74ede65f48fd62b897b",
            "@type": "ScholarlyArticle",
            "paperId": "e4a323a3a1ca5ff4cc2dd74ede65f48fd62b897b",
            "corpusId": 11540100,
            "url": "https://www.semanticscholar.org/paper/e4a323a3a1ca5ff4cc2dd74ede65f48fd62b897b",
            "title": "Deep API learning",
            "venue": "SIGSOFT FSE",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2402619042",
                "DBLP": "conf/sigsoft/GuZZK16",
                "ArXiv": "1605.08535",
                "DOI": "10.1145/2950290.2950334",
                "CorpusId": 11540100
            },
            "abstract": "Developers often wonder how to implement a certain functionality (e.g., how to parse XML files) using APIs. Obtaining an API usage sequence based on an API-related natural language query is very helpful in this regard. Given a query, existing approaches utilize information retrieval models to search for matching API sequences. These approaches treat queries and APIs as bags-of-words and lack a deep understanding of the semantics of the query. We propose DeepAPI, a deep learning based approach to generate API usage sequences for a given natural language query. Instead of a bag-of-words assumption, it learns the sequence of words in a query and the sequence of associated APIs. DeepAPI adapts a neural language model named RNN Encoder-Decoder. It encodes a word sequence (user query) into a fixed-length context vector, and generates an API sequence based on the context vector. We also augment the RNN Encoder-Decoder by considering the importance of individual APIs. We empirically evaluate our approach with more than 7 million annotated code snippets collected from GitHub. The results show that our approach generates largely accurate API sequences and outperforms the related approaches.",
            "referenceCount": 54,
            "citationCount": 493,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2016-05-27",
            "journal": {
                "name": "Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Gu2016DeepAL,\n author = {Xiaodong Gu and Hongyu Zhang and D. Zhang and Sunghun Kim},\n booktitle = {SIGSOFT FSE},\n journal = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},\n title = {Deep API learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dca8aa17ccbf72d9eeeba7dd701e851f2e6d39fd",
            "@type": "ScholarlyArticle",
            "paperId": "dca8aa17ccbf72d9eeeba7dd701e851f2e6d39fd",
            "corpusId": 23083969,
            "url": "https://www.semanticscholar.org/paper/dca8aa17ccbf72d9eeeba7dd701e851f2e6d39fd",
            "title": "Deep Metric Learning with Angular Loss",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2949303439",
                "ArXiv": "1708.01682",
                "DBLP": "journals/corr/abs-1708-01682",
                "DOI": "10.1109/ICCV.2017.283",
                "CorpusId": 23083969
            },
            "abstract": "The modern image search system requires semantic understanding of image, and a key yet under-addressed problem is to learn a good metric for measuring the similarity between images. While deep metric learning has yielded impressive performance gains by extracting high level abstractions from image data, a proper objective loss function becomes the central issue to boost the performance. In this paper, we propose a novel angular loss, which takes angle relationship into account, for learning better similarity metric. Whereas previous metric learning methods focus on optimizing the similarity (contrastive loss) or relative similarity (triplet loss) of image pairs, our proposed method aims at constraining the angle at the negative point of triplet triangles. Several favorable properties are observed when compared with conventional methods. First, scale invariance is introduced, improving the robustness of objective against feature variance. Second, a third-order geometric constraint is inherently imposed, capturing additional local structure of triplet triangles than contrastive loss or triplet loss. Third, better convergence has been demonstrated by experiments on three publicly available datasets.",
            "referenceCount": 39,
            "citationCount": 441,
            "influentialCitationCount": 50,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1708.01682",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-08-04",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2017DeepML,\n author = {Jian Wang and Feng Zhou and Shilei Wen and Xiao Liu and Yuanqing Lin},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2017 IEEE International Conference on Computer Vision (ICCV)},\n pages = {2612-2620},\n title = {Deep Metric Learning with Angular Loss},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:04162cb8cfaa0f7e37586823ff4ad0bff09ed21d",
            "@type": "ScholarlyArticle",
            "paperId": "04162cb8cfaa0f7e37586823ff4ad0bff09ed21d",
            "corpusId": 8121626,
            "url": "https://www.semanticscholar.org/paper/04162cb8cfaa0f7e37586823ff4ad0bff09ed21d",
            "title": "Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2963590100",
                "DBLP": "journals/corr/FinnLA16",
                "ArXiv": "1603.00448",
                "CorpusId": 8121626
            },
            "abstract": "Reinforcement learning can acquire complex behaviors from high-level specifications. However, defining a cost function that can be optimized effectively and encodes the correct task is challenging in practice. We explore how inverse optimal control (IOC) can be used to learn behaviors from demonstrations, with applications to torque control of high-dimensional robotic systems. Our method addresses two key challenges in inverse optimal control: first, the need for informative features and effective regularization to impose structure on the cost, and second, the difficulty of learning the cost function under unknown dynamics for high-dimensional continuous systems. To address the former challenge, we present an algorithm capable of learning arbitrary nonlinear cost functions, such as neural networks, without meticulous feature engineering. To address the latter challenge, we formulate an efficient sample-based approximation for MaxEnt IOC. We evaluate our method on a series of simulated tasks and real-world robotic manipulation problems, demonstrating substantial improvement over prior methods both in terms of task complexity and sample efficiency.",
            "referenceCount": 32,
            "citationCount": 809,
            "influentialCitationCount": 87,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-03-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Finn2016GuidedCL,\n author = {Chelsea Finn and S. Levine and P. Abbeel},\n booktitle = {International Conference on Machine Learning},\n pages = {49-58},\n title = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ad0a1b0991a9150b765c2a45eb2b368702b35cd1",
            "@type": "ScholarlyArticle",
            "paperId": "ad0a1b0991a9150b765c2a45eb2b368702b35cd1",
            "corpusId": 46955236,
            "url": "https://www.semanticscholar.org/paper/ad0a1b0991a9150b765c2a45eb2b368702b35cd1",
            "title": "Deep Variational Reinforcement Learning for POMDPs",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2803743229",
                "DBLP": "journals/corr/abs-1806-02426",
                "ArXiv": "1806.02426",
                "CorpusId": 46955236
            },
            "abstract": "Many real-world sequential decision making problems are partially observable by nature, and the environment model is typically unknown. Consequently, there is great need for reinforcement learning methods that can tackle such problems given only a stream of incomplete and noisy observations. In this paper, we propose deep variational reinforcement learning (DVRL), which introduces an inductive bias that allows an agent to learn a generative model of the environment and perform inference in that model to effectively aggregate the available information. We develop an n-step approximation to the evidence lower bound (ELBO), allowing the model to be trained jointly with the policy. This ensures that the latent state representation is suitable for the control task. In experiments on Mountain Hike and flickering Atari we show that our method outperforms previous approaches relying on recurrent neural networks to encode the past.",
            "referenceCount": 52,
            "citationCount": 220,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-06-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Igl2018DeepVR,\n author = {Maximilian Igl and L. Zintgraf and T. Le and Frank Wood and Shimon Whiteson},\n booktitle = {International Conference on Machine Learning},\n pages = {2122-2131},\n title = {Deep Variational Reinforcement Learning for POMDPs},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:90368e1751b34f22492ed18cc3b1ab19ae546afa",
            "@type": "ScholarlyArticle",
            "paperId": "90368e1751b34f22492ed18cc3b1ab19ae546afa",
            "corpusId": 7102424,
            "url": "https://www.semanticscholar.org/paper/90368e1751b34f22492ed18cc3b1ab19ae546afa",
            "title": "Learning Deep Representations of Fine-Grained Visual Descriptions",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/ReedASL16",
                "ArXiv": "1605.05395",
                "MAG": "2951538594",
                "DOI": "10.1109/CVPR.2016.13",
                "CorpusId": 7102424
            },
            "abstract": "State-of-the-art methods for zero-shot visual recognition formulate learning as a joint embedding problem of images and side information. In these formulations the current best complement to visual features are attributes: manually-encoded vectors describing shared characteristics among categories. Despite good performance, attributes have limitations: (1) finer-grained recognition requires commensurately more attributes, and (2) attributes do not provide a natural language interface. We propose to overcome these limitations by training neural language models from scratch, i.e. without pre-training and only consuming words and characters. Our proposed models train end-to-end to align with the fine-grained and category-specific content of images. Natural language provides a flexible and compact way of encoding only the salient visual aspects for distinguishing categories. By training on raw text, our model can do inference on raw text as well, providing humans a familiar mode both for annotation and retrieval. Our model achieves strong performance on zero-shot text-based image retrieval and significantly outperforms the attribute-based state-of-the-art for zero-shot classification on the Caltech-UCSD Birds 200-2011 dataset.",
            "referenceCount": 53,
            "citationCount": 754,
            "influentialCitationCount": 76,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1605.05395",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-05-17",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Reed2016LearningDR,\n author = {Scott E. Reed and Zeynep Akata and Honglak Lee and B. Schiele},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {49-58},\n title = {Learning Deep Representations of Fine-Grained Visual Descriptions},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:600bfe5f0597ebd84898f0c4270ddfb3750594f5",
            "@type": "ScholarlyArticle",
            "paperId": "600bfe5f0597ebd84898f0c4270ddfb3750594f5",
            "corpusId": 13301124,
            "url": "https://www.semanticscholar.org/paper/600bfe5f0597ebd84898f0c4270ddfb3750594f5",
            "title": "Imagination-Augmented Agents for Deep Reinforcement Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2964295739",
                "ArXiv": "1707.06203",
                "DBLP": "conf/nips/RacaniereWRBGRB17",
                "CorpusId": 13301124
            },
            "abstract": "We introduce Imagination-Augmented Agents (I2As), a novel architecture for deep reinforcement learning combining model-free and model-based aspects. In contrast to most existing model-based reinforcement learning and planning methods, which prescribe how a model should be used to arrive at a policy, I2As learn to interpret predictions from a learned environment model to construct implicit plans in arbitrary ways, by using the predictions as additional context in deep policy networks. I2As show improved data efficiency, performance, and robustness to model misspecification compared to several baselines.",
            "referenceCount": 60,
            "citationCount": 492,
            "influentialCitationCount": 27,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-07-19",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1707.06203"
            },
            "citationStyles": {
                "bibtex": "@Article{Racani\u00e8re2017ImaginationAugmentedAF,\n author = {S. Racani\u00e8re and T. Weber and David P. Reichert and Lars Buesing and A. Guez and Danilo Jimenez Rezende and Adri\u00e0 Puigdom\u00e8nech Badia and Oriol Vinyals and N. Heess and Yujia Li and Razvan Pascanu and P. Battaglia and D. Hassabis and David Silver and Daan Wierstra},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Imagination-Augmented Agents for Deep Reinforcement Learning},\n volume = {abs/1707.06203},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:30741e7e30976f7b482eef3d00295ae4740ec21b",
            "@type": "ScholarlyArticle",
            "paperId": "30741e7e30976f7b482eef3d00295ae4740ec21b",
            "corpusId": 327425,
            "url": "https://www.semanticscholar.org/paper/30741e7e30976f7b482eef3d00295ae4740ec21b",
            "title": "On-Line Building Energy Optimization Using Deep Reinforcement Learning",
            "venue": "IEEE Transactions on Smart Grid",
            "publicationVenue": {
                "id": "urn:research:1c2f3998-b5ca-48ca-9991-94b71c71ecb7",
                "name": "IEEE Transactions on Smart Grid",
                "alternate_names": [
                    "IEEE Trans Smart Grid"
                ],
                "issn": "1949-3053",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5165411"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963317745",
                "ArXiv": "1707.05878",
                "DBLP": "journals/corr/MocanuMNLWGS17",
                "DOI": "10.1109/TSG.2018.2834219",
                "CorpusId": 327425
            },
            "abstract": "Unprecedented high volumes of data are becoming available with the growth of the advanced metering infrastructure. These are expected to benefit planning and operation of the future power systems and to help customers transition from a passive to an active role. In this paper, we explore for the first time in the smart grid context the benefits of using deep reinforcement learning, a hybrid type of methods that combines reinforcement learning with deep learning, to perform on-line optimization of schedules for building energy management systems. The learning procedure was explored using two methods, Deep Q-learning and deep policy gradient, both of which have been extended to perform multiple actions simultaneously. The proposed approach was validated on the large-scale Pecan Street Inc. database. This highly dimensional database includes information about photovoltaic power generation, electric vehicles and buildings appliances. Moreover, these on-line energy scheduling strategies could be used to provide real-time feedback to consumers to encourage more efficient use of electricity.",
            "referenceCount": 37,
            "citationCount": 369,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1707.05878",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-18",
            "journal": {
                "name": "IEEE Transactions on Smart Grid",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Mocanu2017OnLineBE,\n author = {Elena Mocanu and D. Mocanu and Phuong H. Nguyen and A. Liotta and M. Webber and M. Gibescu and J. Slootweg},\n booktitle = {IEEE Transactions on Smart Grid},\n journal = {IEEE Transactions on Smart Grid},\n pages = {3698-3708},\n title = {On-Line Building Energy Optimization Using Deep Reinforcement Learning},\n volume = {10},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ed2b19734b7001c324e711524f39225e9cbb46af",
            "@type": "ScholarlyArticle",
            "paperId": "ed2b19734b7001c324e711524f39225e9cbb46af",
            "corpusId": 9168527,
            "url": "https://www.semanticscholar.org/paper/ed2b19734b7001c324e711524f39225e9cbb46af",
            "title": "Hybrid Deep Learning for Face Verification",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2344661575",
                "DBLP": "conf/iccv/SunWT13",
                "DOI": "10.1109/ICCV.2013.188",
                "CorpusId": 9168527,
                "PubMed": "26660699"
            },
            "abstract": "This paper proposes a hybrid convolutional network (ConvNet)-Restricted Boltzmann Machine (RBM) model for face verification in wild conditions. A key contribution of this work is to directly learn relational visual features, which indicate identity similarities, from raw pixels of face pairs with a hybrid deep network. The deep ConvNets in our model mimic the primary visual cortex to jointly extract local relational visual features from two face images compared with the learned filter pairs. These relational features are further processed through multiple layers to extract high-level and global features. Multiple groups of ConvNets are constructed in order to achieve robustness and characterize face similarities from different aspects. The top-layer RBM performs inference from complementary high-level features extracted from different ConvNet groups with a two-level average pooling hierarchy. The entire hybrid deep network is jointly fine-tuned to optimize for the task of face verification. Our model achieves competitive face verification performance on the LFW dataset.",
            "referenceCount": 70,
            "citationCount": 390,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Sun_Hybrid_Deep_Learning_2013_ICCV_paper.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-12-01",
            "journal": {
                "name": "2013 IEEE International Conference on Computer Vision",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sun2013HybridDL,\n author = {Yi Sun and Xiaogang Wang and Xiaoou Tang},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2013 IEEE International Conference on Computer Vision},\n pages = {1489-1496},\n title = {Hybrid Deep Learning for Face Verification},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:63a513832f56addb67be81a2fa399b233f3030fc",
            "@type": "ScholarlyArticle",
            "paperId": "63a513832f56addb67be81a2fa399b233f3030fc",
            "corpusId": 70349949,
            "url": "https://www.semanticscholar.org/paper/63a513832f56addb67be81a2fa399b233f3030fc",
            "title": "Fast Graph Representation Learning with PyTorch Geometric",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2918342466",
                "DBLP": "journals/corr/abs-1903-02428",
                "ArXiv": "1903.02428",
                "CorpusId": 70349949
            },
            "abstract": "We introduce PyTorch Geometric, a library for deep learning on irregularly structured input data such as graphs, point clouds and manifolds, built upon PyTorch. In addition to general graph data structures and processing methods, it contains a variety of recently published methods from the domains of relational learning and 3D data processing. PyTorch Geometric achieves high data throughput by leveraging sparse GPU acceleration, by providing dedicated CUDA kernels and by introducing efficient mini-batch handling for input examples of different size. In this work, we present the library in detail and perform a comprehensive comparative study of the implemented methods in homogeneous evaluation scenarios.",
            "referenceCount": 51,
            "citationCount": 2852,
            "influentialCitationCount": 301,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1903.02428"
            },
            "citationStyles": {
                "bibtex": "@Article{Fey2019FastGR,\n author = {Matthias Fey and J. E. Lenssen},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Fast Graph Representation Learning with PyTorch Geometric},\n volume = {abs/1903.02428},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:34ab95637e7723302058f6526e33dc73857b9af2",
            "@type": "ScholarlyArticle",
            "paperId": "34ab95637e7723302058f6526e33dc73857b9af2",
            "corpusId": 1443279,
            "url": "https://www.semanticscholar.org/paper/34ab95637e7723302058f6526e33dc73857b9af2",
            "title": "Deep Kernel Learning",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2167085024",
                "ArXiv": "1511.02222",
                "DBLP": "conf/aistats/WilsonHSX16",
                "CorpusId": 1443279
            },
            "abstract": "We introduce scalable deep kernels, which combine the structural properties of deep learning architectures with the non-parametric flexibility of kernel methods. Specifically, we transform the inputs of a spectral mixture base kernel with a deep architecture, using local kernel interpolation, inducing points, and structure exploiting (Kronecker and Toeplitz) algebra for a scalable kernel representation. These closed-form kernels can be used as drop-in replacements for standard kernels, with benefits in expressive power and scalability. We jointly learn the properties of these kernels through the marginal likelihood of a Gaussian process. Inference and learning cost $O(n)$ for $n$ training points, and predictions cost $O(1)$ per test point. On a large and diverse collection of applications, including a dataset with 2 million examples, we show improved performance over scalable Gaussian processes with flexible kernel learning models, and stand-alone deep architectures.",
            "referenceCount": 32,
            "citationCount": 703,
            "influentialCitationCount": 95,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-11-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wilson2015DeepKL,\n author = {A. Wilson and Zhiting Hu and R. Salakhutdinov and E. Xing},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n pages = {370-378},\n title = {Deep Kernel Learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:25badc676197a70aaf9911865eb03469e402ba57",
            "@type": "ScholarlyArticle",
            "paperId": "25badc676197a70aaf9911865eb03469e402ba57",
            "corpusId": 17793133,
            "url": "https://www.semanticscholar.org/paper/25badc676197a70aaf9911865eb03469e402ba57",
            "title": "Machine learning - a probabilistic perspective",
            "venue": "Adaptive computation and machine learning series",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "books/lib/Murphy12",
                "MAG": "1503398984",
                "CorpusId": 17793133
            },
            "abstract": "Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.",
            "referenceCount": 1022,
            "citationCount": 8564,
            "influentialCitationCount": 1066,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2012-08-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Murphy2012MachineL,\n author = {Kevin P. Murphy},\n booktitle = {Adaptive computation and machine learning series},\n pages = {I-XXIX, 1-1067},\n title = {Machine learning - a probabilistic perspective},\n year = {2012}\n}\n"
            }
        }
    }
]