[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4315b75e9ec6b8a357218a55bd7698b8262f0c27",
            "@type": "ScholarlyArticle",
            "paperId": "4315b75e9ec6b8a357218a55bd7698b8262f0c27",
            "corpusId": 209515898,
            "url": "https://www.semanticscholar.org/paper/4315b75e9ec6b8a357218a55bd7698b8262f0c27",
            "title": "Deep Learning on Image Denoising: An overview",
            "venue": "Neural Networks",
            "publicationVenue": {
                "id": "urn:research:a13f3cb8-2492-4ccb-9329-73a5ddcaab9b",
                "name": "Neural Networks",
                "alternate_names": [
                    "Neural Netw"
                ],
                "issn": "0893-6080",
                "url": "http://www.elsevier.com/locate/neunet"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1912-13171",
                "MAG": "2998718015",
                "ArXiv": "1912.13171",
                "DOI": "10.1016/j.neunet.2020.07.025",
                "CorpusId": 209515898,
                "PubMed": "32829002"
            },
            "abstract": null,
            "referenceCount": 279,
            "citationCount": 517,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1912.13171",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2019-12-31",
            "journal": {
                "name": "Neural networks : the official journal of the International Neural Network Society",
                "volume": "131"
            },
            "citationStyles": {
                "bibtex": "@Article{Tian2019DeepLO,\n author = {Chunwei Tian and Lunke Fei and Wenxian Zheng and Yong Xu and W. Zuo and Chia-Wen Lin},\n booktitle = {Neural Networks},\n journal = {Neural networks : the official journal of the International Neural Network Society},\n pages = {\n          251-275\n        },\n title = {Deep Learning on Image Denoising: An overview},\n volume = {131},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5ff64afd70434b12e043ff39a91271eab6391124",
            "@type": "ScholarlyArticle",
            "paperId": "5ff64afd70434b12e043ff39a91271eab6391124",
            "corpusId": 40804218,
            "url": "https://www.semanticscholar.org/paper/5ff64afd70434b12e043ff39a91271eab6391124",
            "title": "Building Extraction in Very High Resolution Remote Sensing Imagery Using Deep Learning and Guided Filters",
            "venue": "Remote Sensing",
            "publicationVenue": {
                "id": "urn:research:8e1bd4b5-d5b2-4e22-ba0a-01fe5568d472",
                "name": "Remote Sensing",
                "alternate_names": [
                    "Remote Sens"
                ],
                "issn": "2315-4675",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-169233"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2787614951",
                "DBLP": "journals/remotesensing/XuWXC18",
                "DOI": "10.3390/rs10010144",
                "CorpusId": 40804218
            },
            "abstract": "Very high resolution (VHR) remote sensing imagery has been used for land cover classification, and it tends to a transition from land-use classification to pixel-level semantic segmentation. Inspired by the recent success of deep learning and the filter method in computer vision, this work provides a segmentation model, which designs an image segmentation neural network based on the deep residual networks and uses a guided filter to extract buildings in remote sensing imagery. Our method includes the following steps: first, the VHR remote sensing imagery is preprocessed and some hand-crafted features are calculated. Second, a designed deep network architecture is trained with the urban district remote sensing image to extract buildings at the pixel level. Third, a guided filter is employed to optimize the classification map produced by deep learning; at the same time, some salt-and-pepper noise is removed. Experimental results based on the Vaihingen and Potsdam datasets demonstrate that our method, which benefits from neural networks and guided filtering, achieves a higher overall accuracy when compared with other machine learning and deep learning methods. The method proposed shows outstanding performance in terms of the building extraction from diversified objects in the urban district.",
            "referenceCount": 51,
            "citationCount": 330,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/2072-4292/10/1/144/pdf?version=1516375440",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-01-19",
            "journal": {
                "name": "Remote. Sens.",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Xu2018BuildingEI,\n author = {Yongyang Xu and Liang Wu and Zhong Xie and Zhanlong Chen},\n booktitle = {Remote Sensing},\n journal = {Remote. Sens.},\n pages = {144},\n title = {Building Extraction in Very High Resolution Remote Sensing Imagery Using Deep Learning and Guided Filters},\n volume = {10},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:177bc509dd0c7b8d388bb47403f28d6228c14b5c",
            "@type": "ScholarlyArticle",
            "paperId": "177bc509dd0c7b8d388bb47403f28d6228c14b5c",
            "corpusId": 206592295,
            "url": "https://www.semanticscholar.org/paper/177bc509dd0c7b8d388bb47403f28d6228c14b5c",
            "title": "Deep Learning Face Representation from Predicting 10,000 Classes",
            "venue": "2014 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/cvpr/SunWT14",
                "MAG": "1998808035",
                "DOI": "10.1109/CVPR.2014.244",
                "CorpusId": 206592295
            },
            "abstract": "This paper proposes to learn a set of high-level feature representations through deep learning, referred to as Deep hidden IDentity features (DeepID), for face verification. We argue that DeepID can be effectively learned through challenging multi-class face identification tasks, whilst they can be generalized to other tasks (such as verification) and new identities unseen in the training set. Moreover, the generalization capability of DeepID increases as more face classes are to be predicted at training. DeepID features are taken from the last hidden layer neuron activations of deep convolutional networks (ConvNets). When learned as classifiers to recognize about 10, 000 face identities in the training set and configured to keep reducing the neuron numbers along the feature extraction hierarchy, these deep ConvNets gradually form compact identity-related features in the top layers with only a small number of hidden neurons. The proposed features are extracted from various face regions to form complementary and over-complete representations. Any state-of-the-art classifiers can be learned based on these high-level representations for face verification. 97:45% verification accuracy on LFW is achieved with only weakly aligned faces.",
            "referenceCount": 37,
            "citationCount": 1887,
            "influentialCitationCount": 116,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://mmlab.ie.cuhk.edu.hk/pdf/YiSun_CVPR14.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-06-23",
            "journal": {
                "name": "2014 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sun2014DeepLF,\n author = {Yi Sun and Xiaogang Wang and Xiaoou Tang},\n booktitle = {2014 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2014 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {1891-1898},\n title = {Deep Learning Face Representation from Predicting 10,000 Classes},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:62f06cc675675c3f585369d1bf659b9c04fdfd83",
            "@type": "ScholarlyArticle",
            "paperId": "62f06cc675675c3f585369d1bf659b9c04fdfd83",
            "corpusId": 52298689,
            "url": "https://www.semanticscholar.org/paper/62f06cc675675c3f585369d1bf659b9c04fdfd83",
            "title": "Deep Learning for an Effective Nonorthogonal Multiple Access Scheme",
            "venue": "IEEE Transactions on Vehicular Technology",
            "publicationVenue": {
                "id": "urn:research:983b0731-eddf-4f05-9c9b-81059a9f9c51",
                "name": "IEEE Transactions on Vehicular Technology",
                "alternate_names": [
                    "IEEE Trans Veh Technol"
                ],
                "issn": "0018-9545",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=25"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2808769300",
                "DBLP": "journals/tvt/GuiHSS18",
                "DOI": "10.1109/TVT.2018.2848294",
                "CorpusId": 52298689
            },
            "abstract": "Nonorthogonal multiple access (NOMA) has been considered as an essential multiple access technique for enhancing system capacity and spectral efficiency in future communication scenarios. However, the existing NOMA systems have a fundamental limit: high computational complexity and a sharply changing wireless channel make exploiting the characteristics of the channel and deriving the ideal allocation methods very difficult tasks. To break this fundamental limit, in this paper, we propose a novel and effective deep learning (DL)-aided NOMA system, in which several NOMA users with random deployment are served by one base station. Since DL is advantageous in that it allows training the input signals and detecting sharply changing channel conditions, we exploit it to address wireless NOMA channels in an end-to-end manner. Specifically, it is employed in the proposed NOMA system to learn a completely unknown channel environment. A long short-term memory (LSTM) network based on DL is incorporated into a typical NOMA system, enabling the proposed scheme to detect the channel characteristics automatically. In the proposed strategy, the LSTM is first trained by simulated data under different channel conditions via offline learning, and then the corresponding output data can be obtained based on the current input data used during the online learning process. In general, we build, train and test the proposed cooperative framework to realize automatic encoding, decoding and channel detection in an additive white Gaussian noise channel. Furthermore, we regard one conventional user activity and data detection scheme as an unknown nonlinear mapping operation and use  LSTM to approximate it to evaluate the data detection capacity of DL based on NOMA. Simulation results demonstrate that the proposed scheme is robust and efficient compared with conventional approaches. In addition, the accuracy of the LSTM-aided NOMA scheme is studied by introducing the well-known tenfold cross-validation procedure.",
            "referenceCount": 31,
            "citationCount": 389,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-06-18",
            "journal": {
                "name": "IEEE Transactions on Vehicular Technology",
                "volume": "67"
            },
            "citationStyles": {
                "bibtex": "@Article{Gui2018DeepLF,\n author = {Guan Gui and Hongji Huang and Yiwei Song and H. Sari},\n booktitle = {IEEE Transactions on Vehicular Technology},\n journal = {IEEE Transactions on Vehicular Technology},\n pages = {8440-8450},\n title = {Deep Learning for an Effective Nonorthogonal Multiple Access Scheme},\n volume = {67},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b7cf49e30355633af2db19f35189410c8515e91f",
            "@type": "ScholarlyArticle",
            "paperId": "b7cf49e30355633af2db19f35189410c8515e91f",
            "corpusId": 2547043,
            "url": "https://www.semanticscholar.org/paper/b7cf49e30355633af2db19f35189410c8515e91f",
            "title": "Deep Learning with Limited Numerical Precision",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/GuptaAGN15",
                "MAG": "2950826343",
                "ArXiv": "1502.02551",
                "CorpusId": 2547043
            },
            "abstract": "Training of large-scale deep neural networks is often constrained by the available computational resources. We study the effect of limited precision data representation and computation on neural network training. Within the context of low-precision fixed-point computations, we observe the rounding scheme to play a crucial role in determining the network's behavior during training. Our results show that deep networks can be trained using only 16-bit wide fixed-point number representation when using stochastic rounding, and incur little to no degradation in the classification accuracy. We also demonstrate an energy-efficient hardware accelerator that implements low-precision fixed-point arithmetic with stochastic rounding.",
            "referenceCount": 33,
            "citationCount": 1829,
            "influentialCitationCount": 115,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-02-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gupta2015DeepLW,\n author = {Suyog Gupta and A. Agrawal and K. Gopalakrishnan and P. Narayanan},\n booktitle = {International Conference on Machine Learning},\n pages = {1737-1746},\n title = {Deep Learning with Limited Numerical Precision},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b76690c87021c8451f7a900b8f6de9c56819a103",
            "@type": "ScholarlyArticle",
            "paperId": "b76690c87021c8451f7a900b8f6de9c56819a103",
            "corpusId": 243145014,
            "url": "https://www.semanticscholar.org/paper/b76690c87021c8451f7a900b8f6de9c56819a103",
            "title": "Deep Learning",
            "venue": "Lecture Notes on Numerical Methods in Engineering and Sciences",
            "publicationVenue": {
                "id": "urn:research:3ed6bf7c-5325-4480-aa46-1c436b88cbe4",
                "name": "Lecture Notes on Numerical Methods in Engineering and Sciences",
                "alternate_names": [
                    "Lect Note Numer Method Eng Sci"
                ],
                "issn": "1877-7341",
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.1007/978-3-030-66111-3_3",
                "CorpusId": 243145014
            },
            "abstract": null,
            "referenceCount": 5,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Lecture Notes on Numerical Methods in Engineering and Sciences",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yagawa2021DeepL,\n author = {G. Yagawa and Atsuya Oishi},\n booktitle = {Lecture Notes on Numerical Methods in Engineering and Sciences},\n journal = {Lecture Notes on Numerical Methods in Engineering and Sciences},\n title = {Deep Learning},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5379993289542692e7e31d17bbb5ff30568ed614",
            "@type": "ScholarlyArticle",
            "paperId": "5379993289542692e7e31d17bbb5ff30568ed614",
            "corpusId": 239970363,
            "url": "https://www.semanticscholar.org/paper/5379993289542692e7e31d17bbb5ff30568ed614",
            "title": "Deep learning",
            "venue": "Radiopaedia.org",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.53347/rid-88648",
                "CorpusId": 239970363
            },
            "abstract": null,
            "referenceCount": 6,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2021-04-15",
            "journal": {
                "name": "Radiopaedia.org",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Moore2021DeepL,\n author = {Candace Moore and Dimitrios Toumpanakis},\n booktitle = {Radiopaedia.org},\n journal = {Radiopaedia.org},\n title = {Deep learning},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:39b7971c483eca7b032e5bfd826fc693a7e27bb5",
            "@type": "ScholarlyArticle",
            "paperId": "39b7971c483eca7b032e5bfd826fc693a7e27bb5",
            "corpusId": 3382679,
            "url": "https://www.semanticscholar.org/paper/39b7971c483eca7b032e5bfd826fc693a7e27bb5",
            "title": "Deep learning based tissue analysis predicts outcome in colorectal cancer",
            "venue": "Scientific Reports",
            "publicationVenue": {
                "id": "urn:research:f99f77b7-b1b6-44d3-984a-f288e9884b9b",
                "name": "Scientific Reports",
                "alternate_names": [
                    "Sci Rep"
                ],
                "issn": "2045-2322",
                "url": "http://www.nature.com/srep/"
            },
            "year": 2018,
            "externalIds": {
                "PubMedCentral": "5821847",
                "MAG": "2794803511",
                "DOI": "10.1038/s41598-018-21758-3",
                "CorpusId": 3382679,
                "PubMed": "29467373"
            },
            "abstract": null,
            "referenceCount": 55,
            "citationCount": 436,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41598-018-21758-3.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-21",
            "journal": {
                "name": "Scientific Reports",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Bychkov2018DeepLB,\n author = {Dmitrii Bychkov and N. Linder and Riku Turkki and S. Nordling and P. Kovanen and C. Verrill and Margarita Walliander and M. Lundin and C. Haglund and J. Lundin},\n booktitle = {Scientific Reports},\n journal = {Scientific Reports},\n title = {Deep learning based tissue analysis predicts outcome in colorectal cancer},\n volume = {8},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:073788a29dfd94619b37a4e394b7492395d12af7",
            "@type": "ScholarlyArticle",
            "paperId": "073788a29dfd94619b37a4e394b7492395d12af7",
            "corpusId": 210866724,
            "url": "https://www.semanticscholar.org/paper/073788a29dfd94619b37a4e394b7492395d12af7",
            "title": "Deep learning interpretation of echocardiograms",
            "venue": "bioRxiv",
            "publicationVenue": {
                "id": "urn:research:027ffd21-ebb0-4af8-baf5-911124292fd0",
                "name": "bioRxiv",
                "alternate_names": null,
                "issn": null,
                "url": "http://biorxiv.org/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/npjdm/GhorbaniOAHCHLA20",
                "MAG": "3002705197",
                "PubMedCentral": "6981156",
                "DOI": "10.1038/s41746-019-0216-8",
                "CorpusId": 210866724,
                "PubMed": "31993508"
            },
            "abstract": null,
            "referenceCount": 73,
            "citationCount": 241,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41746-019-0216-8.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Biology",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-24",
            "journal": {
                "name": "NPJ Digital Medicine",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Ghorbani2019DeepLI,\n author = {Amirata Ghorbani and David Ouyang and Abubakar Abid and B. He and Jonathan H. Chen and R. Harrington and D. Liang and E. Ashley and J. Zou},\n booktitle = {bioRxiv},\n journal = {NPJ Digital Medicine},\n title = {Deep learning interpretation of echocardiograms},\n volume = {3},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f38b9ca303fc7b2c81470ce0ca2963d8b50474de",
            "@type": "ScholarlyArticle",
            "paperId": "f38b9ca303fc7b2c81470ce0ca2963d8b50474de",
            "corpusId": 3558190,
            "url": "https://www.semanticscholar.org/paper/f38b9ca303fc7b2c81470ce0ca2963d8b50474de",
            "title": "Deep learning in radiology: An overview of the concepts and a survey of the state of the art with focus on MRI",
            "venue": "Journal of Magnetic Resonance Imaging",
            "publicationVenue": {
                "id": "urn:research:3f47b086-88ae-45dd-a8fb-c831f3d57938",
                "name": "Journal of Magnetic Resonance Imaging",
                "alternate_names": [
                    "J Magn Reson Imaging"
                ],
                "issn": "1053-1807",
                "url": "http://www3.interscience.wiley.com/cgi-bin/jtoc?ID=10005199"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2906598409",
                "DBLP": "journals/corr/abs-1802-08717",
                "ArXiv": "1802.08717",
                "DOI": "10.1002/jmri.26534",
                "CorpusId": 3558190,
                "PubMed": "30575178"
            },
            "abstract": "Deep learning is a branch of artificial intelligence where networks of simple interconnected units are used to extract patterns from data in order to solve complex problems. Deep\u2010learning algorithms have shown groundbreaking performance in a variety of sophisticated tasks, especially those related to images. They have often matched or exceeded human performance. Since the medical field of radiology mainly relies on extracting useful information from images, it is a very natural application area for deep learning, and research in this area has rapidly grown in recent years. In this article, we discuss the general context of radiology and opportunities for application of deep\u2010learning algorithms. We also introduce basic concepts of deep learning, including convolutional neural networks. Then, we present a survey of the research in deep learning applied to radiology. We organize the studies by the types of specific tasks that they attempt to solve and review a broad range of deep\u2010learning algorithms being utilized. Finally, we briefly discuss opportunities and challenges for incorporating deep learning in the radiology practice of the future.",
            "referenceCount": 159,
            "citationCount": 324,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc6483404?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-02-10",
            "journal": {
                "name": "Journal of Magnetic Resonance Imaging",
                "volume": "49"
            },
            "citationStyles": {
                "bibtex": "@Article{Mazurowski2018DeepLI,\n author = {M. Mazurowski and Mateusz Buda and Ashirbani Saha and M. Bashir},\n booktitle = {Journal of Magnetic Resonance Imaging},\n journal = {Journal of Magnetic Resonance Imaging},\n title = {Deep learning in radiology: An overview of the concepts and a survey of the state of the art with focus on MRI},\n volume = {49},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:64be9999b68e12d260ba7423f6b55ffd41552ad3",
            "@type": "ScholarlyArticle",
            "paperId": "64be9999b68e12d260ba7423f6b55ffd41552ad3",
            "corpusId": 206491372,
            "url": "https://www.semanticscholar.org/paper/64be9999b68e12d260ba7423f6b55ffd41552ad3",
            "title": "Deep Learning Applications in Medical Image Analysis",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2777186991",
                "DBLP": "journals/access/KerWRL18",
                "DOI": "10.1109/ACCESS.2017.2788044",
                "CorpusId": 206491372
            },
            "abstract": "The tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging. This review introduces the machine learning algorithms as applied to medical image analysis, focusing on convolutional neural networks, and emphasizing clinical aspects of the field. The advantage of machine learning in an era of medical big data is that significant hierarchal relationships within the data can be discovered algorithmically without laborious hand-crafting of features. We cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration. We conclude by discussing research obstacles, emerging trends, and possible future directions.",
            "referenceCount": 124,
            "citationCount": 878,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Access",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Ker2018DeepLA,\n author = {Justin Ker and Lipo Wang and J. Rao and Tchoyoson C. C. Lim},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {9375-9389},\n title = {Deep Learning Applications in Medical Image Analysis},\n volume = {6},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7d291d5fca0e9cd9e0ed72fb6f82289a197f7f02",
            "@type": "ScholarlyArticle",
            "paperId": "7d291d5fca0e9cd9e0ed72fb6f82289a197f7f02",
            "corpusId": 62795222,
            "url": "https://www.semanticscholar.org/paper/7d291d5fca0e9cd9e0ed72fb6f82289a197f7f02",
            "title": "Machine Learning and Deep Learning",
            "venue": "International Journal of Innovative Technology and Exploring Engineering",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "DOI": "10.35940/ijitee.l3550.1081219",
                "CorpusId": 62795222
            },
            "abstract": "Now-a-days artificial intelligence has become an asset for engineering and experimental studies, just like statistics and calculus. Data science is a growing field for researchers and artificial intelligence, machine learning and deep learning are roots of it. This paper describes the relation between these roots of data science. There is a need of machine learning if any kind of analysis is to be performed. This study describes machine learning from the scratch. It also focuses on Deep Learning. Deep learning can also be known as new trend of machine learning. This paper gives a light on basic architecture of Deep learning. A comparative study of machine learning and deep learning is also given in the paper and allows researcher to have a broad view on these techniques so that they can understand which one will be preferable solution for a particular problem.",
            "referenceCount": 7,
            "citationCount": 237,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-10-10",
            "journal": {
                "name": "International Journal of Innovative Technology and Exploring Engineering",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bhattacharjee2019MachineLA,\n author = {Abhijit Bhattacharjee},\n booktitle = {International Journal of Innovative Technology and Exploring Engineering},\n journal = {International Journal of Innovative Technology and Exploring Engineering},\n title = {Machine Learning and Deep Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f19284f6ab802c8a1fcde076fcb3fba195a71723",
            "@type": "ScholarlyArticle",
            "paperId": "f19284f6ab802c8a1fcde076fcb3fba195a71723",
            "corpusId": 6662846,
            "url": "https://www.semanticscholar.org/paper/f19284f6ab802c8a1fcde076fcb3fba195a71723",
            "title": "A guide to convolution arithmetic for deep learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/DumoulinV16",
                "ArXiv": "1603.07285",
                "MAG": "2304648132",
                "CorpusId": 6662846
            },
            "abstract": "We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.",
            "referenceCount": 24,
            "citationCount": 1361,
            "influentialCitationCount": 70,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-03-23",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1603.07285"
            },
            "citationStyles": {
                "bibtex": "@Article{Dumoulin2016AGT,\n author = {Vincent Dumoulin and Francesco Visin},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A guide to convolution arithmetic for deep learning},\n volume = {abs/1603.07285},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b42c38975f3d3f8bfe4b0c1a6e576c3e297cec38",
            "@type": "ScholarlyArticle",
            "paperId": "b42c38975f3d3f8bfe4b0c1a6e576c3e297cec38",
            "corpusId": 53753741,
            "url": "https://www.semanticscholar.org/paper/b42c38975f3d3f8bfe4b0c1a6e576c3e297cec38",
            "title": "Stochastic Gradient Push for Distributed Deep Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1811-10792",
                "MAG": "2902410171",
                "ArXiv": "1811.10792",
                "CorpusId": 53753741
            },
            "abstract": "Distributed data-parallel algorithms aim to accelerate the training of deep neural networks by parallelizing the computation of large mini-batch gradient updates across multiple nodes. Approaches that synchronize nodes using exact distributed averaging (e.g., via AllReduce) are sensitive to stragglers and communication delays. The PushSum gossip algorithm is robust to these issues, but only performs approximate distributed averaging. This paper studies Stochastic Gradient Push (SGP), which combines PushSum with stochastic gradient updates. We prove that SGP converges to a stationary point of smooth, non-convex objectives at the same sub-linear rate as SGD, and that all nodes achieve consensus. We empirically validate the performance of SGP on image classification (ResNet-50, ImageNet) and machine translation (Transformer, WMT'16 En-De) workloads. Our code will be made publicly available.",
            "referenceCount": 42,
            "citationCount": 275,
            "influentialCitationCount": 64,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-09-27",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Assran2018StochasticGP,\n author = {Mahmoud Assran and Nicolas Loizou and Nicolas Ballas and Michael G. Rabbat},\n booktitle = {International Conference on Machine Learning},\n pages = {344-353},\n title = {Stochastic Gradient Push for Distributed Deep Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eb2fcb003541b29f727588da1183bf1ca289cb73",
            "@type": "ScholarlyArticle",
            "paperId": "eb2fcb003541b29f727588da1183bf1ca289cb73",
            "corpusId": 53094072,
            "url": "https://www.semanticscholar.org/paper/eb2fcb003541b29f727588da1183bf1ca289cb73",
            "title": "Deep learning in medical imaging and radiation therapy.",
            "venue": "Medical Physics (Lancaster)",
            "publicationVenue": {
                "id": "urn:research:4e90b61b-3ae1-4b4c-9348-d67a3825e703",
                "name": "Medical Physics (Lancaster)",
                "alternate_names": [
                    "Med Phys (lancaster",
                    "Medical Physics",
                    "Med Phys"
                ],
                "issn": "0094-2405",
                "url": "http://scitation.aip.org/content/aapm/journal/medphys"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2898197178",
                "DOI": "10.1002/mp.13264",
                "CorpusId": 53094072,
                "PubMed": "30367497"
            },
            "abstract": "The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges, and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks, survey five major areas of application of DL in medical imaging and radiation therapy, identify common themes, discuss methods for dataset expansion, and conclude by summarizing lessons learned, remaining challenges, and future directions.",
            "referenceCount": 396,
            "citationCount": 514,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://aapm.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mp.13264",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-11-20",
            "journal": {
                "name": "Medical physics",
                "volume": "46 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Sahiner2018DeepLI,\n author = {B. Sahiner and Aria Pezeshk and Lubomir M. Hadjiiski and Xiaosong Wang and K. Drukker and Kenny H. Cha and R. Summers and M. Giger},\n booktitle = {Medical Physics (Lancaster)},\n journal = {Medical physics},\n pages = {\n          e1-e36\n        },\n title = {Deep learning in medical imaging and radiation therapy.},\n volume = {46 1},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8c113fc0b05da2fa0e73ccdf3b039a1fe02ba1b6",
            "@type": "ScholarlyArticle",
            "paperId": "8c113fc0b05da2fa0e73ccdf3b039a1fe02ba1b6",
            "corpusId": 52159572,
            "url": "https://www.semanticscholar.org/paper/8c113fc0b05da2fa0e73ccdf3b039a1fe02ba1b6",
            "title": "Deep learning in biomedicine",
            "venue": "Nature Biotechnology",
            "publicationVenue": {
                "id": "urn:research:458166b3-de17-4bf3-bbbb-e53782de2f0f",
                "name": "Nature Biotechnology",
                "alternate_names": [
                    "Nat Biotechnol"
                ],
                "issn": "1087-0156",
                "url": "http://www.nature.com/nbt/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2892221324",
                "DOI": "10.1038/nbt.4233",
                "CorpusId": 52159572,
                "PubMed": "30188539"
            },
            "abstract": null,
            "referenceCount": 64,
            "citationCount": 386,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-06",
            "journal": {
                "name": "Nature Biotechnology",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{Wainberg2018DeepLI,\n author = {Michael Wainberg and D. Merico and Andrew Delong and B. Frey},\n booktitle = {Nature Biotechnology},\n journal = {Nature Biotechnology},\n pages = {829-838},\n title = {Deep learning in biomedicine},\n volume = {36},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6966d2b49fa885897e0b2e18ce144831c55f3e5f",
            "@type": "ScholarlyArticle",
            "paperId": "6966d2b49fa885897e0b2e18ce144831c55f3e5f",
            "corpusId": 67856359,
            "url": "https://www.semanticscholar.org/paper/6966d2b49fa885897e0b2e18ce144831c55f3e5f",
            "title": "Deep learning in bioinformatics: introduction, application, and perspective in big data era",
            "venue": "bioRxiv",
            "publicationVenue": {
                "id": "urn:research:027ffd21-ebb0-4af8-baf5-911124292fd0",
                "name": "bioRxiv",
                "alternate_names": null,
                "issn": null,
                "url": "http://biorxiv.org/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1903.00342",
                "MAG": "2915583118",
                "DBLP": "journals/corr/abs-1903-00342",
                "DOI": "10.1101/563601",
                "CorpusId": 67856359,
                "PubMed": "31022451"
            },
            "abstract": "Deep learning, which is especially formidable in handling big data, has achieved great success in various fields, including bioinformatics. With the advances of the big data era in biology, it is foreseeable that deep learning will become increasingly important in the field and will be incorporated in vast majorities of analysis pipelines. In this review, we provide both the exoteric introduction of deep learning, and concrete examples and implementations of its representative applications in bioinformatics. We start from the recent achievements of deep learning in the bioinformatics field, pointing out the problems which are suitable to use deep learning. After that, we introduce deep learning in an easy-to-understand fashion, from shallow neural networks to legendary convolutional neural networks, legendary recurrent neural networks, graph neural networks, generative adversarial networks, variational autoencoder, and the most recent state-of-the-art architectures. After that, we provide eight examples, covering five bioinformatics research directions and all the four kinds of data type, with the implementation written in Tensorflow and Keras. Finally, we discuss the common issues, such as overfitting and interpretability, that users will encounter when adopting deep learning methods and provide corresponding suggestions. The implementations are freely available at https://github.com/lykaust15/Deep_learning_examples.",
            "referenceCount": 213,
            "citationCount": 233,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.biorxiv.org/content/biorxiv/early/2019/02/28/563601.full.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Biology",
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-02-28",
            "journal": {
                "name": "bioRxiv",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Li2019DeepLI,\n author = {Yu Li and Chao Huang and Lizhong Ding and Zhongxiao Li and Yijie Pan and Xin Gao},\n booktitle = {bioRxiv},\n journal = {bioRxiv},\n title = {Deep learning in bioinformatics: introduction, application, and perspective in big data era},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d3850595d3ae7c73e9488054c9b437f75511b569",
            "@type": "ScholarlyArticle",
            "paperId": "d3850595d3ae7c73e9488054c9b437f75511b569",
            "corpusId": 168170169,
            "url": "https://www.semanticscholar.org/paper/d3850595d3ae7c73e9488054c9b437f75511b569",
            "title": "SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1905-12149",
                "ArXiv": "1905.12149",
                "MAG": "2945570796",
                "CorpusId": 168170169
            },
            "abstract": "Integrating logical reasoning within deep learning architectures has been a major goal of modern AI systems. In this paper, we propose a new direction toward this goal by introducing a differentiable (smoothed) maximum satisfiability (MAXSAT) solver that can be integrated into the loop of larger deep learning systems. Our (approximate) solver is based upon a fast coordinate descent approach to solving the semidefinite program (SDP) associated with the MAXSAT problem. We show how to analytically differentiate through the solution to this SDP and efficiently solve the associated backward pass. We demonstrate that by integrating this solver into end-to-end learning systems, we can learn the logical structure of challenging problems in a minimally supervised fashion. In particular, we show that we can learn the parity function using single-bit supervision (a traditionally hard task for deep networks) and learn how to play 9x9 Sudoku solely from examples. We also solve a \"visual Sudok\" problem that maps images of Sudoku puzzles to their associated logical solutions by combining our MAXSAT solver with a traditional convolutional architecture. Our approach thus shows promise in integrating logical structures within deep learning.",
            "referenceCount": 33,
            "citationCount": 198,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-05-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2019SATNetBD,\n author = {Po-Wei Wang and P. Donti and Bryan Wilder and Zico Kolter},\n booktitle = {International Conference on Machine Learning},\n pages = {6545-6554},\n title = {SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b06d260b504a20e90d07180aa3c4eaecb3b5cde5",
            "@type": "ScholarlyArticle",
            "paperId": "b06d260b504a20e90d07180aa3c4eaecb3b5cde5",
            "corpusId": 195750622,
            "url": "https://www.semanticscholar.org/paper/b06d260b504a20e90d07180aa3c4eaecb3b5cde5",
            "title": "Selection Via Proxy: Efficient Data Selection For Deep Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1906-11829",
                "MAG": "2995592331",
                "ArXiv": "1906.11829",
                "CorpusId": 195750622
            },
            "abstract": "Data selection methods such as active learning and core-set selection are useful tools for machine learning on large datasets, but they can be prohibitively expensive to apply in deep learning. Unlike in other areas of machine learning, the feature representations that these techniques depend on are learned in deep learning rather than given, which takes a substantial amount of training time. In this work, we show that we can significantly improve the computational efficiency of data selection in deep learning by using a much smaller proxy model to perform data selection for tasks that will eventually require a large target model (e.g., selecting data points to label for active learning). In deep learning, we can scale down models by removing hidden layers or reducing their dimension to create proxies that are an order of magnitude faster. Although these small proxy models have significantly higher error, we find that they empirically provide useful rankings for data selection that have a high correlation with those of larger models. We evaluate this \"selection via proxy\" (SVP) approach on several data selection tasks. For active learning, applying SVP to Sener and Savarese [2018]'s recent method for active learning in deep learning gives a 4x improvement in execution time while yielding the same model accuracy. For core-set selection, we show that a proxy model that trains 10x faster than a target ResNet164 model on CIFAR10 can be used to remove 50% of the training data without compromising the accuracy of the target model, making end-to-end training time improvements via core-set selection possible.",
            "referenceCount": 60,
            "citationCount": 179,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-26",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1906.11829"
            },
            "citationStyles": {
                "bibtex": "@Article{Coleman2019SelectionVP,\n author = {Cody A. Coleman and Christopher Yeh and Stephen Mussmann and Baharan Mirzasoleiman and Peter D. Bailis and Percy Liang and J. Leskovec and M. Zaharia},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Selection Via Proxy: Efficient Data Selection For Deep Learning},\n volume = {abs/1906.11829},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1f135e98e867ffcde5b359e7b817bbe21f80cfce",
            "@type": "ScholarlyArticle",
            "paperId": "1f135e98e867ffcde5b359e7b817bbe21f80cfce",
            "corpusId": 118926724,
            "url": "https://www.semanticscholar.org/paper/1f135e98e867ffcde5b359e7b817bbe21f80cfce",
            "title": "Deep Learning and Its Application to LHC Physics",
            "venue": "Annual Review of Nuclear and Particle Science",
            "publicationVenue": {
                "id": "urn:research:9a1eb53e-bbc0-4488-976f-6db6d80789ca",
                "name": "Annual Review of Nuclear and Particle Science",
                "alternate_names": [
                    "Annu Rev Nucl Part Sci"
                ],
                "issn": "0163-8998",
                "url": "https://www.annualreviews.org/journal/nucl"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "3099381338",
                "ArXiv": "1806.11484",
                "DOI": "10.1146/annurev-nucl-101917-021019",
                "CorpusId": 118926724
            },
            "abstract": "Machine learning has played an important role in the analysis of high-energy physics data for decades. The emergence of deep learning in 2012 allowed for machine learning tools which could adeptly handle higher-dimensional and more complex problems than previously feasible. This review is aimed at the reader who is familiar with high-energy physics but not machine learning. The connections between machine learning and high-energy physics data analysis are explored, followed by an introduction to the core concepts of neural networks, examples of the key results demonstrating the power of deep learning for analysis of LHC data, and discussion of future prospects and concerns.",
            "referenceCount": 41,
            "citationCount": 312,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1806.11484",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2018-06-29",
            "journal": {
                "name": "Annual Review of Nuclear and Particle Science",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Guest2018DeepLA,\n author = {D. Guest and Kyle Cranmer and D. Whiteson},\n booktitle = {Annual Review of Nuclear and Particle Science},\n journal = {Annual Review of Nuclear and Particle Science},\n title = {Deep Learning and Its Application to LHC Physics},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e6ed2eae6d810deb0dd00b2bdedf07252dedd51b",
            "@type": "ScholarlyArticle",
            "paperId": "e6ed2eae6d810deb0dd00b2bdedf07252dedd51b",
            "corpusId": 86816819,
            "url": "https://www.semanticscholar.org/paper/e6ed2eae6d810deb0dd00b2bdedf07252dedd51b",
            "title": "A Review of Deep Learning with Special Emphasis on Architectures, Applications and Recent Trends",
            "venue": "Knowledge-Based Systems",
            "publicationVenue": {
                "id": "urn:research:12fff95b-d469-49a0-84a5-4fd4696c3f28",
                "name": "Knowledge-Based Systems",
                "alternate_names": [
                    "Knowl Based Syst",
                    "Knowledge Based Systems",
                    "Knowledge-based Syst"
                ],
                "issn": "0950-7051",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/525448/description#description"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3004442222",
                "DBLP": "journals/corr/abs-1905-13294",
                "ArXiv": "1905.13294",
                "DOI": "10.20944/preprints201902.0233.v1",
                "CorpusId": 86816819
            },
            "abstract": "Deep learning has taken over - both in problems beyond the realm of traditional, hand-crafted machine learning paradigms as well as in capturing the imagination of the practitioner sitting on top of petabytes of data. While the public perception about the efficacy of deep neural architectures in complex pattern recognition tasks grows, sequentially up-to-date primers on the current state of affairs must follow. In this review, we seek to present a refresher of the many different stacked, connectionist networks that make up the deep learning architectures followed by automatic architecture optimization protocols using multi-agent approaches. Further, since guaranteeing system uptime is fast becoming an indispensable asset across multiple industrial modalities, we include an investigative section on testing neural networks for fault detection and subsequent mitigation. This is followed by an exploratory survey of several application areas where deep learning has emerged as a game-changing technology - be it anomalous behavior detection in financial applications or financial time-series forecasting, predictive and prescriptive analytics, medical imaging, natural language processing or power systems research. The thrust of this review is on outlining emerging areas of application-oriented research within the deep learning community as well as to provide a handy reference to researchers seeking to embrace deep learning in their work for what it is: statistical pattern recognizers with unparalleled hierarchical structure learning capacity with the ability to scale with information.",
            "referenceCount": 363,
            "citationCount": 224,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1905.13294",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-02-26",
            "journal": {
                "name": "Knowl. Based Syst.",
                "volume": "194"
            },
            "citationStyles": {
                "bibtex": "@Article{Sengupta2019ARO,\n author = {Saptarshi Sengupta and Sanchita Basak and P. Saikia and Sayak Paul and Vasilios Tsalavoutis and Frederick Ditliac Atiah and V. Ravi and R. Peters},\n booktitle = {Knowledge-Based Systems},\n journal = {Knowl. Based Syst.},\n pages = {105596},\n title = {A Review of Deep Learning with Special Emphasis on Architectures, Applications and Recent Trends},\n volume = {194},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5f824248ff8eb9cd12dd6a13f4ed11a1d696abac",
            "@type": "ScholarlyArticle",
            "paperId": "5f824248ff8eb9cd12dd6a13f4ed11a1d696abac",
            "corpusId": 6305490,
            "url": "https://www.semanticscholar.org/paper/5f824248ff8eb9cd12dd6a13f4ed11a1d696abac",
            "title": "HashNet: Deep Learning to Hash by Continuation",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2950007757",
                "DBLP": "conf/iccv/CaoLWY17",
                "ArXiv": "1702.00758",
                "DOI": "10.1109/ICCV.2017.598",
                "CorpusId": 6305490
            },
            "abstract": "Learning to hash has been widely applied to approximate nearest neighbor search for large-scale multimedia retrieval, due to its computation efficiency and retrieval quality. Deep learning to hash, which improves retrieval quality by end-to-end representation learning and hash encoding, has received increasing attention recently. Subject to the ill-posed gradient difficulty in the optimization with sign activations, existing deep learning to hash methods need to first learn continuous representations and then generate binary hash codes in a separated binarization step, which suffer from substantial loss of retrieval quality. This work presents HashNet, a novel deep architecture for deep learning to hash by continuation method with convergence guarantees, which learns exactly binary hash codes from imbalanced similarity data. The key idea is to attack the ill-posed gradient problem in optimizing deep networks with non-smooth binary activations by continuation method, in which we begin from learning an easier network with smoothed activation function and let it evolve during the training, until it eventually goes back to being the original, difficult to optimize, deep network with the sign activation function. Comprehensive empirical evidence shows that HashNet can generate exactly binary hash codes and yield state-of-the-art multimedia retrieval performance on standard benchmarks.",
            "referenceCount": 48,
            "citationCount": 534,
            "influentialCitationCount": 156,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1702.00758",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-02-02",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cao2017HashNetDL,\n author = {Zhangjie Cao and Mingsheng Long and Jianmin Wang and Philip S. Yu},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2017 IEEE International Conference on Computer Vision (ICCV)},\n pages = {5609-5618},\n title = {HashNet: Deep Learning to Hash by Continuation},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1e4709c0b8fe3bf759cd64dc1ede695d6e5316f0",
            "@type": "ScholarlyArticle",
            "paperId": "1e4709c0b8fe3bf759cd64dc1ede695d6e5316f0",
            "corpusId": 11392154,
            "url": "https://www.semanticscholar.org/paper/1e4709c0b8fe3bf759cd64dc1ede695d6e5316f0",
            "title": "Deep learning applications and challenges in big data analytics",
            "venue": "Journal of Big Data",
            "publicationVenue": {
                "id": "urn:research:d60da343-ab92-4310-b3d7-2c0860287a9d",
                "name": "Journal of Big Data",
                "alternate_names": [
                    "J Big Data",
                    "Journal on Big Data"
                ],
                "issn": "2196-1115",
                "url": "http://www.journalofbigdata.com/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/jbd/NajafabadiVKSWM15",
                "MAG": "2118023920",
                "DOI": "10.1186/s40537-014-0007-7",
                "CorpusId": 11392154
            },
            "abstract": null,
            "referenceCount": 65,
            "citationCount": 1809,
            "influentialCitationCount": 37,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-014-0007-7",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-02-24",
            "journal": {
                "name": "Journal of Big Data",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Najafabadi2015DeepLA,\n author = {M. M. Najafabadi and Flavio Villanustre and T. Khoshgoftaar and Naeem Seliya and Randall Wald and Edin A. Muharemagic},\n booktitle = {Journal of Big Data},\n journal = {Journal of Big Data},\n title = {Deep learning applications and challenges in big data analytics},\n volume = {2},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7dae942104dc8283504ce7a492c9ca12fa119189",
            "@type": "ScholarlyArticle",
            "paperId": "7dae942104dc8283504ce7a492c9ca12fa119189",
            "corpusId": 67922904,
            "url": "https://www.semanticscholar.org/paper/7dae942104dc8283504ce7a492c9ca12fa119189",
            "title": "Applications, promises, and pitfalls of deep learning for fluorescence image reconstruction",
            "venue": "Nature Methods",
            "publicationVenue": {
                "id": "urn:research:099483df-e8f2-4bee-805d-8a69f07b6cbf",
                "name": "Nature Methods",
                "alternate_names": [
                    "Nat Method"
                ],
                "issn": "1548-7091",
                "url": "http://www.nature.com/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2910683834",
                "DOI": "10.1038/s41592-019-0458-z",
                "CorpusId": 67922904,
                "PubMed": "31285623"
            },
            "abstract": null,
            "referenceCount": 118,
            "citationCount": 316,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-12-11",
            "journal": {
                "name": "Nature Methods",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Belthangady2018ApplicationsPA,\n author = {C. Belthangady and Loic A. Royer},\n booktitle = {Nature Methods},\n journal = {Nature Methods},\n pages = {1215 - 1225},\n title = {Applications, promises, and pitfalls of deep learning for fluorescence image reconstruction},\n volume = {16},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0ab99aa04e3a8340a7552355fb547374a5604b24",
            "@type": "ScholarlyArticle",
            "paperId": "0ab99aa04e3a8340a7552355fb547374a5604b24",
            "corpusId": 5501470,
            "url": "https://www.semanticscholar.org/paper/0ab99aa04e3a8340a7552355fb547374a5604b24",
            "title": "Deep Learning in Medical Imaging: Overview and Future Promise of an Exciting New Technique",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "CorpusId": 5501470
            },
            "abstract": "D EEP learning is a growing trend in general data analysis and has been termed one of the 10 breakthrough technologies of 2013 [1]. Deep learning is an improvement of artificial neural networks, consisting of more layers that permit higher levels of abstraction and improved predictions from data [2]. To date, it is emerging as the leading machine-learning tool in the general imaging and computer vision domains. In particular, convolutional neural networks (CNNs) have proven to be powerful tools for a broad range of computer vision tasks. Deep CNNs automatically learn mid-level and high-level abstractions obtained from raw data (e.g., images). Recent results indicate that the generic descriptors extracted from CNNs are extremely effective in object recognition and localization in natural images. Medical image analysis groups across the world are quickly entering the field and applying CNNs and other deep learning methodologies to a wide variety of applications. Promising results are emerging. In medical imaging, the accurate diagnosis and/or assessment of a disease depends on both image acquisition and image interpretation. Image acquisition has improved substantially over recent years, with devices acquiring data at faster rates and increased resolution. The image interpretation process, however, has only recently begun to benefit from computer technology. Most interpretations of medical images are performed by physicians; however, image interpretation by humans is limited due to its subjectivity, large variations across interpreters, and fatigue. Many diagnostic tasks require an initial search process to detect abnormalities, and to quantify measurements and changes over time. Computerized tools, specifically image analysis and machine learning, are the key enablers to improve diagnosis, by facilitating identification of the findings that require treatment and to support the expert\u2019s workflow. Among these tools, deep learning is rapidly proving to be the state-of-the-art foundation, leading to improved accuracy. It has also opened up new frontiers in data analysis with rates of progress not before experienced.",
            "referenceCount": 36,
            "citationCount": 1223,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{None,\n title = {Deep Learning in Medical Imaging: Overview and Future Promise of an Exciting New Technique},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3eaf79589dbb9bce5a502e867a8f03917e52de26",
            "@type": "ScholarlyArticle",
            "paperId": "3eaf79589dbb9bce5a502e867a8f03917e52de26",
            "corpusId": 4833213,
            "url": "https://www.semanticscholar.org/paper/3eaf79589dbb9bce5a502e867a8f03917e52de26",
            "title": "Collaborative Deep Learning for Recommender Systems",
            "venue": "Knowledge Discovery and Data Mining",
            "publicationVenue": {
                "id": "urn:research:a0edb93b-1e95-4128-a295-6b1659149cef",
                "name": "Knowledge Discovery and Data Mining",
                "alternate_names": [
                    "KDD",
                    "Knowl Discov Data Min"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigkdd/"
            },
            "year": 2014,
            "externalIds": {
                "ArXiv": "1409.2944",
                "DBLP": "journals/corr/WangWY14",
                "MAG": "2157881433",
                "DOI": "10.1145/2783258.2783273",
                "CorpusId": 4833213
            },
            "abstract": "Collaborative filtering (CF) is a successful approach commonly used by many recommender systems. Conventional CF-based methods use the ratings given to items by users as the sole source of information for learning to make recommendation. However, the ratings are often very sparse in many applications, causing CF-based methods to degrade significantly in their recommendation performance. To address this sparsity problem, auxiliary information such as item content information may be utilized. Collaborative topic regression (CTR) is an appealing recent method taking this approach which tightly couples the two components that learn from two different sources of information. Nevertheless, the latent representation learned by CTR may not be very effective when the auxiliary information is very sparse. To address this problem, we generalize recently advances in deep learning from i.i.d. input to non-i.i.d. (CF-based) input and propose in this paper a hierarchical Bayesian model called collaborative deep learning (CDL), which jointly performs deep representation learning for the content information and collaborative filtering for the ratings (feedback) matrix. Extensive experiments on three real-world datasets from different domains show that CDL can significantly advance the state of the art.",
            "referenceCount": 46,
            "citationCount": 1502,
            "influentialCitationCount": 182,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1409.2944.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-09-09",
            "journal": {
                "name": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Wang2014CollaborativeDL,\n author = {Hao Wang and Naiyan Wang and D. Yeung},\n booktitle = {Knowledge Discovery and Data Mining},\n journal = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},\n title = {Collaborative Deep Learning for Recommender Systems},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:612cc29c22b544fc329ed17c8d5e3b86a8fa1cd3",
            "@type": "ScholarlyArticle",
            "paperId": "612cc29c22b544fc329ed17c8d5e3b86a8fa1cd3",
            "corpusId": 3449450,
            "url": "https://www.semanticscholar.org/paper/612cc29c22b544fc329ed17c8d5e3b86a8fa1cd3",
            "title": "Over-the-Air Deep Learning Based Radio Signal Classification",
            "venue": "IEEE Journal on Selected Topics in Signal Processing",
            "publicationVenue": {
                "id": "urn:research:e93ebb7d-cfa6-4361-8051-3c6dff3eed1f",
                "name": "IEEE Journal on Selected Topics in Signal Processing",
                "alternate_names": [
                    "IEEE J Sel Top Signal Process",
                    "IEEE Journal of Selected Topics in Signal Processing"
                ],
                "issn": "1932-4553",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=4200690"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2773170971",
                "DBLP": "journals/corr/abs-1712-04578",
                "ArXiv": "1712.04578",
                "DOI": "10.1109/JSTSP.2018.2797022",
                "CorpusId": 3449450
            },
            "abstract": "We conduct an in\u00a0 depth study on the performance of deep learning based radio signal classification for radio communications signals. We consider a rigorous baseline method using higher order moments and strong boosted gradient tree classification, and compare performance between the two approaches across a range of configurations and channel impairments. We consider the effects of carrier frequency offset, symbol rate, and multipath fading in simulation, and conduct over-the-air measurement of radio classification performance in the lab using software radios, and we compare performance and training strategies for both. Finally, we conclude with a discussion of remaining problems, and design considerations for using such techniques.",
            "referenceCount": 37,
            "citationCount": 734,
            "influentialCitationCount": 114,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1712.04578",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-12-13",
            "journal": {
                "name": "IEEE Journal of Selected Topics in Signal Processing",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{O'Shea2017OvertheAirDL,\n author = {Tim O'Shea and Tamoghna Roy and T. Clancy},\n booktitle = {IEEE Journal on Selected Topics in Signal Processing},\n journal = {IEEE Journal of Selected Topics in Signal Processing},\n pages = {168-179},\n title = {Over-the-Air Deep Learning Based Radio Signal Classification},\n volume = {12},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1fb42852a47f77d26efdbacbf75cddcb294b5c3d",
            "@type": "ScholarlyArticle",
            "paperId": "1fb42852a47f77d26efdbacbf75cddcb294b5c3d",
            "corpusId": 108286189,
            "url": "https://www.semanticscholar.org/paper/1fb42852a47f77d26efdbacbf75cddcb294b5c3d",
            "title": "Deep-STORM: super-resolution single-molecule microscopy by deep learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "3104053397",
                "ArXiv": "1801.09631",
                "DOI": "10.1364/OPTICA.5.000458",
                "CorpusId": 108286189
            },
            "abstract": "We present an ultra-fast, precise, parameter-free method, which we term Deep-STORM, for obtaining super-resolution images from stochastically-blinking emitters, such as fluorescent molecules used for localization microscopy. Deep-STORM uses a deep convolutional neural network that can be trained on simulated data or experimental measurements, both of which are demonstrated. The method achieves state-of-the-art resolution under challenging signal-to-noise conditions and high emitter densities, and is significantly faster than existing approaches. Additionally, no prior information on the shape of the underlying structure is required, making the method applicable to any blinking data-set. We validate our approach by super-resolution image reconstruction of simulated and experimentally obtained data.",
            "referenceCount": 45,
            "citationCount": 399,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-01-29",
            "journal": {
                "name": "arXiv: Optics",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Nehme2018DeepSTORMSS,\n author = {E. Nehme and Lucien E. Weiss and T. Michaeli and Yoav Shechtman Department of Electrical Engineering and Technion and Haifa and Israel Department of Biomedical Engineering and Israel},\n journal = {arXiv: Optics},\n title = {Deep-STORM: super-resolution single-molecule microscopy by deep learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:391596b543afaf45f5d0213719b4863596c1dd11",
            "@type": "ScholarlyArticle",
            "paperId": "391596b543afaf45f5d0213719b4863596c1dd11",
            "corpusId": 3677231,
            "url": "https://www.semanticscholar.org/paper/391596b543afaf45f5d0213719b4863596c1dd11",
            "title": "Deep Learning for Massive MIMO CSI Feedback",
            "venue": "IEEE Wireless Communications Letters",
            "publicationVenue": {
                "id": "urn:research:f8912cb6-c5cb-446c-bb21-596484c48df0",
                "name": "IEEE Wireless Communications Letters",
                "alternate_names": [
                    "IEEE Wirel Commun Lett"
                ],
                "issn": "2162-2337",
                "url": "http://www.comsoc.org/wcl"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/wcl/WenSJ18",
                "ArXiv": "1712.08919",
                "MAG": "2963145597",
                "DOI": "10.1109/LWC.2018.2818160",
                "CorpusId": 3677231
            },
            "abstract": "In frequency division duplex mode, the downlink channel state information (CSI) should be sent to the base station through feedback links so that the potential gains of a massive multiple-input multiple-output can be exhibited. However, such a transmission is hindered by excessive feedback overhead. In this letter, we use deep learning technology to develop CsiNet, a novel CSI sensing and recovery mechanism that learns to effectively use channel structure from training samples. CsiNet learns a transformation from CSI to a near-optimal number of representations (or codewords) and an inverse transformation from codewords to CSI. We perform experiments to demonstrate that CsiNet can recover CSI with significantly improved reconstruction quality compared with existing compressive sensing (CS)-based methods. Even at excessively low compression regions where CS-based methods cannot work, CsiNet retains effective beamforming gain.",
            "referenceCount": 17,
            "citationCount": 583,
            "influentialCitationCount": 117,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1712.08919",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-12-24",
            "journal": {
                "name": "IEEE Wireless Communications Letters",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Wen2017DeepLF,\n author = {Chao-Kai Wen and Wan-Ting Shih and Shi Jin},\n booktitle = {IEEE Wireless Communications Letters},\n journal = {IEEE Wireless Communications Letters},\n pages = {748-751},\n title = {Deep Learning for Massive MIMO CSI Feedback},\n volume = {7},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:00521e876d109fdcf344e027f218a768499060c8",
            "@type": "ScholarlyArticle",
            "paperId": "00521e876d109fdcf344e027f218a768499060c8",
            "corpusId": 204734206,
            "url": "https://www.semanticscholar.org/paper/00521e876d109fdcf344e027f218a768499060c8",
            "title": "An Exponential Learning Rate Schedule for Deep Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1910-07454",
                "MAG": "2980844465",
                "ArXiv": "1910.07454",
                "CorpusId": 204734206
            },
            "abstract": "Intriguing empirical evidence exists that deep learning can work well with exoticschedules for varying the learning rate. This paper suggests that the phenomenon may be due to Batch Normalization or BN, which is ubiquitous and provides benefits in optimization and generalization across all standard architectures. The following new results are shown about BN with weight decay and momentum (in other words, the typical use case which was not considered in earlier theoretical analyses of stand-alone BN. \n1. Training can be done using SGD with momentum and an exponentially increasing learning rate schedule, i.e., learning rate increases by some $(1 +\\alpha)$ factor in every epoch for some $\\alpha >0$. (Precise statement in the paper.) To the best of our knowledge this is the first time such a rate schedule has been successfully used, let alone for highly successful architectures. As expected, such training rapidly blows up network weights, but the net stays well-behaved due to normalization. \n2. Mathematical explanation of the success of the above rate schedule: a rigorous proof that it is equivalent to the standard setting of BN + SGD + StandardRate Tuning + Weight Decay + Momentum. This equivalence holds for other normalization layers as well, Group Normalization, LayerNormalization, Instance Norm, etc. \n3. A worked-out toy example illustrating the above linkage of hyper-parameters. Using either weight decay or BN alone reaches global minimum, but convergence fails when both are used.",
            "referenceCount": 28,
            "citationCount": 142,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-10-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1910.07454"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2019AnEL,\n author = {Zhiyuan Li and Sanjeev Arora},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {An Exponential Learning Rate Schedule for Deep Learning},\n volume = {abs/1910.07454},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7238200341f0fc27cadf07a00046a994fe89f6e4",
            "@type": "ScholarlyArticle",
            "paperId": "7238200341f0fc27cadf07a00046a994fe89f6e4",
            "corpusId": 202750227,
            "url": "https://www.semanticscholar.org/paper/7238200341f0fc27cadf07a00046a994fe89f6e4",
            "title": "Synthetic Data for Deep Learning",
            "venue": "Springer Optimization and Its Applications",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1909.11512",
                "MAG": "2975317124",
                "DBLP": "journals/corr/abs-1909-11512",
                "DOI": "10.1007/978-3-030-75178-4",
                "CorpusId": 202750227
            },
            "abstract": null,
            "referenceCount": 706,
            "citationCount": 203,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-030-75178-4/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Review"
            ],
            "publicationDate": "2019-09-25",
            "journal": {
                "name": "Synthetic Data for Deep Learning",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Nikolenko2019SyntheticDF,\n author = {S. Nikolenko},\n booktitle = {Springer Optimization and Its Applications},\n journal = {Synthetic Data for Deep Learning},\n title = {Synthetic Data for Deep Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:027b9a21d6ee849b3268c45df10a44cc3d7b7c24",
            "@type": "ScholarlyArticle",
            "paperId": "027b9a21d6ee849b3268c45df10a44cc3d7b7c24",
            "corpusId": 56482317,
            "url": "https://www.semanticscholar.org/paper/027b9a21d6ee849b3268c45df10a44cc3d7b7c24",
            "title": "An explainable deep-learning algorithm for the detection of acute intracranial haemorrhage from small datasets",
            "venue": "Nature Biomedical Engineering",
            "publicationVenue": {
                "id": "urn:research:5619586e-de5a-4bc3-ac80-04dd8530d80c",
                "name": "Nature Biomedical Engineering",
                "alternate_names": [
                    "Nat Biomed Eng"
                ],
                "issn": "2157-846X",
                "url": "http://www.nature.com/natbiomedeng/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2905307056",
                "DOI": "10.1038/s41551-018-0324-9",
                "CorpusId": 56482317,
                "PubMed": "30948806"
            },
            "abstract": null,
            "referenceCount": 43,
            "citationCount": 303,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-12-17",
            "journal": {
                "name": "Nature Biomedical Engineering",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Lee2018AnED,\n author = {Hyunkwang Lee and Sehyo Yune and Mohammad Mansouri and Myeongchan Kim and Shahein H. Tajmir and Claude E. Guerrier and Sarah A. Ebert and S. Pomerantz and J. Romero and S. Kamalian and R. Gonz\u00e1lez and M. Lev and Synho Do},\n booktitle = {Nature Biomedical Engineering},\n journal = {Nature Biomedical Engineering},\n pages = {173 - 182},\n title = {An explainable deep-learning algorithm for the detection of acute intracranial haemorrhage from small datasets},\n volume = {3},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6419cd260b314c22bad57053dfd48c09411490d3",
            "@type": "ScholarlyArticle",
            "paperId": "6419cd260b314c22bad57053dfd48c09411490d3",
            "corpusId": 53286887,
            "url": "https://www.semanticscholar.org/paper/6419cd260b314c22bad57053dfd48c09411490d3",
            "title": "Scene Text Detection and Recognition: The Deep Learning Era",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1811-04256",
                "MAG": "3082397598",
                "ArXiv": "1811.04256",
                "DOI": "10.1007/s11263-020-01369-0",
                "CorpusId": 53286887
            },
            "abstract": null,
            "referenceCount": 234,
            "citationCount": 303,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1811.04256",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-11-10",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "129"
            },
            "citationStyles": {
                "bibtex": "@Article{Long2018SceneTD,\n author = {Shangbang Long and Xin He and C. Yao},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {161 - 184},\n title = {Scene Text Detection and Recognition: The Deep Learning Era},\n volume = {129},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6edf7ed0e68bcf98ebcb600343c1e08f27c1c62f",
            "@type": "ScholarlyArticle",
            "paperId": "6edf7ed0e68bcf98ebcb600343c1e08f27c1c62f",
            "corpusId": 53016938,
            "url": "https://www.semanticscholar.org/paper/6edf7ed0e68bcf98ebcb600343c1e08f27c1c62f",
            "title": "Deep Learning for Encrypted Traffic Classification: An Overview",
            "venue": "IEEE Communications Magazine",
            "publicationVenue": {
                "id": "urn:research:a1b15bc8-157e-45a9-b4c8-8211f938775d",
                "name": "IEEE Communications Magazine",
                "alternate_names": [
                    "IEEE Commun Mag"
                ],
                "issn": "0163-6804",
                "url": "http://www.comsoc.org/commag"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1810.07906",
                "MAG": "2952806211",
                "DBLP": "journals/cm/RezaeiL19",
                "DOI": "10.1109/MCOM.2019.1800819",
                "CorpusId": 53016938
            },
            "abstract": "Traffic classification has been studied for two decades and applied to a wide range of applications from QoS provisioning and billing in ISPs to security-related applications in firewalls and intrusion detection systems. Port-based, data packet inspection, and classical machine learning methods have been used extensively in the past, but their accuracy has declined due to the dramatic changes in Internet traffic, particularly the increase in encrypted traffic. With the proliferation of deep learning methods, researchers have recently investigated these methods for traffic classification and reported high accuracy. In this article, we introduce a general framework for deep-learning-based traffic classification. We present commonly used deep learning methods and their application in traffic classification tasks. Then we discuss open problems, challenges, and opportunities for traffic classification.",
            "referenceCount": 20,
            "citationCount": 297,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1810.07906",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-10-18",
            "journal": {
                "name": "IEEE Communications Magazine",
                "volume": "57"
            },
            "citationStyles": {
                "bibtex": "@Article{Rezaei2018DeepLF,\n author = {Shahbaz Rezaei and Xin Liu},\n booktitle = {IEEE Communications Magazine},\n journal = {IEEE Communications Magazine},\n pages = {76-81},\n title = {Deep Learning for Encrypted Traffic Classification: An Overview},\n volume = {57},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:651644a5dbbe97cf69e4e64c0c6afb2b532c447d",
            "@type": "ScholarlyArticle",
            "paperId": "651644a5dbbe97cf69e4e64c0c6afb2b532c447d",
            "corpusId": 2880908,
            "url": "https://www.semanticscholar.org/paper/651644a5dbbe97cf69e4e64c0c6afb2b532c447d",
            "title": "Deep Learning for Hate Speech Detection in Tweets",
            "venue": "The Web Conference",
            "publicationVenue": {
                "id": "urn:research:e07422f9-c065-40c3-a37b-75e98dce79fe",
                "name": "The Web Conference",
                "alternate_names": [
                    "Web Conf",
                    "WWW"
                ],
                "issn": null,
                "url": "http://www.iw3c2.org/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2613977835",
                "DBLP": "conf/www/BadjatiyaG0V17",
                "ArXiv": "1706.00188",
                "DOI": "10.1145/3041021.3054223",
                "CorpusId": 2880908
            },
            "abstract": "Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging. We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity. Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by ~18 F1 points.",
            "referenceCount": 7,
            "citationCount": 942,
            "influentialCitationCount": 99,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1706.00188",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2017-04-03",
            "journal": {
                "name": "Proceedings of the 26th International Conference on World Wide Web Companion",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Badjatiya2017DeepLF,\n author = {Pinkesh Badjatiya and Shashank Gupta and Manish Gupta and Vasudeva Varma},\n booktitle = {The Web Conference},\n journal = {Proceedings of the 26th International Conference on World Wide Web Companion},\n title = {Deep Learning for Hate Speech Detection in Tweets},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4cdf4cbeed7f55953850410ebd9da8104033876e",
            "@type": "ScholarlyArticle",
            "paperId": "4cdf4cbeed7f55953850410ebd9da8104033876e",
            "corpusId": 38484207,
            "url": "https://www.semanticscholar.org/paper/4cdf4cbeed7f55953850410ebd9da8104033876e",
            "title": "Deep-learning tomography",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2776585113",
                "DOI": "10.1190/TLE37010058.1",
                "CorpusId": 38484207
            },
            "abstract": "Abstract Velocity-model building is a key step in hydrocarbon exploration. The main product of velocity-model building is an initial model of the subsurface that is subsequently used in seismic imaging and interpretation workflows. Reflection or refraction tomography and full-waveform inversion (FWI) are the most commonly used techniques in velocity-model building. On one hand, tomography is a time-consuming activity that relies on successive updates of highly human-curated analysis of gathers. On the other hand, FWI is very computationally demanding with no guarantees of global convergence. We propose and implement a novel concept that bypasses these demanding steps, directly producing an accurate gridding or layered velocity model from shot gathers. Our approach relies on training deep neural networks. The resulting predictive model maps relationships between the data space and the final output (particularly the presence of high-velocity segments that might indicate salt formations). The training task t...",
            "referenceCount": 34,
            "citationCount": 350,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Geology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Geophysics",
                "volume": "37"
            },
            "citationStyles": {
                "bibtex": "@Article{Araya-Polo2018DeeplearningT,\n author = {M. Araya-Polo and Joseph Jennings and A. Adler and T. Dahlke},\n journal = {Geophysics},\n pages = {58-66},\n title = {Deep-learning tomography},\n volume = {37},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:96285d5747916f4f0a1d8c4e402bba1468b079eb",
            "@type": "ScholarlyArticle",
            "paperId": "96285d5747916f4f0a1d8c4e402bba1468b079eb",
            "corpusId": 195833301,
            "url": "https://www.semanticscholar.org/paper/96285d5747916f4f0a1d8c4e402bba1468b079eb",
            "title": "Deep Learning in Ultrasound Imaging",
            "venue": "Proceedings of the IEEE",
            "publicationVenue": {
                "id": "urn:research:6faaccca-1cc4-45a9-aeb6-96a4901d2606",
                "name": "Proceedings of the IEEE",
                "alternate_names": [
                    "Proc IEEE"
                ],
                "issn": "0018-9219",
                "url": "http://www.ieee.org/portal/pages/pubs/proceedings/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2955895861",
                "DBLP": "journals/corr/abs-1907-02994",
                "ArXiv": "1907.02994",
                "DOI": "10.1109/JPROC.2019.2932116",
                "CorpusId": 195833301
            },
            "abstract": "In this article, we consider deep learning strategies in ultrasound systems, from the front end to advanced applications. Our goal is to provide the reader with a broad understanding of the possible impact of deep learning methodologies on many aspects of ultrasound imaging. In particular, we discuss methods that lie at the interface of signal acquisition and machine learning, exploiting both data structure (e.g., sparsity in some domain) and data dimensionality (big data) already at the raw radio-frequency channel stage. As some examples, we outline efficient and effective deep learning solutions for adaptive beamforming and adaptive spectral Doppler through artificial agents, learn compressive encodings for the color Doppler, and provide a framework for structured signal recovery by learning fast approximations of iterative minimization problems, with applications to clutter suppression and super-resolution ultrasound. These emerging technologies may have a considerable impact on ultrasound imaging, showing promise across key components in the receive processing chain.",
            "referenceCount": 147,
            "citationCount": 181,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1907.02994",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-07-05",
            "journal": {
                "name": "Proceedings of the IEEE",
                "volume": "108"
            },
            "citationStyles": {
                "bibtex": "@Article{Sloun2019DeepLI,\n author = {R. V. van Sloun and Regev Cohen and Yonina C. Eldar},\n booktitle = {Proceedings of the IEEE},\n journal = {Proceedings of the IEEE},\n pages = {11-29},\n title = {Deep Learning in Ultrasound Imaging},\n volume = {108},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c7d3d0ef7129dea47c5a1caa8f56791088a02408",
            "@type": "ScholarlyArticle",
            "paperId": "c7d3d0ef7129dea47c5a1caa8f56791088a02408",
            "corpusId": 201645479,
            "url": "https://www.semanticscholar.org/paper/c7d3d0ef7129dea47c5a1caa8f56791088a02408",
            "title": "Fairness in Deep Learning: A Computational Perspective",
            "venue": "IEEE Intelligent Systems",
            "publicationVenue": {
                "id": "urn:research:7404efea-88b2-4c7c-8cb1-b3a8ced6363f",
                "name": "IEEE Intelligent Systems",
                "alternate_names": [
                    "IEEE Intell Syst"
                ],
                "issn": "1541-1672",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=9670"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3035447285",
                "ArXiv": "1908.08843",
                "DBLP": "journals/expert/DuYZH21",
                "DOI": "10.1109/MIS.2020.3000681",
                "CorpusId": 201645479
            },
            "abstract": "Fairness in deep learning has attracted tremendous attention recently, as deep learning is increasingly being used in high-stake decision making applications that affect individual lives. We provide a review covering recent progresses to tackle algorithmic fairness problems of deep learning from the computational perspective. Specifically, we show that interpretability can serve as a useful ingredient to diagnose the reasons that lead to algorithmic discrimination. We also discuss fairness mitigation approaches categorized according to three stages of deep learning life-cycle, aiming to push forward the area of fairness in deep learning and build genuinely fair and reliable deep learning systems.",
            "referenceCount": 56,
            "citationCount": 157,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-08-23",
            "journal": {
                "name": "IEEE Intelligent Systems",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{Du2019FairnessID,\n author = {Mengnan Du and Fan Yang and Na Zou and Xia Hu},\n booktitle = {IEEE Intelligent Systems},\n journal = {IEEE Intelligent Systems},\n pages = {25-34},\n title = {Fairness in Deep Learning: A Computational Perspective},\n volume = {36},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0b313332dbfc4abfea6140d0be0b810808493cf5",
            "@type": "ScholarlyArticle",
            "paperId": "0b313332dbfc4abfea6140d0be0b810808493cf5",
            "corpusId": 135464251,
            "url": "https://www.semanticscholar.org/paper/0b313332dbfc4abfea6140d0be0b810808493cf5",
            "title": "Unsupervised Deep Learning by Neighbourhood Discovery",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2941964676",
                "ArXiv": "1904.11567",
                "DBLP": "conf/icml/HuangDGZ19",
                "CorpusId": 135464251
            },
            "abstract": "Deep convolutional neural networks (CNNs) have demonstrated remarkable success in computer vision by supervisedly learning strong visual feature representations. However, training CNNs relies heavily on the availability of exhaustive training data annotations, limiting significantly their deployment and scalability in many application scenarios. In this work, we introduce a generic unsupervised deep learning approach to training deep models without the need for any manual label supervision. Specifically, we progressively discover sample anchored/centred neighbourhoods to reason and learn the underlying class decision boundaries iteratively and accumulatively. Every single neighbourhood is specially formulated so that all the member samples can share the same unseen class labels at high probability for facilitating the extraction of class discriminative feature representations during training. Experiments on image classification show the performance advantages of the proposed method over the state-of-the-art unsupervised learning models on six benchmarks including both coarse-grained and fine-grained object image categorisation.",
            "referenceCount": 45,
            "citationCount": 126,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1904.11567"
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2019UnsupervisedDL,\n author = {Jiabo Huang and Qi Dong and S. Gong and Xiatian Zhu},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Unsupervised Deep Learning by Neighbourhood Discovery},\n volume = {abs/1904.11567},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:54378aef6ec3423ad44d61de61b301be9f5c686d",
            "@type": "ScholarlyArticle",
            "paperId": "54378aef6ec3423ad44d61de61b301be9f5c686d",
            "corpusId": 207111722,
            "url": "https://www.semanticscholar.org/paper/54378aef6ec3423ad44d61de61b301be9f5c686d",
            "title": "Deep learning for visual understanding: A review",
            "venue": "Neurocomputing",
            "publicationVenue": {
                "id": "urn:research:df12d289-f447-47d3-8846-75e39de3ab57",
                "name": "Neurocomputing",
                "alternate_names": null,
                "issn": "0925-2312",
                "url": "http://www.elsevier.com/locate/neucom"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2176950688",
                "DBLP": "journals/ijon/GuoLOLWL16",
                "DOI": "10.1016/j.neucom.2015.09.116",
                "CorpusId": 207111722
            },
            "abstract": null,
            "referenceCount": 219,
            "citationCount": 1740,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-04-26",
            "journal": {
                "name": "Neurocomputing",
                "volume": "187"
            },
            "citationStyles": {
                "bibtex": "@Article{Guo2016DeepLF,\n author = {Yanming Guo and Yu Liu and Ard A. J. Oerlemans and Songyang Lao and Song Wu and M. Lew},\n booktitle = {Neurocomputing},\n journal = {Neurocomputing},\n pages = {27-48},\n title = {Deep learning for visual understanding: A review},\n volume = {187},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b661520bf0061b7d96ccf12016e351dd3a6ee780",
            "@type": "ScholarlyArticle",
            "paperId": "b661520bf0061b7d96ccf12016e351dd3a6ee780",
            "corpusId": 83458523,
            "url": "https://www.semanticscholar.org/paper/b661520bf0061b7d96ccf12016e351dd3a6ee780",
            "title": "What is the Effect of Importance Weighting in Deep Learning?",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/icml/ByrdL19",
                "ArXiv": "1812.03372",
                "MAG": "2952421377",
                "CorpusId": 83458523
            },
            "abstract": "Importance-weighted risk minimization is a key ingredient in many machine learning algorithms for causal inference, domain adaptation, class imbalance, and off-policy reinforcement learning. While the effect of importance weighting is well-characterized for low-capacity misspecified models, little is known about how it impacts over-parameterized, deep neural networks. This work is inspired by recent theoretical results showing that on (linearly) separable data, deep linear networks optimized by SGD learn weight-agnostic solutions, prompting us to ask, for realistic deep networks, for which many practical datasets are separable, what is the effect of importance weighting? We present the surprising finding that while importance weighting impacts models early in training, its effect diminishes over successive epochs. Moreover, while L2 regularization and batch normalization (but not dropout), restore some of the impact of importance weighting, they express the effect via (seemingly) the wrong abstraction: why should practitioners tweak the L2 regularization, and by how much, to produce the correct weighting effect? Our experiments confirm these findings across a range of architectures and datasets.",
            "referenceCount": 38,
            "citationCount": 328,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-12-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Byrd2018WhatIT,\n author = {Jonathon Byrd and Zachary Chase Lipton},\n booktitle = {International Conference on Machine Learning},\n pages = {872-881},\n title = {What is the Effect of Importance Weighting in Deep Learning?},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:31c36d445367ba204244bb74893c5654e31c3869",
            "@type": "ScholarlyArticle",
            "paperId": "31c36d445367ba204244bb74893c5654e31c3869",
            "corpusId": 12330432,
            "url": "https://www.semanticscholar.org/paper/31c36d445367ba204244bb74893c5654e31c3869",
            "title": "cuDNN: Efficient Primitives for Deep Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1667652561",
                "ArXiv": "1410.0759",
                "DBLP": "journals/corr/ChetlurWVCTCS14",
                "CorpusId": 12330432
            },
            "abstract": "We present a library that provides optimized implementations for deep learning primitives. Deep learning workloads are computationally intensive, and optimizing the kernels of deep learning workloads is difficult and time-consuming. As parallel architectures evolve, kernels must be reoptimized for new processors, which makes maintaining codebases difficult over time. Similar issues have long been addressed in the HPC community by libraries such as the Basic Linear Algebra Subroutines (BLAS) [2]. However, there is no analogous library for deep learning. Without such a library, researchers implementing deep learning workloads on parallel processors must create and optimize their own implementations of the main computational kernels, and this work must be repeated as new parallel processors emerge. To address this problem, we have created a library similar in intent to BLAS, with optimized routines for deep learning workloads. Our implementation contains routines for GPUs, and similarly to the BLAS library, could be implemented for other platforms. The library is easy to integrate into existing frameworks, and provides optimized performance and memory usage. For example, integrating cuDNN into Caffe, a popular framework for convolutional networks, improves performance by 36% on a standard model while also reducing memory consumption.",
            "referenceCount": 20,
            "citationCount": 1662,
            "influentialCitationCount": 154,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-10-02",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1410.0759"
            },
            "citationStyles": {
                "bibtex": "@Article{Chetlur2014cuDNNEP,\n author = {Sharan Chetlur and Cliff Woolley and Philippe Vandermersch and Jonathan M. Cohen and J. Tran and Bryan Catanzaro and Evan Shelhamer},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {cuDNN: Efficient Primitives for Deep Learning},\n volume = {abs/1410.0759},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:44a97f4eaaefaf5338f8aed2913d5debb2459f7e",
            "@type": "ScholarlyArticle",
            "paperId": "44a97f4eaaefaf5338f8aed2913d5debb2459f7e",
            "corpusId": 5051282,
            "url": "https://www.semanticscholar.org/paper/44a97f4eaaefaf5338f8aed2913d5debb2459f7e",
            "title": "Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning",
            "venue": "Conference on Computer and Communications Security",
            "publicationVenue": {
                "id": "urn:research:73f7fe95-b68b-468f-b7ba-3013ca879e50",
                "name": "Conference on Computer and Communications Security",
                "alternate_names": [
                    "Int Workshop Cogn Cell Syst",
                    "CCS",
                    "Comput Commun Secur",
                    "CcS",
                    "International Symposium on Community-centric Systems",
                    "International Workshop on Cognitive Cellular Systems",
                    "Conf Comput Commun Secur",
                    "Comb Comput Sci",
                    "Int Symp Community-centric Syst",
                    "Combinatorics and Computer Science",
                    "Circuits, Signals, and Systems",
                    "Computer and Communications Security",
                    "Circuit Signal Syst"
                ],
                "issn": null,
                "url": "https://dl.acm.org/conference/ccs"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2951368041",
                "DBLP": "conf/ccs/HitajAP17",
                "ArXiv": "1702.07464",
                "DOI": "10.1145/3133956.3134012",
                "CorpusId": 5051282
            },
            "abstract": "Deep Learning has recently become hugely popular in machine learning for its ability to solve end-to-end learning systems, in which the features and the classifiers are learned simultaneously, providing significant improvements in classification accuracy in the presence of highly-structured and large databases. Its success is due to a combination of recent algorithmic breakthroughs, increasingly powerful computers, and access to significant amounts of data. Researchers have also considered privacy implications of deep learning. Models are typically trained in a centralized manner with all the data being processed by the same training algorithm. If the data is a collection of users' private data, including habits, personal pictures, geographical positions, interests, and more, the centralized server will have access to sensitive information that could potentially be mishandled. To tackle this problem, collaborative deep learning models have recently been proposed where parties locally train their deep learning structures and only share a subset of the parameters in the attempt to keep their respective training sets private. Parameters can also be obfuscated via differential privacy (DP) to make information extraction even more challenging, as proposed by Shokri and Shmatikov at CCS'15. Unfortunately, we show that any privacy-preserving collaborative deep learning is susceptible to a powerful attack that we devise in this paper. In particular, we show that a distributed, federated, or decentralized deep learning approach is fundamentally broken and does not protect the training sets of honest participants. The attack we developed exploits the real-time nature of the learning process that allows the adversary to train a Generative Adversarial Network (GAN) that generates prototypical samples of the targeted training set that was meant to be private (the samples generated by the GAN are intended to come from the same distribution as the training data). Interestingly, we show that record-level differential privacy applied to the shared parameters of the model, as suggested in previous work, is ineffective (i.e., record-level DP is not designed to address our attack).",
            "referenceCount": 103,
            "citationCount": 1036,
            "influentialCitationCount": 87,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://acmccs.github.io/papers/p603-hitajA.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-02-24",
            "journal": {
                "name": "Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Hitaj2017DeepMU,\n author = {B. Hitaj and G. Ateniese and F. P\u00e9rez-Cruz},\n booktitle = {Conference on Computer and Communications Security},\n journal = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},\n title = {Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:05cf03b87ae2f680778e6f5e29f7f7af42253a42",
            "@type": "ScholarlyArticle",
            "paperId": "05cf03b87ae2f680778e6f5e29f7f7af42253a42",
            "corpusId": 52128218,
            "url": "https://www.semanticscholar.org/paper/05cf03b87ae2f680778e6f5e29f7f7af42253a42",
            "title": "A review on deep learning for recommender systems: challenges and remedies",
            "venue": "Artificial Intelligence Review",
            "publicationVenue": {
                "id": "urn:research:ea8553fe-2467-4367-afee-c4deb3754820",
                "name": "Artificial Intelligence Review",
                "alternate_names": [
                    "Artif Intell Rev"
                ],
                "issn": "0269-2821",
                "url": "https://link.springer.com/journal/10462"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2889526258",
                "DBLP": "journals/air/BatmazYBK19",
                "DOI": "10.1007/s10462-018-9654-y",
                "CorpusId": 52128218
            },
            "abstract": null,
            "referenceCount": 129,
            "citationCount": 296,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-08-29",
            "journal": {
                "name": "Artificial Intelligence Review",
                "volume": "52"
            },
            "citationStyles": {
                "bibtex": "@Article{Batmaz2018ARO,\n author = {Zeynep Batmaz and Ali Yurekli and Alper Bilge and C. Kaleli},\n booktitle = {Artificial Intelligence Review},\n journal = {Artificial Intelligence Review},\n pages = {1-37},\n title = {A review on deep learning for recommender systems: challenges and remedies},\n volume = {52},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0ef9ae1ce8c91ce671a211bdda792bf3752d1522",
            "@type": "ScholarlyArticle",
            "paperId": "0ef9ae1ce8c91ce671a211bdda792bf3752d1522",
            "corpusId": 1946600,
            "url": "https://www.semanticscholar.org/paper/0ef9ae1ce8c91ce671a211bdda792bf3752d1522",
            "title": "A Deep Learning Approach for Intrusion Detection Using Recurrent Neural Networks",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2762776925",
                "DBLP": "journals/access/YinZFH17",
                "DOI": "10.1109/ACCESS.2017.2762418",
                "CorpusId": 1946600
            },
            "abstract": "Intrusion detection plays an important role in ensuring information security, and the key technology is to accurately identify various attacks in the network. In this paper, we explore how to model an intrusion detection system based on deep learning, and we propose a deep learning approach for intrusion detection using recurrent neural networks (RNN-IDS). Moreover, we study the performance of the model in binary classification and multiclass classification, and the number of neurons and different learning rate impacts on the performance of the proposed model. We compare it with those of J48, artificial neural network, random forest, support vector machine, and other machine learning methods proposed by previous researchers on the benchmark data set. The experimental results show that RNN-IDS is very suitable for modeling a classification model with high accuracy and that its performance is superior to that of traditional machine learning classification methods in both binary and multiclass classification. The RNN-IDS model improves the accuracy of the intrusion detection and provides a new research method for intrusion detection.",
            "referenceCount": 27,
            "citationCount": 1098,
            "influentialCitationCount": 84,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-12",
            "journal": {
                "name": "IEEE Access",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Yin2017ADL,\n author = {Chuanlong Yin and Yuefei Zhu and Jin-long Fei and Xin-Zheng He},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {21954-21961},\n title = {A Deep Learning Approach for Intrusion Detection Using Recurrent Neural Networks},\n volume = {5},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1a13bec308614ed56b9af2532a3d5e4cd8e2af94",
            "@type": "ScholarlyArticle",
            "paperId": "1a13bec308614ed56b9af2532a3d5e4cd8e2af94",
            "corpusId": 5039751,
            "url": "https://www.semanticscholar.org/paper/1a13bec308614ed56b9af2532a3d5e4cd8e2af94",
            "title": "Deep Learning in Spiking Neural Networks",
            "venue": "Neural Networks",
            "publicationVenue": {
                "id": "urn:research:a13f3cb8-2492-4ccb-9329-73a5ddcaab9b",
                "name": "Neural Networks",
                "alternate_names": [
                    "Neural Netw"
                ],
                "issn": "0893-6080",
                "url": "http://www.elsevier.com/locate/neunet"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2798878556",
                "DBLP": "journals/nn/TavanaeiGKMM19",
                "ArXiv": "1804.08150",
                "DOI": "10.1016/j.neunet.2018.12.002",
                "CorpusId": 5039751,
                "PubMed": "30682710"
            },
            "abstract": null,
            "referenceCount": 258,
            "citationCount": 734,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1804.08150",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-04-22",
            "journal": {
                "name": "Neural networks : the official journal of the International Neural Network Society",
                "volume": "111"
            },
            "citationStyles": {
                "bibtex": "@Article{Tavanaei2018DeepLI,\n author = {A. Tavanaei and M. Ghodrati and S. R. Kheradpisheh and T. Masquelier and A. Maida},\n booktitle = {Neural Networks},\n journal = {Neural networks : the official journal of the International Neural Network Society},\n pages = {\n          47-63\n        },\n title = {Deep Learning in Spiking Neural Networks},\n volume = {111},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:983dda1eac92afd1fa6234a713ae07a6008b4534",
            "@type": "ScholarlyArticle",
            "paperId": "983dda1eac92afd1fa6234a713ae07a6008b4534",
            "corpusId": 125145546,
            "url": "https://www.semanticscholar.org/paper/983dda1eac92afd1fa6234a713ae07a6008b4534",
            "title": "A review on the application of deep learning in system health management",
            "venue": "Mechanical systems and signal processing",
            "publicationVenue": {
                "id": "urn:research:dc4b3846-1e31-4c19-a196-e8b1d091037f",
                "name": "Mechanical systems and signal processing",
                "alternate_names": [
                    "Mech syst signal process",
                    "Mech Syst Signal Process",
                    "Mechanical Systems and Signal Processing"
                ],
                "issn": "0888-3270",
                "url": "https://www.journals.elsevier.com/mechanical-systems-and-signal-processing"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2793062918",
                "DOI": "10.1016/J.YMSSP.2017.11.024",
                "CorpusId": 125145546
            },
            "abstract": null,
            "referenceCount": 74,
            "citationCount": 727,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2018-07-01",
            "journal": {
                "name": "Mechanical Systems and Signal Processing",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Khan2018ARO,\n author = {Samir Khan and T. Yairi},\n booktitle = {Mechanical systems and signal processing},\n journal = {Mechanical Systems and Signal Processing},\n title = {A review on the application of deep learning in system health management},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f80963348e6c04458a0e9d3824b2c2bb6641c0ad",
            "@type": "ScholarlyArticle",
            "paperId": "f80963348e6c04458a0e9d3824b2c2bb6641c0ad",
            "corpusId": 57574065,
            "url": "https://www.semanticscholar.org/paper/f80963348e6c04458a0e9d3824b2c2bb6641c0ad",
            "title": "A call for deep-learning healthcare",
            "venue": "Nature Network Boston",
            "publicationVenue": {
                "id": "urn:research:9e995b6d-f30b-4ab4-a13b-3dc2cc992f47",
                "name": "Nature Network Boston",
                "alternate_names": [
                    "Nat Netw Boston",
                    "Nat Med",
                    "Nature Medicine"
                ],
                "issn": "1744-7933",
                "url": "https://www.nature.com/nature/articles?code=archive_news"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2906311950",
                "DOI": "10.1038/s41591-018-0320-3",
                "CorpusId": 57574065,
                "PubMed": "30617337"
            },
            "abstract": null,
            "referenceCount": 2,
            "citationCount": 151,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-01-01",
            "journal": {
                "name": "Nature Medicine",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{Norgeot2019ACF,\n author = {Beau Norgeot and B. Glicksberg and A. Butte},\n booktitle = {Nature Network Boston},\n journal = {Nature Medicine},\n pages = {14-15},\n title = {A call for deep-learning healthcare},\n volume = {25},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b7919fadb4c1bf959b1e410463594afacfda7dc6",
            "@type": "ScholarlyArticle",
            "paperId": "b7919fadb4c1bf959b1e410463594afacfda7dc6",
            "corpusId": 3269862,
            "url": "https://www.semanticscholar.org/paper/b7919fadb4c1bf959b1e410463594afacfda7dc6",
            "title": "A survey on deep learning for big data",
            "venue": "Information Fusion",
            "publicationVenue": {
                "id": "urn:research:06afdd0b-0d85-413f-af8a-c3045c12c561",
                "name": "Information Fusion",
                "alternate_names": [
                    "Inf Fusion"
                ],
                "issn": "1566-2535",
                "url": "https://www.journals.elsevier.com/information-fusion"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/inffus/ZhangYCL18a",
                "MAG": "2767547957",
                "DOI": "10.1016/j.inffus.2017.10.006",
                "CorpusId": 3269862
            },
            "abstract": null,
            "referenceCount": 102,
            "citationCount": 557,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-07-01",
            "journal": {
                "name": "Inf. Fusion",
                "volume": "42"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018ASO,\n author = {Qingchen Zhang and L. Yang and Zhikui Chen and Peng Li},\n booktitle = {Information Fusion},\n journal = {Inf. Fusion},\n pages = {146-157},\n title = {A survey on deep learning for big data},\n volume = {42},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4af05d0b97513e19174b759c5039b115e7ff0d4c",
            "@type": "ScholarlyArticle",
            "paperId": "4af05d0b97513e19174b759c5039b115e7ff0d4c",
            "corpusId": 135466220,
            "url": "https://www.semanticscholar.org/paper/4af05d0b97513e19174b759c5039b115e7ff0d4c",
            "title": "Bayesian Generative Active Deep Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2951433186",
                "DBLP": "journals/corr/abs-1904-11643",
                "ArXiv": "1904.11643",
                "CorpusId": 135466220
            },
            "abstract": "\u00a9 36th International Conference on Machine Learning, ICML 2019. All rights reserved. Deep learning models have demonstrated outstanding performance in several problems, but their training process tends to require immense amounts of computational and human resources for training and labeling, constraining the types of problems that can be tackled. Therefore, the design of effective training methods that require small labeled training sets is an important research direction that will allow a more effective use of resources. Among current approaches designed to address this issue, two are particularly interesting: data augmentation and active learning. Data augmentation achieves this goal by artificially generating new training points, while active learning relies on the selection of the \"most informative\" subset of unlabeled training samples to be labelled by an oracle. Although successful in practice, data augmentation can waste computational resources because it indiscriminately generates samples that are not guaranteed to be informative, and active learning selects a small subset of informative samples (from a large un-annotated set) that may be insufficient for the training process. In this paper, we propose a Bayesian generative active deep learning approach that combines active learning with data augmentation - we provide theoretical and empirical evidence (MNIST, CIFAR-{10,100}, and SVHN) that our approach has more efficient training and better classification results than data augmentation and active learning.",
            "referenceCount": 37,
            "citationCount": 95,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-26",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tran2019BayesianGA,\n author = {Toan Tran and Thanh-Toan Do and I. Reid and G. Carneiro},\n booktitle = {International Conference on Machine Learning},\n pages = {6295-6304},\n title = {Bayesian Generative Active Deep Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e9126a98de0c39dcffe4c4f5158e037460196724",
            "@type": "ScholarlyArticle",
            "paperId": "e9126a98de0c39dcffe4c4f5158e037460196724",
            "corpusId": 4897444,
            "url": "https://www.semanticscholar.org/paper/e9126a98de0c39dcffe4c4f5158e037460196724",
            "title": "SchNet - A deep learning architecture for molecules and materials.",
            "venue": "Journal of Chemical Physics",
            "publicationVenue": {
                "id": "urn:research:1bb63b2b-3f57-4387-aaf6-b2a33dfcdcc5",
                "name": "Journal of Chemical Physics",
                "alternate_names": [
                    "J Chem Phys"
                ],
                "issn": "0021-9606",
                "url": "http://jcp.aip.org/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2778051509",
                "ArXiv": "1712.06113",
                "DOI": "10.1063/1.5019779",
                "CorpusId": 4897444,
                "PubMed": "29960322"
            },
            "abstract": "Deep learning has led to a paradigm shift in artificial intelligence, including web, text, and image search, speech recognition, as well as bioinformatics, with growing impact in chemical physics. Machine learning, in general, and deep learning, in particular, are ideally suitable for representing quantum-mechanical interactions, enabling us to model nonlinear potential-energy surfaces or enhancing the exploration of chemical compound space. Here we present the deep learning architecture SchNet that is specifically designed to model atomistic systems by making use of continuous-filter convolutional layers. We demonstrate the capabilities of SchNet by accurately predicting a range of properties across chemical space for molecules and materials, where our model learns chemically plausible embeddings of atom types across the periodic table. Finally, we employ SchNet to predict potential-energy surfaces and energy-conserving force fields for molecular dynamics simulations of small molecules and perform an exemplary study on the quantum-mechanical properties of C20-fullerene that would have been infeasible with regular ab initio molecular dynamics.",
            "referenceCount": 48,
            "citationCount": 1161,
            "influentialCitationCount": 74,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://orbilu.uni.lu/bitstream/10993/35404/1/122-SchNet-JCP-2018.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Physics",
                "Computer Science",
                "Chemistry",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-12-17",
            "journal": {
                "name": "The Journal of chemical physics",
                "volume": "148 24"
            },
            "citationStyles": {
                "bibtex": "@Article{Sch\u00fctt2017SchNetA,\n author = {Kristof T. Sch\u00fctt and H. E. Sauceda and P. Kindermans and A. Tkatchenko and K. M\u00fcller},\n booktitle = {Journal of Chemical Physics},\n journal = {The Journal of chemical physics},\n pages = {\n          241722\n        },\n title = {SchNet - A deep learning architecture for molecules and materials.},\n volume = {148 24},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca1a5064de08a56e6dcbf72c58600c98a62a6059",
            "@type": "ScholarlyArticle",
            "paperId": "ca1a5064de08a56e6dcbf72c58600c98a62a6059",
            "corpusId": 4428382,
            "url": "https://www.semanticscholar.org/paper/ca1a5064de08a56e6dcbf72c58600c98a62a6059",
            "title": "Reconstructing cell cycle and disease progression using deep learning",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2750796620",
                "PubMedCentral": "5587733",
                "DOI": "10.1038/s41467-017-00623-3",
                "CorpusId": 4428382,
                "PubMed": "28878212"
            },
            "abstract": null,
            "referenceCount": 32,
            "citationCount": 1086,
            "influentialCitationCount": 76,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.biorxiv.org/content/biorxiv/early/2017/06/05/081364.full.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Biology",
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-06-05",
            "journal": {
                "name": "Nature Communications",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Eulenberg2017ReconstructingCC,\n author = {P. Eulenberg and Niklas D. Koehler and T. Blasi and A. Filby and Anne E Carpenter and Paul Rees and Paul Rees and Fabian J Theis and F. A. Wolf},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {Reconstructing cell cycle and disease progression using deep learning},\n volume = {8},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:21d08abf967d6ce56f72f96d8e87b2288f53a4ed",
            "@type": "ScholarlyArticle",
            "paperId": "21d08abf967d6ce56f72f96d8e87b2288f53a4ed",
            "corpusId": 2988078,
            "url": "https://www.semanticscholar.org/paper/21d08abf967d6ce56f72f96d8e87b2288f53a4ed",
            "title": "The Deep Ritz Method: A Deep Learning-Based Numerical Algorithm for Solving Variational Problems",
            "venue": "Communications in Mathematics and Statistics",
            "publicationVenue": {
                "id": "urn:research:f2ccdde5-01ea-4801-8a2d-35d9889dac47",
                "name": "Communications in Mathematics and Statistics",
                "alternate_names": [
                    "Commun Math Stat"
                ],
                "issn": "2194-671X",
                "url": "https://link.springer.com/journal/40304"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/abs-1710-00211",
                "MAG": "2760972773",
                "ArXiv": "1710.00211",
                "DOI": "10.1007/s40304-018-0127-z",
                "CorpusId": 2988078
            },
            "abstract": null,
            "referenceCount": 16,
            "citationCount": 867,
            "influentialCitationCount": 81,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/1710.00211",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-09-30",
            "journal": {
                "name": "Communications in Mathematics and Statistics",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Weinan2017TheDR,\n author = {E. Weinan and Ting Yu},\n booktitle = {Communications in Mathematics and Statistics},\n journal = {Communications in Mathematics and Statistics},\n pages = {1 - 12},\n title = {The Deep Ritz Method: A Deep Learning-Based Numerical Algorithm for Solving Variational Problems},\n volume = {6},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a326d9f2d2d351001fece788165dbcbb524da2e4",
            "@type": "ScholarlyArticle",
            "paperId": "a326d9f2d2d351001fece788165dbcbb524da2e4",
            "corpusId": 215827910,
            "url": "https://www.semanticscholar.org/paper/a326d9f2d2d351001fece788165dbcbb524da2e4",
            "title": "D4RL: Datasets for Deep Data-Driven Reinforcement Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3016525976",
                "ArXiv": "2004.07219",
                "DBLP": "journals/corr/abs-2004-07219",
                "CorpusId": 215827910
            },
            "abstract": "The offline reinforcement learning (RL) problem, also known as batch RL, refers to the setting where a policy must be learned from a static dataset, without additional online data collection. This setting is compelling as potentially it allows RL methods to take advantage of large, pre-collected datasets, much like how the rise of large datasets has fueled results in supervised learning in recent years. However, existing online RL benchmarks are not tailored towards the offline setting, making progress in offline RL difficult to measure. In this work, we introduce benchmarks specifically designed for the offline setting, guided by key properties of datasets relevant to real-world applications of offline RL. Examples of such properties include: datasets generated via hand-designed controllers and human demonstrators, multi-objective datasets where an agent can perform different tasks in the same environment, and datasets consisting of a mixtures of policies. To facilitate research, we release our benchmark tasks and datasets with a comprehensive evaluation of existing algorithms and an evaluation protocol together with an open-source codebase. We hope that our benchmark will focus research effort on methods that drive improvements not just on simulated tasks, but ultimately on the kinds of real-world problems where offline RL will have the largest impact.",
            "referenceCount": 41,
            "citationCount": 753,
            "influentialCitationCount": 275,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-04-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2004.07219"
            },
            "citationStyles": {
                "bibtex": "@Article{Fu2020D4RLDF,\n author = {Justin Fu and Aviral Kumar and Ofir Nachum and G. Tucker and S. Levine},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {D4RL: Datasets for Deep Data-Driven Reinforcement Learning},\n volume = {abs/2004.07219},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d63b884d5ebc739f6e1bdf861fa9276260781404",
            "@type": "ScholarlyArticle",
            "paperId": "d63b884d5ebc739f6e1bdf861fa9276260781404",
            "corpusId": 9461213,
            "url": "https://www.semanticscholar.org/paper/d63b884d5ebc739f6e1bdf861fa9276260781404",
            "title": "Deep Learning for IoT Big Data and Streaming Analytics: A Survey",
            "venue": "IEEE Communications Surveys and Tutorials",
            "publicationVenue": {
                "id": "urn:research:95d0dda7-5d58-4afd-b59f-315447b81992",
                "name": "IEEE Communications Surveys and Tutorials",
                "alternate_names": [
                    "IEEE Commun Surv Tutor"
                ],
                "issn": "1553-877X",
                "url": "http://www.comsoc.org/cst"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/comsur/MohammadiASG18",
                "MAG": "2950502220",
                "ArXiv": "1712.04301",
                "DOI": "10.1109/COMST.2018.2844341",
                "CorpusId": 9461213
            },
            "abstract": "In the era of the Internet of Things (IoT), an enormous amount of sensing devices collect and/or generate various sensory data over time for a wide range of fields and applications. Based on the nature of the application, these devices will result in big or fast/real-time data streams. Applying analytics over such data streams to discover new information, predict future insights, and make control decisions is a crucial process that makes IoT a worthy paradigm for businesses and a quality-of-life improving technology. In this paper, we provide a thorough overview on using a class of advanced machine learning techniques, namely deep learning (DL), to facilitate the analytics and learning in the IoT domain. We start by articulating IoT data characteristics and identifying two major treatments for IoT data from a machine learning perspective, namely IoT big data analytics and IoT streaming data analytics. We also discuss why DL is a promising approach to achieve the desired analytics in these types of data and applications. The potential of using emerging DL techniques for IoT data analytics are then discussed, and its promises and challenges are introduced. We present a comprehensive background on different DL architectures and algorithms. We also analyze and summarize major reported research attempts that leveraged DL in the IoT domain. The smart IoT devices that have incorporated DL in their intelligence background are also discussed. DL implementation approaches on the fog and cloud centers in support of IoT applications are also surveyed. Finally, we shed light on some challenges and potential directions for future research. At the end of each section, we highlight the lessons learned based on our experiments and review of the recent literature.",
            "referenceCount": 228,
            "citationCount": 905,
            "influentialCitationCount": 51,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1712.04301",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-12-09",
            "journal": {
                "name": "IEEE Communications Surveys & Tutorials",
                "volume": "20"
            },
            "citationStyles": {
                "bibtex": "@Article{Mohammadi2017DeepLF,\n author = {M. Mohammadi and A. Al-Fuqaha and Sameh Sorour and M. Guizani},\n booktitle = {IEEE Communications Surveys and Tutorials},\n journal = {IEEE Communications Surveys & Tutorials},\n pages = {2923-2960},\n title = {Deep Learning for IoT Big Data and Streaming Analytics: A Survey},\n volume = {20},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cc384cff27d8a609f89f9e915c26bf31c39749a1",
            "@type": "ScholarlyArticle",
            "paperId": "cc384cff27d8a609f89f9e915c26bf31c39749a1",
            "corpusId": 2958085,
            "url": "https://www.semanticscholar.org/paper/cc384cff27d8a609f89f9e915c26bf31c39749a1",
            "title": "Deep learning in bioinformatics",
            "venue": "Briefings Bioinform.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/MinLY16",
                "ArXiv": "1603.06430",
                "MAG": "2951055789",
                "DOI": "10.1093/bib/bbw068",
                "CorpusId": 2958085,
                "PubMed": "27473064"
            },
            "abstract": "In the era of big data, transformation of biomedical big data into valuable knowledge has been one of the most important challenges in bioinformatics. Deep learning has advanced rapidly since the early 2000s and now demonstrates state-of-the-art performance in various fields. Accordingly, application of deep learning in bioinformatics to gain insight from data has been emphasized in both academia and industry. Here, we review deep learning in bioinformatics, presenting examples of current research. To provide a useful and comprehensive perspective, we categorize research both by the bioinformatics domain (i.e. omics, biomedical imaging, biomedical signal processing) and deep learning architecture (i.e. deep neural networks, convolutional neural networks, recurrent neural networks, emergent architectures) and present brief descriptions of each study. Additionally, we discuss theoretical and practical issues of deep learning in bioinformatics and suggest future research directions. We believe that this review will provide valuable insights and serve as a starting point for researchers to apply deep learning approaches in their bioinformatics studies.",
            "referenceCount": 277,
            "citationCount": 1186,
            "influentialCitationCount": 37,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1603.06430",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Biology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2016-03-21",
            "journal": {
                "name": "Briefings in Bioinformatics",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Min2016DeepLI,\n author = {Seonwoo Min and Byunghan Lee and Sungroh Yoon},\n booktitle = {Briefings Bioinform.},\n journal = {Briefings in Bioinformatics},\n pages = {851\u2013869},\n title = {Deep learning in bioinformatics},\n volume = {18},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c0f17f99c44807762f2a386ac6579c364330e082",
            "@type": "ScholarlyArticle",
            "paperId": "c0f17f99c44807762f2a386ac6579c364330e082",
            "corpusId": 8574504,
            "url": "https://www.semanticscholar.org/paper/c0f17f99c44807762f2a386ac6579c364330e082",
            "title": "A Review on Deep Learning Techniques Applied to Semantic Segmentation",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/Garcia-GarciaOO17",
                "ArXiv": "1704.06857",
                "MAG": "2609077090",
                "CorpusId": 8574504
            },
            "abstract": "Image semantic segmentation is more and more being of interest for computer vision and machine learning researchers. Many applications on the rise need accurate and efficient segmentation mechanisms: autonomous driving, indoor navigation, and even virtual or augmented reality systems to name a few. This demand coincides with the rise of deep learning approaches in almost every field or application target related to computer vision, including semantic segmentation or scene understanding. This paper provides a review on deep learning methods for semantic segmentation applied to various application areas. Firstly, we describe the terminology of this field as well as mandatory background concepts. Next, the main datasets and challenges are exposed to help researchers decide which are the ones that best suit their needs and their targets. Then, existing methods are reviewed, highlighting their contributions and their significance in the field. Finally, quantitative results are given for the described methods and the datasets in which they were evaluated, following up with a discussion of the results. At last, we point out a set of promising future works and draw our own conclusions about the state of the art of semantic segmentation using deep learning techniques.",
            "referenceCount": 116,
            "citationCount": 1090,
            "influentialCitationCount": 49,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-04-22",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1704.06857"
            },
            "citationStyles": {
                "bibtex": "@Article{Garcia-Garcia2017ARO,\n author = {Alberto Garcia-Garcia and Sergio Orts and Sergiu Oprea and Victor Villena-Martinez and J. G. Rodr\u00edguez},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A Review on Deep Learning Techniques Applied to Semantic Segmentation},\n volume = {abs/1704.06857},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ae523e2f137fa2a4f5a6cbcc443ba63db2642a96",
            "@type": "ScholarlyArticle",
            "paperId": "ae523e2f137fa2a4f5a6cbcc443ba63db2642a96",
            "corpusId": 206603045,
            "url": "https://www.semanticscholar.org/paper/ae523e2f137fa2a4f5a6cbcc443ba63db2642a96",
            "title": "Supervised Speech Separation Based on Deep Learning: An Overview",
            "venue": "IEEE/ACM Transactions on Audio Speech and Language Processing",
            "publicationVenue": {
                "id": "urn:research:309e00f7-4bbd-461f-ab37-a90cd14ef21d",
                "name": "IEEE/ACM Transactions on Audio Speech and Language Processing",
                "alternate_names": [
                    "IEEE/ACM Trans Audio Speech Lang Process"
                ],
                "issn": "2329-9290",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=6570655"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2949318493",
                "DBLP": "journals/taslp/WangC18a",
                "ArXiv": "1708.07524",
                "DOI": "10.1109/TASLP.2018.2842159",
                "CorpusId": 206603045,
                "PubMed": "31223631"
            },
            "abstract": "Speech separation is the task of separating target speech from background interference. Traditionally, speech separation is studied as a signal processing problem. A more recent approach formulates speech separation as a supervised learning problem, where the discriminative patterns of speech, speakers, and background noise are learned from training data. Over the past decade, many supervised separation algorithms have been put forward. In particular, the recent introduction of deep learning to supervised speech separation has dramatically accelerated progress and boosted separation performance. This paper provides a comprehensive overview of the research on deep learning based supervised speech separation in the last several years. We first introduce the background of speech separation and the formulation of supervised separation. Then, we discuss three main components of supervised separation: learning machines, training targets, and acoustic features. Much of the overview is on separation algorithms where we review monaural methods, including speech enhancement (speech-nonspeech separation), speaker separation (multitalker separation), and speech dereverberation, as well as multimicrophone techniques. The important issue of generalization, unique to supervised learning, is discussed. This overview provides a historical perspective on how advances are made. In addition, we discuss a number of conceptual issues, including what constitutes the target source.",
            "referenceCount": 211,
            "citationCount": 1109,
            "influentialCitationCount": 47,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-08-24",
            "journal": {
                "name": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
                "volume": "26"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2017SupervisedSS,\n author = {Deliang Wang and Jitong Chen},\n booktitle = {IEEE/ACM Transactions on Audio Speech and Language Processing},\n journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},\n pages = {1702-1726},\n title = {Supervised Speech Separation Based on Deep Learning: An Overview},\n volume = {26},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1a0365567850837931d04126714ae6e2cbfc6270",
            "@type": "ScholarlyArticle",
            "paperId": "1a0365567850837931d04126714ae6e2cbfc6270",
            "corpusId": 1009397,
            "url": "https://www.semanticscholar.org/paper/1a0365567850837931d04126714ae6e2cbfc6270",
            "title": "Deep Learning for Extreme Multi-label Text Classification",
            "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
            "publicationVenue": {
                "id": "urn:research:8dce23a9-44e0-4381-a39e-2acc1edff700",
                "name": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
                "alternate_names": [
                    "International ACM SIGIR Conference on Research and Development in Information Retrieval",
                    "Int ACM SIGIR Conf Res Dev Inf Retr",
                    "SIGIR",
                    "Annu Int ACM SIGIR Conf Res Dev Inf Retr"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigir/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/sigir/LiuCWY17",
                "MAG": "2739996966",
                "DOI": "10.1145/3077136.3080834",
                "CorpusId": 1009397
            },
            "abstract": "Extreme multi-label text classification (XMTC) refers to the problem of assigning to each document its most relevant subset of class labels from an extremely large label collection, where the number of labels could reach hundreds of thousands or millions. The huge label space raises research challenges such as data sparsity and scalability. Significant progress has been made in recent years by the development of new machine learning methods, such as tree induction with large-margin partitions of the instance spaces and label-vector embedding in the target space. However, deep learning has not been explored for XMTC, despite its big successes in other related areas. This paper presents the first attempt at applying deep learning to XMTC, with a family of new Convolutional Neural Network (CNN) models which are tailored for multi-label classification in particular. With a comparative evaluation of 7 state-of-the-art methods on 6 benchmark datasets where the number of labels is up to 670,000, we show that the proposed CNN approach successfully scaled to the largest datasets, and consistently produced the best or the second best results on all the datasets. On the Wikipedia dataset with over 2 million documents and 500,000 labels in particular, it outperformed the second best method by 11.7%~15.3% in precision@K and by 11.5%~11.7% in NDCG@K for K = 1,3,5.",
            "referenceCount": 53,
            "citationCount": 523,
            "influentialCitationCount": 89,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2017-08-07",
            "journal": {
                "name": "Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2017DeepLF,\n author = {Jingzhou Liu and Wei-Cheng Chang and Yuexin Wu and Yiming Yang},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n title = {Deep Learning for Extreme Multi-label Text Classification},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:66e9dc728b5041271bff0cd6ac0d7eadcd88442f",
            "@type": "ScholarlyArticle",
            "paperId": "66e9dc728b5041271bff0cd6ac0d7eadcd88442f",
            "corpusId": 6593498,
            "url": "https://www.semanticscholar.org/paper/66e9dc728b5041271bff0cd6ac0d7eadcd88442f",
            "title": "Image Super-Resolution Using Deep Convolutional Networks",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/pami/DongLHT16",
                "MAG": "2949064199",
                "ArXiv": "1501.00092",
                "DOI": "10.1109/TPAMI.2015.2439281",
                "CorpusId": 6593498,
                "PubMed": "26761735"
            },
            "abstract": "We propose a deep learning method for single image super-resolution (SR). Our method directly learns an end-to-end mapping between the low/high-resolution images. The mapping is represented as a deep convolutional neural network (CNN) that takes the low-resolution image as the input and outputs the high-resolution one. We further show that traditional sparse-coding-based SR methods can also be viewed as a deep convolutional network. But unlike traditional methods that handle each component separately, our method jointly optimizes all layers. Our deep CNN has a lightweight structure, yet demonstrates state-of-the-art restoration quality, and achieves fast speed for practical on-line usage. We explore different network structures and parameter settings to achieve trade-offs between performance and speed. Moreover, we extend our network to cope with three color channels simultaneously, and show better overall reconstruction quality.",
            "referenceCount": 64,
            "citationCount": 6493,
            "influentialCitationCount": 1040,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1501.00092",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-12-31",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "38"
            },
            "citationStyles": {
                "bibtex": "@Article{Dong2014ImageSU,\n author = {Chao Dong and Chen Change Loy and Kaiming He and Xiaoou Tang},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {295-307},\n title = {Image Super-Resolution Using Deep Convolutional Networks},\n volume = {38},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e7f6fd860c157b4b1908e68b778c782ba721e889",
            "@type": "ScholarlyArticle",
            "paperId": "e7f6fd860c157b4b1908e68b778c782ba721e889",
            "corpusId": 51886568,
            "url": "https://www.semanticscholar.org/paper/e7f6fd860c157b4b1908e68b778c782ba721e889",
            "title": "Deep Learning in Physical Layer Communications",
            "venue": "IEEE wireless communications",
            "publicationVenue": {
                "id": "urn:research:2e8c30d0-78f6-4b13-aecb-9a65bff00635",
                "name": "IEEE wireless communications",
                "alternate_names": [
                    "IEEE Wirel Commun",
                    "IEEE Wireless Communications",
                    "IEEE wirel commun"
                ],
                "issn": "1536-1284",
                "url": "http://www.comsoc.org/wirelessmag/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1807-11713",
                "MAG": "2951937695",
                "ArXiv": "1807.11713",
                "DOI": "10.1109/MWC.2019.1800601",
                "CorpusId": 51886568
            },
            "abstract": "DL has shown great potential to revolutionize communication systems. This article provides an overview of the recent advancements in DL-based physical layer communications. DL can improve the performance of each individual block in communication systems or optimize the whole transmitter/receiver. Therefore, we categorize the applications of DL in physical layer communications into systems with and without block structures. For DL-based communication systems with the block structure, we demonstrate the power of DL in signal compression and signal detection. We also discuss the recent endeavors in developing DL-based end-to-end communication systems. Finally, potential research directions are identified to boost intelligent physical layer communications. Introduction",
            "referenceCount": 18,
            "citationCount": 425,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1807.11713",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-07-31",
            "journal": {
                "name": "IEEE Wireless Communications",
                "volume": "26"
            },
            "citationStyles": {
                "bibtex": "@Article{Qin2018DeepLI,\n author = {Zhijin Qin and Hao Ye and Geoffrey Y. Li and B. Juang},\n booktitle = {IEEE wireless communications},\n journal = {IEEE Wireless Communications},\n pages = {93-99},\n title = {Deep Learning in Physical Layer Communications},\n volume = {26},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:051bc84485f0d9be02003e27e0ca67e9a06f2e4d",
            "@type": "ScholarlyArticle",
            "paperId": "051bc84485f0d9be02003e27e0ca67e9a06f2e4d",
            "corpusId": 25015381,
            "url": "https://www.semanticscholar.org/paper/051bc84485f0d9be02003e27e0ca67e9a06f2e4d",
            "title": "Deep Learning for Precipitation Nowcasting: A Benchmark and A New Model",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1706.03458",
                "DBLP": "conf/nips/ShiGL0YWW17",
                "MAG": "2625614184",
                "CorpusId": 25015381
            },
            "abstract": "With the goal of making high-resolution forecasts of regional rainfall, precipitation nowcasting has become an important and fundamental technology underlying various public services ranging from rainstorm warnings to flight safety. Recently, the Convolutional LSTM (ConvLSTM) model has been shown to outperform traditional optical flow based methods for precipitation nowcasting, suggesting that deep learning models have a huge potential for solving the problem. However, the convolutional recurrence structure in ConvLSTM-based models is location-invariant while natural motion and transformation (e.g., rotation) are location-variant in general. Furthermore, since deep-learning-based precipitation nowcasting is a newly emerging area, clear evaluation protocols have not yet been established. To address these problems, we propose both a new model and a benchmark for precipitation nowcasting. Specifically, we go beyond ConvLSTM and propose the Trajectory GRU (TrajGRU) model that can actively learn the location-variant structure for recurrent connections. Besides, we provide a benchmark that includes a real-world large-scale dataset from the Hong Kong Observatory, a new training loss, and a comprehensive evaluation protocol to facilitate future research and gauge the state of the art.",
            "referenceCount": 32,
            "citationCount": 584,
            "influentialCitationCount": 83,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-06-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shi2017DeepLF,\n author = {Xingjian Shi and Zhihan Gao and Leonard Lausen and Hao Wang and D. Yeung and W. Wong and W. Woo},\n booktitle = {Neural Information Processing Systems},\n pages = {5617-5627},\n title = {Deep Learning for Precipitation Nowcasting: A Benchmark and A New Model},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:785bdd008e13b3fc7ba0a336adfc0c87b39db574",
            "@type": "ScholarlyArticle",
            "paperId": "785bdd008e13b3fc7ba0a336adfc0c87b39db574",
            "corpusId": 90296455,
            "url": "https://www.semanticscholar.org/paper/785bdd008e13b3fc7ba0a336adfc0c87b39db574",
            "title": "Applications for deep learning in ecology",
            "venue": "bioRxiv",
            "publicationVenue": {
                "id": "urn:research:027ffd21-ebb0-4af8-baf5-911124292fd0",
                "name": "bioRxiv",
                "alternate_names": null,
                "issn": null,
                "url": "http://biorxiv.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2954932437",
                "DOI": "10.1111/2041-210X.13256",
                "CorpusId": 90296455
            },
            "abstract": "A lot of hype has recently been generated around deep learning, a group of artificial intelligence approaches able to break accuracy records in pattern recognition. Over the course of just a few years, deep learning revolutionized several research fields such as bioinformatics or medicine. Yet such a surge of tools and knowledge is still in its infancy in ecology despite the ever-growing size and the complexity of ecological datasets. Here we performed a literature review of deep learning implementations in ecology to identify its benefits in most ecological disciplines, even in applied ecology, up to decision makers and conservationists alike. We also provide guidelines on useful resources and recommendations for ecologists to start adding deep learning to their toolkit. At a time when automatic monitoring of populations and ecosystems generates a vast amount of data that cannot be processed by humans anymore, deep learning could become a necessity in ecology.",
            "referenceCount": 113,
            "citationCount": 282,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.biorxiv.org/content/biorxiv/early/2018/05/30/334854.full.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2018-05-30",
            "journal": {
                "name": "bioRxiv",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Christin2018ApplicationsFD,\n author = {Sylvain Christin and \u00c9. Hervet and N. Lecomte},\n booktitle = {bioRxiv},\n journal = {bioRxiv},\n title = {Applications for deep learning in ecology},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:76444b1a166f41d437fa5ed443244acc518e7d6c",
            "@type": "ScholarlyArticle",
            "paperId": "76444b1a166f41d437fa5ed443244acc518e7d6c",
            "corpusId": 3797027,
            "url": "https://www.semanticscholar.org/paper/76444b1a166f41d437fa5ed443244acc518e7d6c",
            "title": "Deep Learning and Its Applications in Biomedicine",
            "venue": "Genomics, Proteomics & Bioinformatics",
            "publicationVenue": {
                "id": "urn:research:cc4b2ffc-b9cd-40f9-8bf6-a11e389db4d5",
                "name": "Genomics, Proteomics & Bioinformatics",
                "alternate_names": [
                    "Genom Proteom  Bioinform"
                ],
                "issn": "1672-0229",
                "url": "https://www.journals.elsevier.com/genomics-proteomics-and-bioinformatics/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/gpb/CaoLTSSLZBX18",
                "PubMedCentral": "6000200",
                "MAG": "2789367970",
                "DOI": "10.1016/j.gpb.2017.07.003",
                "CorpusId": 3797027,
                "PubMed": "29522900"
            },
            "abstract": null,
            "referenceCount": 195,
            "citationCount": 387,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-02-01",
            "journal": {
                "name": "Genomics, Proteomics & Bioinformatics",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Cao2018DeepLA,\n author = {Chensi Cao and Feng Liu and Hai Tan and D. Song and Wenjie Shu and Weizhong Li and Yiming Zhou and Xiaochen Bo and Zhi Xie},\n booktitle = {Genomics, Proteomics & Bioinformatics},\n journal = {Genomics, Proteomics & Bioinformatics},\n pages = {17 - 32},\n title = {Deep Learning and Its Applications in Biomedicine},\n volume = {16},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d6c1e14e8bea932f821352ea9e33928129f7d065",
            "@type": "ScholarlyArticle",
            "paperId": "d6c1e14e8bea932f821352ea9e33928129f7d065",
            "corpusId": 52088075,
            "url": "https://www.semanticscholar.org/paper/d6c1e14e8bea932f821352ea9e33928129f7d065",
            "title": "Deep Learning of Graph Matching",
            "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2799132636",
                "DBLP": "conf/cvpr/ZanfirS18",
                "DOI": "10.1109/CVPR.2018.00284",
                "CorpusId": 52088075
            },
            "abstract": "The problem of graph matching under node and pairwise constraints is fundamental in areas as diverse as combinatorial optimization, machine learning or computer vision, where representing both the relations between nodes and their neighborhood structure is essential. We present an end-to-end model that makes it possible to learn all parameters of the graph matching process, including the unary and pairwise node neighborhoods, represented as deep feature extraction hierarchies. The challenge is in the formulation of the different matrix computation layers of the model in a way that enables the consistent, efficient propagation of gradients in the complete pipeline from the loss function, through the combinatorial optimization layer solving the matching problem, and the feature extraction hierarchy. Our computer vision experiments and ablation studies on challenging datasets like PASCAL VOC keypoints, Sintel and CUB show that matching models refined end-to-end are superior to counterparts based on feature hierarchies trained for other problems.",
            "referenceCount": 40,
            "citationCount": 198,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zanfir2018DeepLO,\n author = {Andrei Zanfir and C. Sminchisescu},\n booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n pages = {2684-2693},\n title = {Deep Learning of Graph Matching},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:288765f82241bb31d94f35e58f41c00bce4a44b0",
            "@type": "ScholarlyArticle",
            "paperId": "288765f82241bb31d94f35e58f41c00bce4a44b0",
            "corpusId": 206725404,
            "url": "https://www.semanticscholar.org/paper/288765f82241bb31d94f35e58f41c00bce4a44b0",
            "title": "PCANet: A Simple Deep Learning Baseline for Image Classification?",
            "venue": "IEEE Transactions on Image Processing",
            "publicationVenue": {
                "id": "urn:research:e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                "name": "IEEE Transactions on Image Processing",
                "alternate_names": [
                    "IEEE Trans Image Process"
                ],
                "issn": "1057-7149",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/tip/ChanJGLZM15",
                "MAG": "1616262590",
                "ArXiv": "1404.3606",
                "DOI": "10.1109/TIP.2015.2475625",
                "CorpusId": 206725404,
                "PubMed": "26340772"
            },
            "abstract": "In this paper, we propose a very simple deep learning network for image classification that is based on very basic data processing components: 1) cascaded principal component analysis (PCA); 2) binary hashing; and 3) blockwise histograms. In the proposed architecture, the PCA is employed to learn multistage filter banks. This is followed by simple binary hashing and block histograms for indexing and pooling. This architecture is thus called the PCA network (PCANet) and can be extremely easily and efficiently designed and learned. For comparison and to provide a better understanding, we also introduce and study two simple variations of PCANet: 1) RandNet and 2) LDANet. They share the same topology as PCANet, but their cascaded filters are either randomly selected or learned from linear discriminant analysis. We have extensively tested these basic networks on many benchmark visual data sets for different tasks, including Labeled Faces in the Wild (LFW) for face verification; the MultiPIE, Extended Yale B, AR, Facial Recognition Technology (FERET) data sets for face recognition; and MNIST for hand-written digit recognition. Surprisingly, for all tasks, such a seemingly naive PCANet model is on par with the state-of-the-art features either prefixed, highly hand-crafted, or carefully learned [by deep neural networks (DNNs)]. Even more surprisingly, the model sets new records for many classification tasks on the Extended Yale B, AR, and FERET data sets and on MNIST variations. Additional experiments on other public data sets also demonstrate the potential of PCANet to serve as a simple but highly competitive baseline for texture classification and object recognition.",
            "referenceCount": 71,
            "citationCount": 1411,
            "influentialCitationCount": 125,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1404.3606",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-04-14",
            "journal": {
                "name": "IEEE Transactions on Image Processing",
                "volume": "24"
            },
            "citationStyles": {
                "bibtex": "@Article{Chan2014PCANetAS,\n author = {Tsung-Han Chan and K. Jia and Shenghua Gao and Jiwen Lu and Zinan Zeng and Yi Ma},\n booktitle = {IEEE Transactions on Image Processing},\n journal = {IEEE Transactions on Image Processing},\n pages = {5017-5032},\n title = {PCANet: A Simple Deep Learning Baseline for Image Classification?},\n volume = {24},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c144420df0aec4f3d8f5771021cc1217ceca5184",
            "@type": "ScholarlyArticle",
            "paperId": "c144420df0aec4f3d8f5771021cc1217ceca5184",
            "corpusId": 209055089,
            "url": "https://www.semanticscholar.org/paper/c144420df0aec4f3d8f5771021cc1217ceca5184",
            "title": "Deep Learning for Wireless Communications",
            "venue": "Development and Analysis of Deep Learning Architectures",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2986517689",
                "ArXiv": "2005.06068",
                "DBLP": "journals/corr/abs-2005-06068",
                "DOI": "10.1007/978-3-030-31764-5_9",
                "CorpusId": 209055089
            },
            "abstract": null,
            "referenceCount": 87,
            "citationCount": 87,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2005.06068",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-11-02",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2005.06068"
            },
            "citationStyles": {
                "bibtex": "@Article{Erpek2019DeepLF,\n author = {T. Erpek and Tim O'Shea and Y. Sagduyu and Yi Shi and T. Clancy},\n booktitle = {Development and Analysis of Deep Learning Architectures},\n journal = {ArXiv},\n title = {Deep Learning for Wireless Communications},\n volume = {abs/2005.06068},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:788142b03f2c8683ee2fe8bc11c481d635041d9f",
            "@type": "ScholarlyArticle",
            "paperId": "788142b03f2c8683ee2fe8bc11c481d635041d9f",
            "corpusId": 13752387,
            "url": "https://www.semanticscholar.org/paper/788142b03f2c8683ee2fe8bc11c481d635041d9f",
            "title": "Imbalanced Deep Learning by Minority Class Incremental Rectification",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1804-10851",
                "ArXiv": "1804.10851",
                "MAG": "2798869704",
                "DOI": "10.1109/TPAMI.2018.2832629",
                "CorpusId": 13752387,
                "PubMed": "29993438"
            },
            "abstract": "Model learning from class imbalanced training data is a long-standing and significant challenge for machine learning. In particular, existing deep learning methods consider mostly either class balanced data or moderately imbalanced data in model training, and ignore the challenge of learning from significantly imbalanced training data. To address this problem, we formulate a class imbalanced deep learning model based on batch-wise incremental minority (sparsely sampled) class rectification by hard sample mining in majority (frequently sampled) classes during model training. This model is designed to minimise the dominant effect of majority classes by discovering sparsely sampled boundaries of minority classes in an iterative batch-wise learning process. To that end, we introduce a Class Rectification Loss (CRL) function that can be deployed readily in deep network architectures. Extensive experimental evaluations are conducted on three imbalanced person attribute benchmark datasets (CelebA, X-Domain, DeepFashion) and one balanced object category benchmark dataset (CIFAR-100). These experimental results demonstrate the performance advantages and model scalability of the proposed batch-wise incremental minority class rectification model over the existing state-of-the-art models for addressing the problem of imbalanced data learning.",
            "referenceCount": 82,
            "citationCount": 274,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1804.10851",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-28",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "41"
            },
            "citationStyles": {
                "bibtex": "@Article{Dong2018ImbalancedDL,\n author = {Qi Dong and S. Gong and Xiatian Zhu},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {1367-1381},\n title = {Imbalanced Deep Learning by Minority Class Incremental Rectification},\n volume = {41},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e70b9a38fcf8373865dd6e7b45e45cca7ff2eaa9",
            "@type": "ScholarlyArticle",
            "paperId": "e70b9a38fcf8373865dd6e7b45e45cca7ff2eaa9",
            "corpusId": 8696462,
            "url": "https://www.semanticscholar.org/paper/e70b9a38fcf8373865dd6e7b45e45cca7ff2eaa9",
            "title": "Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/PapernotAEGT16",
                "ArXiv": "1610.05755",
                "MAG": "2532781556",
                "CorpusId": 8696462
            },
            "abstract": "Some machine learning applications involve training data that is sensitive, such as the medical histories of patients in a clinical trial. A model may inadvertently and implicitly store some of its training data; careful analysis of the model may therefore reveal sensitive information. \nTo address this problem, we demonstrate a generally applicable approach to providing strong privacy guarantees for training data: Private Aggregation of Teacher Ensembles (PATE). The approach combines, in a black-box fashion, multiple models trained with disjoint datasets, such as records from different subsets of users. Because they rely directly on sensitive data, these models are not published, but instead used as \"teachers\" for a \"student\" model. The student learns to predict an output chosen by noisy voting among all of the teachers, and cannot directly access an individual teacher or the underlying data or parameters. The student's privacy properties can be understood both intuitively (since no single teacher and thus no single dataset dictates the student's training) and formally, in terms of differential privacy. These properties hold even if an adversary can not only query the student but also inspect its internal workings. \nCompared with previous work, the approach imposes only weak assumptions on how teachers are trained: it applies to any model, including non-convex models like DNNs. We achieve state-of-the-art privacy/utility trade-offs on MNIST and SVHN thanks to an improved privacy analysis and semi-supervised learning.",
            "referenceCount": 44,
            "citationCount": 848,
            "influentialCitationCount": 147,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-10-18",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1610.05755"
            },
            "citationStyles": {
                "bibtex": "@Article{Papernot2016SemisupervisedKT,\n author = {Nicolas Papernot and Mart\u00edn Abadi and \u00da. Erlingsson and I. Goodfellow and Kunal Talwar},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data},\n volume = {abs/1610.05755},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4c94ee7df6bc2bfcac76703be4f059a79010f7e5",
            "@type": "ScholarlyArticle",
            "paperId": "4c94ee7df6bc2bfcac76703be4f059a79010f7e5",
            "corpusId": 62841734,
            "url": "https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5",
            "title": "Self-Supervised Visual Feature Learning With Deep Neural Networks: A Survey",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3023371261",
                "ArXiv": "1902.06162",
                "DBLP": "journals/pami/JingT21",
                "DOI": "10.1109/TPAMI.2020.2992393",
                "CorpusId": 62841734,
                "PubMed": "32386141"
            },
            "abstract": "Large-scale labeled data are generally required to train deep neural networks in order to obtain better performance in visual feature learning from images or videos for computer vision applications. To avoid extensive cost of collecting and annotating large-scale datasets, as a subset of unsupervised learning methods, self-supervised learning methods are proposed to learn general image and video features from large-scale unlabeled data without using any human-annotated labels. This paper provides an extensive review of deep learning-based self-supervised general visual feature learning methods from images or videos. First, the motivation, general pipeline, and terminologies of this field are described. Then the common deep neural network architectures that used for self-supervised learning are summarized. Next, the schema and evaluation metrics of self-supervised learning methods are reviewed followed by the commonly used datasets for images, videos, audios, and 3D data, as well as the existing self-supervised visual feature learning methods. Finally, quantitative performance comparisons of the reviewed methods on benchmark datasets are summarized and discussed for both image and video feature learning. At last, this paper is concluded and lists a set of promising future directions for self-supervised visual feature learning.",
            "referenceCount": 219,
            "citationCount": 1224,
            "influentialCitationCount": 53,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-02-16",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "43"
            },
            "citationStyles": {
                "bibtex": "@Article{Jing2019SelfSupervisedVF,\n author = {Longlong Jing and Yingli Tian},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {4037-4058},\n title = {Self-Supervised Visual Feature Learning With Deep Neural Networks: A Survey},\n volume = {43},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6b3c06f148deba3926eff3c22ddf4dfd1195ac8a",
            "@type": "ScholarlyArticle",
            "paperId": "6b3c06f148deba3926eff3c22ddf4dfd1195ac8a",
            "corpusId": 15281419,
            "url": "https://www.semanticscholar.org/paper/6b3c06f148deba3926eff3c22ddf4dfd1195ac8a",
            "title": "PipeLayer: A Pipelined ReRAM-Based Accelerator for Deep Learning",
            "venue": "International Symposium on High-Performance Computer Architecture",
            "publicationVenue": {
                "id": "urn:research:b7aa40ac-729b-49d6-9064-4d1a9480e9a9",
                "name": "International Symposium on High-Performance Computer Architecture",
                "alternate_names": [
                    "HPCA",
                    "High Perform Comput Appl",
                    "Int Symp High-performance Comput Archit",
                    "High Performance Computing and Applications"
                ],
                "issn": null,
                "url": "https://web.archive.org/web/*/http://www.hpcaconf.org/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/hpca/SongQ0C17",
                "MAG": "2613989746",
                "DOI": "10.1109/HPCA.2017.55",
                "CorpusId": 15281419
            },
            "abstract": "Convolution neural networks (CNNs) are the heart of deep learning applications. Recent works PRIME [1] and ISAAC [2] demonstrated the promise of using resistive random access memory (ReRAM) to perform neural computations in memory. We found that training cannot be efficiently supported with the current schemes. First, they do not consider weight update and complex data dependency in training procedure. Second, ISAAC attempts to increase system throughput with a very deep pipeline. It is only beneficial when a large number of consecutive images can be fed into the architecture. In training, the notion of batch (e.g. 64) limits the number of images can be processed consecutively, because the images in the next batch need to be processed based on the updated weights. Third, the deep pipeline in ISAAC is vulnerable to pipeline bubbles and execution stall. In this paper, we present PipeLayer, a ReRAM-based PIM accelerator for CNNs that support both training and testing. We analyze data dependency and weight update in training algorithms and propose efficient pipeline to exploit inter-layer parallelism. To exploit intra-layer parallelism, we propose highly parallel design based on the notion of parallelism granularity and weight replication. With these design choices, PipeLayer enables the highly pipelined execution of both training and testing, without introducing the potential stalls in previous work. The experiment results show that, PipeLayer achieves the speedups of 42.45x compared with GPU platform on average. The average energy saving of PipeLayer compared with GPU implementation is 7.17x.",
            "referenceCount": 66,
            "citationCount": 570,
            "influentialCitationCount": 82,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-02-01",
            "journal": {
                "name": "2017 IEEE International Symposium on High Performance Computer Architecture (HPCA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Song2017PipeLayerAP,\n author = {Linghao Song and Xuehai Qian and Hai Helen Li and Yiran Chen},\n booktitle = {International Symposium on High-Performance Computer Architecture},\n journal = {2017 IEEE International Symposium on High Performance Computer Architecture (HPCA)},\n pages = {541-552},\n title = {PipeLayer: A Pipelined ReRAM-Based Accelerator for Deep Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:36f13179cdfc13017df535fdee582d58067301f3",
            "@type": "ScholarlyArticle",
            "paperId": "36f13179cdfc13017df535fdee582d58067301f3",
            "corpusId": 35187639,
            "url": "https://www.semanticscholar.org/paper/36f13179cdfc13017df535fdee582d58067301f3",
            "title": "Deep packet: a novel approach for encrypted traffic classification using deep learning",
            "venue": "Soft Computing - A Fusion of Foundations, Methodologies and Applications",
            "publicationVenue": {
                "id": "urn:research:32505816-936f-497d-8f3c-ee241a290329",
                "name": "Soft Computing - A Fusion of Foundations, Methodologies and Applications",
                "alternate_names": [
                    "Soft Comput",
                    "Soft Comput  Fusion Found Methodol Appl",
                    "Soft Computing"
                ],
                "issn": "1432-7643",
                "url": "https://link.springer.com/journal/500"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/soco/LotfollahiSZS20",
                "MAG": "2963516518",
                "ArXiv": "1709.02656",
                "DOI": "10.1007/s00500-019-04030-2",
                "CorpusId": 35187639
            },
            "abstract": null,
            "referenceCount": 78,
            "citationCount": 569,
            "influentialCitationCount": 80,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1709.02656",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-09-08",
            "journal": {
                "name": "Soft Computing",
                "volume": "24"
            },
            "citationStyles": {
                "bibtex": "@Article{Lotfollahi2017DeepPA,\n author = {M. Lotfollahi and Mahdi Jafari Siavoshani and Ramin Shirali Hossein Zade and Mohammdsadegh Saberian},\n booktitle = {Soft Computing - A Fusion of Foundations, Methodologies and Applications},\n journal = {Soft Computing},\n pages = {1999 - 2012},\n title = {Deep packet: a novel approach for encrypted traffic classification using deep learning},\n volume = {24},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c522d0ecba069ab0e903e93af1bb89c54daed796",
            "@type": "ScholarlyArticle",
            "paperId": "c522d0ecba069ab0e903e93af1bb89c54daed796",
            "corpusId": 52115220,
            "url": "https://www.semanticscholar.org/paper/c522d0ecba069ab0e903e93af1bb89c54daed796",
            "title": "Hyperspectral Image Classification With Deep Learning Models",
            "venue": "IEEE Transactions on Geoscience and Remote Sensing",
            "publicationVenue": {
                "id": "urn:research:70628d6a-97aa-4571-9701-bc0eb3989c32",
                "name": "IEEE Transactions on Geoscience and Remote Sensing",
                "alternate_names": [
                    "IEEE Trans Geosci Remote Sens"
                ],
                "issn": "0196-2892",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/tgrs/YangYLLZH18",
                "MAG": "2799390666",
                "DOI": "10.1109/TGRS.2018.2815613",
                "CorpusId": 52115220
            },
            "abstract": "Deep learning has achieved great successes in conventional computer vision tasks. In this paper, we exploit deep learning techniques to address the hyperspectral image classification problem. In contrast to conventional computer vision tasks that only examine the spatial context, our proposed method can exploit both spatial context and spectral correlation to enhance hyperspectral image classification. In particular, we advocate four new deep learning models, namely, 2-D convolutional neural network (2-D-CNN), 3-D-CNN, recurrent 2-D CNN (R-2-D-CNN), and recurrent 3-D-CNN (R-3-D-CNN) for hyperspectral image classification. We conducted rigorous experiments based on six publicly available data sets. Through a comparative evaluation with other state-of-the-art methods, our experimental results confirm the superiority of the proposed deep learning models, especially the R-3-D-CNN and the R-2-D-CNN deep learning models.",
            "referenceCount": 43,
            "citationCount": 270,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-17",
            "journal": {
                "name": "IEEE Transactions on Geoscience and Remote Sensing",
                "volume": "56"
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2018HyperspectralIC,\n author = {Xiaofei Yang and Yunming Ye and Xutao Li and Raymond Y. K. Lau and Xiaofeng Zhang and Xiaohui Huang},\n booktitle = {IEEE Transactions on Geoscience and Remote Sensing},\n journal = {IEEE Transactions on Geoscience and Remote Sensing},\n pages = {5408-5423},\n title = {Hyperspectral Image Classification With Deep Learning Models},\n volume = {56},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6053679654c06315f39986535a343085b07b3efd",
            "@type": "ScholarlyArticle",
            "paperId": "6053679654c06315f39986535a343085b07b3efd",
            "corpusId": 25720100,
            "url": "https://www.semanticscholar.org/paper/6053679654c06315f39986535a343085b07b3efd",
            "title": "A novel deep learning approach for classification of EEG motor imagery signals",
            "venue": "Journal of Neural Engineering",
            "publicationVenue": {
                "id": "urn:research:aa06d038-4db2-4d34-a660-be35ff62d392",
                "name": "Journal of Neural Engineering",
                "alternate_names": [
                    "J Neural Eng"
                ],
                "issn": "1741-2552",
                "url": "http://iopscience.iop.org/1741-2552/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2557301950",
                "DOI": "10.1088/1741-2560/14/1/016003",
                "CorpusId": 25720100,
                "PubMed": "27900952"
            },
            "abstract": "Objective. Signal classification is an important issue in brain computer interface (BCI) systems. Deep learning approaches have been used successfully in many recent studies to learn features and classify different types of data. However, the number of studies that employ these approaches on BCI applications is very limited. In this study we aim to use deep learning methods to improve classification performance of EEG motor imagery signals. Approach. In this study we investigate convolutional neural networks (CNN) and stacked autoencoders (SAE) to classify EEG Motor Imagery signals. A new form of input is introduced to combine time, frequency and location information extracted from EEG signal and it is used in CNN having one 1D convolutional and one max-pooling layers. We also proposed a new deep network by combining CNN and SAE. In this network, the features that are extracted in CNN are classified through the deep network SAE. Main results. The classification performance obtained by the proposed method on BCI competition IV dataset 2b in terms of kappa value is 0.547. Our approach yields 9% improvement over the winner algorithm of the competition. Significance. Our results show that deep learning methods provide better classification performance compared to other state of art approaches. These methods can be applied successfully to BCI systems where the amount of data is large due to daily recording.",
            "referenceCount": 46,
            "citationCount": 641,
            "influentialCitationCount": 57,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Physics",
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Study",
                "JournalArticle"
            ],
            "publicationDate": "2017-02-01",
            "journal": {
                "name": "Journal of Neural Engineering",
                "volume": "14"
            },
            "citationStyles": {
                "bibtex": "@Article{Tabar2017AND,\n author = {Y. R. Tabar and U. Halici},\n booktitle = {Journal of Neural Engineering},\n journal = {Journal of Neural Engineering},\n title = {A novel deep learning approach for classification of EEG motor imagery signals},\n volume = {14},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9302e07c4951559ad9a538295029881a171faeec",
            "@type": "ScholarlyArticle",
            "paperId": "9302e07c4951559ad9a538295029881a171faeec",
            "corpusId": 9328854,
            "url": "https://www.semanticscholar.org/paper/9302e07c4951559ad9a538295029881a171faeec",
            "title": "Bayesian Compression for Deep Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/nips/LouizosUW17",
                "ArXiv": "1705.08665",
                "MAG": "2619890685",
                "CorpusId": 9328854
            },
            "abstract": "Compression and computational efficiency in deep learning have become a problem of great significance. In this work, we argue that the most principled and effective way to attack this problem is by adopting a Bayesian point of view, where through sparsity inducing priors we prune large parts of the network. We introduce two novelties in this paper: 1) we use hierarchical priors to prune nodes instead of individual weights, and 2) we use the posterior uncertainties to determine the optimal fixed point precision to encode the weights. Both factors significantly contribute to achieving the state of the art in terms of compression rates, while still staying competitive with methods designed to optimize for speed or energy efficiency.",
            "referenceCount": 80,
            "citationCount": 435,
            "influentialCitationCount": 63,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-05-24",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1705.08665"
            },
            "citationStyles": {
                "bibtex": "@Article{Louizos2017BayesianCF,\n author = {Christos Louizos and Karen Ullrich and M. Welling},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Bayesian Compression for Deep Learning},\n volume = {abs/1705.08665},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d53fb3feeeab07a0d70bf466dd473ec6052ecc07",
            "@type": "ScholarlyArticle",
            "paperId": "d53fb3feeeab07a0d70bf466dd473ec6052ecc07",
            "corpusId": 9597660,
            "url": "https://www.semanticscholar.org/paper/d53fb3feeeab07a0d70bf466dd473ec6052ecc07",
            "title": "Exploring Generalization in Deep Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963739978",
                "DBLP": "conf/nips/NeyshaburBMS17",
                "ArXiv": "1706.08947",
                "CorpusId": 9597660
            },
            "abstract": "With a goal of understanding what drives generalization in deep networks, we consider several recently suggested explanations, including norm-based control, sharpness and robustness. We study how these measures can ensure generalization, highlighting the importance of scale normalization, and making a connection between sharpness and PAC-Bayes theory. We then investigate how well the measures explain different observed phenomena.",
            "referenceCount": 32,
            "citationCount": 1032,
            "influentialCitationCount": 80,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-06-27",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Neyshabur2017ExploringGI,\n author = {Behnam Neyshabur and Srinadh Bhojanapalli and D. McAllester and N. Srebro},\n booktitle = {Neural Information Processing Systems},\n pages = {5947-5956},\n title = {Exploring Generalization in Deep Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:274e5454e22b8cd73f7110dc42e09b8a84ff5a82",
            "@type": "ScholarlyArticle",
            "paperId": "274e5454e22b8cd73f7110dc42e09b8a84ff5a82",
            "corpusId": 206593071,
            "url": "https://www.semanticscholar.org/paper/274e5454e22b8cd73f7110dc42e09b8a84ff5a82",
            "title": "An improved deep learning architecture for person re-identification",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/cvpr/AhmedJM15",
                "MAG": "1928419358",
                "DOI": "10.1109/CVPR.2015.7299016",
                "CorpusId": 206593071
            },
            "abstract": "In this work, we propose a method for simultaneously learning features and a corresponding similarity metric for person re-identification. We present a deep convolutional architecture with layers specially designed to address the problem of re-identification. Given a pair of images as input, our network outputs a similarity value indicating whether the two input images depict the same person. Novel elements of our architecture include a layer that computes cross-input neighborhood differences, which capture local relationships between the two input images based on mid-level features from each input image. A high-level summary of the outputs of this layer is computed by a layer of patch summary features, which are then spatially integrated in subsequent layers. Our method significantly outperforms the state of the art on both a large data set (CUHK03) and a medium-sized data set (CUHK01), and is resistant to over-fitting. We also demonstrate that by initially training on an unrelated large data set before fine-tuning on a small target data set, our network can achieve results comparable to the state of the art even on a small data set (VIPeR).",
            "referenceCount": 31,
            "citationCount": 1226,
            "influentialCitationCount": 129,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-06-07",
            "journal": {
                "name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ahmed2015AnID,\n author = {Ejaz Ahmed and Michael Jones and Tim K. Marks},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {3908-3916},\n title = {An improved deep learning architecture for person re-identification},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:767dcaf77f73f958cfee0f54cfcde0882e8ec50e",
            "@type": "ScholarlyArticle",
            "paperId": "767dcaf77f73f958cfee0f54cfcde0882e8ec50e",
            "corpusId": 151204888,
            "url": "https://www.semanticscholar.org/paper/767dcaf77f73f958cfee0f54cfcde0882e8ec50e",
            "title": "Deep Learning: A Practitioner's Approach",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2942056403",
                "CorpusId": 151204888
            },
            "abstract": "Although interest in machine learning has reached a high point, lofty expectations often scuttle projects before they get very far. How can machine learningespecially deep neural networksmake a real difference in your organization? This hands-on guide not only provides the most practical information available on the subject, but also helps you get started building efficient deep learning networks. Authors Adam Gibson and Josh Patterson provide theory on deep learning before introducing their open-source Deeplearning4j (DL4J) library for developing production-class workflows. Through real-world examples, youll learn methods and strategies for training deep network architectures and running deep learning workflows on Spark and Hadoop with DL4J. Dive into machine learning concepts in general, as well as deep learning in particular Understand how deep networks evolved from neural network fundamentals Explore the major deep network architectures, including Convolutional and Recurrent Learn how to map specific deep networks to the right problem Walk through the fundamentals of tuning general neural networks and specific deep network architectures Use vectorization techniques for different data types with DataVec, DL4Js workflow toolLearn how to use DL4J natively on Spark and Hadoop",
            "referenceCount": 0,
            "citationCount": 438,
            "influentialCitationCount": 55,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-07-28",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Patterson2017DeepLA,\n author = {Joshua Patterson and Adam Gibson},\n title = {Deep Learning: A Practitioner's Approach},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6adeda1af8abc6bc3c17c0b39f635a845476cd9f",
            "@type": "ScholarlyArticle",
            "paperId": "6adeda1af8abc6bc3c17c0b39f635a845476cd9f",
            "corpusId": 4854885,
            "url": "https://www.semanticscholar.org/paper/6adeda1af8abc6bc3c17c0b39f635a845476cd9f",
            "title": "Deep learning for universal linear embeddings of nonlinear dynamics",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2777417212",
                "PubMedCentral": "6251871",
                "ArXiv": "1712.09707",
                "DBLP": "journals/corr/abs-1712-09707",
                "DOI": "10.1038/s41467-018-07210-0",
                "CorpusId": 4854885,
                "PubMed": "30470743"
            },
            "abstract": null,
            "referenceCount": 66,
            "citationCount": 853,
            "influentialCitationCount": 41,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41467-018-07210-0.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-12-27",
            "journal": {
                "name": "Nature Communications",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Lusch2017DeepLF,\n author = {Bethany Lusch and J. Kutz and S. Brunton},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {Deep learning for universal linear embeddings of nonlinear dynamics},\n volume = {9},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:94c4ba7246f781632aa68ca5b1acff0fdbb2d92f",
            "@type": "ScholarlyArticle",
            "paperId": "94c4ba7246f781632aa68ca5b1acff0fdbb2d92f",
            "corpusId": 16970545,
            "url": "https://www.semanticscholar.org/paper/94c4ba7246f781632aa68ca5b1acff0fdbb2d92f",
            "title": "Using goal-driven deep learning models to understand sensory cortex",
            "venue": "Nature Neuroscience",
            "publicationVenue": {
                "id": "urn:research:7892f01e-f701-4d07-8c36-e108b84ec6ab",
                "name": "Nature Neuroscience",
                "alternate_names": [
                    "Nat Neurosci"
                ],
                "issn": "1097-6256",
                "url": "http://www.nature.com/neuro/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2274405424",
                "DOI": "10.1038/nn.4244",
                "CorpusId": 16970545,
                "PubMed": "26906502"
            },
            "abstract": null,
            "referenceCount": 78,
            "citationCount": 1259,
            "influentialCitationCount": 60,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2016-02-23",
            "journal": {
                "name": "Nature Neuroscience",
                "volume": "19"
            },
            "citationStyles": {
                "bibtex": "@Article{Yamins2016UsingGD,\n author = {Daniel Yamins and J. DiCarlo},\n booktitle = {Nature Neuroscience},\n journal = {Nature Neuroscience},\n pages = {356-365},\n title = {Using goal-driven deep learning models to understand sensory cortex},\n volume = {19},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b6f381ccf98493c0f7d84050f8771be500cc6d50",
            "@type": "ScholarlyArticle",
            "paperId": "b6f381ccf98493c0f7d84050f8771be500cc6d50",
            "corpusId": 4599618,
            "url": "https://www.semanticscholar.org/paper/b6f381ccf98493c0f7d84050f8771be500cc6d50",
            "title": "Distributed deep learning networks among institutions for medical imaging",
            "venue": "J. Am. Medical Informatics Assoc.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "PubMedCentral": "6077811",
                "DBLP": "journals/jamia/ChangBLYBBRRK18",
                "MAG": "2795354529",
                "DOI": "10.1093/jamia/ocy017",
                "CorpusId": 4599618,
                "PubMed": "29617797"
            },
            "abstract": "Abstract Objective Deep learning has become a promising approach for automated support for clinical diagnosis. When medical data samples are limited, collaboration among multiple institutions is necessary to achieve high algorithm performance. However, sharing patient data often has limitations due to technical, legal, or ethical concerns. In this study, we propose methods of distributing deep learning models as an attractive alternative to sharing patient data. Methods We simulate the distribution of deep learning models across 4 institutions using various training heuristics and compare the results with a deep learning model trained on centrally hosted patient data. The training heuristics investigated include ensembling single institution models, single weight transfer, and cyclical weight transfer. We evaluated these approaches for image classification in 3 independent image collections (retinal fundus photos, mammography, and ImageNet). Results We find that cyclical weight transfer resulted in a performance that was comparable to that of centrally hosted patient data. We also found that there is an improvement in the performance of cyclical weight transfer heuristic with a high frequency of weight transfer. Conclusions We show that distributing deep learning models is an effective alternative to sharing patient data. This finding has implications for any collaborative deep learning study.",
            "referenceCount": 23,
            "citationCount": 235,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/jamia/article-pdf/25/8/945/25430879/ocy017.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-03-29",
            "journal": {
                "name": "Journal of the American Medical Informatics Association : JAMIA",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{Chang2018DistributedDL,\n author = {Ken Chang and N. Balachandar and Carson K. Lam and Darvin Yi and James M. Brown and Andrew L Beers and B. Rosen and D. Rubin and Jayashree Kalpathy-Cramer},\n booktitle = {J. Am. Medical Informatics Assoc.},\n journal = {Journal of the American Medical Informatics Association : JAMIA},\n pages = {945 - 954},\n title = {Distributed deep learning networks among institutions for medical imaging},\n volume = {25},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c4ab32dc966bff2de35723374f7410eeab85053f",
            "@type": "ScholarlyArticle",
            "paperId": "c4ab32dc966bff2de35723374f7410eeab85053f",
            "corpusId": 53107519,
            "url": "https://www.semanticscholar.org/paper/c4ab32dc966bff2de35723374f7410eeab85053f",
            "title": "A Closer Look at Deep Learning Heuristics: Learning rate restarts, Warmup and Distillation",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1810.13243",
                "DBLP": "conf/iclr/GotmareKXS19",
                "MAG": "2964293126",
                "CorpusId": 53107519
            },
            "abstract": "The convergence rate and final performance of common deep learning models have significantly benefited from heuristics such as learning rate schedules, knowledge distillation, skip connections, and normalization layers. In the absence of theoretical underpinnings, controlled experiments aimed at explaining these strategies can aid our understanding of deep learning landscapes and the training dynamics. Existing approaches for empirical analysis rely on tools of linear interpolation and visualizations with dimensionality reduction, each with their limitations. Instead, we revisit such analysis of heuristics through the lens of recently proposed methods for loss surface and representation analysis, viz., mode connectivity and canonical correlation analysis (CCA), and hypothesize reasons for the success of the heuristics. In particular, we explore knowledge distillation and learning rate heuristics of (cosine) restarts and warmup using mode connectivity and CCA. Our empirical analysis suggests that: (a) the reasons often quoted for the success of cosine annealing are not evidenced in practice; (b) that the effect of learning rate warmup is to prevent the deeper layers from creating training instability; and (c) that the latent knowledge shared by the teacher is primarily disbursed to the deeper layers.",
            "referenceCount": 39,
            "citationCount": 196,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1810.13243"
            },
            "citationStyles": {
                "bibtex": "@Article{Gotmare2018ACL,\n author = {Akhilesh Deepak Gotmare and N. Keskar and Caiming Xiong and R. Socher},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {A Closer Look at Deep Learning Heuristics: Learning rate restarts, Warmup and Distillation},\n volume = {abs/1810.13243},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7ddc973a3243d6d6559c9aa5da976670552e2784",
            "@type": "ScholarlyArticle",
            "paperId": "7ddc973a3243d6d6559c9aa5da976670552e2784",
            "corpusId": 4707598,
            "url": "https://www.semanticscholar.org/paper/7ddc973a3243d6d6559c9aa5da976670552e2784",
            "title": "Visual Analytics for Explainable Deep Learning",
            "venue": "IEEE Computer Graphics and Applications",
            "publicationVenue": {
                "id": "urn:research:0bf2c493-a93b-464a-b3d9-e18fbb4a7965",
                "name": "IEEE Computer Graphics and Applications",
                "alternate_names": [
                    "IEEE Comput Graph Appl"
                ],
                "issn": "0272-1716",
                "url": "http://www.computer.org/cga/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1804.02527",
                "MAG": "2963707011",
                "DBLP": "journals/corr/abs-1804-02527",
                "DOI": "10.1109/MCG.2018.042731661",
                "CorpusId": 4707598,
                "PubMed": "29975192"
            },
            "abstract": "Recently, deep learning has been advancing the state of the art in artificial intelligence to a new level, and humans rely on artificial intelligence techniques more than ever. However, even with such unprecedented advancements, the lack of explanation regarding the decisions made by deep learning models and absence of control over their internal processes act as major drawbacks in critical decision-making processes, such as precision medicine and law enforcement. In response, efforts are being made to make deep learning interpretable and controllable by humans. This article reviews visual analytics, information visualization, and machine learning perspectives relevant to this aim, and discusses potential challenges and future research directions.",
            "referenceCount": 18,
            "citationCount": 208,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1804.02527",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-04-07",
            "journal": {
                "name": "IEEE Computer Graphics and Applications",
                "volume": "38"
            },
            "citationStyles": {
                "bibtex": "@Article{Choo2018VisualAF,\n author = {J. Choo and Shixia Liu},\n booktitle = {IEEE Computer Graphics and Applications},\n journal = {IEEE Computer Graphics and Applications},\n pages = {84-92},\n title = {Visual Analytics for Explainable Deep Learning},\n volume = {38},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:415229903f91a1f3fc7404f5e5997fde025c221d",
            "@type": "ScholarlyArticle",
            "paperId": "415229903f91a1f3fc7404f5e5997fde025c221d",
            "corpusId": 5541663,
            "url": "https://www.semanticscholar.org/paper/415229903f91a1f3fc7404f5e5997fde025c221d",
            "title": "Deep learning and the information bottleneck principle",
            "venue": "Information Theory Workshop",
            "publicationVenue": {
                "id": "urn:research:d8b35857-6ad1-4a4c-a3b3-2e651a0e3666",
                "name": "Information Theory Workshop",
                "alternate_names": [
                    "ITW",
                    "Inf Theory Workshop"
                ],
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2949385597",
                "ArXiv": "1503.02406",
                "DBLP": "conf/itw/TishbyZ15",
                "DOI": "10.1109/ITW.2015.7133169",
                "CorpusId": 5541663
            },
            "abstract": "Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.",
            "referenceCount": 14,
            "citationCount": 1193,
            "influentialCitationCount": 90,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/1503.02406",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-03-09",
            "journal": {
                "name": "2015 IEEE Information Theory Workshop (ITW)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tishby2015DeepLA,\n author = {Naftali Tishby and Noga Zaslavsky},\n booktitle = {Information Theory Workshop},\n journal = {2015 IEEE Information Theory Workshop (ITW)},\n pages = {1-5},\n title = {Deep learning and the information bottleneck principle},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8718f7463b65147431872def16ddd2f08059fa23",
            "@type": "ScholarlyArticle",
            "paperId": "8718f7463b65147431872def16ddd2f08059fa23",
            "corpusId": 37606221,
            "url": "https://www.semanticscholar.org/paper/8718f7463b65147431872def16ddd2f08059fa23",
            "title": "A deep learning framework for financial time series using stacked autoencoders and long-short term memory",
            "venue": "PLoS ONE",
            "publicationVenue": {
                "id": "urn:research:0aed7a40-85f3-4c66-9e1b-c1556c57001b",
                "name": "PLoS ONE",
                "alternate_names": [
                    "Plo ONE",
                    "PLOS ONE",
                    "PLO ONE"
                ],
                "issn": "1932-6203",
                "url": "https://journals.plos.org/plosone/"
            },
            "year": 2017,
            "externalIds": {
                "PubMedCentral": "5510866",
                "MAG": "2734777338",
                "DOI": "10.1371/journal.pone.0180944",
                "CorpusId": 37606221,
                "PubMed": "28708865"
            },
            "abstract": "The application of deep learning approaches to finance has received a great deal of attention from both investors and researchers. This study presents a novel deep learning framework where wavelet transforms (WT), stacked autoencoders (SAEs) and long-short term memory (LSTM) are combined for stock price forecasting. The SAEs for hierarchically extracted deep features is introduced into stock price forecasting for the first time. The deep learning framework comprises three stages. First, the stock price time series is decomposed by WT to eliminate noise. Second, SAEs is applied to generate deep high-level features for predicting the stock price. Third, high-level denoising features are fed into LSTM to forecast the next day\u2019s closing price. Six market indices and their corresponding index futures are chosen to examine the performance of the proposed model. Results show that the proposed model outperforms other similar models in both predictive accuracy and profitability performance.",
            "referenceCount": 85,
            "citationCount": 680,
            "influentialCitationCount": 45,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0180944&type=printable",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-14",
            "journal": {
                "name": "PLoS ONE",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Bao2017ADL,\n author = {Wei Bao and Jun Yue and Yulei Rao},\n booktitle = {PLoS ONE},\n journal = {PLoS ONE},\n title = {A deep learning framework for financial time series using stacked autoencoders and long-short term memory},\n volume = {12},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:58e0ca33ae3068fee7005f339bf6c444fc17d55f",
            "@type": "ScholarlyArticle",
            "paperId": "58e0ca33ae3068fee7005f339bf6c444fc17d55f",
            "corpusId": 4376915,
            "url": "https://www.semanticscholar.org/paper/58e0ca33ae3068fee7005f339bf6c444fc17d55f",
            "title": "Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1708.08296",
                "DBLP": "journals/corr/abs-1708-08296",
                "MAG": "2753415590",
                "CorpusId": 4376915
            },
            "abstract": "With the availability of large databases and recent improvements in deep learning methodology, the performance of AI systems is reaching or even exceeding the human level on an increasing number of complex tasks. Impressive examples of this development can be found in domains such as image classification, sentiment analysis, speech understanding or strategic game playing. However, because of their nested non-linear structure, these highly successful machine learning and artificial intelligence models are usually applied in a black box manner, i.e., no information is provided about what exactly makes them arrive at their predictions. Since this lack of transparency can be a major drawback, e.g., in medical applications, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This paper summarizes recent developments in this field and makes a plea for more interpretability in artificial intelligence. Furthermore, it presents two approaches to explaining predictions of deep learning models, one method which computes the sensitivity of the prediction with respect to changes in the input and one approach which meaningfully decomposes the decision in terms of the input variables. These methods are evaluated on three classification tasks.",
            "referenceCount": 40,
            "citationCount": 955,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-08-28",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1708.08296"
            },
            "citationStyles": {
                "bibtex": "@Article{Samek2017ExplainableAI,\n author = {W. Samek and T. Wiegand and K. M\u00fcller},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models},\n volume = {abs/1708.08296},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:abe8a57dc27598937c2cffde3fc21c1e6d1f11ce",
            "@type": "ScholarlyArticle",
            "paperId": "abe8a57dc27598937c2cffde3fc21c1e6d1f11ce",
            "corpusId": 3519414,
            "url": "https://www.semanticscholar.org/paper/abe8a57dc27598937c2cffde3fc21c1e6d1f11ce",
            "title": "Deep EHR: A Survey of Recent Advances in Deep Learning Techniques for Electronic Health Record (EHR) Analysis",
            "venue": "IEEE journal of biomedical and health informatics",
            "publicationVenue": {
                "id": "urn:research:eac74c9c-a5c0-417d-8088-8164a6a8bfb3",
                "name": "IEEE journal of biomedical and health informatics",
                "alternate_names": [
                    "IEEE Journal of Biomedical and Health Informatics",
                    "IEEE j biomed health informatics",
                    "IEEE J Biomed Health Informatics"
                ],
                "issn": "2168-2194",
                "url": "https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6221020"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/ShickelTBR17",
                "MAG": "2625625371",
                "ArXiv": "1706.03446",
                "DOI": "10.1109/JBHI.2017.2767063",
                "CorpusId": 3519414,
                "PubMed": "29989977"
            },
            "abstract": "The past decade has seen an explosion in the amount of digital information stored in electronic health records (EHRs). While primarily designed for archiving patient information and performing administrative healthcare tasks like billing, many researchers have found secondary use of these records for various clinical informatics applications. Over the same period, the machine learning community has seen widespread advances in the field of deep learning. In this review, we survey the current research on applying deep learning to clinical tasks based on EHR data, where we find a variety of deep learning techniques and frameworks being applied to several types of clinical applications including information extraction, representation learning, outcome prediction, phenotyping, and deidentification. We identify several limitations of current research involving topics such as model interpretability, data heterogeneity, and lack of universal benchmarks. We conclude by summarizing the state of the field and identifying avenues of future deep EHR research.",
            "referenceCount": 65,
            "citationCount": 867,
            "influentialCitationCount": 33,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc6043423?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-06-12",
            "journal": {
                "name": "IEEE Journal of Biomedical and Health Informatics",
                "volume": "22"
            },
            "citationStyles": {
                "bibtex": "@Article{Shickel2017DeepEA,\n author = {B. Shickel and P. Tighe and A. Bihorac and Parisa Rashidi},\n booktitle = {IEEE journal of biomedical and health informatics},\n journal = {IEEE Journal of Biomedical and Health Informatics},\n pages = {1589-1604},\n title = {Deep EHR: A Survey of Recent Advances in Deep Learning Techniques for Electronic Health Record (EHR) Analysis},\n volume = {22},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ffc211476f2e40e79466ffc198c919a97da3bb76",
            "@type": "ScholarlyArticle",
            "paperId": "ffc211476f2e40e79466ffc198c919a97da3bb76",
            "corpusId": 4533648,
            "url": "https://www.semanticscholar.org/paper/ffc211476f2e40e79466ffc198c919a97da3bb76",
            "title": "QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2951109555",
                "DBLP": "journals/corr/abs-1803-11485",
                "ArXiv": "1803.11485",
                "CorpusId": 4533648
            },
            "abstract": "In many real-world settings, a team of agents must coordinate their behaviour while acting in a decentralised way. At the same time, it is often possible to train the agents in a centralised fashion in a simulated or laboratory setting, where global state information is available and communication constraints are lifted. Learning joint action-values conditioned on extra state information is an attractive way to exploit centralised learning, but the best strategy for then extracting decentralised policies is unclear. Our solution is QMIX, a novel value-based method that can train decentralised policies in a centralised end-to-end fashion. QMIX employs a network that estimates joint action-values as a complex non-linear combination of per-agent values that condition only on local observations. We structurally enforce that the joint-action value is monotonic in the per-agent values, which allows tractable maximisation of the joint action-value in off-policy learning, and guarantees consistency between the centralised and decentralised policies. We evaluate QMIX on a challenging set of StarCraft II micromanagement tasks, and show that QMIX significantly outperforms existing value-based multi-agent reinforcement learning methods.",
            "referenceCount": 77,
            "citationCount": 1303,
            "influentialCitationCount": 387,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-03-30",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1803.11485"
            },
            "citationStyles": {
                "bibtex": "@Article{Rashid2018QMIXMV,\n author = {Tabish Rashid and Mikayel Samvelyan and C. S. D. Witt and Gregory Farquhar and Jakob N. Foerster and Shimon Whiteson},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning},\n volume = {abs/1803.11485},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9a5eb38bcf3097cbeaa9307627015528e88efda3",
            "@type": "ScholarlyArticle",
            "paperId": "9a5eb38bcf3097cbeaa9307627015528e88efda3",
            "corpusId": 43933271,
            "url": "https://www.semanticscholar.org/paper/9a5eb38bcf3097cbeaa9307627015528e88efda3",
            "title": "Communication Algorithms via Deep Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/iclr/KimJRKOV18",
                "MAG": "2952741960",
                "ArXiv": "1805.09317",
                "CorpusId": 43933271
            },
            "abstract": "Coding theory is a central discipline underpinning wireline and wireless modems that are the workhorses of the information age. Progress in coding theory is largely driven by individual human ingenuity with sporadic breakthroughs over the past century. In this paper we study whether it is possible to automate the discovery of decoding algorithms via deep learning. We study a family of sequential codes parameterized by recurrent neural network (RNN) architectures. We show that creatively designed and trained RNN architectures can decode well known sequential codes such as the convolutional and turbo codes with close to optimal performance on the additive white Gaussian noise (AWGN) channel, which itself is achieved by breakthrough algorithms of our times (Viterbi and BCJR decoders, representing dynamic programing and forward-backward algorithms). We show strong generalizations, i.e., we train at a specific signal to noise ratio and block length but test at a wide range of these quantities, as well as robustness and adaptivity to deviations from the AWGN setting.",
            "referenceCount": 29,
            "citationCount": 180,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-05-23",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1805.09317"
            },
            "citationStyles": {
                "bibtex": "@Article{Kim2018CommunicationAV,\n author = {Hyeji Kim and Yihan Jiang and Ranvir Rana and Sreeram Kannan and Sewoong Oh and P. Viswanath},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Communication Algorithms via Deep Learning},\n volume = {abs/1805.09317},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b19729b27a1b4c24b52f87308c907653300afa7f",
            "@type": "ScholarlyArticle",
            "paperId": "b19729b27a1b4c24b52f87308c907653300afa7f",
            "corpusId": 209376771,
            "url": "https://www.semanticscholar.org/paper/b19729b27a1b4c24b52f87308c907653300afa7f",
            "title": "Dota 2 with Large Scale Deep Reinforcement Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2996037775",
                "DBLP": "journals/corr/abs-1912-06680",
                "ArXiv": "1912.06680",
                "CorpusId": 209376771
            },
            "abstract": "On April 13th, 2019, OpenAI Five became the first AI system to defeat the world champions at an esports game. The game of Dota 2 presents novel challenges for AI systems such as long time horizons, imperfect information, and complex, continuous state-action spaces, all challenges which will become increasingly central to more capable AI systems. OpenAI Five leveraged existing reinforcement learning techniques, scaled to learn from batches of approximately 2 million frames every 2 seconds. We developed a distributed training system and tools for continual training which allowed us to train OpenAI Five for 10 months. By defeating the Dota 2 world champion (Team OG), OpenAI Five demonstrates that self-play reinforcement learning can achieve superhuman performance on a difficult task.",
            "referenceCount": 50,
            "citationCount": 1314,
            "influentialCitationCount": 72,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-12-13",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1912.06680"
            },
            "citationStyles": {
                "bibtex": "@Article{Berner2019Dota2W,\n author = {Christopher Berner and Greg Brockman and Brooke Chan and Vicki Cheung and Przemyslaw Debiak and Christy Dennison and David Farhi and Quirin Fischer and Shariq Hashme and Christopher Hesse and R. J\u00f3zefowicz and S. Gray and Catherine Olsson and J. Pachocki and Michael Petrov and Henrique Pond\u00e9 de Oliveira Pinto and Jonathan Raiman and Tim Salimans and Jeremy Schlatter and Jonas Schneider and Szymon Sidor and Ilya Sutskever and Jie Tang and F. Wolski and Susan Zhang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Dota 2 with Large Scale Deep Reinforcement Learning},\n volume = {abs/1912.06680},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3f25e17eb717e5894e0404ea634451332f85d287",
            "@type": "ScholarlyArticle",
            "paperId": "3f25e17eb717e5894e0404ea634451332f85d287",
            "corpusId": 13936837,
            "url": "https://www.semanticscholar.org/paper/3f25e17eb717e5894e0404ea634451332f85d287",
            "title": "Learning Structured Output Representation using Deep Conditional Generative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/nips/SohnLY15",
                "MAG": "2188365844",
                "CorpusId": 13936837
            },
            "abstract": "Supervised deep learning has been successfully applied to many recognition problems. Although it can approximate a complex many-to-one function well when a large amount of training data is provided, it is still challenging to model complex structured output representations that effectively perform probabilistic inference and make diverse predictions. In this work, we develop a deep conditional generative model for structured output prediction using Gaussian latent variables. The model is trained efficiently in the framework of stochastic gradient variational Bayes, and allows for fast prediction using stochastic feed-forward inference. In addition, we provide novel strategies to build robust structured prediction algorithms, such as input noise-injection and multi-scale prediction objective at training. In experiments, we demonstrate the effectiveness of our proposed algorithm in comparison to the deterministic deep neural network counterparts in generating diverse but realistic structured output predictions using stochastic inference. Furthermore, the proposed training methods are complimentary, which leads to strong pixel-level object segmentation and semantic labeling performance on Caltech-UCSD Birds 200 and the subset of Labeled Faces in the Wild dataset.",
            "referenceCount": 37,
            "citationCount": 2424,
            "influentialCitationCount": 535,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-12-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sohn2015LearningSO,\n author = {Kihyuk Sohn and Honglak Lee and Xinchen Yan},\n booktitle = {Neural Information Processing Systems},\n pages = {3483-3491},\n title = {Learning Structured Output Representation using Deep Conditional Generative Models},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f8dcff771d6969fccc7afc92a7c2db53e99de0dd",
            "@type": "ScholarlyArticle",
            "paperId": "f8dcff771d6969fccc7afc92a7c2db53e99de0dd",
            "corpusId": 69348735,
            "url": "https://www.semanticscholar.org/paper/f8dcff771d6969fccc7afc92a7c2db53e99de0dd",
            "title": "Applications of deep learning to MRI images: A survey",
            "venue": "Big Data Mining and Analytics",
            "publicationVenue": {
                "id": "urn:research:fa31ff53-6717-46c5-934d-9f21c27f96ba",
                "name": "Big Data Mining and Analytics",
                "alternate_names": [
                    "Big Data Min Anal"
                ],
                "issn": "2096-0654",
                "url": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8254253"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/bigdatama/LiuPLCTLW18",
                "MAG": "2893483035",
                "DOI": "10.26599/BDMA.2018.9020001",
                "CorpusId": 69348735
            },
            "abstract": "Deep learning provides exciting solutions in many fields, such as image analysis, natural language processing, and expert system, and is seen as a key method for various future applications. On account of its non-invasive and good soft tissue contrast, in recent years, Magnetic Resonance Imaging (MRI) has been attracting increasing attention. With the development of deep learning, many innovative deep learning methods have been proposed to improve MRI image processing and analysis performance. The purpose of this article is to provide a comprehensive overview of deep learning-based MRI image processing and analysis. First, a brief introduction of deep learning and imaging modalities of MRI images is given. Then, common deep learning architectures are introduced. Next, deep learning applications of MRI images, such as image detection, image registration, image segmentation, and image classification are discussed. Subsequently, the advantages and weaknesses of several common tools are discussed, and several deep learning tools in the applications of MRI images are presented. Finally, an objective assessment of deep learning in MRI applications is presented, and future developments and trends with regard to deep learning for MRI images are addressed.",
            "referenceCount": 140,
            "citationCount": 201,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-01-25",
            "journal": {
                "name": "Big Data Min. Anal.",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2018ApplicationsOD,\n author = {Jin Liu and Yi Pan and Min Li and Ziyue Chen and L.Y.W. Tang and Chengqian Lu and Jianxin Wang},\n booktitle = {Big Data Mining and Analytics},\n journal = {Big Data Min. Anal.},\n pages = {1-18},\n title = {Applications of deep learning to MRI images: A survey},\n volume = {1},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4135da4cc0ef70917e45ae4436e7a6411077325c",
            "@type": "ScholarlyArticle",
            "paperId": "4135da4cc0ef70917e45ae4436e7a6411077325c",
            "corpusId": 133604065,
            "url": "https://www.semanticscholar.org/paper/4135da4cc0ef70917e45ae4436e7a6411077325c",
            "title": "A Review of Machine Learning and Deep Learning Applications",
            "venue": "International Conference on Computing Communication Control and automation",
            "publicationVenue": {
                "id": "urn:research:9213b848-c171-4f98-8c0b-e69f0b41941b",
                "name": "International Conference on Computing Communication Control and automation",
                "alternate_names": [
                    "ICCUBEA",
                    "Int Conf Comput Commun Control autom"
                ],
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2941584439",
                "DOI": "10.1109/ICCUBEA.2018.8697857",
                "CorpusId": 133604065
            },
            "abstract": "Machine learning is one of the fields in the modern computing world. A plenty of research has been undertaken to make machines intelligent. Learning is a natural human behavior which has been made an essential aspect of the machines as well. There are various techniques devised for the same. Traditional machine learning algorithms have been applied in many application areas. Researchers have put many efforts to improve the accuracy of that machinelearning algorithms. Another dimension was given thought which leads to deep learning concept. Deep learning is a subset of machine learning. So far few applications of deep learning have been explored. This is definitely going to cater to solving issues in several new application domains, sub-domains using deep learning. A review of these past and future application domains, sub-domains, and applications of machine learning and deep learning are illustrated in this paper.",
            "referenceCount": 10,
            "citationCount": 204,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference",
                "Review"
            ],
            "publicationDate": "2018-08-01",
            "journal": {
                "name": "2018 Fourth International Conference on Computing Communication Control and Automation (ICCUBEA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Shinde2018ARO,\n author = {Pramila Shinde and Seema Shah},\n booktitle = {International Conference on Computing Communication Control and automation},\n journal = {2018 Fourth International Conference on Computing Communication Control and Automation (ICCUBEA)},\n pages = {1-6},\n title = {A Review of Machine Learning and Deep Learning Applications},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cca4d9cb41135fbe9775063f67568b05bb3cccd5",
            "@type": "ScholarlyArticle",
            "paperId": "cca4d9cb41135fbe9775063f67568b05bb3cccd5",
            "corpusId": 187099819,
            "url": "https://www.semanticscholar.org/paper/cca4d9cb41135fbe9775063f67568b05bb3cccd5",
            "title": "Introduction to Deep Learning",
            "venue": "Undergraduate Topics in Computer Science",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2792259108",
                "DBLP": "series/utcs/Skansi18",
                "DOI": "10.1007/978-3-319-73004-2",
                "CorpusId": 187099819
            },
            "abstract": null,
            "referenceCount": 38,
            "citationCount": 180,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-01-10",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Skansi2018IntroductionTD,\n author = {Sandro Skansi},\n booktitle = {Undergraduate Topics in Computer Science},\n pages = {1-187},\n title = {Introduction to Deep Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:51c741acb1cf73eaed1c0e496ccc150bd8926939",
            "@type": "ScholarlyArticle",
            "paperId": "51c741acb1cf73eaed1c0e496ccc150bd8926939",
            "corpusId": 52243686,
            "url": "https://www.semanticscholar.org/paper/51c741acb1cf73eaed1c0e496ccc150bd8926939",
            "title": "Deep Learning and Medical Diagnosis: A Review of Literature",
            "venue": "Multimodal Technologies and Interaction",
            "publicationVenue": {
                "id": "urn:research:5cc5c2ff-6f8d-4f83-9524-37fb8ea37941",
                "name": "Multimodal Technologies and Interaction",
                "alternate_names": [
                    "Multimodal Technol Interact"
                ],
                "issn": "2414-4088",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-994038"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/mti/BakatorR18",
                "MAG": "2886848602",
                "DOI": "10.3390/MTI2030047",
                "CorpusId": 52243686
            },
            "abstract": "In this review the application of deep learning for medical diagnosis is addressed. A thorough analysis of various scientific articles in the domain of deep neural networks application in the medical field has been conducted. More than 300 research articles were obtained, and after several selection steps, 46 articles were presented in more detail. The results indicate that convolutional neural networks (CNN) are the most widely represented when it comes to deep learning and medical image analysis. Furthermore, based on the findings of this article, it can be noted that the application of deep learning technology is widespread, but the majority of applications are focused on bioinformatics, medical diagnosis and other similar fields.",
            "referenceCount": 55,
            "citationCount": 278,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/2414-4088/2/3/47/pdf?version=1534504711",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-08-17",
            "journal": {
                "name": "Multimodal Technol. Interact.",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Bakator2018DeepLA,\n author = {Mihalj Bakator and D. Radosav},\n booktitle = {Multimodal Technologies and Interaction},\n journal = {Multimodal Technol. Interact.},\n pages = {47},\n title = {Deep Learning and Medical Diagnosis: A Review of Literature},\n volume = {2},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:886674a5abae3c9bfd262006c67d4ba078e1462b",
            "@type": "ScholarlyArticle",
            "paperId": "886674a5abae3c9bfd262006c67d4ba078e1462b",
            "corpusId": 6353008,
            "url": "https://www.semanticscholar.org/paper/886674a5abae3c9bfd262006c67d4ba078e1462b",
            "title": "A Robust Deep-Learning-Based Detector for Real-Time Tomato Plant Diseases and Pests Recognition",
            "venue": "Italian National Conference on Sensors",
            "publicationVenue": {
                "id": "urn:research:3dbf084c-ef47-4b74-9919-047b40704538",
                "name": "Italian National Conference on Sensors",
                "alternate_names": [
                    "SENSORS",
                    "IEEE Sens",
                    "Ital National Conf Sens",
                    "IEEE Sensors",
                    "Sensors"
                ],
                "issn": "1424-8220",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-142001"
            },
            "year": 2017,
            "externalIds": {
                "PubMedCentral": "5620500",
                "DBLP": "journals/sensors/FuentesYKP17",
                "MAG": "2753403518",
                "DOI": "10.3390/s17092022",
                "CorpusId": 6353008,
                "PubMed": "28869539"
            },
            "abstract": "Plant Diseases and Pests are a major challenge in the agriculture sector. An accurate and a faster detection of diseases and pests in plants could help to develop an early treatment technique while substantially reducing economic losses. Recent developments in Deep Neural Networks have allowed researchers to drastically improve the accuracy of object detection and recognition systems. In this paper, we present a deep-learning-based approach to detect diseases and pests in tomato plants using images captured in-place by camera devices with various resolutions. Our goal is to find the more suitable deep-learning architecture for our task. Therefore, we consider three main families of detectors: Faster Region-based Convolutional Neural Network (Faster R-CNN), Region-based Fully Convolutional Network (R-FCN), and Single Shot Multibox Detector (SSD), which for the purpose of this work are called \u201cdeep learning meta-architectures\u201d. We combine each of these meta-architectures with \u201cdeep feature extractors\u201d such as VGG net and Residual Network (ResNet). We demonstrate the performance of deep meta-architectures and feature extractors, and additionally propose a method for local and global class annotation and data augmentation to increase the accuracy and reduce the number of false positives during training. We train and test our systems end-to-end on our large Tomato Diseases and Pests Dataset, which contains challenging images with diseases and pests, including several inter- and extra-class variations, such as infection status and location in the plant. Experimental results show that our proposed system can effectively recognize nine different types of diseases and pests, with the ability to deal with complex scenarios from a plant\u2019s surrounding area.",
            "referenceCount": 55,
            "citationCount": 837,
            "influentialCitationCount": 34,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/1424-8220/17/9/2022/pdf?version=1504687369",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-09-01",
            "journal": {
                "name": "Sensors (Basel, Switzerland)",
                "volume": "17"
            },
            "citationStyles": {
                "bibtex": "@Article{Fuentes2017ARD,\n author = {A. Fuentes and Sook Yoon and Sang Cheol Kim and D. Park},\n booktitle = {Italian National Conference on Sensors},\n journal = {Sensors (Basel, Switzerland)},\n title = {A Robust Deep-Learning-Based Detector for Real-Time Tomato Plant Diseases and Pests Recognition},\n volume = {17},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:08dc94471605308669c8d3d8284ba94fcc93e345",
            "@type": "ScholarlyArticle",
            "paperId": "08dc94471605308669c8d3d8284ba94fcc93e345",
            "corpusId": 51612859,
            "url": "https://www.semanticscholar.org/paper/08dc94471605308669c8d3d8284ba94fcc93e345",
            "title": "Deep Learning in Microscopy Image Analysis: A Survey",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2768673271",
                "DBLP": "journals/tnn/XingXSLY18",
                "DOI": "10.1109/TNNLS.2017.2766168",
                "CorpusId": 51612859,
                "PubMed": "29989994"
            },
            "abstract": "Computerized microscopy image analysis plays an important role in computer aided diagnosis and prognosis. Machine learning techniques have powered many aspects of medical investigation and clinical practice. Recently, deep learning is emerging as a leading machine learning tool in computer vision and has attracted considerable attention in biomedical image analysis. In this paper, we provide a snapshot of this fast-growing field, specifically for microscopy image analysis. We briefly introduce the popular deep neural networks and summarize current deep learning achievements in various tasks, such as detection, segmentation, and classification in microscopy image analysis. In particular, we explain the architectures and the principles of convolutional neural networks, fully convolutional networks, recurrent neural networks, stacked autoencoders, and deep belief networks, and interpret their formulations or modelings for specific tasks on various microscopy images. In addition, we discuss the open challenges and the potential trends of future research in microscopy image analysis using deep learning.",
            "referenceCount": 0,
            "citationCount": 271,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-10-01",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "29"
            },
            "citationStyles": {
                "bibtex": "@Article{Xing2018DeepLI,\n author = {F. Xing and Yuanpu Xie and H. Su and Fujun Liu and Lin Yang},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {4550-4568},\n title = {Deep Learning in Microscopy Image Analysis: A Survey},\n volume = {29},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca9f84c3922004ec6133aa9c2048ceeb17702fee",
            "@type": "ScholarlyArticle",
            "paperId": "ca9f84c3922004ec6133aa9c2048ceeb17702fee",
            "corpusId": 6128905,
            "url": "https://www.semanticscholar.org/paper/ca9f84c3922004ec6133aa9c2048ceeb17702fee",
            "title": "Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1610.04794",
                "DBLP": "journals/corr/YangFSH16",
                "MAG": "2950803263",
                "CorpusId": 6128905
            },
            "abstract": "Most learning approaches treat dimensionality reduction (DR) and clustering separately (i.e., sequentially), but recent research has shown that optimizing the two tasks jointly can substantially improve the performance of both. The premise behind the latter genre is that the data samples are obtained via linear transformation of latent representations that are easy to cluster; but in practice, the transformation from the latent space to the data can be more complicated. In this work, we assume that this transformation is an unknown and possibly nonlinear function. To recover the 'clustering-friendly' latent representations and to better cluster the data, we propose a joint DR and K-means clustering approach in which DR is accomplished via learning a deep neural network (DNN). The motivation is to keep the advantages of jointly optimizing the two tasks, while exploiting the deep neural network's ability to approximate any nonlinear function. This way, the proposed approach can work well for a broad class of generative models. Towards this end, we carefully design the DNN structure and the associated joint optimization criterion, and propose an effective and scalable algorithm to handle the formulated optimization problem. Experiments using different real datasets are employed to showcase the effectiveness of the proposed approach.",
            "referenceCount": 47,
            "citationCount": 705,
            "influentialCitationCount": 125,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-10-15",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2016TowardsKS,\n author = {Bo Yang and Xiao Fu and N. Sidiropoulos and Mingyi Hong},\n booktitle = {International Conference on Machine Learning},\n pages = {3861-3870},\n title = {Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:32ef8fb03197c0dd19b2b01ef6172a845e56a272",
            "@type": "ScholarlyArticle",
            "paperId": "32ef8fb03197c0dd19b2b01ef6172a845e56a272",
            "corpusId": 3633346,
            "url": "https://www.semanticscholar.org/paper/32ef8fb03197c0dd19b2b01ef6172a845e56a272",
            "title": "Deep learning with convolutional neural network in radiology",
            "venue": "Japanese Journal of Radiology",
            "publicationVenue": {
                "id": "urn:research:c4ba8fc8-e8c0-4eb3-bee0-b61f85830814",
                "name": "Japanese Journal of Radiology",
                "alternate_names": [
                    "Jpn J Radiol"
                ],
                "issn": "1867-1071",
                "url": "http://www.radiology.jp/modules/english/index.php?id=3"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2789956930",
                "DOI": "10.1007/s11604-018-0726-3",
                "CorpusId": 3633346,
                "PubMed": "29498017"
            },
            "abstract": null,
            "referenceCount": 75,
            "citationCount": 234,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-03-01",
            "journal": {
                "name": "Japanese Journal of Radiology",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{Yasaka2018DeepLW,\n author = {K. Yasaka and H. Akai and A. Kunimatsu and Shigeru Kiryu and O. Abe},\n booktitle = {Japanese Journal of Radiology},\n journal = {Japanese Journal of Radiology},\n pages = {257-272},\n title = {Deep learning with convolutional neural network in radiology},\n volume = {36},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1b4f140f7f7452b2c7b0af592929942ea8a9624c",
            "@type": "ScholarlyArticle",
            "paperId": "1b4f140f7f7452b2c7b0af592929942ea8a9624c",
            "corpusId": 125529590,
            "url": "https://www.semanticscholar.org/paper/1b4f140f7f7452b2c7b0af592929942ea8a9624c",
            "title": "Deep learning for denoising",
            "venue": "Geophysics",
            "publicationVenue": {
                "id": "urn:research:74f68976-b242-4148-9315-8fd8095a9ecd",
                "name": "Geophysics",
                "alternate_names": null,
                "issn": "0016-8033",
                "url": "http://www.geo-online.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2963332929",
                "DOI": "10.1190/GEO2018-0668.1",
                "CorpusId": 125529590
            },
            "abstract": "Compared with traditional seismic noise attenuation algorithms that depend on signal models and their corresponding prior assumptions, removing noise with a deep neural network is trained based on a large training set in which the inputs are the raw data sets and the corresponding outputs are the desired clean data. After the completion of training, the deep-learning (DL) method achieves adaptive denoising with no requirements of (1)\u00a0accurate modelings of the signal and noise or (2)\u00a0optimal parameters tuning. We call this intelligent denoising. We have used a convolutional neural network (CNN) as the basic tool for DL. In random and linear noise attenuation, the training set is generated with artificially added noise. In the multiple attenuation step, the training set is generated with the acoustic wave equation. The stochastic gradient descent is used to solve the optimal parameters for the CNN. The runtime of DL on a graphics processing unit for denoising has the same order as the [Formula: see text]-[Formula: see text] deconvolution method. Synthetic and field results indicate the potential applications of DL in automatic attenuation of random noise (with unknown variance), linear noise, and multiples.",
            "referenceCount": 64,
            "citationCount": 158,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-10-27",
            "journal": {
                "name": "GEOPHYSICS",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yu2018DeepLF,\n author = {Siwei Yu and Jianwei Ma and Wenlong Wang},\n booktitle = {Geophysics},\n journal = {GEOPHYSICS},\n title = {Deep learning for denoising},\n year = {2018}\n}\n"
            }
        }
    }
]