[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:129983331ca874142a3e8eb2d93d820bdf1f9aca",
            "@type": "ScholarlyArticle",
            "paperId": "129983331ca874142a3e8eb2d93d820bdf1f9aca",
            "corpusId": 211011033,
            "url": "https://www.semanticscholar.org/paper/129983331ca874142a3e8eb2d93d820bdf1f9aca",
            "title": "Deep Reinforcement Learning for Autonomous Driving: A Survey",
            "venue": "IEEE transactions on intelligent transportation systems (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2002.00444",
                "DBLP": "journals/tits/KiranSTMSYP22",
                "MAG": "3003533476",
                "DOI": "10.1109/TITS.2021.3054625",
                "CorpusId": 211011033
            },
            "abstract": "With the development of deep representation learning, the domain of reinforcement learning (RL) has become a powerful learning framework now capable of learning complex policies in high dimensional environments. This review summarises deep reinforcement learning (DRL) algorithms and provides a taxonomy of automated driving tasks where (D)RL methods have been employed, while addressing key computational challenges in real world deployment of autonomous driving agents. It also delineates adjacent domains such as behavior cloning, imitation learning, inverse reinforcement learning that are related but are not classical RL algorithms. The role of simulators in training agents, methods to validate, test and robustify existing solutions in RL are discussed.",
            "referenceCount": 156,
            "citationCount": 863,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2002.00444",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-02-02",
            "journal": {
                "name": "IEEE Transactions on Intelligent Transportation Systems",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Kiran2020DeepRL,\n author = {B. R. Kiran and Ibrahim Sobh and V. Talpaert and P. Mannion and A. A. Sallab and S. Yogamani and P. P'erez},\n booktitle = {IEEE transactions on intelligent transportation systems (Print)},\n journal = {IEEE Transactions on Intelligent Transportation Systems},\n pages = {4909-4926},\n title = {Deep Reinforcement Learning for Autonomous Driving: A Survey},\n volume = {23},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:24d110aa47213e600c89b3fa28bb65e39fc794ab",
            "@type": "ScholarlyArticle",
            "paperId": "24d110aa47213e600c89b3fa28bb65e39fc794ab",
            "corpusId": 112333615,
            "url": "https://www.semanticscholar.org/paper/24d110aa47213e600c89b3fa28bb65e39fc794ab",
            "title": "Deep learning for estimating building energy consumption",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2295959395",
                "DOI": "10.1016/J.SEGAN.2016.02.005",
                "CorpusId": 112333615
            },
            "abstract": null,
            "referenceCount": 32,
            "citationCount": 452,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2016-06-01",
            "journal": {
                "name": "Sustainable Energy, Grids and Networks",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Mocanu2016DeepLF,\n author = {Elena Mocanu and H. Nguyen and M. Gibescu and W. Kling},\n journal = {Sustainable Energy, Grids and Networks},\n pages = {91-99},\n title = {Deep learning for estimating building energy consumption},\n volume = {6},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:566de8271556e8776a1b0cef86a045ef3a92d214",
            "@type": "ScholarlyArticle",
            "paperId": "566de8271556e8776a1b0cef86a045ef3a92d214",
            "corpusId": 88515114,
            "url": "https://www.semanticscholar.org/paper/566de8271556e8776a1b0cef86a045ef3a92d214",
            "title": "Deep learning for short-term traffic flow prediction",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2593182953",
                "ArXiv": "1604.04527",
                "DOI": "10.1016/j.trc.2017.02.024",
                "CorpusId": 88515114
            },
            "abstract": null,
            "referenceCount": 79,
            "citationCount": 740,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1604.04527",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Engineering",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2016-04-15",
            "journal": {
                "name": "Transportation Research Part C-emerging Technologies",
                "volume": "79"
            },
            "citationStyles": {
                "bibtex": "@Article{Polson2016DeepLF,\n author = {Nicholas G. Polson and Vadim O. Sokolov},\n journal = {Transportation Research Part C-emerging Technologies},\n pages = {1-17},\n title = {Deep learning for short-term traffic flow prediction},\n volume = {79},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b8e49216e5b4a017342b0be5f6fbbd79e690a1c7",
            "@type": "ScholarlyArticle",
            "paperId": "b8e49216e5b4a017342b0be5f6fbbd79e690a1c7",
            "corpusId": 3798360,
            "url": "https://www.semanticscholar.org/paper/b8e49216e5b4a017342b0be5f6fbbd79e690a1c7",
            "title": "Optimal auctions through deep learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2950704505",
                "DBLP": "journals/corr/DuttingFNP17",
                "DOI": "10.1145/3470442",
                "CorpusId": 3798360
            },
            "abstract": "Designing an incentive compatible auction that maximizes expected revenue is an intricate task. The single-item case was resolved in a seminal piece of work by Myerson in 1981. Even after 30--40 years of intense research, the problem remains unsolved for settings with two or more items. We overview recent research results that show how tools from deep learning are shaping up to become a powerful tool for the automated design of near-optimal auctions auctions. In this approach, an auction is modeled as a multilayer neural network, with optimal auction design framed as a constrained learning problem that can be addressed with standard machine learning pipelines. Through this approach, it is possible to recover to a high degree of accuracy essentially all known analytically derived solutions for multi-item settings and obtain novel mechanisms for settings in which the optimal mechanism is unknown.",
            "referenceCount": 69,
            "citationCount": 188,
            "influentialCitationCount": 38,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3470442",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2017-06-12",
            "journal": {
                "name": "Communications of the ACM",
                "volume": "64"
            },
            "citationStyles": {
                "bibtex": "@Article{D\u00fctting2017OptimalAT,\n author = {Paul D\u00fctting and Zhe Feng and H. Narasimhan and D. Parkes},\n booktitle = {International Conference on Machine Learning},\n journal = {Communications of the ACM},\n pages = {109 - 116},\n title = {Optimal auctions through deep learning},\n volume = {64},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ee3837d335c43019347274db8ff4402a0cfa2c8e",
            "@type": "ScholarlyArticle",
            "paperId": "ee3837d335c43019347274db8ff4402a0cfa2c8e",
            "corpusId": 17241828,
            "url": "https://www.semanticscholar.org/paper/ee3837d335c43019347274db8ff4402a0cfa2c8e",
            "title": "On the Origin of Deep Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1702.07800",
                "DBLP": "journals/corr/WangRX17",
                "MAG": "2592484110",
                "CorpusId": 17241828
            },
            "abstract": "This paper is a review of the evolutionary history of deep learning models. It covers from the genesis of neural networks when associationism modeling of the brain is studied, to the models that dominate the last decade of research in deep learning like convolutional neural networks, deep belief networks, and recurrent neural networks. In addition to a review of these models, this paper primarily focuses on the precedents of the models above, examining how the initial ideas are assembled to construct the early models and how these preliminary models are developed into their current forms. Many of these evolutionary paths last more than half a century and have a diversity of directions. For example, CNN is built on prior knowledge of biological vision system; DBN is evolved from a trade-off of modeling power and computation complexity of graphical models and many nowadays models are neural counterparts of ancient linear models. This paper reviews these evolutionary paths and offers a concise thought flow of how these models are developed, and aims to provide a thorough background for deep learning. More importantly, along with the path, this paper summarizes the gist behind these milestones and proposes many directions to guide the future research of deep learning.",
            "referenceCount": 198,
            "citationCount": 201,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-02-24",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1702.07800"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2017OnTO,\n author = {Haohan Wang and B. Raj and E. Xing},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {On the Origin of Deep Learning},\n volume = {abs/1702.07800},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eff61216e0136886e1158625b1e5a88ed1a7cbce",
            "@type": "ScholarlyArticle",
            "paperId": "eff61216e0136886e1158625b1e5a88ed1a7cbce",
            "corpusId": 1639981,
            "url": "https://www.semanticscholar.org/paper/eff61216e0136886e1158625b1e5a88ed1a7cbce",
            "title": "Predicting Parameters in Deep Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/nips/DenilSDRF13",
                "MAG": "2952899695",
                "ArXiv": "1306.0543",
                "DOI": "10.14288/1.0165555",
                "CorpusId": 1639981
            },
            "abstract": "We demonstrate that there is significant redundancy in the parameterization of several deep learning models. Given only a few weight values for each feature it is possible to accurately predict the remaining values. Moreover, we show that not only can the parameter values be predicted, but many of them need not be learned at all. We train several different architectures by learning only a small number of weights and predicting the rest. In the best case we are able to predict more than 95% of the weights of a network without any drop in accuracy.",
            "referenceCount": 37,
            "citationCount": 1212,
            "influentialCitationCount": 70,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-06-03",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Denil2013PredictingPI,\n author = {Misha Denil and B. Shakibi and Laurent Dinh and Marc'Aurelio Ranzato and Nando de Freitas},\n booktitle = {Neural Information Processing Systems},\n pages = {2148-2156},\n title = {Predicting Parameters in Deep Learning},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6d05a2a8e5b179407de8e4c2507bced8bc99eaed",
            "@type": "ScholarlyArticle",
            "paperId": "6d05a2a8e5b179407de8e4c2507bced8bc99eaed",
            "corpusId": 4300434,
            "url": "https://www.semanticscholar.org/paper/6d05a2a8e5b179407de8e4c2507bced8bc99eaed",
            "title": "Ian Goodfellow, Yoshua Bengio, and Aaron Courville: Deep learning",
            "venue": "Genetic Programming and Evolvable Machines",
            "publicationVenue": {
                "id": "urn:research:6f4efebe-b0de-4221-9037-fe8d06c85a99",
                "name": "Genetic Programming and Evolvable Machines",
                "alternate_names": [
                    "Genet Program Evolvable Mach"
                ],
                "issn": "1389-2576",
                "url": "https://link.springer.com/journal/10710"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/gpem/Heaton18",
                "MAG": "2765982206",
                "DOI": "10.1007/s10710-017-9314-z",
                "CorpusId": 4300434
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 265,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s10710-017-9314-z.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-10-29",
            "journal": {
                "name": "Genetic Programming and Evolvable Machines",
                "volume": "19"
            },
            "citationStyles": {
                "bibtex": "@Article{Heaton2017IanGY,\n author = {Jeff Heaton},\n booktitle = {Genetic Programming and Evolvable Machines},\n journal = {Genetic Programming and Evolvable Machines},\n pages = {305-307},\n title = {Ian Goodfellow, Yoshua Bengio, and Aaron Courville: Deep learning},\n volume = {19},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:18c287e1eec0598528372d23627447a938f4e5ba",
            "@type": "ScholarlyArticle",
            "paperId": "18c287e1eec0598528372d23627447a938f4e5ba",
            "corpusId": 26131992,
            "url": "https://www.semanticscholar.org/paper/18c287e1eec0598528372d23627447a938f4e5ba",
            "title": "Text feature extraction based on deep learning: a review",
            "venue": "EURASIP Journal on Wireless Communications and Networking",
            "publicationVenue": {
                "id": "urn:research:3215af4b-a40f-474d-bc19-27c154ff31a3",
                "name": "EURASIP Journal on Wireless Communications and Networking",
                "alternate_names": [
                    "Eurasip J Wirel Commun Netw",
                    "Eurasip Journal on Wireless Communications and Networking",
                    "EURASIP J Wirel Commun Netw"
                ],
                "issn": "1687-1472",
                "url": "http://jwcn.eurasipjournals.com/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/ejwcn/LiangSSG17",
                "MAG": "2772515592",
                "PubMedCentral": "5732309",
                "DOI": "10.1186/s13638-017-0993-1",
                "CorpusId": 26131992,
                "PubMed": "29263717"
            },
            "abstract": null,
            "referenceCount": 124,
            "citationCount": 213,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://jwcn-eurasipjournals.springeropen.com/track/pdf/10.1186/s13638-017-0993-1",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-12-15",
            "journal": {
                "name": "Eurasip Journal on Wireless Communications and Networking",
                "volume": "2017"
            },
            "citationStyles": {
                "bibtex": "@Article{Liang2017TextFE,\n author = {Hong Liang and Xiao Sun and Yunlei Sun and Yuan Gao},\n booktitle = {EURASIP Journal on Wireless Communications and Networking},\n journal = {Eurasip Journal on Wireless Communications and Networking},\n title = {Text feature extraction based on deep learning: a review},\n volume = {2017},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cf5a21684aefb1b8db6e0490167636d245396095",
            "@type": "ScholarlyArticle",
            "paperId": "cf5a21684aefb1b8db6e0490167636d245396095",
            "corpusId": 182953134,
            "url": "https://www.semanticscholar.org/paper/cf5a21684aefb1b8db6e0490167636d245396095",
            "title": "Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1906.03671",
                "MAG": "2995188922",
                "DBLP": "journals/corr/abs-1906-03671",
                "CorpusId": 182953134
            },
            "abstract": "We design a new algorithm for batch active learning with deep neural network models. Our algorithm, Batch Active learning by Diverse Gradient Embeddings (BADGE), samples groups of points that are disparate and high-magnitude when represented in a hallucinated gradient space, a strategy designed to incorporate both predictive uncertainty and sample diversity into every selected batch. Crucially, BADGE trades off between diversity and uncertainty without requiring any hand-tuned hyperparameters. We show that while other approaches sometimes succeed for particular batch sizes or architectures, BADGE consistently performs as well or better, making it a versatile option for practical active learning problems.",
            "referenceCount": 55,
            "citationCount": 495,
            "influentialCitationCount": 124,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-09",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1906.03671"
            },
            "citationStyles": {
                "bibtex": "@Article{Ash2019DeepBA,\n author = {J. Ash and Chicheng Zhang and A. Krishnamurthy and J. Langford and Alekh Agarwal},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds},\n volume = {abs/1906.03671},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5e3fd9e6e7bcfc37fa751385ea3c8c7c7ac80c43",
            "@type": "ScholarlyArticle",
            "paperId": "5e3fd9e6e7bcfc37fa751385ea3c8c7c7ac80c43",
            "corpusId": 3804623,
            "url": "https://www.semanticscholar.org/paper/5e3fd9e6e7bcfc37fa751385ea3c8c7c7ac80c43",
            "title": "Maximum Principle Based Algorithms for Deep Learning",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1710.09513",
                "MAG": "2765410998",
                "DBLP": "journals/jmlr/LiCTE17",
                "CorpusId": 3804623
            },
            "abstract": "The continuous dynamical system approach to deep learning is explored in order to devise alternative frameworks for training algorithms. Training is recast as a control problem and this allows us to formulate necessary optimality conditions in continuous time using the Pontryagin's maximum principle (PMP). A modification of the method of successive approximations is then used to solve the PMP, giving rise to an alternative training algorithm for deep learning. This approach has the advantage that rigorous error estimates and convergence results can be established. We also show that it may avoid some pitfalls of gradient-based methods, such as slow convergence on flat landscapes near saddle points. Furthermore, we demonstrate that it obtains favorable initial convergence rate per-iteration, provided Hamiltonian maximization can be efficiently carried out - a step which is still in need of improvement. Overall, the approach opens up new avenues to attack problems associated with deep learning, such as trapping in slow manifolds and inapplicability of gradient-based methods for discrete trainable variables.",
            "referenceCount": 60,
            "citationCount": 192,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-26",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1710.09513"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2017MaximumPB,\n author = {Qianxiao Li and Long Chen and Cheng Tai and E. Weinan},\n booktitle = {Journal of machine learning research},\n journal = {ArXiv},\n title = {Maximum Principle Based Algorithms for Deep Learning},\n volume = {abs/1710.09513},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:da5c65b0ac8b525c3d3d4889bf44d8a48d254a07",
            "@type": "ScholarlyArticle",
            "paperId": "da5c65b0ac8b525c3d3d4889bf44d8a48d254a07",
            "corpusId": 6318455,
            "url": "https://www.semanticscholar.org/paper/da5c65b0ac8b525c3d3d4889bf44d8a48d254a07",
            "title": "Deep Bayesian Active Learning with Image Data",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/icml/GalIG17",
                "MAG": "2951786554",
                "ArXiv": "1703.02910",
                "DOI": "10.17863/CAM.11070",
                "CorpusId": 6318455
            },
            "abstract": "Even though active learning forms an important pillar of machine learning, deep learning tools are not prevalent within it. Deep learning poses several difficulties when used in an active learning setting. First, active learning (AL) methods generally rely on being able to learn and update models from small amounts of data. Recent advances in deep learning, on the other hand, are notorious for their dependence on large amounts of data. Second, many AL acquisition functions rely on model uncertainty, yet deep learning methods rarely represent such model uncertainty. In this paper we combine recent advances in Bayesian deep learning into the active learning framework in a practical way. We develop an active learning framework for high dimensional data, a task which has been extremely challenging so far, with very sparse existing literature. Taking advantage of specialised models such as Bayesian convolutional neural networks, we demonstrate our active learning techniques with image data, obtaining a significant improvement on existing active learning approaches. We demonstrate this on both the MNIST dataset, as well as for skin cancer diagnosis from lesion images (ISIC2016 task).",
            "referenceCount": 43,
            "citationCount": 1334,
            "influentialCitationCount": 198,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.02910"
            },
            "citationStyles": {
                "bibtex": "@Article{Gal2017DeepBA,\n author = {Y. Gal and Riashat Islam and Zoubin Ghahramani},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Deep Bayesian Active Learning with Image Data},\n volume = {abs/1703.02910},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b28f75371e04c39090c17c2caee2d98b758b2104",
            "@type": "ScholarlyArticle",
            "paperId": "b28f75371e04c39090c17c2caee2d98b758b2104",
            "corpusId": 3298505,
            "url": "https://www.semanticscholar.org/paper/b28f75371e04c39090c17c2caee2d98b758b2104",
            "title": "Deep-learning-based ghost imaging",
            "venue": "Scientific Reports",
            "publicationVenue": {
                "id": "urn:research:f99f77b7-b1b6-44d3-984a-f288e9884b9b",
                "name": "Scientific Reports",
                "alternate_names": [
                    "Sci Rep"
                ],
                "issn": "2045-2322",
                "url": "http://www.nature.com/srep/"
            },
            "year": 2017,
            "externalIds": {
                "PubMedCentral": "5736587",
                "MAG": "2772609332",
                "DOI": "10.1038/s41598-017-18171-7",
                "CorpusId": 3298505,
                "PubMed": "29259269"
            },
            "abstract": null,
            "referenceCount": 33,
            "citationCount": 222,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41598-017-18171-7.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-12-19",
            "journal": {
                "name": "Scientific Reports",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Lyu2017DeeplearningbasedGI,\n author = {Meng Lyu and Wei Wang and Hao Wang and Haichao Wang and Guowei Li and Ni Chen and G. Situ},\n booktitle = {Scientific Reports},\n journal = {Scientific Reports},\n title = {Deep-learning-based ghost imaging},\n volume = {7},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d517b13f2b152c913b81ce534a149493517dbdad",
            "@type": "ScholarlyArticle",
            "paperId": "d517b13f2b152c913b81ce534a149493517dbdad",
            "corpusId": 10158224,
            "url": "https://www.semanticscholar.org/paper/d517b13f2b152c913b81ce534a149493517dbdad",
            "title": "Big Data Deep Learning: Challenges and Perspectives",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/access/ChenL14",
                "MAG": "1984020445",
                "DOI": "10.1109/ACCESS.2014.2325029",
                "CorpusId": 10158224
            },
            "abstract": "Deep learning is currently an extremely active research area in machine learning and pattern recognition society. It has gained huge successes in a broad area of applications such as speech recognition, computer vision, and natural language processing. With the sheer size of data available today, big data brings big opportunities and transformative potential for various sectors; on the other hand, it also presents unprecedented challenges to harnessing data and information. As the data keeps getting bigger, deep learning is coming to play a key role in providing big data predictive analytics solutions. In this paper, we provide a brief overview of deep learning, and highlight current research efforts and the challenges to big data, as well as the future trends.",
            "referenceCount": 115,
            "citationCount": 973,
            "influentialCitationCount": 32,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2014-05-16",
            "journal": {
                "name": "IEEE Access",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2014BigDD,\n author = {Xue-wen Chen and Xiaotong Lin},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {514-525},\n title = {Big Data Deep Learning: Challenges and Perspectives},\n volume = {2},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0ab3f7ecbdc5a33565a234215604a6ca9d155a33",
            "@type": "ScholarlyArticle",
            "paperId": "0ab3f7ecbdc5a33565a234215604a6ca9d155a33",
            "corpusId": 19135734,
            "url": "https://www.semanticscholar.org/paper/0ab3f7ecbdc5a33565a234215604a6ca9d155a33",
            "title": "Rainbow: Combining Improvements in Deep Reinforcement Learning",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/aaai/HesselMHSODHPAS18",
                "MAG": "2761873684",
                "ArXiv": "1710.02298",
                "DOI": "10.1609/aaai.v32i1.11796",
                "CorpusId": 19135734
            },
            "abstract": "\n \n The deep reinforcement learning community has made several independent improvements to the DQN algorithm. However, it is unclear which of these extensions are complementary and can be fruitfully combined. This paper examines six extensions to the DQN algorithm and empirically studies their combination. Our experiments show that the combination provides state-of-the-art performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. We also provide results from a detailed ablation study that shows the contribution of each component to overall performance.\n \n",
            "referenceCount": 32,
            "citationCount": 1743,
            "influentialCitationCount": 327,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/11796/11655",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-10-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hessel2017RainbowCI,\n author = {Matteo Hessel and Joseph Modayil and H. V. Hasselt and T. Schaul and Georg Ostrovski and Will Dabney and Dan Horgan and Bilal Piot and M. G. Azar and David Silver},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {3215-3222},\n title = {Rainbow: Combining Improvements in Deep Reinforcement Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:98e8b2f6a8583e83ce0159dd29cf5d848adcbd24",
            "@type": "ScholarlyArticle",
            "paperId": "98e8b2f6a8583e83ce0159dd29cf5d848adcbd24",
            "corpusId": 7403403,
            "url": "https://www.semanticscholar.org/paper/98e8b2f6a8583e83ce0159dd29cf5d848adcbd24",
            "title": "Failures of Gradient-Based Deep Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963847403",
                "ArXiv": "1703.07950",
                "DBLP": "conf/icml/Shalev-ShwartzS17",
                "CorpusId": 7403403
            },
            "abstract": "In recent years, Deep Learning has become the go-to solution for a broad range of applications, often outperforming state-of-the-art. However, it is important, for both theoreticians and practitioners, to gain a deeper understanding of the difficulties and limitations associated with common approaches and algorithms. We describe four types of simple problems, for which the gradient-based algorithms commonly used in deep learning either fail or suffer from significant difficulties. We illustrate the failures through practical experiments, and provide theoretical insights explaining their source, and how they might be remedied.",
            "referenceCount": 35,
            "citationCount": 167,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-23",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shalev-Shwartz2017FailuresOG,\n author = {S. Shalev-Shwartz and O. Shamir and Shaked Shammah},\n booktitle = {International Conference on Machine Learning},\n pages = {3067-3075},\n title = {Failures of Gradient-Based Deep Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b3d7a7440bb170a935589f6e12aa665fb7516b47",
            "@type": "ScholarlyArticle",
            "paperId": "b3d7a7440bb170a935589f6e12aa665fb7516b47",
            "corpusId": 25670768,
            "url": "https://www.semanticscholar.org/paper/b3d7a7440bb170a935589f6e12aa665fb7516b47",
            "title": "Deep learning in robotics: a review of recent research",
            "venue": "Adv. Robotics",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2736506089",
                "DBLP": "journals/ar/PiersonG17",
                "ArXiv": "1707.07217",
                "DOI": "10.1080/01691864.2017.1365009",
                "CorpusId": 25670768
            },
            "abstract": "Abstract Advances in deep learning over the last decade have led to a flurry of research in the application of deep artificial neural networks to robotic systems, with at least 30 papers published on the subject between 2014 and the present. This review discusses the applications, benefits, and limitations of deep learning vis-\u00e0-vis physical robotic systems, using contemporary research as exemplars. It is intended to communicate recent advances to the wider robotics community and inspire additional interest in and application of deep learning in robotics.",
            "referenceCount": 140,
            "citationCount": 215,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1707.07217",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-07-22",
            "journal": {
                "name": "Advanced Robotics",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Pierson2017DeepLI,\n author = {H. Pierson and Michael S. Gashler},\n booktitle = {Adv. Robotics},\n journal = {Advanced Robotics},\n pages = {821 - 835},\n title = {Deep learning in robotics: a review of recent research},\n volume = {31},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2292300654a2719d0617596b58c36b5d92457514",
            "@type": "ScholarlyArticle",
            "paperId": "2292300654a2719d0617596b58c36b5d92457514",
            "corpusId": 12118055,
            "url": "https://www.semanticscholar.org/paper/2292300654a2719d0617596b58c36b5d92457514",
            "title": "Deep Learning Based Feature Selection for Remote Sensing Scene Classification",
            "venue": "IEEE Geoscience and Remote Sensing Letters",
            "publicationVenue": {
                "id": "urn:research:290335d6-cddc-465d-87f1-807e86d8efee",
                "name": "IEEE Geoscience and Remote Sensing Letters",
                "alternate_names": [
                    "IEEE Geosci Remote Sens Lett"
                ],
                "issn": "1545-598X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=8859"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/lgrs/ZouNZW15",
                "MAG": "1958291604",
                "DOI": "10.1109/LGRS.2015.2475299",
                "CorpusId": 12118055
            },
            "abstract": "With the popular use of high-resolution satellite images, more and more research efforts have been placed on remote sensing scene classification/recognition. In scene classification, effective feature selection can significantly boost the final performance. In this letter, a novel deep-learning-based feature-selection method is proposed, which formulates the feature-selection problem as a feature reconstruction problem. Note that the popular deep-learning technique, i.e., the deep belief network (DBN), achieves feature abstraction by minimizing the reconstruction error over the whole feature set, and features with smaller reconstruction errors would hold more feature intrinsics for image representation. Therefore, the proposed method selects features that are more reconstructible as the discriminative features. Specifically, an iterative algorithm is developed to adapt the DBN to produce the inquired reconstruction weights. In the experiments, 2800 remote sensing scene images of seven categories are collected for performance evaluation. Experimental results demonstrate the effectiveness of the proposed method.",
            "referenceCount": 18,
            "citationCount": 598,
            "influentialCitationCount": 73,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-09-18",
            "journal": {
                "name": "IEEE Geoscience and Remote Sensing Letters",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Zou2015DeepLB,\n author = {Qin Zou and Lihao Ni and T. Zhang and Qian Wang},\n booktitle = {IEEE Geoscience and Remote Sensing Letters},\n journal = {IEEE Geoscience and Remote Sensing Letters},\n pages = {2321-2325},\n title = {Deep Learning Based Feature Selection for Remote Sensing Scene Classification},\n volume = {12},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:132029da36a43540567e27970b36b0b6f1631473",
            "@type": "ScholarlyArticle",
            "paperId": "132029da36a43540567e27970b36b0b6f1631473",
            "corpusId": 3566105,
            "url": "https://www.semanticscholar.org/paper/132029da36a43540567e27970b36b0b6f1631473",
            "title": "Is Multitask Deep Learning Practical for Pharma?",
            "venue": "Journal of Chemical Information and Modeling",
            "publicationVenue": {
                "id": "urn:research:3f16aef5-6b9f-4f87-baca-cbf8147e352f",
                "name": "Journal of Chemical Information and Modeling",
                "alternate_names": [
                    "J Chem Inf Model"
                ],
                "issn": "1549-9596",
                "url": "http://pubs.acs.org/jcim"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2734982589",
                "DBLP": "journals/jcisd/RamsundarLWVTSP17",
                "DOI": "10.1021/acs.jcim.7b00146",
                "CorpusId": 3566105,
                "PubMed": "28692267"
            },
            "abstract": "Multitask deep learning has emerged as a powerful tool for computational drug discovery. However, despite a number of preliminary studies, multitask deep networks have yet to be widely deployed in the pharmaceutical and biotech industries. This lack of acceptance stems from both software difficulties and lack of understanding of the robustness of multitask deep networks. Our work aims to resolve both of these barriers to adoption. We introduce a high-quality open-source implementation of multitask deep networks as part of the DeepChem open-source platform. Our implementation enables simple python scripts to construct, fit, and evaluate sophisticated deep models. We use our implementation to analyze the performance of multitask deep networks and related deep models on four collections of pharmaceutical data (three of which have not previously been analyzed in the literature). We split these data sets into train/valid/test using time and neighbor splits to test multitask deep learning performance under challenging conditions. Our results demonstrate that multitask deep networks are surprisingly robust and can offer strong improvement over random forests. Our analysis and open-source implementation in DeepChem provide an argument that multitask deep networks are ready for widespread use in commercial drug discovery.",
            "referenceCount": 16,
            "citationCount": 196,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://doi.org/10.1021/acs.jcim.7b00146.s001",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-08-01",
            "journal": {
                "name": "Journal of chemical information and modeling",
                "volume": "57 8"
            },
            "citationStyles": {
                "bibtex": "@Article{Ramsundar2017IsMD,\n author = {Bharath Ramsundar and Bowen Liu and Zhenqin Wu and A. Verras and M. Tudor and R. Sheridan and V. Pande},\n booktitle = {Journal of Chemical Information and Modeling},\n journal = {Journal of chemical information and modeling},\n pages = {\n          2068-2076\n        },\n title = {Is Multitask Deep Learning Practical for Pharma?},\n volume = {57 8},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:597de1eed79608bcceee1bba0bafd2ac48f0d26a",
            "@type": "ScholarlyArticle",
            "paperId": "597de1eed79608bcceee1bba0bafd2ac48f0d26a",
            "corpusId": 3340838,
            "url": "https://www.semanticscholar.org/paper/597de1eed79608bcceee1bba0bafd2ac48f0d26a",
            "title": "Improving palliative care with deep learning",
            "venue": "IEEE International Conference on Bioinformatics and Biomedicine",
            "publicationVenue": {
                "id": "urn:research:6363ebc9-706a-4203-b804-148cbf8810ce",
                "name": "IEEE International Conference on Bioinformatics and Biomedicine",
                "alternate_names": [
                    "Bioinform Biomed",
                    "BIBM",
                    "IEEE Int Conf Bioinform Biomed",
                    "Bioinformatics and Biomedicine"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=283"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/midm/AvatiJHDNS18",
                "MAG": "2964291773",
                "PubMedCentral": "6290509",
                "ArXiv": "1711.06402",
                "DOI": "10.1186/s12911-018-0677-8",
                "CorpusId": 3340838,
                "PubMed": "30537977"
            },
            "abstract": null,
            "referenceCount": 56,
            "citationCount": 319,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-018-0677-8",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2017-11-01",
            "journal": {
                "name": "BMC Medical Informatics and Decision Making",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Avati2017ImprovingPC,\n author = {A. Avati and Kenneth Jung and S. Harman and L. Downing and A. Ng and N. Shah},\n booktitle = {IEEE International Conference on Bioinformatics and Biomedicine},\n journal = {BMC Medical Informatics and Decision Making},\n title = {Improving palliative care with deep learning},\n volume = {18},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cafcdab811c7834c9c09960e09f9feb045efc945",
            "@type": "ScholarlyArticle",
            "paperId": "cafcdab811c7834c9c09960e09f9feb045efc945",
            "corpusId": 104291869,
            "url": "https://www.semanticscholar.org/paper/cafcdab811c7834c9c09960e09f9feb045efc945",
            "title": "Label Propagation for Deep Semi-Supervised Learning",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2936604471",
                "DBLP": "journals/corr/abs-1904-04717",
                "ArXiv": "1904.04717",
                "DOI": "10.1109/CVPR.2019.00521",
                "CorpusId": 104291869
            },
            "abstract": "Semi-supervised learning is becoming increasingly important because it can combine data carefully labeled by humans with abundant unlabeled data to train deep neural networks. Classic methods on semi-supervised learning that have focused on transductive learning have not been fully exploited in the inductive framework followed by modern deep learning. The same holds for the manifold assumption---that similar examples should get the same prediction. In this work, we employ a transductive label propagation method that is based on the manifold assumption to make predictions on the entire dataset and use these predictions to generate pseudo-labels for the unlabeled data and train a deep neural network. At the core of the transductive method lies a nearest neighbor graph of the dataset that we create based on the embeddings of the same network. Therefore our learning process iterates between these two steps. We improve performance on several datasets especially in the few labels regime and show that our work is complementary to current state of the art.",
            "referenceCount": 45,
            "citationCount": 491,
            "influentialCitationCount": 47,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1904.04717",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-09",
            "journal": {
                "name": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Iscen2019LabelPF,\n author = {Ahmet Iscen and Giorgos Tolias and Yannis Avrithis and Ond\u0159ej Chum},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {5065-5074},\n title = {Label Propagation for Deep Semi-Supervised Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:44229bef9966e65e7b13c2c9fe867afd9dd8b450",
            "@type": "ScholarlyArticle",
            "paperId": "44229bef9966e65e7b13c2c9fe867afd9dd8b450",
            "corpusId": 7017535,
            "url": "https://www.semanticscholar.org/paper/44229bef9966e65e7b13c2c9fe867afd9dd8b450",
            "title": "Deep Learning for Event-Driven Stock Prediction",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2296438605",
                "DBLP": "conf/ijcai/DingZLD15",
                "CorpusId": 7017535
            },
            "abstract": "We propose a deep learning method for event-driven stock market prediction. First, events are extracted from news text, and represented as dense vectors, trained using a novel neural tensor network. Second, a deep convolutional neural network is used to model both short-term and long-term influences of events on stock price movements. Experimental results show that our model can achieve nearly 6% improvements on S&P 500 index prediction and individual stock prediction, respectively, compared to state-of-the-art baseline methods. In addition, market simulation results show that our system is more capable of making profits than previously reported systems trained on S&P 500 stock historical data.",
            "referenceCount": 36,
            "citationCount": 627,
            "influentialCitationCount": 52,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-07-25",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ding2015DeepLF,\n author = {Xiao Ding and Yue Zhang and Ting Liu and Junwen Duan},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {2327-2333},\n title = {Deep Learning for Event-Driven Stock Prediction},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0cb28924c02aa06e6de0d2315605e8193d9c8d46",
            "@type": "ScholarlyArticle",
            "paperId": "0cb28924c02aa06e6de0d2315605e8193d9c8d46",
            "corpusId": 3330242,
            "url": "https://www.semanticscholar.org/paper/0cb28924c02aa06e6de0d2315605e8193d9c8d46",
            "title": "Deep learning of binary hash codes for fast image retrieval",
            "venue": "2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/cvpr/LinYHC15",
                "MAG": "1913628733",
                "DOI": "10.1109/CVPRW.2015.7301269",
                "CorpusId": 3330242
            },
            "abstract": "Approximate nearest neighbor search is an efficient strategy for large-scale image retrieval. Encouraged by the recent advances in convolutional neural networks (CNNs), we propose an effective deep learning framework to generate binary hash codes for fast image retrieval. Our idea is that when the data labels are available, binary codes can be learned by employing a hidden layer for representing the latent concepts that dominate the class labels. The utilization of the CNN also allows for learning image representations. Unlike other supervised methods that require pair-wised inputs for binary code learning, our method learns hash codes and image representations in a point-wised manner, making it suitable for large-scale datasets. Experimental results show that our method outperforms several state-of-the-art hashing algorithms on the CIFAR-10 and MNIST datasets. We further demonstrate its scalability and efficacy on a large-scale dataset of 1 million clothing images.",
            "referenceCount": 33,
            "citationCount": 563,
            "influentialCitationCount": 59,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.iis.sinica.edu.tw/papers/song/18379-F.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-06-07",
            "journal": {
                "name": "2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lin2015DeepLO,\n author = {Kevin Lin and Huei-Fang Yang and Jen-Hao Hsiao and Chu-Song Chen},\n booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},\n journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},\n pages = {27-35},\n title = {Deep learning of binary hash codes for fast image retrieval},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1ddd174935c7bb4f0c341273f541da14cf8aa5d8",
            "@type": "ScholarlyArticle",
            "paperId": "1ddd174935c7bb4f0c341273f541da14cf8aa5d8",
            "corpusId": 10064123,
            "url": "https://www.semanticscholar.org/paper/1ddd174935c7bb4f0c341273f541da14cf8aa5d8",
            "title": "Learning to decode linear codes using deep learning",
            "venue": "Allerton Conference on Communication, Control, and Computing",
            "publicationVenue": {
                "id": "urn:research:e3e363b2-60f3-46d7-9067-5deaddc3f3f2",
                "name": "Allerton Conference on Communication, Control, and Computing",
                "alternate_names": [
                    "Allerton",
                    "T Conf Commun Control Comput"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2963408536",
                "ArXiv": "1607.04793",
                "DBLP": "conf/allerton/NachmaniBB16",
                "DOI": "10.1109/ALLERTON.2016.7852251",
                "CorpusId": 10064123
            },
            "abstract": "A novel deep learning method for improving the belief propagation algorithm is proposed. The method generalizes the standard belief propagation algorithm by assigning weights to the edges of the Tanner graph. These edges are then trained using deep learning techniques. A well-known property of the belief propagation algorithm is the independence of the performance on the transmitted codeword. A crucial property of our new method is that our decoder preserved this property. Furthermore, this property allows us to learn only a single codeword instead of exponential number of codewords. Improvements over the belief propagation algorithm are demonstrated for various high density parity check codes.",
            "referenceCount": 23,
            "citationCount": 376,
            "influentialCitationCount": 38,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1607.04793",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-07-16",
            "journal": {
                "name": "2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Nachmani2016LearningTD,\n author = {Eliya Nachmani and Yair Be\u2019ery and D. Burshtein},\n booktitle = {Allerton Conference on Communication, Control, and Computing},\n journal = {2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},\n pages = {341-346},\n title = {Learning to decode linear codes using deep learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dc8861b4ab6799be542829ae1ace13f23cf807cd",
            "@type": "ScholarlyArticle",
            "paperId": "dc8861b4ab6799be542829ae1ace13f23cf807cd",
            "corpusId": 1900475,
            "url": "https://www.semanticscholar.org/paper/dc8861b4ab6799be542829ae1ace13f23cf807cd",
            "title": "Learning Deep CNN Denoiser Prior for Image Restoration",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/ZhangZGZ17",
                "ArXiv": "1704.03264",
                "MAG": "2951070760",
                "DOI": "10.1109/cvpr.2017.300",
                "CorpusId": 1900475
            },
            "abstract": "Model-based optimization methods and discriminative learning methods have been the two dominant strategies for solving various inverse problems in low-level vision. Typically, those two kinds of methods have their respective merits and drawbacks, e.g., model-based optimization methods are flexible for handling different inverse problems but are usually time-consuming with sophisticated priors for the purpose of good performance, in the meanwhile, discriminative learning methods have fast testing speed but their application range is greatly restricted by the specialized task. Recent works have revealed that, with the aid of variable splitting techniques, denoiser prior can be plugged in as a modular part of model-based optimization methods to solve other inverse problems (e.g., deblurring). Such an integration induces considerable advantage when the denoiser is obtained via discriminative learning. However, the study of integration with fast discriminative denoiser prior is still lacking. To this end, this paper aims to train a set of fast and effective CNN (convolutional neural network) denoisers and integrate them into model-based optimization method to solve other inverse problems. Experimental results demonstrate that the learned set of denoisers can not only achieve promising Gaussian denoising results but also can be used as prior to deliver good performance for various low-level vision applications.",
            "referenceCount": 70,
            "citationCount": 1540,
            "influentialCitationCount": 296,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1704.03264",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-04-11",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2017LearningDC,\n author = {K. Zhang and W. Zuo and Shuhang Gu and Lei Zhang},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {2808-2817},\n title = {Learning Deep CNN Denoiser Prior for Image Restoration},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4c05d7caa357148f0bbd61720bdd35f0bc05eb81",
            "@type": "ScholarlyArticle",
            "paperId": "4c05d7caa357148f0bbd61720bdd35f0bc05eb81",
            "corpusId": 5389801,
            "url": "https://www.semanticscholar.org/paper/4c05d7caa357148f0bbd61720bdd35f0bc05eb81",
            "title": "Dueling Network Architectures for Deep Reinforcement Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/icml/WangSHHLF16",
                "ArXiv": "1511.06581",
                "MAG": "2951799221",
                "CorpusId": 5389801
            },
            "abstract": "In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional networks, LSTMs, or auto-encoders. In this paper, we present a new neural network architecture for model-free reinforcement learning. Our dueling network represents two separate estimators: one for the state value function and one for the state-dependent action advantage function. The main benefit of this factoring is to generalize learning across actions without imposing any change to the underlying reinforcement learning algorithm. Our results show that this architecture leads to better policy evaluation in the presence of many similar-valued actions. Moreover, the dueling architecture enables our RL agent to outperform the state-of-the-art on the Atari 2600 domain.",
            "referenceCount": 28,
            "citationCount": 2929,
            "influentialCitationCount": 485,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-11-20",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2015DuelingNA,\n author = {Ziyun Wang and T. Schaul and Matteo Hessel and H. V. Hasselt and Marc Lanctot and Nando de Freitas},\n booktitle = {International Conference on Machine Learning},\n pages = {1995-2003},\n title = {Dueling Network Architectures for Deep Reinforcement Learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:391b86cf16c2702dcc4beee55a6dd6d3bd7cf27b",
            "@type": "ScholarlyArticle",
            "paperId": "391b86cf16c2702dcc4beee55a6dd6d3bd7cf27b",
            "corpusId": 207217044,
            "url": "https://www.semanticscholar.org/paper/391b86cf16c2702dcc4beee55a6dd6d3bd7cf27b",
            "title": "Deep Learning for Content-Based Image Retrieval: A Comprehensive Study",
            "venue": "ACM Multimedia",
            "publicationVenue": {
                "id": "urn:research:f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                "name": "ACM Multimedia",
                "alternate_names": [
                    "MM"
                ],
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2123229215",
                "DBLP": "conf/mm/WanWHWZZL14",
                "DOI": "10.1145/2647868.2654948",
                "CorpusId": 207217044
            },
            "abstract": "Learning effective feature representations and similarity measures are crucial to the retrieval performance of a content-based image retrieval (CBIR) system. Despite extensive research efforts for decades, it remains one of the most challenging open problems that considerably hinders the successes of real-world CBIR systems. The key challenge has been attributed to the well-known ``semantic gap'' issue that exists between low-level image pixels captured by machines and high-level semantic concepts perceived by human. Among various techniques, machine learning has been actively investigated as a possible direction to bridge the semantic gap in the long term. Inspired by recent successes of deep learning techniques for computer vision and other applications, in this paper, we attempt to address an open problem: if deep learning is a hope for bridging the semantic gap in CBIR and how much improvements in CBIR tasks can be achieved by exploring the state-of-the-art deep learning techniques for learning feature representations and similarity measures. Specifically, we investigate a framework of deep learning with application to CBIR tasks with an extensive set of empirical studies by examining a state-of-the-art deep learning method (Convolutional Neural Networks) for CBIR tasks under varied settings. From our empirical studies, we find some encouraging results and summarize some important insights for future research.",
            "referenceCount": 61,
            "citationCount": 839,
            "influentialCitationCount": 41,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book"
            ],
            "publicationDate": "2014-11-03",
            "journal": {
                "name": "Proceedings of the 22nd ACM international conference on Multimedia",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wan2014DeepLF,\n author = {Ji Wan and Dayong Wang and S. Hoi and Pengcheng Wu and Jianke Zhu and Yongdong Zhang and Jintao Li},\n booktitle = {ACM Multimedia},\n journal = {Proceedings of the 22nd ACM international conference on Multimedia},\n title = {Deep Learning for Content-Based Image Retrieval: A Comprehensive Study},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8fbb115c578e8bfbcc1615bd7af990396abf6776",
            "@type": "ScholarlyArticle",
            "paperId": "8fbb115c578e8bfbcc1615bd7af990396abf6776",
            "corpusId": 17786716,
            "url": "https://www.semanticscholar.org/paper/8fbb115c578e8bfbcc1615bd7af990396abf6776",
            "title": "Identity Matters in Deep Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/iclr/HardtM17",
                "MAG": "2565538933",
                "ArXiv": "1611.04231",
                "CorpusId": 17786716
            },
            "abstract": "An emerging design principle in deep learning is that each layer of a deep artificial neural network should be able to easily express the identity transformation. This idea not only motivated various normalization techniques, such as \\emph{batch normalization}, but was also key to the immense success of \\emph{residual networks}. \nIn this work, we put the principle of \\emph{identity parameterization} on a more solid theoretical footing alongside further empirical progress. We first give a strikingly simple proof that arbitrarily deep linear residual networks have no spurious local optima. The same result for linear feed-forward networks in their standard parameterization is substantially more delicate. Second, we show that residual networks with ReLu activations have universal finite-sample expressivity in the sense that the network can represent any function of its sample provided that the model has more parameters than the sample size. \nDirectly inspired by our theory, we experiment with a radically simple residual architecture consisting of only residual convolutional layers and ReLu activations, but no batch normalization, dropout, or max pool. Our model improves significantly on previous all-convolutional networks on the CIFAR10, CIFAR100, and ImageNet classification benchmarks.",
            "referenceCount": 18,
            "citationCount": 361,
            "influentialCitationCount": 32,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-04",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1611.04231"
            },
            "citationStyles": {
                "bibtex": "@Article{Hardt2016IdentityMI,\n author = {Moritz Hardt and Tengyu Ma},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Identity Matters in Deep Learning},\n volume = {abs/1611.04231},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:06fe23c7b8a1336b8f63d85d0482674d559762bf",
            "@type": "ScholarlyArticle",
            "paperId": "06fe23c7b8a1336b8f63d85d0482674d559762bf",
            "corpusId": 20117583,
            "url": "https://www.semanticscholar.org/paper/06fe23c7b8a1336b8f63d85d0482674d559762bf",
            "title": "Searching for prostate cancer by fully automated magnetic resonance imaging classification: deep learning versus non-deep learning",
            "venue": "Scientific Reports",
            "publicationVenue": {
                "id": "urn:research:f99f77b7-b1b6-44d3-984a-f288e9884b9b",
                "name": "Scientific Reports",
                "alternate_names": [
                    "Sci Rep"
                ],
                "issn": "2045-2322",
                "url": "http://www.nature.com/srep/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2767969013",
                "PubMedCentral": "5684419",
                "DOI": "10.1038/s41598-017-15720-y",
                "CorpusId": 20117583,
                "PubMed": "29133818"
            },
            "abstract": null,
            "referenceCount": 42,
            "citationCount": 155,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41598-017-15720-y.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-13",
            "journal": {
                "name": "Scientific Reports",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2017SearchingFP,\n author = {Xinggang Wang and W. Yang and J. Weinreb and Juan Han and Qiubai Li and Xiangchuang Kong and Yongluan Yan and Zan Ke and Bo Luo and Tao Liu and Liang Wang},\n booktitle = {Scientific Reports},\n journal = {Scientific Reports},\n title = {Searching for prostate cancer by fully automated magnetic resonance imaging classification: deep learning versus non-deep learning},\n volume = {7},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7601b995303f953955004db7b9b8b206c0e02ff8",
            "@type": "ScholarlyArticle",
            "paperId": "7601b995303f953955004db7b9b8b206c0e02ff8",
            "corpusId": 2056019,
            "url": "https://www.semanticscholar.org/paper/7601b995303f953955004db7b9b8b206c0e02ff8",
            "title": "Learning Structured Sparsity in Deep Neural Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1608.03665",
                "DBLP": "journals/corr/WenWWCL16",
                "MAG": "2513419314",
                "CorpusId": 2056019
            },
            "abstract": "High demand for computation resources severely hinders deployment of large-scale Deep Neural Networks (DNN) in resource constrained devices. In this work, we propose a Structured Sparsity Learning (SSL) method to regularize the structures (i.e., filters, channels, filter shapes, and layer depth) of DNNs. SSL can: (1) learn a compact structure from a bigger DNN to reduce computation cost; (2) obtain a hardware-friendly structured sparsity of DNN to efficiently accelerate the DNNs evaluation. Experimental results show that SSL achieves on average 5.1x and 3.1x speedups of convolutional layer computation of AlexNet against CPU and GPU, respectively, with off-the-shelf libraries. These speedups are about twice speedups of non-structured sparsity; (3) regularize the DNN structure to improve classification accuracy. The results show that for CIFAR-10, regularization on layer depth can reduce 20 layers of a Deep Residual Network (ResNet) to 18 layers while improve the accuracy from 91.25% to 92.60%, which is still slightly higher than that of original ResNet with 32 layers. For AlexNet, structure regularization by SSL also reduces the error by around ~1%. Open source code is in this https URL",
            "referenceCount": 22,
            "citationCount": 2023,
            "influentialCitationCount": 224,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-08-12",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1608.03665"
            },
            "citationStyles": {
                "bibtex": "@Article{Wen2016LearningSS,\n author = {W. Wen and Chunpeng Wu and Yandan Wang and Yiran Chen and Hai Helen Li},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Learning Structured Sparsity in Deep Neural Networks},\n volume = {abs/1608.03665},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a9c8124b18c0e843878f2df4d49da6f250dc06e7",
            "@type": "ScholarlyArticle",
            "paperId": "a9c8124b18c0e843878f2df4d49da6f250dc06e7",
            "corpusId": 3461501,
            "url": "https://www.semanticscholar.org/paper/a9c8124b18c0e843878f2df4d49da6f250dc06e7",
            "title": "Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/icml/DepewegHDU18",
                "MAG": "2788755844",
                "CorpusId": 3461501
            },
            "abstract": "\u00a9 2018 35th International Conference on Machine Learning, ICML 2018. All rights reserved. Bayesian neural networks with latent variables are scalable and flexible probabilistic models: They account for uncertainty in the estimation of the network weights and, by making use of latent variables, can capture complex noise patterns in the : data. Using these models we show how to per- \u2217 form and utilize a decomposition of uncertainty in \u2022 aleatoric and epistemic components for decision making purposes. This allows us to successfully identify informative points for active learning of functions with heteroscedastic and bimodal noise. ' t Using the decomposition we further define a novel risk-sensitive criterion for reinforcement learning to identify policies that balance expected cost, model-bias and noise aversion.",
            "referenceCount": 40,
            "citationCount": 280,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-10-19",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Depeweg2017DecompositionOU,\n author = {Stefan Depeweg and Jos\u00e9 Miguel Hern\u00e1ndez-Lobato and F. Doshi-Velez and S. Udluft},\n booktitle = {International Conference on Machine Learning},\n pages = {1192-1201},\n title = {Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:78a11b7d2d7e1b19d92d2afd51bd3624eca86c3c",
            "@type": "ScholarlyArticle",
            "paperId": "78a11b7d2d7e1b19d92d2afd51bd3624eca86c3c",
            "corpusId": 911406,
            "url": "https://www.semanticscholar.org/paper/78a11b7d2d7e1b19d92d2afd51bd3624eca86c3c",
            "title": "Improved Deep Metric Learning with Multi-class N-pair Loss Objective",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2555897561",
                "DBLP": "conf/nips/Sohn16",
                "CorpusId": 911406
            },
            "abstract": "Deep metric learning has gained much popularity in recent years, following the success of deep learning. However, existing frameworks of deep metric learning based on contrastive loss and triplet loss often suffer from slow convergence, partially because they employ only one negative example while not interacting with the other negative classes in each update. In this paper, we propose to address this problem with a new metric learning objective called multi-class N-pair loss. The proposed objective function firstly generalizes triplet loss by allowing joint comparison among more than one negative examples - more specifically, N-1 negative examples - and secondly reduces the computational burden of evaluating deep embedding vectors via an efficient batch construction strategy using only N pairs of examples, instead of (N+1) x N. We demonstrate the superiority of our proposed loss to the triplet loss as well as other competing loss functions for a variety of tasks on several visual recognition benchmark, including fine-grained object recognition and verification, image clustering and retrieval, and face verification and identification.",
            "referenceCount": 32,
            "citationCount": 1637,
            "influentialCitationCount": 185,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-12-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sohn2016ImprovedDM,\n author = {Kihyuk Sohn},\n booktitle = {Neural Information Processing Systems},\n pages = {1849-1857},\n title = {Improved Deep Metric Learning with Multi-class N-pair Loss Objective},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d6c850b41500be8cfadb5aa710934d9c5c7bc100",
            "@type": "ScholarlyArticle",
            "paperId": "d6c850b41500be8cfadb5aa710934d9c5c7bc100",
            "corpusId": 3634811,
            "url": "https://www.semanticscholar.org/paper/d6c850b41500be8cfadb5aa710934d9c5c7bc100",
            "title": "Towards deep learning with segregated dendrites",
            "venue": "eLife",
            "publicationVenue": {
                "id": "urn:research:07365b9a-c0ce-4dd3-b93b-a02e1c81e0c6",
                "name": "eLife",
                "alternate_names": null,
                "issn": "2050-084X",
                "url": "https://epub.uni-regensburg.de/40444/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2529004582",
                "PubMedCentral": "5716677",
                "ArXiv": "1610.00161",
                "DOI": "10.7554/eLife.22901",
                "CorpusId": 3634811,
                "PubMed": "29205151"
            },
            "abstract": "Deep learning has led to significant advances in artificial intelligence, in part, by adopting strategies motivated by neurophysiology. However, it is unclear whether deep learning could occur in the real brain. Here, we show that a deep learning algorithm that utilizes multi-compartment neurons might help us to understand how the neocortex optimizes cost functions. Like neocortical pyramidal neurons, neurons in our model receive sensory information and higher-order feedback in electrotonically segregated compartments. Thanks to this segregation, neurons in different layers of the network can coordinate synaptic weight updates. As a result, the network learns to categorize images better than a single layer network. Furthermore, we show that our algorithm takes advantage of multilayer architectures to identify useful higher-order representations\u2014the hallmark of deep learning. This work demonstrates that deep learning can be achieved using segregated dendritic compartments, which may help to explain the morphology of neocortical pyramidal neurons.",
            "referenceCount": 81,
            "citationCount": 337,
            "influentialCitationCount": 20,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Medicine",
                "Computer Science",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-10-01",
            "journal": {
                "name": "eLife",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Guerguiev2016TowardsDL,\n author = {Jordan Guerguiev and T. Lillicrap and B. Richards},\n booktitle = {eLife},\n journal = {eLife},\n title = {Towards deep learning with segregated dendrites},\n volume = {6},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bfbdf36d50066c39dedf688150d63ba4b84d7e52",
            "@type": "ScholarlyArticle",
            "paperId": "bfbdf36d50066c39dedf688150d63ba4b84d7e52",
            "corpusId": 2605091,
            "url": "https://www.semanticscholar.org/paper/bfbdf36d50066c39dedf688150d63ba4b84d7e52",
            "title": "DroidDetector: Android Malware Characterization and Detection Using Deep Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2313513770",
                "DOI": "10.1109/TST.2016.7399288",
                "CorpusId": 2605091
            },
            "abstract": "Smartphones and mobile tablets are rapidly becoming indispensable in daily life. Android has been the most popular mobile operating system since 2012. However, owing to the open nature of Android, countless malwares are hidden in a large number of benign apps in Android markets that seriously threaten Android security. Deep learning is a new area of machine learning research that has gained increasing attention in artificial intelligence. In this study, we propose to associate the features from the static analysis with features from dynamic analysis of Android apps and characterize malware using deep learning techniques. We implement an online deep-learning-based Android malware detection engine (DroidDetector) that can automatically detect whether an app is a malware or not. With thousands of Android apps, we thoroughly test DroidDetector and perform an indepth analysis on the features that deep learning essentially exploits to characterize malware. The results show that deep learning is suitable for characterizing Android malware and especially effective with the availability of more training data. DroidDetector can achieve 96.76% detection accuracy, which outperforms traditional machine learning techniques. An evaluation of ten popular anti-virus softwares demonstrates the urgency of advancing our capabilities in Android malware detection.",
            "referenceCount": 29,
            "citationCount": 356,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/5971803/7399276/07399288.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2016-02-04",
            "journal": {
                "name": "Tsinghua Science & Technology",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Yuan2016DroidDetectorAM,\n author = {Zhenlong Yuan and Yongqiang Lu and Y. Xue},\n journal = {Tsinghua Science & Technology},\n pages = {114-123},\n title = {DroidDetector: Android Malware Characterization and Detection Using Deep Learning},\n volume = {21},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6bf513fc03d1d67b908a81abe856477ea5fcfbf4",
            "@type": "ScholarlyArticle",
            "paperId": "6bf513fc03d1d67b908a81abe856477ea5fcfbf4",
            "corpusId": 3040291,
            "url": "https://www.semanticscholar.org/paper/6bf513fc03d1d67b908a81abe856477ea5fcfbf4",
            "title": "Benchmarking State-of-the-Art Deep Learning Software Tools",
            "venue": "International Conference on Cloud Computing and Big Data",
            "publicationVenue": {
                "id": "urn:research:9af0c4a9-9d20-428b-b002-352f06623d40",
                "name": "International Conference on Cloud Computing and Big Data",
                "alternate_names": [
                    "Int Conf Cloud Comput Big Data",
                    "CCBD",
                    "CloudCom-Asia"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2514858228",
                "DBLP": "conf/ccbd/ShiWXC16",
                "ArXiv": "1608.07249",
                "DOI": "10.1109/CCBD.2016.029",
                "CorpusId": 3040291
            },
            "abstract": "Deep learning has been shown as a successful machine learning method for a variety of tasks, and its popularity results in numerous open-source deep learning software tools coming to public. Training a deep network is usually a very time-consuming process. To address the huge computational challenge in deep learning, many tools exploit hardware features such as multi-core CPUs and many-core GPUs to shorten the training and inference time. However, different tools exhibit different features and running performance when they train different types of deep networks on different hardware platforms, making it difficult for end users to select an appropriate pair of software and hardware. In this paper, we present our attempt to benchmark several state-of-the-art GPU-accelerated deep learning software tools, including Caffe, CNTK, TensorFlow, and Torch. We focus on evaluating the running time performance (i.e., speed) of these tools with three popular types of neural networks on two representative CPU platforms and three representative GPU platforms. Our contribution is two-fold. First, for end users of deep learning software tools, our benchmarking results can serve as a reference to selecting appropriate hardware platforms and software tools. Second, for developers of deep learning software tools, our in-depth analysis points out possible future directions to further optimize the running performance.",
            "referenceCount": 55,
            "citationCount": 307,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1608.07249",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-08-25",
            "journal": {
                "name": "2016 7th International Conference on Cloud Computing and Big Data (CCBD)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shi2016BenchmarkingSD,\n author = {S. Shi and Qiang Wang and Pengfei Xu and Xiaowen Chu},\n booktitle = {International Conference on Cloud Computing and Big Data},\n journal = {2016 7th International Conference on Cloud Computing and Big Data (CCBD)},\n pages = {99-104},\n title = {Benchmarking State-of-the-Art Deep Learning Software Tools},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d1e4365de165463e51134f10bf3939f2b00a6667",
            "@type": "ScholarlyArticle",
            "paperId": "d1e4365de165463e51134f10bf3939f2b00a6667",
            "corpusId": 1275282,
            "url": "https://www.semanticscholar.org/paper/d1e4365de165463e51134f10bf3939f2b00a6667",
            "title": "Deep learning with Elastic Averaging SGD",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2950678211",
                "DBLP": "journals/corr/ZhangCL14a",
                "ArXiv": "1412.6651",
                "CorpusId": 1275282
            },
            "abstract": "We study the problem of stochastic optimization for deep learning in the parallel computing environment under communication constraints. A new algorithm is proposed in this setting where the communication and coordination of work among concurrent processes (local workers), is based on an elastic force which links the parameters they compute with a center variable stored by the parameter server (master). The algorithm enables the local workers to perform more exploration, i.e. the algorithm allows the local variables to fluctuate further from the center variable by reducing the amount of communication between local workers and the master. We empirically demonstrate that in the deep learning setting, due to the existence of many local optima, allowing more exploration can lead to the improved performance. We propose synchronous and asynchronous variants of the new algorithm. We provide the stability analysis of the asynchronous variant in the round-robin scheme and compare it with the more common parallelized method ADMM. We show that the stability of EASGD is guaranteed when a simple stability condition is satisfied, which is not the case for ADMM. We additionally propose the momentum-based version of our algorithm that can be applied in both synchronous and asynchronous settings. Asynchronous variant of the algorithm is applied to train convolutional neural networks for image classification on the CIFAR and ImageNet datasets. Experiments demonstrate that the new algorithm accelerates the training of deep architectures compared to DOWNPOUR and other common baseline approaches and furthermore is very communication efficient.",
            "referenceCount": 34,
            "citationCount": 550,
            "influentialCitationCount": 89,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-12-20",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2014DeepLW,\n author = {Sixin Zhang and A. Choroma\u0144ska and Yann LeCun},\n booktitle = {Neural Information Processing Systems},\n pages = {685-693},\n title = {Deep learning with Elastic Averaging SGD},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ae9e5e72aefd19b81c1fe75d7baf6c0bedad75e5",
            "@type": "ScholarlyArticle",
            "paperId": "ae9e5e72aefd19b81c1fe75d7baf6c0bedad75e5",
            "corpusId": 12757870,
            "url": "https://www.semanticscholar.org/paper/ae9e5e72aefd19b81c1fe75d7baf6c0bedad75e5",
            "title": "Deep Transfer Learning with Joint Adaptation Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2408201877",
                "ArXiv": "1605.06636",
                "DBLP": "conf/icml/LongZ0J17",
                "CorpusId": 12757870
            },
            "abstract": "Deep networks have been successfully applied to learn transferable features for adapting models from a source domain to a different target domain. In this paper, we present joint adaptation networks (JAN), which learn a transfer network by aligning the joint distributions of multiple domain-specific layers across domains based on a joint maximum mean discrepancy (JMMD) criterion. Adversarial training strategy is adopted to maximize JMMD such that the distributions of the source and target domains are made more distinguishable. Learning can be performed by stochastic gradient descent with the gradients computed by back-propagation in linear-time. Experiments testify that our model yields state of the art results on standard datasets.",
            "referenceCount": 46,
            "citationCount": 1943,
            "influentialCitationCount": 308,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-05-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1605.06636"
            },
            "citationStyles": {
                "bibtex": "@Article{Long2016DeepTL,\n author = {Mingsheng Long and Hanhua Zhu and Jianmin Wang and Michael I. Jordan},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Deep Transfer Learning with Joint Adaptation Networks},\n volume = {abs/1605.06636},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:431a1a620b762750ac92b35d97de67169eb8069c",
            "@type": "ScholarlyArticle",
            "paperId": "431a1a620b762750ac92b35d97de67169eb8069c",
            "corpusId": 6469688,
            "url": "https://www.semanticscholar.org/paper/431a1a620b762750ac92b35d97de67169eb8069c",
            "title": "DLAU: A Scalable Deep Learning Accelerator Unit on FPGA",
            "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
            "publicationVenue": {
                "id": "urn:research:e86c30b0-c1dd-4f0e-be5e-22af711f7d5f",
                "name": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
                "alternate_names": [
                    "IEEE Trans Comput Des Integr Circuit Syst"
                ],
                "issn": "0278-0070",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=43"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1605.06894",
                "DBLP": "journals/corr/WangYGLXZ16",
                "MAG": "2788328524",
                "DOI": "10.1109/TCAD.2016.2587683",
                "CorpusId": 6469688
            },
            "abstract": "As the emerging field of machine learning, deep learning shows excellent ability in solving complex learning problems. However, the size of the networks becomes increasingly large scale due to the demands of the practical applications, which poses significant challenge to construct a high performance implementations of deep learning neural networks. In order to improve the performance as well as to maintain the low power cost, in this paper we design deep learning accelerator unit (DLAU), which is a scalable accelerator architecture for large-scale deep learning networks using field-programmable gate array (FPGA) as the hardware prototype. The DLAU accelerator employs three pipelined processing units to improve the throughput and utilizes tile techniques to explore locality for deep learning applications. Experimental results on the state-of-the-art Xilinx FPGA board demonstrate that the DLAU accelerator is able to achieve up to  $36.1 {\\times }$  speedup comparing to the Intel Core2 processors, with the power consumption at 234 mW.",
            "referenceCount": 11,
            "citationCount": 272,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1605.06894",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-05-23",
            "journal": {
                "name": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2016DLAUAS,\n author = {Chao Wang and Lei Gong and Qi Yu and Xi Li and Yuan Xie and Xuehai Zhou},\n booktitle = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},\n journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},\n pages = {513-517},\n title = {DLAU: A Scalable Deep Learning Accelerator Unit on FPGA},\n volume = {36},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6f4065f0cc99a0839b0248ffb4457e5f0277b30d",
            "@type": "ScholarlyArticle",
            "paperId": "6f4065f0cc99a0839b0248ffb4457e5f0277b30d",
            "corpusId": 18235792,
            "url": "https://www.semanticscholar.org/paper/6f4065f0cc99a0839b0248ffb4457e5f0277b30d",
            "title": "Domain Adaptation for Large-Scale Sentiment Classification: A Deep Learning Approach",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "22861983",
                "DBLP": "conf/icml/GlorotBB11",
                "CorpusId": 18235792
            },
            "abstract": "The exponential increase in the availability of online reviews and recommendations makes sentiment classification an interesting topic in academic and industrial research. Reviews can span so many different domains that it is difficult to gather annotated training data for all of them. Hence, this paper studies the problem of domain adaptation for sentiment classifiers, hereby a system is trained on labeled reviews from one source domain but is meant to be deployed on another. We propose a deep learning approach which learns to extract a meaningful representation for each review in an unsupervised fashion. Sentiment classifiers trained with this high-level feature representation clearly outperform state-of-the-art methods on a benchmark composed of reviews of 4 types of Amazon products. Furthermore, this method scales well and allowed us to successfully perform domain adaptation on a larger industrial-strength dataset of 22 domains.",
            "referenceCount": 28,
            "citationCount": 1738,
            "influentialCitationCount": 121,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2011-06-28",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Glorot2011DomainAF,\n author = {Xavier Glorot and Antoine Bordes and Yoshua Bengio},\n booktitle = {International Conference on Machine Learning},\n pages = {513-520},\n title = {Domain Adaptation for Large-Scale Sentiment Classification: A Deep Learning Approach},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:04020ef38378005829c3ffdc0b117dcec76842df",
            "@type": "ScholarlyArticle",
            "paperId": "04020ef38378005829c3ffdc0b117dcec76842df",
            "corpusId": 157587749,
            "url": "https://www.semanticscholar.org/paper/04020ef38378005829c3ffdc0b117dcec76842df",
            "title": "Deep Learning for Finance: Deep Portfolios",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2528775566",
                "DOI": "10.2139/ssrn.2838013",
                "CorpusId": 157587749
            },
            "abstract": "We explore the use of deep learning hierarchical models for problems in financial prediction and classification. Financial prediction problems \u2013 such as those presented in designing and pricing securities, constructing portfolios, and risk management \u2013 often involve large data sets with complex data interactions that currently are difficult or impossible to specify in a full economic model. Applying deep learning methods to these problems can produce more useful results than standard methods in finance. In particular, deep learning can detect and exploit interactions in the data that are, at least currently, invisible to any existing financial economic theory.",
            "referenceCount": 18,
            "citationCount": 291,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2016-09-05",
            "journal": {
                "name": "ERN: Other Econometrics: Computer Programs & Software (Topic)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Heaton2016DeepLF,\n author = {J. B. Heaton and Nicholas G. Polson and J. Witte},\n journal = {ERN: Other Econometrics: Computer Programs & Software (Topic)},\n title = {Deep Learning for Finance: Deep Portfolios},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:56136aa0b2c347cbcf3d50821f310c4253155026",
            "@type": "ScholarlyArticle",
            "paperId": "56136aa0b2c347cbcf3d50821f310c4253155026",
            "corpusId": 44177328,
            "url": "https://www.semanticscholar.org/paper/56136aa0b2c347cbcf3d50821f310c4253155026",
            "title": "Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2963960193",
                "ArXiv": "1805.12114",
                "DBLP": "conf/nips/ChuaCML18",
                "CorpusId": 44177328
            },
            "abstract": "Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance. This is especially true with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).",
            "referenceCount": 62,
            "citationCount": 946,
            "influentialCitationCount": 198,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-05-30",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chua2018DeepRL,\n author = {Kurtland Chua and R. Calandra and R. McAllister and S. Levine},\n booktitle = {Neural Information Processing Systems},\n pages = {4759-4770},\n title = {Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9c9ba700f9871a41cfc007658c9ff24f84dc4dcb",
            "@type": "ScholarlyArticle",
            "paperId": "9c9ba700f9871a41cfc007658c9ff24f84dc4dcb",
            "corpusId": 1011245,
            "url": "https://www.semanticscholar.org/paper/9c9ba700f9871a41cfc007658c9ff24f84dc4dcb",
            "title": "Deep Learning with Topological Signatures",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2734579475",
                "ArXiv": "1707.04041",
                "DBLP": "journals/corr/HoferKNU17",
                "CorpusId": 1011245
            },
            "abstract": "Inferring topological and geometrical information from data can offer an alternative perspective on machine learning problems. Methods from topological data analysis, e.g., persistent homology, enable us to obtain such information, typically in the form of summary representations of topological features. However, such topological signatures often come with an unusual structure (e.g., multisets of intervals) that is highly impractical for most machine learning techniques. While many strategies have been proposed to map these topological signatures into machine learning compatible representations, they suffer from being agnostic to the target learning task. In contrast, we propose a technique that enables us to input topological signatures to deep neural networks and learn a task-optimal representation during training. Our approach is realized as a novel input layer with favorable theoretical properties. Classification experiments on 2D object shapes and social network graphs demonstrate the versatility of the approach and, in case of the latter, we even outperform the state-of-the-art by a large margin.",
            "referenceCount": 31,
            "citationCount": 196,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-07-13",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1707.04041"
            },
            "citationStyles": {
                "bibtex": "@Article{Hofer2017DeepLW,\n author = {Christoph Hofer and R. Kwitt and M. Niethammer and A. Uhl},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Deep Learning with Topological Signatures},\n volume = {abs/1707.04041},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0a4804b7bbc943073c3fa7693035be7fd017e324",
            "@type": "ScholarlyArticle",
            "paperId": "0a4804b7bbc943073c3fa7693035be7fd017e324",
            "corpusId": 205687522,
            "url": "https://www.semanticscholar.org/paper/0a4804b7bbc943073c3fa7693035be7fd017e324",
            "title": "Deep Learning in Label-free Cell Classification",
            "venue": "Scientific Reports",
            "publicationVenue": {
                "id": "urn:research:f99f77b7-b1b6-44d3-984a-f288e9884b9b",
                "name": "Scientific Reports",
                "alternate_names": [
                    "Sci Rep"
                ],
                "issn": "2045-2322",
                "url": "http://www.nature.com/srep/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2302517508",
                "PubMedCentral": "4791545",
                "DOI": "10.1038/srep21471",
                "CorpusId": 205687522,
                "PubMed": "26975219"
            },
            "abstract": null,
            "referenceCount": 70,
            "citationCount": 378,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/srep21471.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-03-15",
            "journal": {
                "name": "Scientific Reports",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2016DeepLI,\n author = {C. Chen and A. Mahjoubfar and L. Tai and Ian K. Blaby and A. Huang and K. Niazi and B. Jalali},\n booktitle = {Scientific Reports},\n journal = {Scientific Reports},\n title = {Deep Learning in Label-free Cell Classification},\n volume = {6},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:498238a3bd5fd322fc3ce1572e33bbe3853a356f",
            "@type": "ScholarlyArticle",
            "paperId": "498238a3bd5fd322fc3ce1572e33bbe3853a356f",
            "corpusId": 4884302,
            "url": "https://www.semanticscholar.org/paper/498238a3bd5fd322fc3ce1572e33bbe3853a356f",
            "title": "Deep Reinforcement Learning: A Brief Survey",
            "venue": "IEEE Signal Processing Magazine",
            "publicationVenue": {
                "id": "urn:research:f62e5eab-173a-4e0a-a963-ed8de9835d22",
                "name": "IEEE Signal Processing Magazine",
                "alternate_names": [
                    "IEEE Signal Process Mag"
                ],
                "issn": "1053-5888",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=79"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "3100789280",
                "ArXiv": "1708.05866",
                "DBLP": "journals/spm/ArulkumaranDBB17",
                "DOI": "10.1109/MSP.2017.2743240",
                "CorpusId": 4884302
            },
            "abstract": "Deep reinforcement learning (DRL) is poised to revolutionize the field of artificial intelligence (AI) and represents a step toward building autonomous systems with a higherlevel understanding of the visual world. Currently, deep learning is enabling reinforcement learning (RL) to scale to problems that were previously intractable, such as learning to play video games directly from pixels. DRL algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of RL, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep RL, including the deep Q-network (DQN), trust region policy optimization (TRPO), and asynchronous advantage actor critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via RL. To conclude, we describe several current areas of research within the field.",
            "referenceCount": 181,
            "citationCount": 1894,
            "influentialCitationCount": 119,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1708.05866",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-08-19",
            "journal": {
                "name": "IEEE Signal Processing Magazine",
                "volume": "34"
            },
            "citationStyles": {
                "bibtex": "@Article{Arulkumaran2017DeepRL,\n author = {Kai Arulkumaran and M. Deisenroth and Miles Brundage and A. Bharath},\n booktitle = {IEEE Signal Processing Magazine},\n journal = {IEEE Signal Processing Magazine},\n pages = {26-38},\n title = {Deep Reinforcement Learning: A Brief Survey},\n volume = {34},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:484ad17c926292fbe0d5211540832a8c8a8e958b",
            "@type": "ScholarlyArticle",
            "paperId": "484ad17c926292fbe0d5211540832a8c8a8e958b",
            "corpusId": 16895865,
            "url": "https://www.semanticscholar.org/paper/484ad17c926292fbe0d5211540832a8c8a8e958b",
            "title": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1909320841",
                "DBLP": "conf/icml/RezendeMW14",
                "CorpusId": 16895865
            },
            "abstract": "We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic back-propagation -- rules for back-propagation through stochastic variables -- and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.",
            "referenceCount": 38,
            "citationCount": 4708,
            "influentialCitationCount": 731,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-01-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Rezende2014StochasticBA,\n author = {Danilo Jimenez Rezende and S. Mohamed and Daan Wierstra},\n booktitle = {International Conference on Machine Learning},\n pages = {1278-1286},\n title = {Stochastic Backpropagation and Approximate Inference in Deep Generative Models},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:12806c298e01083a79db77927530367d85939907",
            "@type": "ScholarlyArticle",
            "paperId": "12806c298e01083a79db77927530367d85939907",
            "corpusId": 11919941,
            "url": "https://www.semanticscholar.org/paper/12806c298e01083a79db77927530367d85939907",
            "title": "An Empirical Evaluation of Deep Learning on Highway Driving",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1585377561",
                "DBLP": "journals/corr/HuvalWTKSPARMCM15",
                "ArXiv": "1504.01716",
                "CorpusId": 11919941
            },
            "abstract": "Numerous groups have applied a variety of deep learning techniques to computer vision problems in highway perception scenarios. In this paper, we presented a number of empirical evaluations of recent deep learning advances. Computer vision, combined with deep learning, has the potential to bring about a relatively inexpensive, robust solution to autonomous driving. To prepare deep learning for industry uptake and practical applications, neural networks will require large data sets that represent all possible driving environments and scenarios. We collect a large data set of highway data and apply deep learning and computer vision algorithms to problems such as car and lane detection. We show how existing convolutional neural networks (CNNs) can be used to perform lane and vehicle detection while running at frame rates required for a real-time system. Our results lend credence to the hypothesis that deep learning holds promise for autonomous driving.",
            "referenceCount": 20,
            "citationCount": 557,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-04-07",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1504.01716"
            },
            "citationStyles": {
                "bibtex": "@Article{Huval2015AnEE,\n author = {Brody Huval and Tao Wang and S. Tandon and Jeff Kiske and W. Song and Joel Pazhayampallil and Mykhaylo Andriluka and Pranav Rajpurkar and Toki Migimatsu and Royce Cheng-Yue and Fernando A. Mujica and Adam Coates and A. Ng},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {An Empirical Evaluation of Deep Learning on Highway Driving},\n volume = {abs/1504.01716},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2dcef55a07f8607a819c21fe84131ea269cc2e3c",
            "@type": "ScholarlyArticle",
            "paperId": "2dcef55a07f8607a819c21fe84131ea269cc2e3c",
            "corpusId": 14888175,
            "url": "https://www.semanticscholar.org/paper/2dcef55a07f8607a819c21fe84131ea269cc2e3c",
            "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2129069237",
                "DBLP": "journals/corr/Sohl-DicksteinW15",
                "ArXiv": "1503.03585",
                "CorpusId": 14888175
            },
            "abstract": "A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.",
            "referenceCount": 60,
            "citationCount": 2590,
            "influentialCitationCount": 269,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-03-11",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1503.03585"
            },
            "citationStyles": {
                "bibtex": "@Article{Sohl-Dickstein2015DeepUL,\n author = {Jascha Narain Sohl-Dickstein and Eric A. Weiss and Niru Maheswaranathan and S. Ganguli},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},\n volume = {abs/1503.03585},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a39398f68ae7e042f2ef5009e31b4e6a20fd5736",
            "@type": "ScholarlyArticle",
            "paperId": "a39398f68ae7e042f2ef5009e31b4e6a20fd5736",
            "corpusId": 174799399,
            "url": "https://www.semanticscholar.org/paper/a39398f68ae7e042f2ef5009e31b4e6a20fd5736",
            "title": "Learning Deep Transformer Models for Machine Translation",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/acl/WangLXZLWC19",
                "ACL": "P19-1176",
                "MAG": "2952268781",
                "ArXiv": "1906.01787",
                "DOI": "10.18653/v1/P19-1176",
                "CorpusId": 174799399
            },
            "abstract": "Transformer is the state-of-the-art model in recent machine translation evaluations. Two strands of research are promising to improve models of this kind: the first uses wide networks (a.k.a. Transformer-Big) and has been the de facto standard for development of the Transformer system, and the other uses deeper language representation but faces the difficulty arising from learning deep networks. Here, we continue the line of research on the latter. We claim that a truly deep Transformer model can surpass the Transformer-Big counterpart by 1) proper use of layer normalization and 2) a novel way of passing the combination of previous layers to the next. On WMT\u201916 English-German and NIST OpenMT\u201912 Chinese-English tasks, our deep system (30/25-layer encoder) outperforms the shallow Transformer-Big/Base baseline (6-layer encoder) by 0.4-2.4 BLEU points. As another bonus, the deep model is 1.6X smaller in size and 3X faster in training than Transformer-Big.",
            "referenceCount": 38,
            "citationCount": 486,
            "influentialCitationCount": 48,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1906.01787",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-06-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2019LearningDT,\n author = {Qiang Wang and Bei Li and Tong Xiao and Jingbo Zhu and Changliang Li and Derek F. Wong and Lidia S. Chao},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1810-1822},\n title = {Learning Deep Transformer Models for Machine Translation},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d04d6db5f0df11d0cff57ec7e15134990ac07a4f",
            "@type": "ScholarlyArticle",
            "paperId": "d04d6db5f0df11d0cff57ec7e15134990ac07a4f",
            "corpusId": 207178999,
            "url": "https://www.semanticscholar.org/paper/d04d6db5f0df11d0cff57ec7e15134990ac07a4f",
            "title": "Learning Deep Architectures for AI",
            "venue": "Found. Trends Mach. Learn.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2007,
            "externalIds": {
                "MAG": "2072128103",
                "DBLP": "journals/ftml/Bengio09",
                "DOI": "10.1561/2200000006",
                "CorpusId": 207178999
            },
            "abstract": "Theoretical results strongly suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one needs deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult optimization task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This paper discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks.",
            "referenceCount": 248,
            "citationCount": 8235,
            "influentialCitationCount": 513,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.iro.umontreal.ca/~bengioy/papers/ftml.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Found. Trends Mach. Learn.",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Bengio2007LearningDA,\n author = {Yoshua Bengio},\n booktitle = {Found. Trends Mach. Learn.},\n journal = {Found. Trends Mach. Learn.},\n pages = {1-127},\n title = {Learning Deep Architectures for AI},\n volume = {2},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd",
            "@type": "ScholarlyArticle",
            "paperId": "5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd",
            "corpusId": 4787508,
            "url": "https://www.semanticscholar.org/paper/5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd",
            "title": "Deep Reinforcement Learning from Human Preferences",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2626804490",
                "DBLP": "journals/corr/abs-1706-03741",
                "ArXiv": "1706.03741",
                "CorpusId": 4787508
            },
            "abstract": "For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on less than one percent of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any that have been previously learned from human feedback.",
            "referenceCount": 44,
            "citationCount": 1323,
            "influentialCitationCount": 184,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-06-12",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1706.03741"
            },
            "citationStyles": {
                "bibtex": "@Article{Christiano2017DeepRL,\n author = {P. Christiano and J. Leike and Tom B. Brown and Miljan Martic and S. Legg and Dario Amodei},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Deep Reinforcement Learning from Human Preferences},\n volume = {abs/1706.03741},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5c7e5248d9eb7f373f10277410bf8506160907ea",
            "@type": "ScholarlyArticle",
            "paperId": "5c7e5248d9eb7f373f10277410bf8506160907ea",
            "corpusId": 13753997,
            "url": "https://www.semanticscholar.org/paper/5c7e5248d9eb7f373f10277410bf8506160907ea",
            "title": "All-optical machine learning using diffractive deep neural networks",
            "venue": "Science",
            "publicationVenue": {
                "id": "urn:research:f59506a8-d8bb-4101-b3d4-c4ac3ed03dad",
                "name": "Science",
                "alternate_names": null,
                "issn": "0193-4511",
                "url": "https://www.jstor.org/journal/science"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2798701005",
                "ArXiv": "1804.08711",
                "DBLP": "journals/corr/abs-1804-08711",
                "DOI": "10.1126/science.aat8084",
                "CorpusId": 13753997,
                "PubMed": "30049787"
            },
            "abstract": "All-optical deep learning Deep learning uses multilayered artificial neural networks to learn digitally from large datasets. It then performs advanced identification and classification tasks. To date, these multilayered neural networks have been implemented on a computer. Lin et al. demonstrate all-optical machine learning that uses passive optical components that can be patterned and fabricated with 3D-printing. Their hardware approach comprises stacked layers of diffractive optical elements analogous to an artificial neural network that can be trained to execute complex functions at the speed of light. Science, this issue p. 1004 All-optical deep learning can be implemented with 3D-printed passive optical components. Deep learning has been transforming our ability to execute advanced inference tasks using computers. Here we introduce a physical mechanism to perform machine learning by demonstrating an all-optical diffractive deep neural network (D2NN) architecture that can implement various functions following the deep learning\u2013based design of passive diffractive layers that work collectively. We created 3D-printed D2NNs that implement classification of images of handwritten digits and fashion products, as well as the function of an imaging lens at a terahertz spectrum. Our all-optical deep learning framework can perform, at the speed of light, various complex functions that computer-based neural networks can execute; will find applications in all-optical image analysis, feature detection, and object classification; and will also enable new camera designs and optical components that perform distinctive tasks using D2NNs.",
            "referenceCount": 55,
            "citationCount": 1069,
            "influentialCitationCount": 52,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.science.org/cms/asset/e0345a34-e2a8-46ff-81d8-e68e47e223c6/pap.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-14",
            "journal": {
                "name": "Science",
                "volume": "361"
            },
            "citationStyles": {
                "bibtex": "@Article{Lin2018AllopticalML,\n author = {Xing Lin and Y. Rivenson and N. Yardimci and Muhammed Veli and Yilin Luo and M. Jarrahi and A. Ozcan},\n booktitle = {Science},\n journal = {Science},\n pages = {1004 - 1008},\n title = {All-optical machine learning using diffractive deep neural networks},\n volume = {361},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:66f44806cd46a27f02ceb74bdfd9ad6e77e044ca",
            "@type": "ScholarlyArticle",
            "paperId": "66f44806cd46a27f02ceb74bdfd9ad6e77e044ca",
            "corpusId": 18950272,
            "url": "https://www.semanticscholar.org/paper/66f44806cd46a27f02ceb74bdfd9ad6e77e044ca",
            "title": "Toward an Online Anomaly Intrusion Detection System Based on Deep Learning",
            "venue": "International Conference on Machine Learning and Applications",
            "publicationVenue": {
                "id": "urn:research:f6752838-f268-4a1b-87e7-c5f30a36713c",
                "name": "International Conference on Machine Learning and Applications",
                "alternate_names": [
                    "Int Conf Mach Learn Appl",
                    "ICMLA"
                ],
                "issn": null,
                "url": "http://www.icmla-conference.org/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/icmla/AlrawashdehP16",
                "MAG": "2584408238",
                "DOI": "10.1109/ICMLA.2016.0040",
                "CorpusId": 18950272
            },
            "abstract": "In the past twenty years, progress in intrusion detection has been steady but slow. The biggest challenge is to detect new attacks in real time. In this work, a deep learning approach for anomaly detection using a Restricted Boltzmann Machine (RBM) and a deep belief network are implemented. Our method uses a one-hidden layer RBM to perform unsupervised feature reduction. The resultant weights from this RBM are passed to another RBM producing a deep belief network. The pre-trained weights are passed into a fine tuning layer consisting of a Logistic Regression (LR) classifier with multi-class soft-max. We have implemented the deep learning architecture in C++ in Microsoft Visual Studio 2013 and we use the DARPA KDDCUP'99 dataset to evaluate its performance. Our architecture outperforms previous deep learning methods implemented by Li and Salama in both detection speed and accuracy. We achieve a detection rate of 97.9% on the total 10% KDDCUP'99 test dataset. By improving the training process of the simulation, we are also able to produce a low false negative rate of 2.47%. Although the deficiencies in the KDDCUP'99 dataset are well understood, it still presents machine learning approaches for predicting attacks with a reasonable challenge. Our future work will include applying our machine learning strategy to larger and more challenging datasets, which include larger classes of attacks.",
            "referenceCount": 21,
            "citationCount": 197,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-12-01",
            "journal": {
                "name": "2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Alrawashdeh2016TowardAO,\n author = {Khaled Alrawashdeh and C. Purdy},\n booktitle = {International Conference on Machine Learning and Applications},\n journal = {2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)},\n pages = {195-200},\n title = {Toward an Online Anomaly Intrusion Detection System Based on Deep Learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7a42a314fb5f5062d07edcbb90af8ec14ef39ce8",
            "@type": "ScholarlyArticle",
            "paperId": "7a42a314fb5f5062d07edcbb90af8ec14ef39ce8",
            "corpusId": 3240382,
            "url": "https://www.semanticscholar.org/paper/7a42a314fb5f5062d07edcbb90af8ec14ef39ce8",
            "title": "Modelling uncertainty in deep learning for camera relocalization",
            "venue": "IEEE International Conference on Robotics and Automation",
            "publicationVenue": {
                "id": "urn:research:3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                "name": "IEEE International Conference on Robotics and Automation",
                "alternate_names": [
                    "International Conference on Robotics and Automation",
                    "Int Conf Robot Autom",
                    "ICRA",
                    "IEEE Int Conf Robot Autom"
                ],
                "issn": "2152-4092",
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2950599749",
                "DBLP": "journals/corr/KendallC15",
                "ArXiv": "1509.05909",
                "DOI": "10.1109/ICRA.2016.7487679",
                "CorpusId": 3240382
            },
            "abstract": "We present a robust and real-time monocular six degree of freedom visual relocalization system. We use a Bayesian convolutional neural network to regress the 6-DOF camera pose from a single RGB image. It is trained in an end-to-end manner with no need of additional engineering or graph optimisation. The algorithm can operate indoors and outdoors in real time, taking under 6ms to compute. It obtains approximately 2m and 6\u00b0 accuracy for very large scale outdoor scenes and 0.5m and 10\u00b0 accuracy indoors. Using a Bayesian convolutional neural network implementation we obtain an estimate of the model's relocalization uncertainty and improve state of the art localization accuracy on a large scale outdoor dataset. We leverage the uncertainty measure to estimate metric relocalization error and to detect the presence or absence of the scene in the input image. We show that the model's uncertainty is caused by images being dissimilar to the training dataset in either pose or appearance.",
            "referenceCount": 29,
            "citationCount": 479,
            "influentialCitationCount": 75,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1509.05909",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-09-19",
            "journal": {
                "name": "2016 IEEE International Conference on Robotics and Automation (ICRA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kendall2015ModellingUI,\n author = {Alex Kendall and R. Cipolla},\n booktitle = {IEEE International Conference on Robotics and Automation},\n journal = {2016 IEEE International Conference on Robotics and Automation (ICRA)},\n pages = {4762-4769},\n title = {Modelling uncertainty in deep learning for camera relocalization},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ecff18cabf32db788c6c3d0c3f54a100f0b41367",
            "@type": "ScholarlyArticle",
            "paperId": "ecff18cabf32db788c6c3d0c3f54a100f0b41367",
            "corpusId": 57373825,
            "url": "https://www.semanticscholar.org/paper/ecff18cabf32db788c6c3d0c3f54a100f0b41367",
            "title": "A Theoretical Analysis of Deep Q-Learning",
            "venue": "Conference on Learning for Dynamics & Control",
            "publicationVenue": {
                "id": "urn:research:20e3e0c7-fed4-4b57-a89c-0c9956afb80b",
                "name": "Conference on Learning for Dynamics & Control",
                "alternate_names": [
                    "L4DC",
                    "Conf Learn Dyn  Control"
                ],
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3101940057",
                "DBLP": "conf/l4dc/FanWXY20",
                "ArXiv": "1901.00137",
                "CorpusId": 57373825
            },
            "abstract": "Despite the great empirical success of deep reinforcement learning, its theoretical foundation is less well understood. In this work, we make the first attempt to theoretically understand the deep Q-network (DQN) algorithm (Mnih et al., 2015) from both algorithmic and statistical perspectives. In specific, we focus on a slight simplification of DQN that fully captures its key features. Under mild assumptions, we establish the algorithmic and statistical rates of convergence for the action-value functions of the iterative policy sequence obtained by DQN. In particular, the statistical error characterizes the bias and variance that arise from approximating the action-value function using deep neural network, while the algorithmic error converges to zero at a geometric rate. As a byproduct, our analysis provides justifications for the techniques of experience replay and target network, which are crucial to the empirical success of DQN. Furthermore, as a simple extension of DQN, we propose the Minimax-DQN algorithm for zero-sum Markov game with two players. Borrowing the analysis of DQN, we also quantify the difference between the policies obtained by Minimax-DQN and the Nash equilibrium of the Markov game in terms of both the algorithmic and statistical rates of convergence.",
            "referenceCount": 152,
            "citationCount": 393,
            "influentialCitationCount": 55,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-01-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2019ATA,\n author = {Zhuoran Yang and Yuchen Xie and Zhaoran Wang},\n booktitle = {Conference on Learning for Dynamics & Control},\n pages = {486-489},\n title = {A Theoretical Analysis of Deep Q-Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4b675d8f63888d7d6d7d77a0834efa5eaded64c5",
            "@type": "ScholarlyArticle",
            "paperId": "4b675d8f63888d7d6d7d77a0834efa5eaded64c5",
            "corpusId": 6021932,
            "url": "https://www.semanticscholar.org/paper/4b675d8f63888d7d6d7d77a0834efa5eaded64c5",
            "title": "In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/corr/NeyshaburTS14",
                "ArXiv": "1412.6614",
                "MAG": "2963695615",
                "CorpusId": 6021932
            },
            "abstract": "We present experiments demonstrating that some other form of capacity control, different from network size, plays a central role in learning multilayer feed-forward networks. We argue, partially through analogy to matrix factorization, that this is an inductive bias that can help shed light on deep learning.",
            "referenceCount": 22,
            "citationCount": 555,
            "influentialCitationCount": 39,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-12-19",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1412.6614"
            },
            "citationStyles": {
                "bibtex": "@Article{Neyshabur2014InSO,\n author = {Behnam Neyshabur and Ryota Tomioka and N. Srebro},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning},\n volume = {abs/1412.6614},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:af3b7e1e2921aa68f6e00e07589c0d0f585e9f76",
            "@type": "ScholarlyArticle",
            "paperId": "af3b7e1e2921aa68f6e00e07589c0d0f585e9f76",
            "corpusId": 18599847,
            "url": "https://www.semanticscholar.org/paper/af3b7e1e2921aa68f6e00e07589c0d0f585e9f76",
            "title": "A review of unsupervised feature learning and deep learning for time-series modeling",
            "venue": "Pattern Recognition Letters",
            "publicationVenue": {
                "id": "urn:research:f35e3e87-9df4-497b-aa0d-bb8584197290",
                "name": "Pattern Recognition Letters",
                "alternate_names": [
                    "Pattern Recognit Lett"
                ],
                "issn": "0167-8655",
                "url": "https://www.journals.elsevier.com/pattern-recognition-letters/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/prl/LangkvistKL14",
                "MAG": "2026430219",
                "DOI": "10.1016/j.patrec.2014.01.008",
                "CorpusId": 18599847
            },
            "abstract": null,
            "referenceCount": 162,
            "citationCount": 1025,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://oru.diva-portal.org/smash/get/diva2:710518/FULLTEXT02",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2014-06-01",
            "journal": {
                "name": "Pattern Recognit. Lett.",
                "volume": "42"
            },
            "citationStyles": {
                "bibtex": "@Article{L\u00e4ngkvist2014ARO,\n author = {Martin L\u00e4ngkvist and L. Karlsson and A. Loutfi},\n booktitle = {Pattern Recognition Letters},\n journal = {Pattern Recognit. Lett.},\n pages = {11-24},\n title = {A review of unsupervised feature learning and deep learning for time-series modeling},\n volume = {42},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f06a12928307e17b1aff2b9f4a6c11791f19b6a7",
            "@type": "ScholarlyArticle",
            "paperId": "f06a12928307e17b1aff2b9f4a6c11791f19b6a7",
            "corpusId": 26071966,
            "url": "https://www.semanticscholar.org/paper/f06a12928307e17b1aff2b9f4a6c11791f19b6a7",
            "title": "Deep Mutual Learning",
            "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/ZhangXHL17",
                "MAG": "2951168573",
                "ArXiv": "1706.00384",
                "DOI": "10.1109/CVPR.2018.00454",
                "CorpusId": 26071966
            },
            "abstract": "Model distillation is an effective and widely used technique to transfer knowledge from a teacher to a student network. The typical application is to transfer from a powerful large network or ensemble to a small network, in order to meet the low-memory or fast execution requirements. In this paper, we present a deep mutual learning (DML) strategy. Different from the one-way transfer between a static pre-defined teacher and a student in model distillation, with DML, an ensemble of students learn collaboratively and teach each other throughout the training process. Our experiments show that a variety of network architectures benefit from mutual learning and achieve compelling results on both category and instance recognition tasks. Surprisingly, it is revealed that no prior powerful teacher network is necessary - mutual learning of a collection of simple student networks works, and moreover outperforms distillation from a more powerful yet static teacher.",
            "referenceCount": 42,
            "citationCount": 1250,
            "influentialCitationCount": 230,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pure.ed.ac.uk/ws/files/58941044/zhang2018DeepMutualLearning.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-06-01",
            "journal": {
                "name": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2017DeepML,\n author = {Ying Zhang and T. Xiang and Timothy M. Hospedales and Huchuan Lu},\n booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n pages = {4320-4328},\n title = {Deep Mutual Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fff114cbba4f3ba900f33da574283e3de7f26c83",
            "@type": "ScholarlyArticle",
            "paperId": "fff114cbba4f3ba900f33da574283e3de7f26c83",
            "corpusId": 3051291,
            "url": "https://www.semanticscholar.org/paper/fff114cbba4f3ba900f33da574283e3de7f26c83",
            "title": "DeepWalk: online learning of social representations",
            "venue": "Knowledge Discovery and Data Mining",
            "publicationVenue": {
                "id": "urn:research:a0edb93b-1e95-4128-a295-6b1659149cef",
                "name": "Knowledge Discovery and Data Mining",
                "alternate_names": [
                    "KDD",
                    "Knowl Discov Data Min"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigkdd/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/kdd/PerozziAS14",
                "MAG": "2154851992",
                "ArXiv": "1403.6652",
                "DOI": "10.1145/2623330.2623732",
                "CorpusId": 3051291
            },
            "abstract": "We present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk's latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk's representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk's representations are able to outperform all baseline methods while using 60% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.",
            "referenceCount": 52,
            "citationCount": 8073,
            "influentialCitationCount": 1705,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1403.6652",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2014-03-26",
            "journal": {
                "name": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Perozzi2014DeepWalkOL,\n author = {Bryan Perozzi and Rami Al-Rfou and S. Skiena},\n booktitle = {Knowledge Discovery and Data Mining},\n journal = {Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining},\n title = {DeepWalk: online learning of social representations},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e2e2789ea31e54fba2f2a472a3d068a064e1a5af",
            "@type": "ScholarlyArticle",
            "paperId": "e2e2789ea31e54fba2f2a472a3d068a064e1a5af",
            "corpusId": 243280948,
            "url": "https://www.semanticscholar.org/paper/e2e2789ea31e54fba2f2a472a3d068a064e1a5af",
            "title": "Deep Learning",
            "venue": "Text Mining with Machine Learning",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "DOI": "10.1201/9780429469275-11",
                "CorpusId": 243280948
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-10-31",
            "journal": {
                "name": "Text Mining with Machine Learning",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zizka2019DeepL,\n author = {J. Zizka and F. Da\u0159ena and Arno\u0161t Svoboda},\n booktitle = {Text Mining with Machine Learning},\n journal = {Text Mining with Machine Learning},\n title = {Deep Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:faec80928a758062e0ced9aae445257f67c740a8",
            "@type": "ScholarlyArticle",
            "paperId": "faec80928a758062e0ced9aae445257f67c740a8",
            "corpusId": 240685693,
            "url": "https://www.semanticscholar.org/paper/faec80928a758062e0ced9aae445257f67c740a8",
            "title": "Deep Learning",
            "venue": "Data Science and Machine Learning",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "DOI": "10.1201/9780367816971-9",
                "CorpusId": 240685693
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-11-20",
            "journal": {
                "name": "Data Science and Machine Learning",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kroese2019DeepL,\n author = {Dirk P. Kroese and Z. Botev and T. Taimre and Radislav Vaisman},\n booktitle = {Data Science and Machine Learning},\n journal = {Data Science and Machine Learning},\n title = {Deep Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:50db42104b0770156c1a3f5ee585bf341050e787",
            "@type": "ScholarlyArticle",
            "paperId": "50db42104b0770156c1a3f5ee585bf341050e787",
            "corpusId": 10101897,
            "url": "https://www.semanticscholar.org/paper/50db42104b0770156c1a3f5ee585bf341050e787",
            "title": "A survey of deep learning methods and software tools for image classification and object detection",
            "venue": "Pattern Recognition and Image Analysis",
            "publicationVenue": {
                "id": "urn:research:c95e79f8-dc6a-45e2-8413-c9c90694a216",
                "name": "Pattern Recognition and Image Analysis",
                "alternate_names": [
                    "Pattern Recognit Image Anal"
                ],
                "issn": "1054-6618",
                "url": "https://link.springer.com/journal/11493"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2322112093",
                "DOI": "10.1134/S1054661816010065",
                "CorpusId": 10101897
            },
            "abstract": null,
            "referenceCount": 42,
            "citationCount": 239,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Pattern Recognition and Image Analysis",
                "volume": "26"
            },
            "citationStyles": {
                "bibtex": "@Article{Druzhkov2016ASO,\n author = {P. Druzhkov and V. Kustikova},\n booktitle = {Pattern Recognition and Image Analysis},\n journal = {Pattern Recognition and Image Analysis},\n pages = {9-15},\n title = {A survey of deep learning methods and software tools for image classification and object detection},\n volume = {26},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ff95dcec9098a66f0110b10b76618f1eee505f84",
            "@type": "ScholarlyArticle",
            "paperId": "ff95dcec9098a66f0110b10b76618f1eee505f84",
            "corpusId": 9928823,
            "url": "https://www.semanticscholar.org/paper/ff95dcec9098a66f0110b10b76618f1eee505f84",
            "title": "A tutorial survey of architectures, algorithms, and applications for deep learning",
            "venue": "APSIPA Transactions on Signal and Information Processing",
            "publicationVenue": {
                "id": "urn:research:d081062e-f8a7-4018-9072-ca99195f38d8",
                "name": "APSIPA Transactions on Signal and Information Processing",
                "alternate_names": [
                    "APSIPA Trans Signal Inf Process"
                ],
                "issn": "2048-7703",
                "url": "https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2123585936",
                "DOI": "10.1017/atsip.2013.9",
                "CorpusId": 9928823
            },
            "abstract": "In this invited paper, my overview material on the same topic as presented in the plenary overview session of APSIPA-2011 and the tutorial material presented in the same conference [1] are expanded and updated to include more recent developments in deep learning. The previous and the updated materials cover both theory and applications, and analyze its future directions. The goal of this tutorial survey is to introduce the emerging area of deep learning or hierarchical learning to the APSIPA community. Deep learning refers to a class of machine learning techniques, developed largely since 2006, where many stages of non-linear information processing in hierarchical architectures are exploited for pattern classification and for feature learning. In the more recent literature, it is also connected to representation learning, which involves a hierarchy of features or concepts where higher-level concepts are defined from lower-level ones and where the same lower-level concepts help to define higher-level ones. In this tutorial survey, a brief history of deep learning research is discussed first. Then, a classificatory scheme is developed to analyze and summarize major work reported in the recent deep learning literature. Using this scheme, I provide a taxonomy-oriented survey on the existing deep architectures and algorithms in the literature, and categorize them into three classes: generative, discriminative, and hybrid. Three representative deep architectures \u2013 deep autoencoders, deep stacking networks with their generalization to the temporal domain (recurrent networks), and deep neural networks (pretrained with deep belief networks) \u2013 one in each of the three classes, are presented in more detail. Next, selected applications of deep learning are reviewed in broad areas of signal and information processing including audio/speech, image/vision, multimodality, language modeling, natural language processing, and information retrieval. Finally, future directions of deep learning are discussed and analyzed.",
            "referenceCount": 243,
            "citationCount": 696,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/023B6ADF962FA37F8EC684B209E3DFAE/S2048770313000097a.pdf/div-class-title-a-tutorial-survey-of-architectures-algorithms-and-applications-for-deep-learning-div.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2014-01-22",
            "journal": {
                "name": "APSIPA Transactions on Signal and Information Processing",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Deng2014ATS,\n author = {L. Deng},\n booktitle = {APSIPA Transactions on Signal and Information Processing},\n journal = {APSIPA Transactions on Signal and Information Processing},\n title = {A tutorial survey of architectures, algorithms, and applications for deep learning},\n volume = {3},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9667f8264745b626c6173b1310e2ff0298b09cfc",
            "@type": "ScholarlyArticle",
            "paperId": "9667f8264745b626c6173b1310e2ff0298b09cfc",
            "corpusId": 1849990,
            "url": "https://www.semanticscholar.org/paper/9667f8264745b626c6173b1310e2ff0298b09cfc",
            "title": "Learning Deep Features for Scene Recognition using Places Database",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/nips/ZhouLXTO14",
                "MAG": "2134670479",
                "CorpusId": 1849990
            },
            "abstract": "Scene recognition is one of the hallmark tasks of computer vision, allowing definition of a context for object recognition. Whereas the tremendous recent progress in object recognition tasks is due to the availability of large datasets like ImageNet and the rise of Convolutional Neural Networks (CNNs) for learning high-level features, performance at scene recognition has not attained the same level of success. This may be because current deep features trained from ImageNet are not competitive enough for such tasks. Here, we introduce a new scene-centric database called Places with over 7 million labeled pictures of scenes. We propose new methods to compare the density and diversity of image datasets and show that Places is as dense as other scene datasets and has more diversity. Using CNN, we learn deep features for scene recognition tasks, and establish new state-of-the-art results on several scene-centric datasets. A visualization of the CNN layers' responses allows us to show differences in the internal representations of object-centric and scene-centric networks.",
            "referenceCount": 25,
            "citationCount": 2857,
            "influentialCitationCount": 412,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-12-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhou2014LearningDF,\n author = {Bolei Zhou and \u00c0gata Lapedriza and Jianxiong Xiao and A. Torralba and A. Oliva},\n booktitle = {Neural Information Processing Systems},\n pages = {487-495},\n title = {Learning Deep Features for Scene Recognition using Places Database},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:66ad2fbc8b73242a889699868611fcf239e3435d",
            "@type": "ScholarlyArticle",
            "paperId": "66ad2fbc8b73242a889699868611fcf239e3435d",
            "corpusId": 6377199,
            "url": "https://www.semanticscholar.org/paper/66ad2fbc8b73242a889699868611fcf239e3435d",
            "title": "Semi-supervised Learning with Deep Generative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/nips/KingmaMRW14",
                "MAG": "2949416428",
                "ArXiv": "1406.5298",
                "CorpusId": 6377199
            },
            "abstract": "The ever-increasing size of modern data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning.",
            "referenceCount": 27,
            "citationCount": 2390,
            "influentialCitationCount": 309,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-06-20",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1406.5298"
            },
            "citationStyles": {
                "bibtex": "@Article{Kingma2014SemisupervisedLW,\n author = {Diederik P. Kingma and S. Mohamed and Danilo Jimenez Rezende and M. Welling},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Semi-supervised Learning with Deep Generative Models},\n volume = {abs/1406.5298},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:08c13be14da51f2ed531ffe980bb993e45042e41",
            "@type": "ScholarlyArticle",
            "paperId": "08c13be14da51f2ed531ffe980bb993e45042e41",
            "corpusId": 59999372,
            "url": "https://www.semanticscholar.org/paper/08c13be14da51f2ed531ffe980bb993e45042e41",
            "title": "Automatic Speech Recognition: A Deep Learning Approach",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "330298975",
                "DOI": "10.1007/978-1-4471-5779-3",
                "CorpusId": 59999372
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 537,
            "influentialCitationCount": 41,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2014-11-11",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Yu2014AutomaticSR,\n author = {Dong Yu and L. Deng},\n title = {Automatic Speech Recognition: A Deep Learning Approach},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:be26cdf0573bc8eee1119802e548dfaa2e401bdb",
            "@type": "ScholarlyArticle",
            "paperId": "be26cdf0573bc8eee1119802e548dfaa2e401bdb",
            "corpusId": 33038618,
            "url": "https://www.semanticscholar.org/paper/be26cdf0573bc8eee1119802e548dfaa2e401bdb",
            "title": "Overview of deep learning",
            "venue": "Youth Academic Annual Conference of Chinese Association of Automation",
            "publicationVenue": {
                "id": "urn:research:7e280d98-c90c-428c-baba-a46e4abde912",
                "name": "Youth Academic Annual Conference of Chinese Association of Automation",
                "alternate_names": [
                    "YAC",
                    "Youth Acad Annu Conf Chin Assoc Autom"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2572219278",
                "DOI": "10.1109/YAC.2016.7804882",
                "CorpusId": 33038618
            },
            "abstract": "In recent years, deep learning has achieved great success in many fields, such as computer vision and natural language processing. Compared to traditional machine learning methods, deep learning has a strong learning ability and can make better use of datasets for feature extraction. Because of its practicability, deep learning becomes more and more popular for many researchers to do research works. In this paper, we mainly introduce some advanced neural networks of deep learning and their applications. Besides, we also discuss the limitations and prospects of deep learning.",
            "referenceCount": 37,
            "citationCount": 229,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference",
                "Review"
            ],
            "publicationDate": "2016-11-01",
            "journal": {
                "name": "2016 31st Youth Academic Annual Conference of Chinese Association of Automation (YAC)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Du2016OverviewOD,\n author = {Xuedan Du and Yinghao Cai and Shuo Wang and Leijie Zhang},\n booktitle = {Youth Academic Annual Conference of Chinese Association of Automation},\n journal = {2016 31st Youth Academic Annual Conference of Chinese Association of Automation (YAC)},\n pages = {159-164},\n title = {Overview of deep learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:524664475292ad6cdbdda3992fe5dc8f036b6ce5",
            "@type": "ScholarlyArticle",
            "paperId": "524664475292ad6cdbdda3992fe5dc8f036b6ce5",
            "corpusId": 12359230,
            "url": "https://www.semanticscholar.org/paper/524664475292ad6cdbdda3992fe5dc8f036b6ce5",
            "title": "Deep Learning for Emotion Recognition on Small Datasets using Transfer Learning",
            "venue": "International Conference on Multimodal Interaction",
            "publicationVenue": {
                "id": "urn:research:d11025b6-9660-45df-b13a-555e3ff4ceca",
                "name": "International Conference on Multimodal Interaction",
                "alternate_names": [
                    "Int Conf Multimodal Interact",
                    "International Conference on Multimodal Interfaces",
                    "Int Conf Multimodal Interface",
                    "ICMI"
                ],
                "issn": null,
                "url": "https://en.wikipedia.org/wiki/ACM/IEEE_Virtual_Reality_International_Conference"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/icmi/NgNVW15",
                "MAG": "2253728219",
                "DOI": "10.1145/2818346.2830593",
                "CorpusId": 12359230
            },
            "abstract": "This paper presents the techniques employed in our team's submissions to the 2015 Emotion Recognition in the Wild contest, for the sub-challenge of Static Facial Expression Recognition in the Wild. The objective of this sub-challenge is to classify the emotions expressed by the primary human subject in static images extracted from movies. We follow a transfer learning approach for deep Convolutional Neural Network (CNN) architectures. Starting from a network pre-trained on the generic ImageNet dataset, we perform supervised fine-tuning on the network in a two-stage process, first on datasets relevant to facial expressions, followed by the contest's dataset. Experimental results show that this cascading fine-tuning approach achieves better results, compared to a single stage fine-tuning with the combined datasets. Our best submission exhibited an overall accuracy of 48.5% in the validation set and 55.6% in the test set, which compares favorably to the respective 35.96% and 39.13% of the challenge baseline.",
            "referenceCount": 30,
            "citationCount": 568,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2015-11-09",
            "journal": {
                "name": "Proceedings of the 2015 ACM on International Conference on Multimodal Interaction",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Ng2015DeepLF,\n author = {Hongwei Ng and Viet Dung Nguyen and Vassilios Vonikakis and Stefan Winkler},\n booktitle = {International Conference on Multimodal Interaction},\n journal = {Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},\n title = {Deep Learning for Emotion Recognition on Small Datasets using Transfer Learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6622bdc1aed1f4d5719ca6cab80927e373c4f183",
            "@type": "ScholarlyArticle",
            "paperId": "6622bdc1aed1f4d5719ca6cab80927e373c4f183",
            "corpusId": 322504,
            "url": "https://www.semanticscholar.org/paper/6622bdc1aed1f4d5719ca6cab80927e373c4f183",
            "title": "Learning Robust Features using Deep Learning for Automatic Seizure Detection",
            "venue": "Machine Learning in Health Care",
            "publicationVenue": {
                "id": "urn:research:6171bcff-8306-41c7-af12-fa1d87117cf1",
                "name": "Machine Learning in Health Care",
                "alternate_names": [
                    "MLHC",
                    "Mach Learn Health Care"
                ],
                "issn": null,
                "url": "http://mucmd.org"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2953263050",
                "DBLP": "conf/mlhc/ThodoroffPL16",
                "ArXiv": "1608.00220",
                "CorpusId": 322504
            },
            "abstract": "We present and evaluate the capacity of a deep neural network to learn robust features from EEG to automatically detect seizures. This is a challenging problem because seizure manifestations on EEG are extremely variable both inter- and intra-patient. By simultaneously capturing spectral, temporal and spatial information our recurrent convolutional neural network learns a general spatially invariant representation of a seizure. The proposed approach exceeds significantly previous results obtained on cross-patient classifiers both in terms of sensitivity and false positive rate. Furthermore, our model proves to be robust to missing channel and variable electrode montage.",
            "referenceCount": 24,
            "citationCount": 261,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-07-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1608.00220"
            },
            "citationStyles": {
                "bibtex": "@Article{Thodoroff2016LearningRF,\n author = {Pierre Thodoroff and Joelle Pineau and Andrew Lim},\n booktitle = {Machine Learning in Health Care},\n journal = {ArXiv},\n title = {Learning Robust Features using Deep Learning for Automatic Seizure Detection},\n volume = {abs/1608.00220},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f2c5a5b90a4c271a783e97af7427db647ca5b9f9",
            "@type": "ScholarlyArticle",
            "paperId": "f2c5a5b90a4c271a783e97af7427db647ca5b9f9",
            "corpusId": 26109462,
            "url": "https://www.semanticscholar.org/paper/f2c5a5b90a4c271a783e97af7427db647ca5b9f9",
            "title": "Broad Learning System: An Effective and Efficient Incremental Learning System Without the Need for Deep Architecture",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2738226240",
                "DBLP": "journals/tnn/ChenL18",
                "DOI": "10.1109/TNNLS.2017.2716952",
                "CorpusId": 26109462,
                "PubMed": "28742048"
            },
            "abstract": "Broad Learning System (BLS) that aims to offer an alternative way of learning in deep structure is proposed in this paper. Deep structure and learning suffer from a time-consuming training process because of a large number of connecting parameters in filters and layers. Moreover, it encounters a complete retraining process if the structure is not sufficient to model the system. The BLS is established in the form of a flat network, where the original inputs are transferred and placed as \u201cmapped features\u201d in feature nodes and the structure is expanded in wide sense in the \u201cenhancement nodes.\u201d The incremental learning algorithms are developed for fast remodeling in broad expansion without a retraining process if the network deems to be expanded. Two incremental learning algorithms are given for both the increment of the feature nodes (or filters in deep structure) and the increment of the enhancement nodes. The designed model and algorithms are very versatile for selecting a model rapidly. In addition, another incremental learning is developed for a system that has been modeled encounters a new incoming input. Specifically, the system can be remodeled in an incremental way without the entire retraining from the beginning. Satisfactory result for model reduction using singular value decomposition is conducted to simplify the final structure. Compared with existing deep neural networks, experimental results on the Modified National Institute of Standards and Technology database and NYU NORB object recognition dataset benchmark data demonstrate the effectiveness of the proposed BLS.",
            "referenceCount": 52,
            "citationCount": 962,
            "influentialCitationCount": 160,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "29"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2018BroadLS,\n author = {C. L. P. Chen and Zhulin Liu},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {10-24},\n title = {Broad Learning System: An Effective and Efficient Incremental Learning System Without the Need for Deep Architecture},\n volume = {29},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0d2336389dff3031910bd21dd1c44d1b4cd51725",
            "@type": "ScholarlyArticle",
            "paperId": "0d2336389dff3031910bd21dd1c44d1b4cd51725",
            "corpusId": 15796526,
            "url": "https://www.semanticscholar.org/paper/0d2336389dff3031910bd21dd1c44d1b4cd51725",
            "title": "Why Does Unsupervised Pre-training Help Deep Learning?",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2964947096",
                "DBLP": "journals/jmlr/ErhanCBV10",
                "DOI": "10.5555/1756006.1756025",
                "CorpusId": 15796526
            },
            "abstract": "Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training.",
            "referenceCount": 69,
            "citationCount": 2259,
            "influentialCitationCount": 77,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-03-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Erhan2010WhyDU,\n author = {D. Erhan and Aaron C. Courville and Yoshua Bengio and Pascal Vincent},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n pages = {201-208},\n title = {Why Does Unsupervised Pre-training Help Deep Learning?},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4954fa180728932959997a4768411ff9136aac81",
            "@type": "ScholarlyArticle",
            "paperId": "4954fa180728932959997a4768411ff9136aac81",
            "corpusId": 6287870,
            "url": "https://www.semanticscholar.org/paper/4954fa180728932959997a4768411ff9136aac81",
            "title": "TensorFlow: A system for large-scale machine learning",
            "venue": "USENIX Symposium on Operating Systems Design and Implementation",
            "publicationVenue": {
                "id": "urn:research:86c43745-31d9-4c1a-b33f-ce3aa0042dbb",
                "name": "USENIX Symposium on Operating Systems Design and Implementation",
                "alternate_names": [
                    "Oper Syst Des Implement",
                    "Operating Systems Design and Implementation",
                    "OSDI",
                    "USENIX Symp Oper Syst Des Implement"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2402144811",
                "DBLP": "conf/osdi/AbadiBCCDDDGIIK16",
                "ArXiv": "1605.08695",
                "CorpusId": 6287870
            },
            "abstract": "TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous \"parameter server\" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.",
            "referenceCount": 91,
            "citationCount": 16315,
            "influentialCitationCount": 1875,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-05-27",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Abadi2016TensorFlowAS,\n author = {Mart\u00edn Abadi and P. Barham and Jianmin Chen and Z. Chen and Andy Davis and J. Dean and Matthieu Devin and S. Ghemawat and G. Irving and M. Isard and M. Kudlur and J. Levenberg and R. Monga and Sherry Moore and D. Murray and Benoit Steiner and P. Tucker and Vijay Vasudevan and P. Warden and M. Wicke and Yuan Yu and Xiaoqiang Zhang},\n booktitle = {USENIX Symposium on Operating Systems Design and Implementation},\n pages = {265-283},\n title = {TensorFlow: A system for large-scale machine learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:79c8f930bb66c82421b84617e4b6c0b2855cd063",
            "@type": "ScholarlyArticle",
            "paperId": "79c8f930bb66c82421b84617e4b6c0b2855cd063",
            "corpusId": 53018231,
            "url": "https://www.semanticscholar.org/paper/79c8f930bb66c82421b84617e4b6c0b2855cd063",
            "title": "Applications of Deep Reinforcement Learning in Communications and Networking: A Survey",
            "venue": "IEEE Communications Surveys and Tutorials",
            "publicationVenue": {
                "id": "urn:research:95d0dda7-5d58-4afd-b59f-315447b81992",
                "name": "IEEE Communications Surveys and Tutorials",
                "alternate_names": [
                    "IEEE Commun Surv Tutor"
                ],
                "issn": "1553-877X",
                "url": "http://www.comsoc.org/cst"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2952941635",
                "DBLP": "journals/corr/abs-1810-07862",
                "ArXiv": "1810.07862",
                "DOI": "10.1109/COMST.2019.2916583",
                "CorpusId": 53018231
            },
            "abstract": "This paper presents a comprehensive literature review on applications of deep reinforcement learning (DRL) in communications and networking. Modern networks, e.g., Internet of Things (IoT) and unmanned aerial vehicle (UAV) networks, become more decentralized and autonomous. In such networks, network entities need to make decisions locally to maximize the network performance under uncertainty of network environment. Reinforcement learning has been efficiently used to enable the network entities to obtain the optimal policy including, e.g., decisions or actions, given their states when the state and action spaces are small. However, in complex and large-scale networks, the state and action spaces are usually large, and the reinforcement learning may not be able to find the optimal policy in reasonable time. Therefore, DRL, a combination of reinforcement learning with deep learning, has been developed to overcome the shortcomings. In this survey, we first give a tutorial of DRL from fundamental concepts to advanced models. Then, we review DRL approaches proposed to address emerging issues in communications and networking. The issues include dynamic network access, data rate control, wireless caching, data offloading, network security, and connectivity preservation which are all important to next generation networks, such as 5G and beyond. Furthermore, we present applications of DRL for traffic routing, resource sharing, and data collection. Finally, we highlight important challenges, open issues, and future research directions of applying DRL.",
            "referenceCount": 214,
            "citationCount": 1023,
            "influentialCitationCount": 52,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://opus.lib.uts.edu.au/bitstream/10453/138762/4/draft1.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-10-18",
            "journal": {
                "name": "IEEE Communications Surveys & Tutorials",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Luong2018ApplicationsOD,\n author = {Nguyen Cong Luong and D. Hoang and Shimin Gong and D. Niyato and Ping Wang and Ying-Chang Liang and Dong In Kim},\n booktitle = {IEEE Communications Surveys and Tutorials},\n journal = {IEEE Communications Surveys & Tutorials},\n pages = {3133-3174},\n title = {Applications of Deep Reinforcement Learning in Communications and Networking: A Survey},\n volume = {21},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:761b69164d8b34398f010931faa534c031bdaad6",
            "@type": "ScholarlyArticle",
            "paperId": "761b69164d8b34398f010931faa534c031bdaad6",
            "corpusId": 5492686,
            "url": "https://www.semanticscholar.org/paper/761b69164d8b34398f010931faa534c031bdaad6",
            "title": "Why Deep Learning Works: A Manifold Disentanglement Perspective",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/tnn/BrahmaWS16",
                "MAG": "2342792901",
                "DOI": "10.1109/TNNLS.2015.2496947",
                "CorpusId": 5492686,
                "PubMed": "26672049"
            },
            "abstract": "Deep hierarchical representations of the data have been found out to provide better informative features for several machine learning applications. In addition, multilayer neural networks surprisingly tend to achieve better performance when they are subject to an unsupervised pretraining. The booming of deep learning motivates researchers to identify the factors that contribute to its success. One possible reason identified is the flattening of manifold-shaped data in higher layers of neural networks. However, it is not clear how to measure the flattening of such manifold-shaped data and what amount of flattening a deep neural network can achieve. For the first time, this paper provides quantitative evidence to validate the flattening hypothesis. To achieve this, we propose a few quantities for measuring manifold entanglement under certain assumptions and conduct experiments with both synthetic and real-world data. Our experimental results validate the proposition and lead to new insights on deep learning.",
            "referenceCount": 28,
            "citationCount": 145,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-10-01",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Brahma2016WhyDL,\n author = {P. Brahma and Dapeng Oliver Wu and Yiyuan She},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {1997-2008},\n title = {Why Deep Learning Works: A Manifold Disentanglement Perspective},\n volume = {27},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:57458bc1cffe5caa45a885af986d70f723f406b4",
            "@type": "ScholarlyArticle",
            "paperId": "57458bc1cffe5caa45a885af986d70f723f406b4",
            "corpusId": 2617020,
            "url": "https://www.semanticscholar.org/paper/57458bc1cffe5caa45a885af986d70f723f406b4",
            "title": "A unified architecture for natural language processing: deep neural networks with multitask learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2117130368",
                "DBLP": "conf/icml/CollobertW08",
                "DOI": "10.1145/1390156.1390177",
                "CorpusId": 2617020
            },
            "abstract": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.",
            "referenceCount": 24,
            "citationCount": 5608,
            "influentialCitationCount": 301,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-07-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Collobert2008AUA,\n author = {Ronan Collobert and J. Weston},\n booktitle = {International Conference on Machine Learning},\n pages = {160-167},\n title = {A unified architecture for natural language processing: deep neural networks with multitask learning},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:59a922212153d3407e658109f36c11a34ee7d283",
            "@type": "ScholarlyArticle",
            "paperId": "59a922212153d3407e658109f36c11a34ee7d283",
            "corpusId": 1888776,
            "url": "https://www.semanticscholar.org/paper/59a922212153d3407e658109f36c11a34ee7d283",
            "title": "Continual Learning with Deep Generative Replay",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963559848",
                "DBLP": "conf/nips/ShinLKK17",
                "ArXiv": "1705.08690",
                "CorpusId": 1888776
            },
            "abstract": "Attempts to train a comprehensive artificial intelligence capable of solving multiple tasks have been impeded by a chronic problem called catastrophic forgetting. Although simply replaying all previous data alleviates the problem, it requires large memory and even worse, often infeasible in real world applications where the access to past data is limited. Inspired by the generative nature of hippocampus as a short-term memory system in primate brain, we propose the Deep Generative Replay, a novel framework with a cooperative dual model architecture consisting of a deep generative model (\"generator\") and a task solving model (\"solver\"). With only these two models, training data for previous tasks can easily be sampled and interleaved with those for a new task. We test our methods in several sequential learning settings involving image classification tasks.",
            "referenceCount": 36,
            "citationCount": 1458,
            "influentialCitationCount": 137,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-05-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shin2017ContinualLW,\n author = {Hanul Shin and Jung Kwon Lee and Jaehong Kim and Jiwon Kim},\n booktitle = {Neural Information Processing Systems},\n pages = {2990-2999},\n title = {Continual Learning with Deep Generative Replay},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4b61c25a86083c20730c9b12737ac6ac4178c364",
            "@type": "ScholarlyArticle",
            "paperId": "4b61c25a86083c20730c9b12737ac6ac4178c364",
            "corpusId": 54434537,
            "url": "https://www.semanticscholar.org/paper/4b61c25a86083c20730c9b12737ac6ac4178c364",
            "title": "An Introduction to Deep Reinforcement Learning",
            "venue": "Found. Trends Mach. Learn.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "3100366369",
                "DBLP": "journals/corr/abs-1811-12560",
                "ArXiv": "1811.12560",
                "DOI": "10.1561/2200000071",
                "CorpusId": 54434537
            },
            "abstract": "Deep reinforcement learning is the combination of reinforcement learning (RL) and deep learning. This field of research has been able to solve a wide range of complex decision-making tasks that were previously out of reach for a machine. Thus, deep RL opens up many new applications in domains such as healthcare, robotics, smart grids, finance, and many more. This manuscript provides an introduction to deep reinforcement learning models, algorithms and techniques. Particular focus is on the aspects related to generalization and how deep RL can be used for practical applications. We assume the reader is familiar with basic machine learning concepts.",
            "referenceCount": 352,
            "citationCount": 874,
            "influentialCitationCount": 50,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://repositorio.unal.edu.co/bitstream/unal/80758/2/98554412.2021.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-11-30",
            "journal": {
                "name": "Found. Trends Mach. Learn.",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Fran\u00e7ois-Lavet2018AnIT,\n author = {Vincent Fran\u00e7ois-Lavet and Peter Henderson and Riashat Islam and Marc G. Bellemare and Joelle Pineau},\n booktitle = {Found. Trends Mach. Learn.},\n journal = {Found. Trends Mach. Learn.},\n pages = {219-354},\n title = {An Introduction to Deep Reinforcement Learning},\n volume = {11},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1464776f20e2bccb6182f183b5ff2e15b0ae5e56",
            "@type": "ScholarlyArticle",
            "paperId": "1464776f20e2bccb6182f183b5ff2e15b0ae5e56",
            "corpusId": 12296499,
            "url": "https://www.semanticscholar.org/paper/1464776f20e2bccb6182f183b5ff2e15b0ae5e56",
            "title": "Benchmarking Deep Reinforcement Learning for Continuous Control",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/icml/DuanCHSA16",
                "MAG": "2963641140",
                "ArXiv": "1604.06778",
                "CorpusId": 12296499
            },
            "abstract": "Recently, researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning. Some notable examples include training agents to play Atari games based on raw pixel data and to acquire advanced manipulation skills using raw sensory inputs. However, it has been difficult to quantify progress in the domain of continuous control due to the lack of a commonly adopted benchmark. In this work, we present a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, tasks with partial observations, and tasks with hierarchical structure. We report novel findings based on the systematic evaluation of a range of implemented reinforcement learning algorithms. Both the benchmark and reference implementations are released at this https URL in order to facilitate experimental reproducibility and to encourage adoption by other researchers.",
            "referenceCount": 86,
            "citationCount": 1509,
            "influentialCitationCount": 122,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-04-22",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Duan2016BenchmarkingDR,\n author = {Yan Duan and Xi Chen and Rein Houthooft and J. Schulman and P. Abbeel},\n booktitle = {International Conference on Machine Learning},\n pages = {1329-1338},\n title = {Benchmarking Deep Reinforcement Learning for Continuous Control},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eb37e7b76d26b75463df22b2a3aa32b6a765c672",
            "@type": "ScholarlyArticle",
            "paperId": "eb37e7b76d26b75463df22b2a3aa32b6a765c672",
            "corpusId": 49470584,
            "url": "https://www.semanticscholar.org/paper/eb37e7b76d26b75463df22b2a3aa32b6a765c672",
            "title": "QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation",
            "venue": "Conference on Robot Learning",
            "publicationVenue": {
                "id": "urn:research:fbfbf10a-faa4-4d2a-85be-3ac660454ce3",
                "name": "Conference on Robot Learning",
                "alternate_names": [
                    "CoRL",
                    "Conf Robot Learn"
                ],
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1806.10293",
                "DBLP": "journals/corr/abs-1806-10293",
                "MAG": "2951747857",
                "CorpusId": 49470584
            },
            "abstract": "In this paper, we study the problem of learning vision-based dynamic manipulation skills using a scalable reinforcement learning approach. We study this problem in the context of grasping, a longstanding challenge in robotic manipulation. In contrast to static learning behaviors that choose a grasp point and then execute the desired grasp, our method enables closed-loop vision-based control, whereby the robot continuously updates its grasp strategy based on the most recent observations to optimize long-horizon grasp success. To that end, we introduce QT-Opt, a scalable self-supervised vision-based reinforcement learning framework that can leverage over 580k real-world grasp attempts to train a deep neural network Q-function with over 1.2M parameters to perform closed-loop, real-world grasping that generalizes to 96% grasp success on unseen objects. Aside from attaining a very high success rate, our method exhibits behaviors that are quite distinct from more standard grasping systems: using only RGB vision-based perception from an over-the-shoulder camera, our method automatically learns regrasping strategies, probes objects to find the most effective grasps, learns to reposition objects and perform other non-prehensile pre-grasp manipulations, and responds dynamically to disturbances and perturbations.",
            "referenceCount": 49,
            "citationCount": 1112,
            "influentialCitationCount": 62,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-06-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1806.10293"
            },
            "citationStyles": {
                "bibtex": "@Article{Kalashnikov2018QTOptSD,\n author = {Dmitry Kalashnikov and A. Irpan and P. Pastor and Julian Ibarz and Alexander Herzog and Eric Jang and Deirdre Quillen and E. Holly and Mrinal Kalakrishnan and Vincent Vanhoucke and S. Levine},\n booktitle = {Conference on Robot Learning},\n journal = {ArXiv},\n title = {QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},\n volume = {abs/1806.10293},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:08ca35366a4708ead695497c82edf1401d1bbf27",
            "@type": "ScholarlyArticle",
            "paperId": "08ca35366a4708ead695497c82edf1401d1bbf27",
            "corpusId": 7239967,
            "url": "https://www.semanticscholar.org/paper/08ca35366a4708ead695497c82edf1401d1bbf27",
            "title": "A deep learning approach to structured signal recovery",
            "venue": "Allerton Conference on Communication, Control, and Computing",
            "publicationVenue": {
                "id": "urn:research:e3e363b2-60f3-46d7-9067-5deaddc3f3f2",
                "name": "Allerton Conference on Communication, Control, and Computing",
                "alternate_names": [
                    "Allerton",
                    "T Conf Commun Control Comput"
                ],
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/MousaviPB15",
                "MAG": "3102722370",
                "ArXiv": "1508.04065",
                "DOI": "10.1109/ALLERTON.2015.7447163",
                "CorpusId": 7239967
            },
            "abstract": "In this paper, we develop a new framework for sensing and recovering structured signals. In contrast to compressive sensing (CS) systems that employ linear measurements, sparse representations, and computationally complex convex/greedy algorithms, we introduce a deep learning framework that supports both linear and mildly nonlinear measurements, that learns a structured representation from training data, and that efficiently computes a signal estimate. In particular, we apply a stacked denoising autoencoder (SDA), as an unsupervised feature learner. SDA enables us to capture statistical dependencies between the different elements of certain signals and improve signal recovery performance as compared to the CS approach.",
            "referenceCount": 43,
            "citationCount": 385,
            "influentialCitationCount": 44,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1508.04065",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-08-17",
            "journal": {
                "name": "2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mousavi2015ADL,\n author = {A. Mousavi and Ankit B. Patel and Richard Baraniuk},\n booktitle = {Allerton Conference on Communication, Control, and Computing},\n journal = {2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)},\n pages = {1336-1343},\n title = {A deep learning approach to structured signal recovery},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:306a2e8ca31fdcc148618d37074785c290f96375",
            "@type": "ScholarlyArticle",
            "paperId": "306a2e8ca31fdcc148618d37074785c290f96375",
            "corpusId": 51876228,
            "url": "https://www.semanticscholar.org/paper/306a2e8ca31fdcc148618d37074785c290f96375",
            "title": "MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2885593519",
                "DBLP": "conf/icml/JiangZLLF18",
                "ArXiv": "1712.05055",
                "CorpusId": 51876228
            },
            "abstract": "Recent deep networks are capable of memorizing the entire data even when the labels are completely random. To overcome the overfitting on corrupted labels, we propose a novel technique of learning another neural network, called MentorNet, to supervise the training of the base deep networks, namely, StudentNet. During training, MentorNet provides a curriculum (sample weighting scheme) for StudentNet to focus on the sample the label of which is probably correct. Unlike the existing curriculum that is usually predefined by human experts, MentorNet learns a data-driven curriculum dynamically with StudentNet. Experimental results demonstrate that our approach can significantly improve the generalization performance of deep networks trained on corrupted training data. Notably, to the best of our knowledge, we achieve the best-published result on WebVision, a large benchmark containing 2.2 million images of real-world noisy labels. The code are at this https URL",
            "referenceCount": 66,
            "citationCount": 1163,
            "influentialCitationCount": 190,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-12-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Jiang2017MentorNetLD,\n author = {Lu Jiang and Zhengyuan Zhou and Thomas Leung and Li-Jia Li and Li Fei-Fei},\n booktitle = {International Conference on Machine Learning},\n pages = {2309-2318},\n title = {MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:74f23063ca77f5b1caa3770a5957ae5fc565843e",
            "@type": "ScholarlyArticle",
            "paperId": "74f23063ca77f5b1caa3770a5957ae5fc565843e",
            "corpusId": 221819295,
            "url": "https://www.semanticscholar.org/paper/74f23063ca77f5b1caa3770a5957ae5fc565843e",
            "title": "Multi-Task Learning with Deep Neural Networks: A Survey",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2009-09796",
                "ArXiv": "2009.09796",
                "MAG": "3087549734",
                "CorpusId": 221819295
            },
            "abstract": "Multi-task learning (MTL) is a subfield of machine learning in which multiple tasks are simultaneously learned by a shared model. Such approaches offer advantages like improved data efficiency, reduced overfitting through shared representations, and fast learning by leveraging auxiliary information. However, the simultaneous learning of multiple tasks presents new design and optimization challenges, and choosing which tasks should be learned jointly is in itself a non-trivial problem. In this survey, we give an overview of multi-task learning methods for deep neural networks, with the aim of summarizing both the well-established and most recent directions within the field. Our discussion is structured according to a partition of the existing deep MTL techniques into three groups: architectures, optimization methods, and task relationship learning. We also provide a summary of common multi-task benchmarks.",
            "referenceCount": 181,
            "citationCount": 364,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-09-10",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2009.09796"
            },
            "citationStyles": {
                "bibtex": "@Article{Crawshaw2020MultiTaskLW,\n author = {M. Crawshaw},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Multi-Task Learning with Deep Neural Networks: A Survey},\n volume = {abs/2009.09796},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:325e51cdb065666f3c9e21e70a823bbe33fefae7",
            "@type": "ScholarlyArticle",
            "paperId": "325e51cdb065666f3c9e21e70a823bbe33fefae7",
            "corpusId": 215826733,
            "url": "https://www.semanticscholar.org/paper/325e51cdb065666f3c9e21e70a823bbe33fefae7",
            "title": "On the Expressive Power of Deep Learning: A Tensor Analysis",
            "venue": "Annual Conference Computational Learning Theory",
            "publicationVenue": {
                "id": "urn:research:24b0721b-0592-414a-ac79-7271515aaab0",
                "name": "Annual Conference Computational Learning Theory",
                "alternate_names": [
                    "Conf Learn Theory",
                    "COLT",
                    "Conference on Learning Theory",
                    "Annu Conf Comput Learn Theory"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=536"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2951209844",
                "ArXiv": "1509.05009",
                "DBLP": "conf/colt/CohenSS16",
                "CorpusId": 215826733
            },
            "abstract": "It has long been conjectured that hypotheses spaces suitable for data that is compositional in nature, such as text or images, may be more efficiently represented with deep hierarchical networks than with shallow ones. Despite the vast empirical evidence supporting this belief, theoretical justifications to date are limited. In particular, they do not account for the locality, sharing and pooling constructs of convolutional networks, the most successful deep learning architecture to date. In this work we derive a deep network architecture based on arithmetic circuits that inherently employs locality, sharing and pooling. An equivalence between the networks and hierarchical tensor factorizations is established. We show that a shallow network corresponds to CP (rank-1) decomposition, whereas a deep network corresponds to Hierarchical Tucker decomposition. Using tools from measure theory and matrix algebra, we prove that besides a negligible set, all functions that can be implemented by a deep network of polynomial size, require exponential size in order to be realized (or even approximated) by a shallow network. Since log-space computation transforms our networks into SimNets, the result applies directly to a deep learning architecture demonstrating promising empirical performance. The construction and theory developed in this paper shed new light on various practices and ideas employed by the deep learning community.",
            "referenceCount": 80,
            "citationCount": 436,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-09-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cohen2015OnTE,\n author = {Nadav Cohen and Or Sharir and A. Shashua},\n booktitle = {Annual Conference Computational Learning Theory},\n pages = {698-728},\n title = {On the Expressive Power of Deep Learning: A Tensor Analysis},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ce76fea215a40b7d538f1aaba4bb35f863764296",
            "@type": "ScholarlyArticle",
            "paperId": "ce76fea215a40b7d538f1aaba4bb35f863764296",
            "corpusId": 18848337,
            "url": "https://www.semanticscholar.org/paper/ce76fea215a40b7d538f1aaba4bb35f863764296",
            "title": "Computer-aided classification of lung nodules on computed tomography images via deep learning technique",
            "venue": "OncoTargets and Therapy",
            "publicationVenue": {
                "id": "urn:research:a3c92136-86d8-407a-9c91-45bd53eb2c77",
                "name": "OncoTargets and Therapy",
                "alternate_names": [
                    "Oncotargets Ther"
                ],
                "issn": "1178-6930",
                "url": "https://www.dovepress.com/oncotargets-and-therapy-journal"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1832115302",
                "PubMedCentral": "4531007",
                "DOI": "10.2147/OTT.S80733",
                "CorpusId": 18848337,
                "PubMed": "26346558"
            },
            "abstract": "Lung cancer has a poor prognosis when not diagnosed early and unresectable lesions are present. The management of small lung nodules noted on computed tomography scan is controversial due to uncertain tumor characteristics. A conventional computer-aided diagnosis (CAD) scheme requires several image processing and pattern recognition steps to accomplish a quantitative tumor differentiation result. In such an ad hoc image analysis pipeline, every step depends heavily on the performance of the previous step. Accordingly, tuning of classification performance in a conventional CAD scheme is very complicated and arduous. Deep learning techniques, on the other hand, have the intrinsic advantage of an automatic exploitation feature and tuning of performance in a seamless fashion. In this study, we attempted to simplify the image analysis pipeline of conventional CAD with deep learning techniques. Specifically, we introduced models of a deep belief network and a convolutional neural network in the context of nodule classification in computed tomography images. Two baseline methods with feature computing steps were implemented for comparison. The experimental results suggest that deep learning methods could achieve better discriminative results and hold promise in the CAD application domain.",
            "referenceCount": 23,
            "citationCount": 430,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.dovepress.com/getfile.php?fileID=26305",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-08-04",
            "journal": {
                "name": "OncoTargets and therapy",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Hua2015ComputeraidedCO,\n author = {K. Hua and Che-Hao Hsu and S. Hidayati and Wen-Huang Cheng and Yu-Jen Chen},\n booktitle = {OncoTargets and Therapy},\n journal = {OncoTargets and therapy},\n pages = {2015 - 2022},\n title = {Computer-aided classification of lung nodules on computed tomography images via deep learning technique},\n volume = {8},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f7100e9fd9b87c7d8cff9fea986254afadb392ea",
            "@type": "ScholarlyArticle",
            "paperId": "f7100e9fd9b87c7d8cff9fea986254afadb392ea",
            "corpusId": 26334788,
            "url": "https://www.semanticscholar.org/paper/f7100e9fd9b87c7d8cff9fea986254afadb392ea",
            "title": "Deep learning for steganalysis via convolutional neural networks",
            "venue": "Electronic imaging",
            "publicationVenue": {
                "id": "urn:research:d068a5ed-de42-4f73-8312-51d07ecc19b7",
                "name": "Electronic imaging",
                "alternate_names": [
                    "Electron imaging",
                    "electron imaging",
                    "electronic imaging"
                ],
                "issn": "0737-6553",
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2046180645",
                "DBLP": "conf/mediaforensics/QianD0T15",
                "DOI": "10.1117/12.2083479",
                "CorpusId": 26334788
            },
            "abstract": "Current work on steganalysis for digital images is focused on the construction of complex handcrafted features. This paper proposes a new paradigm for steganalysis to learn features automatically via deep learning models. We novelly propose a customized Convolutional Neural Network for steganalysis. The proposed model can capture the complex dependencies that are useful for steganalysis. Compared with existing schemes, this model can automatically learn feature representations with several convolutional layers. The feature extraction and classification steps are unified under a single architecture, which means the guidance of classification can be used during the feature extraction step. We demonstrate the effectiveness of the proposed model on three state-of-theart spatial domain steganographic algorithms - HUGO, WOW, and S-UNIWARD. Compared to the Spatial Rich Model (SRM), our model achieves comparable performance on BOSSbase and the realistic and large ImageNet database.",
            "referenceCount": 28,
            "citationCount": 419,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-03-04",
            "journal": {
                "name": null,
                "volume": "9409"
            },
            "citationStyles": {
                "bibtex": "@Article{Qian2015DeepLF,\n author = {Y. Qian and Jing Dong and Wei Wang and T. Tan},\n booktitle = {Electronic imaging},\n title = {Deep learning for steganalysis via convolutional neural networks},\n volume = {9409},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:33690ff21ef1efb576410e656f2e60c89d0307d6",
            "@type": "ScholarlyArticle",
            "paperId": "33690ff21ef1efb576410e656f2e60c89d0307d6",
            "corpusId": 4674781,
            "url": "https://www.semanticscholar.org/paper/33690ff21ef1efb576410e656f2e60c89d0307d6",
            "title": "Deep Reinforcement Learning that Matters",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/aaai/0002IBPPM18",
                "MAG": "2963120839",
                "ArXiv": "1709.06560",
                "DOI": "10.1609/aaai.v32i1.11694",
                "CorpusId": 4674781
            },
            "abstract": "\n \n In recent years, significant progress has been made in solving challenging problems across various domains using deep reinforcement learning (RL). Reproducing existing work and accurately judging the improvements offered by novel methods is vital to sustaining this progress. Unfortunately, reproducing results for state-of-the-art deep RL methods is seldom straightforward. In particular, non-determinism in standard benchmark environments, combined with variance intrinsic to the methods, can make reported results tough to interpret. Without significance metrics and tighter standardization of experimental reporting, it is difficult to determine whether improvements over the prior state-of-the-art are meaningful. In this paper, we investigate challenges posed by reproducibility, proper experimental techniques, and reporting procedures. We illustrate the variability in reported metrics and results when comparing against common baselines and suggest guidelines to make future results in deep RL more reproducible. We aim to spur discussion about how to ensure continued progress in the field by minimizing wasted effort stemming from results that are non-reproducible and easily misinterpreted.\n \n",
            "referenceCount": 43,
            "citationCount": 1553,
            "influentialCitationCount": 100,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/11694/11553",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-09-19",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Henderson2017DeepRL,\n author = {Peter Henderson and Riashat Islam and Philip Bachman and Joelle Pineau and Doina Precup and D. Meger},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {3207-3214},\n title = {Deep Reinforcement Learning that Matters},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4417f78b31546227784941bbd6f6532a177e60b8",
            "@type": "ScholarlyArticle",
            "paperId": "4417f78b31546227784941bbd6f6532a177e60b8",
            "corpusId": 6928185,
            "url": "https://www.semanticscholar.org/paper/4417f78b31546227784941bbd6f6532a177e60b8",
            "title": "Deep Learning using Linear Support Vector Machines",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "MAG": "1546411676",
                "ArXiv": "1306.0239",
                "CorpusId": 6928185
            },
            "abstract": "Recently, fully-connected and convolutional neural networks have been trained to achieve state-of-the-art performance on a wide variety of tasks such as speech recognition, image classification, natural language processing, and bioinformatics. For classification tasks, most of these \"deep learning\" models employ the softmax activation function for prediction and minimize cross-entropy loss. In this paper, we demonstrate a small but consistent advantage of replacing the softmax layer with a linear support vector machine. Learning minimizes a margin-based loss instead of the cross-entropy loss. While there have been various combinations of neural nets and SVMs in prior art, our results using L2-SVMs show that by simply replacing softmax with linear SVMs gives significant gains on popular deep learning datasets MNIST, CIFAR-10, and the ICML 2013 Representation Learning Workshop's face expression recognition challenge.",
            "referenceCount": 25,
            "citationCount": 822,
            "influentialCitationCount": 82,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2013-06-02",
            "journal": {
                "name": "arXiv: Learning",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Tang2013DeepLU,\n author = {Yichuan Tang},\n journal = {arXiv: Learning},\n title = {Deep Learning using Linear Support Vector Machines},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0ba19bb88c856b880d198f4b6e9dcf8144657df8",
            "@type": "ScholarlyArticle",
            "paperId": "0ba19bb88c856b880d198f4b6e9dcf8144657df8",
            "corpusId": 2658860,
            "url": "https://www.semanticscholar.org/paper/0ba19bb88c856b880d198f4b6e9dcf8144657df8",
            "title": "End-to-End Learning of Geometry and Context for Deep Stereo Regression",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/iccv/KendallMDH17",
                "MAG": "2951179855",
                "ArXiv": "1703.04309",
                "DOI": "10.1109/ICCV.2017.17",
                "CorpusId": 2658860
            },
            "abstract": "We propose a novel deep learning architecture for regressing disparity from a rectified pair of stereo images. We leverage knowledge of the problem\u2019s geometry to form a cost volume using deep feature representations. We learn to incorporate contextual information using 3-D convolutions over this volume. Disparity values are regressed from the cost volume using a proposed differentiable soft argmin operation, which allows us to train our method end-to-end to sub-pixel accuracy without any additional post-processing or regularization. We evaluate our method on the Scene Flow and KITTI datasets and on KITTI we set a new stateof-the-art benchmark, while being significantly faster than competing approaches.",
            "referenceCount": 48,
            "citationCount": 1056,
            "influentialCitationCount": 225,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/1703.04309",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-13",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kendall2017EndtoEndLO,\n author = {Alex Kendall and H. Martirosyan and Saumitro Dasgupta and Peter Henry},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2017 IEEE International Conference on Computer Vision (ICCV)},\n pages = {66-75},\n title = {End-to-End Learning of Geometry and Context for Deep Stereo Regression},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5cc51fb6ecadc853cb4017a43fb644ad1b852bc1",
            "@type": "ScholarlyArticle",
            "paperId": "5cc51fb6ecadc853cb4017a43fb644ad1b852bc1",
            "corpusId": 11362170,
            "url": "https://www.semanticscholar.org/paper/5cc51fb6ecadc853cb4017a43fb644ad1b852bc1",
            "title": "Chest pathology detection using deep learning with non-medical training",
            "venue": "IEEE International Symposium on Biomedical Imaging",
            "publicationVenue": {
                "id": "urn:research:a38e0d3d-6929-4868-b4e4-af8bbacf711e",
                "name": "IEEE International Symposium on Biomedical Imaging",
                "alternate_names": [
                    "ISBI",
                    "International Symposium on Biomedical Imaging",
                    "Int Symp Biomed Imaging",
                    "IEEE Int Symp Biomed Imaging"
                ],
                "issn": "1945-7928",
                "url": "http://www.biomedicalimaging.org/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/isbi/BarDWLKG15",
                "MAG": "1570613334",
                "DOI": "10.1109/ISBI.2015.7163871",
                "CorpusId": 11362170
            },
            "abstract": "In this work, we examine the strength of deep learning approaches for pathology detection in chest radiographs. Convolutional neural networks (CNN) deep architecture classification approaches have gained popularity due to their ability to learn mid and high level image representations. We explore the ability of CNN learned from a non-medical dataset to identify different types of pathologies in chest x-rays. We tested our algorithm on a 433 image dataset. The best performance was achieved using CNN and GIST features. We obtained an area under curve (AUC) of 0.87-0.94 for the different pathologies. The results demonstrate the feasibility of detecting pathology in chest x-rays using deep learning approaches based on non-medical learning. This is a first-of-its-kind experiment that shows that Deep learning with ImageNet, a large scale non-medical image database may be a good substitute to domain specific representations, which are yet to be available, for general medical image recognition tasks.",
            "referenceCount": 15,
            "citationCount": 346,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-04-16",
            "journal": {
                "name": "2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bar2015ChestPD,\n author = {Yaniv Bar and I. Diamant and Lior Wolf and S. Lieberman and E. Konen and H. Greenspan},\n booktitle = {IEEE International Symposium on Biomedical Imaging},\n journal = {2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)},\n pages = {294-297},\n title = {Chest pathology detection using deep learning with non-medical training},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1c3e323d69a41ca914f714e6c1c88ee1e1d9c06a",
            "@type": "ScholarlyArticle",
            "paperId": "1c3e323d69a41ca914f714e6c1c88ee1e1d9c06a",
            "corpusId": 13068979,
            "url": "https://www.semanticscholar.org/paper/1c3e323d69a41ca914f714e6c1c88ee1e1d9c06a",
            "title": "Towards Biologically Plausible Deep Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/BengioLBL15",
                "MAG": "1520121841",
                "ArXiv": "1502.04156",
                "CorpusId": 13068979
            },
            "abstract": "Neuroscientists have long criticised deep learning algorithms as incompatible with current knowledge of neurobiology. We explore more biologically plausible versions of deep representation learning, focusing here mostly on unsupervised learning but developing a learning mechanism that could account for supervised, unsupervised and reinforcement learning. The starting point is that the basic learning rule believed to govern synaptic weight updates (Spike-TimingDependent Plasticity) can be interpreted as gradient descent on some objective function so long as the neuronal dynamics push firing rates towards better values of the objective function (be it supervised, unsupervised, or reward-driven). The second main idea is that this corresponds to a form of the variational EM algorithm, i.e., with approximate rather than exact posteriors, implemented by neural dynamics. Another contribution of this paper is that the gradients required for updating the hidden states in the above variational interpretation can be estimated using an approximation that only requires propagating activations forward and backward, with pairs of layers learning to form a denoising auto-encoder. Finally, we extend the theory about the probabilistic interpretation of auto-encoders to justify improved sampling schemes based on the generative interpretation of denoising auto-encoders, and we validate all these ideas on generative learning tasks.",
            "referenceCount": 43,
            "citationCount": 308,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-02-13",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1502.04156"
            },
            "citationStyles": {
                "bibtex": "@Article{Bengio2015TowardsBP,\n author = {Yoshua Bengio and Dong-Hyun Lee and J. Bornschein and Zhouhan Lin},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Towards Biologically Plausible Deep Learning},\n volume = {abs/1502.04156},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1b6d713d303a97d66c98b93f04b0d405cad79621",
            "@type": "ScholarlyArticle",
            "paperId": "1b6d713d303a97d66c98b93f04b0d405cad79621",
            "corpusId": 14770183,
            "url": "https://www.semanticscholar.org/paper/1b6d713d303a97d66c98b93f04b0d405cad79621",
            "title": "Gene expression inference with deep learning",
            "venue": "bioRxiv",
            "publicationVenue": {
                "id": "urn:research:027ffd21-ebb0-4af8-baf5-911124292fd0",
                "name": "bioRxiv",
                "alternate_names": null,
                "issn": null,
                "url": "http://biorxiv.org/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/bioinformatics/ChenLNSX16",
                "MAG": "2951484915",
                "DOI": "10.1101/034421",
                "CorpusId": 14770183,
                "PubMed": "26873929"
            },
            "abstract": "Motivation Large-scale gene expression profiling has been widely used to characterize cellular states in response to various disease conditions, genetic perturbations, etc. Although the cost of whole-genome expression profiles has been dropping steadily, generating a compendium of expression profiling over thousands of samples is still very expensive. Recognizing that gene expressions are often highly correlated, researchers from the NIH LINCS program have developed a cost-effective strategy of profiling only \u1fc01,000 carefully selected landmark genes and relying on computational methods to infer the expression of remaining target genes. However, the computational approach adopted by the LINCS program is currently based on linear regression, limiting its accuracy since it does not capture complex nonlinear relationship between expression of genes. Results We present a deep learning method (abbreviated as D-GEX) to infer the expression of target genes from the expression of landmark genes. We used the microarray-based GEO dataset, consisting of 111K expression profiles, to train our model and compare its performance to those from other methods. In terms of mean absolute error averaged across all genes, deep learning significantly outperforms linear regression with 15.33% relative improvement. A gene-wise comparative analysis shows that deep learning achieves lower error than linear regression in 99.97% of the target genes. We also tested the performance of our learned model on an independent RNA-Seq-based GTEx dataset, which consists of 2,921 expression profiles. Deep learning still outperforms linear regression with 6.57% relative improvement, and achieves lower error in 81.31% of the target genes. Availability D-GEX is available at https://github.com/uci-cbcl/D-GEX. Contact xhx@ics.uci.edu",
            "referenceCount": 39,
            "citationCount": 331,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/bioinformatics/article-pdf/32/12/1832/49021690/bioinformatics_32_12_1832.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Biology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-12-15",
            "journal": {
                "name": "bioRxiv",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2015GeneEI,\n author = {Yifei Chen and Yi Li and Rajiv Narayan and A. Subramanian and Xiaohui Xie},\n booktitle = {bioRxiv},\n journal = {bioRxiv},\n title = {Gene expression inference with deep learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:83d410601e3d55fab285926882828a48e23b97e4",
            "@type": "ScholarlyArticle",
            "paperId": "83d410601e3d55fab285926882828a48e23b97e4",
            "corpusId": 52169381,
            "url": "https://www.semanticscholar.org/paper/83d410601e3d55fab285926882828a48e23b97e4",
            "title": "Transferable Representation Learning with Deep Adaptation Networks",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/pami/LongCCWJ19",
                "MAG": "2889945482",
                "DOI": "10.1109/TPAMI.2018.2868685",
                "CorpusId": 52169381,
                "PubMed": "30188813"
            },
            "abstract": "Domain adaptation studies learning algorithms that generalize across source domains and target domains that exhibit different distributions. Recent studies reveal that deep neural networks can learn transferable features that generalize well to similar novel tasks. However, as deep features eventually transition from general to specific along the network, feature transferability drops significantly in higher task-specific layers with increasing domain discrepancy. To formally reduce the effects of this discrepancy and enhance feature transferability in task-specific layers, we develop a novel framework for deep adaptation networks that extends deep convolutional neural networks to domain adaptation problems. The framework embeds the deep features of all task-specific layers into reproducing kernel Hilbert spaces (RKHSs) and optimally matches different domain distributions. The deep features are made more transferable by exploiting low-density separation of target-unlabeled data in very deep architectures, while the domain discrepancy is further reduced via the use of multiple kernel learning that enhances the statistical power of kernel embedding matching. The overall framework is cast in a minimax game setting. Extensive empirical evidence shows that the proposed networks yield state-of-the-art results on standard visual domain-adaptation benchmarks.",
            "referenceCount": 56,
            "citationCount": 381,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-12-01",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "41"
            },
            "citationStyles": {
                "bibtex": "@Article{Long2019TransferableRL,\n author = {Mingsheng Long and Yue Cao and Zhangjie Cao and Jianmin Wang and Michael I. Jordan},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {3071-3085},\n title = {Transferable Representation Learning with Deep Adaptation Networks},\n volume = {41},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:370a5f4b305540f35821d2179c384f95f5a63eee",
            "@type": "ScholarlyArticle",
            "paperId": "370a5f4b305540f35821d2179c384f95f5a63eee",
            "corpusId": 367166,
            "url": "https://www.semanticscholar.org/paper/370a5f4b305540f35821d2179c384f95f5a63eee",
            "title": "Toward Deep Learning Software Repositories",
            "venue": "2015 IEEE/ACM 12th Working Conference on Mining Software Repositories",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/msr/WhiteVVP15",
                "MAG": "2018389835",
                "DOI": "10.1109/MSR.2015.38",
                "CorpusId": 367166
            },
            "abstract": "Deep learning subsumes algorithms that automatically learn compositional representations. The ability of these models to generalize well has ushered in tremendous advances in many fields such as natural language processing (NLP). Recent research in the software engineering (SE) community has demonstrated the usefulness of applying NLP techniques to software corpora. Hence, we motivate deep learning for software language modeling, highlighting fundamental differences between state-of-the-practice software language models and connectionist models. Our deep learning models are applicable to source code files (since they only require lexically analyzed source code written in any programming language) and other types of artifacts. We show how a particular deep learning model can remember its state to effectively model sequential data, e.g., Streaming software tokens, and the state is shown to be much more expressive than discrete tokens in a prefix. Then we instantiate deep learning models and show that deep learning induces high-quality models compared to n-grams and cache-based n-grams on a corpus of Java projects. We experiment with two of the models' hyper parameters, which govern their capacity and the amount of context they use to inform predictions, before building several committees of software language models to aid generalization. Then we apply the deep learning models to code suggestion and demonstrate their effectiveness at a real SE task compared to state-of-the-practice models. Finally, we propose avenues for future work, where deep learning can be brought to bear to support model-based testing, improve software lexicons, and conceptualize software artifacts. Thus, our work serves as the first step toward deep learning software repositories.",
            "referenceCount": 85,
            "citationCount": 283,
            "influentialCitationCount": 20,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cs.wm.edu/%7Edenys/pubs/MSR%2715-DeepLearning-CRC.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-05-16",
            "journal": {
                "name": "2015 IEEE/ACM 12th Working Conference on Mining Software Repositories",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{White2015TowardDL,\n author = {Martin White and Christopher Vendome and M. V\u00e1squez and D. Poshyvanyk},\n booktitle = {2015 IEEE/ACM 12th Working Conference on Mining Software Repositories},\n journal = {2015 IEEE/ACM 12th Working Conference on Mining Software Repositories},\n pages = {334-345},\n title = {Toward Deep Learning Software Repositories},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:21d2d64408fcfbe6f2c8d0cb53a614dcdb16ede5",
            "@type": "ScholarlyArticle",
            "paperId": "21d2d64408fcfbe6f2c8d0cb53a614dcdb16ede5",
            "corpusId": 6393352,
            "url": "https://www.semanticscholar.org/paper/21d2d64408fcfbe6f2c8d0cb53a614dcdb16ede5",
            "title": "Pedestrian detection aided by deep learning semantic tasks",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2014,
            "externalIds": {
                "ArXiv": "1412.0069",
                "DBLP": "conf/cvpr/TianLWT15",
                "MAG": "1903127635",
                "DOI": "10.1109/CVPR.2015.7299143",
                "CorpusId": 6393352
            },
            "abstract": "Deep learning methods have achieved great successes in pedestrian detection, owing to its ability to learn discriminative features from raw pixels. However, they treat pedestrian detection as a single binary classification task, which may confuse positive with hard negative samples (Fig.1 (a)). To address this ambiguity, this work jointly optimize pedestrian detection with semantic tasks, including pedestrian attributes (e.g. `carrying backpack') and scene attributes (e.g. `vehicle', `tree', and `horizontal'). Rather than expensively annotating scene attributes, we transfer attributes information from existing scene segmentation datasets to the pedestrian dataset, by proposing a novel deep model to learn high-level features from multiple tasks and multiple data sources. Since distinct tasks have distinct convergence rates and data from different datasets have different distributions, a multi-task deep model is carefully designed to coordinate tasks and reduce discrepancies among datasets. Extensive evaluations show that the proposed approach outperforms the state-of-the-art on the challenging Caltech [9] and ETH [10] datasets where it reduces the miss rates of previous deep models by 17 and 5.5 percent, respectively.",
            "referenceCount": 43,
            "citationCount": 418,
            "influentialCitationCount": 46,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.ee.cuhk.edu.hk/%7Exgwang/papers/tianLWTcvpr15.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-11-28",
            "journal": {
                "name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tian2014PedestrianDA,\n author = {Yonglong Tian and Ping Luo and Xiaogang Wang and Xiaoou Tang},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {5079-5087},\n title = {Pedestrian detection aided by deep learning semantic tasks},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2b1a3d7e6045dc6b544a548b372c1f8492b85967",
            "@type": "ScholarlyArticle",
            "paperId": "2b1a3d7e6045dc6b544a548b372c1f8492b85967",
            "corpusId": 13748870,
            "url": "https://www.semanticscholar.org/paper/2b1a3d7e6045dc6b544a548b372c1f8492b85967",
            "title": "Realistic Evaluation of Deep Semi-Supervised Learning Algorithms",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2951820285",
                "DBLP": "conf/nips/OliverORCG18",
                "ArXiv": "1804.09170",
                "CorpusId": 13748870
            },
            "abstract": "Semi-supervised learning (SSL) provides a powerful framework for leveraging unlabeled data when labels are limited or expensive to obtain. SSL algorithms based on deep neural networks have recently proven successful on standard benchmark tasks. However, we argue that these benchmarks fail to address many issues that these algorithms would face in real-world applications. After creating a unified reimplementation of various widely-used SSL techniques, we test them in a suite of experiments designed to address these issues. We find that the performance of simple baselines which do not use unlabeled data is often underreported, that SSL methods differ in sensitivity to the amount of labeled and unlabeled data, and that performance can degrade substantially when the unlabeled dataset contains out-of-class examples. To help guide SSL research towards real-world applicability, we make our unified reimplemention and evaluation platform publicly available.",
            "referenceCount": 58,
            "citationCount": 802,
            "influentialCitationCount": 103,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Oliver2018RealisticEO,\n author = {Avital Oliver and Augustus Odena and Colin Raffel and E. D. Cubuk and I. Goodfellow},\n booktitle = {Neural Information Processing Systems},\n pages = {3239-3250},\n title = {Realistic Evaluation of Deep Semi-Supervised Learning Algorithms},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:798d9840d2439a0e5d47bcf5d164aa46d5e7dc26",
            "@type": "ScholarlyArticle",
            "paperId": "798d9840d2439a0e5d47bcf5d164aa46d5e7dc26",
            "corpusId": 18507866,
            "url": "https://www.semanticscholar.org/paper/798d9840d2439a0e5d47bcf5d164aa46d5e7dc26",
            "title": "Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2946635600",
                "CorpusId": 18507866
            },
            "abstract": "We propose the simple and e\ufb03cient method of semi-supervised learning for deep neural networks. Basically, the proposed network is trained in a supervised fashion with labeled and unlabeled data simultaneously. For unlabeled data, Pseudo-Label s, just picking up the class which has the maximum network output, are used as if they were true labels. Without any unsupervised pre-training method, this simple method with dropout shows the state-of-the-art performance.",
            "referenceCount": 17,
            "citationCount": 2780,
            "influentialCitationCount": 298,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Lee2013PseudoLabelT,\n author = {Dong-Hyun Lee},\n title = {Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5460c1cde49a0d89575f9b4e59d51c06139f436b",
            "@type": "ScholarlyArticle",
            "paperId": "5460c1cde49a0d89575f9b4e59d51c06139f436b",
            "corpusId": 30627853,
            "url": "https://www.semanticscholar.org/paper/5460c1cde49a0d89575f9b4e59d51c06139f436b",
            "title": "Jet-images \u2014 deep learning edition",
            "venue": "Journal of High Energy Physics",
            "publicationVenue": {
                "id": "urn:research:cb5c6d2c-8c82-406e-b42e-b691561f3e4e",
                "name": "Journal of High Energy Physics",
                "alternate_names": [
                    "J High Energy Phys"
                ],
                "issn": "1029-8479",
                "url": "http://www.springer.com/13130"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1511.05190",
                "MAG": "2257617748",
                "DOI": "10.1007/JHEP07(2016)069",
                "CorpusId": 30627853
            },
            "abstract": null,
            "referenceCount": 49,
            "citationCount": 286,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2FJHEP07%282016%29069.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Physics",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2015-11-16",
            "journal": {
                "name": "Journal of High Energy Physics",
                "volume": "2016"
            },
            "citationStyles": {
                "bibtex": "@Article{Oliveira2015JetimagesD,\n author = {Luke de Oliveira and M. Kagan and Lester W. Mackey and B. Nachman and A. Schwartzman},\n booktitle = {Journal of High Energy Physics},\n journal = {Journal of High Energy Physics},\n title = {Jet-images \u2014 deep learning edition},\n volume = {2016},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:884750937bb97e82c41316d80e5d104e0c0e4795",
            "@type": "ScholarlyArticle",
            "paperId": "884750937bb97e82c41316d80e5d104e0c0e4795",
            "corpusId": 5726681,
            "url": "https://www.semanticscholar.org/paper/884750937bb97e82c41316d80e5d104e0c0e4795",
            "title": "Deep Metric Learning via Lifted Structured Feature Embedding",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2176040302",
                "ArXiv": "1511.06452",
                "DBLP": "journals/corr/SongXJS15",
                "DOI": "10.1109/CVPR.2016.434",
                "CorpusId": 5726681
            },
            "abstract": "Learning the distance metric between pairs of examples is of great importance for learning and visual recognition. With the remarkable success from the state of the art convolutional neural networks, recent works [1, 31] have shown promising results on discriminatively training the networks to learn semantic feature embeddings where similar examples are mapped close to each other and dissimilar examples are mapped farther apart. In this paper, we describe an algorithm for taking full advantage of the training batches in the neural network training by lifting the vector of pairwise distances within the batch to the matrix of pairwise distances. This step enables the algorithm to learn the state of the art feature embedding by optimizing a novel structured prediction objective on the lifted problem. Additionally, we collected Stanford Online Products dataset: 120k images of 23k classes of online products for metric learning. Our experiments on the CUB-200-2011 [37], CARS196 [19], and Stanford Online Products datasets demonstrate significant improvement over existing deep feature embedding methods on all experimented embedding sizes with the GoogLeNet [33] network. The source code and the dataset are available at: https://github.com/rksltnl/ Deep-Metric-Learning-CVPR16.",
            "referenceCount": 38,
            "citationCount": 1443,
            "influentialCitationCount": 306,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dspace.mit.edu/bitstream/1721.1/113397/1/Jegelka_Deep%20metric.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-11-19",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Song2015DeepML,\n author = {Hyun Oh Song and Yu Xiang and S. Jegelka and S. Savarese},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {4004-4012},\n title = {Deep Metric Learning via Lifted Structured Feature Embedding},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b5c98214f5a03813323bf7dbee376b6ef735e5fe",
            "@type": "ScholarlyArticle",
            "paperId": "b5c98214f5a03813323bf7dbee376b6ef735e5fe",
            "corpusId": 6843798,
            "url": "https://www.semanticscholar.org/paper/b5c98214f5a03813323bf7dbee376b6ef735e5fe",
            "title": "Hands Deep in Deep Learning for Hand Pose Estimation",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/OberwegerWL15",
                "ArXiv": "1502.06807",
                "MAG": "1702419847",
                "CorpusId": 6843798
            },
            "abstract": "We introduce and evaluate several architectures for Convolutional Neural Networks to predict the 3D joint locations of a hand given a depth map. We first show that a prior on the 3D pose can be easily introduced and significantly improves the accuracy and reliability of the predictions. We also show how to use context efficiently to deal with ambiguities between fingers. These two contributions allow us to significantly outperform the state-of-the-art on several challenging benchmarks, both in terms of accuracy and computation times.",
            "referenceCount": 29,
            "citationCount": 358,
            "influentialCitationCount": 71,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-02-24",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1502.06807"
            },
            "citationStyles": {
                "bibtex": "@Article{Oberweger2015HandsDI,\n author = {Markus Oberweger and Paul Wohlhart and V. Lepetit},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Hands Deep in Deep Learning for Hand Pose Estimation},\n volume = {abs/1502.06807},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ba013acca784bfea74241c879e18b72984950493",
            "@type": "ScholarlyArticle",
            "paperId": "ba013acca784bfea74241c879e18b72984950493",
            "corpusId": 102350936,
            "url": "https://www.semanticscholar.org/paper/ba013acca784bfea74241c879e18b72984950493",
            "title": "On The Power of Curriculum Learning in Training Deep Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2926516160",
                "ArXiv": "1904.03626",
                "DBLP": "conf/icml/HacohenW19",
                "CorpusId": 102350936
            },
            "abstract": "Training neural networks is traditionally done by providing a sequence of random mini-batches sampled uniformly from the entire training data. In this work, we analyze the effect of curriculum learning, which involves the non-uniform sampling of mini-batches, on the training of deep networks, and specifically CNNs trained for image recognition. To employ curriculum learning, the training algorithm must resolve 2 problems: (i) sort the training examples by difficulty; (ii) compute a series of mini-batches that exhibit an increasing level of difficulty. We address challenge (i) using two methods: transfer learning from some competitive ``teacher\" network, and bootstrapping. In our empirical evaluation, both methods show similar benefits in terms of increased learning speed and improved final performance on test data. We address challenge (ii) by investigating different pacing functions to guide the sampling. The empirical investigation includes a variety of network architectures, using images from CIFAR-10, CIFAR-100 and subsets of ImageNet. We conclude with a novel theoretical analysis of curriculum learning, where we show how it effectively modifies the optimization landscape. We then define the concept of an ideal curriculum, and show that under mild conditions it does not change the corresponding global minimum of the optimization function.",
            "referenceCount": 33,
            "citationCount": 314,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hacohen2019OnTP,\n author = {Guy Hacohen and D. Weinshall},\n booktitle = {International Conference on Machine Learning},\n pages = {2535-2544},\n title = {On The Power of Curriculum Learning in Training Deep Networks},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c48e85a7a4ed7895096ae074a6c544415e6c4b85",
            "@type": "ScholarlyArticle",
            "paperId": "c48e85a7a4ed7895096ae074a6c544415e6c4b85",
            "corpusId": 3353375,
            "url": "https://www.semanticscholar.org/paper/c48e85a7a4ed7895096ae074a6c544415e6c4b85",
            "title": "RAPID: Rating Pictorial Aesthetics using Deep Learning",
            "venue": "ACM Multimedia",
            "publicationVenue": {
                "id": "urn:research:f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                "name": "ACM Multimedia",
                "alternate_names": [
                    "MM"
                ],
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/mm/LuLJYW14",
                "MAG": "2009678853",
                "DOI": "10.1145/2647868.2654927",
                "CorpusId": 3353375
            },
            "abstract": "Effective visual features are essential for computational aesthetic quality rating systems. Existing methods used machine learning and statistical modeling techniques on handcrafted features or generic image descriptors. A recently-published large-scale dataset, the AVA dataset, has further empowered machine learning based approaches. We present the RAPID (RAting PIctorial aesthetics using Deep learning) system, which adopts a novel deep neural network approach to enable automatic feature learning. The central idea is to incorporate heterogeneous inputs generated from the image, which include a global view and a local view, and to unify the feature learning and classifier training using a double-column deep convolutional neural network. In addition, we utilize the style attributes of images to help improve the aesthetic quality categorization accuracy. Experimental results show that our approach significantly outperforms the state of the art on the AVA dataset.",
            "referenceCount": 33,
            "citationCount": 349,
            "influentialCitationCount": 49,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Art",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2014-11-03",
            "journal": {
                "name": "Proceedings of the 22nd ACM international conference on Multimedia",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Lu2014RAPIDRP,\n author = {Xin Lu and Zhe L. Lin and Hailin Jin and Jianchao Yang and J. Z. Wang},\n booktitle = {ACM Multimedia},\n journal = {Proceedings of the 22nd ACM international conference on Multimedia},\n title = {RAPID: Rating Pictorial Aesthetics using Deep Learning},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6ff50528f3d7c72772f8c0e3f8398f9dd8e06575",
            "@type": "ScholarlyArticle",
            "paperId": "6ff50528f3d7c72772f8c0e3f8398f9dd8e06575",
            "corpusId": 166228022,
            "url": "https://www.semanticscholar.org/paper/6ff50528f3d7c72772f8c0e3f8398f9dd8e06575",
            "title": "Adversarial Policies: Attacking Deep Reinforcement Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1905.10615",
                "MAG": "2945924974",
                "DBLP": "conf/iclr/GleaveDWKLR20",
                "CorpusId": 166228022
            },
            "abstract": "Deep reinforcement learning (RL) policies are known to be vulnerable to adversarial perturbations to their observations, similar to adversarial examples for classifiers. However, an attacker is not usually able to directly modify another agent's observations. This might lead one to wonder: is it possible to attack an RL agent simply by choosing an adversarial policy acting in a multi-agent environment so as to create natural observations that are adversarial? We demonstrate the existence of adversarial policies in zero-sum games between simulated humanoid robots with proprioceptive observations, against state-of-the-art victims trained via self-play to be robust to opponents. The adversarial policies reliably win against the victims but generate seemingly random and uncoordinated behavior. We find that these policies are more successful in high-dimensional environments, and induce substantially different activations in the victim policy network than when the victim plays against a normal opponent. Videos are available at this https URL.",
            "referenceCount": 39,
            "citationCount": 275,
            "influentialCitationCount": 38,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-05-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1905.10615"
            },
            "citationStyles": {
                "bibtex": "@Article{Gleave2019AdversarialPA,\n author = {A. Gleave and Michael Dennis and Neel Kant and Cody Wild and S. Levine and Stuart J. Russell},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Adversarial Policies: Attacking Deep Reinforcement Learning},\n volume = {abs/1905.10615},\n year = {2019}\n}\n"
            }
        }
    }
]