[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:484ad17c926292fbe0d5211540832a8c8a8e958b",
            "@type": "ScholarlyArticle",
            "paperId": "484ad17c926292fbe0d5211540832a8c8a8e958b",
            "corpusId": 16895865,
            "url": "https://www.semanticscholar.org/paper/484ad17c926292fbe0d5211540832a8c8a8e958b",
            "title": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1909320841",
                "DBLP": "conf/icml/RezendeMW14",
                "CorpusId": 16895865
            },
            "abstract": "We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic back-propagation -- rules for back-propagation through stochastic variables -- and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.",
            "referenceCount": 38,
            "citationCount": 4708,
            "influentialCitationCount": 731,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-01-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Rezende2014StochasticBA,\n author = {Danilo Jimenez Rezende and S. Mohamed and Daan Wierstra},\n booktitle = {International Conference on Machine Learning},\n pages = {1278-1286},\n title = {Stochastic Backpropagation and Approximate Inference in Deep Generative Models},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2f4c451922e227cbbd4f090b74298445bbd900d0",
            "@type": "ScholarlyArticle",
            "paperId": "2f4c451922e227cbbd4f090b74298445bbd900d0",
            "corpusId": 249240415,
            "url": "https://www.semanticscholar.org/paper/2f4c451922e227cbbd4f090b74298445bbd900d0",
            "title": "Elucidating the Design Space of Diffusion-Based Generative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2022,
            "externalIds": {
                "DBLP": "journals/corr/abs-2206-00364",
                "ArXiv": "2206.00364",
                "DOI": "10.48550/arXiv.2206.00364",
                "CorpusId": 249240415
            },
            "abstract": "We argue that the theory and practice of diffusion-based generative models are currently unnecessarily convoluted and seek to remedy the situation by presenting a design space that clearly separates the concrete design choices. This lets us identify several changes to both the sampling and training processes, as well as preconditioning of the score networks. Together, our improvements yield new state-of-the-art FID of 1.79 for CIFAR-10 in a class-conditional setting and 1.97 in an unconditional setting, with much faster sampling (35 network evaluations per image) than prior designs. To further demonstrate their modular nature, we show that our design changes dramatically improve both the efficiency and quality obtainable with pre-trained score networks from previous work, including improving the FID of a previously trained ImageNet-64 model from 2.07 to near-SOTA 1.55, and after re-training with our proposed improvements to a new SOTA of 1.36.",
            "referenceCount": 62,
            "citationCount": 483,
            "influentialCitationCount": 144,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/2206.00364",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2022-06-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2206.00364"
            },
            "citationStyles": {
                "bibtex": "@Article{Karras2022ElucidatingTD,\n author = {Tero Karras and M. Aittala and Timo Aila and S. Laine},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Elucidating the Design Space of Diffusion-Based Generative Models},\n volume = {abs/2206.00364},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9cbc044e315cdefe9a255119037ac7c23e9abdd5",
            "@type": "ScholarlyArticle",
            "paperId": "9cbc044e315cdefe9a255119037ac7c23e9abdd5",
            "corpusId": 246867298,
            "url": "https://www.semanticscholar.org/paper/9cbc044e315cdefe9a255119037ac7c23e9abdd5",
            "title": "Predictability and Surprise in Large Generative Models",
            "venue": "Conference on Fairness, Accountability and Transparency",
            "publicationVenue": {
                "id": "urn:research:cdc83875-a82d-445c-b097-cbe91afe99a8",
                "name": "Conference on Fairness, Accountability and Transparency",
                "alternate_names": [
                    "FAccT",
                    "Conf Fairness Account Transpar"
                ],
                "issn": null,
                "url": "https://facctconference.org/"
            },
            "year": 2022,
            "externalIds": {
                "ArXiv": "2202.07785",
                "DBLP": "journals/corr/abs-2202-07785",
                "DOI": "10.1145/3531146.3533229",
                "CorpusId": 246867298
            },
            "abstract": "Large-scale pre-training has recently emerged as a technique for creating capable, general-purpose, generative models such as GPT-3, Megatron-Turing NLG, Gopher, and many others. In this paper, we highlight a counterintuitive property of such models and discuss the policy implications of this property. Namely, these generative models have a paradoxical combination of predictable loss on a broad training distribution (as embodied in their \u201dscaling laws\u201d), and unpredictable specific capabilities, inputs, and outputs. We believe that the high-level predictability and appearance of useful capabilities drives rapid development of such models, while the unpredictable qualities make it difficult to anticipate the consequences of model deployment. We go through examples of how this combination can lead to socially harmful behavior with examples from the literature and real world observations, and we also perform two novel experiments to illustrate our point about harms from unpredictability. Furthermore, we analyze how these conflicting properties combine to give model developers various motivations for deploying these models, and challenges that can hinder deployment. We conclude with a list of possible interventions the AI community may take to increase the chance of these models having a beneficial impact. We intend for this paper to be useful to policymakers who want to understand and regulate AI systems, technologists who care about the potential policy impact of their work, funders who want to support work addressing these challenges, and academics who want to analyze, critique, and potentially develop large generative models.",
            "referenceCount": 100,
            "citationCount": 111,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3531146.3533229",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Political Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2022-02-15",
            "journal": {
                "name": "Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Ganguli2022PredictabilityAS,\n author = {Deep Ganguli and Danny Hernandez and Liane Lovitt and Nova DasSarma and T. Henighan and Andy Jones and Nicholas Joseph and John Kernion and Benjamin Mann and Amanda Askell and Yuntao Bai and Anna Chen and Tom Conerly and Dawn Drain and Nelson Elhage and S. E. Showk and Stanislav Fort and Zac Hatfield-Dodds and Scott Johnston and S. Kravec and Neel Nanda and Kamal Ndousse and Catherine Olsson and D. Amodei and Dario Amodei and Tom B. Brown and Jared Kaplan and Sam McCandlish and C. Olah and Jack Clark},\n booktitle = {Conference on Fairness, Accountability and Transparency},\n journal = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},\n title = {Predictability and Surprise in Large Generative Models},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2a29e1bcbed17c588ffbae1fea2af3baaab924b8",
            "@type": "ScholarlyArticle",
            "paperId": "2a29e1bcbed17c588ffbae1fea2af3baaab924b8",
            "corpusId": 252907242,
            "url": "https://www.semanticscholar.org/paper/2a29e1bcbed17c588ffbae1fea2af3baaab924b8",
            "title": "Is synthetic data from generative models ready for image recognition?",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2022,
            "externalIds": {
                "DBLP": "journals/corr/abs-2210-07574",
                "ArXiv": "2210.07574",
                "DOI": "10.48550/arXiv.2210.07574",
                "CorpusId": 252907242
            },
            "abstract": "Recent text-to-image generation models have shown promising results in generating high-fidelity photo-realistic images. Though the results are astonishing to human eyes, how applicable these generated images are for recognition tasks remains under-explored. In this work, we extensively study whether and how synthetic images generated from state-of-the-art text-to-image generation models can be used for image recognition tasks, and focus on two perspectives: synthetic data for improving classification models in data-scarce settings (i.e. zero-shot and few-shot), and synthetic data for large-scale model pre-training for transfer learning. We showcase the powerfulness and shortcomings of synthetic data from existing generative models, and propose strategies for better applying synthetic data for recognition tasks. Code: https://github.com/CVMI-Lab/SyntheticData.",
            "referenceCount": 77,
            "citationCount": 101,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/2210.07574",
                "status": "CLOSED"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2022-10-14",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2210.07574"
            },
            "citationStyles": {
                "bibtex": "@Article{He2022IsSD,\n author = {Ruifei He and Shuyang Sun and Xin Yu and Chuhui Xue and Wenqing Zhang and Philip H. S. Torr and Song Bai and Xiaojuan Qi},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Is synthetic data from generative models ready for image recognition?},\n volume = {abs/2210.07574},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:66ad2fbc8b73242a889699868611fcf239e3435d",
            "@type": "ScholarlyArticle",
            "paperId": "66ad2fbc8b73242a889699868611fcf239e3435d",
            "corpusId": 6377199,
            "url": "https://www.semanticscholar.org/paper/66ad2fbc8b73242a889699868611fcf239e3435d",
            "title": "Semi-supervised Learning with Deep Generative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/nips/KingmaMRW14",
                "MAG": "2949416428",
                "ArXiv": "1406.5298",
                "CorpusId": 6377199
            },
            "abstract": "The ever-increasing size of modern data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning.",
            "referenceCount": 27,
            "citationCount": 2390,
            "influentialCitationCount": 309,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-06-20",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1406.5298"
            },
            "citationStyles": {
                "bibtex": "@Article{Kingma2014SemisupervisedLW,\n author = {Diederik P. Kingma and S. Mohamed and Danilo Jimenez Rezende and M. Welling},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Semi-supervised Learning with Deep Generative Models},\n volume = {abs/1406.5298},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ebf62718b2e86dda0e0bfaaad5774663c66c6512",
            "@type": "ScholarlyArticle",
            "paperId": "ebf62718b2e86dda0e0bfaaad5774663c66c6512",
            "corpusId": 247839443,
            "url": "https://www.semanticscholar.org/paper/ebf62718b2e86dda0e0bfaaad5774663c66c6512",
            "title": "Speech Enhancement with Score-Based Generative Models in the Complex STFT Domain",
            "venue": "Interspeech",
            "publicationVenue": {
                "id": "urn:research:af90489e-312f-4514-bea2-bcb399cb8ece",
                "name": "Interspeech",
                "alternate_names": [
                    "Conf Int Speech Commun Assoc",
                    "INTERSPEECH",
                    "Conference of the International Speech Communication Association"
                ],
                "issn": "2308-457X",
                "url": "https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech"
            },
            "year": 2022,
            "externalIds": {
                "DBLP": "journals/corr/abs-2203-17004",
                "ArXiv": "2203.17004",
                "DOI": "10.48550/arXiv.2203.17004",
                "CorpusId": 247839443
            },
            "abstract": "Score-based generative models (SGMs) have recently shown impressive results for difficult generative tasks such as the unconditional and conditional generation of natural images and audio signals. In this work, we extend these models to the complex short-time Fourier transform (STFT) domain, proposing a novel training task for speech enhancement using a complex-valued deep neural network. We derive this training task within the formalism of stochastic differential equations (SDEs), thereby enabling the use of predictor-corrector samplers. We provide alternative formulations inspired by previous publications on using generative diffusion models for speech enhancement, avoiding the need for any prior assumptions on the noise distribution and making the training task purely generative which, as we show, results in improved enhancement performance.",
            "referenceCount": 47,
            "citationCount": 46,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/2203.17004",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2022-03-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2203.17004"
            },
            "citationStyles": {
                "bibtex": "@Article{Welker2022SpeechEW,\n author = {Simon Welker and Julius Richter and Timo Gerkmann},\n booktitle = {Interspeech},\n journal = {ArXiv},\n title = {Speech Enhancement with Score-Based Generative Models in the Complex STFT Domain},\n volume = {abs/2203.17004},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:36bb5573f4108a41fa559b8b068922fa4136707a",
            "@type": "ScholarlyArticle",
            "paperId": "36bb5573f4108a41fa559b8b068922fa4136707a",
            "corpusId": 247248974,
            "url": "https://www.semanticscholar.org/paper/36bb5573f4108a41fa559b8b068922fa4136707a",
            "title": "Generative models for molecular discovery: Recent advances and challenges",
            "venue": "WIREs Computational Molecular Science",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2022,
            "externalIds": {
                "DOI": "10.1002/wcms.1608",
                "CorpusId": 247248974
            },
            "abstract": "Development of new products often relies on the discovery of novel molecules. While conventional molecular design involves using human expertise to propose, synthesize, and test new molecules, this process can be cost and time intensive, limiting the number of molecules that can be reasonably tested. Generative modeling provides an alternative approach to molecular discovery by reformulating molecular design as an inverse design problem. Here, we review the recent advances in the state\u2010of\u2010the\u2010art of generative molecular design and discusses the considerations for integrating these models into real molecular discovery campaigns. We first review the model design choices required to develop and train a generative model including common 1D, 2D, and 3D representations of molecules and typical generative modeling neural network architectures. We then describe different problem statements for molecular discovery applications and explore the benchmarks used to evaluate models based on those problem statements. Finally, we discuss the important factors that play a role in integrating generative models into experimental workflows. Our aim is that this review will equip the reader with the information and context necessary to utilize generative modeling within their domain.",
            "referenceCount": 118,
            "citationCount": 75,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dspace.mit.edu/bitstream/1721.1/142651.2/1/WIREs%20Comput%20Mol%20Sci%20-%202022%20-%20Bilodeau%20-%20Generative%20models%20for%20molecular%20discovery%20Recent%20advances%20and%20challenges.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2022-03-05",
            "journal": {
                "name": "Wiley Interdisciplinary Reviews: Computational Molecular Science",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Bilodeau2022GenerativeMF,\n author = {Camille Bilodeau and Wengong Jin and T. Jaakkola and R. Barzilay and K. Jensen},\n booktitle = {WIREs Computational Molecular Science},\n journal = {Wiley Interdisciplinary Reviews: Computational Molecular Science},\n title = {Generative models for molecular discovery: Recent advances and challenges},\n volume = {12},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cdb24383b1477410311e7ab3eb8f4731fef5fac0",
            "@type": "ScholarlyArticle",
            "paperId": "cdb24383b1477410311e7ab3eb8f4731fef5fac0",
            "corpusId": 250048835,
            "url": "https://www.semanticscholar.org/paper/cdb24383b1477410311e7ab3eb8f4731fef5fac0",
            "title": "Score-based Generative Models for Calorimeter Shower Simulation",
            "venue": "Physical Review D",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2022,
            "externalIds": {
                "DBLP": "journals/corr/abs-2206-11898",
                "ArXiv": "2206.11898",
                "DOI": "10.1103/PhysRevD.106.092009",
                "CorpusId": 250048835
            },
            "abstract": "Score-based generative models are a new class of generative algorithms that have been shown to produce realistic images even in high dimensional spaces, currently surpassing other state-of-the-art models for different benchmark categories and applications. In this work we introduce CaloScore, a score-based generative model for collider physics applied to calorimeter shower generation. Three different diffusion models are investigated using the Fast Calorimeter Simulation Challenge 2022 dataset. CaloScore is the first application of a score-based generative model in collider physics and is able to produce high-fidelity calorimeter images for all datasets, providing an alternative paradigm for calorimeter shower simulation.",
            "referenceCount": 60,
            "citationCount": 36,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://link.aps.org/pdf/10.1103/PhysRevD.106.092009",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2022-06-17",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2206.11898"
            },
            "citationStyles": {
                "bibtex": "@Article{Mikuni2022ScorebasedGM,\n author = {V. Mikuni and B. Nachman},\n booktitle = {Physical Review D},\n journal = {ArXiv},\n title = {Score-based Generative Models for Calorimeter Shower Simulation},\n volume = {abs/2206.11898},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3f25e17eb717e5894e0404ea634451332f85d287",
            "@type": "ScholarlyArticle",
            "paperId": "3f25e17eb717e5894e0404ea634451332f85d287",
            "corpusId": 13936837,
            "url": "https://www.semanticscholar.org/paper/3f25e17eb717e5894e0404ea634451332f85d287",
            "title": "Learning Structured Output Representation using Deep Conditional Generative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/nips/SohnLY15",
                "MAG": "2188365844",
                "CorpusId": 13936837
            },
            "abstract": "Supervised deep learning has been successfully applied to many recognition problems. Although it can approximate a complex many-to-one function well when a large amount of training data is provided, it is still challenging to model complex structured output representations that effectively perform probabilistic inference and make diverse predictions. In this work, we develop a deep conditional generative model for structured output prediction using Gaussian latent variables. The model is trained efficiently in the framework of stochastic gradient variational Bayes, and allows for fast prediction using stochastic feed-forward inference. In addition, we provide novel strategies to build robust structured prediction algorithms, such as input noise-injection and multi-scale prediction objective at training. In experiments, we demonstrate the effectiveness of our proposed algorithm in comparison to the deterministic deep neural network counterparts in generating diverse but realistic structured output predictions using stochastic inference. Furthermore, the proposed training methods are complimentary, which leads to strong pixel-level object segmentation and semantic labeling performance on Caltech-UCSD Birds 200 and the subset of Labeled Faces in the Wild dataset.",
            "referenceCount": 37,
            "citationCount": 2424,
            "influentialCitationCount": 535,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-12-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sohn2015LearningSO,\n author = {Kihyuk Sohn and Honglak Lee and Xinchen Yan},\n booktitle = {Neural Information Processing Systems},\n pages = {3483-3491},\n title = {Learning Structured Output Representation using Deep Conditional Generative Models},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ea8c46e193d5121e440daf96edfd15a47151c293",
            "@type": "ScholarlyArticle",
            "paperId": "ea8c46e193d5121e440daf96edfd15a47151c293",
            "corpusId": 220302360,
            "url": "https://www.semanticscholar.org/paper/ea8c46e193d5121e440daf96edfd15a47151c293",
            "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering",
            "venue": "Conference of the European Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:8de18c35-6785-4e54-99f2-21ee961302c6",
                "name": "Conference of the European Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "Conf Eur Chapter Assoc Comput Linguistics",
                    "EACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/eacl/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "conf/eacl/IzacardG21",
                "ACL": "2021.eacl-main.74",
                "ArXiv": "2007.01282",
                "MAG": "3039017601",
                "DOI": "10.18653/v1/2021.eacl-main.74",
                "CorpusId": 220302360
            },
            "abstract": "Generative models for open domain question answering have proven to be competitive, without resorting to external knowledge. While promising, this approach requires to use models with billions of parameters, which are expensive to train and query. In this paper, we investigate how much these models can benefit from retrieving text passages, potentially containing evidence. We obtain state-of-the-art results on the Natural Questions and TriviaQA open benchmarks. Interestingly, we observe that the performance of this method significantly improves when increasing the number of retrieved passages. This is evidence that sequence-to-sequence models offers a flexible framework to efficiently aggregate and combine evidence from multiple passages.",
            "referenceCount": 35,
            "citationCount": 591,
            "influentialCitationCount": 128,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://aclanthology.org/2021.eacl-main.74.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-07-02",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2007.01282"
            },
            "citationStyles": {
                "bibtex": "@Article{Izacard2020LeveragingPR,\n author = {Gautier Izacard and Edouard Grave},\n booktitle = {Conference of the European Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering},\n volume = {abs/2007.01282},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1156e277fa7ec195b043161d3c5c97715da17658",
            "@type": "ScholarlyArticle",
            "paperId": "1156e277fa7ec195b043161d3c5c97715da17658",
            "corpusId": 219708245,
            "url": "https://www.semanticscholar.org/paper/1156e277fa7ec195b043161d3c5c97715da17658",
            "title": "Improved Techniques for Training Score-Based Generative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "conf/nips/0011E20",
                "ArXiv": "2006.09011",
                "MAG": "3035384201",
                "CorpusId": 219708245
            },
            "abstract": "Score-based generative models can produce high quality image samples comparable to GANs, without requiring adversarial optimization. However, existing training procedures are limited to images of low resolution (typically below 32x32), and can be unstable under some settings. We provide a new theoretical analysis of learning and sampling from score models in high dimensional spaces, explaining existing failure modes and motivating new solutions that generalize across datasets. To enhance stability, we also propose to maintain an exponential moving average of model weights. With these improvements, we can effortlessly scale score-based generative models to images with unprecedented resolutions ranging from 64x64 to 256x256. Our score-based models can generate high-fidelity samples that rival best-in-class GANs on various image datasets, including CelebA, FFHQ, and multiple LSUN categories.",
            "referenceCount": 32,
            "citationCount": 615,
            "influentialCitationCount": 83,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-06-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2006.09011"
            },
            "citationStyles": {
                "bibtex": "@Article{Song2020ImprovedTF,\n author = {Yang Song and Stefano Ermon},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Improved Techniques for Training Score-Based Generative Models},\n volume = {abs/2006.09011},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f99de990f791799df398fcd38034c4b395d9b7e0",
            "@type": "ScholarlyArticle",
            "paperId": "f99de990f791799df398fcd38034c4b395d9b7e0",
            "corpusId": 233004601,
            "url": "https://www.semanticscholar.org/paper/f99de990f791799df398fcd38034c4b395d9b7e0",
            "title": "Skilful precipitation nowcasting using deep generative models of radar",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2021,
            "externalIds": {
                "PubMedCentral": "8481123",
                "DBLP": "journals/corr/abs-2104-00954",
                "ArXiv": "2104.00954",
                "DOI": "10.1038/s41586-021-03854-z",
                "CorpusId": 233004601,
                "PubMed": "34588668"
            },
            "abstract": null,
            "referenceCount": 90,
            "citationCount": 397,
            "influentialCitationCount": 26,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41586-021-03854-z.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-04-02",
            "journal": {
                "name": "Nature",
                "volume": "597"
            },
            "citationStyles": {
                "bibtex": "@Article{Ravuri2021SkilfulPN,\n author = {Suman V. Ravuri and Karel Lenc and M. Willson and D. Kangin and R\u00e9mi R. Lam and Piotr Wojciech Mirowski and Megan Fitzsimons and M. Athanassiadou and Sheleem Kashem and Sam Madge and R. Prudden and Amol Mandhane and Aidan Clark and Andrew Brock and K. Simonyan and R. Hadsell and Nial H. Robinson and Ellen Clancy and A. Arribas and S. Mohamed},\n booktitle = {Nature},\n journal = {Nature},\n pages = {672 - 677},\n title = {Skilful precipitation nowcasting using deep generative models of radar},\n volume = {597},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6fca4e69d8d7fec0b1fe118e769017b3610d1bd5",
            "@type": "ScholarlyArticle",
            "paperId": "6fca4e69d8d7fec0b1fe118e769017b3610d1bd5",
            "corpusId": 247038603,
            "url": "https://www.semanticscholar.org/paper/6fca4e69d8d7fec0b1fe118e769017b3610d1bd5",
            "title": "A survey of multimodal deep generative models",
            "venue": "Adv. Robotics",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2022,
            "externalIds": {
                "DBLP": "journals/corr/abs-2207-02127",
                "ArXiv": "2207.02127",
                "DOI": "10.1080/01691864.2022.2035253",
                "CorpusId": 247038603
            },
            "abstract": "Multimodal learning is a framework for building models that make predictions based on different types of modalities. Important challenges in multimodal learning are the inference of shared representations from arbitrary modalities and cross-modal generation via these representations; however, achieving this requires taking the heterogeneous nature of multimodal data into account. In recent years, deep generative models, i.e. generative models in which distributions are parameterized by deep neural networks, have attracted much attention, especially variational autoencoders, which are suitable for accomplishing the above challenges because they can consider heterogeneity and infer good representations of data. Therefore, various multimodal generative models based on variational autoencoders, called multimodal deep generative models, have been proposed in recent years. In this paper, we provide a categorized survey of studies on multimodal deep generative models. GRAPHICAL ABSTRACT",
            "referenceCount": 138,
            "citationCount": 24,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2207.02127",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2022-02-21",
            "journal": {
                "name": "Advanced Robotics",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{Suzuki2022ASO,\n author = {Masahiro Suzuki and Y. Matsuo},\n booktitle = {Adv. Robotics},\n journal = {Advanced Robotics},\n pages = {261 - 278},\n title = {A survey of multimodal deep generative models},\n volume = {36},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bad1a8de342823bdf484ce49bf1688173168251c",
            "@type": "ScholarlyArticle",
            "paperId": "bad1a8de342823bdf484ce49bf1688173168251c",
            "corpusId": 247900241,
            "url": "https://www.semanticscholar.org/paper/bad1a8de342823bdf484ce49bf1688173168251c",
            "title": "Deep generative models for peptide design",
            "venue": "Digital Discovery",
            "publicationVenue": {
                "id": "urn:research:738bbcb3-7641-4f2a-8b05-79ca86a3681b",
                "name": "Digital Discovery",
                "alternate_names": [
                    "Digit Discov"
                ],
                "issn": "2635-098X",
                "url": "https://www.rsc.org/journals-books-databases/about-journals/digital-discovery"
            },
            "year": 2022,
            "externalIds": {
                "PubMedCentral": "9189861",
                "DOI": "10.1039/d1dd00024a",
                "CorpusId": 247900241,
                "PubMed": "35769205"
            },
            "abstract": "Computers can already be programmed for superhuman pattern recognition of images and text. For machines to discover novel molecules, they must first be trained to sort through the many characteristics of molecules and determine which properties should be retained, suppressed, or enhanced to optimize functions of interest. Machines need to be able to understand, read, write, and eventually create new molecules. Today, this creative process relies on deep generative models, which have gained popularity since powerful deep neural networks were introduced to generative model frameworks. In recent years, they have demonstrated excellent ability to model complex distribution of real-word data (e.g., images, audio, text, molecules, and biological sequences). Deep generative models can generate data beyond those provided in training samples, thus yielding an efficient and rapid tool for exploring the massive search space of high-dimensional data such as DNA/protein sequences and facilitating the design of biomolecules with desired functions. Here, we review the emerging field of deep generative models applied to peptide science. In particular, we discuss several popular deep generative model frameworks as well as their applications to generate peptides with various kinds of properties (e.g., antimicrobial, anticancer, cell penetration, etc). We conclude our review with a discussion of current limitations and future perspectives in this emerging field.",
            "referenceCount": 62,
            "citationCount": 23,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://pubs.rsc.org/en/content/articlepdf/2022/dd/d1dd00024a",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2022-03-31",
            "journal": {
                "name": "Digital Discovery",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Wan2022DeepGM,\n author = {Fangping Wan and Daphne Kontogiorgos-Heintz and C. de la Fuente-Nunez},\n booktitle = {Digital Discovery},\n journal = {Digital Discovery},\n pages = {195 - 208},\n title = {Deep generative models for peptide design},\n volume = {1},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0537c62e32299b8e9b4e3cac44d82ffa123cbbe1",
            "@type": "ScholarlyArticle",
            "paperId": "0537c62e32299b8e9b4e3cac44d82ffa123cbbe1",
            "corpusId": 240071819,
            "url": "https://www.semanticscholar.org/paper/0537c62e32299b8e9b4e3cac44d82ffa123cbbe1",
            "title": "Disease variant prediction with deep generative models of evolutionary data",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.1038/s41586-021-04043-8",
                "CorpusId": 240071819,
                "PubMed": "34707284"
            },
            "abstract": null,
            "referenceCount": 45,
            "citationCount": 238,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.biorxiv.org/content/biorxiv/early/2020/12/22/2020.12.21.423785.full.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-10-27",
            "journal": {
                "name": "Nature",
                "volume": "599"
            },
            "citationStyles": {
                "bibtex": "@Article{Frazer2021DiseaseVP,\n author = {J. Frazer and Pascal Notin and M. Dias and Aidan N. Gomez and Joseph K Min and Kelly P. Brock and Y. Gal and D. Marks},\n booktitle = {Nature},\n journal = {Nature},\n pages = {91 - 95},\n title = {Disease variant prediction with deep generative models of evolutionary data},\n volume = {599},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:49f6dbf4ead6a8a3d26f9cf218a654f2f3d1d896",
            "@type": "ScholarlyArticle",
            "paperId": "49f6dbf4ead6a8a3d26f9cf218a654f2f3d1d896",
            "corpusId": 244130146,
            "url": "https://www.semanticscholar.org/paper/49f6dbf4ead6a8a3d26f9cf218a654f2f3d1d896",
            "title": "Solving Inverse Problems in Medical Imaging with Score-Based Generative Models",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2111.08005",
                "DBLP": "journals/corr/abs-2111-08005",
                "CorpusId": 244130146
            },
            "abstract": "Reconstructing medical images from partial measurements is an important inverse problem in Computed Tomography (CT) and Magnetic Resonance Imaging (MRI). Existing solutions based on machine learning typically train a model to directly map measurements to medical images, leveraging a training dataset of paired images and measurements. These measurements are typically synthesized from images using a fixed physical model of the measurement process, which hinders the generalization capability of models to unknown measurement processes. To address this issue, we propose a fully unsupervised technique for inverse problem solving, leveraging the recently introduced score-based generative models. Specifically, we first train a score-based generative model on medical images to capture their prior distribution. Given measurements and a physical model of the measurement process at test time, we introduce a sampling method to reconstruct an image consistent with both the prior and the observed measurements. Our method does not assume a fixed measurement process during training, and can thus be flexibly adapted to different measurement processes at test time. Empirically, we observe comparable or better performance to supervised learning techniques in several medical imaging tasks in CT and MRI, while demonstrating significantly better generalization to unknown measurement processes.",
            "referenceCount": 51,
            "citationCount": 201,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-11-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2111.08005"
            },
            "citationStyles": {
                "bibtex": "@Article{Song2021SolvingIP,\n author = {Yang Song and Liyue Shen and Lei Xing and Stefano Ermon},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Solving Inverse Problems in Medical Imaging with Score-Based Generative Models},\n volume = {abs/2111.08005},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "@type": "ScholarlyArticle",
            "paperId": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "corpusId": 49313245,
            "url": "https://www.semanticscholar.org/paper/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "title": "Improving Language Understanding by Generative Pre-Training",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2965425874",
                "CorpusId": 49313245
            },
            "abstract": "Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classi\ufb01cation. Although large unlabeled text corpora are abundant, labeled data for learning these speci\ufb01c tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative \ufb01ne-tuning on each speci\ufb01c task. In contrast to previous approaches, we make use of task-aware input transformations during \ufb01ne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, signi\ufb01cantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI).",
            "referenceCount": 73,
            "citationCount": 7065,
            "influentialCitationCount": 1049,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Radford2018ImprovingLU,\n author = {Alec Radford and Karthik Narasimhan},\n title = {Improving Language Understanding by Generative Pre-Training},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0968f1592f9401d72bf0d97e740496818c1a3135",
            "@type": "ScholarlyArticle",
            "paperId": "0968f1592f9401d72bf0d97e740496818c1a3135",
            "corpusId": 237513697,
            "url": "https://www.semanticscholar.org/paper/0968f1592f9401d72bf0d97e740496818c1a3135",
            "title": "Design Guidelines for Prompt Engineering Text-to-Image Generative Models",
            "venue": "International Conference on Human Factors in Computing Systems",
            "publicationVenue": {
                "id": "urn:research:b55b50b1-aae7-47a7-b042-8aecc930073d",
                "name": "International Conference on Human Factors in Computing Systems",
                "alternate_names": [
                    "CHI",
                    "Int Conf Hum Factor Comput Syst",
                    "Human Factors in Computing Systems",
                    "Conference on Human Interface",
                    "Conf Hum Interface",
                    "Hum Factor Comput Syst"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigchi/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/chi/LiuC22a",
                "ArXiv": "2109.06977",
                "DOI": "10.1145/3491102.3501825",
                "CorpusId": 237513697
            },
            "abstract": "Text-to-image generative models are a new and powerful way to generate visual artwork. However, the open-ended nature of text as interaction is double-edged; while users can input anything and have access to an infinite range of generations, they also must engage in brute-force trial and error with the text prompt when the result quality is poor. We conduct a study exploring what prompt keywords and model hyperparameters can help produce coherent outputs. In particular, we study prompts structured to include subject and style keywords and investigate success and failure modes of these prompts. Our evaluation of 5493 generations over the course of five experiments spans 51 abstract and concrete subjects as well as 51 abstract and figurative styles. From this evaluation, we present design guidelines that can help people produce better outcomes from text-to-image generative models.",
            "referenceCount": 47,
            "citationCount": 160,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2109.06977",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Art",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2021-09-14",
            "journal": {
                "name": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2021DesignGF,\n author = {Vivian Liu and Lydia B. Chilton},\n booktitle = {International Conference on Human Factors in Computing Systems},\n journal = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},\n title = {Design Guidelines for Prompt Engineering Text-to-Image Generative Models},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5be878987dfccd543c73f31db973a81cc738aefa",
            "@type": "ScholarlyArticle",
            "paperId": "5be878987dfccd543c73f31db973a81cc738aefa",
            "corpusId": 212634162,
            "url": "https://www.semanticscholar.org/paper/5be878987dfccd543c73f31db973a81cc738aefa",
            "title": "PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "conf/cvpr/MenonDHRR20",
                "MAG": "3034352949",
                "ArXiv": "2003.03808",
                "DOI": "10.1109/cvpr42600.2020.00251",
                "CorpusId": 212634162
            },
            "abstract": "The primary aim of single-image super-resolution is to construct a high-resolution (HR) image from a corresponding low-resolution (LR) input. In previous approaches, which have generally been supervised, the training objective typically measures a pixel-wise average distance between the super-resolved (SR) and HR images. Optimizing such metrics often leads to blurring, especially in high variance (detailed) regions. We propose an alternative formulation of the super-resolution problem based on creating realistic SR images that downscale correctly. We present a novel super-resolution algorithm addressing this problem, PULSE (Photo Upsampling via Latent Space Exploration), which generates high-resolution, realistic images at resolutions previously unseen in the literature. It accomplishes this in an entirely self-supervised fashion and is not confined to a specific degradation operator used during training, unlike previous methods (which require training on databases of LR-HR image pairs for supervised learning). Instead of starting with the LR image and slowly adding detail, PULSE traverses the high-resolution natural image manifold, searching for images that downscale to the original LR image. This is formalized through the \u201cdownscaling loss,\u201d which guides exploration through the latent space of a generative model. By leveraging properties of high-dimensional Gaussians, we restrict the search space to guarantee that our outputs are realistic. PULSE thereby generates super-resolved images that both are realistic and downscale correctly. We show extensive experimental results demonstrating the efficacy of our approach in the domain of face super-resolution (also known as face hallucination). Our method outperforms state-of-the-art methods in perceptual quality at higher resolutions and scale factors than previously possible.",
            "referenceCount": 30,
            "citationCount": 392,
            "influentialCitationCount": 65,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2003.03808",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-03-08",
            "journal": {
                "name": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Menon2020PULSESP,\n author = {Sachit Menon and Alexandru Damian and Shijia Hu and Nikhil Ravi and C. Rudin},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {2434-2442},\n title = {PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c8b25a128f4bfd0c79de82c174dd403b2ef6eeb1",
            "@type": "ScholarlyArticle",
            "paperId": "c8b25a128f4bfd0c79de82c174dd403b2ef6eeb1",
            "corpusId": 53632457,
            "url": "https://www.semanticscholar.org/paper/c8b25a128f4bfd0c79de82c174dd403b2ef6eeb1",
            "title": "Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/icml/HoCSDA19",
                "MAG": "2951682695",
                "ArXiv": "1902.00275",
                "CorpusId": 53632457
            },
            "abstract": "Flow-based generative models are powerful exact likelihood models with efficient sampling and inference. Despite their computational efficiency, flow-based models generally have much worse density modeling performance compared to state-of-the-art autoregressive models. In this paper, we investigate and improve upon three limiting design choices employed by flow-based models in prior work: the use of uniform noise for dequantization, the use of inexpressive affine flows, and the use of purely convolutional conditioning networks in coupling layers. Based on our findings, we propose Flow++, a new flow-based model that is now the state-of-the-art non-autoregressive model for unconditional density estimation on standard image benchmarks. Our work has begun to close the significant performance gap that has so far existed between autoregressive models and flow-based models. Our implementation is available at this https URL",
            "referenceCount": 40,
            "citationCount": 368,
            "influentialCitationCount": 47,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-02-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1902.00275"
            },
            "citationStyles": {
                "bibtex": "@Article{Ho2019FlowIF,\n author = {Jonathan Ho and Xi Chen and A. Srinivas and Yan Duan and P. Abbeel},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design},\n volume = {abs/1902.00275},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d383dd8ced85d7898d8b1546c514a34fb626ea16",
            "@type": "ScholarlyArticle",
            "paperId": "d383dd8ced85d7898d8b1546c514a34fb626ea16",
            "corpusId": 118648975,
            "url": "https://www.semanticscholar.org/paper/d383dd8ced85d7898d8b1546c514a34fb626ea16",
            "title": "Improved Precision and Recall Metric for Assessing Generative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1904-06991",
                "MAG": "2971128425",
                "ArXiv": "1904.06991",
                "CorpusId": 118648975
            },
            "abstract": "The ability to automatically estimate the quality and coverage of the samples produced by a generative model is a vital requirement for driving algorithm research. We present an evaluation metric that can separately and reliably measure both of these aspects in image generation tasks by forming explicit, non-parametric representations of the manifolds of real and generated data. We demonstrate the effectiveness of our metric in StyleGAN and BigGAN by providing several illustrative examples where existing metrics yield uninformative or contradictory results. Furthermore, we analyze multiple design variants of StyleGAN to better understand the relationships between the model architecture, training methods, and the properties of the resulting sample distribution. In the process, we identify new variants that improve the state-of-the-art. We also perform the first principled analysis of truncation methods and identify an improved method. Finally, we extend our metric to estimate the perceptual quality of individual samples, and use this to study latent space interpolations.",
            "referenceCount": 37,
            "citationCount": 446,
            "influentialCitationCount": 85,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-04-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1904.06991"
            },
            "citationStyles": {
                "bibtex": "@Article{Kynk\u00e4\u00e4nniemi2019ImprovedPA,\n author = {T. Kynk\u00e4\u00e4nniemi and Tero Karras and S. Laine and J. Lehtinen and Timo Aila},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Improved Precision and Recall Metric for Assessing Generative Models},\n volume = {abs/1904.06991},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8afa6dd9f9ac46462a1fb70a757c4ae1cd45bbf6",
            "@type": "ScholarlyArticle",
            "paperId": "8afa6dd9f9ac46462a1fb70a757c4ae1cd45bbf6",
            "corpusId": 52908831,
            "url": "https://www.semanticscholar.org/paper/8afa6dd9f9ac46462a1fb70a757c4ae1cd45bbf6",
            "title": "FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2895434480",
                "DBLP": "journals/corr/abs-1810-01367",
                "ArXiv": "1810.01367",
                "CorpusId": 52908831
            },
            "abstract": "A promising class of generative models maps points from a simple distribution to a complex distribution through an invertible neural network. Likelihood-based training of these models requires restricting their architectures to allow cheap computation of Jacobian determinants. Alternatively, the Jacobian trace can be used if the transformation is specified by an ordinary differential equation. In this paper, we use Hutchinson's trace estimator to give a scalable unbiased estimate of the log-density. The result is a continuous-time invertible generative model with unbiased density estimation and one-pass sampling, while allowing unrestricted neural network architectures. We demonstrate our approach on high-dimensional density estimation, image generation, and variational inference, achieving the state-of-the-art among exact likelihood methods with efficient sampling.",
            "referenceCount": 24,
            "citationCount": 667,
            "influentialCitationCount": 135,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1810.01367"
            },
            "citationStyles": {
                "bibtex": "@Article{Grathwohl2018FFJORDFC,\n author = {Will Grathwohl and Ricky T. Q. Chen and J. Bettencourt and Ilya Sutskever and D. Duvenaud},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models},\n volume = {abs/1810.01367},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:63d6a3cc7f2f52c9b4e224bb8b18f17b03f6de1e",
            "@type": "ScholarlyArticle",
            "paperId": "63d6a3cc7f2f52c9b4e224bb8b18f17b03f6de1e",
            "corpusId": 235358715,
            "url": "https://www.semanticscholar.org/paper/63d6a3cc7f2f52c9b4e224bb8b18f17b03f6de1e",
            "title": "A Variational Perspective on Diffusion-Based Generative Models and Score Matching",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/nips/HuangLC21",
                "ArXiv": "2106.02808",
                "CorpusId": 235358715
            },
            "abstract": "Discrete-time diffusion-based generative models and score matching methods have shown promising results in modeling high-dimensional image data. Recently, Song et al. (2021) show that diffusion processes that transform data into noise can be reversed via learning the score function, i.e. the gradient of the log-density of the perturbed data. They propose to plug the learned score function into an inverse formula to define a generative diffusion process. Despite the empirical success, a theoretical underpinning of this procedure is still lacking. In this work, we approach the (continuous-time) generative diffusion directly and derive a variational framework for likelihood estimation, which includes continuous-time normalizing flows as a special case, and can be seen as an infinitely deep variational autoencoder. Under this framework, we show that minimizing the score-matching loss is equivalent to maximizing a lower bound of the likelihood of the plug-in reverse SDE proposed by Song et al. (2021), bridging the theoretical gap.",
            "referenceCount": 61,
            "citationCount": 123,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-06-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2106.02808"
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2021AVP,\n author = {Chin-Wei Huang and Jae Hyun Lim and Aaron C. Courville},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {A Variational Perspective on Diffusion-Based Generative Models and Score Matching},\n volume = {abs/2106.02808},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ba2f73db4e38324f751fbf30f7dde0bf4e7fa520",
            "@type": "ScholarlyArticle",
            "paperId": "ba2f73db4e38324f751fbf30f7dde0bf4e7fa520",
            "corpusId": 230799531,
            "url": "https://www.semanticscholar.org/paper/ba2f73db4e38324f751fbf30f7dde0bf4e7fa520",
            "title": "Knowledge Distillation in Iterative Generative Models for Improved Sampling Speed",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2101.02388",
                "DBLP": "journals/corr/abs-2101-02388",
                "CorpusId": 230799531
            },
            "abstract": "Iterative generative models, such as noise conditional score networks and denoising diffusion probabilistic models, produce high quality samples by gradually denoising an initial noise vector. However, their denoising process has many steps, making them 2-3 orders of magnitude slower than other generative models such as GANs and VAEs. In this paper, we establish a novel connection between knowledge distillation and image generation with a technique that distills a multi-step denoising process into a single step, resulting in a sampling speed similar to other single-step generative models. Our Denoising Student generates high quality samples comparable to GANs on the CIFAR-10 and CelebA datasets, without adversarial training. We demonstrate that our method scales to higher resolutions through experiments on 256 x 256 LSUN. Code and checkpoints are available at https://github.com/tcl9876/Denoising_Student",
            "referenceCount": 47,
            "citationCount": 122,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-01-07",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2101.02388"
            },
            "citationStyles": {
                "bibtex": "@Article{Luhman2021KnowledgeDI,\n author = {Eric Luhman and Troy Luhman},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Knowledge Distillation in Iterative Generative Models for Improved Sampling Speed},\n volume = {abs/2101.02388},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cb5323ef22a5a38cfba318abadcadee822ccf8a9",
            "@type": "ScholarlyArticle",
            "paperId": "cb5323ef22a5a38cfba318abadcadee822ccf8a9",
            "corpusId": 235367990,
            "url": "https://www.semanticscholar.org/paper/cb5323ef22a5a38cfba318abadcadee822ccf8a9",
            "title": "Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/nips/BengioJKPB21",
                "ArXiv": "2106.04399",
                "CorpusId": 235367990
            },
            "abstract": "This paper is about the problem of learning a stochastic policy for generating an object (like a molecular graph) from a sequence of actions, such that the probability of generating an object is proportional to a given positive reward for that object. Whereas standard return maximization tends to converge to a single return-maximizing sequence, there are cases where we would like to sample a diverse set of high-return solutions. These arise, for example, in black-box function optimization when few rounds are possible, each with large batches of queries, where the batches should be diverse, e.g., in the design of new molecules. One can also see this as a problem of approximately converting an energy function to a generative distribution. While MCMC methods can achieve that, they are expensive and generally only perform local exploration. Instead, training a generative policy amortizes the cost of search during training and yields to fast generation. Using insights from Temporal Difference learning, we propose GFlowNet, based on a view of the generative process as a flow network, making it possible to handle the tricky case where different trajectories can yield the same final state, e.g., there are many ways to sequentially add atoms to generate some molecular graph. We cast the set of trajectories as a flow and convert the flow consistency equations into a learning objective, akin to the casting of the Bellman equations into Temporal Difference methods. We prove that any global minimum of the proposed objectives yields a policy which samples from the desired distribution, and demonstrate the improved performance and diversity of GFlowNet on a simple domain where there are many modes to the reward function, and on a molecule synthesis task.",
            "referenceCount": 50,
            "citationCount": 139,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-06-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2106.04399"
            },
            "citationStyles": {
                "bibtex": "@Article{Bengio2021FlowNB,\n author = {Emmanuel Bengio and Moksh Jain and Maksym Korablyov and Doina Precup and Y. Bengio},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation},\n volume = {abs/2106.04399},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f7bb1636ced9036b3d0edafc7d82ad43164d41a3",
            "@type": "ScholarlyArticle",
            "paperId": "f7bb1636ced9036b3d0edafc7d82ad43164d41a3",
            "corpusId": 3458858,
            "url": "https://www.semanticscholar.org/paper/f7bb1636ced9036b3d0edafc7d82ad43164d41a3",
            "title": "Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2951911318",
                "DBLP": "conf/iclr/SamangoueiKC18",
                "ArXiv": "1805.06605",
                "CorpusId": 3458858
            },
            "abstract": "In recent years, deep neural network approaches have been widely adopted for machine learning tasks, including classification. However, they were shown to be vulnerable to adversarial perturbations: carefully crafted small perturbations can cause misclassification of legitimate images. We propose Defense-GAN, a new framework leveraging the expressive capability of generative models to defend deep neural networks against such attacks. Defense-GAN is trained to model the distribution of unperturbed images. At inference time, it finds a close output to a given image which does not contain the adversarial changes. This output is then fed to the classifier. Our proposed method can be used with any classification model and does not modify the classifier structure or training procedure. It can also be used as a defense against any attack as it does not assume knowledge of the process for generating the adversarial examples. We empirically show that Defense-GAN is consistently effective against different attack methods and improves on existing defense strategies. Our code has been made publicly available at this https URL",
            "referenceCount": 25,
            "citationCount": 1022,
            "influentialCitationCount": 103,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1805.06605"
            },
            "citationStyles": {
                "bibtex": "@Article{Samangouei2018DefenseGANPC,\n author = {Pouya Samangouei and Maya Kabkab and R. Chellappa},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models},\n volume = {abs/1805.06605},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6b4e030193fc5a2cf82486ec3b3929dc3d3ac308",
            "@type": "ScholarlyArticle",
            "paperId": "6b4e030193fc5a2cf82486ec3b3929dc3d3ac308",
            "corpusId": 231942787,
            "url": "https://www.semanticscholar.org/paper/6b4e030193fc5a2cf82486ec3b3929dc3d3ac308",
            "title": "How Faithful is your Synthetic Data? Sample-level Metrics for Evaluating and Auditing Generative Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2102-08921",
                "ArXiv": "2102.08921",
                "CorpusId": 231942787
            },
            "abstract": "Devising domain- and model-agnostic evaluation metrics for generative models is an important and as yet unresolved problem. Most existing metrics, which were tailored solely to the image synthesis setup, exhibit a limited capacity for diagnosing the different modes of failure of generative models across broader application domains. In this paper, we introduce a 3-dimensional evaluation metric, ($\\alpha$-Precision, $\\beta$-Recall, Authenticity), that characterizes the fidelity, diversity and generalization performance of any generative model in a domain-agnostic fashion. Our metric unifies statistical divergence measures with precision-recall analysis, enabling sample- and distribution-level diagnoses of model fidelity and diversity. We introduce generalization as an additional, independent dimension (to the fidelity-diversity trade-off) that quantifies the extent to which a model copies training data -- a crucial performance indicator when modeling sensitive data with requirements on privacy. The three metric components correspond to (interpretable) probabilistic quantities, and are estimated via sample-level binary classification. The sample-level nature of our metric inspires a novel use case which we call model auditing, wherein we judge the quality of individual samples generated by a (black-box) model, discarding low-quality samples and hence improving the overall model performance in a post-hoc manner.",
            "referenceCount": 49,
            "citationCount": 84,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-02-17",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Alaa2021HowFI,\n author = {A. Alaa and B. V. Breugel and Evgeny S. Saveliev and M. Schaar},\n booktitle = {International Conference on Machine Learning},\n pages = {290-306},\n title = {How Faithful is your Synthetic Data? Sample-level Metrics for Evaluating and Auditing Generative Models},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fc0b21675cc7ec8d9cd39c3ca5257008bbcec4df",
            "@type": "ScholarlyArticle",
            "paperId": "fc0b21675cc7ec8d9cd39c3ca5257008bbcec4df",
            "corpusId": 235377428,
            "url": "https://www.semanticscholar.org/paper/fc0b21675cc7ec8d9cd39c3ca5257008bbcec4df",
            "title": "Generative Models as a Data Source for Multiview Representation Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/iclr/0002PTI22",
                "ArXiv": "2106.05258",
                "CorpusId": 235377428
            },
            "abstract": "Generative models are now capable of producing highly realistic images that look nearly indistinguishable from the data on which they are trained. This raises the question: if we have good enough generative models, do we still need datasets? We investigate this question in the setting of learning general-purpose visual representations from a black-box generative model rather than directly from data. Given an off-the-shelf image generator without any access to its training data, we train representations from the samples output by this generator. We compare several representation learning methods that can be applied to this setting, using the latent space of the generator to generate multiple\"views\"of the same semantic content. We show that for contrastive methods, this multiview data can naturally be used to identify positive pairs (nearby in latent space) and negative pairs (far apart in latent space). We find that the resulting representations rival or even outperform those learned directly from real data, but that good performance requires care in the sampling strategy applied and the training method. Generative models can be viewed as a compressed and organized copy of a dataset, and we envision a future where more and more\"model zoos\"proliferate while datasets become increasingly unwieldy, missing, or private. This paper suggests several techniques for dealing with visual representation learning in such a future. Code is available on our project page https://ali-design.github.io/GenRep/.",
            "referenceCount": 90,
            "citationCount": 73,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-06-09",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2106.05258"
            },
            "citationStyles": {
                "bibtex": "@Article{Jahanian2021GenerativeMA,\n author = {Ali Jahanian and Xavier Puig and Yonglong Tian and Phillip Isola},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Generative Models as a Data Source for Multiview Representation Learning},\n volume = {abs/2106.05258},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1d41857ba8e0e8286268989036cd138a1f8ca372",
            "@type": "ScholarlyArticle",
            "paperId": "1d41857ba8e0e8286268989036cd138a1f8ca372",
            "corpusId": 231855635,
            "url": "https://www.semanticscholar.org/paper/1d41857ba8e0e8286268989036cd138a1f8ca372",
            "title": "Generative Models as Distributions of Functions",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/aistats/DupontTD22",
                "ArXiv": "2102.04776",
                "CorpusId": 231855635
            },
            "abstract": "Generative models are typically trained on grid-like data such as images. As a result, the size of these models usually scales directly with the underlying grid resolution. In this paper, we abandon discretized grids and instead parameterize individual data points by continuous functions. We then build generative models by learning distributions over such functions. By treating data points as functions, we can abstract away from the specific type of data we train on and construct models that are agnostic to discretization. To train our model, we use an adversarial approach with a discriminator that acts on continuous signals. Through experiments on a wide variety of data modalities including images, 3D shapes and climate data, we demonstrate that our model can learn rich distributions of functions independently of data type and resolution.",
            "referenceCount": 83,
            "citationCount": 69,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-02-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Dupont2021GenerativeMA,\n author = {Emilien Dupont and Y. Teh and A. Doucet},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n pages = {2989-3015},\n title = {Generative Models as Distributions of Functions},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:90c4081fd752df2bb4a6cabce728d116472d457d",
            "@type": "ScholarlyArticle",
            "paperId": "90c4081fd752df2bb4a6cabce728d116472d457d",
            "corpusId": 239050450,
            "url": "https://www.semanticscholar.org/paper/90c4081fd752df2bb4a6cabce728d116472d457d",
            "title": "Deep Generative Models in Engineering Design: A Review",
            "venue": "Journal of Mechanical Design",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2110-10863",
                "ArXiv": "2110.10863",
                "DOI": "10.1115/1.4053859",
                "CorpusId": 239050450
            },
            "abstract": "\n Automated design synthesis has the potential to revolutionize the modern engineering design process and improve access to highly optimized and customized products across countless industries. Successfully adapting generative Machine Learning to design engineering may enable such automated design synthesis and is a research subject of great importance. We present a review and analysis of Deep Generative Learning models in engineering design. Deep Generative Models (DGMs) typically leverage deep networks to learn from an input dataset and synthesize new designs. Recently, DGMs such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), feedforward Neural Networks (NNs) and certain Deep Reinforcement Learning (DRL) frameworks have shown promising results in design applications like structural optimization, materials design, and shape synthesis. The prevalence of DGMs in Engineering Design has skyrocketed since 2016. Anticipating continued growth, we conduct a review of recent advances with the hope of benefitting researchers interested in DGMs for design. We structure our review as an exposition of the algorithms, datasets, representation methods, and applications commonly used in the current literature. In particular, we discuss key works that have introduced new techniques and methods in DGMs, successfully applied DGMs to a design-related domain, or directly supported development of DGMs through datasets or auxiliary methods. We further identify key challenges and limitations currently seen in DGMs across design fields, such as design creativity, handling constraints and objectives, and modeling both form and functional performance simultaneously. In our discussion we identify possible solution pathways as key areas on which to target future work.",
            "referenceCount": 190,
            "citationCount": 73,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2110.10863",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-10-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2110.10863"
            },
            "citationStyles": {
                "bibtex": "@Article{Regenwetter2021DeepGM,\n author = {Lyle Regenwetter and A. Nobari and Faez Ahmed},\n booktitle = {Journal of Mechanical Design},\n journal = {ArXiv},\n title = {Deep Generative Models in Engineering Design: A Review},\n volume = {abs/2110.10863},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:02b86623755c6541a3799c26b31bd8f2918ce3f8",
            "@type": "ScholarlyArticle",
            "paperId": "02b86623755c6541a3799c26b31bd8f2918ce3f8",
            "corpusId": 237953101,
            "url": "https://www.semanticscholar.org/paper/02b86623755c6541a3799c26b31bd8f2918ce3f8",
            "title": "Structure-based de novo drug design using 3D deep generative models",
            "venue": "Chemical Science",
            "publicationVenue": {
                "id": "urn:research:2a0713ba-a4af-4a0a-ae49-81b8edeca660",
                "name": "Chemical Science",
                "alternate_names": [
                    "Chem Sci",
                    "Chem sci",
                    "Chemical science"
                ],
                "issn": "2041-6520",
                "url": "http://www.rsc.org/chemicalscience"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2104.08474",
                "DBLP": "journals/corr/abs-2104-08474",
                "PubMedCentral": "8549794",
                "DOI": "10.1039/D1SC04444C",
                "CorpusId": 237953101,
                "PubMed": "34760151"
            },
            "abstract": "Deep generative models are attracting much attention in the field of de novo molecule design. Compared to traditional methods, deep generative models can be trained in a fully data-driven way with little requirement for expert knowledge. Although many models have been developed to generate 1D and 2D molecular structures, 3D molecule generation is less explored, and the direct design of drug-like molecules inside target binding sites remains challenging. In this work, we introduce DeepLigBuilder, a novel deep learning-based method for de novo drug design that generates 3D molecular structures in the binding sites of target proteins. We first developed Ligand Neural Network (L-Net), a novel graph generative model for the end-to-end design of chemically and conformationally valid 3D molecules with high drug-likeness. Then, we combined L-Net with Monte Carlo tree search to perform structure-based de novo drug design tasks. In the case study of inhibitor design for the main protease of SARS-CoV-2, DeepLigBuilder suggested a list of drug-like compounds with novel chemical structures, high predicted affinity, and similar binding features to those of known inhibitors. The current version of L-Net was trained on drug-like compounds from ChEMBL, which could be easily extended to other molecular datasets with desired properties based on users' demands and applied in functional molecule generation. Merging deep generative models with atomic-level interaction evaluation, DeepLigBuilder provides a state-of-the-art model for structure-based de novo drug design and lead optimization.",
            "referenceCount": 76,
            "citationCount": 66,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://pubs.rsc.org/en/content/articlepdf/2021/sc/d1sc04444c",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Biology",
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-04-17",
            "journal": {
                "name": "Chemical Science",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2021StructurebasedDN,\n author = {Yibo Li and Jianfeng Pei and L. Lai},\n booktitle = {Chemical Science},\n journal = {Chemical Science},\n pages = {13664 - 13675},\n title = {Structure-based de novo drug design using 3D deep generative models},\n volume = {12},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e0d71cbf1f775843fe79a42ff93df0b9b0ea4fef",
            "@type": "ScholarlyArticle",
            "paperId": "e0d71cbf1f775843fe79a42ff93df0b9b0ea4fef",
            "corpusId": 231925054,
            "url": "https://www.semanticscholar.org/paper/e0d71cbf1f775843fe79a42ff93df0b9b0ea4fef",
            "title": "Intermediate Layer Optimization for Inverse Problems using Deep Generative Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2102.07364",
                "DBLP": "journals/corr/abs-2102-07364",
                "CorpusId": 231925054
            },
            "abstract": "We propose Intermediate Layer Optimization (ILO), a novel optimization algorithm for solving inverse problems with deep generative models. Instead of optimizing only over the initial latent code, we progressively change the input layer obtaining successively more expressive generators. To explore the higher dimensional spaces, our method searches for latent codes that lie within a small $l_1$ ball around the manifold induced by the previous layer. Our theoretical analysis shows that by keeping the radius of the ball relatively small, we can improve the established error bound for compressed sensing with deep generative models. We empirically show that our approach outperforms state-of-the-art methods introduced in StyleGAN-2 and PULSE for a wide range of inverse problems including inpainting, denoising, super-resolution and compressed sensing.",
            "referenceCount": 74,
            "citationCount": 54,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-02-15",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Daras2021IntermediateLO,\n author = {Giannis Daras and Joseph Dean and A. Jalal and A. Dimakis},\n booktitle = {International Conference on Machine Learning},\n pages = {2421-2432},\n title = {Intermediate Layer Optimization for Inverse Problems using Deep Generative Models},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2d6c105a24be3a2f1c5da32901d70d7c32305126",
            "@type": "ScholarlyArticle",
            "paperId": "2d6c105a24be3a2f1c5da32901d70d7c32305126",
            "corpusId": 220514403,
            "url": "https://www.semanticscholar.org/paper/2d6c105a24be3a2f1c5da32901d70d7c32305126",
            "title": "Estimation of Thermodynamic Observables in Lattice Field Theories with Deep Generative Models.",
            "venue": "Physical Review Letters",
            "publicationVenue": {
                "id": "urn:research:16c9f9d4-bee1-435d-8c85-22a3deba109d",
                "name": "Physical Review Letters",
                "alternate_names": [
                    "Phys Rev Lett"
                ],
                "issn": "0031-9007",
                "url": "https://journals.aps.org/prl/"
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.1103/PhysRevLett.126.032001",
                "CorpusId": 220514403,
                "PubMed": "33543982"
            },
            "abstract": "In this Letter, we demonstrate that applying deep generative machine learning models for lattice field theory is a promising route for solving problems where Markov chain Monte\u00a0Carlo (MCMC) methods are problematic. More specifically, we show that generative models can be used to estimate the absolute value of the free energy, which is in contrast to existing MCMC-based methods, which are limited to only estimate free energy differences. We demonstrate the effectiveness of the proposed method for two-dimensional \u03d5^{4} theory and compare it to MCMC-based methods in detailed numerical experiments.",
            "referenceCount": 50,
            "citationCount": 56,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://link.aps.org/pdf/10.1103/PhysRevLett.126.032001",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-01-19",
            "journal": {
                "name": "Physical review letters",
                "volume": "126 3"
            },
            "citationStyles": {
                "bibtex": "@Article{Nicoli2021EstimationOT,\n author = {K. Nicoli and Christopher J. Anders and L. Funcke and T. Hartung and K. Jansen and P. Kessel and Shinichi Nakajima and Paolo Stornati},\n booktitle = {Physical Review Letters},\n journal = {Physical review letters},\n pages = {\n          032001\n        },\n title = {Estimation of Thermodynamic Observables in Lattice Field Theories with Deep Generative Models.},\n volume = {126 3},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6507909a8f77c88144c3a67b9336bd1c85e84cac",
            "@type": "ScholarlyArticle",
            "paperId": "6507909a8f77c88144c3a67b9336bd1c85e84cac",
            "corpusId": 53046534,
            "url": "https://www.semanticscholar.org/paper/6507909a8f77c88144c3a67b9336bd1c85e84cac",
            "title": "Do Deep Generative Models Know What They Don't Know?",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/iclr/NalisnickMTGL19",
                "MAG": "2963546708",
                "ArXiv": "1810.09136",
                "CorpusId": 53046534
            },
            "abstract": "A neural network deployed in the wild may be asked to make predictions for inputs that were drawn from a different distribution than that of the training data. A plethora of work has demonstrated that it is easy to find or synthesize inputs for which a neural network is highly confident yet wrong. Generative models are widely viewed to be robust to such mistaken confidence as modeling the density of the input features can be used to detect novel, out-of-distribution inputs. In this paper we challenge this assumption. We find that the density learned by flow-based models, VAEs, and PixelCNNs cannot distinguish images of common objects such as dogs, trucks, and horses (i.e. CIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher likelihood to the latter when the model is trained on the former. Moreover, we find evidence of this phenomenon when pairing several popular image data sets: FashionMNIST vs MNIST, CelebA vs SVHN, ImageNet vs CIFAR-10 / CIFAR-100 / SVHN. To investigate this curious behavior, we focus analysis on flow-based generative models in particular since they are trained and evaluated via the exact marginal likelihood. We find such behavior persists even when we restrict the flows to constant-volume transformations. These transformations admit some theoretical analysis, and we show that the difference in likelihoods can be explained by the location and variances of the data and the model curvature. Our results caution against using the density estimates from deep generative models to identify inputs similar to the training distribution until their behavior for out-of-distribution inputs is better understood.",
            "referenceCount": 39,
            "citationCount": 628,
            "influentialCitationCount": 75,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1810.09136"
            },
            "citationStyles": {
                "bibtex": "@Article{Nalisnick2018DoDG,\n author = {Eric T. Nalisnick and Akihiro Matsukawa and Y. Teh and Dilan G\u00f6r\u00fcr and Balaji Lakshminarayanan},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Do Deep Generative Models Know What They Don't Know?},\n volume = {abs/1810.09136},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8bcb5534227214b83255f5b9dedbc0d46a44794a",
            "@type": "ScholarlyArticle",
            "paperId": "8bcb5534227214b83255f5b9dedbc0d46a44794a",
            "corpusId": 237940634,
            "url": "https://www.semanticscholar.org/paper/8bcb5534227214b83255f5b9dedbc0d46a44794a",
            "title": "Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/iclr/SehwagMHD0CM22",
                "ArXiv": "2104.09425",
                "CorpusId": 237940634
            },
            "abstract": "While additional training data improves the robustness of deep neural networks against adversarial examples, it presents the challenge of curating a large number of specific real-world samples. We circumvent this challenge by using additional data from proxy distributions learned by advanced generative models. We first seek to formally understand the transfer of robustness from classifiers trained on proxy distributions to the real data distribution. We prove that the difference between the robustness of a classifier on the two distributions is upper bounded by the conditional Wasserstein distance between them. Next we use proxy distributions to significantly improve the performance of adversarial training on five different datasets. For example, we improve robust accuracy by up to 7.5% and 6.7% in $\\ell_{\\infty}$ and $\\ell_2$ threat model over baselines that are not using proxy distributions on the CIFAR-10 dataset. We also improve certified robust accuracy by 7.6% on the CIFAR-10 dataset. We further demonstrate that different generative models bring a disparate improvement in the performance in robust training. We propose a robust discrimination approach to characterize the impact of individual generative models and further provide a deeper understanding of why current state-of-the-art in diffusion-based generative models are a better choice for proxy distribution than generative adversarial networks.",
            "referenceCount": 80,
            "citationCount": 75,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-04-19",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sehwag2021RobustLM,\n author = {Vikash Sehwag and Saeed Mahloujifar and Tinashe Handina and Sihui Dai and Chong Xiang and M. Chiang and Prateek Mittal},\n booktitle = {International Conference on Learning Representations},\n title = {Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3676e5c74effe6674bd00a8283ef410045cf600a",
            "@type": "ScholarlyArticle",
            "paperId": "3676e5c74effe6674bd00a8283ef410045cf600a",
            "corpusId": 237546263,
            "url": "https://www.semanticscholar.org/paper/3676e5c74effe6674bd00a8283ef410045cf600a",
            "title": "Generative Models for De Novo Drug Design.",
            "venue": "Journal of Medicinal Chemistry",
            "publicationVenue": {
                "id": "urn:research:4cce60a8-2106-4240-bece-fb6488df6bd1",
                "name": "Journal of Medicinal Chemistry",
                "alternate_names": [
                    "J Med Chem"
                ],
                "issn": "0022-2623",
                "url": "https://pubs.acs.org/journal/jmcmar"
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.1021/acs.jmedchem.1c00927",
                "CorpusId": 237546263,
                "PubMed": "34533311"
            },
            "abstract": "Artificial intelligence (AI) is booming. Among various AI approaches, generative models have received much attention in recent years. Inspired by these successes, researchers are now applying generative model techniques to de novo drug design, which has been considered as the \"holy grail\" of drug discovery. In this Perspective, we first focus on describing models such as recurrent neural network, autoencoder, generative adversarial network, transformer, and hybrid models with reinforcement learning. Next, we summarize the applications of generative models to drug design, including generating various compounds to expand the compound library and designing compounds with specific properties, and we also list a few publicly available molecular design tools based on generative models which can be used directly to generate molecules. In addition, we also introduce current benchmarks and metrics frequently used for generative models. Finally, we discuss the challenges and prospects of using generative models to aid drug design.",
            "referenceCount": 90,
            "citationCount": 62,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-09-17",
            "journal": {
                "name": "Journal of medicinal chemistry",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tong2021GenerativeMF,\n author = {X. Tong and Xiaohong Liu and Xiaoqin Tan and Xutong Li and Jiaxin Jiang and Zhaoping Xiong and Tingyang Xu and Hualiang Jiang and Nan Qiao and Mingyue Zheng},\n booktitle = {Journal of Medicinal Chemistry},\n journal = {Journal of medicinal chemistry},\n title = {Generative Models for De Novo Drug Design.},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3a37dedf3f1a0064994c19a4791fc5a892d17b05",
            "@type": "ScholarlyArticle",
            "paperId": "3a37dedf3f1a0064994c19a4791fc5a892d17b05",
            "corpusId": 202767602,
            "url": "https://www.semanticscholar.org/paper/3a37dedf3f1a0064994c19a4791fc5a892d17b05",
            "title": "Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep Generative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2970873268",
                "DBLP": "journals/corr/abs-1911-03393",
                "ArXiv": "1911.03393",
                "CorpusId": 202767602
            },
            "abstract": "Learning generative models that span multiple data modalities, such as vision and language, is often motivated by the desire to learn more useful, generalisable representations that faithfully capture common underlying factors between the modalities. In this work, we characterise successful learning of such models as the fulfilment of four criteria: i) implicit latent decomposition into shared and private subspaces, ii) coherent joint generation over all modalities, iii) coherent cross-generation across individual modalities, and iv) improved model learning for individual modalities through multi-modal integration. Here, we propose a mixture-of-experts multi-modal variational autoencoder (MMVAE) for learning of generative models on different sets of modalities, including a challenging image language dataset, and demonstrate its ability to satisfy all four criteria, both qualitatively and quantitatively.",
            "referenceCount": 59,
            "citationCount": 169,
            "influentialCitationCount": 42,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-11-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shi2019VariationalMA,\n author = {Yuge Shi and Siddharth Narayanaswamy and Brooks Paige and Philip H. S. Torr},\n booktitle = {Neural Information Processing Systems},\n pages = {15692-15703},\n title = {Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep Generative Models},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7f4c17cde1da6f7af2d8596f51a6e3e5041a3312",
            "@type": "ScholarlyArticle",
            "paperId": "7f4c17cde1da6f7af2d8596f51a6e3e5041a3312",
            "corpusId": 237242054,
            "url": "https://www.semanticscholar.org/paper/7f4c17cde1da6f7af2d8596f51a6e3e5041a3312",
            "title": "Molecular design in drug discovery: a comprehensive review of deep generative models",
            "venue": "Briefings Bioinform.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/bib/ChengGLSZ21",
                "DOI": "10.1093/bib/bbab344",
                "CorpusId": 237242054,
                "PubMed": "34415297"
            },
            "abstract": "Deep generative models have been an upsurge in the deep learning community since they were proposed. These models are designed for generating new synthetic data including images, videos and texts by fitting the data approximate distributions. In the last few years, deep generative models have shown superior performance in drug discovery especially de novo molecular design. In this study, deep generative models are reviewed to witness the recent advances of de novo molecular design for drug discovery. In addition, we divide those models into two categories based on molecular representations in silico. Then these two classical types of models are reported in detail and discussed about both pros and cons. We also indicate the current challenges in deep generative models for de novo molecular design. De novo molecular design automatically is promising but a long road to be explored.",
            "referenceCount": 95,
            "citationCount": 47,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-08-20",
            "journal": {
                "name": "Briefings in bioinformatics",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cheng2021MolecularDI,\n author = {Yu Cheng and Yongshun Gong and Yuansheng Liu and Bosheng Song and Q. Zou},\n booktitle = {Briefings Bioinform.},\n journal = {Briefings in bioinformatics},\n title = {Molecular design in drug discovery: a comprehensive review of deep generative models},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a70dee1025cca957bab4b5f8d7c0009b07fab3a8",
            "@type": "ScholarlyArticle",
            "paperId": "a70dee1025cca957bab4b5f8d7c0009b07fab3a8",
            "corpusId": 231662294,
            "url": "https://www.semanticscholar.org/paper/a70dee1025cca957bab4b5f8d7c0009b07fab3a8",
            "title": "Enhancing Generative Models via Quantum Correlations",
            "venue": "Physical Review X",
            "publicationVenue": {
                "id": "urn:research:98eedf55-1e67-4c3d-a25d-79861b87ae04",
                "name": "Physical Review X",
                "alternate_names": [
                    "Phys Rev X"
                ],
                "issn": "2160-3308",
                "url": "https://journals.aps.org/prx/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2101-08354",
                "ArXiv": "2101.08354",
                "DOI": "10.1103/PhysRevX.12.021037",
                "CorpusId": 231662294
            },
            "abstract": "Generative modeling using samples drawn from the probability distribution constitutes a powerful approach for unsupervised machine learning. Quantum mechanical systems can produce probability distributions that exhibit quantum correlations which are di\ufb03cult to capture using classical models. We show theoretically that such quantum correlations provide a powerful resource for generative modeling. In particular, we provide an unconditional proof of separation in expressive power between a class of widely-used generative models, known as Bayesian networks, and its minimal quantum extension. We show that this expressivity advantage is associated with quantum nonlocality and quantum contextuality. Furthermore, we numerically test this separation on standard machine learning data sets and show that it holds for practical problems. The possibility of quantum advantage demonstrated in this work not only sheds light on the design of useful quantum machine learning protocols but also provides inspiration to draw on ideas from quantum foundations to improve purely classical algorithms.",
            "referenceCount": 85,
            "citationCount": 47,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://link.aps.org/pdf/10.1103/PhysRevX.12.021037",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Physics",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-01-20",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2101.08354"
            },
            "citationStyles": {
                "bibtex": "@Article{Gao2021EnhancingGM,\n author = {Xun Gao and Eric R. Anschuetz and Sheng-Tao Wang and J. Cirac and M. Lukin},\n booktitle = {Physical Review X},\n journal = {ArXiv},\n title = {Enhancing Generative Models via Quantum Correlations},\n volume = {abs/2101.08354},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1ea9f643171115e4a89e77c9a770c593f0794712",
            "@type": "ScholarlyArticle",
            "paperId": "1ea9f643171115e4a89e77c9a770c593f0794712",
            "corpusId": 44104089,
            "url": "https://www.semanticscholar.org/paper/1ea9f643171115e4a89e77c9a770c593f0794712",
            "title": "Assessing Generative Models via Precision and Recall",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2951984970",
                "DBLP": "journals/corr/abs-1806-00035",
                "ArXiv": "1806.00035",
                "CorpusId": 44104089
            },
            "abstract": "Recent advances in generative modeling have led to an increased interest in the study of statistical divergences as means of model comparison. Commonly used evaluation methods, such as the Frechet Inception Distance (FID), correlate well with the perceived quality of samples and are sensitive to mode dropping. However, these metrics are unable to distinguish between different failure cases since they only yield one-dimensional scores. We propose a novel definition of precision and recall for distributions which disentangles the divergence into two separate dimensions. The proposed notion is intuitive, retains desirable properties, and naturally leads to an efficient algorithm that can be used to evaluate generative models. We relate this notion to total variation as well as to recent evaluation metrics such as Inception Score and FID. To demonstrate the practical utility of the proposed approach we perform an empirical study on several variants of Generative Adversarial Networks and Variational Autoencoders. In an extensive set of experiments we show that the proposed metric is able to disentangle the quality of generated samples from the coverage of the target distribution.",
            "referenceCount": 24,
            "citationCount": 404,
            "influentialCitationCount": 66,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-05-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1806.00035"
            },
            "citationStyles": {
                "bibtex": "@Article{Sajjadi2018AssessingGM,\n author = {Mehdi S. M. Sajjadi and Olivier Bachem and Mario Lucic and O. Bousquet and S. Gelly},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Assessing Generative Models via Precision and Recall},\n volume = {abs/1806.00035},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b3159fd22e19e24d7cde9d37b3e482b832d4fa58",
            "@type": "ScholarlyArticle",
            "paperId": "b3159fd22e19e24d7cde9d37b3e482b832d4fa58",
            "corpusId": 23102425,
            "url": "https://www.semanticscholar.org/paper/b3159fd22e19e24d7cde9d37b3e482b832d4fa58",
            "title": "Learning Representations and Generative Models for 3D Point Clouds",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2930206194",
                "DBLP": "conf/icml/AchlioptasDMG18",
                "CorpusId": 23102425
            },
            "abstract": "Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep AutoEncoder (AE) network with state-of-the-art reconstruction quality and generalization ability. The learned representations outperform existing methods on 3D recognition tasks and enable shape editing via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation, as well as shape completion. We perform a thorough study of different generative models including GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space of our AEs, and Gaussian Mixture Models (GMMs). To quantitatively evaluate generative models we introduce measures of sample fidelity and diversity based on matchings between sets of point clouds. Interestingly, our evaluation of generalization, fidelity and diversity reveals that GMMs trained in the latent space of our AEs yield the best results overall.",
            "referenceCount": 59,
            "citationCount": 1078,
            "influentialCitationCount": 208,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-07-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Achlioptas2017LearningRA,\n author = {Panos Achlioptas and Olga Diamanti and Ioannis Mitliagkas and L. Guibas},\n booktitle = {International Conference on Machine Learning},\n pages = {40-49},\n title = {Learning Representations and Generative Models for 3D Point Clouds},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f32f16ca3c27ff945198c6551a5d35fae3b1a660",
            "@type": "ScholarlyArticle",
            "paperId": "f32f16ca3c27ff945198c6551a5d35fae3b1a660",
            "corpusId": 3783953,
            "url": "https://www.semanticscholar.org/paper/f32f16ca3c27ff945198c6551a5d35fae3b1a660",
            "title": "Learning Deep Generative Models of Graphs",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1803-03324",
                "ArXiv": "1803.03324",
                "MAG": "2963555927",
                "CorpusId": 3783953
            },
            "abstract": "Graphs are fundamental data structures which concisely capture the relational structure in many important real-world domains, such as knowledge graphs, physical and social interactions, language, and chemistry. Here we introduce a powerful new approach for learning generative models over graphs, which can capture both their structure and attributes. Our approach uses graph neural networks to express probabilistic dependencies among a graph's nodes and edges, and can, in principle, learn distributions over any arbitrary graph. In a series of experiments our results show that once trained, our models can generate good quality samples of both synthetic graphs as well as real molecular graphs, both unconditionally and conditioned on data. Compared to baselines that do not use graph-structured representations, our models often perform far better. We also explore key challenges of learning generative models of graphs, such as how to handle symmetries and ordering of elements during the graph generation process, and offer possible solutions. Our work is the first and most general approach for learning generative models over arbitrary graphs, and opens new directions for moving away from restrictions of vector- and sequence-like knowledge representations, toward more expressive and flexible relational data structures.",
            "referenceCount": 43,
            "citationCount": 556,
            "influentialCitationCount": 63,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1803.03324"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2018LearningDG,\n author = {Yujia Li and Oriol Vinyals and Chris Dyer and Razvan Pascanu and P. Battaglia},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Learning Deep Generative Models of Graphs},\n volume = {abs/1803.03324},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a9ec03dbe702f6909acd1f1f14a3395d0141043b",
            "@type": "ScholarlyArticle",
            "paperId": "a9ec03dbe702f6909acd1f1f14a3395d0141043b",
            "corpusId": 160017948,
            "url": "https://www.semanticscholar.org/paper/a9ec03dbe702f6909acd1f1f14a3395d0141043b",
            "title": "Generative Models for Graph-Based Protein Design",
            "venue": "DGS@ICLR",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2957874522",
                "DBLP": "conf/nips/IngrahamGBJ19",
                "CorpusId": 160017948
            },
            "abstract": "Engineered proteins offer the potential to solve many problems in biomedicine, energy, and materials science, but creating designs that succeed is difficult in practice. A significant aspect of this challenge is the complex coupling between protein sequence and 3D structure, with the task of finding a viable design often referred to as the inverse protein folding problem. We develop relational language models for protein sequences that directly condition on a graph specification of the target structure. Our approach efficiently captures the complex dependencies in proteins by focusing on those that are long-range in sequence but local in 3D space. Our framework significantly improves in both speed and robustness over conventional and deep-learning-based methods for structure-based protein sequence design, and takes a step toward rapid and targeted biomolecular design with the aid of deep generative models.",
            "referenceCount": 50,
            "citationCount": 312,
            "influentialCitationCount": 36,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-27",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ingraham2019GenerativeMF,\n author = {John Ingraham and Vikas K. Garg and R. Barzilay and T. Jaakkola},\n booktitle = {DGS@ICLR},\n pages = {15794-15805},\n title = {Generative Models for Graph-Based Protein Design},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:68a384025c650bf6be41a227c6b1035896e75004",
            "@type": "ScholarlyArticle",
            "paperId": "68a384025c650bf6be41a227c6b1035896e75004",
            "corpusId": 235359053,
            "url": "https://www.semanticscholar.org/paper/68a384025c650bf6be41a227c6b1035896e75004",
            "title": "On Memorization in Probabilistic Deep Generative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2106-03216",
                "ArXiv": "2106.03216",
                "CorpusId": 235359053
            },
            "abstract": "Recent advances in deep generative models have led to impressive results in a variety of application domains. Motivated by the possibility that deep learning models might memorize part of the input data, there have been increased efforts to understand how memorization arises. In this work, we extend a recently proposed measure of memorization for supervised learning (Feldman, 2019) to the unsupervised density estimation problem and adapt it to be more computationally efficient. Next, we present a study that demonstrates how memorization can occur in probabilistic deep generative models such as variational autoencoders. This reveals that the form of memorization to which these models are susceptible differs fundamentally from mode collapse and overfitting. Furthermore, we show that the proposed memorization score measures a phenomenon that is not captured by commonly-used nearest neighbor tests. Finally, we discuss several strategies that can be used to limit memorization in practice. Our work thus provides a framework for understanding problematic memorization in probabilistic generative models.",
            "referenceCount": 81,
            "citationCount": 32,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-06-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Burg2021OnMI,\n author = {G. V. D. Burg and Christopher K. I. Williams},\n booktitle = {Neural Information Processing Systems},\n pages = {27916-27928},\n title = {On Memorization in Probabilistic Deep Generative Models},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:175e37bca3762b3a52c6a0e153060b98a251d061",
            "@type": "ScholarlyArticle",
            "paperId": "175e37bca3762b3a52c6a0e153060b98a251d061",
            "corpusId": 50787617,
            "url": "https://www.semanticscholar.org/paper/175e37bca3762b3a52c6a0e153060b98a251d061",
            "title": "Inverse molecular design using machine learning: Generative models for matter engineering",
            "venue": "Science",
            "publicationVenue": {
                "id": "urn:research:f59506a8-d8bb-4101-b3d4-c4ac3ed03dad",
                "name": "Science",
                "alternate_names": null,
                "issn": "0193-4511",
                "url": "https://www.jstor.org/journal/science"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2883583109",
                "DOI": "10.1126/science.aat2663",
                "CorpusId": 50787617,
                "PubMed": "30049875"
            },
            "abstract": "The discovery of new materials can bring enormous societal and technological progress. In this context, exploring completely the large space of potential materials is computationally intractable. Here, we review methods for achieving inverse design, which aims to discover tailored materials from the starting point of a particular desired functionality. Recent advances from the rapidly growing field of artificial intelligence, mostly from the subfield of machine learning, have resulted in a fertile exchange of ideas, where approaches to inverse molecular design are being proposed and employed at a rapid pace. Among these, deep generative models have been applied to numerous classes of materials: rational design of prospective drugs, synthetic routes to organic compounds, and optimization of photovoltaics and redox flow batteries, as well as a variety of other solid-state materials.",
            "referenceCount": 93,
            "citationCount": 1056,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://science.sciencemag.org/content/sci/361/6400/360.full.pdf",
                "status": "CLOSED"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-07-27",
            "journal": {
                "name": "Science",
                "volume": "361"
            },
            "citationStyles": {
                "bibtex": "@Article{S\u00e1nchez-Lengeling2018InverseMD,\n author = {Benjam\u00edn S\u00e1nchez-Lengeling and Al\u00e1n Aspuru-Guzik},\n booktitle = {Science},\n journal = {Science},\n pages = {360 - 365},\n title = {Inverse molecular design using machine learning: Generative models for matter engineering},\n volume = {361},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:353ecf7b66b3e9ff5e9f41145a147e899a2eea5c",
            "@type": "ScholarlyArticle",
            "paperId": "353ecf7b66b3e9ff5e9f41145a147e899a2eea5c",
            "corpusId": 12803511,
            "url": "https://www.semanticscholar.org/paper/353ecf7b66b3e9ff5e9f41145a147e899a2eea5c",
            "title": "Conditional Generative Adversarial Nets",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2125389028",
                "ArXiv": "1411.1784",
                "DBLP": "journals/corr/MirzaO14",
                "CorpusId": 12803511
            },
            "abstract": "Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.",
            "referenceCount": 18,
            "citationCount": 8527,
            "influentialCitationCount": 1269,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-11-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1411.1784"
            },
            "citationStyles": {
                "bibtex": "@Article{Mirza2014ConditionalGA,\n author = {Mehdi Mirza and Simon Osindero},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Conditional Generative Adversarial Nets},\n volume = {abs/1411.1784},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:13bc4e683075bdd6a3f0155241c276a772d4aa06",
            "@type": "ScholarlyArticle",
            "paperId": "13bc4e683075bdd6a3f0155241c276a772d4aa06",
            "corpusId": 1033682,
            "url": "https://www.semanticscholar.org/paper/13bc4e683075bdd6a3f0155241c276a772d4aa06",
            "title": "Generative adversarial networks",
            "venue": "Communications of the ACM",
            "publicationVenue": {
                "id": "urn:research:4d9ce1c4-dc84-46b9-903e-e3751c00c7dd",
                "name": "Communications of the ACM",
                "alternate_names": [
                    "Commun ACM",
                    "Communications of The ACM"
                ],
                "issn": "0001-0782",
                "url": "http://www.acm.org/pubs/cacm/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "3093962121",
                "DBLP": "journals/corr/GoodfellowPMXWOCB14",
                "DOI": "10.1145/3422622",
                "CorpusId": 1033682
            },
            "abstract": "Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.",
            "referenceCount": 156,
            "citationCount": 39089,
            "influentialCitationCount": 5941,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3422622",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-06-10",
            "journal": {
                "name": "Communications of the ACM",
                "volume": "63"
            },
            "citationStyles": {
                "bibtex": "@Article{Goodfellow2014GenerativeAN,\n author = {I. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron C. Courville and Yoshua Bengio},\n booktitle = {Communications of the ACM},\n journal = {Communications of the ACM},\n pages = {139 - 144},\n title = {Generative adversarial networks},\n volume = {63},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bc519f58ae61afbf6318d6e4239d2d565c7ba467",
            "@type": "ScholarlyArticle",
            "paperId": "bc519f58ae61afbf6318d6e4239d2d565c7ba467",
            "corpusId": 232147810,
            "url": "https://www.semanticscholar.org/paper/bc519f58ae61afbf6318d6e4239d2d565c7ba467",
            "title": "Deep Generative Modelling: A Comparative Review of VAEs, GANs, Normalizing Flows, Energy-Based and Autoregressive Models",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2103-04922",
                "ArXiv": "2103.04922",
                "DOI": "10.1109/TPAMI.2021.3116668",
                "CorpusId": 232147810,
                "PubMed": "34591756"
            },
            "abstract": "Deep generative models are a class of techniques that train deep neural networks to model the distribution of training samples. Research has fragmented into various interconnected approaches, each of which make trade-offs including run-time, diversity, and architectural restrictions. In particular, this compendium covers energy-based models, variational autoencoders, generative adversarial networks, autoregressive models, normalizing flows, in addition to numerous hybrid approaches. These techniques are compared and contrasted, explaining the premises behind each and how they are interrelated, while reviewing current state-of-the-art advances and implementations.",
            "referenceCount": 276,
            "citationCount": 220,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/34/9910240/09555209.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-03-08",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "44"
            },
            "citationStyles": {
                "bibtex": "@Article{Bond-Taylor2021DeepGM,\n author = {Sam Bond-Taylor and Adam Leach and Yang Long and Chris G. Willcocks},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {7327-7347},\n title = {Deep Generative Modelling: A Comparative Review of VAEs, GANs, Normalizing Flows, Energy-Based and Autoregressive Models},\n volume = {44},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bd1f217e7bd396d3e4b5ca51df8d9f80d0649264",
            "@type": "ScholarlyArticle",
            "paperId": "bd1f217e7bd396d3e4b5ca51df8d9f80d0649264",
            "corpusId": 211259260,
            "url": "https://www.semanticscholar.org/paper/bd1f217e7bd396d3e4b5ca51df8d9f80d0649264",
            "title": "Reliable Fidelity and Diversity Metrics for Generative Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2002.09797",
                "DBLP": "conf/icml/NaeemOUCY20",
                "MAG": "3034723908",
                "CorpusId": 211259260
            },
            "abstract": "Devising indicative evaluation metrics for the image generation task remains an open problem. The most widely used metric for measuring the similarity between real and generated images has been the Frechet Inception Distance (FID) score. Because it does not differentiate the fidelity and diversity aspects of the generated images, recent papers have introduced variants of precision and recall metrics to diagnose those properties separately. In this paper, we show that even the latest version of the precision and recall metrics are not reliable yet. For example, they fail to detect the match between two identical distributions, they are not robust against outliers, and the evaluation hyperparameters are selected arbitrarily. We propose density and coverage metrics that solve the above issues. We analytically and experimentally show that density and coverage provide more interpretable and reliable signals for practitioners than the existing metrics. Code: this https URL.",
            "referenceCount": 25,
            "citationCount": 194,
            "influentialCitationCount": 31,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-02-23",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2002.09797"
            },
            "citationStyles": {
                "bibtex": "@Article{Naeem2020ReliableFA,\n author = {Muhammad Ferjad Naeem and Seong Joon Oh and Youngjung Uh and Yunjey Choi and Jaejun Yoo},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Reliable Fidelity and Diversity Metrics for Generative Models},\n volume = {abs/2002.09797},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b59233aab8364186603967bc12d88af48cc0992d",
            "@type": "ScholarlyArticle",
            "paperId": "b59233aab8364186603967bc12d88af48cc0992d",
            "corpusId": 54458806,
            "url": "https://www.semanticscholar.org/paper/b59233aab8364186603967bc12d88af48cc0992d",
            "title": "Towards Accurate Generative Models of Video: A New Metric & Challenges",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1812-01717",
                "ArXiv": "1812.01717",
                "MAG": "2902437806",
                "CorpusId": 54458806
            },
            "abstract": "Recent advances in deep generative models have lead to remarkable progress in synthesizing high quality images. Following their successful application in image processing and representation learning, an important next step is to consider videos. Learning generative models of video is a much harder task, requiring a model to capture the temporal dynamics of a scene, in addition to the visual presentation of objects. While recent attempts at formulating generative models of video have had some success, current progress is hampered by (1) the lack of qualitative metrics that consider visual quality, temporal coherence, and diversity of samples, and (2) the wide gap between purely synthetic video data sets and challenging real-world data sets in terms of complexity. To this extent we propose Fr\\'{e}chet Video Distance (FVD), a new metric for generative models of video, and StarCraft 2 Videos (SCV), a benchmark of game play from custom starcraft 2 scenarios that challenge the current capabilities of generative models of video. We contribute a large-scale human study, which confirms that FVD correlates well with qualitative human judgment of generated videos, and provide initial benchmark results on SCV.",
            "referenceCount": 53,
            "citationCount": 277,
            "influentialCitationCount": 97,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-12-03",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1812.01717"
            },
            "citationStyles": {
                "bibtex": "@Article{Unterthiner2018TowardsAG,\n author = {Thomas Unterthiner and Sjoerd van Steenkiste and Karol Kurach and Rapha\u00ebl Marinier and Marcin Michalski and S. Gelly},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Towards Accurate Generative Models of Video: A New Metric & Challenges},\n volume = {abs/1812.01717},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4f00c357b4757e324dc5b0d45cf0d345e995d10d",
            "@type": "ScholarlyArticle",
            "paperId": "4f00c357b4757e324dc5b0d45cf0d345e995d10d",
            "corpusId": 3328096,
            "url": "https://www.semanticscholar.org/paper/4f00c357b4757e324dc5b0d45cf0d345e995d10d",
            "title": "Multimodal Generative Models for Scalable Weakly-Supervised Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2786541991",
                "ArXiv": "1802.05335",
                "DBLP": "conf/nips/WuG18",
                "CorpusId": 3328096
            },
            "abstract": "Multiple modalities often co-occur when describing natural phenomena. Learning a joint representation of these modalities should yield deeper and more useful representations. Previous work have proposed generative models to handle multi-modal input. However, these models either do not learn a joint distribution or require complex additional computations to handle missing data. Here, we introduce a multimodal variational autoencoder that uses a product-of-experts inference network and a sub-sampled training paradigm to solve the multi-modal inference problem. Notably, our model shares parameters to efficiently learn under any combination of missing modalities, thereby enabling weakly-supervised learning. We apply our method on four datasets and show that we match state-of-the-art performance using many fewer parameters. In each case our approach yields strong weakly-supervised results. We then consider a case study of learning image transformations---edge detection, colorization, facial landmark segmentation, etc.---as a set of modalities. We find appealing results across this range of tasks.",
            "referenceCount": 39,
            "citationCount": 269,
            "influentialCitationCount": 91,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2018MultimodalGM,\n author = {Mike Wu and Noah D. Goodman},\n booktitle = {Neural Information Processing Systems},\n pages = {5580-5590},\n title = {Multimodal Generative Models for Scalable Weakly-Supervised Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:df6cb11aeb94b8b4261420db6d07e9d71c7c0a44",
            "@type": "ScholarlyArticle",
            "paperId": "df6cb11aeb94b8b4261420db6d07e9d71c7c0a44",
            "corpusId": 9272289,
            "url": "https://www.semanticscholar.org/paper/df6cb11aeb94b8b4261420db6d07e9d71c7c0a44",
            "title": "Compressed Sensing using Generative Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2949536516",
                "DBLP": "journals/corr/BoraJPD17",
                "ArXiv": "1703.03208",
                "CorpusId": 9272289
            },
            "abstract": "The goal of compressed sensing is to estimate a vector from an underdetermined system of noisy linear measurements, by making use of prior knowledge on the structure of vectors in the relevant domain. For almost all results in this literature, the structure is represented by sparsity in a well-chosen basis. We show how to achieve guarantees similar to standard compressed sensing but without employing sparsity at all. Instead, we suppose that vectors lie near the range of a generative model G : \u211dk \u2192 \u211dn. Our main theorem is that, if G is L-Lipschitz, then roughly O(k log L) random Gaussian measurements suffice for an l2/l2 recovery guarantee. We demonstrate our results using generative models from published variational autoencoder and generative adversarial networks. Our method can use 5-10x fewer measurements than Lasso for the same accuracy.",
            "referenceCount": 45,
            "citationCount": 676,
            "influentialCitationCount": 136,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bora2017CompressedSU,\n author = {Ashish Bora and A. Jalal and Eric Price and A. Dimakis},\n booktitle = {International Conference on Machine Learning},\n pages = {537-546},\n title = {Compressed Sensing using Generative Models},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1322719978980a831e1aee78aa80a141379c44dd",
            "@type": "ScholarlyArticle",
            "paperId": "1322719978980a831e1aee78aa80a141379c44dd",
            "corpusId": 202749994,
            "url": "https://www.semanticscholar.org/paper/1322719978980a831e1aee78aa80a141379c44dd",
            "title": "Input complexity and out-of-distribution detection with likelihood-based generative models",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2976969310",
                "DBLP": "conf/iclr/SerraAGSNL20",
                "ArXiv": "1909.11480",
                "CorpusId": 202749994
            },
            "abstract": "Likelihood-based generative models are a promising resource to detect out-of-distribution (OOD) inputs which could compromise the robustness or reliability of a machine learning system. However, likelihoods derived from such models have been shown to be problematic for detecting certain types of inputs that significantly differ from training data. In this paper, we pose that this problem is due to the excessive influence that input complexity has in generative models' likelihoods. We report a set of experiments supporting this hypothesis, and use an estimate of input complexity to derive an efficient and parameter-free OOD score, which can be seen as a likelihood-ratio, akin to Bayesian model comparison. We find such score to perform comparably to, or even better than, existing OOD detection approaches under a wide range of data sets, models, model sizes, and complexity estimates.",
            "referenceCount": 32,
            "citationCount": 210,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-09-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1909.11480"
            },
            "citationStyles": {
                "bibtex": "@Article{Serr\u00e02019InputCA,\n author = {J. Serr\u00e0 and David \u00c1lvarez and V. G\u00f3mez and Olga Slizovskaia and Jos\u00e9 F. N\u00fa\u00f1ez and J. Luque},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Input complexity and out-of-distribution detection with likelihood-based generative models},\n volume = {abs/1909.11480},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:103b4fe9242ece169e80fd5adf015e109125663c",
            "@type": "ScholarlyArticle",
            "paperId": "103b4fe9242ece169e80fd5adf015e109125663c",
            "corpusId": 221203089,
            "url": "https://www.semanticscholar.org/paper/103b4fe9242ece169e80fd5adf015e109125663c",
            "title": "GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative Models",
            "venue": "Conference on Computer and Communications Security",
            "publicationVenue": {
                "id": "urn:research:73f7fe95-b68b-468f-b7ba-3013ca879e50",
                "name": "Conference on Computer and Communications Security",
                "alternate_names": [
                    "Int Workshop Cogn Cell Syst",
                    "CCS",
                    "Comput Commun Secur",
                    "CcS",
                    "International Symposium on Community-centric Systems",
                    "International Workshop on Cognitive Cellular Systems",
                    "Conf Comput Commun Secur",
                    "Comb Comput Sci",
                    "Int Symp Community-centric Syst",
                    "Combinatorics and Computer Science",
                    "Circuits, Signals, and Systems",
                    "Computer and Communications Security",
                    "Circuit Signal Syst"
                ],
                "issn": null,
                "url": "https://dl.acm.org/conference/ccs"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3071470454",
                "DBLP": "conf/ccs/ChenYZF20",
                "DOI": "10.1145/3372297.3417238",
                "CorpusId": 221203089
            },
            "abstract": "Deep learning has achieved overwhelming success, spanning from discriminative models to generative models. In particular, deep generative models have facilitated a new level of performance in a myriad of areas, ranging from media manipulation to sanitized dataset generation. Despite the great success, the potential risks of privacy breach caused by generative models have not been analyzed systematically. In this paper, we focus on membership inference attack against deep generative models that reveals information about the training data used for victim models. Specifically, we present the first taxonomy of membership inference attacks, encompassing not only existing attacks but also our novel ones. In addition, we propose the first generic attack model that can be instantiated in a large range of settings and is applicable to various kinds of deep generative models. Moreover, we provide a theoretically grounded attack calibration technique, which consistently boosts the attack performance in all cases, across different attack settings, data modalities, and training configurations. We complement the systematic analysis of attack performance by a comprehensive experimental study, that investigates the effectiveness of various attacks w.r.t. model type and training configurations, over three diverse application scenarios (i.e., images, medical data, and location data).",
            "referenceCount": 100,
            "citationCount": 212,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1909.03935",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-09-09",
            "journal": {
                "name": "Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Chen2019GANLeaksAT,\n author = {Dingfan Chen and Ning Yu and Yang Zhang and Mario Fritz},\n booktitle = {Conference on Computer and Communications Security},\n journal = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},\n title = {GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative Models},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d5fe03eadeeb0a183bdd69e19d3fc61a09331e41",
            "@type": "ScholarlyArticle",
            "paperId": "d5fe03eadeeb0a183bdd69e19d3fc61a09331e41",
            "corpusId": 252085985,
            "url": "https://www.semanticscholar.org/paper/d5fe03eadeeb0a183bdd69e19d3fc61a09331e41",
            "title": "Probabilistic Generative Models",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2022,
            "externalIds": {
                "CorpusId": 252085985
            },
            "abstract": "A generative model is a model that learns to imitate some patterngenerating process. That is, we have (high-dimensional) patterns x \u2208 X that are generated according to a probability distribution p on X . We want to learn a model p\u03b8 that is indistinguishable from p. In particular, our model should (1) avoid missing patterns that are generated by p (this is called mode collapse) and (2) avoid generating patterns that are not supported by p. A famous example is the example of generating human faces, where we want to generate facial features proportional to how frequently they occur in real human faces.",
            "referenceCount": 3,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{H\u00fcbotter2022ProbabilisticGM,\n author = {Jonas H\u00fcbotter},\n title = {Probabilistic Generative Models},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa",
            "@type": "ScholarlyArticle",
            "paperId": "ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa",
            "corpusId": 166228599,
            "url": "https://www.semanticscholar.org/paper/ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa",
            "title": "Classification Accuracy Score for Conditional Generative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/nips/RavuriV19",
                "MAG": "2945027741",
                "ArXiv": "1905.10887",
                "CorpusId": 166228599
            },
            "abstract": "Deep generative models (DGMs) of images are now sufficiently mature that they produce nearly photorealistic samples and obtain scores similar to the data distribution on heuristics such as Frechet Inception Distance (FID). These results, especially on large-scale datasets such as ImageNet, suggest that DGMs are learning the data distribution in a perceptually meaningful space and can be used in downstream tasks. To test this latter hypothesis, we use class-conditional generative models from a number of model classes---variational autoencoders, autoregressive models, and generative adversarial networks (GANs)---to infer the class labels of real data. We perform this inference by training an image classifier using only synthetic data and using the classifier to predict labels on real data. The performance on this task, which we call Classification Accuracy Score (CAS), reveals some surprising results not identified by traditional metrics and constitute our contributions. First, when using a state-of-the-art GAN (BigGAN-deep), Top-1 and Top-5 accuracy decrease by 27.9\\% and 41.6\\%, respectively, compared to the original data; and conditional generative models from other model classes, such as Vector-Quantized Variational Autoencoder-2 (VQ-VAE-2) and Hierarchical Autoregressive Models (HAMs), substantially outperform GANs on this benchmark. Second, CAS automatically surfaces particular classes for which generative models failed to capture the data distribution, and were previously unknown in the literature. Third, we find traditional GAN metrics such as Inception Score (IS) and FID neither predictive of CAS nor useful when evaluating non-GAN models. Furthermore, in order to facilitate better diagnoses of generative models, we open-source the proposed metric.",
            "referenceCount": 48,
            "citationCount": 164,
            "influentialCitationCount": 27,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-05-26",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1905.10887"
            },
            "citationStyles": {
                "bibtex": "@Article{Ravuri2019ClassificationAS,\n author = {Suman V. Ravuri and Oriol Vinyals},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Classification Accuracy Score for Conditional Generative Models},\n volume = {abs/1905.10887},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f34b6423878090c7422c078a3dd6a3db80fb7532",
            "@type": "ScholarlyArticle",
            "paperId": "f34b6423878090c7422c078a3dd6a3db80fb7532",
            "corpusId": 198190707,
            "url": "https://www.semanticscholar.org/paper/f34b6423878090c7422c078a3dd6a3db80fb7532",
            "title": "Estimating the success of re-identifications in incomplete datasets using generative models",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2019,
            "externalIds": {
                "PubMedCentral": "6650473",
                "MAG": "2963693643",
                "DOI": "10.1038/s41467-019-10933-3",
                "CorpusId": 198190707,
                "PubMed": "31337762"
            },
            "abstract": null,
            "referenceCount": 70,
            "citationCount": 449,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41467-019-10933-3.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-07-23",
            "journal": {
                "name": "Nature Communications",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Rocher2019EstimatingTS,\n author = {Luc Rocher and J. Hendrickx and Y. de Montjoye},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {Estimating the success of re-identifications in incomplete datasets using generative models},\n volume = {10},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:555c0d308a1c9faa089430133566bf0dd6e4613d",
            "@type": "ScholarlyArticle",
            "paperId": "555c0d308a1c9faa089430133566bf0dd6e4613d",
            "corpusId": 211132437,
            "url": "https://www.semanticscholar.org/paper/555c0d308a1c9faa089430133566bf0dd6e4613d",
            "title": "The Synthesizability of Molecules Proposed by Generative Models",
            "venue": "Journal of Chemical Information and Modeling",
            "publicationVenue": {
                "id": "urn:research:3f16aef5-6b9f-4f87-baca-cbf8147e352f",
                "name": "Journal of Chemical Information and Modeling",
                "alternate_names": [
                    "J Chem Inf Model"
                ],
                "issn": "1549-9596",
                "url": "http://pubs.acs.org/jcim"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/jcisd/GaoC20",
                "ArXiv": "2002.07007",
                "MAG": "3005864172",
                "DOI": "10.1021/acs.jcim.0c00174",
                "CorpusId": 211132437,
                "PubMed": "32250616"
            },
            "abstract": "The discovery of functional molecules is an expensive and time-consuming process, exemplified by the rising costs of small molecule therapeutic discovery. One class of techniques of growing interest for early-stage drug discovery is de novo molecular generation and optimization, catalyzed by the development of new deep learning approaches. These techniques can suggest novel molecular structures intended to maximize a multi-objective function, e.g., suitability as a therapeutic against a particular target, without relying on brute-force exploration of a chemical space. However, the utility of these approaches is stymied by ignorance of synthesizability. To highlight the severity of this issue, we use a data-driven computer-aided synthesis planning program to quantify how often molecules proposed by state-of-the-art generative models cannot be readily synthesized. Our analysis demonstrates that there are several tasks for which these models generate unrealistic molecular structures despite performing well on popular quantitative benchmarks. Synthetic complexity heuristics can successfully bias generation toward synthetically-tractable chemical space, although doing so necessarily detracts from the primary objective. This analysis suggests that to improve the utility of these models in real discovery workflows, new algorithm development is warranted.",
            "referenceCount": 51,
            "citationCount": 165,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2002.07007",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Biology",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-02-17",
            "journal": {
                "name": "Journal of chemical information and modeling",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gao2020TheSO,\n author = {Wenhao Gao and Connor W. Coley},\n booktitle = {Journal of Chemical Information and Modeling},\n journal = {Journal of chemical information and modeling},\n title = {The Synthesizability of Molecules Proposed by Generative Models},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a1aed6c0f20b659bb0c5f559c6d33584d51c5aab",
            "@type": "ScholarlyArticle",
            "paperId": "a1aed6c0f20b659bb0c5f559c6d33584d51c5aab",
            "corpusId": 214591015,
            "url": "https://www.semanticscholar.org/paper/a1aed6c0f20b659bb0c5f559c6d33584d51c5aab",
            "title": "Deep Generative Models for 3D Linker Design",
            "venue": "Journal of Chemical Information and Modeling",
            "publicationVenue": {
                "id": "urn:research:3f16aef5-6b9f-4f87-baca-cbf8147e352f",
                "name": "Journal of Chemical Information and Modeling",
                "alternate_names": [
                    "J Chem Inf Model"
                ],
                "issn": "1549-9596",
                "url": "http://pubs.acs.org/jcim"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3011847211",
                "DBLP": "journals/jcisd/ImrieBSD20",
                "PubMedCentral": "7189367",
                "DOI": "10.1021/acs.jcim.9b01120",
                "CorpusId": 214591015,
                "PubMed": "32195587"
            },
            "abstract": "Rational compound design remains a challenging problem for both computational methods and medicinal chemists. Computational generative methods have begun to show promising results for the design problem. However, they have not yet used the power of three-dimensional (3D) structural information. We have developed a novel graph-based deep generative model that combines state-of-the-art machine learning techniques with structural knowledge. Our method (\u201cDeLinker\u201d) takes two fragments or partial structures and designs a molecule incorporating both. The generation process is protein-context-dependent, utilizing the relative distance and orientation between the partial structures. This 3D information is vital to successful compound design, and we demonstrate its impact on the generation process and the limitations of omitting such information. In a large-scale evaluation, DeLinker designed 60% more molecules with high 3D similarity to the original molecule than a database baseline. When considering the more relevant problem of longer linkers with at least five atoms, the outperformance increased to 200%. We demonstrate the effectiveness and applicability of this approach on a diverse range of design problems: fragment linking, scaffold hopping, and proteolysis targeting chimera (PROTAC) design. As far as we are aware, this is the first molecular generative model to incorporate 3D structural information directly in the design process. The code is available at https://github.com/oxpig/DeLinker.",
            "referenceCount": 51,
            "citationCount": 124,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc7189367?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-03-20",
            "journal": {
                "name": "Journal of Chemical Information and Modeling",
                "volume": "60"
            },
            "citationStyles": {
                "bibtex": "@Article{Imrie2020DeepGM,\n author = {F. Imrie and A. Bradley and M. Schaar and C. Deane},\n booktitle = {Journal of Chemical Information and Modeling},\n journal = {Journal of Chemical Information and Modeling},\n pages = {1983 - 1995},\n title = {Deep Generative Models for 3D Linker Design},\n volume = {60},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b4cbc3ce5fddfbf2d3271018ae697569834a3433",
            "@type": "ScholarlyArticle",
            "paperId": "b4cbc3ce5fddfbf2d3271018ae697569834a3433",
            "corpusId": 238419552,
            "url": "https://www.semanticscholar.org/paper/b4cbc3ce5fddfbf2d3271018ae697569834a3433",
            "title": "Artificial Fingerprinting for Generative Models: Rooting Deepfake Attribution in Training Data",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2007.08457",
                "DBLP": "conf/iccv/YuSAF21",
                "DOI": "10.1109/ICCV48922.2021.01418",
                "CorpusId": 238419552
            },
            "abstract": "Photorealistic image generation has reached a new level of quality due to the breakthroughs of generative adversarial networks (GANs). Yet, the dark side of such deepfakes, the malicious use of generated media, raises concerns about visual misinformation. While existing research work on deepfake detection demonstrates high accuracy, it is subject to advances in generation techniques and adversarial iterations on detection countermeasure techniques. Thus, we seek a proactive and sustainable solution on deepfake detection, that is agnostic to the evolution of generative models, by introducing artificial fingerprints into the models.Our approach is simple and effective. We first embed artificial fingerprints into training data, then validate a surprising discovery on the transferability of such fingerprints from training data to generative models, which in turn appears in the generated deepfakes. Experiments show that our fingerprinting solution (1) holds for a variety of cutting-edge generative models, (2) leads to a negligible side effect on generation quality, (3) stays robust against image-level and model-level perturbations, (4) stays hard to be detected by adversaries, and (5) converts deepfake detection and attribution into trivial tasks and outperforms the recent state-of-the-art baselines. Our solution closes the responsibility loop between publishing pre-trained generative model inventions and their possible misuses, which makes it independent of the current arms race.",
            "referenceCount": 61,
            "citationCount": 104,
            "influentialCitationCount": 20,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2007.08457",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-07-16",
            "journal": {
                "name": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yu2020ArtificialFF,\n author = {Ning Yu and Vladislav Skripniuk and Sahar Abdelnabi and Mario Fritz},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},\n pages = {14428-14437},\n title = {Artificial Fingerprinting for Generative Models: Rooting Deepfake Attribution in Training Data},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7809846c6ab7437976a2ef495204d745aad77d05",
            "@type": "ScholarlyArticle",
            "paperId": "7809846c6ab7437976a2ef495204d745aad77d05",
            "corpusId": 210932569,
            "url": "https://www.semanticscholar.org/paper/7809846c6ab7437976a2ef495204d745aad77d05",
            "title": "Controlling generative models with continuous factors of variations",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2001.10238",
                "MAG": "2996582215",
                "DBLP": "journals/corr/abs-2001-10238",
                "CorpusId": 210932569
            },
            "abstract": "Recent deep generative models are able to provide photo-realistic images as well as visual or textual content embeddings useful to address various tasks of computer vision and natural language processing. Their usefulness is nevertheless often limited by the lack of control over the generative process or the poor understanding of the learned representation. To overcome these major issues, very recent work has shown the interest of studying the semantics of the latent space of generative models. In this paper, we propose to advance on the interpretability of the latent space of generative models by introducing a new method to find meaningful directions in the latent space of any generative model along which we can move to control precisely specific properties of the generated image like the position or scale of the object in the image. Our method does not require human annotations and is particularly well suited for the search of directions encoding simple transformations of the generated image, such as translation, zoom or color variations. We demonstrate the effectiveness of our method qualitatively and quantitatively, both for GANs and variational auto-encoders.",
            "referenceCount": 34,
            "citationCount": 112,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-01-28",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2001.10238"
            },
            "citationStyles": {
                "bibtex": "@Article{Plumerault2020ControllingGM,\n author = {Antoine Plumerault and H. Borgne and C. Hudelot},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Controlling generative models with continuous factors of variations},\n volume = {abs/2001.10238},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e0a7ab724afc4a598df7cfb39352b21f1b7f8c3e",
            "@type": "ScholarlyArticle",
            "paperId": "e0a7ab724afc4a598df7cfb39352b21f1b7f8c3e",
            "corpusId": 52813442,
            "url": "https://www.semanticscholar.org/paper/e0a7ab724afc4a598df7cfb39352b21f1b7f8c3e",
            "title": "Deep generative models of genetic variation capture the effects of mutations",
            "venue": "Nature Methods",
            "publicationVenue": {
                "id": "urn:research:099483df-e8f2-4bee-805d-8a69f07b6cbf",
                "name": "Nature Methods",
                "alternate_names": [
                    "Nat Method"
                ],
                "issn": "1548-7091",
                "url": "http://www.nature.com/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2890223884",
                "DOI": "10.1038/s41592-018-0138-4",
                "CorpusId": 52813442,
                "PubMed": "30250057"
            },
            "abstract": null,
            "referenceCount": 78,
            "citationCount": 361,
            "influentialCitationCount": 33,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc6693876?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-24",
            "journal": {
                "name": "Nature Methods",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Riesselman2018DeepGM,\n author = {Adam J. Riesselman and John Ingraham and D. Marks},\n booktitle = {Nature Methods},\n journal = {Nature Methods},\n pages = {816 - 822},\n title = {Deep generative models of genetic variation capture the effects of mutations},\n volume = {15},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5023544ad6fa49b35526a62f22207e43c4db870d",
            "@type": "ScholarlyArticle",
            "paperId": "5023544ad6fa49b35526a62f22207e43c4db870d",
            "corpusId": 52309169,
            "url": "https://www.semanticscholar.org/paper/5023544ad6fa49b35526a62f22207e43c4db870d",
            "title": "Constructing Unrestricted Adversarial Examples with Generative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1805.07894",
                "MAG": "2890591829",
                "DBLP": "conf/nips/SongSKE18",
                "CorpusId": 52309169
            },
            "abstract": "Adversarial examples are typically constructed by perturbing an existing data point within a small matrix norm, and current defense methods are focused on guarding against this type of attack. In this paper, we propose unrestricted adversarial examples, a new threat model where the attackers are not restricted to small norm-bounded perturbations. Different from perturbation-based attacks, we propose to synthesize unrestricted adversarial examples entirely from scratch using conditional generative models. Specifically, we first train an Auxiliary Classifier Generative Adversarial Network (AC-GAN) to model the class-conditional distribution over data samples. Then, conditioned on a desired class, we search over the AC-GAN latent space to find images that are likely under the generative model and are misclassified by a target classifier. We demonstrate through human evaluation that unrestricted adversarial examples generated this way are legitimate and belong to the desired class. Our empirical results on the MNIST, SVHN, and CelebA datasets show that unrestricted adversarial examples can bypass strong adversarial training and certified defense methods designed for traditional adversarial attacks.",
            "referenceCount": 54,
            "citationCount": 254,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-05-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Song2018ConstructingUA,\n author = {Yang Song and Rui Shu and Nate Kushman and Stefano Ermon},\n booktitle = {Neural Information Processing Systems},\n pages = {8322-8333},\n title = {Constructing Unrestricted Adversarial Examples with Generative Models},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c6f9e20f574c37e2ef12fa41a5729df8e0499f6f",
            "@type": "ScholarlyArticle",
            "paperId": "c6f9e20f574c37e2ef12fa41a5729df8e0499f6f",
            "corpusId": 219708904,
            "url": "https://www.semanticscholar.org/paper/c6f9e20f574c37e2ef12fa41a5729df8e0499f6f",
            "title": "Sample-Efficient Optimization in the Latent Space of Deep Generative Models via Weighted Retraining",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2006.09191",
                "MAG": "3035236454",
                "DBLP": "conf/nips/TrippDH20",
                "CorpusId": 219708904
            },
            "abstract": "Many important problems in science and engineering, such as drug design, involve optimizing an expensive black-box objective function over a complex, high-dimensional, and structured input space. Although machine learning techniques have shown promise in solving such problems, existing approaches substantially lack sample efficiency. We introduce an improved method for efficient black-box optimization, which performs the optimization in the low-dimensional, continuous latent manifold learned by a deep generative model. In contrast to previous approaches, we actively steer the generative model to maintain a latent manifold that is highly useful for efficiently optimizing the objective. We achieve this by periodically retraining the generative model on the data points queried along the optimization trajectory, as well as weighting those data points according to their objective function value. This weighted retraining can be easily implemented on top of existing methods, and is empirically shown to significantly improve their efficiency and performance on synthetic and real-world optimization problems.",
            "referenceCount": 81,
            "citationCount": 89,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-06-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2006.09191"
            },
            "citationStyles": {
                "bibtex": "@Article{Tripp2020SampleEfficientOI,\n author = {Austin Tripp and Erik A. Daxberger and Jos\u00e9 Miguel Hern\u00e1ndez-Lobato},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Sample-Efficient Optimization in the Latent Space of Deep Generative Models via Weighted Retraining},\n volume = {abs/2006.09191},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:54e0f75bb609fb9745d199891573efba3fcef3a3",
            "@type": "ScholarlyArticle",
            "paperId": "54e0f75bb609fb9745d199891573efba3fcef3a3",
            "corpusId": 219558334,
            "url": "https://www.semanticscholar.org/paper/54e0f75bb609fb9745d199891573efba3fcef3a3",
            "title": "Data augmentation for enhancing EEG-based emotion recognition with deep generative models",
            "venue": "Journal of Neural Engineering",
            "publicationVenue": {
                "id": "urn:research:aa06d038-4db2-4d34-a660-be35ff62d392",
                "name": "Journal of Neural Engineering",
                "alternate_names": [
                    "J Neural Eng"
                ],
                "issn": "1741-2552",
                "url": "http://iopscience.iop.org/1741-2552/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2006-05331",
                "MAG": "3083255269",
                "ArXiv": "2006.05331",
                "DOI": "10.1088/1741-2552/abb580",
                "CorpusId": 219558334,
                "PubMed": "33052888"
            },
            "abstract": "Objective. The data scarcity problem in emotion recognition from electroencephalography (EEG) leads to difficulty in building an affective model with high accuracy using machine learning algorithms or deep neural networks. Inspired by emerging deep generative models, we propose three methods for augmenting EEG training data to enhance the performance of emotion recognition models. Approach. Our proposed methods are based on two deep generative models, variational autoencoder (VAE) and generative adversarial network (GAN), and two data augmentation ways, full and partial usage strategies. For the full usage strategy, all of the generated data are augmented to the training dataset without judging the quality of the generated data, while for the partial usage, only high-quality data are selected and appended to the training dataset. These three methods are called conditional Wasserstein GAN (cWGAN), selective VAE (sVAE), and selective WGAN (sWGAN). Main results. To evaluate the effectiveness of these proposed methods, we perform a systematic experimental study on two public EEG datasets for emotion recognition, namely, SEED and DEAP. We first generate realistic-like EEG training data in two forms: power spectral density and differential entropy. Then, we augment the original training datasets with a different number of generated realistic-like EEG data. Finally, we train support vector machines and deep neural networks with shortcut layers to build affective models using the original and augmented training datasets. The experimental results demonstrate that our proposed data augmentation methods based on generative models outperform the existing data augmentation approaches such as conditional VAE, Gaussian noise, and rotational data augmentation. We also observe that the number of generated data should be less than 10 times of the original training dataset to achieve the best performance. Significance. The augmented training datasets produced by our proposed sWGAN method significantly enhance the performance of EEG-based emotion recognition models.",
            "referenceCount": 76,
            "citationCount": 71,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2006.05331",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science",
                "Physics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-06-04",
            "journal": {
                "name": "Journal of Neural Engineering",
                "volume": "17"
            },
            "citationStyles": {
                "bibtex": "@Article{Luo2020DataAF,\n author = {Yun Luo and Li-Zhen Zhu and Zi-Yu Wan and Bao-Liang Lu},\n booktitle = {Journal of Neural Engineering},\n journal = {Journal of Neural Engineering},\n title = {Data augmentation for enhancing EEG-based emotion recognition with deep generative models},\n volume = {17},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f800a355cb58c003bfd80ffe0a10c5df70013674",
            "@type": "ScholarlyArticle",
            "paperId": "f800a355cb58c003bfd80ffe0a10c5df70013674",
            "corpusId": 220514457,
            "url": "https://www.semanticscholar.org/paper/f800a355cb58c003bfd80ffe0a10c5df70013674",
            "title": "A Systematic Survey on Deep Generative Models for Graph Generation",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2007-06686",
                "ArXiv": "2007.06686",
                "MAG": "3042890712",
                "DOI": "10.1109/TPAMI.2022.3214832",
                "CorpusId": 220514457,
                "PubMed": "36251910"
            },
            "abstract": "Graphs are important data representations for describing objects and their relationships, which appear in a wide diversity of real-world scenarios. As one of a critical problem in this area, graph generation considers learning the distributions of given graphs and generating more novel graphs. Owing to their wide range of applications, generative models for graphs, which have a rich history, however, are traditionally hand-crafted and only capable of modeling a few statistical properties of graphs. Recent advances in deep generative models for graph generation is an important step towards improving the fidelity of generated graphs and paves the way for new kinds of applications. This article provides an extensive overview of the literature in the field of deep generative models for graph generation. First, the formal definition of deep generative models for the graph generation and the preliminary knowledge are provided. Second, taxonomies of deep generative models for both unconditional and conditional graph generation are proposed respectively; the existing works of each are compared and analyzed. After that, an overview of the evaluation metrics in this specific domain is provided. Finally, the applications that deep graph generation enables are summarized and five promising future research directions are highlighted.",
            "referenceCount": 168,
            "citationCount": 73,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://figshare.com/articles/preprint/A_Systematic_Survey_on_Deep_Generative_Models_for_Graph_Generation/12733037/1/files/24102788.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-07-13",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "45"
            },
            "citationStyles": {
                "bibtex": "@Article{Guo2020ASS,\n author = {Xiaojie Guo and Liang Zhao},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {5370-5390},\n title = {A Systematic Survey on Deep Generative Models for Graph Generation},\n volume = {45},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:021642baa03c61c687805364d10420d108bbbf8a",
            "@type": "ScholarlyArticle",
            "paperId": "021642baa03c61c687805364d10420d108bbbf8a",
            "corpusId": 235411073,
            "url": "https://www.semanticscholar.org/paper/021642baa03c61c687805364d10420d108bbbf8a",
            "title": "Beyond generative models: superfast traversal, optimization, novelty, exploration and discovery (STONED) algorithm for molecules using SELFIES\u2020",
            "venue": "Chemical Science",
            "publicationVenue": {
                "id": "urn:research:2a0713ba-a4af-4a0a-ae49-81b8edeca660",
                "name": "Chemical Science",
                "alternate_names": [
                    "Chem Sci",
                    "Chem sci",
                    "Chemical science"
                ],
                "issn": "2041-6520",
                "url": "http://www.rsc.org/chemicalscience"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3200406518",
                "PubMedCentral": "8153210",
                "DOI": "10.1039/d1sc00231g",
                "CorpusId": 235411073,
                "PubMed": "34123336"
            },
            "abstract": "Inverse design allows the generation of molecules with desirable physical quantities using property optimization. Deep generative models have recently been applied to tackle inverse design, as they possess the ability to optimize molecular properties directly through structure modification using gradients. While the ability to carry out direct property optimizations is promising, the use of generative deep learning models to solve practical problems requires large amounts of data and is very time-consuming. In this work, we propose STONED \u2013 a simple and efficient algorithm to perform interpolation and exploration in the chemical space, comparable to deep generative models. STONED bypasses the need for large amounts of data and training times by using string modifications in the SELFIES molecular representation. First, we achieve non-trivial performance on typical benchmarks for generative models without any training. Additionally, we demonstrate applications in high-throughput virtual screening for the design of drugs, photovoltaics, and the construction of chemical paths, allowing for both property and structure-based interpolation in the chemical space. Overall, we anticipate our results to be a stepping stone for developing more sophisticated inverse design models and benchmarking tools, ultimately helping generative models achieve wider adoption.",
            "referenceCount": 59,
            "citationCount": 76,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/60c753f00f50db6830397c37/original/beyond-generative-models-superfast-traversal-optimization-novelty-exploration-and-discovery-stoned-algorithm-for-molecules-using-selfies.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-12-16",
            "journal": {
                "name": "Chemical Science",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Nigam2020BeyondGM,\n author = {AkshatKumar Nigam and R. Pollice and M. Krenn and Gabriel dos Passos Gomes and Al\u00e1n Aspuru-Guzik},\n booktitle = {Chemical Science},\n journal = {Chemical Science},\n pages = {7079 - 7090},\n title = {Beyond generative models: superfast traversal, optimization, novelty, exploration and discovery (STONED) algorithm for molecules using SELFIES\u2020},\n volume = {12},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7d878fe31b9b57f75071586d83cdec2e8b81e039",
            "@type": "ScholarlyArticle",
            "paperId": "7d878fe31b9b57f75071586d83cdec2e8b81e039",
            "corpusId": 51892387,
            "url": "https://www.semanticscholar.org/paper/7d878fe31b9b57f75071586d83cdec2e8b81e039",
            "title": "Fr\u00e9chet ChemNet Distance: A Metric for Generative Models for Molecules in Drug Discovery",
            "venue": "Journal of Chemical Information and Modeling",
            "publicationVenue": {
                "id": "urn:research:3f16aef5-6b9f-4f87-baca-cbf8147e352f",
                "name": "Journal of Chemical Information and Modeling",
                "alternate_names": [
                    "J Chem Inf Model"
                ],
                "issn": "1549-9596",
                "url": "http://pubs.acs.org/jcim"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/jcisd/PreuerRUHK18",
                "MAG": "2887447356",
                "ArXiv": "1803.09518",
                "DOI": "10.1021/acs.jcim.8b00234",
                "CorpusId": 51892387,
                "PubMed": "30118593"
            },
            "abstract": "The new wave of successful generative models in machine learning has increased the interest in deep learning driven de novo drug design. However, method comparison is difficult because of various flaws of the currently employed evaluation metrics. We propose an evaluation metric for generative models called Fr\u00e9chet ChemNet distance (FCD). The advantage of the FCD over previous metrics is that it can detect whether generated molecules are diverse and have similar chemical and biological properties as real molecules.",
            "referenceCount": 29,
            "citationCount": 215,
            "influentialCitationCount": 28,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1803.09518",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Biology",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-03-26",
            "journal": {
                "name": "Journal of chemical information and modeling",
                "volume": "58 9"
            },
            "citationStyles": {
                "bibtex": "@Article{Preuer2018Fr\u00e9chetCD,\n author = {Kristina Preuer and Philipp Renz and Thomas Unterthiner and S. Hochreiter and G. Klambauer},\n booktitle = {Journal of Chemical Information and Modeling},\n journal = {Journal of chemical information and modeling},\n pages = {\n          1736-1741\n        },\n title = {Fr\u00e9chet ChemNet Distance: A Metric for Generative Models for Molecules in Drug Discovery},\n volume = {58 9},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:001aae8ffeaf66dc6d165e94079dbf22997cf223",
            "@type": "ScholarlyArticle",
            "paperId": "001aae8ffeaf66dc6d165e94079dbf22997cf223",
            "corpusId": 253253157,
            "url": "https://www.semanticscholar.org/paper/001aae8ffeaf66dc6d165e94079dbf22997cf223",
            "title": "Generative Models",
            "venue": "Introduction to Deep Learning for Healthcare",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.1007/978-3-030-82184-5_12",
                "CorpusId": 253253157
            },
            "abstract": null,
            "referenceCount": 58,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2021-12-10",
            "journal": {
                "name": "Introduction to Deep Learning for Healthcare",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Xiao2021GenerativeM,\n author = {Cao Xiao and Jimeng Sun},\n booktitle = {Introduction to Deep Learning for Healthcare},\n journal = {Introduction to Deep Learning for Healthcare},\n title = {Generative Models},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b87a3a9a6c31982eb56a8161f75ae79537ac8566",
            "@type": "ScholarlyArticle",
            "paperId": "b87a3a9a6c31982eb56a8161f75ae79537ac8566",
            "corpusId": 235165686,
            "url": "https://www.semanticscholar.org/paper/b87a3a9a6c31982eb56a8161f75ae79537ac8566",
            "title": "The Gaussian equivalence of generative models for learning with shallow neural networks",
            "venue": "Mathematical and Scientific Machine Learning",
            "publicationVenue": {
                "id": "urn:research:bed36c1a-3a44-42af-bd5a-4ffda6aa9fa2",
                "name": "Mathematical and Scientific Machine Learning",
                "alternate_names": [
                    "MSML",
                    "Math Sci Mach Learn"
                ],
                "issn": null,
                "url": "http://msml-conf.org/"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2006.14709",
                "DBLP": "conf/msml/GoldtLRKMZ21",
                "CorpusId": 235165686
            },
            "abstract": "Understanding the impact of data structure on the computational tractability of learning is a key challenge for the theory of neural networks. Many theoretical works do not explicitly model training data, or assume that inputs are drawn component-wise independently from some simple probability distribution. Here, we go beyond this simple paradigm by studying the performance of neural networks trained on data drawn from pre-trained generative models . This is possible due to a Gaussian equivalence stating that the key metrics of interest, such as the training and test errors, can be fully captured by an appropriately chosen Gaussian model. We provide three strands of rigorous, analytical and numerical evidence corroborating this equivalence. First, we establish rigorous conditions for the Gaussian equivalence to hold in the case of single-layer generative models, as well as deterministic rates for convergence in distribution. Second, we leverage this equivalence to derive a closed set of equations describing the generalisation performance of two widely studied machine learning problems: two-layer neural networks trained using one-pass stochastic gradient descent, and full-batch pre-learned features or kernel methods. Finally, we perform experiments demonstrating how our theory applies to deep, pre-trained generative models. These results open a viable path to the theoretical study of machine learning models with realistic data.",
            "referenceCount": 96,
            "citationCount": 59,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-06-25",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Goldt2020TheGE,\n author = {Sebastian Goldt and Bruno Loureiro and G. Reeves and F. Krzakala and M. M'ezard and Lenka Zdeborov'a},\n booktitle = {Mathematical and Scientific Machine Learning},\n pages = {426-471},\n title = {The Gaussian equivalence of generative models for learning with shallow neural networks},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a5feea57de51b8dcaf59fd7b53172a84a619cda4",
            "@type": "ScholarlyArticle",
            "paperId": "a5feea57de51b8dcaf59fd7b53172a84a619cda4",
            "corpusId": 192590099,
            "url": "https://www.semanticscholar.org/paper/a5feea57de51b8dcaf59fd7b53172a84a619cda4",
            "title": "Learning Generative Models of 3D Structures",
            "venue": "Eurographics",
            "publicationVenue": {
                "id": "urn:research:17cdf4bb-fc81-4200-8331-d0a9ebaad546",
                "name": "Eurographics",
                "alternate_names": [
                    "Annu Conf Eur Assoc Comput Graph",
                    "Annual Conference of the European Association for Computer Graphics"
                ],
                "issn": "0946-2767",
                "url": "https://www.eg.org/wp/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "conf/eurographics/ChaudhuriRXZ19",
                "MAG": "2947464908",
                "DOI": "10.1111/cgf.14020",
                "CorpusId": 192590099
            },
            "abstract": "3D models of objects and scenes are critical to many academic disciplines and industrial applications. Of particular interest is the emerging opportunity for 3D graphics to serve artificial intelligence: computer vision systems can benefit from synthetically\u2010generated training data rendered from virtual 3D scenes, and robots can be trained to navigate in and interact with real\u2010world environments by first acquiring skills in simulated ones. One of the most promising ways to achieve this is by learning and applying generative models of 3D content: computer programs that can synthesize new 3D shapes and scenes. To allow users to edit and manipulate the synthesized 3D content to achieve their goals, the generative model should also be structure\u2010aware: it should express 3D shapes and scenes using abstractions that allow manipulation of their high\u2010level structure. This state\u2010of\u2010the\u2010art report surveys historical work and recent progress on learning structure\u2010aware generative models of 3D shapes and scenes. We present fundamental representations of 3D shape and scene geometry and structures, describe prominent methodologies including probabilistic models, deep generative models, program synthesis, and neural networks for structured data, and cover many recent methods for structure\u2010aware synthesis of 3D shapes and indoor scenes.",
            "referenceCount": 176,
            "citationCount": 62,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2020-05-01",
            "journal": {
                "name": "Computer Graphics Forum",
                "volume": "39"
            },
            "citationStyles": {
                "bibtex": "@Article{Chaudhuri2020LearningGM,\n author = {S. Chaudhuri and Daniel Ritchie and Kai Xu and Haotong Zhang},\n booktitle = {Eurographics},\n journal = {Computer Graphics Forum},\n title = {Learning Generative Models of 3D Structures},\n volume = {39},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8509cc4e5421db6fdfd30528bcc15c651be0c0fa",
            "@type": "ScholarlyArticle",
            "paperId": "8509cc4e5421db6fdfd30528bcc15c651be0c0fa",
            "corpusId": 224930744,
            "url": "https://www.semanticscholar.org/paper/8509cc4e5421db6fdfd30528bcc15c651be0c0fa",
            "title": "A comprehensive survey and analysis of generative models in machine learning",
            "venue": "Computer Science Review",
            "publicationVenue": {
                "id": "urn:research:3aa92b7f-af7a-4ebd-8925-1152710bfbc7",
                "name": "Computer Science Review",
                "alternate_names": [
                    "Comput Sci Rev"
                ],
                "issn": "1574-0137",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/710138/description#description"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3046095786",
                "DBLP": "journals/csr/GMGPR20",
                "DOI": "10.1016/j.cosrev.2020.100285",
                "CorpusId": 224930744
            },
            "abstract": null,
            "referenceCount": 88,
            "citationCount": 137,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-11-01",
            "journal": {
                "name": "Comput. Sci. Rev.",
                "volume": "38"
            },
            "citationStyles": {
                "bibtex": "@Article{Harshvardhan2020ACS,\n author = {GM Harshvardhan and Mahendra Kumar Gourisaria and M. Pandey and S. Rautaray},\n booktitle = {Computer Science Review},\n journal = {Comput. Sci. Rev.},\n pages = {100285},\n title = {A comprehensive survey and analysis of generative models in machine learning},\n volume = {38},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:557ed446503524c111d3c0d661672001d559b3c2",
            "@type": "ScholarlyArticle",
            "paperId": "557ed446503524c111d3c0d661672001d559b3c2",
            "corpusId": 221186992,
            "url": "https://www.semanticscholar.org/paper/557ed446503524c111d3c0d661672001d559b3c2",
            "title": "Generative chemistry: drug discovery with deep learning generative models",
            "venue": "Journal of Molecular Modeling",
            "publicationVenue": {
                "id": "urn:research:f5941d4c-ae95-4e56-b615-0f621af56ae0",
                "name": "Journal of Molecular Modeling",
                "alternate_names": [
                    "J Mol Model"
                ],
                "issn": "1430-8622",
                "url": "https://link.springer.com/journal/894"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2008-09000",
                "ArXiv": "2008.09000",
                "MAG": "3050693196",
                "DOI": "10.1007/s00894-021-04674-8",
                "CorpusId": 221186992,
                "PubMed": "33543405"
            },
            "abstract": null,
            "referenceCount": 156,
            "citationCount": 54,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s00894-021-04674-8.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Biology",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2020-08-20",
            "journal": {
                "name": "Journal of Molecular Modeling",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Bian2020GenerativeCD,\n author = {Yuemin Bian and X. Xie},\n booktitle = {Journal of Molecular Modeling},\n journal = {Journal of Molecular Modeling},\n title = {Generative chemistry: drug discovery with deep learning generative models},\n volume = {27},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5a64123f1564401dabf5db45d6f1c27d7b0c6c6c",
            "@type": "ScholarlyArticle",
            "paperId": "5a64123f1564401dabf5db45d6f1c27d7b0c6c6c",
            "corpusId": 229212743,
            "url": "https://www.semanticscholar.org/paper/5a64123f1564401dabf5db45d6f1c27d7b0c6c6c",
            "title": "Responsible Disclosure of Generative Models Using Scalable Fingerprinting",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2012.08726",
                "MAG": "3112815795",
                "DBLP": "conf/iclr/YuSCDF22",
                "CorpusId": 229212743
            },
            "abstract": "Over the past five years, deep generative models have achieved a qualitative new level of performance. Generated data has become difficult, if not impossible, to be distinguished from real data. While there are plenty of use cases that benefit from this technology, there are also strong concerns on how this new technology can be misused to spoof sensors, generate deep fakes, and enable misinformation at scale. Unfortunately, current deep fake detection methods are not sustainable, as the gap between real and fake continues to close. In contrast, our work enables a responsible disclosure of such state-of-the-art generative models, that allows researchers and companies to fingerprint their models, so that the generated samples containing a fingerprint can be accurately detected and attributed to a source. Our technique achieves this by an efficient and scalable ad-hoc generation of a large population of models with distinct fingerprints. Our recommended operation point uses a 128-bit fingerprint which in principle results in more than $10^{36}$ identifiable models. Experimental results show that our method fulfills key properties of a fingerprinting mechanism and achieves effectiveness in deep fake detection and attribution.",
            "referenceCount": 92,
            "citationCount": 46,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-12-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2012.08726"
            },
            "citationStyles": {
                "bibtex": "@Article{Yu2020ResponsibleDO,\n author = {Ning Yu and Vladislav Skripniuk and Dingfan Chen and Larry S. Davis and Mario Fritz},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Responsible Disclosure of Generative Models Using Scalable Fingerprinting},\n volume = {abs/2012.08726},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904",
            "@type": "ScholarlyArticle",
            "paperId": "4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904",
            "corpusId": 245334784,
            "url": "https://www.semanticscholar.org/paper/4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904",
            "title": "Few-shot Learning with Multilingual Generative Language Models",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2112.10668",
                "ACL": "2022.emnlp-main.616",
                "DBLP": "conf/emnlp/LinMAWCSOGBDPSK22",
                "DOI": "10.18653/v1/2022.emnlp-main.616",
                "CorpusId": 245334784
            },
            "abstract": "Large-scale generative language models such as GPT-3 are competitive few-shot learners. While these models are known to be able to jointly represent many different languages, their training data is dominated by English, potentially limiting their cross-lingual generalization. In this work, we train multilingual generative language models on a corpus covering a diverse set of languages, and study their few- and zero-shot learning capabilities in a wide range of tasks. Our largest model with 7.5 billion parameters sets new state of the art in few-shot learning in more than 20 representative languages, outperforming GPT-3 of comparable size in multilingual commonsense reasoning (with +7.4% absolute accuracy improvement in 0-shot settings and +9.4% in 4-shot settings) and natural language inference (+5.4% in each of 0-shot and 4-shot settings). On the FLORES-101 machine translation benchmark, our model outperforms GPT-3 on 171 out of 182 directions with 32 training examples, while surpassing the official supervised baseline in 45 directions. We conduct an in-depth analysis of different multilingual prompting approaches, showing in particular that strong few-shot learning performance across languages can be achieved via cross-lingual transfer through both templates and demonstration examples.",
            "referenceCount": 73,
            "citationCount": 109,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://aclanthology.org/2022.emnlp-main.616.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-12-20",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lin2021FewshotLW,\n author = {Xi Victoria Lin and Todor Mihaylov and Mikel Artetxe and Tianlu Wang and Shuohui Chen and Daniel Simig and Myle Ott and Naman Goyal and Shruti Bhosale and Jingfei Du and Ramakanth Pasunuru and Sam Shleifer and Punit Singh Koura and Vishrav Chaudhary and Brian O'Horo and Jeff Wang and Luke Zettlemoyer and Zornitsa Kozareva and Mona T. Diab and Ves Stoyanov and Xian Li},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {9019-9052},\n title = {Few-shot Learning with Multilingual Generative Language Models},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8c2359bb7ae03cefd2077f4209bff1e117e928d3",
            "@type": "ScholarlyArticle",
            "paperId": "8c2359bb7ae03cefd2077f4209bff1e117e928d3",
            "corpusId": 215745042,
            "url": "https://www.semanticscholar.org/paper/8c2359bb7ae03cefd2077f4209bff1e117e928d3",
            "title": "A Non-Parametric Test to Detect Data-Copying in Generative Models",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3015304056",
                "DBLP": "journals/corr/abs-2004-05675",
                "ArXiv": "2004.05675",
                "CorpusId": 215745042
            },
            "abstract": "Detecting overfitting in generative models is an important challenge in machine learning. In this work, we formalize a form of overfitting that we call {\\em{data-copying}} -- where the generative model memorizes and outputs training samples or small variations thereof. We provide a three sample non-parametric test for detecting data-copying that uses the training set, a separate sample from the target distribution, and a generated sample from the model, and study the performance of our test on several canonical models and datasets. \nFor code \\& examples, visit this https URL",
            "referenceCount": 23,
            "citationCount": 39,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-04-12",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2004.05675"
            },
            "citationStyles": {
                "bibtex": "@Article{Meehan2020ANT,\n author = {Casey Meehan and Kamalika Chaudhuri and S. Dasgupta},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A Non-Parametric Test to Detect Data-Copying in Generative Models},\n volume = {abs/2004.05675},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7306c2579f49d3ac3a5377d9b594788711cb3f57",
            "@type": "ScholarlyArticle",
            "paperId": "7306c2579f49d3ac3a5377d9b594788711cb3f57",
            "corpusId": 208076137,
            "url": "https://www.semanticscholar.org/paper/7306c2579f49d3ac3a5377d9b594788711cb3f57",
            "title": "Generative Models for Effective ML on Private, Decentralized Datasets",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2986692543",
                "DBLP": "conf/iclr/AugensteinMRRKC20",
                "ArXiv": "1911.06679",
                "CorpusId": 208076137
            },
            "abstract": "To improve real-world applications of machine learning, experienced modelers develop intuition about their datasets, their models, and how the two interact. Manual inspection of raw data - of representative samples, of outliers, of misclassifications - is an essential tool in a) identifying and fixing problems in the data, b) generating new modeling hypotheses, and c) assigning or refining human-provided labels. However, manual data inspection is problematic for privacy sensitive datasets, such as those representing the behavior of real-world individuals. Furthermore, manual data inspection is impossible in the increasingly important setting of federated learning, where raw examples are stored at the edge and the modeler may only access aggregated outputs such as metrics or model parameters. This paper demonstrates that generative models - trained using federated methods and with formal differential privacy guarantees - can be used effectively to debug many commonly occurring data issues even when the data cannot be directly inspected. We explore these methods in applications to text with differentially private federated RNNs and to images using a novel algorithm for differentially private federated GANs.",
            "referenceCount": 58,
            "citationCount": 140,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-11-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1911.06679"
            },
            "citationStyles": {
                "bibtex": "@Article{Augenstein2019GenerativeMF,\n author = {S. Augenstein and H. B. McMahan and Daniel Ramage and Swaroop Indra Ramaswamy and P. Kairouz and Mingqing Chen and Rajiv Mathews and B. A. Y. Arcas},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Generative Models for Effective ML on Private, Decentralized Datasets},\n volume = {abs/1911.06679},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1f5d4eeb0582941c5ccf5f0e219b301758528b08",
            "@type": "ScholarlyArticle",
            "paperId": "1f5d4eeb0582941c5ccf5f0e219b301758528b08",
            "corpusId": 159040324,
            "url": "https://www.semanticscholar.org/paper/1f5d4eeb0582941c5ccf5f0e219b301758528b08",
            "title": "Deep Generative Design: Integration of Topology Optimization and Generative Models",
            "venue": "Journal of Mechanical Design",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3105168176",
                "DOI": "10.1115/1.4044229",
                "CorpusId": 159040324
            },
            "abstract": "\n Deep learning has recently been applied to various research areas of design optimization. This study presents the need and effectiveness of adopting deep learning for generative design (or design exploration) research area. This work proposes an artificial intelligent (AI)-based deep generative design framework that is capable of generating numerous design options which are not only aesthetic but also optimized for engineering performance. The proposed framework integrates topology optimization and generative models (e.g., generative adversarial networks (GANs)) in an iterative manner to explore new design options, thus generating a large number of designs starting from limited previous design data. In addition, anomaly detection can evaluate the novelty of generated designs, thus helping designers choose among design options. The 2D wheel design problem is applied as a case study for validation of the proposed framework. The framework manifests better aesthetics, diversity, and robustness of generated designs than previous generative design methods.",
            "referenceCount": 52,
            "citationCount": 199,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1903.01548",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-03-01",
            "journal": {
                "name": "Journal of Mechanical Design",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Oh2019DeepGD,\n author = {Sangeun Oh and Yongsu Jung and Seongsin Kim and Ikjin Lee and Namwoo Kang},\n booktitle = {Journal of Mechanical Design},\n journal = {Journal of Mechanical Design},\n title = {Deep Generative Design: Integration of Topology Optimization and Generative Models},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:132b9d7908b527ef2b95670884482902163f345e",
            "@type": "ScholarlyArticle",
            "paperId": "132b9d7908b527ef2b95670884482902163f345e",
            "corpusId": 221912267,
            "url": "https://www.semanticscholar.org/paper/132b9d7908b527ef2b95670884482902163f345e",
            "title": "Enhancing scientific discoveries in molecular biology with deep generative models",
            "venue": "Molecular Systems Biology",
            "publicationVenue": {
                "id": "urn:research:3bff011d-f05b-46ec-b123-beabcc2a1ba5",
                "name": "Molecular Systems Biology",
                "alternate_names": [
                    "Mol Syst Biology"
                ],
                "issn": "1744-4292",
                "url": "http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1744-4292"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3088354555",
                "PubMedCentral": "7517326",
                "DOI": "10.15252/msb.20199198",
                "CorpusId": 221912267,
                "PubMed": "32975352"
            },
            "abstract": "Generative models provide a well\u2010established statistical framework for evaluating uncertainty and deriving conclusions from large data sets especially in the presence of noise, sparsity, and bias. Initially developed for computer vision and natural language processing, these models have been shown to effectively summarize the complexity that underlies many types of data and enable a range of applications including supervised learning tasks, such as assigning labels to images; unsupervised learning tasks, such as dimensionality reduction; and out\u2010of\u2010sample generation, such as de novo image synthesis. With this early success, the power of generative models is now being increasingly leveraged in molecular biology, with applications ranging from designing new molecules with properties of interest to identifying deleterious mutations in our genomes and to dissecting transcriptional variability between single cells. In this review, we provide a brief overview of the technical notions behind generative models and their implementation with deep learning techniques. We then describe several different ways in which these models can be utilized in practice, using several recent applications in molecular biology as examples.",
            "referenceCount": 174,
            "citationCount": 44,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2020-09-01",
            "journal": {
                "name": "Molecular Systems Biology",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Lopez2020EnhancingSD,\n author = {Romain Lopez and Adam Gayoso and N. Yosef},\n booktitle = {Molecular Systems Biology},\n journal = {Molecular Systems Biology},\n title = {Enhancing scientific discoveries in molecular biology with deep generative models},\n volume = {16},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:698555ce1a2fe59e2f09d5be0336ab6eed70866f",
            "@type": "ScholarlyArticle",
            "paperId": "698555ce1a2fe59e2f09d5be0336ab6eed70866f",
            "corpusId": 167217647,
            "url": "https://www.semanticscholar.org/paper/698555ce1a2fe59e2f09d5be0336ab6eed70866f",
            "title": "Invertible generative models for inverse problems: mitigating representation error and dataset bias",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1905-11672",
                "ArXiv": "1905.11672",
                "MAG": "2947708079",
                "CorpusId": 167217647
            },
            "abstract": "Trained generative models have shown remarkable performance as priors for inverse problems in imaging -- for example, Generative Adversarial Network priors permit recovery of test images from 5-10x fewer measurements than sparsity priors. Unfortunately, these models may be unable to represent any particular image because of architectural choices, mode collapse, and bias in the training dataset. In this paper, we demonstrate that invertible neural networks, which have zero representation error by design, can be effective natural signal priors at inverse problems such as denoising, compressive sensing, and inpainting. Given a trained generative model, we study the empirical risk formulation of the desired inverse problem under a regularization that promotes high likelihood images, either directly by penalization or algorithmically by initialization. For compressive sensing, invertible priors can yield higher accuracy than sparsity priors across almost all undersampling ratios, and due to their lack of representation error, invertible priors can yield better reconstructions than GAN priors for images that have rare features of variation within the biased training set, including out-of-distribution natural images. We additionally compare performance for compressive sensing to unlearned methods, such as the deep decoder, and we establish theoretical bounds on expected recovery error in the case of a linear invertible model.",
            "referenceCount": 36,
            "citationCount": 120,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-05-28",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1905.11672"
            },
            "citationStyles": {
                "bibtex": "@Article{Asim2019InvertibleGM,\n author = {Muhammad Asim and Ali Ahmed and Paul Hand},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Invertible generative models for inverse problems: mitigating representation error and dataset bias},\n volume = {abs/1905.11672},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a50b65a5927343aabc8bca035befbe252d92c67a",
            "@type": "ScholarlyArticle",
            "paperId": "a50b65a5927343aabc8bca035befbe252d92c67a",
            "corpusId": 199546273,
            "url": "https://www.semanticscholar.org/paper/a50b65a5927343aabc8bca035befbe252d92c67a",
            "title": "Monte Carlo and Reconstruction Membership Inference Attacks against Generative Models",
            "venue": "Proceedings on Privacy Enhancing Technologies",
            "publicationVenue": {
                "id": "urn:research:d5dc4224-e4c3-43c9-918a-bd6326650b5b",
                "name": "Proceedings on Privacy Enhancing Technologies",
                "alternate_names": [
                    "Proc Priv Enhancing Technol"
                ],
                "issn": "2299-0984",
                "url": "https://www.degruyter.com/view/j/popets"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2965527189",
                "DBLP": "journals/corr/abs-1906-03006",
                "ArXiv": "1906.03006",
                "DOI": "10.2478/popets-2019-0067",
                "CorpusId": 199546273
            },
            "abstract": "Abstract We present two information leakage attacks that outperform previous work on membership inference against generative models. The first attack allows membership inference without assumptions on the type of the generative model. Contrary to previous evaluation metrics for generative models, like Kernel Density Estimation, it only considers samples of the model which are close to training data records. The second attack specifically targets Variational Autoencoders, achieving high membership inference accuracy. Furthermore, previous work mostly considers membership inference adversaries who perform single record membership inference. We argue for considering regulatory actors who perform set membership inference to identify the use of specific datasets for training. The attacks are evaluated on two generative model architectures, Generative Adversarial Networks (GANs) and Variational Autoen-coders (VAEs), trained on standard image datasets. Our results show that the two attacks yield success rates superior to previous work on most data sets while at the same time having only very mild assumptions. We envision the two attacks in combination with the membership inference attack type formalization as especially useful. For example, to enforce data privacy standards and automatically assessing model quality in machine learning as a service setups. In practice, our work motivates the use of GANs since they prove less vulnerable against information leakage attacks while producing detailed samples.",
            "referenceCount": 33,
            "citationCount": 122,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://content.sciendo.com/downloadpdf/journals/popets/2019/4/article-p232.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-07",
            "journal": {
                "name": "Proceedings on Privacy Enhancing Technologies",
                "volume": "2019"
            },
            "citationStyles": {
                "bibtex": "@Article{Hilprecht2019MonteCA,\n author = {Benjamin Hilprecht and Martin H\u00e4rterich and Daniel Bernau},\n booktitle = {Proceedings on Privacy Enhancing Technologies},\n journal = {Proceedings on Privacy Enhancing Technologies},\n pages = {232 - 249},\n title = {Monte Carlo and Reconstruction Membership Inference Attacks against Generative Models},\n volume = {2019},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b959d5655a3b2f92c2c1a8a7896fecafafea979d",
            "@type": "ScholarlyArticle",
            "paperId": "b959d5655a3b2f92c2c1a8a7896fecafafea979d",
            "corpusId": 3481010,
            "url": "https://www.semanticscholar.org/paper/b959d5655a3b2f92c2c1a8a7896fecafafea979d",
            "title": "AmbientGAN: Generative models from lossy measurements",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/iclr/BoraPD18",
                "MAG": "2785532149",
                "CorpusId": 3481010
            },
            "abstract": "Generative models provide a way to model structure in complex distributions and have been shown to be useful for many tasks of practical interest. However, cur-rent techniques for training generative models require access to fully-observed samples. In many settings, it is expensive or even impossible to obtain fully-observed samples, but economical to obtain partial, noisy observations. We consider the task of learning an implicit generative model given only lossy measurements of samples from the distribution of interest. We show that the true underlying distribution can be provably recovered even in the presence of per-sample information loss for a class of measurement models. Based on this, we propose a new method of training Generative Adversarial Networks (GANs) which we call AmbientGAN. On three benchmark datasets, and for various measurement models, we demonstrate substantial qualitative and quantitative improvements. Generative models trained with our method can obtain 2 - 4 x higher inception scores than the baselines.",
            "referenceCount": 33,
            "citationCount": 158,
            "influentialCitationCount": 27,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Bora2018AmbientGANGM,\n author = {Ashish Bora and Eric Price and A. Dimakis},\n booktitle = {International Conference on Learning Representations},\n title = {AmbientGAN: Generative models from lossy measurements},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a1bc7d90564c342beb75cedf36fd921de89d94ad",
            "@type": "ScholarlyArticle",
            "paperId": "a1bc7d90564c342beb75cedf36fd921de89d94ad",
            "corpusId": 4879286,
            "url": "https://www.semanticscholar.org/paper/a1bc7d90564c342beb75cedf36fd921de89d94ad",
            "title": "Learning Generative Models with Sinkhorn Divergences",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963506485",
                "DBLP": "conf/aistats/GenevayPC18",
                "ArXiv": "1706.00292",
                "CorpusId": 4879286
            },
            "abstract": "The ability to compare two degenerate probability distributions (i.e. two probability distributions supported on two distinct low-dimensional manifolds living in a much higher-dimensional space) is a crucial problem arising in the estimation of generative models for high-dimensional observations such as those arising in computer vision or natural language. It is known that optimal transport metrics can represent a cure for this problem, since they were specifically designed as an alternative to information divergences to handle such problematic scenarios. Unfortunately, training generative machines using OT raises formidable computational and statistical challenges, because of (i) the computational burden of evaluating OT losses, (ii) the instability and lack of smoothness of these losses, (iii) the difficulty to estimate robustly these losses and their gradients in high dimension. This paper presents the first tractable computational method to train large scale generative models using an optimal transport loss, and tackles these three issues by relying on two key ideas: (a) entropic smoothing, which turns the original OT loss into one that can be computed using Sinkhorn fixed point iterations; (b) algorithmic (automatic) differentiation of these iterations. These two approximations result in a robust and differentiable approximation of the OT loss with streamlined GPU execution. Entropic smoothing generates a family of losses interpolating between Wasserstein (OT) and Maximum Mean Discrepancy (MMD), thus allowing to find a sweet spot leveraging the geometry of OT and the favorable high-dimensional sample complexity of MMD which comes with unbiased gradient estimates. The resulting computational architecture complements nicely standard deep network generative models by a stack of extra layers implementing the loss function.",
            "referenceCount": 38,
            "citationCount": 517,
            "influentialCitationCount": 48,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-06-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Genevay2017LearningGM,\n author = {Aude Genevay and G. Peyr\u00e9 and Marco Cuturi},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n pages = {1608-1617},\n title = {Learning Generative Models with Sinkhorn Divergences},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:298b2930ec3ad4c04ce0eeb3b489580cb850ec3d",
            "@type": "ScholarlyArticle",
            "paperId": "298b2930ec3ad4c04ce0eeb3b489580cb850ec3d",
            "corpusId": 227336378,
            "url": "https://www.semanticscholar.org/paper/298b2930ec3ad4c04ce0eeb3b489580cb850ec3d",
            "title": "The neural coding framework for learning generative models",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2012.03405",
                "PubMedCentral": "9018730",
                "DBLP": "journals/corr/abs-2012-03405",
                "MAG": "3110733896",
                "DOI": "10.1038/s41467-022-29632-7",
                "CorpusId": 227336378,
                "PubMed": "35440589"
            },
            "abstract": null,
            "referenceCount": 118,
            "citationCount": 36,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41467-022-29632-7.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-12-07",
            "journal": {
                "name": "Nature Communications",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Ororbia2020TheNC,\n author = {Alexander Ororbia and Daniel Kifer},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {The neural coding framework for learning generative models},\n volume = {13},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:57d71b30f2ff68bde4a0c50322bb93a5c3358ee0",
            "@type": "ScholarlyArticle",
            "paperId": "57d71b30f2ff68bde4a0c50322bb93a5c3358ee0",
            "corpusId": 234789948,
            "url": "https://www.semanticscholar.org/paper/57d71b30f2ff68bde4a0c50322bb93a5c3358ee0",
            "title": "DeepCAD: A Deep Generative Network for Computer-Aided Design Models",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2105.09492",
                "DBLP": "conf/iccv/WuXZ21",
                "DOI": "10.1109/ICCV48922.2021.00670",
                "CorpusId": 234789948
            },
            "abstract": "Deep generative models of 3D shapes have received a great deal of research interest. Yet, almost all of them generate discrete shape representations, such as voxels, point clouds, and polygon meshes. We present the first 3D generative model for a drastically different shape representation\u2014 describing a shape as a sequence of computer-aided design (CAD) operations. Unlike meshes and point clouds, CAD models encode the user creation process of 3D shapes, widely used in numerous industrial and engineering design tasks. However, the sequential and irregular structure of CAD operations poses significant challenges for existing 3D generative models. Drawing an analogy between CAD operations and natural language, we propose a CAD generative network based on the Transformer. We demonstrate the performance of our model for both shape autoencoding and random shape generation. To train our network, we create a new CAD dataset consisting of 178,238 models and their CAD construction sequences. We have made this dataset publicly available to promote future research on this topic.",
            "referenceCount": 50,
            "citationCount": 66,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2105.09492",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-05-20",
            "journal": {
                "name": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2021DeepCADAD,\n author = {Rundi Wu and Chang Xiao and Changxi Zheng},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},\n pages = {6752-6762},\n title = {DeepCAD: A Deep Generative Network for Computer-Aided Design Models},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:12ff508431c627fa01aaaf5779d68b6336dec5d3",
            "@type": "ScholarlyArticle",
            "paperId": "12ff508431c627fa01aaaf5779d68b6336dec5d3",
            "corpusId": 222142784,
            "url": "https://www.semanticscholar.org/paper/12ff508431c627fa01aaaf5779d68b6336dec5d3",
            "title": "Winning Lottery Tickets in Deep Generative Models",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2010.02350",
                "MAG": "3092574632",
                "DBLP": "conf/aaai/KalibhatBF21",
                "DOI": "10.1609/aaai.v35i9.16980",
                "CorpusId": 222142784
            },
            "abstract": "The lottery ticket hypothesis suggests that sparse, sub-networks of a given neural network, if initialized properly, can be trained to reach comparable or even better performance to that of the original network. Prior works in lottery tickets have primarily focused on the supervised learning setup, with several papers proposing effective ways of finding winning tickets in classification problems. In this paper, we confirm the existence of winning tickets in deep generative models such as GANs and VAEs. We show that the popular iterative magnitude pruning approach (with late resetting) can be used with generative losses to find the winning tickets. This approach effectively yields tickets with sparsity up to 99% for AutoEncoders, 93% for VAEs and 89% for GANs on CIFAR and Celeb-A datasets. We also demonstrate the transferability of winning tickets across different generative models (GANs and VAEs) sharing the same architecture, suggesting that winning tickets have inductive biases that could help train a wide range of deep generative models. Furthermore, we show the practical benefits of lottery tickets in generative models by detecting tickets at very early stages in training called early-bird tickets. Through early-bird tickets, we can achieve up to 88% reduction in floating-point operations (FLOPs) and 54% reduction in training time, making it possible to train large-scale generative models over tight resource constraints. These results out-perform existing early pruning methods like SNIP (Lee, Ajanthan, and Torr 2019) and GraSP(Wang, Zhang, and Grosse 2020). Our findings shed light towards existence of proper network initializations that could improve convergence and stability of generative models.",
            "referenceCount": 40,
            "citationCount": 31,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/16980/16787",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-10-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2010.02350"
            },
            "citationStyles": {
                "bibtex": "@Article{Kalibhat2020WinningLT,\n author = {N. Kalibhat and Y. Balaji and S. Feizi},\n booktitle = {AAAI Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {Winning Lottery Tickets in Deep Generative Models},\n volume = {abs/2010.02350},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8c383637d0059b06b245bdb2592a3181035dda36",
            "@type": "ScholarlyArticle",
            "paperId": "8c383637d0059b06b245bdb2592a3181035dda36",
            "corpusId": 229507589,
            "url": "https://www.semanticscholar.org/paper/8c383637d0059b06b245bdb2592a3181035dda36",
            "title": "Comparative Study of Deep Generative Models on Chemical Space Coverage",
            "venue": "Journal of Chemical Information and Modeling",
            "publicationVenue": {
                "id": "urn:research:3f16aef5-6b9f-4f87-baca-cbf8147e352f",
                "name": "Journal of Chemical Information and Modeling",
                "alternate_names": [
                    "J Chem Inf Model"
                ],
                "issn": "1549-9596",
                "url": "http://pubs.acs.org/jcim"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3108004614",
                "DBLP": "journals/jcisd/ZhangMEC21",
                "DOI": "10.26434/chemrxiv.13234289.v1",
                "CorpusId": 229507589,
                "PubMed": "34015916"
            },
            "abstract": "In recent years, deep molecular generative models have emerged as promising methods for de novo molecular design. Thanks to the rapid advance of deep learning techniques, deep learning architectures such as recurrent neural networks, variational autoencoders, and adversarial networks have been successfully employed for constructing generative models. Recently, quite a few metrics have been proposed to evaluate these deep generative models. However, many of these metrics cannot evaluate the chemical space coverage of sampled molecules. This work presents a novel and complementary metric for evaluating deep molecular generative models. The metric is based on the chemical space coverage of a reference dataset-GDB-13. The performance of seven different molecular generative models was compared by calculating what fraction of the structures, ring systems, and functional groups could be reproduced from the largely unseen reference set when using only a small fraction of GDB-13 for training. The results show that the performance of the generative models studied varies significantly using the benchmark metrics introduced herein, such that the generalization capabilities of the generative models can be clearly differentiated. In addition, the coverages of GDB-13 ring systems and functional groups were compared between the models. Our study provides a useful new metric that can be used for evaluating and comparing generative models.",
            "referenceCount": 49,
            "citationCount": 32,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-11-16",
            "journal": {
                "name": "Journal of chemical information and modeling",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2020ComparativeSO,\n author = {J. Zhang and Roc\u00edo Mercado and O. Engkvist and Hongming Chen},\n booktitle = {Journal of Chemical Information and Modeling},\n journal = {Journal of chemical information and modeling},\n title = {Comparative Study of Deep Generative Models on Chemical Space Coverage},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5daf6e4b51387d2a57ca0b4cefdf459aa57893ac",
            "@type": "ScholarlyArticle",
            "paperId": "5daf6e4b51387d2a57ca0b4cefdf459aa57893ac",
            "corpusId": 52211986,
            "url": "https://www.semanticscholar.org/paper/5daf6e4b51387d2a57ca0b4cefdf459aa57893ac",
            "title": "LOGAN: Membership Inference Attacks Against Generative Models",
            "venue": "Proceedings on Privacy Enhancing Technologies",
            "publicationVenue": {
                "id": "urn:research:d5dc4224-e4c3-43c9-918a-bd6326650b5b",
                "name": "Proceedings on Privacy Enhancing Technologies",
                "alternate_names": [
                    "Proc Priv Enhancing Technol"
                ],
                "issn": "2299-0984",
                "url": "https://www.degruyter.com/view/j/popets"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/popets/HayesMDC19",
                "MAG": "2952492946",
                "DOI": "10.2478/popets-2019-0008",
                "CorpusId": 52211986
            },
            "abstract": "Abstract Generative models estimate the underlying distribution of a dataset to generate realistic samples according to that distribution. In this paper, we present the first membership inference attacks against generative models: given a data point, the adversary determines whether or not it was used to train the model. Our attacks leverage Generative Adversarial Networks (GANs), which combine a discriminative and a generative model, to detect overfitting and recognize inputs that were part of training datasets, using the discriminator\u2019s capacity to learn statistical differences in distributions. We present attacks based on both white-box and black-box access to the target model, against several state-of-the-art generative models, over datasets of complex representations of faces (LFW), objects (CIFAR-10), and medical images (Diabetic Retinopathy). We also discuss the sensitivity of the attacks to different training parameters, and their robustness against mitigation strategies, finding that defenses are either ineffective or lead to significantly worse performances of the generative models in terms of training stability and/or sample quality.",
            "referenceCount": 73,
            "citationCount": 386,
            "influentialCitationCount": 44,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://content.sciendo.com/downloadpdf/journals/popets/2019/1/article-p133.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-05-22",
            "journal": {
                "name": "Proceedings on Privacy Enhancing Technologies",
                "volume": "2019"
            },
            "citationStyles": {
                "bibtex": "@Article{Hayes2017LOGANMI,\n author = {Jamie Hayes and Luca Melis and G. Danezis and Emiliano De Cristofaro},\n booktitle = {Proceedings on Privacy Enhancing Technologies},\n journal = {Proceedings on Privacy Enhancing Technologies},\n pages = {133 - 152},\n title = {LOGAN: Membership Inference Attacks Against Generative Models},\n volume = {2019},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d4254d9a938d238182ae55eabd79367404d6ea2b",
            "@type": "ScholarlyArticle",
            "paperId": "d4254d9a938d238182ae55eabd79367404d6ea2b",
            "corpusId": 209318960,
            "url": "https://www.semanticscholar.org/paper/d4254d9a938d238182ae55eabd79367404d6ea2b",
            "title": "Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2980402966",
                "CorpusId": 209318960
            },
            "abstract": "Recent work has shown that deep generative models can assign higher likelihood to out-of-distribution data sets than to their training data (Nalisnick et al., 2019; Choi et al., 2019). We posit that this phenomenon is caused by a mismatch between the model's typical set and its areas of high probability density. In-distribution inputs should reside in the former but not necessarily in the latter, as previous work has presumed. To determine whether or not inputs reside in the typical set, we propose a statistically principled, easy-to-implement test using the empirical distribution of model likelihoods. The test is model agnostic and widely applicable, only requiring that the likelihood can be computed or closely approximated. We report experiments showing that our procedure can successfully detect the out-of-distribution sets in several of the challenging cases reported by Nalisnick et al. (2019).",
            "referenceCount": 65,
            "citationCount": 100,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-09-25",
            "journal": {
                "name": "arXiv: Machine Learning",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Nalisnick2019DetectingOI,\n author = {Eric T. Nalisnick and Akihiro Matsukawa and Y. Teh and Balaji Lakshminarayanan},\n journal = {arXiv: Machine Learning},\n title = {Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8a3bf4d403a39ed33f0fa8cf78dc906d6130595f",
            "@type": "ScholarlyArticle",
            "paperId": "8a3bf4d403a39ed33f0fa8cf78dc906d6130595f",
            "corpusId": 24005817,
            "url": "https://www.semanticscholar.org/paper/8a3bf4d403a39ed33f0fa8cf78dc906d6130595f",
            "title": "Semantic Image Inpainting with Deep Generative Models",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/cvpr/Yeh0LSHD17",
                "MAG": "2963917315",
                "ArXiv": "1607.07539",
                "DOI": "10.1109/CVPR.2017.728",
                "CorpusId": 24005817
            },
            "abstract": "Semantic image inpainting is a challenging task where large missing regions have to be filled based on the available visual data. Existing methods which extract information from only a single image generally produce unsatisfactory results due to the lack of high level context. In this paper, we propose a novel method for semantic image inpainting, which generates the missing content by conditioning on the available data. Given a trained generative model, we search for the closest encoding of the corrupted image in the latent image manifold using our context and prior losses. This encoding is then passed through the generative model to infer the missing content. In our method, inference is possible irrespective of how the missing content is structured, while the state-of-the-art learning based method requires specific information about the holes in the training phase. Experiments on three datasets show that our method successfully predicts information in large missing regions and achieves pixel-level photorealism, significantly outperforming the state-of-the-art methods.",
            "referenceCount": 40,
            "citationCount": 1094,
            "influentialCitationCount": 80,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1607.07539",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-07-26",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yeh2016SemanticII,\n author = {Raymond A. Yeh and Chen Chen and Teck-Yian Lim and A. Schwing and M. Hasegawa-Johnson and M. Do},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {6882-6890},\n title = {Semantic Image Inpainting with Deep Generative Models},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:39e0c341351f8f4a39ac890b96217c7f4bde5369",
            "@type": "ScholarlyArticle",
            "paperId": "39e0c341351f8f4a39ac890b96217c7f4bde5369",
            "corpusId": 2187805,
            "url": "https://www.semanticscholar.org/paper/39e0c341351f8f4a39ac890b96217c7f4bde5369",
            "title": "A note on the evaluation of generative models",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2099057450",
                "DBLP": "journals/corr/TheisOB15",
                "ArXiv": "1511.01844",
                "CorpusId": 2187805
            },
            "abstract": "Probabilistic generative models can be used for compression, denoising, inpainting, texture synthesis, semi-supervised learning, unsupervised feature learning, and other tasks. Given this wide range of applications, it is not surprising that a lot of heterogeneity exists in the way these models are formulated, trained, and evaluated. As a consequence, direct comparison between models is often difficult. This article reviews mostly known but often underappreciated properties relating to the evaluation and interpretation of generative models with a focus on image models. In particular, we show that three of the currently most commonly used criteria---average log-likelihood, Parzen window estimates, and visual fidelity of samples---are largely independent of each other when the data is high-dimensional. Good performance with respect to one criterion therefore need not imply good performance with respect to the other criteria. Our results show that extrapolation from one criterion to another is not warranted and generative models need to be evaluated directly with respect to the application(s) they were intended for. In addition, we provide examples demonstrating that Parzen window estimates should generally be avoided.",
            "referenceCount": 39,
            "citationCount": 991,
            "influentialCitationCount": 65,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2015-11-05",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1511.01844"
            },
            "citationStyles": {
                "bibtex": "@Article{Theis2015ANO,\n author = {Lucas Theis and A\u00e4ron van den Oord and M. Bethge},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {A note on the evaluation of generative models},\n volume = {abs/1511.01844},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2d20253a2c87c8c6a30441051a373d6ce269fb83",
            "@type": "ScholarlyArticle",
            "paperId": "2d20253a2c87c8c6a30441051a373d6ce269fb83",
            "corpusId": 3694842,
            "url": "https://www.semanticscholar.org/paper/2d20253a2c87c8c6a30441051a373d6ce269fb83",
            "title": "Sliced Wasserstein Generative Models",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/cvpr/WuHALTPG19",
                "MAG": "2795520001",
                "ArXiv": "1904.05408",
                "DOI": "10.1109/CVPR.2019.00383",
                "CorpusId": 3694842
            },
            "abstract": "In generative modeling, the Wasserstein distance (WD) has emerged as a useful metric to measure the discrepancy between generated and real data distributions. Unfortunately, it is challenging to approximate the WD of high-dimensional distributions. In contrast, the sliced Wasserstein distance (SWD) factorizes high-dimensional distributions into their multiple one-dimensional marginal distributions and is thus easier to approximate. In this paper, we introduce novel approximations of the primal and dual SWD. Instead of using a large number of random projections, as it is done by conventional SWD approximation methods, we propose to approximate SWDs with a small number of parameterized orthogonal projections in an end-to-end deep learning fashion. As concrete applications of our SWD approximations, we design two types of differentiable SWD blocks to equip modern generative frameworks---Auto-Encoders (AE) and Generative Adversarial Networks (GAN). In the experiments, we not only show the superiority of the proposed generative models on standard image synthesis benchmarks, but also demonstrate the state-of-the-art performance on challenging high resolution image and video generation in an unsupervised manner.",
            "referenceCount": 47,
            "citationCount": 100,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-10",
            "journal": {
                "name": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2019SlicedWG,\n author = {Jiqing Wu and Zhiwu Huang and Dinesh Acharya and Wen Li and Janine Thoma and D. Paudel and L. Gool},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {3708-3717},\n title = {Sliced Wasserstein Generative Models},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:aedf3077e8b2f4b82f3284e5e0fa994d6d9d0ef8",
            "@type": "ScholarlyArticle",
            "paperId": "aedf3077e8b2f4b82f3284e5e0fa994d6d9d0ef8",
            "corpusId": 195345228,
            "url": "https://www.semanticscholar.org/paper/aedf3077e8b2f4b82f3284e5e0fa994d6d9d0ef8",
            "title": "Bias Correction of Learned Generative Models using Likelihood-Free Importance Weighting",
            "venue": "DGS@ICLR",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2965850471",
                "DBLP": "journals/corr/abs-1906-09531",
                "ArXiv": "1906.09531",
                "CorpusId": 195345228
            },
            "abstract": "A learned generative model often produces biased statistics relative to the underlying data distribution. A standard technique to correct this bias is importance sampling, where samples from the model are weighted by the likelihood ratio under model and true distributions. When the likelihood ratio is unknown, it can be estimated by training a probabilistic classifier to distinguish samples from the two distributions. We employ this likelihood-free importance weighting method to correct for the bias in generative models. We find that this technique consistently improves standard goodness-of-fit metrics for evaluating the sample quality of state-of-the-art deep generative models, suggesting reduced bias. Finally, we demonstrate its utility on representative applications in a) data augmentation for classification using generative adversarial networks, and b) model-based policy evaluation using off-policy data.",
            "referenceCount": 67,
            "citationCount": 101,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1906.09531"
            },
            "citationStyles": {
                "bibtex": "@Article{Grover2019BiasCO,\n author = {Aditya Grover and Jiaming Song and Alekh Agarwal and Kenneth Tran and Ashish Kapoor and E. Horvitz and Stefano Ermon},\n booktitle = {DGS@ICLR},\n journal = {ArXiv},\n title = {Bias Correction of Learned Generative Models using Likelihood-Free Importance Weighting},\n volume = {abs/1906.09531},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d053f815a32fce3da5a7df08b9f5507a83f2749c",
            "@type": "ScholarlyArticle",
            "paperId": "d053f815a32fce3da5a7df08b9f5507a83f2749c",
            "corpusId": 51857766,
            "url": "https://www.semanticscholar.org/paper/d053f815a32fce3da5a7df08b9f5507a83f2749c",
            "title": "Deep Generative Models",
            "venue": "Computer Vision",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3105986095",
                "DOI": "10.1007/978-3-030-03243-2_865-1",
                "CorpusId": 51857766
            },
            "abstract": null,
            "referenceCount": 55,
            "citationCount": 35,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Computer Vision",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Siddharth2020DeepGM,\n author = {N. Siddharth and Brooks Paige and Alban Desmaison and Frank Wood},\n booktitle = {Computer Vision},\n journal = {Computer Vision},\n title = {Deep Generative Models},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dbdeac01daf69c3725032c42be04f42c17ea439d",
            "@type": "ScholarlyArticle",
            "paperId": "dbdeac01daf69c3725032c42be04f42c17ea439d",
            "corpusId": 165163969,
            "url": "https://www.semanticscholar.org/paper/dbdeac01daf69c3725032c42be04f42c17ea439d",
            "title": "HYPE: A Benchmark for Human eYe Perceptual Evaluation of Generative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2945475205",
                "DBLP": "conf/nips/ZhouGKNFB19",
                "ArXiv": "1904.01121",
                "CorpusId": 165163969
            },
            "abstract": "Generative models often use human evaluations to measure the perceived quality of their outputs. Automated metrics are noisy indirect proxies, because they rely on heuristics or pretrained embeddings. However, up until now, direct human evaluation strategies have been ad-hoc, neither standardized nor validated. Our work establishes a gold standard human benchmark for generative realism. We construct Human eYe Perceptual Evaluation (HYPE) a human benchmark that is (1) grounded in psychophysics research in perception, (2) reliable across different sets of randomly sampled outputs from a model, (3) able to produce separable model performances, and (4) efficient in cost and time. We introduce two variants: one that measures visual perception under adaptive time constraints to determine the threshold at which a model's outputs appear real (e.g. 250ms), and the other a less expensive variant that measures human error rate on fake and real images sans time constraints. We test HYPE across six state-of-the-art generative adversarial networks and two sampling techniques on conditional and unconditional image generation using four datasets: CelebA, FFHQ, CIFAR-10, and ImageNet. We find that HYPE can track model improvements across training epochs, and we confirm via bootstrap sampling that HYPE rankings are consistent and replicable.",
            "referenceCount": 62,
            "citationCount": 87,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-04-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhou2019HYPEAB,\n author = {Sharon Zhou and Mitchell L. Gordon and Ranjay Krishna and Austin Narcomey and Li Fei-Fei and Michael S. Bernstein},\n booktitle = {Neural Information Processing Systems},\n pages = {3444-3456},\n title = {HYPE: A Benchmark for Human eYe Perceptual Evaluation of Generative Models},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b1e35d23ecdbeec4c7cea862424cbda7b0f8043f",
            "@type": "ScholarlyArticle",
            "paperId": "b1e35d23ecdbeec4c7cea862424cbda7b0f8043f",
            "corpusId": 139104868,
            "url": "https://www.semanticscholar.org/paper/b1e35d23ecdbeec4c7cea862424cbda7b0f8043f",
            "title": "Flow-based generative models for Markov chain Monte Carlo in lattice field theory",
            "venue": "Physical Review D",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1904.12072",
                "MAG": "2969814790",
                "DBLP": "journals/corr/abs-1904-12072",
                "DOI": "10.1103/PhysRevD.100.034515",
                "CorpusId": 139104868
            },
            "abstract": "A Markov chain update scheme using a machine-learned flow-based generative model is proposed for Monte\u00a0Carlo sampling in lattice field theories. The generative model may be optimized (trained) to produce samples from a distribution approximating the desired Boltzmann distribution determined by the lattice action of the theory being studied. Training the model systematically improves autocorrelation times in the Markov chain, even in regions of parameter space where standard Markov chain Monte\u00a0Carlo algorithms exhibit critical slowing down in producing decorrelated updates. Moreover, the model may be trained without existing samples from the desired distribution. The algorithm is compared with HMC and local Metropolis sampling for \u03d54 theory in two dimensions.",
            "referenceCount": 49,
            "citationCount": 158,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://link.aps.org/pdf/10.1103/PhysRevD.100.034515",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-04-26",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1904.12072"
            },
            "citationStyles": {
                "bibtex": "@Article{Albergo2019FlowbasedGM,\n author = {M. S. Albergo and G. Kanwar and P. Shanahan},\n booktitle = {Physical Review D},\n journal = {ArXiv},\n title = {Flow-based generative models for Markov chain Monte Carlo in lattice field theory},\n volume = {abs/1904.12072},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c5f83b7848b5a90a9071123300207fb7372f6be8",
            "@type": "ScholarlyArticle",
            "paperId": "c5f83b7848b5a90a9071123300207fb7372f6be8",
            "corpusId": 153312722,
            "url": "https://www.semanticscholar.org/paper/c5f83b7848b5a90a9071123300207fb7372f6be8",
            "title": "Learning Generative Models across Incomparable Spaces",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2950099875",
                "DBLP": "conf/icml/BunneA0J19",
                "ArXiv": "1905.05461",
                "DOI": "10.3929/ETHZ-B-000382654",
                "CorpusId": 153312722
            },
            "abstract": "Generative Adversarial Networks have shown remarkable success in learning a distribution that faithfully recovers a reference distribution in its entirety. However, in some cases, we may want to only learn some aspects (e.g., cluster or manifold structure), while modifying others (e.g., style, orientation or dimension). In this work, we propose an approach to learn generative models across such incomparable spaces, and demonstrate how to steer the learned distribution towards target properties. A key component of our model is the Gromov-Wasserstein distance, a notion of discrepancy that compares distributions relationally rather than absolutely. While this framework subsumes current generative models in identically reproducing distributions, its inherent flexibility allows application to tasks in manifold learning, relational learning and cross-domain learning.",
            "referenceCount": 57,
            "citationCount": 95,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-05-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bunne2019LearningGM,\n author = {Charlotte Bunne and David Alvarez-Melis and A. Krause and S. Jegelka},\n booktitle = {International Conference on Machine Learning},\n pages = {851-861},\n title = {Learning Generative Models across Incomparable Spaces},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:aab7e4d55cebf531028a4b7e8d977c0bda732ab6",
            "@type": "ScholarlyArticle",
            "paperId": "aab7e4d55cebf531028a4b7e8d977c0bda732ab6",
            "corpusId": 53602754,
            "url": "https://www.semanticscholar.org/paper/aab7e4d55cebf531028a4b7e8d977c0bda732ab6",
            "title": "Reconstructing quantum states with generative models",
            "venue": "Nature Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:6457124b-39bf-4d02-bff4-73752ff21562",
                "name": "Nature Machine Intelligence",
                "alternate_names": [
                    "Nat Mach Intell"
                ],
                "issn": "2522-5839",
                "url": "https://www.nature.com/natmachintell/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2898121159",
                "DBLP": "journals/natmi/CarrasquillaTMA19",
                "ArXiv": "1810.10584",
                "DOI": "10.1038/s42256-019-0028-1",
                "CorpusId": 53602754
            },
            "abstract": null,
            "referenceCount": 64,
            "citationCount": 223,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1810.10584",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-10-24",
            "journal": {
                "name": "Nature Machine Intelligence",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Carrasquilla2018ReconstructingQS,\n author = {J. Carrasquilla and G. Torlai and R. Melko and L. Aolita},\n booktitle = {Nature Machine Intelligence},\n journal = {Nature Machine Intelligence},\n pages = {155 - 161},\n title = {Reconstructing quantum states with generative models},\n volume = {1},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1be50e0653e42ef41132e6bb64bbfb6e64592259",
            "@type": "ScholarlyArticle",
            "paperId": "1be50e0653e42ef41132e6bb64bbfb6e64592259",
            "corpusId": 232128835,
            "url": "https://www.semanticscholar.org/paper/1be50e0653e42ef41132e6bb64bbfb6e64592259",
            "title": "Protein design and variant prediction using autoregressive generative models",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2019,
            "externalIds": {
                "PubMedCentral": "8065141",
                "DOI": "10.1038/s41467-021-22732-w",
                "CorpusId": 232128835,
                "PubMed": "33893299"
            },
            "abstract": null,
            "referenceCount": 110,
            "citationCount": 197,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41467-021-22732-w.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-09-05",
            "journal": {
                "name": "Nature Communications",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Shin2019ProteinDA,\n author = {Jung-Eun Shin and Adam J. Riesselman and A. Kollasch and Conor McMahon and Elana Simon and C. Sander and A. Manglik and A. Kruse and D. Marks},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {Protein design and variant prediction using autoregressive generative models},\n volume = {12},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:729b18d8d91035f4bb84bf2e61b0517824e5d31b",
            "@type": "ScholarlyArticle",
            "paperId": "729b18d8d91035f4bb84bf2e61b0517824e5d31b",
            "corpusId": 1972072,
            "url": "https://www.semanticscholar.org/paper/729b18d8d91035f4bb84bf2e61b0517824e5d31b",
            "title": "Auxiliary Deep Generative Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2280377497",
                "DBLP": "conf/icml/MaaloeSSW16",
                "ArXiv": "1602.05473",
                "CorpusId": 1972072
            },
            "abstract": "Deep generative models parameterized by neural networks have recently achieved state-of-the-art performance in unsupervised and semi-supervised learning. We extend deep generative models with auxiliary variables which improves the variational approximation. The auxiliary variables leave the generative model unchanged but make the variational distribution more expressive. Inspired by the structure of the auxiliary variable we also propose a model with two stochastic layers and skip connections. Our findings suggest that more expressive and properly specified deep generative models converge faster with better results. We show state-of-the-art performance within semi-supervised learning on MNIST, SVHN and NORB datasets.",
            "referenceCount": 27,
            "citationCount": 430,
            "influentialCitationCount": 54,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-02-17",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Maal\u00f8e2016AuxiliaryDG,\n author = {Lars Maal\u00f8e and C. S\u00f8nderby and S\u00f8ren Kaae S\u00f8nderby and O. Winther},\n booktitle = {International Conference on Machine Learning},\n pages = {1445-1453},\n title = {Auxiliary Deep Generative Models},\n year = {2016}\n}\n"
            }
        }
    }
]