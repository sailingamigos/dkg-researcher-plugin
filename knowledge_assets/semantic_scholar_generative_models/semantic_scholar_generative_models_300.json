[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1fa6ba95b8383fad600bcbd6033c6eec73296381",
            "@type": "ScholarlyArticle",
            "paperId": "1fa6ba95b8383fad600bcbd6033c6eec73296381",
            "corpusId": 2002865,
            "url": "https://www.semanticscholar.org/paper/1fa6ba95b8383fad600bcbd6033c6eec73296381",
            "title": "MidiNet: A Convolutional Generative Adversarial Network for Symbolic-Domain Music Generation",
            "venue": "International Society for Music Information Retrieval Conference",
            "publicationVenue": {
                "id": "urn:research:cfc287e4-4c04-4848-ab16-633b33a61a09",
                "name": "International Society for Music Information Retrieval Conference",
                "alternate_names": [
                    "International Symposium/Conference on Music Information Retrieval",
                    "ISMIR",
                    "Int Soc Music Inf Retr Conf",
                    "Int Symp Music Inf Retr"
                ],
                "issn": null,
                "url": "http://www.ismir.net/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2746068898",
                "DBLP": "journals/corr/YangCY17",
                "ArXiv": "1703.10847",
                "CorpusId": 2002865
            },
            "abstract": "Most existing neural network models for music generation use recurrent neural networks. However, the recent WaveNet model proposed by DeepMind shows that convolutional neural networks (CNNs) can also generate realistic musical waveforms in the audio domain. Following this light, we investigate using CNNs for generating melody (a series of MIDI notes) one bar after another in the symbolic domain. In addition to the generator, we use a discriminator to learn the distributions of melodies, making it a generative adversarial network (GAN). Moreover, we propose a novel conditional mechanism to exploit available prior knowledge, so that the model can generate melodies either from scratch, by following a chord sequence, or by conditioning on the melody of previous bars (e.g. a priming melody), among other possibilities. The resulting model, named MidiNet, can be expanded to generate music with multiple MIDI channels (i.e. tracks). We conduct a user study to compare the melody of eight-bar long generated by MidiNet and by Google's MelodyRNN models, each time using the same priming melody. Result shows that MidiNet performs comparably with MelodyRNN models in being realistic and pleasant to listen to, yet MidiNet's melodies are reported to be much more interesting.",
            "referenceCount": 40,
            "citationCount": 391,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.10847"
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2017MidiNetAC,\n author = {Li-Chia Yang and Szu-Yu Chou and Yi-Hsuan Yang},\n booktitle = {International Society for Music Information Retrieval Conference},\n journal = {ArXiv},\n title = {MidiNet: A Convolutional Generative Adversarial Network for Symbolic-Domain Music Generation},\n volume = {abs/1703.10847},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:024d30897e0a2b036bc122163a954b7f1a1d0679",
            "@type": "ScholarlyArticle",
            "paperId": "024d30897e0a2b036bc122163a954b7f1a1d0679",
            "corpusId": 13002849,
            "url": "https://www.semanticscholar.org/paper/024d30897e0a2b036bc122163a954b7f1a1d0679",
            "title": "Mode Regularized Generative Adversarial Networks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2585630030",
                "ArXiv": "1612.02136",
                "DBLP": "journals/corr/CheLJBL16",
                "CorpusId": 13002849
            },
            "abstract": "Although Generative Adversarial Networks achieve state-of-the-art results on a variety of generative tasks, they are regarded as highly unstable and prone to miss modes. We argue that these bad behaviors of GANs are due to the very particular functional shape of the trained discriminators in high dimensional spaces, which can easily make training stuck or push probability mass in the wrong direction, towards that of higher concentration than that of the data generating distribution. We introduce several ways of regularizing the objective, which can dramatically stabilize the training of GAN models. We also show that our regularizers can help the fair distribution of probability mass across the modes of the data generating distribution, during the early phases of training and thus providing a unified solution to the missing modes problem.",
            "referenceCount": 28,
            "citationCount": 494,
            "influentialCitationCount": 51,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1612.02136"
            },
            "citationStyles": {
                "bibtex": "@Article{Che2016ModeRG,\n author = {Tong Che and Yanran Li and Athul Paul Jacob and Yoshua Bengio and Wenjie Li},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Mode Regularized Generative Adversarial Networks},\n volume = {abs/1612.02136},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0e6f668c06e8af5e98a2a280cadc6eab023998ae",
            "@type": "ScholarlyArticle",
            "paperId": "0e6f668c06e8af5e98a2a280cadc6eab023998ae",
            "corpusId": 211259450,
            "url": "https://www.semanticscholar.org/paper/0e6f668c06e8af5e98a2a280cadc6eab023998ae",
            "title": "VFlow: More Expressive Generative Flows with Variational Data Augmentation",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3007345776",
                "ArXiv": "2002.09741",
                "DBLP": "journals/corr/abs-2002-09741",
                "CorpusId": 211259450
            },
            "abstract": "Generative flows are promising tractable models for density modeling that define probabilistic distributions with invertible transformations. However, tractability imposes architectural constraints on generative flows, making them less expressive than other types of generative models. In this work, we study a previously overlooked constraint that all the intermediate representations must have the same dimensionality with the original data due to invertibility, limiting the width of the network. We tackle this constraint by augmenting the data with some extra dimensions and jointly learning a generative flow for augmented data as well as the distribution of augmented dimensions under a variational inference framework. Our approach, VFlow, is a generalization of generative flows and therefore always performs better. Combining with existing generative flows, VFlow achieves a new state-of-the-art 2.98 bits per dimension on the CIFAR-10 dataset and is more compact than previous models to reach similar modeling quality.",
            "referenceCount": 38,
            "citationCount": 51,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-02-22",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2002.09741"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2020VFlowME,\n author = {Jianfei Chen and Cheng Lu and Biqi Chenli and Jun Zhu and Tian Tian},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {VFlow: More Expressive Generative Flows with Variational Data Augmentation},\n volume = {abs/2002.09741},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e2ef0f1a528cd0f415be8265a04466a6d3f74e6c",
            "@type": "ScholarlyArticle",
            "paperId": "e2ef0f1a528cd0f415be8265a04466a6d3f74e6c",
            "corpusId": 2019311,
            "url": "https://www.semanticscholar.org/paper/e2ef0f1a528cd0f415be8265a04466a6d3f74e6c",
            "title": "Optimizing the Latent Space of Generative Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963376432",
                "DBLP": "journals/corr/BojanowskiJLS17",
                "ArXiv": "1707.05776",
                "CorpusId": 2019311
            },
            "abstract": "Generative Adversarial Networks (GANs) have achieved remarkable results in the task of generating realistic natural images. In most successful applications, GAN models share two common aspects: solving a challenging saddle point optimization problem, interpreted as an adversarial game between a generator and a discriminator functions; and parameterizing the generator and the discriminator as deep convolutional neural networks. The goal of this paper is to disentangle the contribution of these two factors to the success of GANs. In particular, we introduce Generative Latent Optimization (GLO), a framework to train deep convolutional generators using simple reconstruction losses. Throughout a variety of experiments, we show that GLO enjoys many of the desirable properties of GANs: synthesizing visually-appealing samples, interpolating meaningfully between samples, and performing linear arithmetic with noise vectors; all of this without the adversarial optimization scheme.",
            "referenceCount": 60,
            "citationCount": 361,
            "influentialCitationCount": 38,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-07-18",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bojanowski2017OptimizingTL,\n author = {Piotr Bojanowski and Armand Joulin and David Lopez-Paz and Arthur Szlam},\n booktitle = {International Conference on Machine Learning},\n pages = {599-608},\n title = {Optimizing the Latent Space of Generative Networks},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2c7c5249474702e886a7bfea36d12047cde8ae6c",
            "@type": "ScholarlyArticle",
            "paperId": "2c7c5249474702e886a7bfea36d12047cde8ae6c",
            "corpusId": 31097208,
            "url": "https://www.semanticscholar.org/paper/2c7c5249474702e886a7bfea36d12047cde8ae6c",
            "title": "Generative programming - methods, tools and applications",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2000,
            "externalIds": {
                "DBLP": "books/daglib/0010411",
                "MAG": "1500250067",
                "CorpusId": 31097208
            },
            "abstract": "1. What Is This Book About? From Handcrafting to Automated Assembly Lines. Generative Programming. Benefits and Applicability. I. ANALYSIS AND DESIGN METHODS AND TECHNIQUES. 2. Domain Engineering. Why Is This Chapter Worth Reading? What Is Domain Engineering? Domain Analysis. Domain Design and Domain Implementation. Application Engineering. Product-Line Practices. Key Domain Engineering Concepts. Domain. Domain Scope and Scoping. Relationships between Domains. Features and Feature Models. Method Tailoring and Specialization. Survey of Domain Analysis and Domain Engineering Methods. Feature-Oriented Domain Analysis (FODA). Organization Domain Modeling (ODM). Draco. Capture. Domain Analysis and Reuse Environment (DARE). Domain-Specific Software Architecture (DSSA) Approach. Algebraic Approach. Other Approaches. Domain Engineering and Related Approaches. Historical Notes. Summary. 3. Domain Engineering and Object-Oriented Analysis and Design. Why Is This Chapter Worth Reading? OO Technology and Reuse. Solution Space. Problem Space. Relationship between Domain Engineering and Object-Oriented Analysis and Design (OOA/D) Methods. Aspects of Integrating Domain Engineering and OOA/D Methods. Horizontal versus Vertical Methods. Selected Methods. Rational Unified Process. 00ram. Reuse-Driven Software Engineering Business (RSEB). FeatuRSEB. Domain Engineering Method for Reusable Algorithmic Libraries (DEMRAL). 4. Feature Modeling. Why Is This Chapter Worth Reading? Features Revisited. Feature Modeling. Feature Models. Feature Diagrams. Other Infon-Nation Associated with Feature Diagrams in a Feature Model. Assigning Priorities to Variable Features. Availability Sites, Binding Sites, and Binding Modes. Relationship between Feature Diagrams and Other Modeling Notations and Implementation Techniques. Single Inheritance. Multiple Inheritance. Parameterized Inheritance. Static Parameterization. Dynamic Parameterization. Implementing Constraints. Tool Support for Feature Models. Frequently Asked Questions about Feature Diagrams. Feature Modeling Process. How to Find Features. Role of Variability in Modeling. 5. The Process of Generative Programming. Why Is This Chapter Worth Reading? Generative Domain Models. Main Development Steps in Generative Programming. Adapting Domain Engineering for Generative Programming. Domain-Specific Languages. DEMRAL: Example of a Domain Engineering Method for Generative Programming. Outline of DEMRAL. Domain Analysis. Domain Definition. Domain Modeling. Domain Design. Scope Domain Model for Implementation. Identify Packages. Develop Target Architectures and Identify the Implementation Components. Identify User DSLs. Identify Interactions between DSLs. Specify DSLs and Their Translation. Configuration DSLs. Expression DSLs. Domain Implementation. II. IMPLEMENTATION TECHNOLOGIES. 6. Generic Programming. Why Is This Chapter Worth Reading? What Is Generic Programming? Generic versus Generative Programming. Generic Parameters. Parametric versus Subtype Polymorphism. Genericity in Java. Bounded versus Unbounded Polymorphism. A Fresh Look at Polymorphism. Parameterized Components. Parameterized Programming. Types, Interfaces, and Specifications. Adapters. Vertical and Horizontal Parameters. Module Expressions. C++ Standard Template Library. Iterators. Freestanding Functions versus Member Functions. Generic Methodology. Historical Notes. 7. Component-Oriented Template-Based C++ Programming Techniques. Why Is This Chapter Worth Reading? Types of System Configuration. C++ Support for Dynamic Configuration. C++ Support for Static Configuration. Static Typing. Static Binding. Inlining. Templates. Parameterized Inheritance. typedefs. Member Types. Nested Classes. Prohibiting Certain Template Instantiations. Static versus Dynamic Parameterization. Wrappers Based on Parameterized Inheritance. Template Method Based on Parameterized Inheritance. Parameterizing Binding Mode. Consistent Parameterization of Multiple Components. Static Interactions between Components. Components with Influence. Components under Influence. Structured Configurations. Recursive Components. Intelligent Configuration. 8. Aspect-Oriented Decomposition and Composition. Why Is This Chapter Worth Reading? What Is Aspect-Oriented Programming? Aspect-Oriented Decomposition Approaches. Subject-Oriented Programming. Composition Filters. Demeter / Adaptive Programming. Aspect-Oriented Decomposition and Domain Engineering. How Aspects Arise. Composition Mechanisms. Requirements on Composition Mechanisms. Example: Synchronizing a Bounded Buffer. \"Tangled\" Synchronized Stack. Separating Synchronization Using Design Patterns. Separating Synchronization Using SOP. Some Problems with Design Patterns and Some Solutions. Implementing Noninvasive, Dynamic Composition in Smalltalk. Kinds of Crosscutting. How to Express Aspects in Programming Languages. Separating Synchronization Using AspectJ Cool. Implementing Dynamic Cool in Smalltalk. Implementation Technologies for Aspect-Oriented Programming. Technologies for Implementing Aspect-Specific Abstractions. Technologies for Implementing Weaving. AOP and Specialized Language Extensions. AOP and Active Libraries. Final Remarks. 9. Generators. Why Is This Chapter Worth Reading? What Are Generators? Transformational Model of Software Development. Technologies for Building Generators. Compositional versus Transformational Generators. Kinds of Transformations. Compiler Transformations. Source-to-Source Transformations. Transformation Systems. Scheduling Transformations. Existing Transformation Systems and Their Applications. Selected Approaches to Generation. Draco. GenVoca. Approaches Based on Algebraic Specifications. 10. Static Metaprogramming in C++. Why Is This Chapter Worth Reading? What Is Metaprogramming? A Quick Tour of Metaprogramming. Static Metaprogramming. C++ as a Two-Level Language. Functional Flavor of the Static Level. Class Templates as Functions. Integers and Types as Data. Symbolic Names Instead of Variables. Constant Initialization and typedef-Statements Instead of Assignment. Template Recursion Instead of Loops. Conditional Operator and Template Specialization as Conditional Constructs. Template Metaprogramming. Template Metafunctions. Metafinctions as Arguments and Return Values of Other Metafinctions. Representing Metainformation. Member Traits. Traits Classes. Traits Templates. Example: Using Template Metafunctions and Traits Templates to Implement Type Promotions. Compile-Time Lists and Trees as Nested Templates. Compile-Time Control Structures. Explicit Selection Constructs. Template Recursion as a Looping Construct. Explicit Looping Constructs. Code Generation. Simple Code Selection. Composing Templates. Generators Based on Expression Templates. Recursive Code Expansion. Explicit Loops for Generating Code. Example: Using Static Execute Loops to Test Metafunctions. Partial Evaluation in C++. Workarounds for Partial Template Specialization. Problems of Template Metaprogramming. Historical Notes. 11. Intentional Programming. Why Is This Chapter Worth Reading? What Is Intentional Programming? Technology behind IP. System Architecture. Representing Programs in IP: The Source Graph. Source Graph + Methods = Active Source. Working with the IP Programming Environment. Editing. Further Capabilities of the IP Editor. Extending the IP System with New Intentions. Advanced Topics. Questions, Methods, and a Frameworklike Organization. Source-Pattem-Based Polymorphism. Methods as Visitors. Asking Questions Synchronously and Asynchronously. Reduction. The Philosophy behind IP. Why Do We Need Extendible Programming Environments? or What Is the Problem with Fixed Programming Languages? Moving Focus from Fixed Languages to Language Features and the Emergence of an Intention Market. Intentional Programming and Component-Based Development. Frequently Asked Questions. Summary. III. APPLICATION EXAMPLES. 12. List Container. Why Is This Chapter Worth Reading? Overview. Domain Analysis. Domain Design. Implementation Components. Manual Assembly. Specifying Lists. The Generator. Extensions. 13. Bank Account. Why Is This Chapter Worth Reading? The Successful Programming Shop. Design Pattems, Frameworks, and Components. Domain Engineering and Generative Programming. Feature Modeling. Architecture Design. Implementation Components. Configurable Class Hierarchies. Designing a Domain-Specific Language. Bank Account Generator. Testing Generators and Their Products. 14. Generative Matrix Computation Library (GMCL). Why Is This Chapter Worth Reading? Why Matrix Computations? Domain Analysis. Domain Definition. Domain Modeling. Domain Design and Implementation. Matrix Type Generation. Generating Code for Matrix Expressions. Implementing the Matrix Component in IP. APPENDICES. Appendix A: Conceptual Modeling. What Are Concepts? Theories of Concepts. Basic Terminology. The Classical View. The Probabilistic View. The Exemplar View. Summary of the Three Views. Important Issues Concerning Concepts. Stability of Concepts. Concept Core. Informational Contents of Features. Feature Composition and Relationships between Features. Quality of Features. Abstraction and Generalization. Conceptual Modeling, Object-Orientation, and Software Reuse. Appendix B: Instance-Specific Extension Protocol for Smalltalk. Appendix C: Protocol for Attaching Listener Objects in Smalltalk. Appendix D: Glossary of Matrix Computation Terms. Appendix E: Metafunction for Evaluating Dependency Tables. Glossary of Generative Programming Terms. References. Index. 020130977T04062001",
            "referenceCount": 11,
            "citationCount": 3123,
            "influentialCitationCount": 305,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2000-06-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Czarnecki2000GenerativeP,\n author = {K. Czarnecki and U. Eisenecker},\n pages = {I-XXVI, 1-832},\n title = {Generative programming - methods, tools and applications},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:87c757138d273ccd38216ca5266406a503507077",
            "@type": "ScholarlyArticle",
            "paperId": "87c757138d273ccd38216ca5266406a503507077",
            "corpusId": 2271164,
            "url": "https://www.semanticscholar.org/paper/87c757138d273ccd38216ca5266406a503507077",
            "title": "Generative and Discriminative Voxel Modeling with Convolutional Neural Networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2952531844",
                "ArXiv": "1608.04236",
                "DBLP": "journals/corr/BrockLRW16",
                "CorpusId": 2271164
            },
            "abstract": "When working with three-dimensional data, choice of representation is key. We explore voxel-based models, and present evidence for the viability of voxellated representations in applications including shape modeling and object classification. Our key contributions are methods for training voxel-based variational autoencoders, a user interface for exploring the latent space learned by the autoencoder, and a deep convolutional neural network architecture for object classification. We address challenges unique to voxel-based representations, and empirically evaluate our models on the ModelNet benchmark, where we demonstrate a 51.5% relative improvement in the state of the art for object classification.",
            "referenceCount": 23,
            "citationCount": 512,
            "influentialCitationCount": 60,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-08-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1608.04236"
            },
            "citationStyles": {
                "bibtex": "@Article{Brock2016GenerativeAD,\n author = {Andrew Brock and Theodore Lim and J. Ritchie and Nick Weston},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Generative and Discriminative Voxel Modeling with Convolutional Neural Networks},\n volume = {abs/1608.04236},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:14f1f267731c89bbff04fce87b223d73168d8a4e",
            "@type": "ScholarlyArticle",
            "paperId": "14f1f267731c89bbff04fce87b223d73168d8a4e",
            "corpusId": 5012890,
            "url": "https://www.semanticscholar.org/paper/14f1f267731c89bbff04fce87b223d73168d8a4e",
            "title": "Multi-objective de novo drug design with conditional graph generative model",
            "venue": "Journal of Cheminformatics",
            "publicationVenue": {
                "id": "urn:research:fd4675fe-4136-446c-aefd-3658aae698ac",
                "name": "Journal of Cheminformatics",
                "alternate_names": [
                    "J Cheminformatics"
                ],
                "issn": "1758-2946",
                "url": "https://jcheminf.biomedcentral.com/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2784374286",
                "DBLP": "journals/corr/abs-1801-07299",
                "PubMedCentral": "6057868",
                "ArXiv": "1801.07299",
                "DOI": "10.1186/s13321-018-0287-6",
                "CorpusId": 5012890,
                "PubMed": "30043127"
            },
            "abstract": null,
            "referenceCount": 73,
            "citationCount": 257,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://jcheminf.biomedcentral.com/track/pdf/10.1186/s13321-018-0287-6",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Biology",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-01-18",
            "journal": {
                "name": "Journal of Cheminformatics",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2018MultiobjectiveDN,\n author = {Yibo Li and L. Zhang and Zhenming Liu},\n booktitle = {Journal of Cheminformatics},\n journal = {Journal of Cheminformatics},\n title = {Multi-objective de novo drug design with conditional graph generative model},\n volume = {10},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dd6de9423afcc0f821fee2bd0363a4091c7f8cd3",
            "@type": "ScholarlyArticle",
            "paperId": "dd6de9423afcc0f821fee2bd0363a4091c7f8cd3",
            "corpusId": 221081806,
            "url": "https://www.semanticscholar.org/paper/dd6de9423afcc0f821fee2bd0363a4091c7f8cd3",
            "title": "Distribution Augmentation for Generative Modeling",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "conf/icml/JunCCSRRS20",
                "CorpusId": 221081806
            },
            "abstract": "We present distribution augmentation (DistAug), a simple and powerful method of regularizing generative models. Our approach applies augmentation functions to data and, importantly, conditions the generative model on the specific function used. Unlike typical data augmentation, DistAug allows usage of functions which modify the target density, enabling aggressive augmentations more commonly seen in supervised and self-supervised learning. We demonstrate this is a more effective regularizer than standard methods, and use it to train a 152M parameter autoregressive model on CIFAR-10 to 2.56 bits per dim (relative to the state-of-the-art 2.80). Samples from this model attain FID 12.75 and IS 8.40, outperforming the majority of GANs. We further demonstrate the technique is broadly applicable across model architectures and problem domains.",
            "referenceCount": 40,
            "citationCount": 46,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Jun2020DistributionAF,\n author = {Heewoo Jun and Rewon Child and Mark Chen and J. Schulman and A. Ramesh and Alec Radford and Ilya Sutskever},\n booktitle = {International Conference on Machine Learning},\n pages = {5006-5019},\n title = {Distribution Augmentation for Generative Modeling},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eaf5b3a28606da5014d5c3d106b2fc4306933808",
            "@type": "ScholarlyArticle",
            "paperId": "eaf5b3a28606da5014d5c3d106b2fc4306933808",
            "corpusId": 4398957,
            "url": "https://www.semanticscholar.org/paper/eaf5b3a28606da5014d5c3d106b2fc4306933808",
            "title": "Graphite: Iterative Generative Modeling of Graphs",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2955772035",
                "DBLP": "journals/corr/abs-1803-10459",
                "ArXiv": "1803.10459",
                "CorpusId": 4398957
            },
            "abstract": "Graphs are a fundamental abstraction for modeling relational data. However, graphs are discrete and combinatorial in nature, and learning representations suitable for machine learning tasks poses statistical and computational challenges. In this work, we propose Graphite, an algorithmic framework for unsupervised learning of representations over nodes in large graphs using deep latent variable generative models. Our model parameterizes variational autoencoders (VAE) with graph neural networks, and uses a novel iterative graph refinement strategy inspired by low-rank approximations for decoding. On a wide variety of synthetic and benchmark datasets, Graphite outperforms competing approaches for the tasks of density estimation, link prediction, and node classification. Finally, we derive a theoretical connection between message passing in graph neural networks and mean-field variational inference.",
            "referenceCount": 85,
            "citationCount": 241,
            "influentialCitationCount": 36,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-03-28",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Grover2018GraphiteIG,\n author = {Aditya Grover and Aaron Zweig and Stefano Ermon},\n booktitle = {International Conference on Machine Learning},\n pages = {2434-2444},\n title = {Graphite: Iterative Generative Modeling of Graphs},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:258fad95e709b6d0572ae6cc99efbbb14d32bdf2",
            "@type": "ScholarlyArticle",
            "paperId": "258fad95e709b6d0572ae6cc99efbbb14d32bdf2",
            "corpusId": 16173261,
            "url": "https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2",
            "title": "SalGAN: Visual Saliency Prediction with Generative Adversarial Networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/PanCMOTSN17",
                "MAG": "2583180462",
                "ArXiv": "1701.01081",
                "CorpusId": 16173261
            },
            "abstract": "We introduce SalGAN, a deep convolutional neural network for visual saliency prediction trained with adversarial examples. The first stage of the network consists of a generator model whose weights are learned by back-propagation computed from a binary cross entropy (BCE) loss over downsampled versions of the saliency maps. The resulting prediction is processed by a discriminator network trained to solve a binary classification task between the saliency maps generated by the generative stage and the ground truth ones. Our experiments show how adversarial training allows reaching state-of-the-art performance across different metrics when combined with a widely-used loss function like BCE. Our results can be reproduced with the source code and trained models available at https://imatge-upc.github. io/saliency-salgan-2017/.",
            "referenceCount": 34,
            "citationCount": 357,
            "influentialCitationCount": 72,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-01-04",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1701.01081"
            },
            "citationStyles": {
                "bibtex": "@Article{Pan2017SalGANVS,\n author = {Junting Pan and C. Canton-Ferrer and Kevin McGuinness and N. O\u2019Connor and Jordi Torres and E. Sayrol and Xavier Giro-i-Nieto},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {SalGAN: Visual Saliency Prediction with Generative Adversarial Networks},\n volume = {abs/1701.01081},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cbca46c24c800bee41b21ac0258651db54892e80",
            "@type": "ScholarlyArticle",
            "paperId": "cbca46c24c800bee41b21ac0258651db54892e80",
            "corpusId": 3662488,
            "url": "https://www.semanticscholar.org/paper/cbca46c24c800bee41b21ac0258651db54892e80",
            "title": "Evolutionary Generative Adversarial Networks",
            "venue": "IEEE Transactions on Evolutionary Computation",
            "publicationVenue": {
                "id": "urn:research:79644985-a91b-42a7-ac72-bb961c283f5e",
                "name": "IEEE Transactions on Evolutionary Computation",
                "alternate_names": [
                    "IEEE Trans Evol Comput"
                ],
                "issn": "1089-778X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=4235"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2964121818",
                "ArXiv": "1803.00657",
                "DBLP": "journals/corr/abs-1803-00657",
                "DOI": "10.1109/TEVC.2019.2895748",
                "CorpusId": 3662488
            },
            "abstract": "Generative adversarial networks (GANs) have been effective for learning generative models for real-world data. However, accompanied with the generative tasks becoming more and more challenging, existing GANs (GAN and its variants) tend to suffer from different training problems such as instability and mode collapse. In this paper, we propose a novel GAN framework called evolutionary GANs (E-GANs) for stable GAN training and improved generative performance. Unlike existing GANs, which employ a predefined adversarial objective function alternately training a generator and a discriminator, we evolve a population of generators to play the adversarial game with the discriminator. Different adversarial training objectives are employed as mutation operations and each individual (i.e., generator candidature) are updated based on these mutations. Then, we devise an evaluation mechanism to measure the quality and diversity of generated samples, such that only well-performing generator(s) are preserved and used for further training. In this way, E-GAN overcomes the limitations of an individual adversarial training objective and always preserves the well-performing offspring, contributing to progress in, and the success of GANs. Experiments on several datasets demonstrate that E-GAN achieves convincing generative performance and reduces the training problems inherent in existing GANs.",
            "referenceCount": 82,
            "citationCount": 233,
            "influentialCitationCount": 33,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1803.00657",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-03-01",
            "journal": {
                "name": "IEEE Transactions on Evolutionary Computation",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2018EvolutionaryGA,\n author = {Chaoyue Wang and Chang Xu and Xin Yao and D. Tao},\n booktitle = {IEEE Transactions on Evolutionary Computation},\n journal = {IEEE Transactions on Evolutionary Computation},\n pages = {921-934},\n title = {Evolutionary Generative Adversarial Networks},\n volume = {23},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d203dce25fd45dfc0c6f154f6558b046a6d25011",
            "@type": "ScholarlyArticle",
            "paperId": "d203dce25fd45dfc0c6f154f6558b046a6d25011",
            "corpusId": 73454874,
            "url": "https://www.semanticscholar.org/paper/d203dce25fd45dfc0c6f154f6558b046a6d25011",
            "title": "Shape-Based Generative Modeling for de Novo Drug Design",
            "venue": "Journal of Chemical Information and Modeling",
            "publicationVenue": {
                "id": "urn:research:3f16aef5-6b9f-4f87-baca-cbf8147e352f",
                "name": "Journal of Chemical Information and Modeling",
                "alternate_names": [
                    "J Chem Inf Model"
                ],
                "issn": "1549-9596",
                "url": "http://pubs.acs.org/jcim"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2914635984",
                "DBLP": "journals/jcisd/SkalicJSF19",
                "DOI": "10.1021/acs.jcim.8b00706",
                "CorpusId": 73454874,
                "PubMed": "30762364"
            },
            "abstract": "In this work, we propose a machine learning approach to generate novel molecules starting from a seed compound, its three-dimensional (3D) shape, and its pharmacophoric features. The pipeline draws inspiration from generative models used in image analysis and represents a first example of the de novo design of lead-like molecules guided by shape-based features. A variational autoencoder is used to perturb the 3D representation of a compound, followed by a system of convolutional and recurrent neural networks that generate a sequence of SMILES tokens. The generative design of novel scaffolds and functional groups can cover unexplored regions of chemical space that still possess lead-like properties.",
            "referenceCount": 57,
            "citationCount": 144,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://figshare.com/articles/journal_contribution/Shape-Based_Generative_Modeling_for_de_Novo_Drug_Design/7785269/1/files/14491601.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-02-14",
            "journal": {
                "name": "Journal of chemical information and modeling",
                "volume": "59 3"
            },
            "citationStyles": {
                "bibtex": "@Article{\u0160kali\u010d2019ShapeBasedGM,\n author = {M. \u0160kali\u010d and J. Jim\u00e9nez and Davide Sabbadin and G. D. Fabritiis},\n booktitle = {Journal of Chemical Information and Modeling},\n journal = {Journal of chemical information and modeling},\n pages = {\n          1205-1214\n        },\n title = {Shape-Based Generative Modeling for de Novo Drug Design},\n volume = {59 3},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:631b7acaba06c42e6ba918ee7a284ba5e5ab0078",
            "@type": "ScholarlyArticle",
            "paperId": "631b7acaba06c42e6ba918ee7a284ba5e5ab0078",
            "corpusId": 47017667,
            "url": "https://www.semanticscholar.org/paper/631b7acaba06c42e6ba918ee7a284ba5e5ab0078",
            "title": "Data Synthesis based on Generative Adversarial Networks",
            "venue": "Proceedings of the VLDB Endowment",
            "publicationVenue": {
                "id": "urn:research:fcbcaf18-8ab1-43e1-a973-604bbc7e344e",
                "name": "Proceedings of the VLDB Endowment",
                "alternate_names": [
                    "Proceedings of The Vldb Endowment",
                    "Proc VLDB Endow",
                    "Proc Vldb Endow"
                ],
                "issn": "2150-8097",
                "url": "http://dl.acm.org/toc.cfm?id=J1174"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2806276686",
                "ArXiv": "1806.03384",
                "DBLP": "journals/pvldb/ParkMGJPK18",
                "DOI": "10.14778/3231751.3231757",
                "CorpusId": 47017667
            },
            "abstract": "\n Privacy is an important concern for our society where sharing data with partners or releasing data to the public is a frequent occurrence. Some of the techniques that are being used to achieve privacy are to remove identifiers, alter quasi-identifiers, and perturb values. Unfortunately, these approaches suffer from two limitations. First, it has been shown that private information can still be leaked if attackers possess some background knowledge or other information sources. Second, they do not take into account the adverse impact these methods will have on the utility of the released data. In this paper, we propose a method that meets both requirements. Our method, called\n table-GAN\n , uses generative adversarial networks (GANs) to synthesize fake tables that are statistically similar to the original table yet do not incur information leakage. We show that the machine learning models trained using our synthetic tables exhibit performance that is similar to that of models trained using the original table for unknown testing cases. We call this property\n model compatibility\n . We believe that anonymization/perturbation/synthesis methods without model compatibility are of little value. We used four real-world datasets from four different domains for our experiments and conducted indepth comparisons with state-of-the-art anonymization, perturbation, and generation techniques. Throughout our experiments, only our method consistently shows balance between privacy level and model compatibility.\n",
            "referenceCount": 32,
            "citationCount": 272,
            "influentialCitationCount": 41,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1806.03384",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "Proc. VLDB Endow.",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Park2018DataSB,\n author = {Noseong Park and Mahmoud Mohammadi and Kshitij Gorde and S. Jajodia and Hongkyu Park and Youngmin Kim},\n booktitle = {Proceedings of the VLDB Endowment},\n journal = {Proc. VLDB Endow.},\n pages = {1071-1083},\n title = {Data Synthesis based on Generative Adversarial Networks},\n volume = {11},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e8da4ff1519011ed018202bb96dee4b611f5d842",
            "@type": "ScholarlyArticle",
            "paperId": "e8da4ff1519011ed018202bb96dee4b611f5d842",
            "corpusId": 4670982,
            "url": "https://www.semanticscholar.org/paper/e8da4ff1519011ed018202bb96dee4b611f5d842",
            "title": "Generative Adversarial Perturbations",
            "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/cvpr/PoursaeedKGB18",
                "MAG": "2963855547",
                "ArXiv": "1712.02328",
                "DOI": "10.1109/CVPR.2018.00465",
                "CorpusId": 4670982
            },
            "abstract": "In this paper, we propose novel generative models for creating adversarial examples, slightly perturbed images resembling natural images but maliciously crafted to fool pre-trained models. We present trainable deep neural networks for transforming images to adversarial perturbations. Our proposed models can produce image-agnostic and image-dependent perturbations for targeted and non-targeted attacks. We also demonstrate that similar architectures can achieve impressive results in fooling both classification and semantic segmentation models, obviating the need for hand-crafting attack methods for each task. Using extensive experiments on challenging high-resolution datasets such as ImageNet and Cityscapes, we show that our perturbations achieve high fooling rates with small perturbation norms. Moreover, our attacks are considerably faster than current iterative methods at inference time.",
            "referenceCount": 64,
            "citationCount": 275,
            "influentialCitationCount": 60,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1712.02328",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-12-06",
            "journal": {
                "name": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Poursaeed2017GenerativeAP,\n author = {Omid Poursaeed and Isay Katsman and Bicheng Gao and Serge J. Belongie},\n booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n pages = {4422-4431},\n title = {Generative Adversarial Perturbations},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:21c3a96db50863ce3db703df385bf24159497842",
            "@type": "ScholarlyArticle",
            "paperId": "21c3a96db50863ce3db703df385bf24159497842",
            "corpusId": 202542431,
            "url": "https://www.semanticscholar.org/paper/21c3a96db50863ce3db703df385bf24159497842",
            "title": "DeepPrivacy: A Generative Adversarial Network for Face Anonymization",
            "venue": "International Symposium on Visual Computing",
            "publicationVenue": {
                "id": "urn:research:4cc90261-8707-4caa-9923-97881691dcb2",
                "name": "International Symposium on Visual Computing",
                "alternate_names": [
                    "Int Symp Vis Comput",
                    "ISVC"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=1764"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/isvc/HukkelasML19",
                "MAG": "2972577742",
                "ArXiv": "1909.04538",
                "DOI": "10.1007/978-3-030-33720-9_44",
                "CorpusId": 202542431
            },
            "abstract": null,
            "referenceCount": 34,
            "citationCount": 147,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1909.04538",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-09-10",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1909.04538"
            },
            "citationStyles": {
                "bibtex": "@Article{Hukkel\u00e5s2019DeepPrivacyAG,\n author = {H\u00e5kon Hukkel\u00e5s and R. Mester and F. Lindseth},\n booktitle = {International Symposium on Visual Computing},\n journal = {ArXiv},\n title = {DeepPrivacy: A Generative Adversarial Network for Face Anonymization},\n volume = {abs/1909.04538},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b8f57509a228f1c84bf67094ec1fa8a99407368b",
            "@type": "ScholarlyArticle",
            "paperId": "b8f57509a228f1c84bf67094ec1fa8a99407368b",
            "corpusId": 1617294,
            "url": "https://www.semanticscholar.org/paper/b8f57509a228f1c84bf67094ec1fa8a99407368b",
            "title": "Church: a language for generative models",
            "venue": "Conference on Uncertainty in Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:f9af8000-42f8-410d-a622-e8811e41660a",
                "name": "Conference on Uncertainty in Artificial Intelligence",
                "alternate_names": [
                    "Uncertainty in Artificial Intelligence",
                    "UAI",
                    "Conf Uncertain Artif Intell",
                    "Uncertain Artif Intell"
                ],
                "issn": null,
                "url": "http://www.auai.org/"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "1890754682",
                "DBLP": "journals/corr/abs-1206-3255",
                "ArXiv": "1206.3255",
                "CorpusId": 1617294
            },
            "abstract": "Formal languages for probabilistic modeling enable re-use, modularity, and descriptive clarity, and can foster generic inference techniques. We introduce Church, a universal language for describing stochastic generative processes. Church is based on the Lisp model of lambda calculus, containing a pure Lisp as its deterministic subset. The semantics of Church is defined in terms of evaluation histories and conditional distributions on such histories. Church also includes a novel language construct, the stochastic memoizer, which enables simple description of many complex non-parametric models. We illustrate language features through several examples, including: a generalized Bayes net in which parameters cluster over trials, infinite PCFGs, planning by inference, and various non-parametric clustering models. Finally, we show how to implement query on any Church program, exactly and approximately, using Monte Carlo techniques.",
            "referenceCount": 25,
            "citationCount": 797,
            "influentialCitationCount": 81,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-07-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Goodman2008ChurchAL,\n author = {Noah D. Goodman and Vikash K. Mansinghka and Daniel M. Roy and Keith Bonawitz and J. Tenenbaum},\n booktitle = {Conference on Uncertainty in Artificial Intelligence},\n pages = {220-229},\n title = {Church: a language for generative models},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a262a7ad405602ec69c57751939dfb61ed74257a",
            "@type": "ScholarlyArticle",
            "paperId": "a262a7ad405602ec69c57751939dfb61ed74257a",
            "corpusId": 1482745,
            "url": "https://www.semanticscholar.org/paper/a262a7ad405602ec69c57751939dfb61ed74257a",
            "title": "PacGAN: The Power of Two Samples in Generative Adversarial Networks",
            "venue": "IEEE Journal on Selected Areas in Information Theory",
            "publicationVenue": {
                "id": "urn:research:b571f31a-c68a-44b2-9c95-906830982180",
                "name": "IEEE Journal on Selected Areas in Information Theory",
                "alternate_names": [
                    "IEEE J Sel Area Inf Theory"
                ],
                "issn": "2641-8770",
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/nips/LinKFO18",
                "ArXiv": "1712.04086",
                "MAG": "2950829066",
                "DOI": "10.1109/JSAIT.2020.2983071",
                "CorpusId": 1482745
            },
            "abstract": "Generative adversarial networks (GANs) are innovative techniques for learning generative models of complex data distributions from samples. Despite remarkable improvements in generating realistic images, one of their major shortcomings is the fact that in practice, they tend to produce samples with little diversity, even when trained on diverse datasets. This phenomenon, known as mode collapse, has been the main focus of several recent advances in GANs. Yet there is little understanding of why mode collapse happens and why recently-proposed approaches mitigate mode collapse. We propose a principled approach to handle mode collapse called packing. The main idea is to modify the discriminator to make decisions based on multiple samples from the same class, either real or artificially generated. We borrow analysis tools from binary hypothesis testing\u2014in particular the seminal result of (Blackwell, 1953)\u2014to prove a fundamental connection between packing and mode collapse. We show that packing naturally penalizes generators with mode collapse, thereby favoring generator distributions with less mode collapse during the training process. Numerical experiments on benchmark datasets suggests that packing provides significant improvements in practice as well.",
            "referenceCount": 77,
            "citationCount": 278,
            "influentialCitationCount": 45,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-12-12",
            "journal": {
                "name": "IEEE Journal on Selected Areas in Information Theory",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Lin2017PacGANTP,\n author = {Zinan Lin and A. Khetan and G. Fanti and Sewoong Oh},\n booktitle = {IEEE Journal on Selected Areas in Information Theory},\n journal = {IEEE Journal on Selected Areas in Information Theory},\n pages = {324-335},\n title = {PacGAN: The Power of Two Samples in Generative Adversarial Networks},\n volume = {1},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bd37ff771acd72ebdf4024043cb62fcacdd3a82b",
            "@type": "ScholarlyArticle",
            "paperId": "bd37ff771acd72ebdf4024043cb62fcacdd3a82b",
            "corpusId": 13969696,
            "url": "https://www.semanticscholar.org/paper/bd37ff771acd72ebdf4024043cb62fcacdd3a82b",
            "title": "Cycle-Consistent Deep Generative Hashing for Cross-Modal Retrieval",
            "venue": "IEEE Transactions on Image Processing",
            "publicationVenue": {
                "id": "urn:research:e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                "name": "IEEE Transactions on Image Processing",
                "alternate_names": [
                    "IEEE Trans Image Process"
                ],
                "issn": "1057-7149",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2953343801",
                "DBLP": "journals/tip/WuWS19",
                "ArXiv": "1804.11013",
                "DOI": "10.1109/TIP.2018.2878970",
                "CorpusId": 13969696,
                "PubMed": "30387732"
            },
            "abstract": "In this paper, we propose a novel deep generative approach to cross-modal retrieval to learn hash functions in the absence of paired training samples through the cycle consistency loss. Our proposed approach employs adversarial training scheme to learn a couple of hash functions enabling translation between modalities while assuming the underlying semantic relationship. To induce the hash codes with semantics to the input-output pair, cycle consistency loss is further delved into the adversarial training to strengthen the correlation between the inputs and corresponding outputs. Our approach is generative to learn hash functions, such that the learned hash codes can maximally correlate each input\u2013output correspondence and also regenerate the inputs so as to minimize the information loss. The learning to hash embedding is thus performed to jointly optimize the parameters of the hash functions across modalities as well as the associated generative models. Extensive experiments on a variety of large-scale cross-modal data sets demonstrate that our proposed method outperforms the state of the arts.",
            "referenceCount": 67,
            "citationCount": 203,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1804.11013",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-30",
            "journal": {
                "name": "IEEE Transactions on Image Processing",
                "volume": "28"
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2018CycleConsistentDG,\n author = {Lin Wu and Yang Wang and Ling Shao},\n booktitle = {IEEE Transactions on Image Processing},\n journal = {IEEE Transactions on Image Processing},\n pages = {1602-1612},\n title = {Cycle-Consistent Deep Generative Hashing for Cross-Modal Retrieval},\n volume = {28},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2c9139b546c5403def3bd75e437b84e4f541727e",
            "@type": "ScholarlyArticle",
            "paperId": "2c9139b546c5403def3bd75e437b84e4f541727e",
            "corpusId": 1346276,
            "url": "https://www.semanticscholar.org/paper/2c9139b546c5403def3bd75e437b84e4f541727e",
            "title": "Voice Conversion from Unaligned Corpora Using Variational Autoencoding Wasserstein Generative Adversarial Networks",
            "venue": "Interspeech",
            "publicationVenue": {
                "id": "urn:research:af90489e-312f-4514-bea2-bcb399cb8ece",
                "name": "Interspeech",
                "alternate_names": [
                    "Conf Int Speech Commun Assoc",
                    "INTERSPEECH",
                    "Conference of the International Speech Communication Association"
                ],
                "issn": "2308-457X",
                "url": "https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1704.00849",
                "MAG": "2962896155",
                "DBLP": "journals/corr/HsuHWTW17",
                "DOI": "10.21437/Interspeech.2017-63",
                "CorpusId": 1346276
            },
            "abstract": "Building a voice conversion (VC) system from non-parallel speech corpora is challenging but highly valuable in real application scenarios. In most situations, the source and the target speakers do not repeat the same texts or they may even speak different languages. In this case, one possible, although indirect, solution is to build a generative model for speech. Generative models focus on explaining the observations with latent variables instead of learning a pairwise transformation function, thereby bypassing the requirement of speech frame alignment. In this paper, we propose a non-parallel VC framework with a variational autoencoding Wasserstein generative adversarial network (VAW-GAN) that explicitly considers a VC objective when building the speech model. Experimental results corroborate the capability of our framework for building a VC system from unaligned data, and demonstrate improved conversion quality.",
            "referenceCount": 25,
            "citationCount": 298,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1704.00849",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-04-04",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1704.00849"
            },
            "citationStyles": {
                "bibtex": "@Article{Hsu2017VoiceCF,\n author = {Chin-Cheng Hsu and Hsin-Te Hwang and Yi-Chiao Wu and Yu Tsao and H. Wang},\n booktitle = {Interspeech},\n journal = {ArXiv},\n title = {Voice Conversion from Unaligned Corpora Using Variational Autoencoding Wasserstein Generative Adversarial Networks},\n volume = {abs/1704.00849},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a78bc54068384d9ea6f07db89a1ce902ef56c2c6",
            "@type": "ScholarlyArticle",
            "paperId": "a78bc54068384d9ea6f07db89a1ce902ef56c2c6",
            "corpusId": 67856392,
            "url": "https://www.semanticscholar.org/paper/a78bc54068384d9ea6f07db89a1ce902ef56c2c6",
            "title": "VideoFlow: A Flow-Based Generative Model for Video",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1903-01434",
                "MAG": "2918222882",
                "CorpusId": 67856392
            },
            "abstract": "Generative models that can model and predict sequences of future events can, in principle, learn to capture complex real-world phenomena, such as physical interactions. In particular, learning predictive models of videos offers an especially appealing mechanism to enable a rich understanding of the physical world: videos of real-world interactions are plentiful and readily available, and a model that can predict future video frames can not only capture useful representations of the world, but can be useful in its own right, for problems such as model-based robotic control. However, a central challenge in video prediction is that the future is highly uncertain: a sequence of past observations of events can imply many possible futures. Although a number of recent works have studied probabilistic models that can represent uncertain futures, such models are either extremely expensive computationally (as in the case of pixel-level autoregressive models), or do not directly optimize the likelihood of the data. In this work, we propose a model for video prediction based on normalizing flows, which allows for direct optimization of the data likelihood, and produces high-quality stochastic predictions. To our knowledge, our work is the first to propose multi-frame video prediction with normalizing flows. We describe an approach for modeling the latent space dynamics, and demonstrate that flow-based generative models offer a viable and competitive approach to generative modeling of video.",
            "referenceCount": 56,
            "citationCount": 115,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-04",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1903.01434"
            },
            "citationStyles": {
                "bibtex": "@Article{Kumar2019VideoFlowAF,\n author = {Manoj Kumar and M. Babaeizadeh and D. Erhan and Chelsea Finn and S. Levine and Laurent Dinh and Durk Kingma},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {VideoFlow: A Flow-Based Generative Model for Video},\n volume = {abs/1903.01434},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c3c7464acb90049c5f520b0732dc7435ba3690bd",
            "@type": "ScholarlyArticle",
            "paperId": "c3c7464acb90049c5f520b0732dc7435ba3690bd",
            "corpusId": 256416326,
            "url": "https://www.semanticscholar.org/paper/c3c7464acb90049c5f520b0732dc7435ba3690bd",
            "title": "Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models",
            "venue": "ACM Transactions on Graphics",
            "publicationVenue": {
                "id": "urn:research:aab03e41-f80d-48b3-89bd-60eeeceafc7d",
                "name": "ACM Transactions on Graphics",
                "alternate_names": [
                    "ACM Trans Graph"
                ],
                "issn": "0730-0301",
                "url": "http://www.acm.org/tog/"
            },
            "year": 2023,
            "externalIds": {
                "ArXiv": "2301.13826",
                "DBLP": "journals/tog/CheferAVWC23",
                "DOI": "10.1145/3592116",
                "CorpusId": 256416326
            },
            "abstract": "Recent text-to-image generative models have demonstrated an unparalleled ability to generate diverse and creative imagery guided by a target text prompt. While revolutionary, current state-of-the-art diffusion models may still fail in generating images that fully convey the semantics in the given text prompt. We analyze the publicly available Stable Diffusion model and assess the existence of catastrophic neglect, where the model fails to generate one or more of the subjects from the input prompt. Moreover, we find that in some cases the model also fails to correctly bind attributes (e.g., colors) to their corresponding subjects. To help mitigate these failure cases, we introduce the concept of Generative Semantic Nursing (GSN), where we seek to intervene in the generative process on the fly during inference time to improve the faithfulness of the generated images. Using an attention-based formulation of GSN, dubbed Attend-and-Excite, we guide the model to refine the cross-attention units to attend to all subject tokens in the text prompt and strengthen --- or excite --- their activations, encouraging the model to generate all subjects described in the text prompt. We compare our approach to alternative approaches and demonstrate that it conveys the desired concepts more faithfully across a range of text prompts. Code is available at our project page: https://attendandexcite.github.io/Attend-and-Excite/.",
            "referenceCount": 60,
            "citationCount": 112,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2301.13826",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2023-01-31",
            "journal": {
                "name": "ACM Transactions on Graphics (TOG)",
                "volume": "42"
            },
            "citationStyles": {
                "bibtex": "@Article{Chefer2023AttendandExciteAS,\n author = {Hila Chefer and Yuval Alaluf and Yael Vinker and Lior Wolf and D. Cohen-Or},\n booktitle = {ACM Transactions on Graphics},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 10},\n title = {Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models},\n volume = {42},\n year = {2023}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4538e353dd98f396c8facc29ebb72e9b1ba5f7c2",
            "@type": "ScholarlyArticle",
            "paperId": "4538e353dd98f396c8facc29ebb72e9b1ba5f7c2",
            "corpusId": 258179174,
            "url": "https://www.semanticscholar.org/paper/4538e353dd98f396c8facc29ebb72e9b1ba5f7c2",
            "title": "Synthetic Data from Diffusion Models Improves ImageNet Classification",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2023,
            "externalIds": {
                "ArXiv": "2304.08466",
                "DBLP": "journals/corr/abs-2304-08466",
                "DOI": "10.48550/arXiv.2304.08466",
                "CorpusId": 258179174
            },
            "abstract": "Deep generative models are becoming increasingly powerful, now generating diverse high fidelity photo-realistic samples given text prompts. Have they reached the point where models of natural images can be used for generative data augmentation, helping to improve challenging discriminative tasks? We show that large-scale text-to image diffusion models can be fine-tuned to produce class conditional models with SOTA FID (1.76 at 256x256 resolution) and Inception Score (239 at 256x256). The model also yields a new SOTA in Classification Accuracy Scores (64.96 for 256x256 generative samples, improving to 69.24 for 1024x1024 samples). Augmenting the ImageNet training set with samples from the resulting models yields significant improvements in ImageNet classification accuracy over strong ResNet and Vision Transformer baselines.",
            "referenceCount": 72,
            "citationCount": 83,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/2304.08466",
                "status": "CLOSED"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2023-04-17",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2304.08466"
            },
            "citationStyles": {
                "bibtex": "@Article{Azizi2023SyntheticDF,\n author = {Shekoofeh Azizi and Simon Kornblith and Chitwan Saharia and Mohammad Norouzi and David J. Fleet},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Synthetic Data from Diffusion Models Improves ImageNet Classification},\n volume = {abs/2304.08466},\n year = {2023}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ac974291d7e3a152067382675524f3e3c2ded11b",
            "@type": "ScholarlyArticle",
            "paperId": "ac974291d7e3a152067382675524f3e3c2ded11b",
            "corpusId": 257280191,
            "url": "https://www.semanticscholar.org/paper/ac974291d7e3a152067382675524f3e3c2ded11b",
            "title": "Consistency Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2023,
            "externalIds": {
                "DBLP": "conf/icml/SongD0S23",
                "ArXiv": "2303.01469",
                "DOI": "10.48550/arXiv.2303.01469",
                "CorpusId": 257280191
            },
            "abstract": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation. To overcome this limitation, we propose consistency models, a new family of models that generate high quality samples by directly mapping noise to data. They support fast one-step generation by design, while still allowing multistep sampling to trade compute for sample quality. They also support zero-shot data editing, such as image inpainting, colorization, and super-resolution, without requiring explicit training on these tasks. Consistency models can be trained either by distilling pre-trained diffusion models, or as standalone generative models altogether. Through extensive experiments, we demonstrate that they outperform existing distillation techniques for diffusion models in one- and few-step sampling, achieving the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on ImageNet 64x64 for one-step generation. When trained in isolation, consistency models become a new family of generative models that can outperform existing one-step, non-adversarial generative models on standard benchmarks such as CIFAR-10, ImageNet 64x64 and LSUN 256x256.",
            "referenceCount": 86,
            "citationCount": 142,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/2303.01469",
                "status": "CLOSED"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2023-03-02",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Song2023ConsistencyM,\n author = {Yang Song and Prafulla Dhariwal and Mark Chen and Ilya Sutskever},\n booktitle = {International Conference on Machine Learning},\n pages = {32211-32252},\n title = {Consistency Models},\n year = {2023}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4bb3301a284d646b4c1ffabcca78ee85c11d1cda",
            "@type": "ScholarlyArticle",
            "paperId": "4bb3301a284d646b4c1ffabcca78ee85c11d1cda",
            "corpusId": 59553550,
            "url": "https://www.semanticscholar.org/paper/4bb3301a284d646b4c1ffabcca78ee85c11d1cda",
            "title": "WAIC, but Why? Generative Ensembles for Robust Anomaly Detection",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2913300775",
                "CorpusId": 59553550
            },
            "abstract": "Machine learning models encounter Out-of-Distribution (OoD) errors when the data seen at test time are generated from a different stochastic generator than the one used to generate the training data. One proposal to scale OoD detection to high-dimensional data is to learn a tractable likelihood approximation of the training distribution, and use it to reject unlikely inputs. However, likelihood models on natural data are themselves susceptible to OoD errors, and even assign large likelihoods to samples from other datasets. To mitigate this problem, we propose Generative Ensembles, which robustify density-based OoD detection by way of estimating epistemic uncertainty of the likelihood model. We present a puzzling observation in need of an explanation -- although likelihood measures cannot account for the typical set of a distribution, and therefore should not be suitable on their own for OoD detection, WAIC performs surprisingly well in practice.",
            "referenceCount": 40,
            "citationCount": 221,
            "influentialCitationCount": 42,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-10-02",
            "journal": {
                "name": "arXiv: Machine Learning",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Choi2018WAICBW,\n author = {Hyun-Jae Choi and Eric Jang and Alexander A. Alemi},\n journal = {arXiv: Machine Learning},\n title = {WAIC, but Why? Generative Ensembles for Robust Anomaly Detection},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e7f11d889450132f8010903475a3aeee25234bd5",
            "@type": "ScholarlyArticle",
            "paperId": "e7f11d889450132f8010903475a3aeee25234bd5",
            "corpusId": 5031033,
            "url": "https://www.semanticscholar.org/paper/e7f11d889450132f8010903475a3aeee25234bd5",
            "title": "Model-Free Renewable Scenario Generation Using Generative Adversarial Networks",
            "venue": "IEEE Transactions on Power Systems",
            "publicationVenue": {
                "id": "urn:research:dbbda9ef-0504-4875-b893-5c964f6b8f0e",
                "name": "IEEE Transactions on Power Systems",
                "alternate_names": [
                    "IEEE Trans Power Syst"
                ],
                "issn": "0885-8950",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=59"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/ChenWKZ17",
                "ArXiv": "1707.09676",
                "MAG": "2739824434",
                "DOI": "10.1109/TPWRS.2018.2794541",
                "CorpusId": 5031033
            },
            "abstract": "Scenario generation is an important step in the operation and planning of power systems with high renewable penetrations. In this work, we proposed a data-driven approach for scenario generation using generative adversarial networks, which is based on two interconnected deep neural networks. Compared with existing methods based on probabilistic models that are often hard to scale or sample from, our method is data-driven, and captures renewable energy production patterns in both temporal and spatial dimensions for a large number of correlated resources. For validation, we use wind and solar times-series data from NREL integration data sets. We demonstrate that the proposed method is able to generate realistic wind and photovoltaic power profiles with full diversity of behaviors. We also illustrate how to generate scenarios based on different conditions of interest by using labeled data during training. For example, scenarios can be conditioned on weather events\u00a0(e.g., high wind day, intense ramp events, or large forecasts errors) or time of the year\u00a0(e.g., solar generation for a day in July). Because of the feedforward nature of the neural networks, scenarios can be generated extremely efficiently without sophisticated sampling techniques.",
            "referenceCount": 36,
            "citationCount": 343,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1707.09676",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-30",
            "journal": {
                "name": "IEEE Transactions on Power Systems",
                "volume": "33"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2017ModelFreeRS,\n author = {Yize Chen and Yishen Wang and D. Kirschen and Baosen Zhang},\n booktitle = {IEEE Transactions on Power Systems},\n journal = {IEEE Transactions on Power Systems},\n pages = {3265-3275},\n title = {Model-Free Renewable Scenario Generation Using Generative Adversarial Networks},\n volume = {33},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d0c63d02bd63ecc0fb9debfe2b93b2e6be983ed8",
            "@type": "ScholarlyArticle",
            "paperId": "d0c63d02bd63ecc0fb9debfe2b93b2e6be983ed8",
            "corpusId": 53816815,
            "url": "https://www.semanticscholar.org/paper/d0c63d02bd63ecc0fb9debfe2b93b2e6be983ed8",
            "title": "Synthesizing Tabular Data using Generative Adversarial Networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2902901670",
                "DBLP": "journals/corr/abs-1811-11264",
                "ArXiv": "1811.11264",
                "CorpusId": 53816815
            },
            "abstract": "Generative adversarial networks (GANs) implicitly learn the probability distribution of a dataset and can draw samples from the distribution. This paper presents, Tabular GAN (TGAN), a generative adversarial network which can generate tabular data like medical or educational records. Using the power of deep neural networks, TGAN generates high-quality and fully synthetic tables while simultaneously generating discrete and continuous variables. When we evaluate our model on three datasets, we find that TGAN outperforms conventional statistical generative models in both capturing the correlation between columns and scaling up for large datasets.",
            "referenceCount": 50,
            "citationCount": 173,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-11-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1811.11264"
            },
            "citationStyles": {
                "bibtex": "@Article{Xu2018SynthesizingTD,\n author = {L. Xu and K. Veeramachaneni},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Synthesizing Tabular Data using Generative Adversarial Networks},\n volume = {abs/1811.11264},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b488f536cdeaafb9ee70c10b1ae83c5d78681487",
            "@type": "ScholarlyArticle",
            "paperId": "b488f536cdeaafb9ee70c10b1ae83c5d78681487",
            "corpusId": 204904806,
            "url": "https://www.semanticscholar.org/paper/b488f536cdeaafb9ee70c10b1ae83c5d78681487",
            "title": "Fair Generative Modeling via Weak Supervision",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2981374076",
                "DBLP": "conf/icml/ChoiGSSE20",
                "ArXiv": "1910.12008",
                "CorpusId": 204904806
            },
            "abstract": "Real-world datasets are often biased with respect to key demographic factors such as race and gender. Due to the latent nature of the underlying factors, detecting and mitigating bias is especially challenging for unsupervised machine learning. We present a weakly supervised algorithm for overcoming dataset bias for deep generative models. Our approach requires access to an additional small, unlabeled reference dataset as the supervision signal, thus sidestepping the need for explicit labels on the underlying bias factors. Using this supplementary dataset, we detect the bias in existing datasets via a density ratio technique and learn generative models which efficiently achieve the twin goals of: 1) data efficiency by using training examples from both biased and reference datasets for learning; and 2) data generation close in distribution to the reference dataset at test time. Empirically, we demonstrate the efficacy of our approach which reduces bias w.r.t. latent factors by an average of up to 34.6% over baselines for comparable image generation using generative adversarial networks.",
            "referenceCount": 89,
            "citationCount": 94,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-10-26",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Grover2019FairGM,\n author = {Aditya Grover and Kristy Choi and Rui Shu and Stefano Ermon},\n booktitle = {International Conference on Machine Learning},\n pages = {1887-1898},\n title = {Fair Generative Modeling via Weak Supervision},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:10eec18a20954f9ac4d8f463524e5f160e23895f",
            "@type": "ScholarlyArticle",
            "paperId": "10eec18a20954f9ac4d8f463524e5f160e23895f",
            "corpusId": 13739672,
            "url": "https://www.semanticscholar.org/paper/10eec18a20954f9ac4d8f463524e5f160e23895f",
            "title": "Quantum generative adversarial networks",
            "venue": "Physical Review A",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1804-08641",
                "ArXiv": "1804.08641",
                "MAG": "2798967590",
                "DOI": "10.1103/PhysRevA.98.012324",
                "CorpusId": 13739672
            },
            "abstract": "Quantum machine learning is expected to be one of the first potential general-purpose applications of near-term quantum devices. A major recent breakthrough in classical machine learning is the notion of generative adversarial training, where the gradients of a discriminator model are used to train a separate generative model. In this work and a companion paper, we extend adversarial training to the quantum domain and show how to construct generative adversarial networks using quantum circuits. Furthermore, we also show how to compute gradients -- a key element in generative adversarial network training -- using another quantum circuit. We give an example of a simple practical circuit ansatz to parametrize quantum machine learning models and perform a simple numerical experiment to demonstrate that quantum generative adversarial networks can be trained successfully.",
            "referenceCount": 34,
            "citationCount": 266,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1804.08641",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-23",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1804.08641"
            },
            "citationStyles": {
                "bibtex": "@Article{Dallaire-Demers2018QuantumGA,\n author = {Pierre-Luc Dallaire-Demers and N. Killoran},\n booktitle = {Physical Review A},\n journal = {ArXiv},\n title = {Quantum generative adversarial networks},\n volume = {abs/1804.08641},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0c9fc038583b7a6b27772e808c798fcdc10778bc",
            "@type": "ScholarlyArticle",
            "paperId": "0c9fc038583b7a6b27772e808c798fcdc10778bc",
            "corpusId": 54217445,
            "url": "https://www.semanticscholar.org/paper/0c9fc038583b7a6b27772e808c798fcdc10778bc",
            "title": "NeVAE: A Deep Generative Model for Molecular Graphs",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "3039085085",
                "ArXiv": "1802.05283",
                "DBLP": "journals/jmlr/SamantaDJGCGG20",
                "DOI": "10.1609/aaai.v33i01.33011110",
                "CorpusId": 54217445
            },
            "abstract": "Deep generative models have been praised for their ability to learn smooth latent representation of images, text, and audio, which can then be used to generate new, plausible data. However, current generative models are unable to work with molecular graphs due to their unique characteristics\u2014their underlying structure is not Euclidean or grid-like, they remain isomorphic under permutation of the nodes labels, and they come with a different number of nodes and edges. In this paper, we propose NeVAE, a novel variational autoencoder for molecular graphs, whose encoder and decoder are specially designed to account for the above properties by means of several technical innovations. In addition, by using masking, the decoder is able to guarantee a set of valid properties in the generated molecules. Experiments reveal that our model can discover plausible, diverse and novel molecules more effectively than several state of the art methods. Moreover, by utilizing Bayesian optimization over the continuous latent representation of molecules our model finds, we can also find molecules that maximize certain desirable properties more effectively than alternatives.",
            "referenceCount": 64,
            "citationCount": 177,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://aaai.org/ojs/index.php/AAAI/article/download/3903/3781",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-02-14",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Samanta2018NeVAEAD,\n author = {Bidisha Samanta and A. De and G. Jana and P. Chattaraj and Niloy Ganguly and Manuel Gomez Rodriguez},\n booktitle = {AAAI Conference on Artificial Intelligence},\n journal = {J. Mach. Learn. Res.},\n pages = {114:1-114:33},\n title = {NeVAE: A Deep Generative Model for Molecular Graphs},\n volume = {21},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b3e11af71552d39070dd9183acb8b8171bc22b38",
            "@type": "ScholarlyArticle",
            "paperId": "b3e11af71552d39070dd9183acb8b8171bc22b38",
            "corpusId": 215824871,
            "url": "https://www.semanticscholar.org/paper/b3e11af71552d39070dd9183acb8b8171bc22b38",
            "title": "A Hierarchical Recurrent Encoder-Decoder for Generative Context-Aware Query Suggestion",
            "venue": "International Conference on Information and Knowledge Management",
            "publicationVenue": {
                "id": "urn:research:7431ff67-91dc-41fa-b322-1b1ca657025f",
                "name": "International Conference on Information and Knowledge Management",
                "alternate_names": [
                    "Conference on Information and Knowledge Management",
                    "Conf Inf Knowl Manag",
                    "Int Conf Inf Knowl Manag",
                    "CIKM"
                ],
                "issn": null,
                "url": "http://www.cikm.org/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2951386572",
                "DBLP": "conf/cikm/SordoniBVLSN15",
                "ArXiv": "1507.02221",
                "DOI": "10.1145/2806416.2806493",
                "CorpusId": 215824871
            },
            "abstract": "Users may strive to formulate an adequate textual query for their information need. Search engines assist the users by presenting query suggestions. To preserve the original search intent, suggestions should be context-aware and account for the previous queries issued by the user. Achieving context awareness is challenging due to data sparsity. We present a novel hierarchical recurrent encoder-decoder architecture that makes possible to account for sequences of previous queries of arbitrary lengths. As a result, our suggestions are sensitive to the order of queries in the context while avoiding data sparsity. Additionally, our model can suggest for rare, or long-tail, queries. The produced suggestions are synthetic and are sampled one word at a time, using computationally cheap decoding techniques. This is in contrast to current synthetic suggestion models relying upon machine learning pipelines and hand-engineered feature sets. Results show that our model outperforms existing context-aware approaches in a next query prediction setting. In addition to query suggestion, our architecture is general enough to be used in a variety of other applications.",
            "referenceCount": 46,
            "citationCount": 503,
            "influentialCitationCount": 76,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1507.02221v1.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2015-07-08",
            "journal": {
                "name": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sordoni2015AHR,\n author = {Alessandro Sordoni and Yoshua Bengio and H. Vahabi and C. Lioma and J. Simonsen and J. Nie},\n booktitle = {International Conference on Information and Knowledge Management},\n journal = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management},\n title = {A Hierarchical Recurrent Encoder-Decoder for Generative Context-Aware Query Suggestion},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7a15950dc71079285a4eaf195de5aadd87c41b40",
            "@type": "ScholarlyArticle",
            "paperId": "7a15950dc71079285a4eaf195de5aadd87c41b40",
            "corpusId": 202660943,
            "url": "https://www.semanticscholar.org/paper/7a15950dc71079285a4eaf195de5aadd87c41b40",
            "title": "Fine-Tuning Language Models from Human Preferences",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1909-08593",
                "ArXiv": "1909.08593",
                "MAG": "2973379954",
                "CorpusId": 202660943
            },
            "abstract": "Reward learning enables the application of reinforcement learning (RL) to tasks where reward is defined by human judgment, building a model of reward by asking humans questions. Most work on reward learning has used simulated environments, but complex information about values is often expressed in natural language, and we believe reward learning for language is a key to making RL practical and safe for real-world tasks. In this paper, we build on advances in generative pretraining of language models to apply reward learning to four natural language tasks: continuing text with positive sentiment or physically descriptive language, and summarization tasks on the TL;DR and CNN/Daily Mail datasets. For stylistic continuation we achieve good results with only 5,000 comparisons evaluated by humans. For summarization, models trained with 60,000 comparisons copy whole sentences from the input but skip irrelevant preamble; this leads to reasonable ROUGE scores and very good performance according to our human labelers, but may be exploiting the fact that labelers rely on simple heuristics.",
            "referenceCount": 49,
            "citationCount": 566,
            "influentialCitationCount": 56,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-09-18",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1909.08593"
            },
            "citationStyles": {
                "bibtex": "@Article{Ziegler2019FineTuningLM,\n author = {Daniel M. Ziegler and Nisan Stiennon and Jeff Wu and Tom B. Brown and Alec Radford and Dario Amodei and Paul Christiano and G. Irving},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Fine-Tuning Language Models from Human Preferences},\n volume = {abs/1909.08593},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c0013cb114d8b16df36858897ff219dbc221b3ed",
            "@type": "ScholarlyArticle",
            "paperId": "c0013cb114d8b16df36858897ff219dbc221b3ed",
            "corpusId": 6988192,
            "url": "https://www.semanticscholar.org/paper/c0013cb114d8b16df36858897ff219dbc221b3ed",
            "title": "Expectation Truncation and the Benefits of Preselection In Training Generative Models",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2128209899",
                "DBLP": "journals/jmlr/LuckeE10",
                "DOI": "10.5555/1756006.1953025",
                "CorpusId": 6988192
            },
            "abstract": "We show how a preselection of hidden variables can be used to efficiently train generative models with binary hidden variables. The approach is based on Expectation Maximization (EM) and uses an efficiently computable approximation to the sufficient statistics of a given model. The computational cost to compute the sufficient statistics is strongly reduced by selecting, for each data point, the relevant hidden causes. The approximation is applicable to a wide range of generative models and provides an interpretation of the benefits of preselection in terms of a variational EM approximation. To empirically show that the method maximizes the data likelihood, it is applied to different types of generative models including: a version of non-negative matrix factorization (NMF), a model for non-linear component extraction (MCA), and a linear generative model similar to sparse coding. The derived algorithms are applied to both artificial and realistic data, and are compared to other models in the literature. We find that the training scheme can reduce computational costs by orders of magnitude and allows for a reliable extraction of hidden causes.",
            "referenceCount": 40,
            "citationCount": 48,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-03-01",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{L\u00fccke2010ExpectationTA,\n author = {J\u00f6rg L\u00fccke and J. Eggert},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {2855-2900},\n title = {Expectation Truncation and the Benefits of Preselection In Training Generative Models},\n volume = {11},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b338cb632eee50743aa62956038b9ff157e8cc38",
            "@type": "ScholarlyArticle",
            "paperId": "b338cb632eee50743aa62956038b9ff157e8cc38",
            "corpusId": 204949374,
            "url": "https://www.semanticscholar.org/paper/b338cb632eee50743aa62956038b9ff157e8cc38",
            "title": "Semantic Object Accuracy for Generative Text-to-Image Synthesis",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1910-13321",
                "MAG": "2982450728",
                "ArXiv": "1910.13321",
                "DOI": "10.1109/TPAMI.2020.3021209",
                "CorpusId": 204949374,
                "PubMed": "32877332"
            },
            "abstract": "Generative adversarial networks conditioned on textual image descriptions are capable of generating realistic-looking images. However, current methods still struggle to generate images based on complex image captions from a heterogeneous domain. Furthermore, quantitatively evaluating these text-to-image models is challenging, as most evaluation metrics only judge image quality but not the conformity between the image and its caption. To address these challenges we introduce a new model that explicitly models individual objects within an image and a new evaluation metric called Semantic Object Accuracy (SOA) that specifically evaluates images given an image caption. The SOA uses a pre-trained object detector to evaluate if a generated image contains objects that are mentioned in the image caption, e.g., whether an image generated from \u201ca car driving down the street\u201d contains a car. We perform a user study comparing several text-to-image models and show that our SOA metric ranks the models the same way as humans, whereas other metrics such as the Inception Score do not. Our evaluation also shows that models which explicitly model objects outperform models which only model global image characteristics.",
            "referenceCount": 67,
            "citationCount": 124,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/34/9703108/09184960.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-10-29",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "44"
            },
            "citationStyles": {
                "bibtex": "@Article{Hinz2019SemanticOA,\n author = {T. Hinz and Stefan Heinrich and S. Wermter},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {1552-1565},\n title = {Semantic Object Accuracy for Generative Text-to-Image Synthesis},\n volume = {44},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:638e41912f314c74436205aa8d332dca963ab1dc",
            "@type": "ScholarlyArticle",
            "paperId": "638e41912f314c74436205aa8d332dca963ab1dc",
            "corpusId": 189999815,
            "url": "https://www.semanticscholar.org/paper/638e41912f314c74436205aa8d332dca963ab1dc",
            "title": "Parameterized quantum circuits as machine learning models",
            "venue": "Quantum Science and Technology",
            "publicationVenue": {
                "id": "urn:research:8eb00c73-e022-4bd6-b48b-1d3b2ccf107d",
                "name": "Quantum Science and Technology",
                "alternate_names": [
                    "Quantum Sci Technol"
                ],
                "issn": "2364-9062",
                "url": "https://iopscience.iop.org/2058-9565"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2980446414",
                "ArXiv": "1906.07682",
                "DBLP": "journals/corr/abs-1906-07682",
                "DOI": "10.1088/2058-9565/ab4eb5",
                "CorpusId": 189999815
            },
            "abstract": "Hybrid quantum\u2013classical systems make it possible to utilize existing quantum computers to their fullest extent. Within this framework, parameterized quantum circuits can be regarded as machine learning models with remarkable expressive power. This Review presents the components of these models and discusses their application to a variety of data-driven tasks, such as supervised learning and generative modeling. With an increasing number of experimental demonstrations carried out on actual quantum hardware and with software being actively developed, this rapidly growing field is poised to have a broad spectrum of real-world applications.",
            "referenceCount": 124,
            "citationCount": 569,
            "influentialCitationCount": 41,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://iopscience.iop.org/article/10.1088/2058-9565/ab4eb5/pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Physics",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-06-18",
            "journal": {
                "name": "Quantum Science and Technology",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Benedetti2019ParameterizedQC,\n author = {Marcello Benedetti and Erika Lloyd and Stefan H. Sack and Mattia Fiorentini},\n booktitle = {Quantum Science and Technology},\n journal = {Quantum Science and Technology},\n title = {Parameterized quantum circuits as machine learning models},\n volume = {4},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6ea90ce79d9f4d962e34b3c8a73fb41455a87322",
            "@type": "ScholarlyArticle",
            "paperId": "6ea90ce79d9f4d962e34b3c8a73fb41455a87322",
            "corpusId": 44106659,
            "url": "https://www.semanticscholar.org/paper/6ea90ce79d9f4d962e34b3c8a73fb41455a87322",
            "title": "FairGAN: Fairness-aware Generative Adversarial Networks",
            "venue": "2018 IEEE International Conference on Big Data (Big Data)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2949927868",
                "ArXiv": "1805.11202",
                "DBLP": "conf/bigdataconf/XuYZW18",
                "DOI": "10.1109/BigData.2018.8622525",
                "CorpusId": 44106659
            },
            "abstract": "Fairness-aware learning is increasingly important in data mining. Discrimination prevention aims to prevent discrimination in the training data before it is used to conduct predictive analysis. In this paper, we focus on fair data generation that ensures the generated data is discrimination free. Inspired by generative adversarial networks (GAN), we present fairness-aware generative adversarial networks, called FairGAN, which are able to learn a generator producing fair data and also preserving good data utility. Compared with the naive fair data generation models, FairGAN further ensures the classifiers which are trained on generated data can achieve fair classification on real data. Experiments on a real dataset show the effectiveness of FairGAN.",
            "referenceCount": 29,
            "citationCount": 227,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1805.11202",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-05-28",
            "journal": {
                "name": "2018 IEEE International Conference on Big Data (Big Data)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Xu2018FairGANFG,\n author = {Depeng Xu and Shuhan Yuan and Lu Zhang and Xintao Wu},\n booktitle = {2018 IEEE International Conference on Big Data (Big Data)},\n journal = {2018 IEEE International Conference on Big Data (Big Data)},\n pages = {570-575},\n title = {FairGAN: Fairness-aware Generative Adversarial Networks},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ab2e9398954142727aa78ac68517159906e3fffd",
            "@type": "ScholarlyArticle",
            "paperId": "ab2e9398954142727aa78ac68517159906e3fffd",
            "corpusId": 7980756,
            "url": "https://www.semanticscholar.org/paper/ab2e9398954142727aa78ac68517159906e3fffd",
            "title": "Imitating driver behavior with generative adversarial networks",
            "venue": "2017 IEEE Intelligent Vehicles Symposium (IV)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2949251504",
                "ArXiv": "1701.06699",
                "DBLP": "conf/ivs/KueflerMWK17",
                "DOI": "10.1109/IVS.2017.7995721",
                "CorpusId": 7980756
            },
            "abstract": "The ability to accurately predict and simulate human driving behavior is critical for the development of intelligent transportation systems. Traditional modeling methods have employed simple parametric models and behavioral cloning. This paper adopts a method for overcoming the problem of cascading errors inherent in prior approaches, resulting in realistic behavior that is robust to trajectory perturbations. We extend Generative Adversarial Imitation Learning to the training of recurrent policies, and we demonstrate that our model rivals rule-based controllers and maximum likelihood models in realistic highway simulations. Our model both reproduces emergent behavior of human drivers, such as lane change rate, while maintaining realistic control over long time horizons.",
            "referenceCount": 42,
            "citationCount": 331,
            "influentialCitationCount": 34,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1701.06699",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-01-24",
            "journal": {
                "name": "2017 IEEE Intelligent Vehicles Symposium (IV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kuefler2017ImitatingDB,\n author = {Alex Kuefler and Jeremy Morton and T. Wheeler and Mykel J. Kochenderfer},\n booktitle = {2017 IEEE Intelligent Vehicles Symposium (IV)},\n journal = {2017 IEEE Intelligent Vehicles Symposium (IV)},\n pages = {204-211},\n title = {Imitating driver behavior with generative adversarial networks},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:517a488f06577401422cf7e03647ac6148ef4e44",
            "@type": "ScholarlyArticle",
            "paperId": "517a488f06577401422cf7e03647ac6148ef4e44",
            "corpusId": 3833699,
            "url": "https://www.semanticscholar.org/paper/517a488f06577401422cf7e03647ac6148ef4e44",
            "title": "Generative Recurrent Networks for De Novo Drug Design",
            "venue": "Molecular Informatics",
            "publicationVenue": {
                "id": "urn:research:5b118ecf-59a2-431d-8c47-4656f9e92e08",
                "name": "Molecular Informatics",
                "alternate_names": [
                    "Mol Informatics"
                ],
                "issn": "1868-1743",
                "url": "http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1868-1751"
            },
            "year": 2017,
            "externalIds": {
                "PubMedCentral": "5836943",
                "MAG": "2765224015",
                "DOI": "10.1002/minf.201700111",
                "CorpusId": 3833699,
                "PubMed": "29095571"
            },
            "abstract": "Generative artificial intelligence models present a fresh approach to chemogenomics and de novo drug design, as they provide researchers with the ability to narrow down their search of the chemical space and focus on regions of interest. We present a method for molecular de novo design that utilizes generative recurrent neural networks (RNN) containing long short\u2010term memory (LSTM) cells. This computational model captured the syntax of molecular representation in terms of SMILES strings with close to perfect accuracy. The learned pattern probabilities can be used for de novo SMILES generation. This molecular design concept eliminates the need for virtual compound library enumeration. By employing transfer learning, we fine\u2010tuned the RNN\u2032s predictions for specific molecular targets. This approach enables virtual compound design without requiring secondary or external activity prediction, which could introduce error or unwanted bias. The results obtained advocate this generative RNN\u2010LSTM system for high\u2010impact use cases, such as low\u2010data drug discovery, fragment based molecular design, and hit\u2010to\u2010lead optimization for diverse drug targets.",
            "referenceCount": 25,
            "citationCount": 334,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/minf.201700111",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-02",
            "journal": {
                "name": "Molecular Informatics",
                "volume": "37"
            },
            "citationStyles": {
                "bibtex": "@Article{Gupta2017GenerativeRN,\n author = {Anvita Gupta and A. T. M\u00fcller and Berend J. H. Huisman and Jens A Fuchs and P. Schneider and G. Schneider},\n booktitle = {Molecular Informatics},\n journal = {Molecular Informatics},\n title = {Generative Recurrent Networks for De Novo Drug Design},\n volume = {37},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4b71ab38d3ac6eee0da5e68ef666d33d1028bad8",
            "@type": "ScholarlyArticle",
            "paperId": "4b71ab38d3ac6eee0da5e68ef666d33d1028bad8",
            "corpusId": 35563,
            "url": "https://www.semanticscholar.org/paper/4b71ab38d3ac6eee0da5e68ef666d33d1028bad8",
            "title": "Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1701.06264",
                "MAG": "2580360036",
                "DBLP": "journals/ijcv/Qi20",
                "DOI": "10.1007/s11263-019-01265-2",
                "CorpusId": 35563
            },
            "abstract": null,
            "referenceCount": 53,
            "citationCount": 312,
            "influentialCitationCount": 33,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1701.06264",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-01-23",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "128"
            },
            "citationStyles": {
                "bibtex": "@Article{Qi2017LossSensitiveGA,\n author = {Guo-Jun Qi},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {1118 - 1140},\n title = {Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities},\n volume = {128},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:711b1f7cc4e92d6f40c7813c6f0e1c2e179d48ad",
            "@type": "ScholarlyArticle",
            "paperId": "711b1f7cc4e92d6f40c7813c6f0e1c2e179d48ad",
            "corpusId": 52290656,
            "url": "https://www.semanticscholar.org/paper/711b1f7cc4e92d6f40c7813c6f0e1c2e179d48ad",
            "title": "Commonsense for Generative Multi-Hop Question Answering Tasks",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1809.06309",
                "MAG": "2892280852",
                "DBLP": "journals/corr/abs-1809-06309",
                "ACL": "D18-1454",
                "DOI": "10.18653/v1/D18-1454",
                "CorpusId": 52290656
            },
            "abstract": "Reading comprehension QA tasks have seen a recent surge in popularity, yet most works have focused on fact-finding extractive QA. We instead focus on a more challenging multi-hop generative task (NarrativeQA), which requires the model to reason, gather, and synthesize disjoint pieces of information within the context to generate an answer. This type of multi-step reasoning also often requires understanding implicit relations, which humans resolve via external, background commonsense knowledge. We first present a strong generative baseline that uses a multi-attention mechanism to perform multiple hops of reasoning and a pointer-generator decoder to synthesize the answer. This model performs substantially better than previous generative models, and is competitive with current state-of-the-art span prediction models. We next introduce a novel system for selecting grounded multi-hop relational commonsense information from ConceptNet via a pointwise mutual information and term-frequency based scoring function. Finally, we effectively use this extracted commonsense information to fill in gaps of reasoning between context hops, using a selectively-gated attention mechanism. This boosts the model\u2019s performance significantly (also verified via human evaluation), establishing a new state-of-the-art for the task. We also show that our background knowledge enhancements are generalizable and improve performance on QAngaroo-WikiHop, another multi-hop reasoning dataset.",
            "referenceCount": 45,
            "citationCount": 156,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/D18-1454.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-09-17",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bauer2018CommonsenseFG,\n author = {Lisa Bauer and Yicheng Wang and Mohit Bansal},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {4220-4230},\n title = {Commonsense for Generative Multi-Hop Question Answering Tasks},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:75c0d369c7151b925155cfe1b3f01dd7d0503981",
            "@type": "ScholarlyArticle",
            "paperId": "75c0d369c7151b925155cfe1b3f01dd7d0503981",
            "corpusId": 46899514,
            "url": "https://www.semanticscholar.org/paper/75c0d369c7151b925155cfe1b3f01dd7d0503981",
            "title": "Generative Code Modeling with Graphs",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2963393993",
                "ArXiv": "1805.08490",
                "DBLP": "conf/iclr/BrockschmidtAGP19",
                "CorpusId": 46899514
            },
            "abstract": "Generative models for source code are an interesting structured prediction problem, requiring to reason about both hard syntactic and semantic constraints as well as about natural, likely programs. We present a novel model for this problem that uses a graph to represent the intermediate state of the generated output. The generative procedure interleaves grammar-driven expansion steps with graph augmentation and neural message passing steps. An experimental evaluation shows that our new model can generate semantically meaningful expressions, outperforming a range of strong baselines.",
            "referenceCount": 29,
            "citationCount": 154,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-05-22",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1805.08490"
            },
            "citationStyles": {
                "bibtex": "@Article{Brockschmidt2018GenerativeCM,\n author = {Marc Brockschmidt and Miltiadis Allamanis and Alexander L. Gaunt and Oleksandr Polozov},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Generative Code Modeling with Graphs},\n volume = {abs/1805.08490},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:60885c61116c5ff5ac61270dcd8d430ca6f3e692",
            "@type": "ScholarlyArticle",
            "paperId": "60885c61116c5ff5ac61270dcd8d430ca6f3e692",
            "corpusId": 10466029,
            "url": "https://www.semanticscholar.org/paper/60885c61116c5ff5ac61270dcd8d430ca6f3e692",
            "title": "Generative adversarial networks: introduction and outlook",
            "venue": "IEEE/CAA Journal of Automatica Sinica",
            "publicationVenue": {
                "id": "urn:research:ef1356d5-69c7-484e-a110-3efae1e93ecc",
                "name": "IEEE/CAA Journal of Automatica Sinica",
                "alternate_names": [
                    "IEEE/CAA J Autom Sin"
                ],
                "issn": "2329-9266",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=6570654"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/ieeejas/WangGDLZW17",
                "MAG": "2755577605",
                "DOI": "10.1109/JAS.2017.7510583",
                "CorpusId": 10466029
            },
            "abstract": "Recently, generative adversarial networks U+0028 GANs U+0029 have become a research focus of artificial intelligence. Inspired by two-player zero-sum game, GANs comprise a generator and a discriminator, both trained under the adversarial learning idea. The goal of GANs is to estimate the potential distribution of real data samples and generate new samples from that distribution. Since their initiation, GANs have been widely studied due to their enormous prospect for applications, including image and vision computing, speech and language processing, etc. In this review paper, we summarize the state of the art of GANs and look into the future. Firstly, we survey GANs U+02BC proposal background, theoretic and implementation models, and application fields. Then, we discuss GANs U+02BC advantages and disadvantages, and their development trends. In particular, we investigate the relation between GANs and parallel intelligence, with the conclusion that GANs have a great potential in parallel systems research in terms of virtual-real interaction and integration. Clearly, GANs can provide substantial algorithmic support for parallel intelligence.",
            "referenceCount": 62,
            "citationCount": 330,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-09-15",
            "journal": {
                "name": "IEEE/CAA Journal of Automatica Sinica",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2017GenerativeAN,\n author = {Kunfeng Wang and Chao Gou and Y. Duan and Yilun Lin and Xinhu Zheng and Fei-yue Wang},\n booktitle = {IEEE/CAA Journal of Automatica Sinica},\n journal = {IEEE/CAA Journal of Automatica Sinica},\n pages = {588-598},\n title = {Generative adversarial networks: introduction and outlook},\n volume = {4},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5ed4617d39833a8dd8e931282ca2fcee136db634",
            "@type": "ScholarlyArticle",
            "paperId": "5ed4617d39833a8dd8e931282ca2fcee136db634",
            "corpusId": 7142128,
            "url": "https://www.semanticscholar.org/paper/5ed4617d39833a8dd8e931282ca2fcee136db634",
            "title": "Unsupervised Generative Modeling Using Matrix Product States",
            "venue": "Physical Review X",
            "publicationVenue": {
                "id": "urn:research:98eedf55-1e67-4c3d-a25d-79861b87ae04",
                "name": "Physical Review X",
                "alternate_names": [
                    "Phys Rev X"
                ],
                "issn": "2160-3308",
                "url": "https://journals.aps.org/prx/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2753545915",
                "DBLP": "journals/corr/abs-1709-01662",
                "ArXiv": "1709.01662",
                "DOI": "10.1103/PhysRevX.8.031012",
                "CorpusId": 7142128
            },
            "abstract": "Generative modeling, which learns joint probability distribution from data and generates samples according to it, is an important task in machine learning and artificial intelligence. Inspired by probabilistic interpretation of quantum physics, we propose a generative model using matrix product states, which is a tensor network originally proposed for describing (particularly one-dimensional) entangled quantum states. Our model enjoys efficient learning analogous to the density matrix renormalization group method, which allows dynamically adjusting dimensions of the tensors and offers an efficient direct sampling approach for generative tasks. We apply our method to generative modeling of several standard datasets including the Bars and Stripes, random binary patterns and the MNIST handwritten digits to illustrate the abilities, features and drawbacks of our model over popular generative models such as Hopfield model, Boltzmann machines and generative adversarial networks. Our work sheds light on many interesting directions of future exploration on the development of quantum-inspired algorithms for unsupervised machine learning, which are promisingly possible to be realized on quantum devices.",
            "referenceCount": 74,
            "citationCount": 220,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://link.aps.org/pdf/10.1103/PhysRevX.8.031012",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-09-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1709.01662"
            },
            "citationStyles": {
                "bibtex": "@Article{Han2017UnsupervisedGM,\n author = {Zhaoyu Han and Jun Wang and H. Fan and Lei Wang and Pan Zhang},\n booktitle = {Physical Review X},\n journal = {ArXiv},\n title = {Unsupervised Generative Modeling Using Matrix Product States},\n volume = {abs/1709.01662},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5a5a1076c3a3d4f7cbcc48a1e3f14307deec6b7a",
            "@type": "ScholarlyArticle",
            "paperId": "5a5a1076c3a3d4f7cbcc48a1e3f14307deec6b7a",
            "corpusId": 12737290,
            "url": "https://www.semanticscholar.org/paper/5a5a1076c3a3d4f7cbcc48a1e3f14307deec6b7a",
            "title": "A Deep Generative Framework for Paraphrase Generation",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2951892025",
                "DBLP": "conf/aaai/GuptaASR18",
                "ArXiv": "1709.05074",
                "DOI": "10.1609/aaai.v32i1.11956",
                "CorpusId": 12737290
            },
            "abstract": "\n \n Paraphrase generation is an important problem in NLP, especially in question answering, information retrieval, information extraction, conversation systems, to name a few. In this paper, we address the problem of generating paraphrases automatically. Our proposed method is based on a combination of deep generative models (VAE) with sequence-to-sequence models (LSTM) to generate paraphrases, given an input sentence. Traditional VAEs when combined with recurrent neural networks can generate free text but they are not suitable for paraphrase generation for a given sentence. We address this problem by conditioning the both, encoder and decoder sides of VAE, on the original sentence, so that it can generate the given sentence's paraphrases. Unlike most existing models, our model is simple, modular and can generate multiple paraphrases, for a given sentence. Quantitative evaluation of the proposed method on a benchmark paraphrase dataset demonstrates its efficacy, and its performance improvement over the state-of-the-art methods by a significant margin, whereas qualitative human evaluation indicate that the generated paraphrases are well-formed, grammatically correct, and are relevant to the input sentence. Furthermore, we evaluate our method on a newly released question paraphrase dataset, and establish a new baseline for future research.\n \n",
            "referenceCount": 36,
            "citationCount": 223,
            "influentialCitationCount": 35,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/11956/11815",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-09-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gupta2017ADG,\n author = {Ankush Gupta and Arvind Agarwal and Prawaan Singh and Piyush Rai},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {5149-5156},\n title = {A Deep Generative Framework for Paraphrase Generation},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f6a201eed70e8b48e2f60d97c98cfc8fe3b7b175",
            "@type": "ScholarlyArticle",
            "paperId": "f6a201eed70e8b48e2f60d97c98cfc8fe3b7b175",
            "corpusId": 76666188,
            "url": "https://www.semanticscholar.org/paper/f6a201eed70e8b48e2f60d97c98cfc8fe3b7b175",
            "title": "Diagnosing and Enhancing VAE Models",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1903.05789",
                "DBLP": "conf/iclr/DaiW19",
                "MAG": "2951927008",
                "CorpusId": 76666188
            },
            "abstract": "Although variational autoencoders (VAEs) represent a widely influential deep generative model, many aspects of the underlying energy function remain poorly understood. In particular, it is commonly believed that Gaussian encoder/decoder assumptions reduce the effectiveness of VAEs in generating realistic samples. In this regard, we rigorously analyze the VAE objective, differentiating situations where this belief is and is not actually true. We then leverage the corresponding insights to develop a simple VAE enhancement that requires no additional hyperparameters or sensitive tuning. Quantitatively, this proposal produces crisp samples and stable FID scores that are actually competitive with a variety of GAN models, all while retaining desirable attributes of the original VAE architecture. A shorter version of this work will appear in the ICLR 2019 conference proceedings (Dai and Wipf, 2019). The code for our model is available at this https URL TwoStageVAE.",
            "referenceCount": 45,
            "citationCount": 311,
            "influentialCitationCount": 63,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-14",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1903.05789"
            },
            "citationStyles": {
                "bibtex": "@Article{Dai2019DiagnosingAE,\n author = {B. Dai and D. Wipf},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Diagnosing and Enhancing VAE Models},\n volume = {abs/1903.05789},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:054ab6f0e392c3580a364814144babf16bd2d2dd",
            "@type": "ScholarlyArticle",
            "paperId": "054ab6f0e392c3580a364814144babf16bd2d2dd",
            "corpusId": 174798083,
            "url": "https://www.semanticscholar.org/paper/054ab6f0e392c3580a364814144babf16bd2d2dd",
            "title": "MelNet: A Generative Model for Audio in the Frequency Domain",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1906-01083",
                "MAG": "2948211236",
                "ArXiv": "1906.01083",
                "CorpusId": 174798083
            },
            "abstract": "Capturing high-level structure in audio waveforms is challenging because a single second of audio spans tens of thousands of timesteps. While long-range dependencies are difficult to model directly in the time domain, we show that they can be more tractably modelled in two-dimensional time-frequency representations such as spectrograms. By leveraging this representational advantage, in conjunction with a highly expressive probabilistic model and a multiscale generation procedure, we design a model capable of generating high-fidelity audio samples which capture structure at timescales that time-domain models have yet to achieve. We apply our model to a variety of audio generation tasks, including unconditional speech generation, music generation, and text-to-speech synthesis---showing improvements over previous approaches in both density estimates and human judgments.",
            "referenceCount": 54,
            "citationCount": 120,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-04",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1906.01083"
            },
            "citationStyles": {
                "bibtex": "@Article{Vasquez2019MelNetAG,\n author = {Sean Vasquez and M. Lewis},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {MelNet: A Generative Model for Audio in the Frequency Domain},\n volume = {abs/1906.01083},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d1c424c261c577958917055f72fb9e2ad0348865",
            "@type": "ScholarlyArticle",
            "paperId": "d1c424c261c577958917055f72fb9e2ad0348865",
            "corpusId": 6199526,
            "url": "https://www.semanticscholar.org/paper/d1c424c261c577958917055f72fb9e2ad0348865",
            "title": "PixelSNAIL: An Improved Autoregressive Generative Model",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1712.09763",
                "MAG": "2951777598",
                "DBLP": "conf/iclr/0022MRA18",
                "CorpusId": 6199526
            },
            "abstract": "Autoregressive generative models consistently achieve the best results in density estimation tasks involving high dimensional data, such as images or audio. They pose density estimation as a sequence modeling task, where a recurrent neural network (RNN) models the conditional distribution over the next element conditioned on all previous elements. In this paradigm, the bottleneck is the extent to which the RNN can model long-range dependencies, and the most successful approaches rely on causal convolutions, which offer better access to earlier parts of the sequence than conventional RNNs. Taking inspiration from recent work in meta reinforcement learning, where dealing with long-range dependencies is also essential, we introduce a new generative model architecture that combines causal convolutions with self attention. In this note, we describe the resulting model and present state-of-the-art log-likelihood results on CIFAR-10 (2.85 bits per dim) and $32 \\times 32$ ImageNet (3.80 bits per dim). Our implementation is available at this https URL",
            "referenceCount": 38,
            "citationCount": 205,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-12-28",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1712.09763"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2017PixelSNAILAI,\n author = {Xi Chen and Nikhil Mishra and Mostafa Rohaninejad and P. Abbeel},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {PixelSNAIL: An Improved Autoregressive Generative Model},\n volume = {abs/1712.09763},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:062cdcb52d52550b46c5d05f3083bfd7f494458b",
            "@type": "ScholarlyArticle",
            "paperId": "062cdcb52d52550b46c5d05f3083bfd7f494458b",
            "corpusId": 1707051,
            "url": "https://www.semanticscholar.org/paper/062cdcb52d52550b46c5d05f3083bfd7f494458b",
            "title": "Neural Decoding with Hierarchical Generative Models",
            "venue": "Neural Computation",
            "publicationVenue": {
                "id": "urn:research:69b9bcdd-8229-4a00-a6e0-00f0e99a2bf3",
                "name": "Neural Computation",
                "alternate_names": [
                    "Neural Comput"
                ],
                "issn": "0899-7667",
                "url": "http://cognet.mit.edu/library/journals/journal?issn=08997667"
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2111143847",
                "DBLP": "journals/neco/GervenLH10",
                "DOI": "10.1162/NECO_a_00047",
                "CorpusId": 1707051,
                "PubMed": "20858128"
            },
            "abstract": "Recent research has shown that reconstruction of perceived images based on hemodynamic response as measured with functional magnetic resonance imaging (fMRI) is starting to become feasible. In this letter, we explore reconstruction based on a learned hierarchy of features by employing a hierarchical generative model that consists of conditional restricted Boltzmann machines. In an unsupervised phase, we learn a hierarchy of features from data, and in a supervised phase, we learn how brain activity predicts the states of those features. Reconstruction is achieved by sampling from the model, conditioned on brain activity. We show that by using the hierarchical generative model, we can obtain good-quality reconstructions of visual images of handwritten digits presented during an fMRI scanning session.",
            "referenceCount": 42,
            "citationCount": 69,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://repository.ubn.ru.nl//bitstream/handle/2066/90034/90034.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-12-01",
            "journal": {
                "name": "Neural Computation",
                "volume": "22"
            },
            "citationStyles": {
                "bibtex": "@Article{Gerven2010NeuralDW,\n author = {M. Gerven and F. P. Lange and T. Heskes},\n booktitle = {Neural Computation},\n journal = {Neural Computation},\n pages = {3127-3142},\n title = {Neural Decoding with Hierarchical Generative Models},\n volume = {22},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0ffa423a5283396c88ff3d4033d541796bd039cc",
            "@type": "ScholarlyArticle",
            "paperId": "0ffa423a5283396c88ff3d4033d541796bd039cc",
            "corpusId": 1345,
            "url": "https://www.semanticscholar.org/paper/0ffa423a5283396c88ff3d4033d541796bd039cc",
            "title": "Three Generative, Lexicalised Models for Statistical Parsing",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 1997,
            "externalIds": {
                "MAG": "2950064328",
                "DBLP": "journals/corr/cmp-lg-9706022",
                "ArXiv": "cmp-lg/9706022",
                "ACL": "P97-1003",
                "DOI": "10.3115/976909.979620",
                "CorpusId": 1345
            },
            "abstract": "In this paper we first propose a new statistical parsing model, which is a generative model of lexicalised context-free grammar. We then extend the model to include a probabilistic treatment of both subcategorisation and wh-movement. Results on Wall Street Journal text show that the parser performs at 88.1/87.5% constituent precision/recall, an average improvement of 2.3% over (Collins 96).",
            "referenceCount": 19,
            "citationCount": 1165,
            "influentialCitationCount": 117,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/976909.979620",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1997-06-17",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Collins1997ThreeGL,\n author = {M. Collins},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {16-23},\n title = {Three Generative, Lexicalised Models for Statistical Parsing},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c7462e0ee928f095a7fc40b91f1e7557d283ae8e",
            "@type": "ScholarlyArticle",
            "paperId": "c7462e0ee928f095a7fc40b91f1e7557d283ae8e",
            "corpusId": 201666234,
            "url": "https://www.semanticscholar.org/paper/c7462e0ee928f095a7fc40b91f1e7557d283ae8e",
            "title": "Release Strategies and the Social Impacts of Language Models",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2969958763",
                "ArXiv": "1908.09203",
                "DBLP": "journals/corr/abs-1908-09203",
                "CorpusId": 201666234
            },
            "abstract": "Large language models have a range of beneficial uses: they can assist in prose, poetry, and programming; analyze dataset biases; and more. However, their flexibility and generative capabilities also raise misuse concerns. This report discusses OpenAI's work related to the release of its GPT-2 language model. It discusses staged release, which allows time between model releases to conduct risk and benefit analyses as model sizes increased. It also discusses ongoing partnership-based research and provides recommendations for better coordination and responsible publication in AI.",
            "referenceCount": 71,
            "citationCount": 305,
            "influentialCitationCount": 50,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-08-24",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1908.09203"
            },
            "citationStyles": {
                "bibtex": "@Article{Solaiman2019ReleaseSA,\n author = {Irene Solaiman and Miles Brundage and Jack Clark and Amanda Askell and Ariel Herbert-Voss and Jeff Wu and Alec Radford and Jasmine Wang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Release Strategies and the Social Impacts of Language Models},\n volume = {abs/1908.09203},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:923d8dd5d36dd5ab68aadbe2e3eecb57de88d859",
            "@type": "ScholarlyArticle",
            "paperId": "923d8dd5d36dd5ab68aadbe2e3eecb57de88d859",
            "corpusId": 5569557,
            "url": "https://www.semanticscholar.org/paper/923d8dd5d36dd5ab68aadbe2e3eecb57de88d859",
            "title": "Learning Deep Generative Models",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "DBLP": "phd/ca/Salakhutdinov10",
                "MAG": "2164700406",
                "DOI": "10.1146/ANNUREV-STATISTICS-010814-020120",
                "CorpusId": 5569557
            },
            "abstract": "Building intelligent systems that are capable of extracting high-level representations from high-dimensional sensory data lies at the core of solving many AI related tasks, including object recognition, speech perception, and language understanding. Theoretical and biological arguments strongly suggest that building such systems requires models with deep architectures that involve many layers of nonlinear processing. \nThe aim of the thesis is to demonstrate that deep generative models that contain many layers of latent variables and millions of parameters can be learned efficiently, and that the learned high-level feature representations can be successfully applied in a wide spectrum of application domains, including visual object recognition, information retrieval, and classification and regression tasks. In addition, similar methods can be used for nonlinear dimensionality reduction. \nThe first part of the thesis focuses on analysis and applications of probabilistic generative models called Deep Belief Networks. We show that these deep hierarchical models can learn useful feature representations from a large supply of unlabeled sensory inputs. The learned high-level representations capture a lot of structure in the input data, which is useful for subsequent problem-specific tasks, such as classification, regression or information retrieval, even though these tasks are unknown when the generative model is being trained. \nIn the second part of the thesis, we introduce a new learning algorithm for a different type of hierarchical probabilistic model, which we call a Deep Boltzmann Machine. Like Deep Belief Networks, Deep Boltzmann Machines have the potential of learning internal representations that become increasingly complex at higher layers, which is a promising way of solving object and speech recognition problems. Unlike Deep Belief Networks and many existing models with deep architectures, the approximate inference procedure, in addition to a fast bottom-up pass, can incorporate top-down feedback. This allows Deep Boltzmann Machines to better propagate uncertainty about ambiguous inputs.",
            "referenceCount": 119,
            "citationCount": 373,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-statistics-010814-020120",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Salakhutdinov2009LearningDG,\n author = {R. Salakhutdinov},\n pages = {361-385},\n title = {Learning Deep Generative Models},\n volume = {2},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f1bb2c95dc270ffa9c2f88e29ae5d2178b4459cb",
            "@type": "ScholarlyArticle",
            "paperId": "f1bb2c95dc270ffa9c2f88e29ae5d2178b4459cb",
            "corpusId": 32665336,
            "url": "https://www.semanticscholar.org/paper/f1bb2c95dc270ffa9c2f88e29ae5d2178b4459cb",
            "title": "A Generative Model of People in Clothing",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1705.04098",
                "DBLP": "conf/iccv/LassnerPG17",
                "MAG": "2963630103",
                "DOI": "10.1109/ICCV.2017.98",
                "CorpusId": 32665336
            },
            "abstract": "We present the first image-based generative model of people in clothing for the full body. We sidestep the commonly used complex graphics rendering pipeline and the need for high-quality 3D scans of dressed people. Instead, we learn generative models from a large image database. The main challenge is to cope with the high variance in human pose, shape and appearance. For this reason, pure image-based approaches have not been considered so far. We show that this challenge can be overcome by splitting the generating process in two parts. First, we learn to generate a semantic segmentation of the body and clothing. Second, we learn a conditional model on the resulting segments that creates realistic images. The full model is differentiable and can be conditioned on pose, shape or color. The result are samples of people in different clothing items and styles. The proposed model can generate entirely new people with realistic clothing. In several experiments we present encouraging results that suggest an entirely data-driven approach to people generation is possible.",
            "referenceCount": 57,
            "citationCount": 216,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/1705.04098",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-05-11",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lassner2017AGM,\n author = {Christoph Lassner and Gerard Pons-Moll and Peter Gehler},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2017 IEEE International Conference on Computer Vision (ICCV)},\n pages = {853-862},\n title = {A Generative Model of People in Clothing},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:41cca0b0a27ba363ca56e7033569aeb1922b0ac9",
            "@type": "ScholarlyArticle",
            "paperId": "41cca0b0a27ba363ca56e7033569aeb1922b0ac9",
            "corpusId": 52171619,
            "url": "https://www.semanticscholar.org/paper/41cca0b0a27ba363ca56e7033569aeb1922b0ac9",
            "title": "Recurrent World Models Facilitate Policy Evolution",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2953072278",
                "DBLP": "journals/corr/abs-1809-01999",
                "ArXiv": "1809.01999",
                "CorpusId": 52171619
            },
            "abstract": "A generative recurrent neural network is quickly trained in an unsupervised manner to model popular reinforcement learning environments through compressed spatio-temporal representations. The world model's extracted features are fed into compact and simple policies trained by evolution, achieving state of the art results in various environments. We also train our agent entirely inside of an environment generated by its own internal world model, and transfer this policy back into the actual environment. Interactive version of this paper is available at https://worldmodels.github.io",
            "referenceCount": 100,
            "citationCount": 679,
            "influentialCitationCount": 83,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ha2018RecurrentWM,\n author = {David R Ha and J. Schmidhuber},\n booktitle = {Neural Information Processing Systems},\n pages = {2455-2467},\n title = {Recurrent World Models Facilitate Policy Evolution},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5bfeb6901db481c08874cfe0ae807d8564513765",
            "@type": "ScholarlyArticle",
            "paperId": "5bfeb6901db481c08874cfe0ae807d8564513765",
            "corpusId": 53787096,
            "url": "https://www.semanticscholar.org/paper/5bfeb6901db481c08874cfe0ae807d8564513765",
            "title": "GuacaMol: Benchmarking Models for De Novo Molecular Design",
            "venue": "Journal of Chemical Information and Modeling",
            "publicationVenue": {
                "id": "urn:research:3f16aef5-6b9f-4f87-baca-cbf8147e352f",
                "name": "Journal of Chemical Information and Modeling",
                "alternate_names": [
                    "J Chem Inf Model"
                ],
                "issn": "1549-9596",
                "url": "http://pubs.acs.org/jcim"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/jcisd/BrownFSV19",
                "MAG": "2900694120",
                "ArXiv": "1811.09621",
                "DOI": "10.1021/acs.jcim.8b00839",
                "CorpusId": 53787096,
                "PubMed": "30887799"
            },
            "abstract": "De novo design seeks to generate molecules with required property profiles by virtual design-make-test cycles. With the emergence of deep learning and neural generative models in many application areas, models for molecular design based on neural networks appeared recently and show promising results. However, the new models have not been profiled on consistent tasks, and comparative studies to well-established algorithms have only seldom been performed. To standardize the assessment of both classical and neural models for de novo molecular design, we propose an evaluation framework, GuacaMol, based on a suite of standardized benchmarks. The benchmark tasks encompass measuring the fidelity of the models to reproduce the property distribution of the training sets, the ability to generate novel molecules, the exploration and exploitation of chemical space, and a variety of single and multiobjective optimization tasks. The benchmarking open-source Python code and a leaderboard can be found on https://benevolent.ai/guacamol .",
            "referenceCount": 97,
            "citationCount": 482,
            "influentialCitationCount": 61,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://pubs.acs.org/doi/pdf/10.1021/acs.jcim.8b00839",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Biology",
                "Physics",
                "Chemistry"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-11-22",
            "journal": {
                "name": "Journal of chemical information and modeling",
                "volume": "59 3"
            },
            "citationStyles": {
                "bibtex": "@Article{Brown2018GuacaMolBM,\n author = {Nathan Brown and Marco Fiscato and Marwin H. S. Segler and Alain C. Vaucher},\n booktitle = {Journal of Chemical Information and Modeling},\n journal = {Journal of chemical information and modeling},\n pages = {\n          1096-1108\n        },\n title = {GuacaMol: Benchmarking Models for De Novo Molecular Design},\n volume = {59 3},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e4799c21ab92421b5de95e7555ef6db923bedb0b",
            "@type": "ScholarlyArticle",
            "paperId": "e4799c21ab92421b5de95e7555ef6db923bedb0b",
            "corpusId": 47020058,
            "url": "https://www.semanticscholar.org/paper/e4799c21ab92421b5de95e7555ef6db923bedb0b",
            "title": "Stochastic Seismic Waveform Inversion Using Generative Adversarial Networks as a Geological Prior",
            "venue": "Mathematical Geosciences",
            "publicationVenue": {
                "id": "urn:research:1f92bb34-5c40-4f63-96fd-95b66eafdcb0",
                "name": "Mathematical Geosciences",
                "alternate_names": [
                    "Math Geosci"
                ],
                "issn": "1874-8953",
                "url": "http://www.springer.com/west/home/geosciences?SGWID=4-10006-70-35611658-0"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1806-03720",
                "MAG": "2987357275",
                "ArXiv": "1806.03720",
                "DOI": "10.1007/s11004-019-09832-6",
                "CorpusId": 47020058
            },
            "abstract": null,
            "referenceCount": 78,
            "citationCount": 159,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s11004-019-09832-6.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Mathematics",
                "Geology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Geology",
                    "source": "external"
                },
                {
                    "category": "Geology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-06-10",
            "journal": {
                "name": "Mathematical Geosciences",
                "volume": "52"
            },
            "citationStyles": {
                "bibtex": "@Article{Mosser2018StochasticSW,\n author = {L. Mosser and O. Dubrule and M. Blunt},\n booktitle = {Mathematical Geosciences},\n journal = {Mathematical Geosciences},\n pages = {53-79},\n title = {Stochastic Seismic Waveform Inversion Using Generative Adversarial Networks as a Geological Prior},\n volume = {52},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:39d08fa8b028217384daeb3e622848451809a422",
            "@type": "ScholarlyArticle",
            "paperId": "39d08fa8b028217384daeb3e622848451809a422",
            "corpusId": 34040907,
            "url": "https://www.semanticscholar.org/paper/39d08fa8b028217384daeb3e622848451809a422",
            "title": "Variational Approaches for Auto-Encoding Generative Adversarial Networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/RoscaLWM17",
                "ArXiv": "1706.04987",
                "MAG": "2624918875",
                "CorpusId": 34040907
            },
            "abstract": "Auto-encoding generative adversarial networks (GANs) combine the standard GAN algorithm, which discriminates between real and model-generated data, with a reconstruction loss given by an auto-encoder. Such models aim to prevent mode collapse in the learned generative model by ensuring that it is grounded in all the available training data. In this paper, we develop a principle upon which auto-encoders can be combined with generative adversarial networks by exploiting the hierarchical structure of the generative model. The underlying principle shows that variational inference can be used a basic tool for learning, but with the in- tractable likelihood replaced by a synthetic likelihood, and the unknown posterior distribution replaced by an implicit distribution; both synthetic likelihoods and implicit posterior distributions can be learned using discriminators. This allows us to develop a natural fusion of variational auto-encoders and generative adversarial networks, combining the best of both these methods. We describe a unified objective for optimization, discuss the constraints needed to guide learning, connect to the wide range of existing work, and use a battery of tests to systematically and quantitatively assess the performance of our method.",
            "referenceCount": 49,
            "citationCount": 248,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-06-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1706.04987"
            },
            "citationStyles": {
                "bibtex": "@Article{Rosca2017VariationalAF,\n author = {Mihaela Rosca and Balaji Lakshminarayanan and David Warde-Farley and S. Mohamed},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Variational Approaches for Auto-Encoding Generative Adversarial Networks},\n volume = {abs/1706.04987},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d1f6e1a666d3d87171f9f1fdc453339e6520f40c",
            "@type": "ScholarlyArticle",
            "paperId": "d1f6e1a666d3d87171f9f1fdc453339e6520f40c",
            "corpusId": 24527328,
            "url": "https://www.semanticscholar.org/paper/d1f6e1a666d3d87171f9f1fdc453339e6520f40c",
            "title": "DeLiGAN: Generative Adversarial Networks for Diverse and Limited Data",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/GurumurthySR17",
                "MAG": "2623550831",
                "ArXiv": "1706.02071",
                "DOI": "10.1109/CVPR.2017.525",
                "CorpusId": 24527328
            },
            "abstract": "A class of recent approaches for generating images, called Generative Adversarial Networks (GAN), have been used to generate impressively realistic images of objects, bedrooms, handwritten digits and a variety of other image modalities. However, typical GAN-based approaches require large amounts of training data to capture the diversity across the image modality. In this paper, we propose DeLiGAN &#x2013; a novel GAN-based architecture for diverse and limited training data scenarios. In our approach, we reparameterize the latent generative space as a mixture model and learn the mixture models parameters along with those of GAN. This seemingly simple modification to the GAN framework is surprisingly effective and results in models which enable diversity in generated samples although trained with limited data. In our work, we show that DeLiGAN can generate images of handwritten digits, objects and hand-drawn sketches, all using limited amounts of data. To quantitatively characterize intra-class diversity of generated samples, we also introduce a modified version of inception-score, a measure which has been found to correlate well with human assessment of generated samples.",
            "referenceCount": 26,
            "citationCount": 235,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1706.02071",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-06-07",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gurumurthy2017DeLiGANGA,\n author = {Swaminathan Gurumurthy and Ravi Kiran Sarvadevabhatla and R. Venkatesh Babu},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {4941-4949},\n title = {DeLiGAN: Generative Adversarial Networks for Diverse and Limited Data},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:404571933e3e87942768c9a5cde8a6285732ad6f",
            "@type": "ScholarlyArticle",
            "paperId": "404571933e3e87942768c9a5cde8a6285732ad6f",
            "corpusId": 54434517,
            "url": "https://www.semanticscholar.org/paper/404571933e3e87942768c9a5cde8a6285732ad6f",
            "title": "Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models",
            "venue": "Frontiers in Pharmacology",
            "publicationVenue": {
                "id": "urn:research:84a6a8b4-8e85-48bd-b65e-a83d83f95908",
                "name": "Frontiers in Pharmacology",
                "alternate_names": [
                    "Front Pharmacol"
                ],
                "issn": "1663-9812",
                "url": "https://www.frontiersin.org/journals/pharmacology"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2903425689",
                "PubMedCentral": "7775580",
                "DBLP": "journals/corr/abs-1811-12823",
                "ArXiv": "1811.12823",
                "DOI": "10.3389/fphar.2020.565644",
                "CorpusId": 54434517,
                "PubMed": "33390943"
            },
            "abstract": "Generative models are becoming a tool of choice for exploring the molecular space. These models learn on a large training dataset and produce novel molecular structures with similar properties. Generated structures can be utilized for virtual screening or training semi-supervized predictive models in the downstream tasks. While there are plenty of generative models, it is unclear how to compare and rank them. In this work, we introduce a benchmarking platform called Molecular Sets (MOSES) to standardize training and comparison of molecular generative models. MOSES provides training and testing datasets, and a set of metrics to evaluate the quality and diversity of generated structures. We have implemented and compared several molecular generation models and suggest to use our results as reference points for further advancements in generative chemistry research. The platform and source code are available at https://github.com/molecularsets/moses.",
            "referenceCount": 125,
            "citationCount": 400,
            "influentialCitationCount": 59,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.frontiersin.org/articles/10.3389/fphar.2020.565644/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-11-29",
            "journal": {
                "name": "Frontiers in Pharmacology",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Polykovskiy2018MolecularS,\n author = {Daniil Polykovskiy and Alexander Zhebrak and Benjam\u00edn S\u00e1nchez-Lengeling and Sergey Golovanov and Oktai Tatanov and Stanislav Belyaev and R. Kurbanov and A. Artamonov and V. Aladinskiy and M. Veselov and Artur Kadurin and S. Nikolenko and Al\u00e1n Aspuru-Guzik and A. Zhavoronkov},\n booktitle = {Frontiers in Pharmacology},\n journal = {Frontiers in Pharmacology},\n title = {Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models},\n volume = {11},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6727f574ad8b1c3763be8d58eeaf82c551aa33ef",
            "@type": "ScholarlyArticle",
            "paperId": "6727f574ad8b1c3763be8d58eeaf82c551aa33ef",
            "corpusId": 668431,
            "url": "https://www.semanticscholar.org/paper/6727f574ad8b1c3763be8d58eeaf82c551aa33ef",
            "title": "Generative and Discriminative Text Classification with Recurrent Neural Networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/YogatamaDLB17",
                "MAG": "2593887162",
                "ArXiv": "1703.01898",
                "CorpusId": 668431
            },
            "abstract": "We empirically characterize the performance of discriminative and generative LSTM models for text classification. We find that although RNN-based generative models are more powerful than their bag-of-words ancestors (e.g., they account for conditional dependencies across words in a document), they have higher asymptotic error rates than discriminatively trained RNN models. However we also find that generative models approach their asymptotic error rate more rapidly than their discriminative counterparts---the same pattern that Ng & Jordan (2001) proved holds for linear classification models that make more naive conditional independence assumptions. Building on this finding, we hypothesize that RNN-based generative classification models will be more robust to shifts in the data distribution. This hypothesis is confirmed in a series of experiments in zero-shot and continual learning settings that show that generative models substantially outperform discriminative models.",
            "referenceCount": 19,
            "citationCount": 181,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.01898"
            },
            "citationStyles": {
                "bibtex": "@Article{Yogatama2017GenerativeAD,\n author = {Dani Yogatama and Chris Dyer and Wang Ling and Phil Blunsom},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Generative and Discriminative Text Classification with Recurrent Neural Networks},\n volume = {abs/1703.01898},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c124d5c6ce8e1d423d05dff3bb9d48d1b1094310",
            "@type": "ScholarlyArticle",
            "paperId": "c124d5c6ce8e1d423d05dff3bb9d48d1b1094310",
            "corpusId": 202687607,
            "url": "https://www.semanticscholar.org/paper/c124d5c6ce8e1d423d05dff3bb9d48d1b1094310",
            "title": "A Review: Generative Adversarial Networks",
            "venue": "2019 14th IEEE Conference on Industrial Electronics and Applications (ICIEA)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2974031746",
                "DOI": "10.1109/ICIEA.2019.8833686",
                "CorpusId": 202687607
            },
            "abstract": "Deep learning has achieved great success in the field of artificial intelligence, and many deep learning models have been developed. Generative Adversarial Networks (GAN) is one of the deep learning model, which was proposed based on zero-sum game theory and has become a new research hotspot. The significance of the model variation is to obtain the data distribution through unsupervised learning and to generate more realistic/actual data. Currently, GANs have been widely studied due to the enormous application prospect, including image and vision computing, video and language processing, etc. In this paper, the background of the GAN, theoretic models and extensional variants of GANs are introduced, where the variants can further optimize the original GAN or change the basic structures. Then the typical applications of GANs are explained. Finally the existing problems of GANs are summarized and the future work of GANs models are given.",
            "referenceCount": 36,
            "citationCount": 89,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference",
                "Review"
            ],
            "publicationDate": "2019-06-01",
            "journal": {
                "name": "2019 14th IEEE Conference on Industrial Electronics and Applications (ICIEA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Gonog2019ARG,\n author = {Liang Gonog and Yimin Zhou},\n booktitle = {2019 14th IEEE Conference on Industrial Electronics and Applications (ICIEA)},\n journal = {2019 14th IEEE Conference on Industrial Electronics and Applications (ICIEA)},\n pages = {505-510},\n title = {A Review: Generative Adversarial Networks},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b3daa22ab8f6ede403c8acf842fb8a427d3c1e62",
            "@type": "ScholarlyArticle",
            "paperId": "b3daa22ab8f6ede403c8acf842fb8a427d3c1e62",
            "corpusId": 31373273,
            "url": "https://www.semanticscholar.org/paper/b3daa22ab8f6ede403c8acf842fb8a427d3c1e62",
            "title": "Synthesizing 3D Shapes via Modeling Multi-view Depth Maps and Silhouettes with Deep Generative Networks",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/cvpr/SoltaniH0KT17",
                "MAG": "2738835886",
                "DOI": "10.1109/CVPR.2017.269",
                "CorpusId": 31373273
            },
            "abstract": "We study the problem of learning generative models of 3D shapes. Voxels or 3D parts have been widely used as the underlying representations to build complex 3D shapes, however, voxel-based representations suffer from high memory requirements, and parts-based models require a large collection of cached or richly parametrized parts. We take an alternative approach: learning a generative model over multi-view depth maps or their corresponding silhouettes, and using a deterministic rendering function to produce 3D shapes from these images. A multi-view representation of shapes enables generation of 3D models with fine details, as 2D depth maps and silhouettes can be modeled at a much higher resolution than 3D voxels. Moreover, our approach naturally brings the ability to recover the underlying 3D representation from depth maps of one or a few viewpoints. Experiments show that our framework can generate 3D shapes with variations and details. We also demonstrate that our model has out-of-sample generalization power for real-world tasks with occluded objects.",
            "referenceCount": 32,
            "citationCount": 184,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dspace.mit.edu/bitstream/1721.1/126644/2/mv3d_cvpr.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-07-01",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Soltani2017Synthesizing3S,\n author = {Amir Arsalan Soltani and Haibin Huang and Jiajun Wu and Tejas D. Kulkarni and J. Tenenbaum},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {2511-2519},\n title = {Synthesizing 3D Shapes via Modeling Multi-view Depth Maps and Silhouettes with Deep Generative Networks},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:15b877e109dbbdd7f815b86cfdf60d83cb39ecda",
            "@type": "ScholarlyArticle",
            "paperId": "15b877e109dbbdd7f815b86cfdf60d83cb39ecda",
            "corpusId": 17584828,
            "url": "https://www.semanticscholar.org/paper/15b877e109dbbdd7f815b86cfdf60d83cb39ecda",
            "title": "Generative Compression",
            "venue": "Picture Coding Symposium",
            "publicationVenue": {
                "id": "urn:research:1895cbce-b62a-4d92-af03-c1ebe12540be",
                "name": "Picture Coding Symposium",
                "alternate_names": [
                    "Pict Coding Symp",
                    "PCS"
                ],
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/SanturkarBS17",
                "ArXiv": "1703.01467",
                "MAG": "2891810238",
                "DOI": "10.1109/PCS.2018.8456298",
                "CorpusId": 17584828
            },
            "abstract": "Traditional image and video compression algorithms rely on hand-crafted encoder/decoder pairs (codecs) that lack adaptability and are agnostic to the data being compressed. We describe the concept of generative compression, the compression of data using generative models, and suggest that it is a direction worth pursuing to produce more accurate and visually pleasing reconstructions at deeper compression levels for both image and video data. We also show that generative compression is orders- of-magnitude more robust to bit errors (e.g., from noisy channels) than traditional variable-length coding schemes.",
            "referenceCount": 54,
            "citationCount": 174,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dspace.mit.edu/bitstream/1721.1/125883/2/1703.01467.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-04",
            "journal": {
                "name": "2018 Picture Coding Symposium (PCS)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Santurkar2017GenerativeC,\n author = {Shibani Santurkar and D. Budden and N. Shavit},\n booktitle = {Picture Coding Symposium},\n journal = {2018 Picture Coding Symposium (PCS)},\n pages = {258-262},\n title = {Generative Compression},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7e9960952cac06593500ef91aad8aa2facdf339f",
            "@type": "ScholarlyArticle",
            "paperId": "7e9960952cac06593500ef91aad8aa2facdf339f",
            "corpusId": 53249313,
            "url": "https://www.semanticscholar.org/paper/7e9960952cac06593500ef91aad8aa2facdf339f",
            "title": "FloWaveNet : A Generative Flow for Raw Audio",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2951815739",
                "ArXiv": "1811.02155",
                "DBLP": "journals/corr/abs-1811-02155",
                "CorpusId": 53249313
            },
            "abstract": "Most modern text-to-speech architectures use a WaveNet vocoder for synthesizing high-fidelity waveform audio, but there have been limitations, such as high inference time, in its practical application due to its ancestral sampling scheme. The recently suggested Parallel WaveNet and ClariNet have achieved real-time audio synthesis capability by incorporating inverse autoregressive flow for parallel sampling. However, these approaches require a two-stage training pipeline with a well-trained teacher network and can only produce natural sound by using probability distillation along with auxiliary loss terms. We propose FloWaveNet, a flow-based generative model for raw audio synthesis. FloWaveNet requires only a single-stage training procedure and a single maximum likelihood loss, without any additional auxiliary terms, and it is inherently parallel due to the characteristics of generative flow. The model can efficiently sample raw audio in real-time, with clarity comparable to previous two-stage parallel models. The code and samples for all models, including our FloWaveNet, are publicly available.",
            "referenceCount": 17,
            "citationCount": 154,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-11-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kim2018FloWaveNetA,\n author = {Sungwon Kim and Sang-gil Lee and Jongyoon Song and Jaehyeon Kim and Sungroh Yoon},\n booktitle = {International Conference on Machine Learning},\n pages = {3370-3378},\n title = {FloWaveNet : A Generative Flow for Raw Audio},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:18c72175ddbb7d5956d180b65a96005c100f6014",
            "@type": "ScholarlyArticle",
            "paperId": "18c72175ddbb7d5956d180b65a96005c100f6014",
            "corpusId": 9234219,
            "url": "https://www.semanticscholar.org/paper/18c72175ddbb7d5956d180b65a96005c100f6014",
            "title": "From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2001,
            "externalIds": {
                "DBLP": "journals/pami/GeorghiadesBK01",
                "MAG": "2123921160",
                "DOI": "10.1109/34.927464",
                "CorpusId": 9234219
            },
            "abstract": "We present a generative appearance-based method for recognizing human faces under variation in lighting and viewpoint. Our method exploits the fact that the set of images of an object in fixed pose, but under all possible illumination conditions, is a convex cone in the space of images. Using a small number of training images of each face taken with different lighting directions, the shape and albedo of the face can be reconstructed. In turn, this reconstruction serves as a generative model that can be used to render (or synthesize) images of the face under novel poses and illumination conditions. The pose space is then sampled and, for each pose, the corresponding illumination cone is approximated by a low-dimensional linear subspace whose basis vectors are estimated using the generative model. Our recognition algorithm assigns to a test image the identity of the closest approximated illumination cone. Test results show that the method performs almost without error, except on the most extreme lighting directions.",
            "referenceCount": 86,
            "citationCount": 4966,
            "influentialCitationCount": 431,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2001-06-01",
            "journal": {
                "name": "IEEE Trans. Pattern Anal. Mach. Intell.",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Georghiades2001FromFT,\n author = {A. Georghiades and P. Belhumeur and D. Kriegman},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Trans. Pattern Anal. Mach. Intell.},\n pages = {643-660},\n title = {From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose},\n volume = {23},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:61fd252dd0e2e511739a5cfab838fa2530919d59",
            "@type": "ScholarlyArticle",
            "paperId": "61fd252dd0e2e511739a5cfab838fa2530919d59",
            "corpusId": 3356718,
            "url": "https://www.semanticscholar.org/paper/61fd252dd0e2e511739a5cfab838fa2530919d59",
            "title": "CapsuleGAN: Generative Adversarial Capsule Network",
            "venue": "ECCV Workshops",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2951588058",
                "ArXiv": "1802.06167",
                "DBLP": "conf/eccv/JaiswalA0N18",
                "DOI": "10.1007/978-3-030-11015-4_38",
                "CorpusId": 3356718
            },
            "abstract": null,
            "referenceCount": 20,
            "citationCount": 145,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1802.06167",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-17",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1802.06167"
            },
            "citationStyles": {
                "bibtex": "@Article{Jaiswal2018CapsuleGANGA,\n author = {Ayush Jaiswal and Wael AbdAlmageed and P. Natarajan},\n booktitle = {ECCV Workshops},\n journal = {ArXiv},\n title = {CapsuleGAN: Generative Adversarial Capsule Network},\n volume = {abs/1802.06167},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9c1201d36d70672a80659a169fd17035574c0b50",
            "@type": "ScholarlyArticle",
            "paperId": "9c1201d36d70672a80659a169fd17035574c0b50",
            "corpusId": 2918027,
            "url": "https://www.semanticscholar.org/paper/9c1201d36d70672a80659a169fd17035574c0b50",
            "title": "Generative communication in Linda",
            "venue": "TOPL",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1985,
            "externalIds": {
                "MAG": "2161307885",
                "DBLP": "journals/toplas/Gelernter85",
                "DOI": "10.1145/2363.2433",
                "CorpusId": 2918027
            },
            "abstract": "Generative communication is the basis of a new distributed programming langauge that is intended for systems programming in distributed settings generally and on integrated network computers in particular. It differs from previous interprocess communication models in specifying that messages be added in tuple-structured form to the computation environment, where they exist as named, independent entities until some process chooses to receive them. Generative communication results in a number of distinguishing properties in the new language, Linda, that is built around it. Linda is fully distributed in space and distributed in time; it allows distributed sharing, continuation passing, and structured naming. We discuss these properties and their implications, then give a series of examples. Linda presents novel implementation problems that we discuss in Part II. We are particularly concerned with implementation of the dynamic global name space that the generative communication model requires.",
            "referenceCount": 30,
            "citationCount": 2727,
            "influentialCitationCount": 305,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/2363.2433",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1985-01-02",
            "journal": {
                "name": "ACM Trans. Program. Lang. Syst.",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Gelernter1985GenerativeCI,\n author = {D. Gelernter},\n booktitle = {TOPL},\n journal = {ACM Trans. Program. Lang. Syst.},\n pages = {80-112},\n title = {Generative communication in Linda},\n volume = {7},\n year = {1985}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ff332c21562c87cab5891d495b7d0956f2d9228b",
            "@type": "ScholarlyArticle",
            "paperId": "ff332c21562c87cab5891d495b7d0956f2d9228b",
            "corpusId": 4807711,
            "url": "https://www.semanticscholar.org/paper/ff332c21562c87cab5891d495b7d0956f2d9228b",
            "title": "World Models",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2795843265",
                "DBLP": "journals/corr/abs-1803-10122",
                "ArXiv": "1803.10122",
                "DOI": "10.5281/zenodo.1207631",
                "CorpusId": 4807711
            },
            "abstract": "We explore building generative neural network models of popular reinforcement learning environments. Our world model can be trained quickly in an unsupervised manner to learn a compressed spatial and temporal representation of the environment. By using features extracted from the world model as inputs to an agent, we can train a very compact and simple policy that can solve the required task. We can even train our agent entirely inside of its own hallucinated dream generated by its world model, and transfer this policy back into the actual environment. An interactive version of this paper is available at https://worldmodels.github.io/",
            "referenceCount": 173,
            "citationCount": 644,
            "influentialCitationCount": 48,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/1803.10122",
                "status": "CLOSED"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-03-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1803.10122"
            },
            "citationStyles": {
                "bibtex": "@Article{Ha2018WorldM,\n author = {David R Ha and J. Schmidhuber},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {World Models},\n volume = {abs/1803.10122},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:559a52d27ff8e3ae0cdf1e7948c137ff566285c8",
            "@type": "ScholarlyArticle",
            "paperId": "559a52d27ff8e3ae0cdf1e7948c137ff566285c8",
            "corpusId": 3621348,
            "url": "https://www.semanticscholar.org/paper/559a52d27ff8e3ae0cdf1e7948c137ff566285c8",
            "title": "Inverting the Generator of a Generative Adversarial Network",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "publicationVenue": {
                "id": "urn:research:79c5a18d-0295-432c-aaa5-961d73de6d88",
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "alternate_names": [
                    "IEEE Trans Neural Netw Learn Syst"
                ],
                "issn": "2162-237X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=5962385"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1611.05644",
                "MAG": "2963105487",
                "DBLP": "journals/corr/CreswellB16b",
                "DOI": "10.1109/TNNLS.2018.2875194",
                "CorpusId": 3621348,
                "PubMed": "30403640"
            },
            "abstract": "Generative adversarial networks (GANs) learn a deep generative model that is able to synthesize novel, high-dimensional data samples. New data samples are synthesized by passing latent samples, drawn from a chosen prior distribution, through the generative model. Once trained, the latent space exhibits interesting properties that may be useful for downstream tasks such as classification or retrieval. Unfortunately, GANs do not offer an \u201cinverse model,\u201d a mapping from data space back to latent space, making it difficult to infer a latent representation for a given data sample. In this paper, we introduce a technique, inversion, to project data samples, specifically images, to the latent space using a pretrained GAN. Using our proposed inversion technique, we are able to identify which attributes of a data set a trained GAN is able to model and quantify GAN performance, based on a reconstruction loss. We demonstrate how our proposed inversion technique may be used to quantitatively compare the performance of various GAN models trained on three image data sets. We provide codes for all of our experiments in the website (https://github.com/ToniCreswell/InvertingGAN).",
            "referenceCount": 28,
            "citationCount": 292,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/5962385/8738884/08520899.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-17",
            "journal": {
                "name": "IEEE Transactions on Neural Networks and Learning Systems",
                "volume": "30"
            },
            "citationStyles": {
                "bibtex": "@Article{Creswell2016InvertingTG,\n author = {Antonia Creswell and A. Bharath},\n booktitle = {IEEE Transactions on Neural Networks and Learning Systems},\n journal = {IEEE Transactions on Neural Networks and Learning Systems},\n pages = {1967-1974},\n title = {Inverting the Generator of a Generative Adversarial Network},\n volume = {30},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2da0ccacb4931f1e89cf7febdafd23a3cff079a4",
            "@type": "ScholarlyArticle",
            "paperId": "2da0ccacb4931f1e89cf7febdafd23a3cff079a4",
            "corpusId": 7252503,
            "url": "https://www.semanticscholar.org/paper/2da0ccacb4931f1e89cf7febdafd23a3cff079a4",
            "title": "A Theory of Generative ConvNet",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/XieLZW16",
                "ArXiv": "1602.03264",
                "MAG": "2949457404",
                "CorpusId": 7252503
            },
            "abstract": "We show that a generative random field model, which we call generative ConvNet, can be derived from the commonly used discriminative ConvNet, by assuming a ConvNet for multicategory classification and assuming one of the categories is a base category generated by a reference distribution. If we further assume that the non-linearity in the ConvNet is Rectified Linear Unit (ReLU) and the reference distribution is Gaussian white noise, then we obtain a generative ConvNet model that is unique among energy-based models: The model is piecewise Gaussian, and the means of the Gaussian pieces are defined by an auto-encoder, where the filters in the bottom-up encoding become the basis functions in the top-down decoding, and the binary activation variables detected by the filters in the bottom-up convolution process become the coefficients of the basis functions in the top-down deconvolution process. The Langevin dynamics for sampling the generative ConvNet is driven by the reconstruction error of this autoencoder. The contrastive divergence learning of the generative ConvNet reconstructs the training images by the auto-encoder. The maximum likelihood learning algorithm can synthesize realistic natural image patterns.",
            "referenceCount": 46,
            "citationCount": 280,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-02-10",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1602.03264"
            },
            "citationStyles": {
                "bibtex": "@Article{Xie2016ATO,\n author = {Jianwen Xie and Yang Lu and Song-Chun Zhu and Y. Wu},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {A Theory of Generative ConvNet},\n volume = {abs/1602.03264},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4c6ffacad6b3d9ff9a7f553e78593d9dfb507229",
            "@type": "ScholarlyArticle",
            "paperId": "4c6ffacad6b3d9ff9a7f553e78593d9dfb507229",
            "corpusId": 8355505,
            "url": "https://www.semanticscholar.org/paper/4c6ffacad6b3d9ff9a7f553e78593d9dfb507229",
            "title": "CM-GANs: Cross-modal Generative Adversarial Networks for Common Representation Learning",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1710.05106",
                "MAG": "2950355382",
                "DBLP": "journals/corr/abs-1710-05106",
                "CorpusId": 8355505
            },
            "abstract": "It is known that the inconsistent distribution and representation of different modalities, such as image and text, cause the heterogeneity gap that makes it challenging to correlate such heterogeneous data. Generative adversarial networks (GANs) have shown its strong ability of modeling data distribution and learning discriminative representation, existing GANs-based works mainly focus on generative problem to generate new data. We have different goal, aim to correlate heterogeneous data, by utilizing the power of GANs to model cross-modal joint distribution. Thus, we propose Cross-modal GANs to learn discriminative common representation for bridging heterogeneity gap. The main contributions are: (1) Cross-modal GANs architecture is proposed to model joint distribution over data of different modalities. The inter-modality and intra-modality correlation can be explored simultaneously in generative and discriminative models. Both of them beat each other to promote cross-modal correlation learning. (2) Cross-modal convolutional autoencoders with weight-sharing constraint are proposed to form generative model. They can not only exploit cross-modal correlation for learning common representation, but also preserve reconstruction information for capturing semantic consistency within each modality. (3) Cross-modal adversarial mechanism is proposed, which utilizes two kinds of discriminative models to simultaneously conduct intra-modality and inter-modality discrimination. They can mutually boost to make common representation more discriminative by adversarial training process. To the best of our knowledge, our proposed CM-GANs approach is the first to utilize GANs to perform cross-modal common representation learning. Experiments are conducted to verify the performance of our proposed approach on cross-modal retrieval paradigm, compared with 10 methods on 3 cross-modal datasets.",
            "referenceCount": 46,
            "citationCount": 220,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-14",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1710.05106"
            },
            "citationStyles": {
                "bibtex": "@Article{Peng2017CMGANsCG,\n author = {Yuxin Peng and Jinwei Qi and Yuxin Yuan},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {CM-GANs: Cross-modal Generative Adversarial Networks for Common Representation Learning},\n volume = {abs/1710.05106},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2cc7cd57349e271f5970e423fca4b1dbf06d7006",
            "@type": "ScholarlyArticle",
            "paperId": "2cc7cd57349e271f5970e423fca4b1dbf06d7006",
            "corpusId": 54062141,
            "url": "https://www.semanticscholar.org/paper/2cc7cd57349e271f5970e423fca4b1dbf06d7006",
            "title": "Generative modeling for protein structures",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2891185006",
                "DBLP": "conf/nips/AnandH18",
                "CorpusId": 54062141
            },
            "abstract": "Analyzing the structure and function of proteins is a key part of understanding biology at the molecular and cellular level. In addition, a major engineering challenge is to design new proteins in a principled and methodical way. Current computational modeling methods for protein design are slow and often require human oversight and intervention. Here, we apply Generative Adversarial Networks (GANs) to the task of generating protein structures, toward application in fast de novo protein design. We encode protein structures in terms of pairwise distances between alpha-carbons on the protein backbone, which eliminates the need for the generative model to learn translational and rotational symmetries. We then introduce a convex formulation of corruption-robust 3D structure recovery to fold the protein structures from generated pairwise distance maps, and solve these problems using the Alternating Direction Method of Multipliers. We test the effectiveness of our models by predicting completions of corrupted protein structures and show that the method is capable of quickly producing structurally plausible solutions.",
            "referenceCount": 44,
            "citationCount": 129,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Anand2018GenerativeMF,\n author = {N. Anand and Po-Ssu Huang},\n booktitle = {Neural Information Processing Systems},\n pages = {7505-7516},\n title = {Generative modeling for protein structures},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:60b3fb579734593ebedaa177569052e90a778009",
            "@type": "ScholarlyArticle",
            "paperId": "60b3fb579734593ebedaa177569052e90a778009",
            "corpusId": 2581941,
            "url": "https://www.semanticscholar.org/paper/60b3fb579734593ebedaa177569052e90a778009",
            "title": "Texture Synthesis with Spatial Generative Adversarial Networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/JetchevBV16",
                "ArXiv": "1611.08207",
                "MAG": "2557969682",
                "CorpusId": 2581941
            },
            "abstract": "Generative adversarial networks (GANs) are a recent approach to train generative models of data, which have been shown to work particularly well on image data. In the current paper we introduce a new model for texture synthesis based on GAN learning. By extending the input noise distribution space from a single vector to a whole spatial tensor, we create an architecture with properties well suited to the task of texture synthesis, which we call spatial GAN (SGAN). To our knowledge, this is the first successful completely data-driven texture synthesis method based on GANs. \nOur method has the following features which make it a state of the art algorithm for texture synthesis: high image quality of the generated textures, very high scalability w.r.t. the output texture size, fast real-time forward generation, the ability to fuse multiple diverse source images in complex textures. To illustrate these capabilities we present multiple experiments with different classes of texture images and use cases. We also discuss some limitations of our method with respect to the types of texture images it can synthesize, and compare it to other neural techniques for texture generation.",
            "referenceCount": 20,
            "citationCount": 188,
            "influentialCitationCount": 25,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-24",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1611.08207"
            },
            "citationStyles": {
                "bibtex": "@Article{Jetchev2016TextureSW,\n author = {Nikolay Jetchev and Urs M. Bergmann and Roland Vollgraf},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Texture Synthesis with Spatial Generative Adversarial Networks},\n volume = {abs/1611.08207},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dfedad21048cafdb7066cd2caeba13228e83d4eb",
            "@type": "ScholarlyArticle",
            "paperId": "dfedad21048cafdb7066cd2caeba13228e83d4eb",
            "corpusId": 1978269,
            "url": "https://www.semanticscholar.org/paper/dfedad21048cafdb7066cd2caeba13228e83d4eb",
            "title": "Structured Generative Models for Unsupervised Named-Entity Clustering",
            "venue": "North American Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:01103732-3808-4930-b8e4-7e9e68d5c68d",
                "name": "North American Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "North Am Chapter Assoc Comput Linguistics",
                    "NAACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/naacl"
            },
            "year": 2009,
            "externalIds": {
                "ACL": "N09-1019",
                "MAG": "2004353685",
                "DBLP": "conf/naacl/ElsnerCJ09",
                "DOI": "10.3115/1620754.1620778",
                "CorpusId": 1978269
            },
            "abstract": "We describe a generative model for clustering named entities which also models named entity internal structure, clustering related words by role. The model is entirely unsupervised; it uses features from the named entity itself and its syntactic context, and coreference information from an unsupervised pronoun resolver. The model scores 86% on the MUC-7 named-entity dataset. To our knowledge, this is the best reported score for a fully unsupervised model, and the best score for a generative model.",
            "referenceCount": 25,
            "citationCount": 54,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2009-05-31",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Elsner2009StructuredGM,\n author = {M. Elsner and Eugene Charniak and Mark Johnson},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {164-172},\n title = {Structured Generative Models for Unsupervised Named-Entity Clustering},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c81938cbb131a45909b9150c972fb2893385254c",
            "@type": "ScholarlyArticle",
            "paperId": "c81938cbb131a45909b9150c972fb2893385254c",
            "corpusId": 13718428,
            "url": "https://www.semanticscholar.org/paper/c81938cbb131a45909b9150c972fb2893385254c",
            "title": "A Non-Parametric Generative Model for Human Trajectories",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2808478781",
                "DBLP": "conf/ijcai/OuyangSRY18",
                "DOI": "10.24963/ijcai.2018/530",
                "CorpusId": 13718428
            },
            "abstract": "Modeling human mobility and synthesizing realistic trajectories play a fundamental role in urban planning and privacy-preserving location data analysis.\u00a0 Due to its high dimensionality and also the diversity of its applications, existing trajectory generative models do not preserve the geometric (and more importantly) semantic features of human mobility, especially for longer trajectories. In this paper, we propose and evaluate a novel non-parametric generative model for location trajectories that tries to capture the statistical features of human mobility {\\em as a whole}.\u00a0 This is in contrast with existing models that generate trajectories in a sequential manner.\u00a0 We design a new representation of locations, and use generative adversarial networks to produce data points in that representation space which will be then transformed to a time-series location trajectory form.\u00a0 We evaluate our method on realistic location trajectories and compare our synthetic traces with multiple existing methods on how they preserve geographic and semantic features of real traces at both aggregated and individual levels.\u00a0 The empirical results prove the capability of our model in preserving the utility of real data.",
            "referenceCount": 22,
            "citationCount": 75,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.ijcai.org/proceedings/2018/0530.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-07-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ouyang2018ANG,\n author = {Kun Ouyang and R. Shokri and David S. Rosenblum and Wenzhuo Yang},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {3812-3817},\n title = {A Non-Parametric Generative Model for Human Trajectories},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:26c23e4af1b6a430abc94e5bf27199d10a0d2cde",
            "@type": "ScholarlyArticle",
            "paperId": "26c23e4af1b6a430abc94e5bf27199d10a0d2cde",
            "corpusId": 8530869,
            "url": "https://www.semanticscholar.org/paper/26c23e4af1b6a430abc94e5bf27199d10a0d2cde",
            "title": "Topic Significance Ranking of LDA Generative Models",
            "venue": "ECML/PKDD",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "DBLP": "conf/pkdd/AlSumaitBGD09",
                "MAG": "1831355885",
                "DOI": "10.1007/978-3-642-04180-8_22",
                "CorpusId": 8530869
            },
            "abstract": null,
            "referenceCount": 11,
            "citationCount": 172,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2F978-3-642-04180-8_22.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-08-30",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{AlSumait2009TopicSR,\n author = {Loulwah AlSumait and Daniel Barbar\u00e1 and J. Gentle and C. Domeniconi},\n booktitle = {ECML/PKDD},\n pages = {67-82},\n title = {Topic Significance Ranking of LDA Generative Models},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8ea9093542075bd8cc4928a4c671a95f363c61ef",
            "@type": "ScholarlyArticle",
            "paperId": "8ea9093542075bd8cc4928a4c671a95f363c61ef",
            "corpusId": 4656694,
            "url": "https://www.semanticscholar.org/paper/8ea9093542075bd8cc4928a4c671a95f363c61ef",
            "title": "Sliced-Wasserstein Autoencoder: An Embarrassingly Simple Generative Model",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2795671189",
                "DBLP": "journals/corr/abs-1804-01947",
                "ArXiv": "1804.01947",
                "CorpusId": 4656694
            },
            "abstract": "In this paper we study generative modeling via autoencoders while using the elegant geometric properties of the optimal transport (OT) problem and the Wasserstein distances. We introduce Sliced-Wasserstein Autoencoders (SWAE), which are generative models that enable one to shape the distribution of the latent space into any samplable probability distribution without the need for training an adversarial network or defining a closed-form for the distribution. In short, we regularize the autoencoder loss with the sliced-Wasserstein distance between the distribution of the encoded training samples and a predefined samplable distribution. We show that the proposed formulation has an efficient numerical solution that provides similar capabilities to Wasserstein Autoencoders (WAE) and Variational Autoencoders (VAE), while benefiting from an embarrassingly simple implementation.",
            "referenceCount": 41,
            "citationCount": 74,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1804.01947"
            },
            "citationStyles": {
                "bibtex": "@Article{Kolouri2018SlicedWassersteinAA,\n author = {Soheil Kolouri and Charles E. Martin and G. Rohde},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Sliced-Wasserstein Autoencoder: An Embarrassingly Simple Generative Model},\n volume = {abs/1804.01947},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:50577b1a6aa575f401bce336e015e7a4eaf7edcb",
            "@type": "ScholarlyArticle",
            "paperId": "50577b1a6aa575f401bce336e015e7a4eaf7edcb",
            "corpusId": 52911314,
            "url": "https://www.semanticscholar.org/paper/50577b1a6aa575f401bce336e015e7a4eaf7edcb",
            "title": "Generative Ensembles for Robust Anomaly Detection",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1810.01392",
                "DBLP": "journals/corr/abs-1810-01392",
                "MAG": "2895363208",
                "CorpusId": 52911314
            },
            "abstract": "Deep generative models are capable of learning probability distributions over large, high-dimensional datasets such as images, video and natural language. Generative models trained on samples from $p(x)$ ought to assign low likelihoods to out-of-distribution (OoD) samples from $q(x)$, making them suitable for anomaly detection applications. We show that in practice, likelihood models are themselves susceptible to OoD errors, and even assign large likelihoods to images from other natural datasets. To mitigate these issues, we propose Generative Ensembles, a model-independent technique for OoD detection that combines density-based anomaly detection with uncertainty estimation. Our method outperforms ODIN and VIB baselines on image datasets, and achieves comparable performance to a classification model on the Kaggle Credit Fraud dataset.",
            "referenceCount": 27,
            "citationCount": 76,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-10-02",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1810.01392"
            },
            "citationStyles": {
                "bibtex": "@Article{Choi2018GenerativeEF,\n author = {Hyun-Jae Choi and Eric Jang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Generative Ensembles for Robust Anomaly Detection},\n volume = {abs/1810.01392},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8fb76c7963ac36e1bdfcc996d99dd9245827e0dc",
            "@type": "ScholarlyArticle",
            "paperId": "8fb76c7963ac36e1bdfcc996d99dd9245827e0dc",
            "corpusId": 4865465,
            "url": "https://www.semanticscholar.org/paper/8fb76c7963ac36e1bdfcc996d99dd9245827e0dc",
            "title": "Few-shot Generative Modelling with Generative Matching Networks",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2799251726",
                "DBLP": "conf/aistats/BartunovV18",
                "CorpusId": 4865465
            },
            "abstract": "Despite recent advances, the remaining bottlenecks in deep generative models are necessity of extensive training and difficulties with generalization from small number of training examples. We develop a new generative model called Generative Matching Network which is inspired by the recently proposed matching networks for one-shot learning in discriminative tasks. By conditioning on the additional input dataset, our model can instantly learn new concepts that were not available in the training data but conform to a similar generative process. The proposed framework does not explicitly restrict diversity of the conditioning data and also does not require an extensive inference procedure for training or adaptation. Our experiments on the Omniglot dataset demonstrate that Generative Matching Networks significantly improve predictive performance on the fly as more additional data is available and outperform existing state of the art conditional generative models.",
            "referenceCount": 26,
            "citationCount": 74,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-03-31",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bartunov2018FewshotGM,\n author = {Sergey Bartunov and D. Vetrov},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n pages = {670-678},\n title = {Few-shot Generative Modelling with Generative Matching Networks},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ba6f8e536f0893eb76dc244a714859a97a7978cf",
            "@type": "ScholarlyArticle",
            "paperId": "ba6f8e536f0893eb76dc244a714859a97a7978cf",
            "corpusId": 19142960,
            "url": "https://www.semanticscholar.org/paper/ba6f8e536f0893eb76dc244a714859a97a7978cf",
            "title": "Binary Generative Adversarial Networks for Image Retrieval",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1708.04150",
                "DBLP": "conf/aaai/SongHGXHS18",
                "MAG": "2950791151",
                "DOI": "10.1609/aaai.v32i1.11276",
                "CorpusId": 19142960
            },
            "abstract": "\n \n The most striking successes in image retrieval using deep hashing have mostly involved discriminative models, which require labels. In this paper, we use binary generative adversarial networks (BGAN) to embed images to binary codes in an unsupervised way. By restricting the input noise variable of generative adversarial networks (GAN) to be binary and conditioned on the features of each input image, BGAN can simultaneously learn a binary representation per image, and generate an image plausibly similar to the original one. In the proposed framework, we address two main problems: 1) how to directly generate binary codes without relaxation? 2) how to equip the binary representation with the ability of accurate image retrieval? We resolve these problems by proposing new sign-activation strategy and a loss function steering the learning process, which consists of new models for adversarial loss, a content loss, and a neighborhood structure loss. Experimental results on standard datasets (CIFAR-10, NUSWIDE, and Flickr) demonstrate that our BGAN significantly outperforms existing hashing methods by up to 107% in terms of mAP (See Table 2).\n \n",
            "referenceCount": 58,
            "citationCount": 167,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/11276/11135",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-08-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Song2017BinaryGA,\n author = {Jingkuan Song},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {394-401},\n title = {Binary Generative Adversarial Networks for Image Retrieval},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8e6853c68479ac8e76a875dd829e3c4b61221c9c",
            "@type": "ScholarlyArticle",
            "paperId": "8e6853c68479ac8e76a875dd829e3c4b61221c9c",
            "corpusId": 42279841,
            "url": "https://www.semanticscholar.org/paper/8e6853c68479ac8e76a875dd829e3c4b61221c9c",
            "title": "Continual Learning in Generative Adversarial Nets",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1705.08395",
                "MAG": "2619508703",
                "DBLP": "journals/corr/SeffBSL17",
                "CorpusId": 42279841
            },
            "abstract": "Developments in deep generative models have allowed for tractable learning of high-dimensional data distributions. While the employed learning procedures typically assume that training data is drawn i.i.d. from the distribution of interest, it may be desirable to model distinct distributions which are observed sequentially, such as when different classes are encountered over time. Although conditional variations of deep generative models permit multiple distributions to be modeled by a single network in a disentangled fashion, they are susceptible to catastrophic forgetting when the distributions are encountered sequentially. In this paper, we adapt recent work in reducing catastrophic forgetting to the task of training generative adversarial networks on a sequence of distinct distributions, enabling continual generative modeling.",
            "referenceCount": 19,
            "citationCount": 119,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-05-23",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1705.08395"
            },
            "citationStyles": {
                "bibtex": "@Article{Seff2017ContinualLI,\n author = {Ari Seff and Alex Beatson and Daniel Suo and Han Liu},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Continual Learning in Generative Adversarial Nets},\n volume = {abs/1705.08395},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0e4a97a0ccbf699272e3d6dc25b6fe16eb35382d",
            "@type": "ScholarlyArticle",
            "paperId": "0e4a97a0ccbf699272e3d6dc25b6fe16eb35382d",
            "corpusId": 17206794,
            "url": "https://www.semanticscholar.org/paper/0e4a97a0ccbf699272e3d6dc25b6fe16eb35382d",
            "title": "How (not) to Train your Generative Model: Scheduled Sampling, Likelihood, Adversary?",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/Huszar15",
                "ArXiv": "1511.05101",
                "MAG": "2174424190",
                "CorpusId": 17206794
            },
            "abstract": "Modern applications and progress in deep learning research have created renewed interest for generative models of text and of images. However, even today it is unclear what objective functions one should use to train and evaluate these models. In this paper we present two contributions. \nFirstly, we present a critique of scheduled sampling, a state-of-the-art training method that contributed to the winning entry to the MSCOCO image captioning benchmark in 2015. Here we show that despite this impressive empirical performance, the objective function underlying scheduled sampling is improper and leads to an inconsistent learning algorithm. \nSecondly, we revisit the problems that scheduled sampling was meant to address, and present an alternative interpretation. We argue that maximum likelihood is an inappropriate training objective when the end-goal is to generate natural-looking samples. We go on to derive an ideal objective function to use in this situation instead. We introduce a generalisation of adversarial training, and show how such method can interpolate between maximum likelihood training and our ideal training objective. To our knowledge this is the first theoretical analysis that explains why adversarial training tends to produce samples with higher perceived quality.",
            "referenceCount": 24,
            "citationCount": 269,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-11-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1511.05101"
            },
            "citationStyles": {
                "bibtex": "@Article{Husz\u00e1r2015HowT,\n author = {Ferenc Husz\u00e1r},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {How (not) to Train your Generative Model: Scheduled Sampling, Likelihood, Adversary?},\n volume = {abs/1511.05101},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2055f44a4b358ff55b131f2b8ea630f4242d16c1",
            "@type": "ScholarlyArticle",
            "paperId": "2055f44a4b358ff55b131f2b8ea630f4242d16c1",
            "corpusId": 16178966,
            "url": "https://www.semanticscholar.org/paper/2055f44a4b358ff55b131f2b8ea630f4242d16c1",
            "title": "Generative Poisoning Attack Method Against Neural Networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1703.01340",
                "MAG": "2591602089",
                "DBLP": "journals/corr/YangWLC17",
                "CorpusId": 16178966
            },
            "abstract": "Poisoning attack is identified as a severe security threat to machine learning algorithms. In many applications, for example, deep neural network (DNN) models collect public data as the inputs to perform re-training, where the input data can be poisoned. Although poisoning attack against support vector machines (SVM) has been extensively studied before, there is still very limited knowledge about how such attack can be implemented on neural networks (NN), especially DNNs. In this work, we first examine the possibility of applying traditional gradient-based method (named as the direct gradient method) to generate poisoned data against NNs by leveraging the gradient of the target model w.r.t. the normal data. We then propose a generative method to accelerate the generation rate of the poisoned data: an auto-encoder (generator) used to generate poisoned data is updated by a reward function of the loss, and the target NN model (discriminator) receives the poisoned data to calculate the loss w.r.t. the normal data. Our experiment results show that the generative method can speed up the poisoned data generation rate by up to 239.38x compared with the direct gradient method, with slightly lower model accuracy degradation. A countermeasure is also designed to detect such poisoning attack methods by checking the loss of the target model.",
            "referenceCount": 19,
            "citationCount": 179,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-03",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.01340"
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2017GenerativePA,\n author = {Chaofei Yang and Qing Wu and Hai Helen Li and Yiran Chen},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Generative Poisoning Attack Method Against Neural Networks},\n volume = {abs/1703.01340},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:55fabc291f3bbbe0e35b5a0928d876af7f718e8f",
            "@type": "ScholarlyArticle",
            "paperId": "55fabc291f3bbbe0e35b5a0928d876af7f718e8f",
            "corpusId": 28639153,
            "url": "https://www.semanticscholar.org/paper/55fabc291f3bbbe0e35b5a0928d876af7f718e8f",
            "title": "A Generative Model of Urban Activities from Cellular Data",
            "venue": "IEEE transactions on intelligent transportation systems (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2617955281",
                "DBLP": "journals/tits/YinSFPP18",
                "DOI": "10.1109/TITS.2017.2695438",
                "CorpusId": 28639153
            },
            "abstract": "Activity-based travel demand models are becoming essential tools used in transportation planning and regional development scenario evaluation. They describe travel itineraries of individual travelers, namely, what activities they are participating in, when they perform these activities, and how they choose to travel to the activity locales. However, data collection for activity-based models is performed through travel surveys that are infrequent, expensive, and reflect the changes in transportation with significant delays. Thanks to the ubiquitous cell phone data, we see an opportunity to substantially complement these surveys with data extracted from network carrier mobile phone usage logs, such as call detail records (CDRs). In this paper, we develop input\u2013output hidden Markov models to infer travelers\u2019 activity patterns from CDRs. We apply the model to the data collected by a major network carrier serving millions of users in the San Francisco Bay Area. Our approach delivers an end-to-end actionable solution to the practitioners in the form of a modular and interpretable activity-based travel demand model. It is experimentally validated with three independent data sources: aggregated statistics from travel surveys, a set of collected ground truth activities, and the results of a traffic micro-simulation informed with the travel plans synthesized from the developed generative model.",
            "referenceCount": 34,
            "citationCount": 117,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "IEEE Transactions on Intelligent Transportation Systems",
                "volume": "19"
            },
            "citationStyles": {
                "bibtex": "@Article{Yin2018AGM,\n author = {Mogeng Yin and M. Sheehan and Sidney A. Feygin and Jean-Fran\u00e7ois Paiement and A. Pozdnoukhov},\n booktitle = {IEEE transactions on intelligent transportation systems (Print)},\n journal = {IEEE Transactions on Intelligent Transportation Systems},\n pages = {1682-1696},\n title = {A Generative Model of Urban Activities from Cellular Data},\n volume = {19},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5969e24ce27042ef0b791678f4d5de667f25d19f",
            "@type": "ScholarlyArticle",
            "paperId": "5969e24ce27042ef0b791678f4d5de667f25d19f",
            "corpusId": 119474793,
            "url": "https://www.semanticscholar.org/paper/5969e24ce27042ef0b791678f4d5de667f25d19f",
            "title": "Fast and Accurate Simulation of Particle Detectors Using Generative Adversarial Networks",
            "venue": "Computing and Software for Big Science",
            "publicationVenue": {
                "id": "urn:research:3a6a506a-7577-4f58-be4a-b4f786c2b892",
                "name": "Computing and Software for Big Science",
                "alternate_names": [
                    "Comput Softw Big Sci"
                ],
                "issn": "2510-2044",
                "url": "https://link.springer.com/journal/41781"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "3105731993",
                "ArXiv": "1805.00850",
                "DOI": "10.1007/s41781-018-0015-y",
                "CorpusId": 119474793
            },
            "abstract": null,
            "referenceCount": 45,
            "citationCount": 80,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1805.00850",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-05-02",
            "journal": {
                "name": "Computing and Software for Big Science",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Musella2018FastAA,\n author = {P. Musella and F. Pandolfi},\n booktitle = {Computing and Software for Big Science},\n journal = {Computing and Software for Big Science},\n title = {Fast and Accurate Simulation of Particle Detectors Using Generative Adversarial Networks},\n volume = {2},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:28121cd9150250fe51de62521065c7e2246a73e9",
            "@type": "ScholarlyArticle",
            "paperId": "28121cd9150250fe51de62521065c7e2246a73e9",
            "corpusId": 46753149,
            "url": "https://www.semanticscholar.org/paper/28121cd9150250fe51de62521065c7e2246a73e9",
            "title": "Blind Image Deconvolution Using Deep Generative Priors",
            "venue": "IEEE Transactions on Computational Imaging",
            "publicationVenue": {
                "id": "urn:research:f2b47cba-3a35-4bd0-9e7e-fd2b23338309",
                "name": "IEEE Transactions on Computational Imaging",
                "alternate_names": [
                    "IEEE Trans Comput Imaging"
                ],
                "issn": "2333-9403",
                "url": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6745852"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1802.04073",
                "DBLP": "journals/tci/AsimSA20",
                "MAG": "3096647320",
                "DOI": "10.1109/TCI.2020.3032671",
                "CorpusId": 46753149
            },
            "abstract": "This article proposes a novel approach to regularize the ill-posed and non-linear blind image deconvolution (blind deblurring) using deep generative networks as priors. We employ two separate pretrained generative networks \u2014 given lower-dimensional Gaussian vectors as input, one of the generative models samples from the distribution of sharp images, while the other from that of the blur kernels. To deblur, we find a sharp image and a blur kernel in the range of the respective generators that best explain the blurred image. Our experiments show promising deblurring results on images even under large blurs, and heavy measurement noise. Generative models often manifest a representation error to fit arbitrary samples from the learned distribution. This may be due to multiple factors such as mode collapse, architectural choices, or training caveats. To improve the generalizability of the proposed approach, we present a modification of the proposed scheme that governs the deblurring process under both generative, and classical priors. Training generative models is computationally expensive on larger and more diverse image datasets. Our experiments also show that even an untrained structured (convolutional) network acts as an image prior. We leverage this fact to deblur diverse/complex images for which a trained generative network might not be available.",
            "referenceCount": 66,
            "citationCount": 70,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1802.04073",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-12",
            "journal": {
                "name": "IEEE Transactions on Computational Imaging",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Asim2018BlindID,\n author = {Muhammad Asim and Fahad Shamshad and Ali Ahmed},\n booktitle = {IEEE Transactions on Computational Imaging},\n journal = {IEEE Transactions on Computational Imaging},\n pages = {1493-1506},\n title = {Blind Image Deconvolution Using Deep Generative Priors},\n volume = {6},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:807e421679d4a9d629d2fad1f60f28787dca60e7",
            "@type": "ScholarlyArticle",
            "paperId": "807e421679d4a9d629d2fad1f60f28787dca60e7",
            "corpusId": 15164488,
            "url": "https://www.semanticscholar.org/paper/807e421679d4a9d629d2fad1f60f28787dca60e7",
            "title": "Semi-Supervised QA with Generative Domain-Adaptive Nets",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963938442",
                "DBLP": "journals/corr/YangHSC17",
                "ArXiv": "1702.02206",
                "ACL": "P17-1096",
                "DOI": "10.18653/v1/P17-1096",
                "CorpusId": 15164488
            },
            "abstract": "We study the problem of semi-supervised question answering\u2014utilizing unlabeled text to boost the performance of question answering models. We propose a novel training framework, the Generative Domain-Adaptive Nets. In this framework, we train a generative model to generate questions based on the unlabeled text, and combine model-generated questions with human-generated questions for training question answering models. We develop novel domain adaptation algorithms, based on reinforcement learning, to alleviate the discrepancy between the model-generated data distribution and the human-generated data distribution. Experiments show that our proposed framework obtains substantial improvement from unlabeled text.",
            "referenceCount": 47,
            "citationCount": 145,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/P17-1096.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-02-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2017SemiSupervisedQW,\n author = {Zhilin Yang and Junjie Hu and R. Salakhutdinov and William W. Cohen},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1040-1050},\n title = {Semi-Supervised QA with Generative Domain-Adaptive Nets},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7f040fe8c563e7e3fb358f234e05282b57a9ca6e",
            "@type": "ScholarlyArticle",
            "paperId": "7f040fe8c563e7e3fb358f234e05282b57a9ca6e",
            "corpusId": 13354644,
            "url": "https://www.semanticscholar.org/paper/7f040fe8c563e7e3fb358f234e05282b57a9ca6e",
            "title": "Global Guarantees for Enforcing Deep Generative Priors by Empirical Risk",
            "venue": "IEEE Transactions on Information Theory",
            "publicationVenue": {
                "id": "urn:research:748e730b-add9-47ee-819d-8ae54e504ef9",
                "name": "IEEE Transactions on Information Theory",
                "alternate_names": [
                    "IEEE Trans Inf Theory"
                ],
                "issn": "0018-9448",
                "url": "http://www.comm.utoronto.ca/trans-it/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1705.07576",
                "MAG": "2967360854",
                "DBLP": "conf/colt/HandV18",
                "DOI": "10.1109/TIT.2019.2935447",
                "CorpusId": 13354644
            },
            "abstract": "We examine the theoretical properties of enforcing priors provided by generative deep neural networks via empirical risk minimization. In particular we consider two models, one in which the task is to invert a generative neural network given access to its last layer and another in which the task is to invert a generative neural network given only compressive linear observations of its last layer. We establish that in both cases, in suitable regimes of network layer sizes and a randomness assumption on the network weights, that the non-convex objective function given by empirical risk minimization does not have any spurious stationary points. That is, we establish that with high probability, at any point away from small neighborhoods around two scalar multiples of the desired solution, there is a descent direction. Hence, there are no local minima, saddle points, or other stationary points outside these neighborhoods. These results constitute the first theoretical guarantees which establish the favorable global geometry of these non-convex optimization problems, and they bridge the gap between the empirical success of enforcing deep generative priors and a rigorous understanding of non-linear inverse problems.",
            "referenceCount": 76,
            "citationCount": 132,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-05-22",
            "journal": {
                "name": "IEEE Transactions on Information Theory",
                "volume": "66"
            },
            "citationStyles": {
                "bibtex": "@Article{Hand2017GlobalGF,\n author = {Paul Hand and V. Voroninski},\n booktitle = {IEEE Transactions on Information Theory},\n journal = {IEEE Transactions on Information Theory},\n pages = {401-418},\n title = {Global Guarantees for Enforcing Deep Generative Priors by Empirical Risk},\n volume = {66},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:48911cd2ce8bc3e2ad9b2775a3758645e90edc22",
            "@type": "ScholarlyArticle",
            "paperId": "48911cd2ce8bc3e2ad9b2775a3758645e90edc22",
            "corpusId": 2714099,
            "url": "https://www.semanticscholar.org/paper/48911cd2ce8bc3e2ad9b2775a3758645e90edc22",
            "title": "Differentially Private Mixture of Generative Neural Networks",
            "venue": "Industrial Conference on Data Mining",
            "publicationVenue": {
                "id": "urn:research:67d15a94-d523-4b5f-be58-03fe2ef9dcfb",
                "name": "Industrial Conference on Data Mining",
                "alternate_names": [
                    "Ind Conf Data Min",
                    "ICDM"
                ],
                "issn": null,
                "url": "http://www.data-mining-forum.de/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/abs-1709-04514",
                "MAG": "2952015308",
                "ArXiv": "1709.04514",
                "DOI": "10.1109/ICDM.2017.81",
                "CorpusId": 2714099
            },
            "abstract": "Generative models are used in an increasing number of applications that rely on large amounts of contextually rich information about individuals. Owing to possible privacy violations, however, publishing or sharing generative models is not always viable. In this paper, we introduce a novel solution for privately releasing generative models and entire high-dimensional datasets produced by these models. We model the generator distribution of the training data by a mixture of k generative neural networks. These are trained together and collectively learn the generator distribution of a dataset. Data is divided into k clusters, using a novel differentially private kernel k-means, then each cluster is given to separate generative neural networks, such as Restricted Boltzmann Machines or Variational Autoencoders, which are trained only on their own cluster using differentially private gradient descent. We evaluate our approach using the MNIST dataset and a large Call Detail Records dataset, showing that it produces realistic synthetic samples, which can also be used to accurately compute arbitrary number of counting queries.",
            "referenceCount": 62,
            "citationCount": 108,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1709.04514",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-09-13",
            "journal": {
                "name": "2017 IEEE International Conference on Data Mining (ICDM)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{\u00c1cs2017DifferentiallyPM,\n author = {G. \u00c1cs and Luca Melis and C. Castelluccia and Emiliano De Cristofaro},\n booktitle = {Industrial Conference on Data Mining},\n journal = {2017 IEEE International Conference on Data Mining (ICDM)},\n pages = {715-720},\n title = {Differentially Private Mixture of Generative Neural Networks},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:79815f31f42708fd59da345f8fa79f635a070730",
            "@type": "ScholarlyArticle",
            "paperId": "79815f31f42708fd59da345f8fa79f635a070730",
            "corpusId": 49212449,
            "url": "https://www.semanticscholar.org/paper/79815f31f42708fd59da345f8fa79f635a070730",
            "title": "Autoregressive Quantile Networks for Generative Modeling",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/icml/OstrovskiDM18",
                "MAG": "2950388961",
                "ArXiv": "1806.05575",
                "CorpusId": 49212449
            },
            "abstract": "We introduce autoregressive implicit quantile networks (AIQN), a fundamentally different approach to generative modeling than those commonly used, that implicitly captures the distribution using quantile regression. AIQN is able to achieve superior perceptual quality and improvements in evaluation metrics, without incurring a loss of sample diversity. The method can be applied to many existing models and architectures. In this work we extend the PixelCNN model with AIQN and demonstrate results on CIFAR-10 and ImageNet using Inception score, FID, non-cherry-picked samples, and inpainting results. We consistently observe that AIQN yields a highly stable algorithm that improves perceptual quality while maintaining a highly diverse distribution.",
            "referenceCount": 47,
            "citationCount": 74,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-06-14",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1806.05575"
            },
            "citationStyles": {
                "bibtex": "@Article{Ostrovski2018AutoregressiveQN,\n author = {Georg Ostrovski and Will Dabney and R. Munos},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Autoregressive Quantile Networks for Generative Modeling},\n volume = {abs/1806.05575},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:35e5a14bb7f3cfcadf9f564f17712bf85239bbc7",
            "@type": "ScholarlyArticle",
            "paperId": "35e5a14bb7f3cfcadf9f564f17712bf85239bbc7",
            "corpusId": 9758832,
            "url": "https://www.semanticscholar.org/paper/35e5a14bb7f3cfcadf9f564f17712bf85239bbc7",
            "title": "Brain Anatomical Structure Segmentation by Hybrid Discriminative/Generative Models",
            "venue": "IEEE Transactions on Medical Imaging",
            "publicationVenue": {
                "id": "urn:research:e0cda45d-3074-4ac0-80b8-e5250df00b89",
                "name": "IEEE Transactions on Medical Imaging",
                "alternate_names": [
                    "IEEE Trans Med Imaging"
                ],
                "issn": "0278-0062",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=42"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2126043693",
                "DBLP": "journals/tmi/TuNDDTT08",
                "DOI": "10.1109/TMI.2007.908121",
                "CorpusId": 9758832,
                "PubMed": "18390346"
            },
            "abstract": "In this paper, a hybrid discriminative/generative model for brain anatomical structure segmentation is proposed. The learning aspect of the approach is emphasized. In the discriminative appearance models, various cues such as intensity and curvatures are combined to locally capture the complex appearances of different anatomical structures. A probabilistic boosting tree (PBT) framework is adopted to learn multiclass discriminative models that combine hundreds of features across different scales. On the generative model side, both global and local shape models are used to capture the shape information about each anatomical structure. The parameters to combine the discriminative appearance and generative shape models are also automatically learned. Thus, low-level and high-level information is learned and integrated in a hybrid model. Segmentations are obtained by minimizing an energy function associated with the proposed hybrid model. Finally, a grid-face structure is designed to explicitly represent the 3-D region topology. This representation handles an arbitrary number of regions and facilitates fast surface evolution. Our system was trained and tested on a set of 3-D magnetic resonance imaging (MRI) volumes and the results obtained are encouraging.",
            "referenceCount": 46,
            "citationCount": 212,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc2807446?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-03-31",
            "journal": {
                "name": "IEEE Transactions on Medical Imaging",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Tu2008BrainAS,\n author = {Z. Tu and K. Narr and Piotr Doll\u00e1r and I. Dinov and P. Thompson and A. Toga},\n booktitle = {IEEE Transactions on Medical Imaging},\n journal = {IEEE Transactions on Medical Imaging},\n pages = {495-508},\n title = {Brain Anatomical Structure Segmentation by Hybrid Discriminative/Generative Models},\n volume = {27},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:672037ca32175b2b1da22d653953ae2ce689443f",
            "@type": "ScholarlyArticle",
            "paperId": "672037ca32175b2b1da22d653953ae2ce689443f",
            "corpusId": 51934625,
            "url": "https://www.semanticscholar.org/paper/672037ca32175b2b1da22d653953ae2ce689443f",
            "title": "Deep Generative Modeling for Scene Synthesis via Hybrid Representations",
            "venue": "ACM Transactions on Graphics",
            "publicationVenue": {
                "id": "urn:research:aab03e41-f80d-48b3-89bd-60eeeceafc7d",
                "name": "ACM Transactions on Graphics",
                "alternate_names": [
                    "ACM Trans Graph"
                ],
                "issn": "0730-0301",
                "url": "http://www.acm.org/tog/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/tog/ZhangYMLHVH20",
                "MAG": "2887953252",
                "ArXiv": "1808.02084",
                "DOI": "10.1145/3381866",
                "CorpusId": 51934625
            },
            "abstract": "We present a deep generative scene modeling technique for indoor environments. Our goal is to train a generative model using a feed-forward neural network that maps a prior distribution (e.g., a normal distribution) to the distribution of primary objects in indoor scenes. We introduce a 3D object arrangement representation that models the locations and orientations of objects, based on their size and shape attributes. Moreover, our scene representation is applicable for 3D objects with different multiplicities (repetition counts), selected from a database. We show a principled way to train this model by combining discriminative losses for both a 3D object arrangement representation and a 2D image-based representation. We demonstrate the effectiveness of our scene representation and the network training method on benchmark datasets. We also show the applications of this generative model in scene interpolation and scene completion.",
            "referenceCount": 107,
            "citationCount": 82,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1808.02084",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-08-06",
            "journal": {
                "name": "ACM Transactions on Graphics (TOG)",
                "volume": "39"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018DeepGM,\n author = {Zaiwei Zhang and Zhenpei Yang and Chongyang Ma and Linjie Luo and Alexander G. Huth and E. Vouga and Qi-Xing Huang},\n booktitle = {ACM Transactions on Graphics},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 21},\n title = {Deep Generative Modeling for Scene Synthesis via Hybrid Representations},\n volume = {39},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e048841270ccf0f105d8a581a59a32284121fd2a",
            "@type": "ScholarlyArticle",
            "paperId": "e048841270ccf0f105d8a581a59a32284121fd2a",
            "corpusId": 329581,
            "url": "https://www.semanticscholar.org/paper/e048841270ccf0f105d8a581a59a32284121fd2a",
            "title": "Agent-based computational models and generative social science",
            "venue": "Complex",
            "publicationVenue": {
                "id": "urn:research:8bc59e8b-e251-4201-839a-ec83ae78859d",
                "name": "Complex",
                "alternate_names": [
                    "Int Conf Complex Sci",
                    "International Conference on Complex Sciences"
                ],
                "issn": "0806-1912",
                "url": "http://wo.uio.no/as/WebObjects/nettlogg.woa/1/wa/logg?logg=5904"
            },
            "year": 1999,
            "externalIds": {
                "MAG": "23379736",
                "DBLP": "journals/complexity/Epstein99",
                "DOI": "10.1002/(SICI)1099-0526(199905/06)4:5%3C41::AID-CPLX9%3E3.0.CO;2-F",
                "CorpusId": 329581
            },
            "abstract": "This article argues that the agent-based computational model permits a distinctive approach to social science for which the term \u201cgenerative\u201d is suitable. In defending this terminology, features distinguishing the approach from both \u201cinductive\u201d and \u201cdeductive\u201d science are given. Then, the following specific contributions to social science are discussed: The agent-based computational model is a new tool for empirical research. It offers a natural environment for the study of connectionist phenomena in social science. Agent-based modeling provides a powerful way to address certain enduring\u2014and especially interdisciplinary\u2014questions. It allows one to subject certain core theories\u2014such as neoclassical microeconomics\u2014to important types of stress (e.g., the effect of evolving preferences). It permits one to study how rules of individual behavior give rise\u2014or \u201cmap up\u201d\u2014to macroscopic regularities and organizations. In turn, one can employ laboratory behavioral research findings to select among competing agent-based (\u201cbottom up\u201d) models. The agent-based approach may well have the important effect of decoupling individual rationality from macroscopic equilibrium and of separating decision science from social science more generally. Agent-based modeling offers powerful new forms of hybrid theoretical-computational work; these are particularly relevant to the study of non-equilibrium systems. The agentbased approach invites the interpretation of society as a distributed computational device, and in turn the interpretation of social dynamics as a type of computation. This interpretation raises important foundational issues in social science\u2014some related to intractability, and some to undecidability proper. Finally, since \u201cemergence\u201d figures prominently in this literature, I take up the connection between agent-based modeling and classical emergentism, criticizing the latter and arguing that the two are incompatible. ! 1999 John Wiley & Sons, Inc.",
            "referenceCount": 154,
            "citationCount": 1118,
            "influentialCitationCount": 82,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://assets.press.princeton.edu/chapters/s8277.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Sociology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Sociology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1999-05-01",
            "journal": {
                "name": "Complex.",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Epstein1999AgentbasedCM,\n author = {J. Epstein},\n booktitle = {Complex},\n journal = {Complex.},\n pages = {41-60},\n title = {Agent-based computational models and generative social science},\n volume = {4},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3f66a6432d93cbf87f7b86d483dccff8ce619252",
            "@type": "ScholarlyArticle",
            "paperId": "3f66a6432d93cbf87f7b86d483dccff8ce619252",
            "corpusId": 52877309,
            "url": "https://www.semanticscholar.org/paper/3f66a6432d93cbf87f7b86d483dccff8ce619252",
            "title": "Monge-Amp\u00e8re Flow for Generative Modeling",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1809-10188",
                "ArXiv": "1809.10188",
                "MAG": "2893472494",
                "CorpusId": 52877309
            },
            "abstract": "We present a deep generative model, named Monge-Ampere flow, which builds on continuous-time gradient flow arising from the Monge-Ampere equation in optimal transport theory. The generative map from the latent space to the data space follows a dynamical system, where a learnable potential function guides a compressible fluid to flow towards the target density distribution. Training of the model amounts to solving an optimal control problem. The Monge-Ampere flow has tractable likelihoods and supports efficient sampling and inference. One can easily impose symmetry constraints in the generative model by designing suitable scalar potential functions. We apply the approach to unsupervised density estimation of the MNIST dataset and variational calculation of the two-dimensional Ising model at the critical point. This approach brings insights and techniques from Monge-Ampere equation, optimal transport, and fluid dynamics into reversible flow-based generative models.",
            "referenceCount": 59,
            "citationCount": 58,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-26",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1809.10188"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018MongeAmp\u00e8reFF,\n author = {Linfeng Zhang and E. Weinan and Lei Wang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Monge-Amp\u00e8re Flow for Generative Modeling},\n volume = {abs/1809.10188},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:63f920458b916a45dfc6d6c87167436750c9531c",
            "@type": "ScholarlyArticle",
            "paperId": "63f920458b916a45dfc6d6c87167436750c9531c",
            "corpusId": 126034204,
            "url": "https://www.semanticscholar.org/paper/63f920458b916a45dfc6d6c87167436750c9531c",
            "title": "CosmoGAN: creating high-fidelity weak lensing convergence maps using Generative Adversarial Networks",
            "venue": "Computational Astrophysics and Cosmology",
            "publicationVenue": {
                "id": "urn:research:192fdb5b-dd67-4b11-961a-0e034c12324a",
                "name": "Computational Astrophysics and Cosmology",
                "alternate_names": [
                    "Comput Astrophys Cosmol"
                ],
                "issn": "2197-7909",
                "url": "http://www.comp-astrophys-cosmol.com/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2906265131",
                "DBLP": "journals/corr/MustafaBBAL17",
                "ArXiv": "1706.02390",
                "DOI": "10.1186/s40668-019-0029-9",
                "CorpusId": 126034204
            },
            "abstract": null,
            "referenceCount": 76,
            "citationCount": 104,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://comp-astrophys-cosmol.springeropen.com/track/pdf/10.1186/s40668-019-0029-9",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-06-07",
            "journal": {
                "name": "Computational Astrophysics and Cosmology",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Mustafa2017CosmoGANCH,\n author = {M. Mustafa and D. Bard and W. Bhimji and Z. Lukic and Rami Al-Rfou and J. Kratochvil},\n booktitle = {Computational Astrophysics and Cosmology},\n journal = {Computational Astrophysics and Cosmology},\n pages = {1-13},\n title = {CosmoGAN: creating high-fidelity weak lensing convergence maps using Generative Adversarial Networks},\n volume = {6},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2af17f153e3fd71e15db9216b972aef222f46617",
            "@type": "ScholarlyArticle",
            "paperId": "2af17f153e3fd71e15db9216b972aef222f46617",
            "corpusId": 2901305,
            "url": "https://www.semanticscholar.org/paper/2af17f153e3fd71e15db9216b972aef222f46617",
            "title": "Structured Inference Networks for Nonlinear State Space Models",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2951228804",
                "ArXiv": "1609.09869",
                "DBLP": "journals/corr/KrishnanSS16a",
                "DOI": "10.1609/aaai.v31i1.10779",
                "CorpusId": 2901305
            },
            "abstract": "\n \n Gaussian state space models have been used for decades as generative models of sequential data. They admit an intuitive probabilistic interpretation, have a simple functional form, and enjoy widespread adoption. We introduce a unified algorithm to efficiently learn a broad class of linear and non-linear state space models, including variants where the emission and transition distributions are modeled by deep neural networks. Our learning algorithm simultaneously learns a compiled inference network and the generative model, leveraging a structured variational approximation parameterized by recurrent neural networks to mimic the posterior distribution. We apply the learning algorithm to both synthetic and real-world datasets, demonstrating its scalability and versatility. We find that using the structured approximation to the posterior results in models with significantly higher held-out likelihood.\n \n",
            "referenceCount": 40,
            "citationCount": 383,
            "influentialCitationCount": 57,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/10779/10638",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-09-30",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Krishnan2016StructuredIN,\n author = {R. G. Krishnan and Uri Shalit and D. Sontag},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {2101-2109},\n title = {Structured Inference Networks for Nonlinear State Space Models},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:29b8b97d554f5139fcf2064ce292204500eee31c",
            "@type": "ScholarlyArticle",
            "paperId": "29b8b97d554f5139fcf2064ce292204500eee31c",
            "corpusId": 8469530,
            "url": "https://www.semanticscholar.org/paper/29b8b97d554f5139fcf2064ce292204500eee31c",
            "title": "Connecting Generative Adversarial Networks and Actor-Critic Methods",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1610.01945",
                "DBLP": "journals/corr/PfauV16",
                "MAG": "2527819024",
                "CorpusId": 8469530
            },
            "abstract": "Both generative adversarial networks (GAN) in unsupervised learning and actor-critic methods in reinforcement learning (RL) have gained a reputation for being difficult to optimize. Practitioners in both fields have amassed a large number of strategies to mitigate these instabilities and improve training. Here we show that GANs can be viewed as actor-critic methods in an environment where the actor cannot affect the reward. We review the strategies for stabilizing training for each class of models, both those that generalize between the two and those that are particular to that model. We also review a number of extensions to GANs and RL algorithms with even more complicated information flow. We hope that by highlighting this formal connection we will encourage both GAN and RL communities to develop general, scalable, and stable algorithms for multilevel optimization with deep networks, and to draw inspiration across communities.",
            "referenceCount": 36,
            "citationCount": 174,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-10-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1610.01945"
            },
            "citationStyles": {
                "bibtex": "@Article{Pfau2016ConnectingGA,\n author = {David Pfau and Oriol Vinyals},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Connecting Generative Adversarial Networks and Actor-Critic Methods},\n volume = {abs/1610.01945},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6472f7d98179c3217209a7ba3bcfa0f9f2a8ca7e",
            "@type": "ScholarlyArticle",
            "paperId": "6472f7d98179c3217209a7ba3bcfa0f9f2a8ca7e",
            "corpusId": 12092339,
            "url": "https://www.semanticscholar.org/paper/6472f7d98179c3217209a7ba3bcfa0f9f2a8ca7e",
            "title": "Generative models of noisy translations with applications to parallel fragment extraction",
            "venue": "Machine Translation Summit",
            "publicationVenue": {
                "id": "urn:research:2ca90f66-d056-4b44-87a2-0f6a88aeb347",
                "name": "Machine Translation Summit",
                "alternate_names": [
                    "MTSummit",
                    "Mach Transl Summit"
                ],
                "issn": null,
                "url": null
            },
            "year": 2007,
            "externalIds": {
                "MAG": "92412080",
                "ACL": "2007.mtsummit-papers.50",
                "DBLP": "conf/mtsummit/QuirkUM07",
                "CorpusId": 12092339
            },
            "abstract": "The development of broad domain statistical machine translation systems is gated by the availability of parallel data. A promising strategy for mitigating data scarcity is to mine parallel data from comparable corpora. Although comparable corpora seldom contain parallel sentences, they often contain parallel words or phrases. Recent fragment extraction approaches have shown that including parallel fragments in SMT training data can significantly improve translation quality. We describe efficient and effective generative models for extracting fragments, and demonstrate that these algorithms produce competitive improvements on cross-domain test data without suffering in-domain degradation even at very large scale.",
            "referenceCount": 28,
            "citationCount": 68,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2007-09-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Quirk2007GenerativeMO,\n author = {Chris Quirk and U. RaghavendraUdupa and Arul Menezes},\n booktitle = {Machine Translation Summit},\n title = {Generative models of noisy translations with applications to parallel fragment extraction},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:23b80dc704e25cf52b5a14935002fc083ce9c317",
            "@type": "ScholarlyArticle",
            "paperId": "23b80dc704e25cf52b5a14935002fc083ce9c317",
            "corpusId": 226145,
            "url": "https://www.semanticscholar.org/paper/23b80dc704e25cf52b5a14935002fc083ce9c317",
            "title": "Learning Generative Models via Discriminative Approaches",
            "venue": "2007 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2007,
            "externalIds": {
                "DBLP": "conf/cvpr/Tu07",
                "MAG": "2163176424",
                "DOI": "10.1109/CVPR.2007.383035",
                "CorpusId": 226145
            },
            "abstract": "Generative model learning is one of the key problems in machine learning and computer vision. Currently the use of generative models is limited due to the difficulty in effectively learning them. A new learning framework is proposed in this paper which progressively learns a target generative distribution through discriminative approaches. This framework provides many interesting aspects to the literature. From the generative model side: (1) A reference distribution is used to assist the learning process, which removes the need for a sampling processes in the early stages. (2) The classification power of discriminative approaches, e.g. boosting, is directly utilized. (3) The ability to select/explore features from a large candidate pool allows us to make nearly no assumptions about the training data. From the discriminative model side: (1) This framework improves the modeling capability of discriminative models. (2) It can start with source training data only and gradually \"invent\" negative samples. (3) We show how sampling schemes can be introduced to discriminative models. (4) The learning procedure helps to tighten the decision boundaries for classification, and therefore, improves robustness. In this paper, we show a variety of applications including texture modeling and classification, non-photorealistic rendering, learning image statistics/denoising, and face modeling. The framework handles both homogeneous patterns, e.g. textures, and inhomogeneous patterns, e.g. faces, with nearly an identical parameter setting for all the tasks in the learning stage.",
            "referenceCount": 28,
            "citationCount": 112,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2007-06-17",
            "journal": {
                "name": "2007 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tu2007LearningGM,\n author = {Z. Tu},\n booktitle = {2007 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2007 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {1-8},\n title = {Learning Generative Models via Discriminative Approaches},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1f3d5f8130c4be8517f8d63467599a207cbb0aae",
            "@type": "ScholarlyArticle",
            "paperId": "1f3d5f8130c4be8517f8d63467599a207cbb0aae",
            "corpusId": 8346605,
            "url": "https://www.semanticscholar.org/paper/1f3d5f8130c4be8517f8d63467599a207cbb0aae",
            "title": "Automated learning of generative models for subcellular location: Building blocks for systems biology",
            "venue": "Cytometry Part A",
            "publicationVenue": {
                "id": "urn:research:298dfa38-1ee5-4cfc-bbf3-0ca3b1f2b389",
                "name": "Cytometry Part A",
                "alternate_names": [
                    "Cytom Part A"
                ],
                "issn": "1552-4922",
                "url": "http://www3.interscience.wiley.com/cgi-bin/jhome/33945"
            },
            "year": 2007,
            "externalIds": {
                "MAG": "2123756340",
                "DOI": "10.1002/cyto.a.20487",
                "CorpusId": 8346605,
                "PubMed": "17972315"
            },
            "abstract": "The goal of location proteomics is the systematic and comprehensive study of protein subcellular location. We have previously developed automated, quantitative methods to identify protein subcellular location families, but there have been no effective means of communicating their patterns to integrate them with other information for building cell models. We built generative models of subcellular location that are learned from a collection of images so that they not only represent the pattern, but also capture its variation from cell to cell. Our models contain three components: a nuclear model, a cell shape model and a protein\u2010containing object model. We built models for six patterns that consist primarily of discrete structures. To validate the generated images, we showed that they are recognized with reasonable accuracy by a classifier trained on real images. We also showed that the model parameters themselves can be used as features to discriminate the classes. The models allow the synthesis of images with the expectation that they are drawn from the same underlying statistical distribution as the images used to train them. They can potentially be combined for many proteins to yield a high resolution location map in support of systems biology. \u00a9 2007 International Society for Analytical Cytology",
            "referenceCount": 42,
            "citationCount": 121,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2007-12-01",
            "journal": {
                "name": "Cytometry Part A",
                "volume": "71A"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhao2007AutomatedLO,\n author = {Ting Zhao and R. Murphy},\n booktitle = {Cytometry Part A},\n journal = {Cytometry Part A},\n title = {Automated learning of generative models for subcellular location: Building blocks for systems biology},\n volume = {71A},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8de1d8425937890522118ca63781c3b318e79f2f",
            "@type": "ScholarlyArticle",
            "paperId": "8de1d8425937890522118ca63781c3b318e79f2f",
            "corpusId": 14166286,
            "url": "https://www.semanticscholar.org/paper/8de1d8425937890522118ca63781c3b318e79f2f",
            "title": "Sequential Neural Models with Stochastic Layers",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/FraccaroSPW16",
                "ArXiv": "1605.07571",
                "MAG": "2952792349",
                "CorpusId": 14166286
            },
            "abstract": "How can we efficiently propagate uncertainty in a latent state representation with recurrent neural networks? This paper introduces stochastic recurrent neural networks which glue a deterministic recurrent neural network and a state space model together to form a stochastic and sequential neural generative model. The clear separation of deterministic and stochastic layers allows a structured variational inference network to track the factorization of the model's posterior distribution. By retaining both the nonlinear recursive structure of a recurrent neural network and averaging over the uncertainty in a latent path, like a state space model, we improve the state of the art results on the Blizzard and TIMIT speech modeling data sets by a large margin, while achieving comparable performances to competing methods on polyphonic music modeling.",
            "referenceCount": 29,
            "citationCount": 355,
            "influentialCitationCount": 67,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-05-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Fraccaro2016SequentialNM,\n author = {Marco Fraccaro and S\u00f8ren Kaae S\u00f8nderby and U. Paquet and O. Winther},\n booktitle = {Neural Information Processing Systems},\n pages = {2199-2207},\n title = {Sequential Neural Models with Stochastic Layers},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e15b386d28e6901872d06ed7b47fff57338a72ca",
            "@type": "ScholarlyArticle",
            "paperId": "e15b386d28e6901872d06ed7b47fff57338a72ca",
            "corpusId": 189488,
            "url": "https://www.semanticscholar.org/paper/e15b386d28e6901872d06ed7b47fff57338a72ca",
            "title": "An end-to-end generative framework for video segmentation and recognition",
            "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:acd15a6d-3248-41fb-8439-9a40aabe5608",
                "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                "alternate_names": [
                    "Workshop on Applications of Computer Vision",
                    "WACV",
                    "IEEE Work Conf Appl Comput Vis",
                    "Workshop Appl Comput Vis"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=2993"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/wacv/KuehneGS16",
                "MAG": "2952349270",
                "ArXiv": "1509.01947",
                "DOI": "10.1109/WACV.2016.7477701",
                "CorpusId": 189488
            },
            "abstract": "We describe an end-to-end generative approach for the segmentation and recognition of human activities. In this approach, a visual representation based on reduced Fisher Vectors is combined with a structured temporal model for recognition. We show that the statistical properties of Fisher Vectors make them an especially suitable front-end for generative models such as Gaussian mixtures. The system is evaluated for both the recognition of complex activities as well as their parsing into action units. Using a variety of video datasets ranging from human cooking activities to animal behaviors, our experiments demonstrate that the resulting architecture outperforms state-of-the-art approaches for larger datasets, i.e. when sufficient amount of data is available for training structured generative models.",
            "referenceCount": 37,
            "citationCount": 163,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/1509.01947",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-09-07",
            "journal": {
                "name": "2016 IEEE Winter Conference on Applications of Computer Vision (WACV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kuehne2015AnEG,\n author = {Hilde Kuehne and Juergen Gall and Thomas Serre},\n booktitle = {IEEE Workshop/Winter Conference on Applications of Computer Vision},\n journal = {2016 IEEE Winter Conference on Applications of Computer Vision (WACV)},\n pages = {1-8},\n title = {An end-to-end generative framework for video segmentation and recognition},\n year = {2015}\n}\n"
            }
        }
    }
]