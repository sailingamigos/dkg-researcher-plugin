[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5ffa8bf1bf3e39227be28de4ff6915d3b21eb52d",
            "@type": "ScholarlyArticle",
            "paperId": "5ffa8bf1bf3e39227be28de4ff6915d3b21eb52d",
            "corpusId": 9494295,
            "url": "https://www.semanticscholar.org/paper/5ffa8bf1bf3e39227be28de4ff6915d3b21eb52d",
            "title": "Deep Generative Stochastic Networks Trainable by Backprop",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2951446714",
                "ArXiv": "1306.1091",
                "DBLP": "conf/icml/BengioLAY14",
                "CorpusId": 9494295
            },
            "abstract": "We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution estimates the data distribution. The transition distribution of the Markov chain is conditional on the previous state, generally involving a small move, so this conditional distribution has fewer dominant modes, being unimodal in the limit of small moves. Thus, it is easier to learn because it is easier to approximate its partition function, more like learning to perform supervised function approximation, with gradients that can be obtained by backprop. We provide theorems that generalize recent work on the probabilistic interpretation of denoising autoencoders and obtain along the way an interesting justification for dependency networks and generalized pseudolikelihood, along with a definition of an appropriate joint distribution and sampling mechanism even when the conditionals are not consistent. GSNs can be used with missing inputs and can be used to sample subsets of variables given the rest. We validate these theoretical results with experiments on two image datasets using an architecture that mimics the Deep Boltzmann Machine Gibbs sampler but allows training to proceed with simple backprop, without the need for layerwise pretraining.",
            "referenceCount": 41,
            "citationCount": 383,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-06-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bengio2013DeepGS,\n author = {Yoshua Bengio and Eric Thibodeau-Laufer and Guillaume Alain and J. Yosinski},\n booktitle = {International Conference on Machine Learning},\n pages = {226-234},\n title = {Deep Generative Stochastic Networks Trainable by Backprop},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:705fa783325b04a2f7792742b0f6659e15ed1fee",
            "@type": "ScholarlyArticle",
            "paperId": "705fa783325b04a2f7792742b0f6659e15ed1fee",
            "corpusId": 8203481,
            "url": "https://www.semanticscholar.org/paper/705fa783325b04a2f7792742b0f6659e15ed1fee",
            "title": "Sentiment Retrieval using Generative Models",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2006,
            "externalIds": {
                "ACL": "W06-1641",
                "DBLP": "conf/emnlp/EguchiL06",
                "MAG": "2145321263",
                "DOI": "10.3115/1610075.1610124",
                "CorpusId": 8203481
            },
            "abstract": "Ranking documents or sentences according to both topic and sentiment relevance should serve a critical function in helping users when topics and sentiment polarities of the targeted text are not explicitly given, as is often the case on the web. In this paper, we propose several sentiment information retrieval models in the framework of probabilistic language models, assuming that a user both inputs query terms expressing a certain topic and also specifies a sentiment polarity of interest in some manner. We combine sentiment relevance models and topic relevance models with model parameters estimated from training data, considering the topic dependence of the sentiment. Our experiments prove that our models are effective.",
            "referenceCount": 32,
            "citationCount": 146,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.5555/1610075.1610124",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-07-22",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Eguchi2006SentimentRU,\n author = {K. Eguchi and V. Lavrenko},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {345-354},\n title = {Sentiment Retrieval using Generative Models},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9e0a8531893ac860b8a1eb91f5d7f3a7d74d7334",
            "@type": "ScholarlyArticle",
            "paperId": "9e0a8531893ac860b8a1eb91f5d7f3a7d74d7334",
            "corpusId": 3905156,
            "url": "https://www.semanticscholar.org/paper/9e0a8531893ac860b8a1eb91f5d7f3a7d74d7334",
            "title": "A Generative Model for Volume Rendering",
            "venue": "IEEE Transactions on Visualization and Computer Graphics",
            "publicationVenue": {
                "id": "urn:research:5e1f6444-5d03-48c7-b202-7f47d492aeae",
                "name": "IEEE Transactions on Visualization and Computer Graphics",
                "alternate_names": [
                    "IEEE Trans Vis Comput Graph"
                ],
                "issn": "1077-2626",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=2945"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1710.09545",
                "MAG": "2951859141",
                "DBLP": "journals/tvcg/BergerLL19",
                "DOI": "10.1109/TVCG.2018.2816059",
                "CorpusId": 3905156,
                "PubMed": "29993811"
            },
            "abstract": "We present a technique to synthesize and analyze volume-rendered images using generative models. We use the Generative Adversarial Network (GAN) framework to compute a model from a large collection of volume renderings, conditioned on (1) viewpoint and (2) transfer functions for opacity and color. Our approach facilitates tasks for volume analysis that are challenging to achieve using existing rendering techniques such as ray casting or texture-based methods. We show how to guide the user in transfer function editing by quantifying expected change in the output image. Additionally, the generative model transforms transfer functions into a view-invariant latent space specifically designed to synthesize volume-rendered images. We use this space directly for rendering, enabling the user to explore the space of volume-rendered images. As our model is independent of the choice of volume rendering process, we show how to analyze volume-rendered images produced by direct and global illumination lighting, for a variety of volume datasets.",
            "referenceCount": 61,
            "citationCount": 60,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-26",
            "journal": {
                "name": "IEEE Transactions on Visualization and Computer Graphics",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{Berger2017AGM,\n author = {M. Berger and Jixian Li and J. Levine},\n booktitle = {IEEE Transactions on Visualization and Computer Graphics},\n journal = {IEEE Transactions on Visualization and Computer Graphics},\n pages = {1636-1650},\n title = {A Generative Model for Volume Rendering},\n volume = {25},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bae9b7a69fa30edaf910d89f559f14901974de93",
            "@type": "ScholarlyArticle",
            "paperId": "bae9b7a69fa30edaf910d89f559f14901974de93",
            "corpusId": 43643294,
            "url": "https://www.semanticscholar.org/paper/bae9b7a69fa30edaf910d89f559f14901974de93",
            "title": "Shape Matching and Recognition - Using Generative Models and Informative Features",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2004,
            "externalIds": {
                "DBLP": "conf/eccv/TuY04",
                "MAG": "1575129940",
                "DOI": "10.1007/978-3-540-24672-5_16",
                "CorpusId": 43643294
            },
            "abstract": null,
            "referenceCount": 17,
            "citationCount": 224,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/978-3-540-24672-5_16.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2004-05-11",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tu2004ShapeMA,\n author = {Z. Tu and A. Yuille},\n booktitle = {European Conference on Computer Vision},\n pages = {195-209},\n title = {Shape Matching and Recognition - Using Generative Models and Informative Features},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0475380e39a5017f5c61b01a0c58c1ea7a7cf50d",
            "@type": "ScholarlyArticle",
            "paperId": "0475380e39a5017f5c61b01a0c58c1ea7a7cf50d",
            "corpusId": 6964497,
            "url": "https://www.semanticscholar.org/paper/0475380e39a5017f5c61b01a0c58c1ea7a7cf50d",
            "title": "Face verification using adapted generative models",
            "venue": "Sixth IEEE International Conference on Automatic Face and Gesture Recognition, 2004. Proceedings.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2153281657",
                "DBLP": "conf/fgr/CardinauxSB04",
                "DOI": "10.1109/AFGR.2004.1301636",
                "CorpusId": 6964497
            },
            "abstract": "It has been shown previously that systems based on local features and relatively complex generative models, namely 1D hidden Markov models (HMMs) and pseudo-2D HMMs, are suitable for face recognition (here we mean both identification and verification). Recently a simpler generative model, namely the Gaussian mixture model (GMM), was also shown to perform well. In this paper we first propose to increase the performance of the GMM approach (without sacrificing its simplicity) through the use of local features with embedded positional information; we show that the performance obtained is comparable to 1D HMMs. Secondly, we evaluate different training techniques for both GMM and HMM based systems. We show that the traditionally used maximum likelihood (ML) training approach has problems estimating robust model parameters when there is only a few training images available; we propose to tackle this problem through the use of maximum a posteriori (MAP) training, where the lack of data problem can be effectively circumvented; we show that models estimated with MAP are significantly more robust and are able to generalize to adverse conditions present in the BANCA database.",
            "referenceCount": 20,
            "citationCount": 73,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://publications.idiap.ch/attachments/reports/2003/rr03-76.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2004-05-17",
            "journal": {
                "name": "Sixth IEEE International Conference on Automatic Face and Gesture Recognition, 2004. Proceedings.",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cardinaux2004FaceVU,\n author = {Fabien Cardinaux and Conrad Sanderson and Samy Bengio},\n booktitle = {Sixth IEEE International Conference on Automatic Face and Gesture Recognition, 2004. Proceedings.},\n journal = {Sixth IEEE International Conference on Automatic Face and Gesture Recognition, 2004. Proceedings.},\n pages = {825-830},\n title = {Face verification using adapted generative models},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f267934e9de60c5badfa9d3f28918e67ae7a2bf4",
            "@type": "ScholarlyArticle",
            "paperId": "f267934e9de60c5badfa9d3f28918e67ae7a2bf4",
            "corpusId": 2865509,
            "url": "https://www.semanticscholar.org/paper/f267934e9de60c5badfa9d3f28918e67ae7a2bf4",
            "title": "Generative Image Modeling Using Spatial LSTMs",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2097039814",
                "ArXiv": "1506.03478",
                "DBLP": "journals/corr/TheisB15",
                "CorpusId": 2865509
            },
            "abstract": "Modeling the distribution of natural images is challenging, partly because of strong statistical dependencies which can extend over hundreds of pixels. Recurrent neural networks have been successful in capturing long-range dependencies in a number of problems but only recently have found their way into generative image models. We here introduce a recurrent image model based on multidimensional long short-term memory units which are particularly suited for image modeling due to their spatial structure. Our model scales to images of arbitrary size and its likelihood is computationally tractable. We find that it outperforms the state of the art in quantitative comparisons on several image datasets and produces promising results when used for texture synthesis and inpainting.",
            "referenceCount": 55,
            "citationCount": 188,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-06-10",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Theis2015GenerativeIM,\n author = {Lucas Theis and M. Bethge},\n booktitle = {Neural Information Processing Systems},\n pages = {1927-1935},\n title = {Generative Image Modeling Using Spatial LSTMs},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0ee0b33abc78ff84718dbc80aae9d2d0717d1085",
            "@type": "ScholarlyArticle",
            "paperId": "0ee0b33abc78ff84718dbc80aae9d2d0717d1085",
            "corpusId": 12229839,
            "url": "https://www.semanticscholar.org/paper/0ee0b33abc78ff84718dbc80aae9d2d0717d1085",
            "title": "Privacy-preserving distributed clustering using generative models",
            "venue": "Third IEEE International Conference on Data Mining",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "2144709747",
                "DBLP": "conf/icdm/MeruguG03",
                "DOI": "10.1109/ICDM.2003.1250922",
                "CorpusId": 12229839
            },
            "abstract": "We present a framework for clustering distributed data in unsupervised and semisupervised scenarios, taking into account privacy requirements and communication costs. Rather than sharing parts of the original or perturbed data, we instead transmit the parameters of suitable generative models built at each local data site to a central location. We mathematically show that the best representative of all the data is a certain \"mean\" model, and empirically show that this model can be approximated quite well by generating artificial samples from the underlying distributions using Markov Chain Monte Carlo techniques, and then fitting a combined global model with a chosen parametric form to these samples. We also propose a new measure that quantifies privacy based on information theoretic concepts, and show that decreasing privacy leads to a higher quality of the combined model and vice versa. We provide empirical results on different data types to highlight the generality of our framework. The results show that high quality distributed clustering can be achieved with little privacy loss and low communication cost.",
            "referenceCount": 22,
            "citationCount": 245,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2003-11-19",
            "journal": {
                "name": "Third IEEE International Conference on Data Mining",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Merugu2003PrivacypreservingDC,\n author = {S. Merugu and Joydeep Ghosh},\n booktitle = {Third IEEE International Conference on Data Mining},\n journal = {Third IEEE International Conference on Data Mining},\n pages = {211-218},\n title = {Privacy-preserving distributed clustering using generative models},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8f31dee642f415743fc989a461faff7096ebc1da",
            "@type": "ScholarlyArticle",
            "paperId": "8f31dee642f415743fc989a461faff7096ebc1da",
            "corpusId": 15377552,
            "url": "https://www.semanticscholar.org/paper/8f31dee642f415743fc989a461faff7096ebc1da",
            "title": "A Comparative Study of Generative Models for Document Clustering",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "181283514",
                "CorpusId": 15377552
            },
            "abstract": "Generative models based on the multivariate Bernoulli and multinomial distributions have been widely used for text classification. Recently, the spherical k-means algorithm, which has desirable properties for text clustering, has been shown to be a special case of a generative model based on a mixture of von Mises-Fisher (vMF) distributions. This paper compares these three probabilistic models for text clustering, both theoretically and empirically, using a general model-based clustering framework. For each model, we investigate three strategies for assigning documents to models: maximum likelihood (k-means) assignment, stochastic assignment, and soft assignment. Our experimental results over a large number of datasets show that, in terms of clustering quality, (a) The Bernoulli model is the worst for text clustering; (b) The vMF model produces better clustering results than both Bernoulli and multinomial models; (c) Soft assignment leads to comparable or slightly better results than hard assignment. We also use deterministic annealing (DA) to improve the vMF-based soft clustering and compare all the model-based algorithms with the state-of-the-art discriminative approach to document clustering based on graph partitioning (CLUTO) and a spectral co-clustering method. Overall, CLUTO and DA perform the best but are also the most computationally expensive; the spectral coclustering algorithm fares worse than the vMF-based methods.",
            "referenceCount": 41,
            "citationCount": 125,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Zhong2003ACS,\n author = {Shi Zhong},\n title = {A Comparative Study of Generative Models for Document Clustering},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:56efc84e0858f1e0a7cf052e5c4275d4c46c21c2",
            "@type": "ScholarlyArticle",
            "paperId": "56efc84e0858f1e0a7cf052e5c4275d4c46c21c2",
            "corpusId": 1171795,
            "url": "https://www.semanticscholar.org/paper/56efc84e0858f1e0a7cf052e5c4275d4c46c21c2",
            "title": "Using Generative Models for Handwritten Digit Recognition",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 1996,
            "externalIds": {
                "DBLP": "journals/pami/RevowWH96",
                "MAG": "2063252599",
                "DOI": "10.1109/34.506410",
                "CorpusId": 1171795
            },
            "abstract": "We describe a method of recognizing handwritten digits by fitting generative models that are built from deformable B-splines with Gaussian \"ink generators\" spaced along the length of the spline. The splines are adjusted using a novel elastic matching procedure based on the expectation maximization algorithm that maximizes the likelihood of the model generating the data. This approach has many advantages: 1) the system not only produces a classification of the digit but also a rich description of the instantiation parameters which can yield information such as the writing style; 2) the generative models can perform recognition driven segmentation; 3) the method involves a relatively small number of parameters and hence training is relatively easy and fast; and 4) unlike many other recognition schemes, it does not rely on some form of pre-normalization of input images, but can handle arbitrary scalings, translations and a limited degree of image rotation. We have demonstrated that our method of fitting models to images does not get trapped in poor local minima. The main disadvantage of the method is that it requires much more computation than more standard OCR techniques.",
            "referenceCount": 57,
            "citationCount": 212,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://publications.aston.ac.uk/id/eprint/664/1/getPDF.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1996-06-01",
            "journal": {
                "name": "IEEE Trans. Pattern Anal. Mach. Intell.",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Revow1996UsingGM,\n author = {M. Revow and Christopher K. I. Williams and Geoffrey E. Hinton},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Trans. Pattern Anal. Mach. Intell.},\n pages = {592-606},\n title = {Using Generative Models for Handwritten Digit Recognition},\n volume = {18},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:66c7be6562e9d09de33c3abb8a594b65fb489080",
            "@type": "ScholarlyArticle",
            "paperId": "66c7be6562e9d09de33c3abb8a594b65fb489080",
            "corpusId": 1420590,
            "url": "https://www.semanticscholar.org/paper/66c7be6562e9d09de33c3abb8a594b65fb489080",
            "title": "Creating generative models from range images",
            "venue": "International Conference on Computer Graphics and Interactive Techniques",
            "publicationVenue": {
                "id": "urn:research:cf6b5e76-9274-46e6-a2dd-7c190ec2ec5f",
                "name": "International Conference on Computer Graphics and Interactive Techniques",
                "alternate_names": [
                    "Int Conf Comput Graph Interact Tech",
                    "SIGGRAPH"
                ],
                "issn": null,
                "url": "http://www.siggraph.org/"
            },
            "year": 1999,
            "externalIds": {
                "DBLP": "conf/siggraph/RamamoorthiA99",
                "MAG": "2038091466",
                "DOI": "10.1145/311535.311557",
                "CorpusId": 1420590
            },
            "abstract": "We describe a new approach for creating concise high-level generative models from one or more approximate range images. Using simple acquisition techniques and a user-defined class of models, our method produces a simple and intuitive object description that is relatively insensitive to noise and is easy to manipulate and edit. The algorithm has two inter-related phases -- recognition, which chooses an appropriate model within a given hierarchy, and parameter estimation, which adjusts the model to fit the data. We give a simple method for automatically making tradeoffs between simplicity and accuracy to determine the best model. We also describe general techniques to optimize a specific generative model. In particular, we address the problem of creating a suitable objective function that is sufficiently continuous for use with finite-difference based optimization techniques. Our technique for model recovery and subsequent manipulation and editing is demonstrated on real objects -- a spoon, bowl, ladle, and cup -- using a simple tree of possible generative models. We believe that higher-level model representations are extremely important, and their recovery for actual objects is a fertile area of research towards which this thesis is a step. However, our work is preliminary and there are currently several limitations. The user is required to create a model hierarchy (and supply methods to provide an initial guess for model parameters within this hierarchy); the use of a large pre-defined class of models can help alleviate this problem. Further, we have demonstrated our technique on only a simple tree of generative models. While our approach is fairly general, a real system would require a tree that is significantly larger. Our methods work only where the entire object can be accurately represented as a single generative model; future work could use constructive solid geometry operations on simple generative models to represent more complicated shapes. We believe that many of the above limitations can be addressed in future work, allowing us to easily acquire and process three-dimensional shape in a simple, intuitive and efficient manner.",
            "referenceCount": 46,
            "citationCount": 52,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/311535.311557",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1999-07-01",
            "journal": {
                "name": "Proceedings of the 26th annual conference on Computer graphics and interactive techniques",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Ramamoorthi1999CreatingGM,\n author = {R. Ramamoorthi and J. Arvo},\n booktitle = {International Conference on Computer Graphics and Interactive Techniques},\n journal = {Proceedings of the 26th annual conference on Computer graphics and interactive techniques},\n title = {Creating generative models from range images},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ff412399f71d907cea8b15e3ecde14e249e358cb",
            "@type": "ScholarlyArticle",
            "paperId": "ff412399f71d907cea8b15e3ecde14e249e358cb",
            "corpusId": 1093842,
            "url": "https://www.semanticscholar.org/paper/ff412399f71d907cea8b15e3ecde14e249e358cb",
            "title": "Combining generative models and Fisher kernels for object recognition",
            "venue": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "conf/iccv/HolubWP05",
                "MAG": "2160360539",
                "DOI": "10.1109/ICCV.2005.56",
                "CorpusId": 1093842
            },
            "abstract": "Learning models for detecting and classifying object categories is a challenging problem in machine vision. While discriminative approaches to learning and classification have, in principle, superior performance, generative approaches provide many useful features, one of which is the ability to naturally establish explicit correspondence between model components and scene features - this, in turn, allows for the handling of missing data and unsupervised learning in clutter. We explore a hybrid generative/discriminative approach using 'Fisher kernels' by Jaakkola and Haussler (1999) which retains most of the desirable properties of generative methods, while increasing the classification performance through a discriminative setting. Furthermore, we demonstrate how this kernel framework can be used to combine different types of features and models into a single classifier. Our experiments, conducted on a number of popular benchmarks, show strong performance improvements over the corresponding generative approach and are competitive with the best results reported in the literature.",
            "referenceCount": 24,
            "citationCount": 122,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://authors.library.caltech.edu/70661/2/01541249.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2005-10-17",
            "journal": {
                "name": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Holub2005CombiningGM,\n author = {Alex Holub and M. Welling and P. Perona},\n booktitle = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},\n journal = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},\n pages = {136-143 Vol. 1},\n title = {Combining generative models and Fisher kernels for object recognition},\n volume = {1},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:397afb869d1df69ea5f1a41ea2e575db1f29aa65",
            "@type": "ScholarlyArticle",
            "paperId": "397afb869d1df69ea5f1a41ea2e575db1f29aa65",
            "corpusId": 2604241,
            "url": "https://www.semanticscholar.org/paper/397afb869d1df69ea5f1a41ea2e575db1f29aa65",
            "title": "Parsing with Generative Models of Predicate-Argument Structure",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2003,
            "externalIds": {
                "MAG": "2140923814",
                "ACL": "P03-1046",
                "DBLP": "conf/acl/Hockenmaier03",
                "DOI": "10.3115/1075096.1075142",
                "CorpusId": 2604241
            },
            "abstract": "The model used by the CCG parser of Hockenmaier and Steedman (2002b) would fail to capture the correct bilexical dependencies in a language with freer word order, such as Dutch. This paper argues that probabilistic parsers should therefore model the dependencies in the predicate-argument structure, as in the model of Clark et al. (2002), and defines a generative model for CCG derivations that captures these dependencies, including bounded and unbounded long-range dependencies.",
            "referenceCount": 8,
            "citationCount": 81,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/1075096.1075142",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2003-07-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hockenmaier2003ParsingWG,\n author = {J. Hockenmaier},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {359-366},\n title = {Parsing with Generative Models of Predicate-Argument Structure},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7e08b47eadfac97fab508485ed5fbef9dbbbd9a3",
            "@type": "ScholarlyArticle",
            "paperId": "7e08b47eadfac97fab508485ed5fbef9dbbbd9a3",
            "corpusId": 17706343,
            "url": "https://www.semanticscholar.org/paper/7e08b47eadfac97fab508485ed5fbef9dbbbd9a3",
            "title": "Generative models for discovering sparse distributed representations.",
            "venue": "Philosophical transactions of the Royal Society of London. Series B, Biological sciences",
            "publicationVenue": {
                "id": "urn:research:6de51a3e-86d6-4b08-92f5-a2a4a3a1c47b",
                "name": "Philosophical transactions of the Royal Society of London. Series B, Biological sciences",
                "alternate_names": [
                    "Philos trans R Soc Lond Ser B Biological sci"
                ],
                "issn": "0080-4622",
                "url": "http://www.jstor.org/action/showPublication?journalCode=philtranroyasoc2"
            },
            "year": 1997,
            "externalIds": {
                "MAG": "1981814724",
                "DOI": "10.1098/RSTB.1997.0101",
                "CorpusId": 17706343,
                "PubMed": "9304685"
            },
            "abstract": "We describe a hierarchical, generative model that can be viewed as a nonlinear generalization of factor analysis and can be implemented in a neural network. The model uses bottom-up, top-down and lateral connections to perform Bayesian perceptual inference correctly. Once perceptual inference has been performed the connection strengths can be updated using a very simple learning rule that only requires locally available information. We demonstrate that the network learns to extract sparse, distributed, hierarchical representations.",
            "referenceCount": 27,
            "citationCount": 268,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc1692002?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1997-08-29",
            "journal": {
                "name": "Philosophical transactions of the Royal Society of London. Series B, Biological sciences",
                "volume": "352 1358"
            },
            "citationStyles": {
                "bibtex": "@Article{Hinton1997GenerativeMF,\n author = {Geoffrey E. Hinton and Zoubin Ghahramani},\n booktitle = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},\n journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},\n pages = {\n          1177-90\n        },\n title = {Generative models for discovering sparse distributed representations.},\n volume = {352 1358},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3a2faa145c5fe63ab906568a29fa4100220e03d9",
            "@type": "ScholarlyArticle",
            "paperId": "3a2faa145c5fe63ab906568a29fa4100220e03d9",
            "corpusId": 14127241,
            "url": "https://www.semanticscholar.org/paper/3a2faa145c5fe63ab906568a29fa4100220e03d9",
            "title": "From few to many: generative models for recognition under variable pose and illumination",
            "venue": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2000,
            "externalIds": {
                "DBLP": "conf/fgr/GeorghiadesBK00",
                "MAG": "2102760078",
                "DOI": "10.1109/AFGR.2000.840647",
                "CorpusId": 14127241
            },
            "abstract": "Image variability due to changes in pose and illumination can seriously impair object recognition. This paper presents appearance-based methods which, unlike previous appearance-based approaches, require only a small set of training images to generate a rich representation that models this variability. Specifically, from as few as three images of an object in fixed pose seen under slightly varying but unknown lighting, a surface and an albedo map are reconstructed. These are then used to generate synthetic images with large variations in pose and illumination and thus build a representation useful for object recognition. Our methods have been tested within the domain of face recognition on a subset of the Yale Face Database B containing 4050 images of 10 faces seen under variable pose and illumination. This database was specifically gathered for testing these generative methods. Their performance is shown to exceed that of popular existing methods.",
            "referenceCount": 18,
            "citationCount": 301,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2000-03-26",
            "journal": {
                "name": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Georghiades2000FromFT,\n author = {A. Georghiades and P. Belhumeur and D. Kriegman},\n booktitle = {Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)},\n journal = {Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)},\n pages = {277-284},\n title = {From few to many: generative models for recognition under variable pose and illumination},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ae027939f3e977ff7ec74a2cd248a286e3847dc9",
            "@type": "ScholarlyArticle",
            "paperId": "ae027939f3e977ff7ec74a2cd248a286e3847dc9",
            "corpusId": 10408622,
            "url": "https://www.semanticscholar.org/paper/ae027939f3e977ff7ec74a2cd248a286e3847dc9",
            "title": "Text2Action: Generative Adversarial Synthesis from Language to Action",
            "venue": "IEEE International Conference on Robotics and Automation",
            "publicationVenue": {
                "id": "urn:research:3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                "name": "IEEE International Conference on Robotics and Automation",
                "alternate_names": [
                    "International Conference on Robotics and Automation",
                    "Int Conf Robot Autom",
                    "ICRA",
                    "IEEE Int Conf Robot Autom"
                ],
                "issn": "2152-4092",
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/icra/AhnHCYO18",
                "MAG": "2964076328",
                "ArXiv": "1710.05298",
                "DOI": "10.1109/ICRA.2018.8460608",
                "CorpusId": 10408622
            },
            "abstract": "In this paper, we propose a generative model which learns the relationship between language and human action in order to generate a human action sequence given a sentence describing human behavior. The proposed generative model is a generative adversarial network (GAN), which is based on the sequence to sequence (SEQ2SEQ) model. Using the proposed generative network, we can synthesize various actions for a robot or a virtual agent using a text encoder recurrent neural network (RNN) and an action decoder RNN. The proposed generative network is trained from 29,770 pairs of actions and sentence annotations extracted from MSR-Video-to-Text (MSR-VTT), a large-scale video dataset. We demonstrate that the network can generate human-like actions which can be transferred to a Baxter robot, such that the robot performs an action based on a provided sentence. Results show that the proposed generative network correctly models the relationship between language and action and can generate a diverse set of actions from the same sentence.",
            "referenceCount": 19,
            "citationCount": 76,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1710.05298",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-10-15",
            "journal": {
                "name": "2018 IEEE International Conference on Robotics and Automation (ICRA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ahn2017Text2ActionGA,\n author = {Hyemin Ahn and Timothy Ha and Yunho Choi and Hwiyeon Yoo and Songhwai Oh},\n booktitle = {IEEE International Conference on Robotics and Automation},\n journal = {2018 IEEE International Conference on Robotics and Automation (ICRA)},\n pages = {1-5},\n title = {Text2Action: Generative Adversarial Synthesis from Language to Action},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9ec5db363a88ff1602b826e982a25bcd63e0de70",
            "@type": "ScholarlyArticle",
            "paperId": "9ec5db363a88ff1602b826e982a25bcd63e0de70",
            "corpusId": 2528292,
            "url": "https://www.semanticscholar.org/paper/9ec5db363a88ff1602b826e982a25bcd63e0de70",
            "title": "Generative Models for Cold-Start Recommendations",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "MAG": "169594500",
                "CorpusId": 2528292
            },
            "abstract": "Systems for automatically recommending items (e.g., movies, products, or information) to users are becoming increasingly important in e-commerce applications, digital libraries, and other domains where personalization is highly valued. Such recommender systems typically base their suggestions on (1) collaborative data encoding which users like which items, and/or (2) content data describing item features and user demographics. Systems that rely solely on collaborative data fail when operating from a cold start|that is, when recommending items (e.g., rst-run movies) that no member of the community has yet seen. We develop several generative probabilistic models that circumvent the cold-start problem by mixing content data with collaborative data in a sound statistical manner. We evaluate the algorithms using MovieLens movie ratings data, augmented with actor and director information from the Internet Movie Database. We nd that maximum likelihood learning with the expectation maximization (EM) algorithm and variants tends to over t complex models that are initialized randomly. However, by seeding parameters of the complex models with parameters learned in simpler models, we obtain greatly improved performance. We explore both methods that exploit a single type of content data (e.g., actors only) and methods that leverage multiple types of content data (e.g., both actors and directors) simultaneously.",
            "referenceCount": 30,
            "citationCount": 71,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Schein2001GenerativeMF,\n author = {A. Schein and Alexandrin Popescul and L. Ungar and David M. Pennock},\n title = {Generative Models for Cold-Start Recommendations},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:976c95f69e8ee160868b1d54d477f56212ee794b",
            "@type": "ScholarlyArticle",
            "paperId": "976c95f69e8ee160868b1d54d477f56212ee794b",
            "corpusId": 2876869,
            "url": "https://www.semanticscholar.org/paper/976c95f69e8ee160868b1d54d477f56212ee794b",
            "title": "Generative Models for Statistical Parsing with Combinatory Categorial Grammar",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2105947498",
                "ACL": "P02-1043",
                "DBLP": "conf/acl/HockenmaierS02",
                "DOI": "10.3115/1073083.1073139",
                "CorpusId": 2876869
            },
            "abstract": "This paper compares a number of generative probability models for a wide-coverage Combinatory Categorial Grammar (CCG) parser. These models are trained and tested on a corpus obtained by translating the Penn Treebank trees into CCG normal-form derivations. According to an evaluation of unlabeled word-word dependencies, our best model achieves a performance of 89.9%, comparable to the figures given by Collins (1999) for a linguistically less expressive grammar. In contrast to Gildea (2001), we find a significant improvement from modeling word-word dependencies.",
            "referenceCount": 16,
            "citationCount": 216,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/1073083.1073139",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2002-07-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hockenmaier2002GenerativeMF,\n author = {J. Hockenmaier and Mark Steedman},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {335-342},\n title = {Generative Models for Statistical Parsing with Combinatory Categorial Grammar},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:978ae7f589f2b8aebc04655a0d9b19eabe97ce86",
            "@type": "ScholarlyArticle",
            "paperId": "978ae7f589f2b8aebc04655a0d9b19eabe97ce86",
            "corpusId": 204705,
            "url": "https://www.semanticscholar.org/paper/978ae7f589f2b8aebc04655a0d9b19eabe97ce86",
            "title": "Active Appearance Models Revisited",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2082308025",
                "DBLP": "journals/ijcv/MatthewsB04",
                "DOI": "10.1023/B:VISI.0000029666.37597.d3",
                "CorpusId": 204705
            },
            "abstract": null,
            "referenceCount": 25,
            "citationCount": 1786,
            "influentialCitationCount": 261,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.ri.cmu.edu/pub_files/pub4/matthews_iain_2003_1/matthews_iain_2003_1.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2004-11-01",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "60"
            },
            "citationStyles": {
                "bibtex": "@Article{Matthews2004ActiveAM,\n author = {I. Matthews and Simon Baker},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {135-164},\n title = {Active Appearance Models Revisited},\n volume = {60},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e2ff540cb13ed8ff3edb859b4ec51cd318d3210a",
            "@type": "ScholarlyArticle",
            "paperId": "e2ff540cb13ed8ff3edb859b4ec51cd318d3210a",
            "corpusId": 1135019,
            "url": "https://www.semanticscholar.org/paper/e2ff540cb13ed8ff3edb859b4ec51cd318d3210a",
            "title": "Learning Generative Texture Models with extended Fields-of-Experts",
            "venue": "British Machine Vision Conference",
            "publicationVenue": {
                "id": "urn:research:78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                "name": "British Machine Vision Conference",
                "alternate_names": [
                    "Br Mach Vis Conf",
                    "BMVC"
                ],
                "issn": null,
                "url": "http://www.bmva.org/bmvc/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2110163763",
                "DBLP": "conf/bmvc/HeessWH09",
                "DOI": "10.5244/C.23.115",
                "CorpusId": 1135019
            },
            "abstract": "We evaluate the ability of the popular Field-of-Experts (FoE) to model structure in images. As a test case we focus on modeling synthetic and natural textures. We find that even for modeling single textures, the FoE provides insufficient flexibility to learn good generative models \u2010 it does not perform any better than the much simpler Gaussian FoE. We propose an extended version of the FoE (allowing for bimodal potentials) and demonstrate that this novel formulation, when trained with a better approximation of the likelihood gradient, gives rise to a more powerful generative model of specific visual structure that produces significantly better results for the texture task.",
            "referenceCount": 19,
            "citationCount": 271,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pure.ed.ac.uk/ws/files/7893923/bmvc09_1_.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Heess2009LearningGT,\n author = {N. Heess and Christopher K. I. Williams and Geoffrey E. Hinton},\n booktitle = {British Machine Vision Conference},\n pages = {1-11},\n title = {Learning Generative Texture Models with extended Fields-of-Experts},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a82a8aa1a77518e5ab7594a06672f5b6105591d8",
            "@type": "ScholarlyArticle",
            "paperId": "a82a8aa1a77518e5ab7594a06672f5b6105591d8",
            "corpusId": 5981386,
            "url": "https://www.semanticscholar.org/paper/a82a8aa1a77518e5ab7594a06672f5b6105591d8",
            "title": "Dynamic representations and generative models of brain function",
            "venue": "Brain Research Bulletin",
            "publicationVenue": {
                "id": "urn:research:e53af798-a995-4e58-b6c1-71e02e07d8b2",
                "name": "Brain Research Bulletin",
                "alternate_names": [
                    "Brain Res Bull"
                ],
                "issn": "0361-9230",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/525456/description#description"
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2044444453",
                "DOI": "10.1016/S0361-9230(00)00436-6",
                "CorpusId": 5981386,
                "PubMed": "11287132"
            },
            "abstract": null,
            "referenceCount": 44,
            "citationCount": 124,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2001-02-01",
            "journal": {
                "name": "Brain Research Bulletin",
                "volume": "54"
            },
            "citationStyles": {
                "bibtex": "@Article{Friston2001DynamicRA,\n author = {Karl J. Friston and C. Price},\n booktitle = {Brain Research Bulletin},\n journal = {Brain Research Bulletin},\n pages = {275-285},\n title = {Dynamic representations and generative models of brain function},\n volume = {54},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2639515c248f220c73d44688c0097a99b01e1474",
            "@type": "ScholarlyArticle",
            "paperId": "2639515c248f220c73d44688c0097a99b01e1474",
            "corpusId": 207605229,
            "url": "https://www.semanticscholar.org/paper/2639515c248f220c73d44688c0097a99b01e1474",
            "title": "GTM: The Generative Topographic Mapping",
            "venue": "Neural Computation",
            "publicationVenue": {
                "id": "urn:research:69b9bcdd-8229-4a00-a6e0-00f0e99a2bf3",
                "name": "Neural Computation",
                "alternate_names": [
                    "Neural Comput"
                ],
                "issn": "0899-7667",
                "url": "http://cognet.mit.edu/library/journals/journal?issn=08997667"
            },
            "year": 1998,
            "externalIds": {
                "MAG": "2107636931",
                "DBLP": "journals/neco/BishopSW98",
                "DOI": "10.1162/089976698300017953",
                "CorpusId": 207605229
            },
            "abstract": "Latent variable models represent the probability density of data in a space of several dimensions in terms of a smaller number of latent, or hidden, variables. A familiar example is factor analysis, which is based on a linear transformation between the latent space and the data space. In this article, we introduce a form of nonlinear latent variable model called the generative topographic mapping, for which the parameters of the model can be determined using the expectation-maximization algorithm. GTM provides a principled alternative to the widely used self-organizing map (SOM) of Kohonen (1982) and overcomes most of the significant limitations of the SOM. We demonstrate the performance of the GTM algorithm on a toy problem and on simulated data from flow diagnostics for a multiphase oil pipeline.",
            "referenceCount": 111,
            "citationCount": 1500,
            "influentialCitationCount": 188,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://publications.aston.ac.uk/id/eprint/1128/1/NCRG_96_015%5B1%5D.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Neural Computation",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Bishop1998GTMTG,\n author = {Charles M. Bishop and M. Svens\u00e9n and Christopher K. I. Williams},\n booktitle = {Neural Computation},\n journal = {Neural Computation},\n pages = {215-234},\n title = {GTM: The Generative Topographic Mapping},\n volume = {10},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e92e8afe2c218fe0f807ace0ff9593d6ae316765",
            "@type": "ScholarlyArticle",
            "paperId": "e92e8afe2c218fe0f807ace0ff9593d6ae316765",
            "corpusId": 6314431,
            "url": "https://www.semanticscholar.org/paper/e92e8afe2c218fe0f807ace0ff9593d6ae316765",
            "title": "A Bayesian Data Augmentation Approach for Learning Deep Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2751049198",
                "DBLP": "journals/corr/abs-1710-10564",
                "ArXiv": "1710.10564",
                "CorpusId": 6314431
            },
            "abstract": "Data augmentation is an essential part of the training process applied to deep learning models. The motivation is that a robust training process for deep learning models depends on large annotated datasets, which are expensive to be acquired, stored and processed. Therefore a reasonable alternative is to be able to automatically generate new annotated training samples using a process known as data augmentation. The dominant data augmentation approach in the field assumes that new training samples can be obtained via random geometric or appearance transformations applied to annotated training samples, but this is a strong assumption because it is unclear if this is a reliable generative model for producing new training samples. In this paper, we provide a novel Bayesian formulation to data augmentation, where new annotated training points are treated as missing variables and generated based on the distribution learned from the training set. For learning, we introduce a theoretically sound algorithm --- generalised Monte Carlo expectation maximisation, and demonstrate one possible implementation via an extension of the Generative Adversarial Network (GAN). Classification results on MNIST, CIFAR-10 and CIFAR-100 show the better performance of our proposed method compared to the current dominant data augmentation approach mentioned above --- the results also show that our approach produces better classification results than similar GAN models.",
            "referenceCount": 32,
            "citationCount": 207,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-10-29",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1710.10564"
            },
            "citationStyles": {
                "bibtex": "@Article{Tran2017ABD,\n author = {Toan Tran and Trung T. Pham and G. Carneiro and L. Palmer and I. Reid},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {A Bayesian Data Augmentation Approach for Learning Deep Models},\n volume = {abs/1710.10564},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4f756a37ecc75a50a834db7239912a32a9a85d85",
            "@type": "ScholarlyArticle",
            "paperId": "4f756a37ecc75a50a834db7239912a32a9a85d85",
            "corpusId": 217711597,
            "url": "https://www.semanticscholar.org/paper/4f756a37ecc75a50a834db7239912a32a9a85d85",
            "title": "Bayesian Optimization for Likelihood-Free Inference of Simulator-Based Statistical Models",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2949160015",
                "DBLP": "journals/jmlr/GutmannC16",
                "ArXiv": "1501.03291",
                "CorpusId": 217711597
            },
            "abstract": "Our paper deals with inferring simulator-based statistical models given some observed data. A simulator-based model is a parametrized mechanism which specifies how data are generated. It is thus also referred to as generative model. We assume that only a finite number of parameters are of interest and allow the generative process to be very general; it may be a noisy nonlinear dynamical system with an unrestricted number of hidden variables. This weak assumption is useful for devising realistic models but it renders statistical inference very difficult. The main challenge is the intractability of the likelihood function. Several likelihood-free inference methods have been proposed which share the basic idea of identifying the parameters by finding values for which the discrepancy between simulated and observed data is small. A major obstacle to using these methods is their computational cost. The cost is largely due to the need to repeatedly simulate data sets and the lack of knowledge about how the parameters affect the discrepancy. We propose a strategy which combines probabilistic modeling of the discrepancy with optimization to facilitate likelihood-free inference. The strategy is implemented using Bayesian optimization and is shown to accelerate the inference through a reduction in the number of required simulations by several orders of magnitude.",
            "referenceCount": 73,
            "citationCount": 263,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-01-14",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "17"
            },
            "citationStyles": {
                "bibtex": "@Article{Gutmann2015BayesianOF,\n author = {Michael U Gutmann and J. Corander},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {125:1-125:47},\n title = {Bayesian Optimization for Likelihood-Free Inference of Simulator-Based Statistical Models},\n volume = {17},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:15355e8e66598003640cdcc35426d3ef1fb97164",
            "@type": "ScholarlyArticle",
            "paperId": "15355e8e66598003640cdcc35426d3ef1fb97164",
            "corpusId": 3365953,
            "url": "https://www.semanticscholar.org/paper/15355e8e66598003640cdcc35426d3ef1fb97164",
            "title": "Learning about Social Learning in MOOCs: From Statistical Analysis to Generative Model",
            "venue": "IEEE Transactions on Learning Technologies",
            "publicationVenue": {
                "id": "urn:research:4e5cb97d-ea4b-4096-a3a7-7e57677a366d",
                "name": "IEEE Transactions on Learning Technologies",
                "alternate_names": [
                    "IEEE Trans Learn Technol"
                ],
                "issn": "1939-1382",
                "url": "https://www.computer.org/web/tlt/about-tlt"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2951287706",
                "DBLP": "journals/tlt/BrintonCJLLW14",
                "ArXiv": "1312.2159",
                "DOI": "10.1109/TLT.2014.2337900",
                "CorpusId": 3365953
            },
            "abstract": "We study user behavior in the courses offered by a major massive online open course (MOOC) provider during the summer of 2013. Since social learning is a key element of scalable education on MOOC and is done via online discussion forums, our main focus is on understanding forum activities. Two salient features of these activities drive our research: (1) high decline rate: for each course studied, the volume of discussion declined continuously throughout the duration of the course; (2) high-volume, noisy discussions: at least 30 percent of the courses produced new threads at rates that are infeasible for students or teaching staff to read through. Further, a substantial portion of these discussions are not directly course-related. In our analysis, we investigate factors that are associated with the decline of activity on MOOC forums, and we find effective strategies to classify threads and rank their relevance. Specifically, we first use linear regression models to analyze the forum activity count data over time, and make a number of observations; for instance, the teaching staff's active participation in the discussions is correlated with an increase in the discussion volume but does not slow down the decline rate. We then propose a unified generative model for the discussion threads, which allows us both to choose efficient thread classifiers and to design an effective algorithm for ranking thread relevance. Further, our algorithm is compared against two baselines using human evaluation from Amazon Mechanical Turk.",
            "referenceCount": 37,
            "citationCount": 254,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/4620076/6994335/06851916.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-12-07",
            "journal": {
                "name": "IEEE Transactions on Learning Technologies",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Brinton2013LearningAS,\n author = {Christopher G. Brinton and M. Chiang and Shaili Jain and H. Lam and Zhenming Liu and F. M. F. Wong},\n booktitle = {IEEE Transactions on Learning Technologies},\n journal = {IEEE Transactions on Learning Technologies},\n pages = {346-359},\n title = {Learning about Social Learning in MOOCs: From Statistical Analysis to Generative Model},\n volume = {7},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f85ae1e4d79e5d5d7e9c10bded2490fe41790496",
            "@type": "ScholarlyArticle",
            "paperId": "f85ae1e4d79e5d5d7e9c10bded2490fe41790496",
            "corpusId": 5298478,
            "url": "https://www.semanticscholar.org/paper/f85ae1e4d79e5d5d7e9c10bded2490fe41790496",
            "title": "Linear dynamical neural population models through nonlinear embeddings",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/nips/GaoAPC16",
                "MAG": "2952139049",
                "ArXiv": "1605.08454",
                "CorpusId": 5298478
            },
            "abstract": "A body of recent work in modeling neural activity focuses on recovering low-dimensional latent features that capture the statistical structure of large-scale neural populations. Most such approaches have focused on linear generative models, where inference is computationally tractable. Here, we propose fLDS, a general class of nonlinear generative models that permits the firing rate of each neuron to vary as an arbitrary smooth function of a latent, linear dynamical state. This extra flexibility allows the model to capture a richer set of neural variability than a purely linear model, but retains an easily visualizable low-dimensional latent space. To fit this class of non-conjugate models we propose a variational inference scheme, along with a novel approximate posterior capable of capturing rich temporal correlations across time. We show that our techniques permit inference in a wide class of generative models.We also show in application to two neural datasets that, compared to state-of-the-art neural population models, fLDS captures a much larger proportion of neural variability with a small number of latent dimensions, providing superior predictive performance and interpretability.",
            "referenceCount": 30,
            "citationCount": 141,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Biology",
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-05-26",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gao2016LinearDN,\n author = {Yuanjun Gao and Evan Archer and L. Paninski and J. Cunningham},\n booktitle = {Neural Information Processing Systems},\n pages = {163-171},\n title = {Linear dynamical neural population models through nonlinear embeddings},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ea775c61144a28136239f1edfa09b6fedd571db0",
            "@type": "ScholarlyArticle",
            "paperId": "ea775c61144a28136239f1edfa09b6fedd571db0",
            "corpusId": 17848107,
            "url": "https://www.semanticscholar.org/paper/ea775c61144a28136239f1edfa09b6fedd571db0",
            "title": "Unsupervised query segmentation using generative language models and wikipedia",
            "venue": "The Web Conference",
            "publicationVenue": {
                "id": "urn:research:e07422f9-c065-40c3-a37b-75e98dce79fe",
                "name": "The Web Conference",
                "alternate_names": [
                    "Web Conf",
                    "WWW"
                ],
                "issn": null,
                "url": "http://www.iw3c2.org/"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2423725643",
                "DBLP": "conf/www/TanP08",
                "DOI": "10.1145/1367497.1367545",
                "CorpusId": 17848107
            },
            "abstract": "In this paper, we propose a novel unsupervised approach to query segmentation, an important task in Web search. We use a generative query model to recover a query's underlying concepts that compose its original segmented form. The model's parameters are estimated using an expectation-maximization (EM) algorithm, optimizing the minimum description length objective function on a partial corpus that is specific to the query. To augment this unsupervised learning, we incorporate evidence from Wikipedia.\n Experiments show that our approach dramatically improves performance over the traditional approach that is based on mutual information, and produces comparable results with a supervised method. In particular, the basic generative language model contributes a 7.4% improvement over the mutual information based method (measured by segment F1 on the Intersection test set). EM optimization further improves the performance by 14.3%. Additional knowledge from Wikipedia provides another improvement of 24.3%, adding up to a total of 46% improvement (from 0.530 to 0.774).",
            "referenceCount": 29,
            "citationCount": 174,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cse.iitb.ac.in/~soumen/doc/www2013/QirWoo/TanP2008QuerySegment.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-04-21",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tan2008UnsupervisedQS,\n author = {Bin Tan and Fuchun Peng},\n booktitle = {The Web Conference},\n pages = {347-356},\n title = {Unsupervised query segmentation using generative language models and wikipedia},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f5d565d307a746d8bc0feb52c873995af698deca",
            "@type": "ScholarlyArticle",
            "paperId": "f5d565d307a746d8bc0feb52c873995af698deca",
            "corpusId": 16216752,
            "url": "https://www.semanticscholar.org/paper/f5d565d307a746d8bc0feb52c873995af698deca",
            "title": "Principled Hybrids of Generative and Discriminative Models",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2153939756",
                "DBLP": "conf/cvpr/LasserreBM06",
                "DOI": "10.1109/CVPR.2006.227",
                "CorpusId": 16216752
            },
            "abstract": "When labelled training data is plentiful, discriminative techniques are widely used since they give excellent generalization performance. However, for large-scale applications such as object recognition, hand labelling of data is expensive, and there is much interest in semi-supervised techniques based on generative models in which the majority of the training data is unlabelled. Although the generalization performance of generative models can often be improved by \u2018training them discriminatively\u2019, they can then no longer make use of unlabelled data. In an attempt to gain the benefit of both generative and discriminative approaches, heuristic procedure have been proposed [2, 3] which interpolate between these two extremes by taking a convex combination of the generative and discriminative objective functions. In this paper we adopt a new perspective which says that there is only one correct way to train a given model, and that a \u2018discriminatively trained\u2019 generative model is fundamentally a new model [7]. From this viewpoint, generative and discriminative models correspond to specific choices for the prior over parameters. As well as giving a principled interpretation of \u2018discriminative training\u2019, this approach opens door to very general ways of interpolating between generative and discriminative extremes through alternative choices of prior. We illustrate this framework using both synthetic data and a practical example in the domain of multi-class object recognition. Our results show that, when the supply of labelled training data is limited, the optimum performance corresponds to a balance between the purely generative and the purely discriminative.",
            "referenceCount": 14,
            "citationCount": 380,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-06-17",
            "journal": {
                "name": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Lasserre2006PrincipledHO,\n author = {Julia A. Lasserre and Charles M. Bishop and T. Minka},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},\n pages = {87-94},\n title = {Principled Hybrids of Generative and Discriminative Models},\n volume = {1},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:36a7b1a82390f5291b3bf8ff592f8630b4f33442",
            "@type": "ScholarlyArticle",
            "paperId": "36a7b1a82390f5291b3bf8ff592f8630b4f33442",
            "corpusId": 18706304,
            "url": "https://www.semanticscholar.org/paper/36a7b1a82390f5291b3bf8ff592f8630b4f33442",
            "title": "Neural Net Models for Open-Domain Discourse Coherence",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/LiJ16b",
                "MAG": "2411759152",
                "ArXiv": "1606.01545",
                "CorpusId": 18706304
            },
            "abstract": "Discourse coherence is strongly associated with text quality, making it important to natural language generation and understanding. Yet existing models of coherence focus on measuring individual aspects of coherence (lexical overlap, rhetorical structure, entity centering) in narrow domains. \nIn this paper, we describe domain-independent neural models of discourse coherence that are capable of measuring multiple aspects of coherence in existing sentences and can maintain coherence while generating new sentences. We study both discriminative models that learn to distinguish coherent from incoherent discourse, and generative models that produce coherent text, including a novel neural latent-variable Markovian generative model that captures the latent discourse dependencies between sentences in a text. \nOur work achieves state-of-the-art performance on multiple coherence evaluations, and marks an initial step in generating coherent texts given discourse contexts.",
            "referenceCount": 73,
            "citationCount": 117,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-06-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1606.01545"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2016NeuralNM,\n author = {Jiwei Li and Dan Jurafsky},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Neural Net Models for Open-Domain Discourse Coherence},\n volume = {abs/1606.01545},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:74ab1f58c81889deea75f87da74e3c62911ceda6",
            "@type": "ScholarlyArticle",
            "paperId": "74ab1f58c81889deea75f87da74e3c62911ceda6",
            "corpusId": 4687946,
            "url": "https://www.semanticscholar.org/paper/74ab1f58c81889deea75f87da74e3c62911ceda6",
            "title": "A Scalable Generative Graph Model with Community Structure",
            "venue": "SIAM Journal on Scientific Computing",
            "publicationVenue": {
                "id": "urn:research:0e3b51a7-21d8-477c-8918-14a55f087532",
                "name": "SIAM Journal on Scientific Computing",
                "alternate_names": [
                    "SIAM J Sci Comput"
                ],
                "issn": "1064-8275",
                "url": "http://www.siam.org/journals/sisc.php"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2028314260",
                "DBLP": "journals/siamsc/KoldaPPS14",
                "ArXiv": "1302.6636",
                "DOI": "10.1137/130914218",
                "CorpusId": 4687946
            },
            "abstract": "Network data is ubiquitous and growing, yet we lack realistic generative network models that can be calibrated to match real-world data. The recently proposed Block Two-Level Erdss-Renyi (BTER) model can be tuned to capture two fundamental properties: degree distribution and clustering coefficients. The latter is particularly important for reproducing graphs with community structure, such as social networks. In this paper, we compare BTER to other scalable models and show that it gives a better fit to real data. We provide a scalable implementation that requires only O(d_max) storage where d_max is the maximum number of neighbors for a single node. The generator is trivially parallelizable, and we show results for a Hadoop MapReduce implementation for a modeling a real-world web graph with over 4.6 billion edges. We propose that the BTER model can be used as a graph generator for benchmarking purposes and provide idealized degree distributions and clustering coefficient profiles that can be tuned for user specifications.",
            "referenceCount": 55,
            "citationCount": 162,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1302.6636",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-02-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1302.6636"
            },
            "citationStyles": {
                "bibtex": "@Article{Kolda2013ASG,\n author = {T. Kolda and Ali Pinar and T. Plantenga and Seshadhri Comandur},\n booktitle = {SIAM Journal on Scientific Computing},\n journal = {ArXiv},\n title = {A Scalable Generative Graph Model with Community Structure},\n volume = {abs/1302.6636},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:34c23b682bb1f02e9e05746758615d0282d42d26",
            "@type": "ScholarlyArticle",
            "paperId": "34c23b682bb1f02e9e05746758615d0282d42d26",
            "corpusId": 180902,
            "url": "https://www.semanticscholar.org/paper/34c23b682bb1f02e9e05746758615d0282d42d26",
            "title": "Reactive, generative, and stratified models of probabilistic processes",
            "venue": "[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1990,
            "externalIds": {
                "MAG": "2135657750",
                "DBLP": "conf/lics/GlabbeekSST90",
                "DOI": "10.1109/LICS.1990.113740",
                "CorpusId": 180902
            },
            "abstract": "Reactive, generative, and stratified models are considered within the framework of PCCS, a specification language for probabilistic processes. A structural operational semantics of PCCS, given as a set of inference rules for each of the models, a notion of bisimulation semantics, and some conference proofs are presented.<<ETX>>",
            "referenceCount": 21,
            "citationCount": 586,
            "influentialCitationCount": 52,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1990-06-04",
            "journal": {
                "name": "[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Glabbeek1990ReactiveGA,\n author = {R. V. Glabbeek and S. Smolka and B. Steffen},\n booktitle = {[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science},\n journal = {[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science},\n pages = {130-141},\n title = {Reactive, generative, and stratified models of probabilistic processes},\n year = {1990}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5c306ce578a8da634a4a64fce282a48d0eacfda1",
            "@type": "ScholarlyArticle",
            "paperId": "5c306ce578a8da634a4a64fce282a48d0eacfda1",
            "corpusId": 8005619,
            "url": "https://www.semanticscholar.org/paper/5c306ce578a8da634a4a64fce282a48d0eacfda1",
            "title": "Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2949727452",
                "DBLP": "conf/nips/MansinghkaKPT13",
                "ArXiv": "1307.0060",
                "CorpusId": 8005619
            },
            "abstract": "The idea of computer vision as the Bayesian inverse problem to computer graphics has a long history and an appealing elegance, but it has proved difficult to directly implement. Instead, most vision tasks are approached via complex bottom-up processing pipelines. Here we show that it is possible to write short, simple probabilistic graphics programs that define flexible generative models and to automatically invert them to interpret real-world images. Generative probabilistic graphics programs (GPGP) consist of a stochastic scene generator, a renderer based on graphics software, a stochastic likelihood model linking the renderer's output and the data, and latent variables that adjust the fidelity of the renderer and the tolerance of the likelihood. Representations and algorithms from computer graphics are used as the deterministic backbone for highly approximate and stochastic generative models. This formulation combines probabilistic programming, computer graphics, and approximate Bayesian computation, and depends only on general-purpose, automatic inference techniques. We describe two applications: reading sequences of degraded and adversarially obscured characters, and inferring 3D road models from vehicle-mounted camera images. Each of the probabilistic graphics programs we present relies on under 20 lines of probabilistic code, and yields accurate, approximately Bayesian inferences about real-world images.",
            "referenceCount": 26,
            "citationCount": 103,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-06-28",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1307.0060"
            },
            "citationStyles": {
                "bibtex": "@Article{Mansinghka2013ApproximateBI,\n author = {Vikash K. Mansinghka and Tejas D. Kulkarni and Yura N. Perov and J. Tenenbaum},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs},\n volume = {abs/1307.0060},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4d8bb2828066de726b31889e45abbf4768894517",
            "@type": "ScholarlyArticle",
            "paperId": "4d8bb2828066de726b31889e45abbf4768894517",
            "corpusId": 15603956,
            "url": "https://www.semanticscholar.org/paper/4d8bb2828066de726b31889e45abbf4768894517",
            "title": "A simple generative model of collective online behavior",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2013,
            "externalIds": {
                "ArXiv": "1305.7440",
                "MAG": "2171140587",
                "DBLP": "journals/corr/GleesonCOPR13",
                "DOI": "10.1073/pnas.1313895111",
                "CorpusId": 15603956,
                "PubMed": "25002470"
            },
            "abstract": "Significance One of the most common strategies in studying complex systems is to investigate and interpret whether any \u201chidden order\u201d is present by fitting observed statistical regularities via data analysis and then reproducing such regularities with long-time or equilibrium dynamics from some generative model. Unfortunately, many different models can possess indistinguishable long-time dynamics, so the above recipe is often insufficient to discern the relative quality of competing models. In this paper, we use the example of collective online behavior to illustrate that, by contrast, time-dependent modeling can be very effective at disentangling competing generative models of a complex system. Human activities increasingly take place in online environments, providing novel opportunities for relating individual behaviors to population-level outcomes. In this paper, we introduce a simple generative model for the collective behavior of millions of social networking site users who are deciding between different software applications. Our model incorporates two distinct mechanisms: one is associated with recent decisions of users, and the other reflects the cumulative popularity of each application. Importantly, although various combinations of the two mechanisms yield long-time behavior that is consistent with data, the only models that reproduce the observed temporal dynamics are those that strongly emphasize the recent popularity of applications over their cumulative popularity. This demonstrates\u2014even when using purely observational data without experimental design\u2014that temporal data-driven modeling can effectively distinguish between competing microscopic mechanisms, allowing us to uncover previously unidentified aspects of collective online behavior.",
            "referenceCount": 68,
            "citationCount": 94,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pnas.org/content/pnas/111/29/10411.full.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-05-31",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences",
                "volume": "111"
            },
            "citationStyles": {
                "bibtex": "@Article{Gleeson2013ASG,\n author = {J. Gleeson and D. Cellai and J. Onnela and M. Porter and F. Reed-Tsochas},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {10411 - 10415},\n title = {A simple generative model of collective online behavior},\n volume = {111},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f87247fb37f6b48da0757d7a1acf38da44510cdb",
            "@type": "ScholarlyArticle",
            "paperId": "f87247fb37f6b48da0757d7a1acf38da44510cdb",
            "corpusId": 16935709,
            "url": "https://www.semanticscholar.org/paper/f87247fb37f6b48da0757d7a1acf38da44510cdb",
            "title": "Stochastic Back-propagation and Variational Inference in Deep Latent Gaussian Models",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/corr/RezendeMW14",
                "ArXiv": "1401.4082",
                "MAG": "1844684489",
                "CorpusId": 16935709
            },
            "abstract": "We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic back-propagation -- rules for back-propagation through stochastic variables -- and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.",
            "referenceCount": 27,
            "citationCount": 127,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-01-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1401.4082"
            },
            "citationStyles": {
                "bibtex": "@Article{Rezende2014StochasticBA,\n author = {Danilo Jimenez Rezende and S. Mohamed and Daan Wierstra},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Stochastic Back-propagation and Variational Inference in Deep Latent Gaussian Models},\n volume = {abs/1401.4082},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6a3819476b99a238d37beb00c878c5602cc639e8",
            "@type": "ScholarlyArticle",
            "paperId": "6a3819476b99a238d37beb00c878c5602cc639e8",
            "corpusId": 503611,
            "url": "https://www.semanticscholar.org/paper/6a3819476b99a238d37beb00c878c5602cc639e8",
            "title": "Why Generative Phrase Models Underperform Surface Heuristics",
            "venue": "WMT@HLT-NAACL",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2148675933",
                "ACL": "W06-3105",
                "DBLP": "conf/wmt/DeNeroGZK06",
                "DOI": "10.3115/1654650.1654656",
                "CorpusId": 503611
            },
            "abstract": "We investigate why weights from generative models underperform heuristic estimates in phrase-based machine translation. We first propose a simple generative, phrase-based model and verify that its estimates are inferior to those given by surface statistics. The performance gap stems primarily from the addition of a hidden segmentation variable, which increases the capacity for overfitting during maximum likelihood training with EM. In particular, while word level models benefit greatly from re-estimation, phrase-level models do not: the crucial difference is that distinct word alignments cannot all be correct, while distinct segmentations can. Alternate segmentations rather than alternate alignments compete, resulting in increased deter-minization of the phrase table, decreased generalization, and decreased final BLEU score. We also show that interpolation of the two methods can result in a modest increase in BLEU score.",
            "referenceCount": 10,
            "citationCount": 84,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=1654656&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-06-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{DeNero2006WhyGP,\n author = {John DeNero and D. Gillick and James Zhang and D. Klein},\n booktitle = {WMT@HLT-NAACL},\n pages = {31-38},\n title = {Why Generative Phrase Models Underperform Surface Heuristics},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:33f33197434dbcb6dbe5b2f5e27d646262fcd19d",
            "@type": "ScholarlyArticle",
            "paperId": "33f33197434dbcb6dbe5b2f5e27d646262fcd19d",
            "corpusId": 65485,
            "url": "https://www.semanticscholar.org/paper/33f33197434dbcb6dbe5b2f5e27d646262fcd19d",
            "title": "Generative Content Models for Structural Analysis of Medical Abstracts",
            "venue": "BioNLP@NAACL-HLT",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "ACL": "W06-3309",
                "MAG": "2121678130",
                "DBLP": "conf/bionlp/LinKDK06",
                "DOI": "10.3115/1567619.1567631",
                "CorpusId": 65485
            },
            "abstract": "The ability to accurately model the content structure of text is important for many natural language processing applications. This paper describes experiments with generative models for analyzing the discourse structure of medical abstracts, which generally follow the pattern of \"introduction\", \"methods\", \"results\", and \"conclusions\". We demonstrate that Hidden Markov Models are capable of accurately capturing the structure of such texts, and can achieve classification accuracy comparable to that of discriminative techniques. In addition, generative approaches provide advantages that may make them preferable to discriminative techniques such as Support Vector Machines under certain conditions. Our work makes two contributions: at the application level, we report good performance on an interesting task in an important domain; more generally, our results contribute to an ongoing discussion regarding the tradeoffs between generative and discriminative techniques.",
            "referenceCount": 30,
            "citationCount": 86,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.5555/1654415.1654427",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-06-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lin2006GenerativeCM,\n author = {Jimmy J. Lin and D. Karakos and Dina Demner-Fushman and S. Khudanpur},\n booktitle = {BioNLP@NAACL-HLT},\n pages = {65-72},\n title = {Generative Content Models for Structural Analysis of Medical Abstracts},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8d2b706dd0aaae1bec2c74f0b66c3e4b1ede57ab",
            "@type": "ScholarlyArticle",
            "paperId": "8d2b706dd0aaae1bec2c74f0b66c3e4b1ede57ab",
            "corpusId": 31172593,
            "url": "https://www.semanticscholar.org/paper/8d2b706dd0aaae1bec2c74f0b66c3e4b1ede57ab",
            "title": "An Information-Theoretic Analysis of Deep Latent-Variable Models",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1711.00464",
                "DBLP": "journals/corr/abs-1711-00464",
                "MAG": "2766227112",
                "CorpusId": 31172593
            },
            "abstract": "We present an information-theoretic framework for understanding trade-offs in unsupervised learning of deep latent-variables models using variational inference. This framework emphasizes the need to consider latent-variable models along two dimensions: the ability to reconstruct inputs (distortion) and the communication cost (rate). We derive the optimal frontier of generative models in the two-dimensional rate-distortion plane, and show how the standard evidence lower bound objective is insufficient to select between points along this frontier. However, by performing targeted optimization to learn generative models with different rates, we are able to learn many models that can achieve similar generative performance but make vastly different trade-offs in terms of the usage of the latent variable. Through experiments on MNIST and Omniglot with a variety of architectures, we show how our framework sheds light on many recent proposed extensions to the variational autoencoder family.",
            "referenceCount": 64,
            "citationCount": 75,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1711.00464"
            },
            "citationStyles": {
                "bibtex": "@Article{Alemi2017AnIA,\n author = {Alexander A. Alemi and Ben Poole and Ian S. Fischer and Joshua V. Dillon and R. Saurous and K. Murphy},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {An Information-Theoretic Analysis of Deep Latent-Variable Models},\n volume = {abs/1711.00464},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:94a8ace25d5112e22f7235bbba26570b008a73e9",
            "@type": "ScholarlyArticle",
            "paperId": "94a8ace25d5112e22f7235bbba26570b008a73e9",
            "corpusId": 3343003,
            "url": "https://www.semanticscholar.org/paper/94a8ace25d5112e22f7235bbba26570b008a73e9",
            "title": "LDA-based document models for ad-hoc retrieval",
            "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
            "publicationVenue": {
                "id": "urn:research:8dce23a9-44e0-4381-a39e-2acc1edff700",
                "name": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
                "alternate_names": [
                    "International ACM SIGIR Conference on Research and Development in Information Retrieval",
                    "Int ACM SIGIR Conf Res Dev Inf Retr",
                    "SIGIR",
                    "Annu Int ACM SIGIR Conf Res Dev Inf Retr"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigir/"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "conf/sigir/WeiC06",
                "MAG": "2042980227",
                "DOI": "10.1145/1148170.1148204",
                "CorpusId": 3343003
            },
            "abstract": "Search algorithms incorporating some form of topic model have a long history in information retrieval. For example, cluster-based retrieval has been studied since the 60s and has recently produced good results in the language model framework. An approach to building topic models based on a formal generative model of documents, Latent Dirichlet Allocation (LDA), is heavily cited in the machine learning literature, but its feasibility and effectiveness in information retrieval is mostly unknown. In this paper, we study how to efficiently use LDA to improve ad-hoc retrieval. We propose an LDA-based document model within the language modeling framework, and evaluate it on several TREC collections. Gibbs sampling is employed to conduct approximate inference in LDA and the computational complexity is analyzed. We show that improvements over retrieval using cluster-based models can be obtained with reasonable efficiency.",
            "referenceCount": 20,
            "citationCount": 1224,
            "influentialCitationCount": 134,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-08-06",
            "journal": {
                "name": "Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Wei2006LDAbasedDM,\n author = {Xing Wei and W. Bruce Croft},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval},\n title = {LDA-based document models for ad-hoc retrieval},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0e0801da1a187d90862cd00ce7f12222ff965ef0",
            "@type": "ScholarlyArticle",
            "paperId": "0e0801da1a187d90862cd00ce7f12222ff965ef0",
            "corpusId": 425446,
            "url": "https://www.semanticscholar.org/paper/0e0801da1a187d90862cd00ce7f12222ff965ef0",
            "title": "Classification with Hybrid Generative/Discriminative Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2003,
            "externalIds": {
                "DBLP": "conf/nips/RainaSNM03",
                "MAG": "2171849160",
                "CorpusId": 425446
            },
            "abstract": "Although discriminatively trained classifiers are usually more accurate when labeled training data is abundant, previous work has shown that when training data is limited, generative classifiers can out-perform them. This paper describes a hybrid model in which a high-dimensional subset of the parameters are trained to maximize generative likelihood, and another, small, subset of parameters are discriminatively trained to maximize conditional likelihood. We give a sample complexity bound showing that in order to fit the discriminative parameters well, the number of training examples required depends only on the logarithm of the number of feature occurrences and feature set size. Experimental results show that hybrid models can provide lower test error and can produce better accuracy/coverage curves than either their purely generative or purely discriminative counterparts. We also discuss several advantages of hybrid models, and advocate further work in this area.",
            "referenceCount": 18,
            "citationCount": 238,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2003-12-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Raina2003ClassificationWH,\n author = {Rajat Raina and Yirong Shen and A. Ng and A. McCallum},\n booktitle = {Neural Information Processing Systems},\n pages = {545-552},\n title = {Classification with Hybrid Generative/Discriminative Models},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7bd0a04b0f0687896e765b48619a27ee545e86db",
            "@type": "ScholarlyArticle",
            "paperId": "7bd0a04b0f0687896e765b48619a27ee545e86db",
            "corpusId": 61970057,
            "url": "https://www.semanticscholar.org/paper/7bd0a04b0f0687896e765b48619a27ee545e86db",
            "title": "On the parameter space of generative lexicalized statistical parsing models",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2305592425",
                "CorpusId": 61970057
            },
            "abstract": "In this thesis, we apply as well as develop techniques and methodologies for the examination of the complex systems that are lexicalized statistical parsing models. The primary idea is that of treating the \u201cmodel as data\u201d, which is not a particular method, but a paradigm and a research methodology. Our argument is that lexicalized statistical parsing models have become increasingly complex, and therefore require thorough scrutiny, both to achieve the scientific aim of understanding what has been built thus far, and to achieve both the scientific and engineering goal of using that understanding for progress. In this thesis, we take a particular, dominant type of parsing model and perform a macro analysis, to reveal its core (and design a software engine that modularizes the periphery), and we also crucially perform a detailed analysis, which provides for the first time a window onto the efficacy of specific parameters. These analyses have not only yielded insight into the core model, but they have also enabled the identification of \u201cinefficiencies\u201d in our baseline model, such that those inefficiencies can be reduced to form a more compact model, or exploited for finding a better-estimated model with higher accuracy, or both.",
            "referenceCount": 79,
            "citationCount": 146,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Bikel2004OnTP,\n author = {Daniel M. Bikel and Mitchell P. Marcus},\n title = {On the parameter space of generative lexicalized statistical parsing models},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dc39505ef0c8b1bffa879a90b2b9c9de6f33f538",
            "@type": "ScholarlyArticle",
            "paperId": "dc39505ef0c8b1bffa879a90b2b9c9de6f33f538",
            "corpusId": 11803941,
            "url": "https://www.semanticscholar.org/paper/dc39505ef0c8b1bffa879a90b2b9c9de6f33f538",
            "title": "Using generative probabilistic models for multimedia retrieval",
            "venue": "SIGF",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "books/daglib/0012454",
                "MAG": "2167017068",
                "DOI": "10.1145/1067268.1067296",
                "CorpusId": 11803941
            },
            "abstract": "This thesis discusses information retrieval from multimedia archives, focusing on documents containing visual material. We investigate search and retrieval in collections of images and video, where video is defined as a sequence of still images. No assumptions are made with respect to the content of the documents; we concentrate on retrieval from generic, heterogeneous multimedia collections. In this research area a user's query typically consists of one or more example images and the implicit request is: \"Find images similar to this one.\" In addition the query may contain a textual description of the information need. The research presented here addresses three issues within this area.",
            "referenceCount": 107,
            "citationCount": 126,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ir.cwi.nl/pub/14951/14951B.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2005-06-01",
            "journal": {
                "name": "SIGIR Forum",
                "volume": "39"
            },
            "citationStyles": {
                "bibtex": "@Article{Westerveld2005UsingGP,\n author = {T. Westerveld},\n booktitle = {SIGF},\n journal = {SIGIR Forum},\n pages = {69},\n title = {Using generative probabilistic models for multimedia retrieval},\n volume = {39},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c5e322890ca7c3dd5bc77cd213a178183318a27b",
            "@type": "ScholarlyArticle",
            "paperId": "c5e322890ca7c3dd5bc77cd213a178183318a27b",
            "corpusId": 2688769,
            "url": "https://www.semanticscholar.org/paper/c5e322890ca7c3dd5bc77cd213a178183318a27b",
            "title": "Generative and recognition models for neuroanatomy",
            "venue": "NeuroImage",
            "publicationVenue": {
                "id": "urn:research:fd4c7628-c16e-4b50-8555-3ac3ad6da2d7",
                "name": "NeuroImage",
                "alternate_names": null,
                "issn": "1053-8119",
                "url": "http://www.elsevier.com/locate/ynimg"
            },
            "year": 2004,
            "externalIds": {
                "DBLP": "journals/neuroimage/FristonA04",
                "MAG": "1970710404",
                "DOI": "10.1016/j.neuroimage.2004.04.021",
                "CorpusId": 2688769,
                "PubMed": "15325348"
            },
            "abstract": null,
            "referenceCount": 12,
            "citationCount": 126,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "LettersAndComments"
            ],
            "publicationDate": "2004-09-01",
            "journal": {
                "name": "NeuroImage",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Friston2004GenerativeAR,\n author = {Karl J. Friston and J. Ashburner},\n booktitle = {NeuroImage},\n journal = {NeuroImage},\n pages = {21-24},\n title = {Generative and recognition models for neuroanatomy},\n volume = {23},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d3624a388fc90879a8f043aeacd6fd55e85160eb",
            "@type": "ScholarlyArticle",
            "paperId": "d3624a388fc90879a8f043aeacd6fd55e85160eb",
            "corpusId": 222240827,
            "url": "https://www.semanticscholar.org/paper/d3624a388fc90879a8f043aeacd6fd55e85160eb",
            "title": "Situations, mental models, and generative knowledge.",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1989,
            "externalIds": {
                "MAG": "3015008300",
                "CorpusId": 222240827
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 295,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Greeno1989SituationsMM,\n author = {J. Greeno},\n title = {Situations, mental models, and generative knowledge.},\n year = {1989}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:af9f365ed86614c800f082bd8eb14be76072ad16",
            "@type": "ScholarlyArticle",
            "paperId": "af9f365ed86614c800f082bd8eb14be76072ad16",
            "corpusId": 249145348,
            "url": "https://www.semanticscholar.org/paper/af9f365ed86614c800f082bd8eb14be76072ad16",
            "title": "Classifier-Free Diffusion Guidance",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2022,
            "externalIds": {
                "ArXiv": "2207.12598",
                "DBLP": "journals/corr/abs-2207-12598",
                "DOI": "10.48550/arXiv.2207.12598",
                "CorpusId": 249145348
            },
            "abstract": "Classifier guidance is a recently introduced method to trade off mode coverage and sample fidelity in conditional diffusion models post training, in the same spirit as low temperature sampling or truncation in other types of generative models. Classifier guidance combines the score estimate of a diffusion model with the gradient of an image classifier and thereby requires training an image classifier separate from the diffusion model. It also raises the question of whether guidance can be performed without a classifier. We show that guidance can be indeed performed by a pure generative model without such a classifier: in what we call classifier-free guidance, we jointly train a conditional and an unconditional diffusion model, and we combine the resulting conditional and unconditional score estimates to attain a trade-off between sample quality and diversity similar to that obtained using classifier guidance.",
            "referenceCount": 25,
            "citationCount": 1123,
            "influentialCitationCount": 148,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/2207.12598",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2022-07-26",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2207.12598"
            },
            "citationStyles": {
                "bibtex": "@Article{Ho2022ClassifierFreeDG,\n author = {Jonathan Ho},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Classifier-Free Diffusion Guidance},\n volume = {abs/2207.12598},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:571b0750085ae3d939525e62af510ee2cee9d5ea",
            "@type": "ScholarlyArticle",
            "paperId": "571b0750085ae3d939525e62af510ee2cee9d5ea",
            "corpusId": 1687220,
            "url": "https://www.semanticscholar.org/paper/571b0750085ae3d939525e62af510ee2cee9d5ea",
            "title": "Improved Techniques for Training GANs",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/nips/SalimansGZCRCC16",
                "ArXiv": "1606.03498",
                "MAG": "2949938177",
                "CorpusId": 1687220
            },
            "abstract": "We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.",
            "referenceCount": 28,
            "citationCount": 7381,
            "influentialCitationCount": 883,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-10",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1606.03498"
            },
            "citationStyles": {
                "bibtex": "@Article{Salimans2016ImprovedTF,\n author = {Tim Salimans and I. Goodfellow and Wojciech Zaremba and Vicki Cheung and Alec Radford and Xi Chen},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Improved Techniques for Training GANs},\n volume = {abs/1606.03498},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:edf73ab12595c6709f646f542a0d2b33eb20a3f4",
            "@type": "ScholarlyArticle",
            "paperId": "edf73ab12595c6709f646f542a0d2b33eb20a3f4",
            "corpusId": 10894094,
            "url": "https://www.semanticscholar.org/paper/edf73ab12595c6709f646f542a0d2b33eb20a3f4",
            "title": "Improved Training of Wasserstein GANs",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1704.00028",
                "MAG": "2605135824",
                "DBLP": "conf/nips/GulrajaniAADC17",
                "CorpusId": 10894094
            },
            "abstract": "Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.",
            "referenceCount": 37,
            "citationCount": 7820,
            "influentialCitationCount": 1504,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-31",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gulrajani2017ImprovedTO,\n author = {Ishaan Gulrajani and Faruk Ahmed and Mart\u00edn Arjovsky and Vincent Dumoulin and Aaron C. Courville},\n booktitle = {Neural Information Processing Systems},\n pages = {5767-5777},\n title = {Improved Training of Wasserstein GANs},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1a014a076cac3c7f5d81a084e296c095f9230437",
            "@type": "ScholarlyArticle",
            "paperId": "1a014a076cac3c7f5d81a084e296c095f9230437",
            "corpusId": 13942547,
            "url": "https://www.semanticscholar.org/paper/1a014a076cac3c7f5d81a084e296c095f9230437",
            "title": "Hierarchical Models in the Brain",
            "venue": "PLoS Comput. Biol.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "1977628053",
                "DBLP": "journals/ploscb/Friston08a",
                "PubMedCentral": "2570625",
                "DOI": "10.1371/journal.pcbi.1000211",
                "CorpusId": 13942547,
                "PubMed": "18989391"
            },
            "abstract": "This paper describes a general model that subsumes many parametric models for continuous data. The model comprises hidden layers of state-space or dynamic causal models, arranged so that the output of one provides input to another. The ensuing hierarchy furnishes a model for many types of data, of arbitrary complexity. Special cases range from the general linear model for static data to generalised convolution models, with system noise, for nonlinear time-series analysis. Crucially, all of these models can be inverted using exactly the same scheme, namely, dynamic expectation maximization. This means that a single model and optimisation scheme can be used to invert a wide range of models. We present the model and a brief review of its inversion to disclose the relationships among, apparently, diverse generative models of empirical data. We then show that this inversion can be formulated as a simple neural network and may provide a useful metaphor for inference and learning in the brain.",
            "referenceCount": 96,
            "citationCount": 807,
            "influentialCitationCount": 78,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1000211&type=printable",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2008-11-01",
            "journal": {
                "name": "PLoS Computational Biology",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Friston2008HierarchicalMI,\n author = {Karl J. Friston},\n booktitle = {PLoS Comput. Biol.},\n journal = {PLoS Computational Biology},\n title = {Hierarchical Models in the Brain},\n volume = {4},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5d90f06bb70a0a3dced62413346235c02b1aa086",
            "@type": "ScholarlyArticle",
            "paperId": "5d90f06bb70a0a3dced62413346235c02b1aa086",
            "corpusId": 18268744,
            "url": "https://www.semanticscholar.org/paper/5d90f06bb70a0a3dced62413346235c02b1aa086",
            "title": "Learning Multiple Layers of Features from Tiny Images",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2945315962",
                "CorpusId": 18268744
            },
            "abstract": "Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it dicult to learn a good set of lters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is signicantly improved by pre-training a layer of features on a large set of unlabeled tiny images.",
            "referenceCount": 15,
            "citationCount": 26458,
            "influentialCitationCount": 8109,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Krizhevsky2009LearningML,\n author = {A. Krizhevsky},\n title = {Learning Multiple Layers of Features from Tiny Images},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c871d2dc802d276608a6734637f8bc9e6da0d837",
            "@type": "ScholarlyArticle",
            "paperId": "c871d2dc802d276608a6734637f8bc9e6da0d837",
            "corpusId": 247292764,
            "url": "https://www.semanticscholar.org/paper/c871d2dc802d276608a6734637f8bc9e6da0d837",
            "title": "GeoDiff: a Geometric Diffusion Model for Molecular Conformation Generation",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2022,
            "externalIds": {
                "ArXiv": "2203.02923",
                "DBLP": "journals/corr/abs-2203-02923",
                "DOI": "10.48550/arXiv.2203.02923",
                "CorpusId": 247292764
            },
            "abstract": "Predicting molecular conformations from molecular graphs is a fundamental problem in cheminformatics and drug discovery. Recently, significant progress has been achieved with machine learning approaches, especially with deep generative models. Inspired by the diffusion process in classical non-equilibrium thermodynamics where heated particles will diffuse from original states to a noise distribution, in this paper, we propose a novel generative model named GeoDiff for molecular conformation prediction. GeoDiff treats each atom as a particle and learns to directly reverse the diffusion process (i.e., transforming from a noise distribution to stable conformations) as a Markov chain. Modeling such a generation process is however very challenging as the likelihood of conformations should be roto-translational invariant. We theoretically show that Markov chains evolving with equivariant Markov kernels can induce an invariant distribution by design, and further propose building blocks for the Markov kernels to preserve the desirable equivariance property. The whole framework can be efficiently trained in an end-to-end fashion by optimizing a weighted variational lower bound to the (conditional) likelihood. Experiments on multiple benchmarks show that GeoDiff is superior or comparable to existing state-of-the-art approaches, especially on large molecules.",
            "referenceCount": 56,
            "citationCount": 249,
            "influentialCitationCount": 26,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/2203.02923",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2022-03-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2203.02923"
            },
            "citationStyles": {
                "bibtex": "@Article{Xu2022GeoDiffAG,\n author = {Minkai Xu and Lantao Yu and Yang Song and Chence Shi and Stefano Ermon and Jian Tang},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {GeoDiff: a Geometric Diffusion Model for Molecular Conformation Generation},\n volume = {abs/2203.02923},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e95d3934e51107da7610acd0b1bcb6551671f9f1",
            "@type": "ScholarlyArticle",
            "paperId": "e95d3934e51107da7610acd0b1bcb6551671f9f1",
            "corpusId": 21145246,
            "url": "https://www.semanticscholar.org/paper/e95d3934e51107da7610acd0b1bcb6551671f9f1",
            "title": "A Practical Guide to Training Restricted Boltzmann Machines",
            "venue": "Neural Networks",
            "publicationVenue": {
                "id": "urn:research:a13f3cb8-2492-4ccb-9329-73a5ddcaab9b",
                "name": "Neural Networks",
                "alternate_names": [
                    "Neural Netw"
                ],
                "issn": "0893-6080",
                "url": "http://www.elsevier.com/locate/neunet"
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "series/lncs/Hinton12",
                "MAG": "44815768",
                "DOI": "10.1007/978-3-642-35289-8_32",
                "CorpusId": 21145246
            },
            "abstract": null,
            "referenceCount": 28,
            "citationCount": 3003,
            "influentialCitationCount": 331,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Hinton2012APG,\n author = {Geoffrey E. Hinton},\n booktitle = {Neural Networks},\n pages = {599-619},\n title = {A Practical Guide to Training Restricted Boltzmann Machines},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c539f6ab5818bde96f61298856cb0c38f6268369",
            "@type": "ScholarlyArticle",
            "paperId": "c539f6ab5818bde96f61298856cb0c38f6268369",
            "corpusId": 249879327,
            "url": "https://www.semanticscholar.org/paper/c539f6ab5818bde96f61298856cb0c38f6268369",
            "title": "On Aliased Resizing and Surprising Subtleties in GAN Evaluation",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2022,
            "externalIds": {
                "DBLP": "conf/cvpr/Parmar0Z22",
                "DOI": "10.1109/CVPR52688.2022.01112",
                "CorpusId": 249879327
            },
            "abstract": "Metrics for evaluating generative models aim to measure the discrepancy between real and generated images. The often-used Fr\u00e9chet Inception Distance (FID) metric, for example, extracts \u201chigh-level\u201d features using a deep network from the two sets. However, we find that the differences in \u201clow-level\u201d preprocessing, specifically image resizing and compression, can induce large variations and have unforeseen consequences. For instance, when resizing an image, e.g., with a bilinear or bicubic kernel, signal processing principles mandate adjusting prefilter width depending on the downsampling factor, to antialias to the appropriate bandwidth. However, commonly-used implementations use a fixed-width prefilter, resulting in aliasing artifacts. Such aliasing leads to corruptions in the feature extraction down-stream. Next, lossy compression, such as JPEG, is commonly used to reduce the file size of an image. Although designed to minimally degrade the perceptual quality of an image, the operation also produces variations downstream. Furthermore, we show that if compression is used on real training images, FID can actually improve if the generated images are also subsequently compressed. This paper shows that choices in low-level image processing have been an under-appreciated aspect of generative modeling. We identify and characterize variations in generative modeling development pipelines, provide recommendations based on signal processing principles, and release a reference implementation to facilitate future comparisons.",
            "referenceCount": 82,
            "citationCount": 153,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2104.11222",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2022-06-01",
            "journal": {
                "name": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Parmar2022OnAR,\n author = {Gaurav Parmar and Richard Zhang and Jun-Yan Zhu},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {11400-11410},\n title = {On Aliased Resizing and Surprising Subtleties in GAN Evaluation},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:15736f7c205d961c00378a938daffaacb5a0718d",
            "@type": "ScholarlyArticle",
            "paperId": "15736f7c205d961c00378a938daffaacb5a0718d",
            "corpusId": 252595883,
            "url": "https://www.semanticscholar.org/paper/15736f7c205d961c00378a938daffaacb5a0718d",
            "title": "Human Motion Diffusion Model",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2022,
            "externalIds": {
                "DBLP": "journals/corr/abs-2209-14916",
                "ArXiv": "2209.14916",
                "DOI": "10.48550/arXiv.2209.14916",
                "CorpusId": 252595883
            },
            "abstract": "Natural and expressive human motion generation is the holy grail of computer animation. It is a challenging task, due to the diversity of possible motion, human perceptual sensitivity to it, and the difficulty of accurately describing it. Therefore, current generative solutions are either low-quality or limited in expressiveness. Diffusion models, which have already shown remarkable generative capabilities in other domains, are promising candidates for human motion due to their many-to-many nature, but they tend to be resource hungry and hard to control. In this paper, we introduce Motion Diffusion Model (MDM), a carefully adapted classifier-free diffusion-based generative model for the human motion domain. MDM is transformer-based, combining insights from motion generation literature. A notable design-choice is the prediction of the sample, rather than the noise, in each diffusion step. This facilitates the use of established geometric losses on the locations and velocities of the motion, such as the foot contact loss. As we demonstrate, MDM is a generic approach, enabling different modes of conditioning, and different generation tasks. We show that our model is trained with lightweight resources and yet achieves state-of-the-art results on leading benchmarks for text-to-motion and action-to-motion. https://guytevet.github.io/mdm-page/ .",
            "referenceCount": 51,
            "citationCount": 217,
            "influentialCitationCount": 67,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/2209.14916",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2022-09-29",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2209.14916"
            },
            "citationStyles": {
                "bibtex": "@Article{Tevet2022HumanMD,\n author = {Guy Tevet and Sigal Raab and Brian Gordon and Yonatan Shafir and Daniel Cohen-Or and Amit H. Bermano},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Human Motion Diffusion Model},\n volume = {abs/2209.14916},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:712e32e2da67428ba6c6add1605410e1c3792883",
            "@type": "ScholarlyArticle",
            "paperId": "712e32e2da67428ba6c6add1605410e1c3792883",
            "corpusId": 210702798,
            "url": "https://www.semanticscholar.org/paper/712e32e2da67428ba6c6add1605410e1c3792883",
            "title": "Image Segmentation Using Deep Learning: A Survey",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2001.05566",
                "DBLP": "journals/corr/abs-2001-05566",
                "MAG": "2999607073",
                "DOI": "10.1109/TPAMI.2021.3059968",
                "CorpusId": 210702798,
                "PubMed": "33596172"
            },
            "abstract": "Image segmentation is a key task in computer vision and image processing with important applications such as scene understanding, medical image analysis, robotic perception, video surveillance, augmented reality, and image compression, among others, and numerous segmentation algorithms are found in the literature. Against this backdrop, the broad success of deep learning (DL) has prompted the development of new image segmentation approaches leveraging DL models. We provide a comprehensive review of this recent literature, covering the spectrum of pioneering efforts in semantic and instance segmentation, including convolutional pixel-labeling networks, encoder-decoder architectures, multiscale and pyramid-based approaches, recurrent networks, visual attention models, and generative models in adversarial settings. We investigate the relationships, strengths, and challenges of these DL-based segmentation models, examine the widely used datasets, compare performances, and discuss promising research directions.",
            "referenceCount": 205,
            "citationCount": 1620,
            "influentialCitationCount": 43,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2001.05566",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-01-15",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "44"
            },
            "citationStyles": {
                "bibtex": "@Article{Minaee2020ImageSU,\n author = {Shervin Minaee and Yuri Boykov and F. Porikli and A. Plaza and N. Kehtarnavaz and Demetri Terzopoulos},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {3523-3542},\n title = {Image Segmentation Using Deep Learning: A Survey},\n volume = {44},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:525f459f369032e2f2fa3eb1d60da34ab99191bc",
            "@type": "ScholarlyArticle",
            "paperId": "525f459f369032e2f2fa3eb1d60da34ab99191bc",
            "corpusId": 251710469,
            "url": "https://www.semanticscholar.org/paper/525f459f369032e2f2fa3eb1d60da34ab99191bc",
            "title": "Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2022,
            "externalIds": {
                "DBLP": "journals/corr/abs-2208-09392",
                "ArXiv": "2208.09392",
                "DOI": "10.48550/arXiv.2208.09392",
                "CorpusId": 251710469
            },
            "abstract": "Standard diffusion models involve an image transform -- adding Gaussian noise -- and an image restoration operator that inverts this degradation. We observe that the generative behavior of diffusion models is not strongly dependent on the choice of image degradation, and in fact an entire family of generative models can be constructed by varying this choice. Even when using completely deterministic degradations (e.g., blur, masking, and more), the training and test-time update rules that underlie diffusion models can be easily generalized to create generative models. The success of these fully deterministic models calls into question the community's understanding of diffusion models, which relies on noise in either gradient Langevin dynamics or variational inference, and paves the way for generalized diffusion models that invert arbitrary processes. Our code is available at https://github.com/arpitbansal297/Cold-Diffusion-Models",
            "referenceCount": 36,
            "citationCount": 126,
            "influentialCitationCount": 22,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/2208.09392",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2022-08-19",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2208.09392"
            },
            "citationStyles": {
                "bibtex": "@Article{Bansal2022ColdDI,\n author = {Arpit Bansal and Eitan Borgnia and Hong-Min Chu and Jie Li and Hamid Kazemi and Furong Huang and Micah Goldblum and Jonas Geiping and T. Goldstein},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise},\n volume = {abs/2208.09392},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2dcef55a07f8607a819c21fe84131ea269cc2e3c",
            "@type": "ScholarlyArticle",
            "paperId": "2dcef55a07f8607a819c21fe84131ea269cc2e3c",
            "corpusId": 14888175,
            "url": "https://www.semanticscholar.org/paper/2dcef55a07f8607a819c21fe84131ea269cc2e3c",
            "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2129069237",
                "DBLP": "journals/corr/Sohl-DicksteinW15",
                "ArXiv": "1503.03585",
                "CorpusId": 14888175
            },
            "abstract": "A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.",
            "referenceCount": 60,
            "citationCount": 2590,
            "influentialCitationCount": 269,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-03-11",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1503.03585"
            },
            "citationStyles": {
                "bibtex": "@Article{Sohl-Dickstein2015DeepUL,\n author = {Jascha Narain Sohl-Dickstein and Eric A. Weiss and Niru Maheswaranathan and S. Ganguli},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},\n volume = {abs/1503.03585},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:31b38a19d87711489786ad54a5a00d5f0b2ead43",
            "@type": "ScholarlyArticle",
            "paperId": "31b38a19d87711489786ad54a5a00d5f0b2ead43",
            "corpusId": 208910764,
            "url": "https://www.semanticscholar.org/paper/31b38a19d87711489786ad54a5a00d5f0b2ead43",
            "title": "Normalizing Flows: An Introduction and Review of Current Methods",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/pami/KobyzevPB21",
                "MAG": "3022376983",
                "DOI": "10.1109/TPAMI.2020.2992934",
                "CorpusId": 208910764,
                "PubMed": "32396070"
            },
            "abstract": "Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.",
            "referenceCount": 114,
            "citationCount": 784,
            "influentialCitationCount": 52,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/1908.09257",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-05-07",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "43"
            },
            "citationStyles": {
                "bibtex": "@Article{Kobyzev2020NormalizingFA,\n author = {I. Kobyzev and S. Prince and Marcus A. Brubaker},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {3964-3979},\n title = {Normalizing Flows: An Introduction and Review of Current Methods},\n volume = {43},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:30755a7614148f1acf5edca72385832410c7c33a",
            "@type": "ScholarlyArticle",
            "paperId": "30755a7614148f1acf5edca72385832410c7c33a",
            "corpusId": 2590898,
            "url": "https://www.semanticscholar.org/paper/30755a7614148f1acf5edca72385832410c7c33a",
            "title": "A Unifying Review of Linear Gaussian Models",
            "venue": "Neural Computation",
            "publicationVenue": {
                "id": "urn:research:69b9bcdd-8229-4a00-a6e0-00f0e99a2bf3",
                "name": "Neural Computation",
                "alternate_names": [
                    "Neural Comput"
                ],
                "issn": "0899-7667",
                "url": "http://cognet.mit.edu/library/journals/journal?issn=08997667"
            },
            "year": 1999,
            "externalIds": {
                "DBLP": "journals/neco/TRG99",
                "MAG": "2103139809",
                "DOI": "10.1162/089976699300016674",
                "CorpusId": 2590898,
                "PubMed": "9950734"
            },
            "abstract": "Factor analysis, principal component analysis, mixtures of gaussian clusters, vector quantization, Kalman filter models, and hidden Markov models can all be unified as variations of unsupervised learning under a single basic generative model. This is achieved by collecting together disparate observations and derivations made by many previous authors and introducing a new way of linking discrete and continuous state models using a simple nonlinearity. Through the use of other nonlinearities, we show how independent component analysis is also a variation of the same basic generative model. We show that factor analysis and mixtures of gaussians can be implemented in autoencoder neural networks and learned using squared error plus the same regularization term. We introduce a new model for static data, known as sensible principal component analysis, as well as a novel concept of spatially adaptive observation noise. We also review some of the literature involving global and local mixtures of the basic models and provide pseudocode for inference and learning for all the basic models.",
            "referenceCount": 79,
            "citationCount": 1043,
            "influentialCitationCount": 86,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://authors.library.caltech.edu/13697/1/ROWnc99.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "1999-02-01",
            "journal": {
                "name": "Neural Computation",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Roweis1999AUR,\n author = {S. Roweis and Zoubin Ghahramani},\n booktitle = {Neural Computation},\n journal = {Neural Computation},\n pages = {305-345},\n title = {A Unifying Review of Linear Gaussian Models},\n volume = {11},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:14fdc18d9c164e5b0d6d946b3238c04e81921358",
            "@type": "ScholarlyArticle",
            "paperId": "14fdc18d9c164e5b0d6d946b3238c04e81921358",
            "corpusId": 209202273,
            "url": "https://www.semanticscholar.org/paper/14fdc18d9c164e5b0d6d946b3238c04e81921358",
            "title": "Analyzing and Improving the Image Quality of StyleGAN",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3035574324",
                "DBLP": "conf/cvpr/KarrasLAHLA20",
                "ArXiv": "1912.04958",
                "DOI": "10.1109/cvpr42600.2020.00813",
                "CorpusId": 209202273
            },
            "abstract": "The style-based GAN architecture (StyleGAN) yields state-of-the-art results in data-driven unconditional generative image modeling. We expose and analyze several of its characteristic artifacts, and propose changes in both model architecture and training methods to address them. In particular, we redesign the generator normalization, revisit progressive growing, and regularize the generator to encourage good conditioning in the mapping from latent codes to images. In addition to improving image quality, this path length regularizer yields the additional benefit that the generator becomes significantly easier to invert. This makes it possible to reliably attribute a generated image to a particular network. We furthermore visualize how well the generator utilizes its output resolution, and identify a capacity problem, motivating us to train larger models for additional quality improvements. Overall, our improved model redefines the state of the art in unconditional image modeling, both in terms of existing distribution quality metrics as well as perceived image quality.",
            "referenceCount": 53,
            "citationCount": 3942,
            "influentialCitationCount": 1083,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1912.04958",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-12-03",
            "journal": {
                "name": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Karras2019AnalyzingAI,\n author = {Tero Karras and S. Laine and M. Aittala and Janne Hellsten and J. Lehtinen and Timo Aila},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {8107-8116},\n title = {Analyzing and Improving the Image Quality of StyleGAN},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ddc45fad8d15771d9f1f8579331458785b2cdd93",
            "@type": "ScholarlyArticle",
            "paperId": "ddc45fad8d15771d9f1f8579331458785b2cdd93",
            "corpusId": 877639,
            "url": "https://www.semanticscholar.org/paper/ddc45fad8d15771d9f1f8579331458785b2cdd93",
            "title": "Deep Boltzmann Machines",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "MAG": "189596042",
                "DBLP": "journals/jmlr/SalakhutdinovH09",
                "CorpusId": 877639
            },
            "abstract": "We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent expectations are estimated using a variational approximation that tends to focus on a single mode, and dataindependent expectations are approximated using persistent Markov chains. The use of two quite different techniques for estimating the two types of expectation that enter into the gradient of the log-likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer \u201cpre-training\u201d phase that allows variational inference to be initialized with a single bottomup pass. We present results on the MNIST and NORB datasets showing that deep Boltzmann machines learn good generative models and perform well on handwritten digit and visual object recognition tasks.",
            "referenceCount": 22,
            "citationCount": 2198,
            "influentialCitationCount": 248,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-04-15",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Salakhutdinov2009DeepBM,\n author = {R. Salakhutdinov and Geoffrey E. Hinton},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n pages = {448-455},\n title = {Deep Boltzmann Machines},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1e80f755bcbf10479afd2338cec05211fdbd325c",
            "@type": "ScholarlyArticle",
            "paperId": "1e80f755bcbf10479afd2338cec05211fdbd325c",
            "corpusId": 12008458,
            "url": "https://www.semanticscholar.org/paper/1e80f755bcbf10479afd2338cec05211fdbd325c",
            "title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2130325614",
                "DBLP": "conf/icml/LeeGRN09",
                "DOI": "10.1145/1553374.1553453",
                "CorpusId": 12008458
            },
            "abstract": "There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.",
            "referenceCount": 30,
            "citationCount": 2638,
            "influentialCitationCount": 206,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-06-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lee2009ConvolutionalDB,\n author = {Honglak Lee and R. Grosse and R. Ranganath and A. Ng},\n booktitle = {International Conference on Machine Learning},\n pages = {609-616},\n title = {Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3813b88a4ec3c63919df47e9694b577f4691f7e5",
            "@type": "ScholarlyArticle",
            "paperId": "3813b88a4ec3c63919df47e9694b577f4691f7e5",
            "corpusId": 195811894,
            "url": "https://www.semanticscholar.org/paper/3813b88a4ec3c63919df47e9694b577f4691f7e5",
            "title": "A survey on Image Data Augmentation for Deep Learning",
            "venue": "Journal of Big Data",
            "publicationVenue": {
                "id": "urn:research:d60da343-ab92-4310-b3d7-2c0860287a9d",
                "name": "Journal of Big Data",
                "alternate_names": [
                    "J Big Data",
                    "Journal on Big Data"
                ],
                "issn": "2196-1115",
                "url": "http://www.journalofbigdata.com/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/jbd/ShortenK19",
                "MAG": "2954996726",
                "DOI": "10.1186/s40537-019-0197-0",
                "CorpusId": 195811894
            },
            "abstract": null,
            "referenceCount": 142,
            "citationCount": 5801,
            "influentialCitationCount": 160,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-019-0197-0",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-07-06",
            "journal": {
                "name": "Journal of Big Data",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Shorten2019ASO,\n author = {Connor Shorten and T. Khoshgoftaar},\n booktitle = {Journal of Big Data},\n journal = {Journal of Big Data},\n pages = {1-48},\n title = {A survey on Image Data Augmentation for Deep Learning},\n volume = {6},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6af440915b8a0718c93be1cf61905e41e620484a",
            "@type": "ScholarlyArticle",
            "paperId": "6af440915b8a0718c93be1cf61905e41e620484a",
            "corpusId": 49312162,
            "url": "https://www.semanticscholar.org/paper/6af440915b8a0718c93be1cf61905e41e620484a",
            "title": "Deep One-Class Classification",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/icml/RuffGDSVBMK18",
                "MAG": "2803697594",
                "CorpusId": 49312162
            },
            "abstract": "Despite the great advances made by deep learning in many machine learning problems, there is a relative dearth of deep learning approaches for anomaly detection. Those approaches which do exist involve networks trained to perform a task other than anomaly detection, namely generative models or compression, which are in turn adapted for use in anomaly detection; they are not trained on an anomaly detection based objec-tive. In this paper we introduce a new anomaly detection method\u2014Deep Support Vector Data Description\u2014, which is trained on an anomaly detection based objective. The adaptation to the deep regime necessitates that our neural network and training procedure satisfy certain properties, which we demonstrate theoretically. We show the effectiveness of our method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GT-SRB stop signs.",
            "referenceCount": 58,
            "citationCount": 1360,
            "influentialCitationCount": 297,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-07-03",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ruff2018DeepOC,\n author = {Lukas Ruff and Nico G\u00f6rnitz and Lucas Deecke and Shoaib Ahmed Siddiqui and Robert A. Vandermeulen and Alexander Binder and Emmanuel M\u00fcller and M. Kloft},\n booktitle = {International Conference on Machine Learning},\n pages = {4390-4399},\n title = {Deep One-Class Classification},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d8d89a0a1eca983512247af701a9e5596c903a16",
            "@type": "ScholarlyArticle",
            "paperId": "d8d89a0a1eca983512247af701a9e5596c903a16",
            "corpusId": 198897678,
            "url": "https://www.semanticscholar.org/paper/d8d89a0a1eca983512247af701a9e5596c903a16",
            "title": "Interpreting the Latent Space of GANs for Semantic Face Editing",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/cvpr/ShenGTZ20",
                "ArXiv": "1907.10786",
                "MAG": "2963577681",
                "DOI": "10.1109/CVPR42600.2020.00926",
                "CorpusId": 198897678
            },
            "abstract": "Despite the recent advance of Generative Adversarial Networks (GANs) in high-fidelity image synthesis, there lacks enough understanding of how GANs are able to map a latent code sampled from a random distribution to a photo-realistic image. Previous work assumes the latent space learned by GANs follows a distributed representation but observes the vector arithmetic phenomenon. In this work, we propose a novel framework, called InterFaceGAN, for semantic face editing by interpreting the latent semantics learned by GANs. In this framework, we conduct a detailed study on how different semantics are encoded in the latent space of GANs for face synthesis. We find that the latent code of well-trained generative models actually learns a disentangled representation after linear transformations. We explore the disentanglement between various semantics and manage to decouple some entangled semantics with subspace projection, leading to more precise control of facial attributes. Besides manipulating gender, age, expression, and the presence of eyeglasses, we can even vary the face pose as well as fix the artifacts accidentally generated by GAN models. The proposed method is further applied to achieve real image manipulation when combined with GAN inversion methods or some encoder-involved models. Extensive results suggest that learning to synthesize faces spontaneously brings a disentangled and controllable facial attribute representation.",
            "referenceCount": 47,
            "citationCount": 856,
            "influentialCitationCount": 146,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1907.10786",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-07-25",
            "journal": {
                "name": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shen2019InterpretingTL,\n author = {Yujun Shen and Jinjin Gu and Xiaoou Tang and Bolei Zhou},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {9240-9249},\n title = {Interpreting the Latent Space of GANs for Semantic Face Editing},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:231af7dc01a166cac3b5b01ca05778238f796e41",
            "@type": "ScholarlyArticle",
            "paperId": "231af7dc01a166cac3b5b01ca05778238f796e41",
            "corpusId": 326772,
            "url": "https://www.semanticscholar.org/paper/231af7dc01a166cac3b5b01ca05778238f796e41",
            "title": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963981733",
                "DBLP": "conf/nips/HeuselRUNH17",
                "CorpusId": 326772
            },
            "abstract": "Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation, we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the \"Frechet Inception Distance\" (FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments, TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN Bedrooms, and the One Billion Word Benchmark.",
            "referenceCount": 60,
            "citationCount": 8257,
            "influentialCitationCount": 2630,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-06-26",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Heusel2017GANsTB,\n author = {M. Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and S. Hochreiter},\n booktitle = {Neural Information Processing Systems},\n pages = {6626-6637},\n title = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:449310e3538b08b43227d660227dfd2875c3c3c1",
            "@type": "ScholarlyArticle",
            "paperId": "449310e3538b08b43227d660227dfd2875c3c3c1",
            "corpusId": 49310446,
            "url": "https://www.semanticscholar.org/paper/449310e3538b08b43227d660227dfd2875c3c3c1",
            "title": "Neural Ordinary Differential Equations",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1806-07366",
                "ArXiv": "1806.07366",
                "MAG": "2951396815",
                "CorpusId": 49310446
            },
            "abstract": "We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.",
            "referenceCount": 64,
            "citationCount": 3278,
            "influentialCitationCount": 844,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-06-19",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2018NeuralOD,\n author = {T. Chen and Yulia Rubanova and J. Bettencourt and D. Duvenaud},\n booktitle = {Neural Information Processing Systems},\n pages = {6572-6583},\n title = {Neural Ordinary Differential Equations},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:22aab110058ebbd198edb1f1e7b4f69fb13c0613",
            "@type": "ScholarlyArticle",
            "paperId": "22aab110058ebbd198edb1f1e7b4f69fb13c0613",
            "corpusId": 52889459,
            "url": "https://www.semanticscholar.org/paper/22aab110058ebbd198edb1f1e7b4f69fb13c0613",
            "title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1809.11096",
                "DBLP": "journals/corr/abs-1809-11096",
                "MAG": "2893749619",
                "CorpusId": 52889459
            },
            "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previous best IS of 52.52 and FID of 18.6.",
            "referenceCount": 59,
            "citationCount": 4192,
            "influentialCitationCount": 630,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1809.11096"
            },
            "citationStyles": {
                "bibtex": "@Article{Brock2018LargeSG,\n author = {Andrew Brock and Jeff Donahue and K. Simonyan},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Large Scale GAN Training for High Fidelity Natural Image Synthesis},\n volume = {abs/1809.11096},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4574d77fff19e093782178595a8988a7f3aa1969",
            "@type": "ScholarlyArticle",
            "paperId": "4574d77fff19e093782178595a8988a7f3aa1969",
            "corpusId": 3177797,
            "url": "https://www.semanticscholar.org/paper/4574d77fff19e093782178595a8988a7f3aa1969",
            "title": "Latent Dirichlet Allocation",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "CorpusId": 3177797
            },
            "abstract": "Latent Dirichlet allocation(LDA) is a generative topic model to find latent topics in a text corpus. It can be trained via collapsed Gibbs sampling. In this project, we train LDA models on two datasets, Classic400 and BBCSport dataset. We discuss possible ways to evaluate goodness-of-fit and to detect overfitting problem of LDA model, and we use these criteria to choose proper hyperparameters, observe convergence, and evaluate the models, the criteria we use include perplexity, VI-distance, visualization of clustering results, and highest-probability words.",
            "referenceCount": 6,
            "citationCount": 34934,
            "influentialCitationCount": 6854,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Blei2009LatentDA,\n author = {D. Blei and A. Ng and Michael I. Jordan},\n title = {Latent Dirichlet Allocation},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6b73775f40467aed52784ff355b9bb7168e9078c",
            "@type": "ScholarlyArticle",
            "paperId": "6b73775f40467aed52784ff355b9bb7168e9078c",
            "corpusId": 44220142,
            "url": "https://www.semanticscholar.org/paper/6b73775f40467aed52784ff355b9bb7168e9078c",
            "title": "Mutual Information Neural Estimation",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2803832867",
                "DBLP": "conf/icml/BelghaziBROBHC18",
                "ArXiv": "1801.04062",
                "CorpusId": 44220142
            },
            "abstract": "We argue that the estimation of mutual information between high dimensional continuous random variables can be achieved by gradient descent over neural networks. We present a Mutual Information Neural Estimator (MINE) that is linearly scalable in dimensionality as well as in sample size, trainable through back-prop, and strongly consistent. We present a handful of applications on which MINE can be used to minimize or maximize mutual information. We apply MINE to improve adversarially trained generative models. We also use MINE to implement Information Bottleneck, applying it to supervised classification; our results demonstrate substantial improvement in flexibility and performance in these settings.",
            "referenceCount": 61,
            "citationCount": 913,
            "influentialCitationCount": 187,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-01-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Belghazi2018MutualIN,\n author = {Mohamed Ishmael Belghazi and A. Baratin and Sai Rajeswar and Sherjil Ozair and Yoshua Bengio and R. Devon Hjelm and Aaron C. Courville},\n booktitle = {International Conference on Machine Learning},\n pages = {530-539},\n title = {Mutual Information Neural Estimation},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6436dce0e39f15a1ca9269e6ca813dfebb0af3a2",
            "@type": "ScholarlyArticle",
            "paperId": "6436dce0e39f15a1ca9269e6ca813dfebb0af3a2",
            "corpusId": 1997763,
            "url": "https://www.semanticscholar.org/paper/6436dce0e39f15a1ca9269e6ca813dfebb0af3a2",
            "title": "The Author-Topic Model for Authors and Documents",
            "venue": "Conference on Uncertainty in Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:f9af8000-42f8-410d-a622-e8811e41660a",
                "name": "Conference on Uncertainty in Artificial Intelligence",
                "alternate_names": [
                    "Uncertainty in Artificial Intelligence",
                    "UAI",
                    "Conf Uncertain Artif Intell",
                    "Uncertain Artif Intell"
                ],
                "issn": null,
                "url": "http://www.auai.org/"
            },
            "year": 2004,
            "externalIds": {
                "DBLP": "journals/corr/abs-1207-4169",
                "ArXiv": "1207.4169",
                "MAG": "2140124448",
                "CorpusId": 1997763
            },
            "abstract": "We introduce the author-topic model, a generative model for documents that extends Latent Dirichlet Allocation (LDA; Blei, Ng, & Jordan, 2003) to include authorship information. Each author is associated with a multinomial distribution over topics and each topic is associated with a multinomial distribution over words. A document with multiple authors is modeled as a distribution over topics that is a mixture of the distributions associated with the authors. We apply the model to a collection of 1,700 NIPS conference papers and 160,000 CiteSeer abstracts. Exact inference is intractable for these datasets and we use Gibbs sampling to estimate the topic and author distributions. We compare the performance with two other generative models for documents, which are special cases of the author-topic model: LDA (a topic model) and a simple author model in which each author is associated with a distribution over words rather than a distribution over topics. We show topics recovered by the author-topic model, and demonstrate applications to computing similarity between authors and entropy of author output.",
            "referenceCount": 7,
            "citationCount": 1664,
            "influentialCitationCount": 158,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2004-07-07",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1207.4169"
            },
            "citationStyles": {
                "bibtex": "@Article{Rosen-Zvi2004TheAM,\n author = {M. Rosen-Zvi and T. Griffiths and M. Steyvers and Padhraic Smyth},\n booktitle = {Conference on Uncertainty in Artificial Intelligence},\n journal = {ArXiv},\n title = {The Author-Topic Model for Authors and Documents},\n volume = {abs/1207.4169},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ad67ccee45b801b0138016e2f44a566344e77320",
            "@type": "ScholarlyArticle",
            "paperId": "ad67ccee45b801b0138016e2f44a566344e77320",
            "corpusId": 7890982,
            "url": "https://www.semanticscholar.org/paper/ad67ccee45b801b0138016e2f44a566344e77320",
            "title": "Semi-supervised Learning by Entropy Minimization",
            "venue": "Conf\u00e9rence francophone sur l'apprentissage automatique",
            "publicationVenue": {
                "id": "urn:research:dd98d0be-11eb-4b8b-a414-ec098f8ac534",
                "name": "Conf\u00e9rence francophone sur l'apprentissage automatique",
                "alternate_names": [
                    "CAP",
                    "Conf\u00e9rence francoph sur l'apprentissage autom"
                ],
                "issn": null,
                "url": null
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2293363371",
                "DBLP": "conf/nips/GrandvaletB04",
                "CorpusId": 7890982
            },
            "abstract": "We consider the semi-supervised learning problem, where a decision rule is to be learned from labeled and unlabeled data. In this framework, we motivate minimum entropy regularization, which enables to incorporate unlabeled data in the standard supervised learning. Our approach includes other approaches to the semi-supervised problem as particular or limiting cases. A series of experiments illustrates that the proposed solution benefits from unlabeled data. The method challenges mixture models when the data are sampled from the distribution class spanned by the generative model. The performances are definitely in favor of minimum entropy regularization when generative models are misspecified, and the weighting of unlabeled data provides robustness to the violation of the \"cluster assumption\". Finally, we also illustrate that the method can also be far superior to manifold learning in high dimension spaces.",
            "referenceCount": 24,
            "citationCount": 1833,
            "influentialCitationCount": 148,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2004-12-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Grandvalet2004SemisupervisedLB,\n author = {Yves Grandvalet and Yoshua Bengio},\n booktitle = {Conf\u00e9rence francophone sur l'apprentissage automatique},\n pages = {529-536},\n title = {Semi-supervised Learning by Entropy Minimization},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1db6e3078597386ac4222ba6c3f4f61b61f53539",
            "@type": "ScholarlyArticle",
            "paperId": "1db6e3078597386ac4222ba6c3f4f61b61f53539",
            "corpusId": 84591,
            "url": "https://www.semanticscholar.org/paper/1db6e3078597386ac4222ba6c3f4f61b61f53539",
            "title": "Adversarial Feature Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2963265008",
                "ArXiv": "1605.09782",
                "DBLP": "journals/corr/DonahueKD16",
                "CorpusId": 84591
            },
            "abstract": "The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing that the latent space of such generators captures semantic variation in the data distribution. Intuitively, models trained to predict these semantic latent representations given data may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping -- projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.",
            "referenceCount": 36,
            "citationCount": 1661,
            "influentialCitationCount": 225,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-05-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1605.09782"
            },
            "citationStyles": {
                "bibtex": "@Article{Donahue2016AdversarialFL,\n author = {Jeff Donahue and Philipp Kr\u00e4henb\u00fchl and Trevor Darrell},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Adversarial Feature Learning},\n volume = {abs/1605.09782},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a2785f66c20fbdf30ec26c0931584c6d6a0f4fca",
            "@type": "ScholarlyArticle",
            "paperId": "a2785f66c20fbdf30ec26c0931584c6d6a0f4fca",
            "corpusId": 1930231,
            "url": "https://www.semanticscholar.org/paper/a2785f66c20fbdf30ec26c0931584c6d6a0f4fca",
            "title": "DRAW: A Recurrent Neural Network For Image Generation",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1850742715",
                "DBLP": "journals/corr/GregorDGW15",
                "ArXiv": "1502.04623",
                "CorpusId": 1930231
            },
            "abstract": "This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye.",
            "referenceCount": 36,
            "citationCount": 1856,
            "influentialCitationCount": 142,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-02-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1502.04623"
            },
            "citationStyles": {
                "bibtex": "@Article{Gregor2015DRAWAR,\n author = {Karol Gregor and Ivo Danihelka and Alex Graves and Danilo Jimenez Rezende and Daan Wierstra},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {DRAW: A Recurrent Neural Network For Image Generation},\n volume = {abs/1502.04623},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:897249c93f55ef1c0d2aa1e799eb67b414c6d4a6",
            "@type": "ScholarlyArticle",
            "paperId": "897249c93f55ef1c0d2aa1e799eb67b414c6d4a6",
            "corpusId": 13936575,
            "url": "https://www.semanticscholar.org/paper/897249c93f55ef1c0d2aa1e799eb67b414c6d4a6",
            "title": "Shallow Parsing with Conditional Random Fields",
            "venue": "North American Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:01103732-3808-4930-b8e4-7e9e68d5c68d",
                "name": "North American Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "North Am Chapter Assoc Comput Linguistics",
                    "NAACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/naacl"
            },
            "year": 2003,
            "externalIds": {
                "ACL": "N03-1028",
                "DBLP": "conf/naacl/ShaP03",
                "MAG": "2156515921",
                "DOI": "10.3115/1073445.1073473",
                "CorpusId": 13936575
            },
            "abstract": "Conditional random fields for sequence labeling offer advantages over both generative models like HMMs and classifiers applied at each sequence position. Among sequence labeling tasks in language processing, shallow parsing has received much attention, with the development of standard evaluation datasets and extensive comparison among methods. We show here how to train a conditional random field to achieve performance as good as any reported base noun-phrase chunking method on the CoNLL task, and better than any reported single model. Improved training methods based on modern optimization algorithms were critical in achieving these results. We present extensive comparisons between models and training methods that confirm and strengthen previous results on shallow parsing and training methods for maximum-entropy models.",
            "referenceCount": 33,
            "citationCount": 1572,
            "influentialCitationCount": 118,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=1073473&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2003-05-27",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Sha2003ShallowPW,\n author = {Fei Sha and Fernando C Pereira},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {134-141},\n title = {Shallow Parsing with Conditional Random Fields},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dc8301b67f98accbb331190dd7bd987952a692af",
            "@type": "ScholarlyArticle",
            "paperId": "dc8301b67f98accbb331190dd7bd987952a692af",
            "corpusId": 13995862,
            "url": "https://www.semanticscholar.org/paper/dc8301b67f98accbb331190dd7bd987952a692af",
            "title": "NICE: Non-linear Independent Components Estimation",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2964020555",
                "DBLP": "journals/corr/DinhKB14",
                "ArXiv": "1410.8516",
                "CorpusId": 13995862
            },
            "abstract": "We propose a deep learning framework for modeling complex high-dimensional densities called Non-linear Independent Component Estimation (NICE). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model. For this purpose, a non-linear deterministic transformation of the data is learned that maps it to a latent space so as to make the transformed data conform to a factorized distribution, i.e., resulting in independent latent variables. We parametrize this transformation so that computing the Jacobian determinant and inverse transform is trivial, yet we maintain the ability to learn complex non-linear transformations, via a composition of simple building blocks, each based on a deep neural network. The training criterion is simply the exact log-likelihood, which is tractable. Unbiased ancestral sampling is also easy. We show that this approach yields good generative models on four image datasets and can be used for inpainting.",
            "referenceCount": 35,
            "citationCount": 1779,
            "influentialCitationCount": 268,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-10-30",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1410.8516"
            },
            "citationStyles": {
                "bibtex": "@Article{Dinh2014NICENI,\n author = {Laurent Dinh and David Krueger and Yoshua Bengio},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {NICE: Non-linear Independent Components Estimation},\n volume = {abs/1410.8516},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3d2c6941a9b4608ba52b328369a3352db2092ae0",
            "@type": "ScholarlyArticle",
            "paperId": "3d2c6941a9b4608ba52b328369a3352db2092ae0",
            "corpusId": 151231,
            "url": "https://www.semanticscholar.org/paper/3d2c6941a9b4608ba52b328369a3352db2092ae0",
            "title": "Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2284050935",
                "DBLP": "conf/nips/SalimansK16",
                "ArXiv": "1602.07868",
                "CorpusId": 151231
            },
            "abstract": "We present weight normalization: a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction. By reparameterizing the weights in this way we improve the conditioning of the optimization problem and we speed up convergence of stochastic gradient descent. Our reparameterization is inspired by batch normalization but does not introduce any dependencies between the examples in a minibatch. This means that our method can also be applied successfully to recurrent models such as LSTMs and to noise-sensitive applications such as deep reinforcement learning or generative models, for which batch normalization is less well suited. Although our method is much simpler, it still provides much of the speed-up of full batch normalization. In addition, the computational overhead of our method is lower, permitting more optimization steps to be taken in the same amount of time. We demonstrate the usefulness of our method on applications in supervised image recognition, generative modelling, and deep reinforcement learning.",
            "referenceCount": 34,
            "citationCount": 1640,
            "influentialCitationCount": 120,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-02-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1602.07868"
            },
            "citationStyles": {
                "bibtex": "@Article{Salimans2016WeightNA,\n author = {Tim Salimans and Diederik P. Kingma},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks},\n volume = {abs/1602.07868},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:630bab4b708bc6621f97789b14f790153f115d15",
            "@type": "ScholarlyArticle",
            "paperId": "630bab4b708bc6621f97789b14f790153f115d15",
            "corpusId": 2703716,
            "url": "https://www.semanticscholar.org/paper/630bab4b708bc6621f97789b14f790153f115d15",
            "title": "Infinite latent feature models and the Indian buffet process",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "conf/nips/GriffithsG05",
                "MAG": "2128002512",
                "CorpusId": 2703716
            },
            "abstract": "We define a probability distribution over equivalence classes of binary matrices with a finite number of rows and an unbounded number of columns. This distribution is suitable for use as a prior in probabilistic models that represent objects using a potentially infinite array of features. We identify a simple generative process that results in the same distribution over equivalence classes, which we call the Indian buffet process. We illustrate the use of this distribution as a prior in an infinite latent feature model, deriving a Markov chain Monte Carlo algorithm for inference in this model and applying the algorithm to an image dataset.",
            "referenceCount": 33,
            "citationCount": 833,
            "influentialCitationCount": 156,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2005-12-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Griffiths2005InfiniteLF,\n author = {T. Griffiths and Zoubin Ghahramani},\n booktitle = {Neural Information Processing Systems},\n pages = {475-482},\n title = {Infinite latent feature models and the Indian buffet process},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc",
            "@type": "ScholarlyArticle",
            "paperId": "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc",
            "corpusId": 58981712,
            "url": "https://www.semanticscholar.org/paper/ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc",
            "title": "Cross-lingual Language Model Pretraining",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1901-07291",
                "ArXiv": "1901.07291",
                "MAG": "2970049541",
                "CorpusId": 58981712
            },
            "abstract": "Recent studies have demonstrated the efficiency of generative pretraining for English natural language understanding. In this work, we extend this approach to multiple languages and show the effectiveness of cross-lingual pretraining. We propose two methods to learn cross-lingual language models (XLMs): one unsupervised that only relies on monolingual data, and one supervised that leverages parallel data with a new cross-lingual language model objective. We obtain state-of-the-art results on cross-lingual classification, unsupervised and supervised machine translation. On XNLI, our approach pushes the state of the art by an absolute gain of 4.9% accuracy. On unsupervised machine translation, we obtain 34.3 BLEU on WMT\u201916 German-English, improving the previous state of the art by more than 9 BLEU. On supervised machine translation, we obtain a new state of the art of 38.5 BLEU on WMT\u201916 Romanian-English, outperforming the previous best approach by more than 4 BLEU. Our code and pretrained models will be made publicly available.",
            "referenceCount": 52,
            "citationCount": 2230,
            "influentialCitationCount": 522,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-01-22",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1901.07291"
            },
            "citationStyles": {
                "bibtex": "@Article{Lample2019CrosslingualLM,\n author = {Guillaume Lample and Alexis Conneau},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Cross-lingual Language Model Pretraining},\n volume = {abs/1901.07291},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ad1b3e5819d7a2234fa2f116cf32665d37ec2dbe",
            "@type": "ScholarlyArticle",
            "paperId": "ad1b3e5819d7a2234fa2f116cf32665d37ec2dbe",
            "corpusId": 1305310,
            "url": "https://www.semanticscholar.org/paper/ad1b3e5819d7a2234fa2f116cf32665d37ec2dbe",
            "title": "Generative Embedding for Model-Based Classification of fMRI Data",
            "venue": "PLoS Comput. Biol.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "MAG": "1967541074",
                "DBLP": "journals/ploscb/BrodersenSLOLBS11",
                "PubMedCentral": "3121683",
                "DOI": "10.1371/journal.pcbi.1002079",
                "CorpusId": 1305310,
                "PubMed": "21731479"
            },
            "abstract": "Decoding models, such as those underlying multivariate classification algorithms, have been increasingly used to infer cognitive or clinical brain states from measures of brain activity obtained by functional magnetic resonance imaging (fMRI). The practicality of current classifiers, however, is restricted by two major challenges. First, due to the high data dimensionality and low sample size, algorithms struggle to separate informative from uninformative features, resulting in poor generalization performance. Second, popular discriminative methods such as support vector machines (SVMs) rarely afford mechanistic interpretability. In this paper, we address these issues by proposing a novel generative-embedding approach that incorporates neurobiologically interpretable generative models into discriminative classifiers. Our approach extends previous work on trial-by-trial classification for electrophysiological recordings to subject-by-subject classification for fMRI and offers two key advantages over conventional methods: it may provide more accurate predictions by exploiting discriminative information encoded in \u2018hidden\u2019 physiological quantities such as synaptic connection strengths; and it affords mechanistic interpretability of clinical classifications. Here, we introduce generative embedding for fMRI using a combination of dynamic causal models (DCMs) and SVMs. We propose a general procedure of DCM-based generative embedding for subject-wise classification, provide a concrete implementation, and suggest good-practice guidelines for unbiased application of generative embedding in the context of fMRI. We illustrate the utility of our approach by a clinical example in which we classify moderately aphasic patients and healthy controls using a DCM of thalamo-temporal regions during speech processing. Generative embedding achieves a near-perfect balanced classification accuracy of 98% and significantly outperforms conventional activation-based and correlation-based methods. This example demonstrates how disease states can be detected with very high accuracy and, at the same time, be interpreted mechanistically in terms of abnormalities in connectivity. We envisage that future applications of generative embedding may provide crucial advances in dissecting spectrum disorders into physiologically more well-defined subgroups.",
            "referenceCount": 115,
            "citationCount": 166,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1002079&type=printable",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2011-06-01",
            "journal": {
                "name": "PLoS Computational Biology",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Brodersen2011GenerativeEF,\n author = {K. Brodersen and T. Schofield and A. Leff and Cheng Soon Ong and Ekaterina I. Lomakina and J. Buhmann and K. Stephan},\n booktitle = {PLoS Comput. Biol.},\n journal = {PLoS Computational Biology},\n title = {Generative Embedding for Model-Based Classification of fMRI Data},\n volume = {7},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f48ae425e2567be2d993efcaaf74c2274fc9d7c5",
            "@type": "ScholarlyArticle",
            "paperId": "f48ae425e2567be2d993efcaaf74c2274fc9d7c5",
            "corpusId": 189762527,
            "url": "https://www.semanticscholar.org/paper/f48ae425e2567be2d993efcaaf74c2274fc9d7c5",
            "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1906.05317",
                "ACL": "P19-1470",
                "MAG": "2950339735",
                "DBLP": "journals/corr/abs-1906-05317",
                "DOI": "10.18653/v1/P19-1470",
                "CorpusId": 189762527
            },
            "abstract": "We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.",
            "referenceCount": 38,
            "citationCount": 679,
            "influentialCitationCount": 129,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/P19-1470.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-06-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bosselut2019COMETCT,\n author = {Antoine Bosselut and Hannah Rashkin and Maarten Sap and Chaitanya Malaviya and Asli Celikyilmaz and Yejin Choi},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {4762-4779},\n title = {COMET: Commonsense Transformers for Automatic Knowledge Graph Construction},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7cf1969d90062090953b8c7a85070328e968ece4",
            "@type": "ScholarlyArticle",
            "paperId": "7cf1969d90062090953b8c7a85070328e968ece4",
            "corpusId": 52186339,
            "url": "https://www.semanticscholar.org/paper/7cf1969d90062090953b8c7a85070328e968ece4",
            "title": "Joint Autoregressive and Hierarchical Priors for Learned Image Compression",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2949361041",
                "DBLP": "journals/corr/abs-1809-02736",
                "ArXiv": "1809.02736",
                "CorpusId": 52186339
            },
            "abstract": "Recent models for learned image compression are based on autoencoders that learn approximately invertible mappings from pixels to a quantized latent representation. The transforms are combined with an entropy model, which is a prior on the latent representation that can be used with standard arithmetic coding algorithms to generate a compressed bitstream. Recently, hierarchical entropy models were introduced as a way to exploit more structure in the latents than previous fully factorized priors, improving compression performance while maintaining end-to-end optimization. Inspired by the success of autoregressive priors in probabilistic generative models, we examine autoregressive, hierarchical, and combined priors as alternatives, weighing their costs and benefits in the context of image compression. While it is well known that autoregressive models can incur a significant computational penalty, we find that in terms of compression performance, autoregressive and hierarchical priors are complementary and can be combined to exploit the probabilistic structure in the latents better than all previous learned models. The combined model yields state-of-the-art rate\u2013distortion performance and generates smaller files than existing methods: 15.8% rate reductions over the baseline hierarchical model and 59.8%, 35%, and 8.4% savings over JPEG, JPEG2000, and BPG, respectively. To the best of our knowledge, our model is the first learning-based method to outperform the top standard image codec (BPG) on both the PSNR and MS-SSIM distortion metrics.",
            "referenceCount": 44,
            "citationCount": 812,
            "influentialCitationCount": 207,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Minnen2018JointAA,\n author = {David C. Minnen and J. Ball\u00e9 and G. Toderici},\n booktitle = {Neural Information Processing Systems},\n pages = {10794-10803},\n title = {Joint Autoregressive and Hierarchical Priors for Learned Image Compression},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:71b0e39e6b59f3d1914c294e1d37cf75e6b73718",
            "@type": "ScholarlyArticle",
            "paperId": "71b0e39e6b59f3d1914c294e1d37cf75e6b73718",
            "corpusId": 8581960,
            "url": "https://www.semanticscholar.org/paper/71b0e39e6b59f3d1914c294e1d37cf75e6b73718",
            "title": "Analysis of i-vector Length Normalization in Speaker Recognition Systems",
            "venue": "Interspeech",
            "publicationVenue": {
                "id": "urn:research:af90489e-312f-4514-bea2-bcb399cb8ece",
                "name": "Interspeech",
                "alternate_names": [
                    "Conf Int Speech Commun Assoc",
                    "INTERSPEECH",
                    "Conference of the International Speech Communication Association"
                ],
                "issn": "2308-457X",
                "url": "https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2395750323",
                "DBLP": "conf/interspeech/Garcia-RomeroE11",
                "DOI": "10.21437/Interspeech.2011-53",
                "CorpusId": 8581960
            },
            "abstract": "We present a method to boost the performance of probabilistic generative models that work with i-vector representations. The proposed approach deals with the nonGaussian behavior of i-vectors by performing a simple length normalization. This non-linear transformation allows the use of probabilistic models with Gaussian assumptions that yield equivalent performance to that of more complicated systems based on Heavy-Tailed assumptions. Significant performance improvements are demonstrated on the telephone portion of NIST SRE 2010.",
            "referenceCount": 10,
            "citationCount": 1053,
            "influentialCitationCount": 82,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Garcia-Romero2011AnalysisOI,\n author = {D. Garcia-Romero and C. Espy-Wilson},\n booktitle = {Interspeech},\n pages = {249-252},\n title = {Analysis of i-vector Length Normalization in Speaker Recognition Systems},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1db9bd18681b96473f3c82b21edc9240b44dc329",
            "@type": "ScholarlyArticle",
            "paperId": "1db9bd18681b96473f3c82b21edc9240b44dc329",
            "corpusId": 3353110,
            "url": "https://www.semanticscholar.org/paper/1db9bd18681b96473f3c82b21edc9240b44dc329",
            "title": "Image Transformer",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1802.05751",
                "DBLP": "conf/icml/ParmarVUKSKT18",
                "MAG": "2950739196",
                "CorpusId": 3353110
            },
            "abstract": "Image generation has been successfully cast as an autoregressive sequence generation or transformation problem. Recent work has shown that self-attention is an effective way of modeling textual sequences. In this work, we generalize a recently proposed model architecture based on self-attention, the Transformer, to a sequence modeling formulation of image generation with a tractable likelihood. By restricting the self-attention mechanism to attend to local neighborhoods we significantly increase the size of images the model can process in practice, despite maintaining significantly larger receptive fields per layer than typical convolutional neural networks. We propose another extension of self-attention allowing it to efficiently take advantage of the two-dimensional nature of images. While conceptually simple, our generative models trained on two image data sets are competitive with or significantly outperform the current state of the art in autoregressive image generation on two different data sets, CIFAR-10 and ImageNet. We also present results on image super-resolution with a large magnification ratio, applying an encoder-decoder configuration of our architecture. In a human evaluation study, we show that our super-resolution models improve significantly over previously published autoregressive super-resolution models. Images they generate fool human observers three times more often than the previous state of the art.",
            "referenceCount": 27,
            "citationCount": 1224,
            "influentialCitationCount": 58,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Parmar2018ImageT,\n author = {Niki Parmar and Ashish Vaswani and Jakob Uszkoreit and Lukasz Kaiser and Noam M. Shazeer and Alexander Ku and Dustin Tran},\n booktitle = {International Conference on Machine Learning},\n pages = {4052-4061},\n title = {Image Transformer},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:843959ffdccf31c6694d135fad07425924f785b1",
            "@type": "ScholarlyArticle",
            "paperId": "843959ffdccf31c6694d135fad07425924f785b1",
            "corpusId": 207168299,
            "url": "https://www.semanticscholar.org/paper/843959ffdccf31c6694d135fad07425924f785b1",
            "title": "Extracting and composing robust features with denoising autoencoders",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2025768430",
                "DBLP": "conf/icml/VincentLBM08",
                "DOI": "10.1145/1390156.1390294",
                "CorpusId": 207168299
            },
            "abstract": "Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.",
            "referenceCount": 30,
            "citationCount": 6660,
            "influentialCitationCount": 520,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.iro.umontreal.ca/~vincentp/Publications/denoising_autoencoders_tr1316.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-07-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Vincent2008ExtractingAC,\n author = {Pascal Vincent and H. Larochelle and Yoshua Bengio and Pierre-Antoine Manzagol},\n booktitle = {International Conference on Machine Learning},\n pages = {1096-1103},\n title = {Extracting and composing robust features with denoising autoencoders},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5247a6e3a60ff0381355e66bfc313bf27512ae0c",
            "@type": "ScholarlyArticle",
            "paperId": "5247a6e3a60ff0381355e66bfc313bf27512ae0c",
            "corpusId": 94285,
            "url": "https://www.semanticscholar.org/paper/5247a6e3a60ff0381355e66bfc313bf27512ae0c",
            "title": "A Neural Network Approach to Context-Sensitive Generation of Conversational Responses",
            "venue": "North American Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:01103732-3808-4930-b8e4-7e9e68d5c68d",
                "name": "North American Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "North Am Chapter Assoc Comput Linguistics",
                    "NAACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/naacl"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/naacl/SordoniGABJMNGD15",
                "MAG": "2951580200",
                "ACL": "N15-1020",
                "ArXiv": "1506.06714",
                "DOI": "10.3115/v1/N15-1020",
                "CorpusId": 94285
            },
            "abstract": "We present a novel response generation system that can be trained end to end on large quantities of unstructured Twitter conversations. A neural network architecture is used to address sparsity issues that arise when integrating contextual information into classic statistical models, allowing the system to take into account previous dialog utterances. Our dynamic-context generative models show consistent gains over both context-sensitive and non-context-sensitive Machine Translation and Information Retrieval baselines.",
            "referenceCount": 31,
            "citationCount": 891,
            "influentialCitationCount": 78,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/N15-1020.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-06-22",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1506.06714"
            },
            "citationStyles": {
                "bibtex": "@Article{Sordoni2015ANN,\n author = {Alessandro Sordoni and Michel Galley and Michael Auli and Chris Brockett and Yangfeng Ji and Margaret Mitchell and Jian-Yun Nie and Jianfeng Gao and W. Dolan},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {A Neural Network Approach to Context-Sensitive Generation of Conversational Responses},\n volume = {abs/1506.06714},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cb596bffc5c5042c254058b62317a57fa156fea4",
            "@type": "ScholarlyArticle",
            "paperId": "cb596bffc5c5042c254058b62317a57fa156fea4",
            "corpusId": 231802355,
            "url": "https://www.semanticscholar.org/paper/cb596bffc5c5042c254058b62317a57fa156fea4",
            "title": "Unifying Vision-and-Language Tasks via Text Generation",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2102.02779",
                "DBLP": "journals/corr/abs-2102-02779",
                "CorpusId": 231802355
            },
            "abstract": "Existing methods for vision-and-language learning typically require designing task-specific architectures and objectives for each task. For example, a multi-label answer classifier for visual question answering, a region scorer for referring expression comprehension, and a language decoder for image captioning, etc. To alleviate these hassles, in this work, we propose a unified framework that learns different tasks in a single architecture with the same language modeling objective, i.e., multimodal conditional text generation, where our models learn to generate labels in text based on the visual and textual inputs. On 7 popular vision-and-language benchmarks, including visual question answering, referring expression comprehension, visual commonsense reasoning, most of which have been previously modeled as discriminative tasks, our generative approach (with a single unified architecture) reaches comparable performance to recent task-specific state-of-the-art vision-and-language models. Moreover, our generative approach shows better generalization ability on questions that have rare answers. Also, we show that our framework allows multi-task learning in a single architecture with a single set of parameters, achieving similar performance to separately optimized single-task models. Our code is publicly available at: https://github.com/j-min/VL-T5",
            "referenceCount": 84,
            "citationCount": 354,
            "influentialCitationCount": 64,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-02-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cho2021UnifyingVT,\n author = {Jaemin Cho and Jie Lei and Hao Tan and Mohit Bansal},\n booktitle = {International Conference on Machine Learning},\n pages = {1931-1942},\n title = {Unifying Vision-and-Language Tasks via Text Generation},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d2b62f77cb2864e465aa60bca6c26bb1d2f84963",
            "@type": "ScholarlyArticle",
            "paperId": "d2b62f77cb2864e465aa60bca6c26bb1d2f84963",
            "corpusId": 9530137,
            "url": "https://www.semanticscholar.org/paper/d2b62f77cb2864e465aa60bca6c26bb1d2f84963",
            "title": "Acoustic Modeling Using Deep Belief Networks",
            "venue": "IEEE Transactions on Audio, Speech, and Language Processing",
            "publicationVenue": {
                "id": "urn:research:96b92082-eb93-4682-be66-0a8fa5f2511c",
                "name": "IEEE Transactions on Audio, Speech, and Language Processing",
                "alternate_names": [
                    "IEEE Trans Audio Speech Lang Process"
                ],
                "issn": "1558-7916",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=10376"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "1993882792",
                "DBLP": "journals/taslp/MohamedDH12",
                "DOI": "10.1109/TASL.2011.2109382",
                "CorpusId": 9530137
            },
            "abstract": "Gaussian mixture models are currently the dominant technique for modeling the emission distribution of hidden Markov models for speech recognition. We show that better phone recognition on the TIMIT dataset can be achieved by replacing Gaussian mixture models by deep neural networks that contain many layers of features and a very large number of parameters. These networks are first pre-trained as a multi-layer generative model of a window of spectral feature vectors without making use of any discriminative information. Once the generative pre-training has designed the features, we perform discriminative fine-tuning using backpropagation to adjust the features slightly to make them better at predicting a probability distribution over the states of monophone hidden Markov models.",
            "referenceCount": 48,
            "citationCount": 1776,
            "influentialCitationCount": 124,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.338.2670&rep=rep1&type=pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Transactions on Audio, Speech, and Language Processing",
                "volume": "20"
            },
            "citationStyles": {
                "bibtex": "@Article{Mohamed2012AcousticMU,\n author = {Abdel-rahman Mohamed and George E. Dahl and Geoffrey E. Hinton},\n booktitle = {IEEE Transactions on Audio, Speech, and Language Processing},\n journal = {IEEE Transactions on Audio, Speech, and Language Processing},\n pages = {14-22},\n title = {Acoustic Modeling Using Deep Belief Networks},\n volume = {20},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c88e8d85fd5160b0793598bda037f977366acf7a",
            "@type": "ScholarlyArticle",
            "paperId": "c88e8d85fd5160b0793598bda037f977366acf7a",
            "corpusId": 4053393,
            "url": "https://www.semanticscholar.org/paper/c88e8d85fd5160b0793598bda037f977366acf7a",
            "title": "Are GANs Created Equal? A Large-Scale Study",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/nips/LucicKMGB18",
                "MAG": "2768599997",
                "ArXiv": "1711.10337",
                "CorpusId": 4053393
            },
            "abstract": "Generative adversarial networks (GAN) are a powerful subclass of generative models. Despite a very rich research activity leading to numerous interesting GAN algorithms, it is still very hard to assess which algorithm(s) perform better than others. We conduct a neutral, multi-faceted large-scale empirical study on state-of-the art models and evaluation measures. We find that most models can reach similar scores with enough hyperparameter optimization and random restarts. This suggests that improvements can arise from a higher computational budget and tuning more than fundamental algorithmic changes. To overcome some limitations of the current metrics, we also propose several data sets on which precision and recall can be computed. Our experimental results suggest that future GAN research should be based on more systematic and objective evaluation procedures. Finally, we did not find evidence that any of the tested algorithms consistently outperforms the non-saturating GAN introduced in \\cite{goodfellow2014generative}.",
            "referenceCount": 28,
            "citationCount": 897,
            "influentialCitationCount": 81,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-28",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lucic2017AreGC,\n author = {Mario Lucic and Karol Kurach and Marcin Michalski and S. Gelly and O. Bousquet},\n booktitle = {Neural Information Processing Systems},\n pages = {698-707},\n title = {Are GANs Created Equal? A Large-Scale Study},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a87cc499cf101b3697cacc65094b4b6590e0d061",
            "@type": "ScholarlyArticle",
            "paperId": "a87cc499cf101b3697cacc65094b4b6590e0d061",
            "corpusId": 14958161,
            "url": "https://www.semanticscholar.org/paper/a87cc499cf101b3697cacc65094b4b6590e0d061",
            "title": "ECO: Efficient Convolution Operators for Tracking",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2557641257",
                "ArXiv": "1611.09224",
                "DBLP": "conf/cvpr/DanelljanBKF17",
                "DOI": "10.1109/CVPR.2017.733",
                "CorpusId": 14958161
            },
            "abstract": "In recent years, Discriminative Correlation Filter (DCF) based methods have significantly advanced the state-of-the-art in tracking. However, in the pursuit of ever increasing tracking performance, their characteristic speed and real-time capability have gradually faded. Further, the increasingly complex models, with massive number of trainable parameters, have introduced the risk of severe over-fitting. In this work, we tackle the key causes behind the problems of computational complexity and over-fitting, with the aim of simultaneously improving both speed and performance. We revisit the core DCF formulation and introduce: (i) a factorized convolution operator, which drastically reduces the number of parameters in the model, (ii) a compact generative model of the training sample distribution, that significantly reduces memory and time complexity, while providing better diversity of samples, (iii) a conservative model update strategy with improved robustness and reduced complexity. We perform comprehensive experiments on four benchmarks: VOT2016, UAV123, OTB-2015, and TempleColor. When using expensive deep features, our tracker provides a 20-fold speedup and achieves a 13.0% relative gain in Expected Average Overlap compared to the top ranked method [12] in the VOT2016 challenge. Moreover, our fast variant, using hand-crafted features, operates at 60 Hz on a single CPU, while obtaining 65.0% AUC on OTB-2015.",
            "referenceCount": 41,
            "citationCount": 2015,
            "influentialCitationCount": 574,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1611.09224",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-11-28",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Danelljan2016ECOEC,\n author = {Martin Danelljan and Goutam Bhat and F. Khan and M. Felsberg},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {6931-6939},\n title = {ECO: Efficient Convolution Operators for Tracking},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7",
            "@type": "ScholarlyArticle",
            "paperId": "ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7",
            "corpusId": 1099052,
            "url": "https://www.semanticscholar.org/paper/ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7",
            "title": "Conditional Image Synthesis with Auxiliary Classifier GANs",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1610.09585",
                "MAG": "2548275288",
                "DBLP": "conf/icml/OdenaOS17",
                "CorpusId": 1099052
            },
            "abstract": "In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in 128 x 128 resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, 128 x 128 samples are more than twice as discriminable as artificially resized 32 x 32 samples. In addition, 84.7% of the classes have samples exhibiting diversity comparable to real ImageNet data.",
            "referenceCount": 44,
            "citationCount": 2779,
            "influentialCitationCount": 428,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-10-30",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Odena2016ConditionalIS,\n author = {Augustus Odena and C. Olah and Jonathon Shlens},\n booktitle = {International Conference on Machine Learning},\n pages = {2642-2651},\n title = {Conditional Image Synthesis with Auxiliary Classifier GANs},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:925182b91f51f8f2b747f7829e9d25ffc2729e5d",
            "@type": "ScholarlyArticle",
            "paperId": "925182b91f51f8f2b747f7829e9d25ffc2729e5d",
            "corpusId": 174801560,
            "url": "https://www.semanticscholar.org/paper/925182b91f51f8f2b747f7829e9d25ffc2729e5d",
            "title": "Likelihood Ratios for Out-of-Distribution Detection",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1906-02845",
                "MAG": "2970946347",
                "ArXiv": "1906.02845",
                "CorpusId": 174801560
            },
            "abstract": "Discriminative neural networks offer little or no performance guarantees when deployed on data not generated by the same process as the training distribution. On such out-of-distribution (OOD) inputs, the prediction may not only be erroneous, but confidently so, limiting the safe deployment of classifiers in real-world applications. One such challenging application is bacteria identification based on genomic sequences, which holds the promise of early detection of diseases, but requires a model that can output low confidence predictions on OOD genomic sequences from new bacteria that were not present in the training data. We introduce a genomics dataset for OOD detection that allows other researchers to benchmark progress on this important problem. We investigate deep generative model based approaches for OOD detection and observe that the likelihood score is heavily affected by population level background statistics. We propose a likelihood ratio method for deep generative models which effectively corrects for these confounding background statistics. We benchmark the OOD detection performance of the proposed method against existing approaches on the genomics dataset and show that our method achieves state-of-the-art performance. We demonstrate the generality of the proposed method by showing that it significantly improves OOD detection when applied to deep generative models of images.",
            "referenceCount": 64,
            "citationCount": 562,
            "influentialCitationCount": 67,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-07",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1906.02845"
            },
            "citationStyles": {
                "bibtex": "@Article{Ren2019LikelihoodRF,\n author = {Jie Jessie Ren and Peter J. Liu and Emily Fertig and Jasper Snoek and R. Poplin and M. DePristo and Joshua V. Dillon and Balaji Lakshminarayanan},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Likelihood Ratios for Out-of-Distribution Detection},\n volume = {abs/1906.02845},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:aac214fd3bef79f4f4bd50eaefe3f679097c5657",
            "@type": "ScholarlyArticle",
            "paperId": "aac214fd3bef79f4f4bd50eaefe3f679097c5657",
            "corpusId": 8861540,
            "url": "https://www.semanticscholar.org/paper/aac214fd3bef79f4f4bd50eaefe3f679097c5657",
            "title": "Statistical topic models for multi-label document classification",
            "venue": "Machine-mediated learning",
            "publicationVenue": {
                "id": "urn:research:22c9862f-a25e-40cd-9d31-d09e68a293e6",
                "name": "Machine-mediated learning",
                "alternate_names": [
                    "Mach learn",
                    "Machine Learning",
                    "Mach Learn"
                ],
                "issn": "0732-6718",
                "url": "http://www.springer.com/computer/artificial/journal/10994"
            },
            "year": 2011,
            "externalIds": {
                "ArXiv": "1107.2462",
                "DBLP": "journals/ml/RubinCSS12",
                "MAG": "2074909580",
                "DOI": "10.1007/s10994-011-5272-5",
                "CorpusId": 8861540
            },
            "abstract": null,
            "referenceCount": 63,
            "citationCount": 316,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s10994-011-5272-5.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2011-07-13",
            "journal": {
                "name": "Machine Learning",
                "volume": "88"
            },
            "citationStyles": {
                "bibtex": "@Article{Rubin2011StatisticalTM,\n author = {T. Rubin and America Chambers and Padhraic Smyth and M. Steyvers},\n booktitle = {Machine-mediated learning},\n journal = {Machine Learning},\n pages = {157-208},\n title = {Statistical topic models for multi-label document classification},\n volume = {88},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5726c7b40fcc454b77d989656c085520bf6c15fa",
            "@type": "ScholarlyArticle",
            "paperId": "5726c7b40fcc454b77d989656c085520bf6c15fa",
            "corpusId": 710430,
            "url": "https://www.semanticscholar.org/paper/5726c7b40fcc454b77d989656c085520bf6c15fa",
            "title": "Multimodal learning with deep Boltzmann machines",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2164587673",
                "DBLP": "conf/nips/SrivastavaS12",
                "DOI": "10.5555/2627435.2697059",
                "CorpusId": 710430
            },
            "abstract": "Data often consists of multiple diverse modalities. For example, images are tagged with textual information and videos are accompanied by audio. Each modality is characterized by having distinct statistical properties. We propose a Deep Boltzmann Machine for learning a generative model of such multimodal data. We show that the model can be used to create fused representations by combining features across modalities. These learned representations are useful for classification and information retrieval. By sampling from the conditional distributions over each data modality, it is possible to create these representations even when some data modalities are missing. We conduct experiments on bimodal image-text and audio-video data. The fused representation achieves good classification results on the MIR-Flickr data set matching or outperforming other deep models as well as SVM based models that use Multiple Kernel Learning. We further demonstrate that this multimodal model helps classification and retrieval even when only unimodal data is available at test time.",
            "referenceCount": 44,
            "citationCount": 1638,
            "influentialCitationCount": 119,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-12-03",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Srivastava2012MultimodalLW,\n author = {Nitish Srivastava and R. Salakhutdinov},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {2949-2980},\n title = {Multimodal learning with deep Boltzmann machines},\n volume = {15},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6be216d93421bf19c1659e7721241ae73d483baf",
            "@type": "ScholarlyArticle",
            "paperId": "6be216d93421bf19c1659e7721241ae73d483baf",
            "corpusId": 173990382,
            "url": "https://www.semanticscholar.org/paper/6be216d93421bf19c1659e7721241ae73d483baf",
            "title": "Generating Diverse High-Fidelity Images with VQ-VAE-2",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2947590261",
                "DBLP": "journals/corr/abs-1906-00446",
                "ArXiv": "1906.00446",
                "CorpusId": 173990382
            },
            "abstract": "We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE) models for large scale image generation. To this end, we scale and enhance the autoregressive priors used in VQ-VAE to generate synthetic samples of much higher coherence and fidelity than possible before. We use simple feed-forward encoder and decoder networks, making our model an attractive candidate for applications where the encoding and/or decoding speed is critical. Additionally, VQ-VAE requires sampling an autoregressive model only in the compressed latent space, which is an order of magnitude faster than sampling in the pixel space, especially for large images. We demonstrate that a multi-scale hierarchical organization of VQ-VAE, augmented with powerful priors over the latent codes, is able to generate samples with quality that rivals that of state of the art Generative Adversarial Networks on multifaceted datasets such as ImageNet, while not suffering from GAN's known shortcomings such as mode collapse and lack of diversity.",
            "referenceCount": 40,
            "citationCount": 1129,
            "influentialCitationCount": 136,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-02",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Razavi2019GeneratingDH,\n author = {Ali Razavi and A\u00e4ron van den Oord and Oriol Vinyals},\n booktitle = {Neural Information Processing Systems},\n pages = {14837-14847},\n title = {Generating Diverse High-Fidelity Images with VQ-VAE-2},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e7d6e2592b530b2f24d949ad9b9aed4a05565776",
            "@type": "ScholarlyArticle",
            "paperId": "e7d6e2592b530b2f24d949ad9b9aed4a05565776",
            "corpusId": 53285250,
            "url": "https://www.semanticscholar.org/paper/e7d6e2592b530b2f24d949ad9b9aed4a05565776",
            "title": "2019 Formatting Instructions for Authors Using LaTeX",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "CorpusId": 53285250
            },
            "abstract": "With recent breakthroughs in artificial neural networks, deep generative models have become one of the leading techniques for computational creativity. Despite very promising progress on image and short sequence generation, symbolic music generation remains a challenging problem since the structure of compositions are usually complicated. In this study, we attempt to solve the melody generation problem constrained by the given chord progression. This music meta-creation problem can also be incorporated into a plan recognition system with user inputs and predictive structural outputs. In particular, we explore the effect of explicit architectural encoding of musical structure via comparing two sequential generative models: LSTM (a type of RNN) and WaveNet (dilated temporal-CNN). As far as we know, this is the first study of applying WaveNet to symbolic music generation, as well as the first systematic comparison between temporal-CNN and RNN for music generation. We conduct a survey for evaluation in our generations and implemented Variable Markov Oracle in music pattern discovery. Experimental results show that to encode structure more explicitly using a stack of dilated convolution layers improved the performance significantly, and a global encoding of underlying chord progression into the generation procedure gains even more.",
            "referenceCount": 153,
            "citationCount": 647,
            "influentialCitationCount": 90,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Wang20182019FI,\n author = {Xiang Wang and Dingxian Wang and Canran Xu and Xiangnan He and Yixin Cao and Tat-Seng Chua},\n title = {2019 Formatting Instructions for Authors Using LaTeX},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8913c23081e46a41cc7ced3c2ff379d9cd7afcde",
            "@type": "ScholarlyArticle",
            "paperId": "8913c23081e46a41cc7ced3c2ff379d9cd7afcde",
            "corpusId": 3637466,
            "url": "https://www.semanticscholar.org/paper/8913c23081e46a41cc7ced3c2ff379d9cd7afcde",
            "title": "GraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders",
            "venue": "International Conference on Artificial Neural Networks",
            "publicationVenue": {
                "id": "urn:research:3e64b1c1-745f-4edf-bd92-b8ef122bb49c",
                "name": "International Conference on Artificial Neural Networks",
                "alternate_names": [
                    "Int Conf Artif Neural Netw",
                    "ICANN"
                ],
                "issn": null,
                "url": "http://www.e-nns.org/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/icann/SimonovskyK18",
                "MAG": "2949586000",
                "ArXiv": "1802.03480",
                "DOI": "10.1007/978-3-030-01418-6_41",
                "CorpusId": 3637466
            },
            "abstract": null,
            "referenceCount": 42,
            "citationCount": 649,
            "influentialCitationCount": 89,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1802.03480",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-02-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Simonovsky2018GraphVAETG,\n author = {M. Simonovsky and N. Komodakis},\n booktitle = {International Conference on Artificial Neural Networks},\n pages = {412-422},\n title = {GraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2e77b99e8bd10b9e4551a780c0bde9dd10fdbe9b",
            "@type": "ScholarlyArticle",
            "paperId": "2e77b99e8bd10b9e4551a780c0bde9dd10fdbe9b",
            "corpusId": 12663716,
            "url": "https://www.semanticscholar.org/paper/2e77b99e8bd10b9e4551a780c0bde9dd10fdbe9b",
            "title": "PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/iclr/SalimansK0K17",
                "MAG": "2951402704",
                "ArXiv": "1701.05517",
                "CorpusId": 12663716
            },
            "abstract": "PixelCNNs are a recently proposed class of powerful generative models with tractable likelihood. Here we discuss our implementation of PixelCNNs which we make available at this https URL Our implementation contains a number of modifications to the original model that both simplify its structure and improve its performance. 1) We use a discretized logistic mixture likelihood on the pixels, rather than a 256-way softmax, which we find to speed up training. 2) We condition on whole pixels, rather than R/G/B sub-pixels, simplifying the model structure. 3) We use downsampling to efficiently capture structure at multiple resolutions. 4) We introduce additional short-cut connections to further speed up optimization. 5) We regularize the model using dropout. Finally, we present state-of-the-art log likelihood results on CIFAR-10 to demonstrate the usefulness of these modifications.",
            "referenceCount": 22,
            "citationCount": 797,
            "influentialCitationCount": 102,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-01-19",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1701.05517"
            },
            "citationStyles": {
                "bibtex": "@Article{Salimans2017PixelCNNIT,\n author = {Tim Salimans and A. Karpathy and Xi Chen and Diederik P. Kingma},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications},\n volume = {abs/1701.05517},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:907a90967f68da4311802247408e0515e363f930",
            "@type": "ScholarlyArticle",
            "paperId": "907a90967f68da4311802247408e0515e363f930",
            "corpusId": 7646250,
            "url": "https://www.semanticscholar.org/paper/907a90967f68da4311802247408e0515e363f930",
            "title": "CyCADA: Cycle-Consistent Adversarial Domain Adaptation",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2962808524",
                "DBLP": "conf/icml/HoffmanTPZISED18",
                "ArXiv": "1711.03213",
                "CorpusId": 7646250
            },
            "abstract": "Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models applied in feature spaces discover domain invariant representations, but are difficult to visualize and sometimes fail to capture pixel-level and low-level domain shifts. Recent work has shown that generative adversarial networks combined with cycle-consistency constraints are surprisingly effective at mapping images between domains, even without the use of aligned image pairs. We propose a novel discriminatively-trained Cycle-Consistent Adversarial Domain Adaptation model. CyCADA adapts representations at both the pixel-level and feature-level, enforces cycle-consistency while leveraging a task loss, and does not require aligned pairs. Our model can be applied in a variety of visual recognition and prediction settings. We show new state-of-the-art results across multiple adaptation tasks, including digit classification and semantic segmentation of road scenes demonstrating transfer from synthetic to real world domains.",
            "referenceCount": 52,
            "citationCount": 2539,
            "influentialCitationCount": 271,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-11-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1711.03213"
            },
            "citationStyles": {
                "bibtex": "@Article{Hoffman2017CyCADACA,\n author = {Judy Hoffman and Eric Tzeng and Taesung Park and Jun-Yan Zhu and Phillip Isola and Kate Saenko and Alexei A. Efros and Trevor Darrell},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {CyCADA: Cycle-Consistent Adversarial Domain Adaptation},\n volume = {abs/1711.03213},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:be697c79df8e4b280fec71751cb2d44667429f36",
            "@type": "ScholarlyArticle",
            "paperId": "be697c79df8e4b280fec71751cb2d44667429f36",
            "corpusId": 236772156,
            "url": "https://www.semanticscholar.org/paper/be697c79df8e4b280fec71751cb2d44667429f36",
            "title": "StyleGAN-NADA",
            "venue": "ACM Transactions on Graphics",
            "publicationVenue": {
                "id": "urn:research:aab03e41-f80d-48b3-89bd-60eeeceafc7d",
                "name": "ACM Transactions on Graphics",
                "alternate_names": [
                    "ACM Trans Graph"
                ],
                "issn": "0730-0301",
                "url": "http://www.acm.org/tog/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/tog/GalPMBCC22",
                "ArXiv": "2108.00946",
                "DOI": "10.1145/3528223.3530164",
                "CorpusId": 236772156
            },
            "abstract": "Can a generative model be trained to produce images from a specific domain, guided only by a text prompt, without seeing any image? In other words: can an image generator be trained \"blindly\"? Leveraging the semantic power of large scale Contrastive-Language-Image-Pre-training (CLIP) models, we present a text-driven method that allows shifting a generative model to new domains, without having to collect even a single image. We show that through natural language prompts and a few minutes of training, our method can adapt a generator across a multitude of domains characterized by diverse styles and shapes. Notably, many of these modifications would be difficult or infeasible to reach with existing methods. We conduct an extensive set of experiments across a wide range of domains. These demonstrate the effectiveness of our approach, and show that our models preserve the latent-space structure that makes generative models appealing for downstream tasks. Code and videos available at: stylegan-nada.github.io/",
            "referenceCount": 77,
            "citationCount": 196,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-08-02",
            "journal": {
                "name": "ACM Transactions on Graphics (TOG)",
                "volume": "41"
            },
            "citationStyles": {
                "bibtex": "@Article{Gal2021StyleGANNADA,\n author = {Rinon Gal and Or Patashnik and Haggai Maron and Amit H. Bermano and Gal Chechik and D. Cohen-Or},\n booktitle = {ACM Transactions on Graphics},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 13},\n title = {StyleGAN-NADA},\n volume = {41},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:64d698ecd01eab99e81e586400e86d3d70b9cba7",
            "@type": "ScholarlyArticle",
            "paperId": "64d698ecd01eab99e81e586400e86d3d70b9cba7",
            "corpusId": 10447416,
            "url": "https://www.semanticscholar.org/paper/64d698ecd01eab99e81e586400e86d3d70b9cba7",
            "title": "Ladder Variational Autoencoders",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2963135265",
                "DBLP": "conf/nips/SonderbyRMSW16",
                "ArXiv": "1602.02282",
                "CorpusId": 10447416
            },
            "abstract": "Variational Autoencoders are powerful models for unsupervised learning. However deep models with several layers of dependent stochastic variables are difficult to train which limits the improvements obtained using these highly expressive models. We propose a new inference model, the Ladder Variational Autoencoder, that recursively corrects the generative distribution by a data dependent approximate likelihood in a process resembling the recently proposed Ladder Network. We show that this model provides state of the art predictive log-likelihood and tighter log-likelihood lower bound compared to the purely bottom-up inference in layered Variational Autoencoders and other generative models. We provide a detailed analysis of the learned hierarchical latent representation and show that our new inference model is qualitatively different and utilizes a deeper more distributed hierarchy of latent variables. Finally, we observe that batch normalization and deterministic warm-up (gradually turning on the KL-term) are crucial for training variational models with many stochastic layers.",
            "referenceCount": 26,
            "citationCount": 773,
            "influentialCitationCount": 113,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-02-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{S\u00f8nderby2016LadderVA,\n author = {C. S\u00f8nderby and T. Raiko and Lars Maal\u00f8e and S\u00f8ren Kaae S\u00f8nderby and O. Winther},\n booktitle = {Neural Information Processing Systems},\n pages = {3738-3746},\n title = {Ladder Variational Autoencoders},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:23f5854b38a15c2ae201e751311665f7995b5e10",
            "@type": "ScholarlyArticle",
            "paperId": "23f5854b38a15c2ae201e751311665f7995b5e10",
            "corpusId": 3361310,
            "url": "https://www.semanticscholar.org/paper/23f5854b38a15c2ae201e751311665f7995b5e10",
            "title": "Variational Autoencoders for Collaborative Filtering",
            "venue": "The Web Conference",
            "publicationVenue": {
                "id": "urn:research:e07422f9-c065-40c3-a37b-75e98dce79fe",
                "name": "The Web Conference",
                "alternate_names": [
                    "Web Conf",
                    "WWW"
                ],
                "issn": null,
                "url": "http://www.iw3c2.org/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1802-05814",
                "ArXiv": "1802.05814",
                "MAG": "2963085847",
                "DOI": "10.1145/3178876.3186150",
                "CorpusId": 3361310
            },
            "abstract": "We extend variational autoencoders (VAEs) to collaborative filtering for implicit feedback. This non-linear probabilistic model enables us to go beyond the limited modeling capacity of linear factor models which still largely dominate collaborative filtering research.We introduce a generative model with multinomial likelihood and use Bayesian inference for parameter estimation. Despite widespread use in language modeling and economics, the multinomial likelihood receives less attention in the recommender systems literature. We introduce a different regularization parameter for the learning objective, which proves to be crucial for achieving competitive performance. Remarkably, there is an efficient way to tune the parameter using annealing. The resulting model and learning algorithm has information-theoretic connections to maximum entropy discrimination and the information bottleneck principle. Empirically, we show that the proposed approach significantly outperforms several state-of-the-art baselines, including two recently-proposed neural network approaches, on several real-world datasets. We also provide extended experiments comparing the multinomial likelihood with other commonly used likelihood functions in the latent factor collaborative filtering literature and show favorable results. Finally, we identify the pros and cons of employing a principled Bayesian inference approach and characterize settings where it provides the most significant improvements.",
            "referenceCount": 54,
            "citationCount": 902,
            "influentialCitationCount": 221,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=3186150&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2018-02-16",
            "journal": {
                "name": "Proceedings of the 2018 World Wide Web Conference",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Liang2018VariationalAF,\n author = {Dawen Liang and R. G. Krishnan and M. Hoffman and T. Jebara},\n booktitle = {The Web Conference},\n journal = {Proceedings of the 2018 World Wide Web Conference},\n title = {Variational Autoencoders for Collaborative Filtering},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa",
            "@type": "ScholarlyArticle",
            "paperId": "1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa",
            "corpusId": 235212350,
            "url": "https://www.semanticscholar.org/paper/1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa",
            "title": "CogView: Mastering Text-to-Image Generation via Transformers",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/nips/DingYHZZYLZSYT21",
                "ArXiv": "2105.13290",
                "CorpusId": 235212350
            },
            "abstract": "Text-to-Image generation in the general domain has long been an open problem, which requires both a powerful generative model and cross-modal understanding. We propose CogView, a 4-billion-parameter Transformer with VQ-VAE tokenizer to advance this problem. We also demonstrate the finetuning strategies for various downstream tasks, e.g. style learning, super-resolution, text-image ranking and fashion design, and methods to stabilize pretraining, e.g. eliminating NaN losses. CogView achieves the state-of-the-art FID on the blurred MS COCO dataset, outperforming previous GAN-based models and a recent similar work DALL-E.",
            "referenceCount": 58,
            "citationCount": 411,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-05-26",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ding2021CogViewMT,\n author = {Ming Ding and Zhuoyi Yang and Wenyi Hong and Wendi Zheng and Chang Zhou and Da Yin and Junyang Lin and Xu Zou and Zhou Shao and Hongxia Yang and Jie Tang},\n booktitle = {Neural Information Processing Systems},\n pages = {19822-19835},\n title = {CogView: Mastering Text-to-Image Generation via Transformers},\n year = {2021}\n}\n"
            }
        }
    }
]