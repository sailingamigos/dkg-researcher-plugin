[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:42998f6a0ef243ffb5555ced81319ea5e8bba788",
            "@type": "ScholarlyArticle",
            "paperId": "42998f6a0ef243ffb5555ced81319ea5e8bba788",
            "corpusId": 13927130,
            "url": "https://www.semanticscholar.org/paper/42998f6a0ef243ffb5555ced81319ea5e8bba788",
            "title": "Active inference and agency: optimal control without cost functions",
            "venue": "Biological cybernetics",
            "publicationVenue": {
                "id": "urn:research:57cada26-a03e-494e-929e-a71ac35f2ad0",
                "name": "Biological cybernetics",
                "alternate_names": [
                    "Biological cybern",
                    "Biological Cybern",
                    "Biological Cybernetics"
                ],
                "issn": "0340-1200",
                "url": "http://link.springer.com/journal/422"
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "journals/bc/FristonSM12",
                "MAG": "2091405003",
                "DOI": "10.1007/s00422-012-0512-8",
                "CorpusId": 13927130,
                "PubMed": "22864468"
            },
            "abstract": null,
            "referenceCount": 82,
            "citationCount": 188,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s00422-012-0512-8.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-10-01",
            "journal": {
                "name": "Biological Cybernetics",
                "volume": "106"
            },
            "citationStyles": {
                "bibtex": "@Article{Friston2012ActiveIA,\n author = {Karl J. Friston and Spyridon Samothrakis and P. Montague},\n booktitle = {Biological cybernetics},\n journal = {Biological Cybernetics},\n pages = {523-541},\n title = {Active inference and agency: optimal control without cost functions},\n volume = {106},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5528ff561c97d863135ff39f1c0cad56a774b0a4",
            "@type": "ScholarlyArticle",
            "paperId": "5528ff561c97d863135ff39f1c0cad56a774b0a4",
            "corpusId": 14298859,
            "url": "https://www.semanticscholar.org/paper/5528ff561c97d863135ff39f1c0cad56a774b0a4",
            "title": "Clustering with Spectral Norm and the k-Means Algorithm",
            "venue": "IEEE Annual Symposium on Foundations of Computer Science",
            "publicationVenue": {
                "id": "urn:research:68cf0e99-5164-4480-8ed4-8b8416a091df",
                "name": "IEEE Annual Symposium on Foundations of Computer Science",
                "alternate_names": [
                    "FOCS",
                    "IEEE Annu Symp Found Comput Sci"
                ],
                "issn": null,
                "url": "http://ieee-focs.org/"
            },
            "year": 2010,
            "externalIds": {
                "ArXiv": "1004.1823",
                "DBLP": "conf/focs/KumarK10",
                "MAG": "2953266361",
                "DOI": "10.1109/FOCS.2010.35",
                "CorpusId": 14298859
            },
            "abstract": "There has been much progress on efficient algorithms for clustering data points generated by a mixture of k probability distributions under the assumption that the means of the distributions are well-separated, i.e., the distance between the means of any two distributions is at least Omega(k) standard deviations. These results generally make heavy use of the generative model and particular properties of the distributions. In this paper, we show that a simple clustering algorithm works without assuming any generative (probabilistic) model. Our only assumption is what we call a \"proximity condition'': the projection of any data point onto the line joining its cluster center to any other cluster center is Omega(k) standard deviations closer to its own center than the other center. Here the notion of standard deviations is based on the spectral norm of the matrix whose rows represent the difference between a point and the mean of the cluster to which it belongs. We show that in the generative models studied, our proximity condition is satisfied and so we are able to derive most known results for generative models as corollaries of our main result. We also prove some new results for generative models - e.g., we can cluster all but a small fraction of points only assuming a bound on the variance. Our algorithm relies on the well known k-means algorithm, and along the way, we prove a result of independent interest \u2013 that the k-means algorithm converges to the \"true centers'' even in the presence of spurious points provided the initial (estimated) centers are close enough to the corresponding actual centers and all but a small fraction of the points satisfy the proximity condition. Finally, we present a new technique for boosting the ratio of inter-center separation to standard deviation. This allows us to prove results for learning certain mixture of distributions under weaker separation conditions.",
            "referenceCount": 25,
            "citationCount": 189,
            "influentialCitationCount": 28,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1004.1823",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-04-11",
            "journal": {
                "name": "2010 IEEE 51st Annual Symposium on Foundations of Computer Science",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kumar2010ClusteringWS,\n author = {Amit Kumar and R. Kannan},\n booktitle = {IEEE Annual Symposium on Foundations of Computer Science},\n journal = {2010 IEEE 51st Annual Symposium on Foundations of Computer Science},\n pages = {299-308},\n title = {Clustering with Spectral Norm and the k-Means Algorithm},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:286d807ac75c6b5789bf86c2997d925bb85fd7b4",
            "@type": "ScholarlyArticle",
            "paperId": "286d807ac75c6b5789bf86c2997d925bb85fd7b4",
            "corpusId": 205086740,
            "url": "https://www.semanticscholar.org/paper/286d807ac75c6b5789bf86c2997d925bb85fd7b4",
            "title": "The Baltimore Experience Corps Trial: Enhancing Generativity via Intergenerational Activity Engagement in Later Life.",
            "venue": "The journals of gerontology. Series B, Psychological sciences and social sciences",
            "publicationVenue": {
                "id": "urn:research:ae36e72f-b788-43da-9c0a-c2a590d4866a",
                "name": "The journals of gerontology. Series B, Psychological sciences and social sciences",
                "alternate_names": [
                    "j gerontol Ser B Psychol sci soc sci",
                    "J Gerontol Ser B-psychological Sci Soc Sci",
                    "The Journals of Gerontology: Series B",
                    "Journals of Gerontology Series B-psychological Sciences and Social Sciences",
                    "J Gerontol Ser B"
                ],
                "issn": "1079-5014",
                "url": "http://psychsoc.gerontologyjournals.org/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2059016987",
                "DOI": "10.1093/geronb/gbv005",
                "CorpusId": 205086740,
                "PubMed": "25721053"
            },
            "abstract": "OBJECTIVES\nBeing and feeling generative, defined as exhibiting concern and behavior to benefit others, is an important developmental goal of midlife and beyond. Although a growing body of evidence suggests mental and physical health benefits of feeling generative in later life, little information exists as to the modifiability of generativity perceptions. The present study examines whether participation in the intergenerational civic engagement program, Experience Corps (EC), benefits older adults' self-perceptions of generativity.\n\n\nMETHOD\nLevels of generativity were compared in older adults randomized to serve as EC volunteers or controls (usual volunteer opportunities) in the Baltimore Experience Corps Trial at 4-, 12-, and 24-month evaluation points over the 2-year trial. Analyses utilized intention-to-treat and complier average causal effects (CACE) analyses which incorporate degree of intervention exposure in analytic models.\n\n\nRESULTS\nParticipants randomized to the EC group had significantly higher levels of generative desire and perceptions of generative achievement than controls at each follow-up point; CACE analyses indicate a dose-response effect with a greater magnitude of intervention effect with greater exposure to the EC program.\n\n\nDISCUSSION\nResults provide the first-ever, large-scale experimental demonstration that participation in an intergenerational civic engagement program can positively alter self-perceptions of generativity in older adulthood.",
            "referenceCount": 45,
            "citationCount": 82,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/psychsocgerontology/article-pdf/71/4/661/8080142/gbv005.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-07-01",
            "journal": {
                "name": "The journals of gerontology. Series B, Psychological sciences and social sciences",
                "volume": "71 4"
            },
            "citationStyles": {
                "bibtex": "@Article{Gruenewald2016TheBE,\n author = {T. Gruenewald and E. Tanner and L. Fried and M. Carlson and Q. Xue and Jeanine M. Parisi and G. Rebok and Lisa M. Yarnell and T. Seeman},\n booktitle = {The journals of gerontology. Series B, Psychological sciences and social sciences},\n journal = {The journals of gerontology. Series B, Psychological sciences and social sciences},\n pages = {\n          661-70\n        },\n title = {The Baltimore Experience Corps Trial: Enhancing Generativity via Intergenerational Activity Engagement in Later Life.},\n volume = {71 4},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:992c958fe0f4bd148b6f4304e1b5e458b8575cb1",
            "@type": "ScholarlyArticle",
            "paperId": "992c958fe0f4bd148b6f4304e1b5e458b8575cb1",
            "corpusId": 381243,
            "url": "https://www.semanticscholar.org/paper/992c958fe0f4bd148b6f4304e1b5e458b8575cb1",
            "title": "Modeling User Rating Profiles For Collaborative Filtering",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2003,
            "externalIds": {
                "DBLP": "conf/nips/Marlin03",
                "MAG": "2151052953",
                "CorpusId": 381243
            },
            "abstract": "In this paper we present a generative latent variable model for rating-based collaborative filtering called the User Rating Profile model (URP). The generative process which underlies URP is designed to produce complete user rating profiles, an assignment of one rating to each item for each user. Our model represents each user as a mixture of user attitudes, and the mixing proportions are distributed according to a Dirichlet random variable. The rating for each item is generated by selecting a user attitude for the item, and then selecting a rating according to the preference pattern associated with that attitude. URP is related to several models including a multinomial mixture model, the aspect model [7], and LDA [1], but has clear advantages over each.",
            "referenceCount": 7,
            "citationCount": 356,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2003-12-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Marlin2003ModelingUR,\n author = {Benjamin M Marlin},\n booktitle = {Neural Information Processing Systems},\n pages = {627-634},\n title = {Modeling User Rating Profiles For Collaborative Filtering},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:73a1f38418ae01768bcc74d4b7b6be3f037826aa",
            "@type": "ScholarlyArticle",
            "paperId": "73a1f38418ae01768bcc74d4b7b6be3f037826aa",
            "corpusId": 7732628,
            "url": "https://www.semanticscholar.org/paper/73a1f38418ae01768bcc74d4b7b6be3f037826aa",
            "title": "TCS:: a DSL for the specification of textual concrete syntaxes in model engineering",
            "venue": "International Conference on Generative Programming: Concepts and Experiences",
            "publicationVenue": {
                "id": "urn:research:42ba2c5a-a60c-4306-988d-ff0928f95afa",
                "name": "International Conference on Generative Programming: Concepts and Experiences",
                "alternate_names": [
                    "Generative Programming and Component Engineering",
                    "Gener Program Compon Eng",
                    "GPCE",
                    "Int Conf Gener Program Concept Exp"
                ],
                "issn": null,
                "url": "https://dl.acm.org/conference/gpce"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "conf/gpce/JouaultBK06",
                "MAG": "2049008406",
                "DOI": "10.1145/1173706.1173744",
                "CorpusId": 7732628
            },
            "abstract": "Domain modeling promotes the description of various facets of information systems by a coordinated set of domain-specific languages (DSL). Some of them have visual/graphical and other may have textual concrete syntaxes. Model Driven Engineering (MDE) helps defining the concepts and relations of the domain by the way of metamodel elements. For visual languages, it is necessary to establish links between these concepts and relations on one side and visual symbols on the other side. Similarly, with textual languages it is necessary to establish links between metamodel elements and syntactic structures of the textual DSL. To successfully apply MDE in a wide range of domains we need tools for fast implementation of the expected growing number of DSLs. Regarding the textual syntax of DSLs, we believe that most current proposals for bridging the world of models (MDE) and the world of grammars (Grammarware) are not completely adapted to this need. We propose a generative solution based on a DSL called TCS (Textual Concrete Syntax). Specifications expressed in TCS are used to automatically generate tools for model-to-text and text-to-model transformations. The proposed approach is illustrated by a case study in the definition of a telephony language.",
            "referenceCount": 25,
            "citationCount": 297,
            "influentialCitationCount": 33,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ris.utwente.nl/ws/files/5449493/p249-jouault.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-10-22",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Jouault2006TCSAD,\n author = {F. Jouault and J. B\u00e9zivin and I. Kurtev},\n booktitle = {International Conference on Generative Programming: Concepts and Experiences},\n pages = {249-254},\n title = {TCS:: a DSL for the specification of textual concrete syntaxes in model engineering},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c74e230a5a6fd5e2db6ace765ce38afe65f96214",
            "@type": "ScholarlyArticle",
            "paperId": "c74e230a5a6fd5e2db6ace765ce38afe65f96214",
            "corpusId": 2837110,
            "url": "https://www.semanticscholar.org/paper/c74e230a5a6fd5e2db6ace765ce38afe65f96214",
            "title": "Learning Multilevel Distributed Representations for High-Dimensional Sequences",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2007,
            "externalIds": {
                "DBLP": "journals/jmlr/SutskeverH07",
                "MAG": "2147010501",
                "CorpusId": 2837110
            },
            "abstract": "We describe a new family of non-linear sequence models that are substantially more powerful than hidden Markov models or linear dynamical systems. Our models have simple approximate inference and learning procedures that work well in practice. Multilevel representations of sequential data can be learned one hidden layer at a time, and adding extra hidden layers improves the resulting generative models. The models can be trained with very high-dimensional, very non-linear data such as raw pixel sequences. Their performance is demonstrated using synthetic video sequences of two balls bouncing in a box.",
            "referenceCount": 16,
            "citationCount": 246,
            "influentialCitationCount": 32,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2007-03-11",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sutskever2007LearningMD,\n author = {Ilya Sutskever and Geoffrey E. Hinton},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n pages = {548-555},\n title = {Learning Multilevel Distributed Representations for High-Dimensional Sequences},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3570ffceceed450e034f4c22ab2582bbf8fcbdc5",
            "@type": "ScholarlyArticle",
            "paperId": "3570ffceceed450e034f4c22ab2582bbf8fcbdc5",
            "corpusId": 37342046,
            "url": "https://www.semanticscholar.org/paper/3570ffceceed450e034f4c22ab2582bbf8fcbdc5",
            "title": "Sensory Cue Integration",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "MAG": "388780593",
                "DOI": "10.1093/ACPROF:OSO/9780195387247.001.0001",
                "CorpusId": 37342046
            },
            "abstract": "Preface I. Theory and Fundamentals 1. Ideal-Observer Models of Cue Integration Landy, Banks, & Knill 2. Causal Inference in Sensorimotor Learning and Control Wei & Kording 3. The Role of Generative Knowledge in Object Perception Battaglia, Kersten, & Schrater 4. Generative Probabilistic Modeling: Understanding Causal Sensorimotor Integration Vijayakumar, Hospedales, & Haith 5. Modeling Cue Integration in Clutter Sahani & Whiteley 6. Recruitment of New Visual Cues for Perceptual Appearance Backus 7. Combining image signals before 3D reconstruction: The Intrinsic Constraint Model of Cue Integration Domini & Caudek 8. Cue Combination: Beyond So-Called \"Optimality\" Rosas & Wichmann II. Behavioral Studies 9. Priors and Learning in Cue Integration Seydell, Knill, & Trommershauser 10. Combining Vision With Audition and Touch, In Adults and In Children Burr, Binda, & Gori 11. The Statistical Relationship",
            "referenceCount": 71,
            "citationCount": 195,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2011-09-14",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Trommersh\u00e4user2011SensoryCI,\n author = {Julia Trommersh\u00e4user and Konrad Paul Kording and M. Landy},\n pages = {225-250},\n title = {Sensory Cue Integration},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5028ad7b06aad811f7bf328d48365795117e7938",
            "@type": "ScholarlyArticle",
            "paperId": "5028ad7b06aad811f7bf328d48365795117e7938",
            "corpusId": 15146942,
            "url": "https://www.semanticscholar.org/paper/5028ad7b06aad811f7bf328d48365795117e7938",
            "title": "Deep Belief Networks Are Compact Universal Approximators",
            "venue": "Neural Computation",
            "publicationVenue": {
                "id": "urn:research:69b9bcdd-8229-4a00-a6e0-00f0e99a2bf3",
                "name": "Neural Computation",
                "alternate_names": [
                    "Neural Comput"
                ],
                "issn": "0899-7667",
                "url": "http://cognet.mit.edu/library/journals/journal?issn=08997667"
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2111838090",
                "DBLP": "journals/neco/RouxB10",
                "DOI": "10.1162/neco.2010.08-09-1081",
                "CorpusId": 15146942
            },
            "abstract": "Deep belief networks (DBN) are generative models with many layers of hidden causal variables, recently introduced by Hinton, Osindero, and Teh (2006), along with a greedy layer-wise unsupervised learning algorithm. Building on Le Roux and Bengio (2008) and Sutskever and Hinton (2008), we show that deep but narrow generative networks do not require more parameters than shallow ones to achieve universal approximation. Exploiting the proof technique, we prove that deep but narrow feedforward neural networks with sigmoidal units can represent any Boolean expression.",
            "referenceCount": 22,
            "citationCount": 166,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-08-01",
            "journal": {
                "name": "Neural Computation",
                "volume": "22"
            },
            "citationStyles": {
                "bibtex": "@Article{Roux2010DeepBN,\n author = {Nicolas Le Roux and Yoshua Bengio},\n booktitle = {Neural Computation},\n journal = {Neural Computation},\n pages = {2192-2207},\n title = {Deep Belief Networks Are Compact Universal Approximators},\n volume = {22},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:39664b871e5b90aa0f82d89469a230d9ecd02498",
            "@type": "ScholarlyArticle",
            "paperId": "39664b871e5b90aa0f82d89469a230d9ecd02498",
            "corpusId": 2316535,
            "url": "https://www.semanticscholar.org/paper/39664b871e5b90aa0f82d89469a230d9ecd02498",
            "title": "Vicinal Risk Minimization",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2000,
            "externalIds": {
                "MAG": "2151239833",
                "DBLP": "conf/nips/ChapelleWBV00",
                "CorpusId": 2316535
            },
            "abstract": "The Vicinal Risk Minimization principle establishes a bridge between generative models and methods derived from the Structural Risk Minimization Principle such as Support Vector Machines or Statistical Regularization. We explain how VRM provides a framework which integrates a number of existing algorithms, such as Parzen windows, Support Vector Machines, Ridge Regression, Constrained Logistic Classifiers and Tangent-Prop. We then show how the approach implies new algorithms for solving problems usually associated with generative models. New algorithms are described for dealing with pattern recognition problems with very different pattern distributions and dealing with unlabeled data. Preliminary empirical results are presented.",
            "referenceCount": 15,
            "citationCount": 292,
            "influentialCitationCount": 44,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chapelle2000VicinalRM,\n author = {O. Chapelle and J. Weston and L. Bottou and V. Vapnik},\n booktitle = {Neural Information Processing Systems},\n pages = {416-422},\n title = {Vicinal Risk Minimization},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:70f8f9a60d4be1fad844a7d6a90d01bc1529b8cd",
            "@type": "ScholarlyArticle",
            "paperId": "70f8f9a60d4be1fad844a7d6a90d01bc1529b8cd",
            "corpusId": 2005756,
            "url": "https://www.semanticscholar.org/paper/70f8f9a60d4be1fad844a7d6a90d01bc1529b8cd",
            "title": "The common patterns of nature",
            "venue": "Journal of Evolutionary Biology",
            "publicationVenue": {
                "id": "urn:research:ebd5707b-9e26-412f-84d4-a93354c1319e",
                "name": "Journal of Evolutionary Biology",
                "alternate_names": [
                    "J Evol Biology"
                ],
                "issn": "1010-061X",
                "url": "http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)1420-9101"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2120141446",
                "ArXiv": "0906.3507",
                "DOI": "10.1111/j.1420-9101.2009.01775.x",
                "CorpusId": 2005756,
                "PubMed": "19538344"
            },
            "abstract": "We typically observe large\u2010scale outcomes that arise from the interactions of many hidden, small\u2010scale processes. Examples include age of disease onset, rates of amino acid substitutions and composition of ecological communities. The macroscopic patterns in each problem often vary around a characteristic shape that can be generated by neutral processes. A neutral generative model assumes that each microscopic process follows unbiased or random stochastic fluctuations: random connections of network nodes; amino acid substitutions with no effect on fitness; species that arise or disappear from communities randomly. These neutral generative models often match common patterns of nature. In this paper, I present the theoretical background by which we can understand why these neutral generative models are so successful. I show where the classic patterns come from, such as the Poisson pattern, the normal or Gaussian pattern and many others. Each classic pattern was often discovered by a simple neutral generative model. The neutral patterns share a special characteristic: they describe the patterns of nature that follow from simple constraints on information. For example, any aggregation of processes that preserves information only about the mean and variance attracts to the Gaussian pattern; any aggregation that preserves information only about the mean attracts to the exponential pattern; any aggregation that preserves information only about the geometric mean attracts to the power law pattern. I present a simple and consistent informational framework of the common patterns of nature based on the method of maximum entropy. This framework shows that each neutral generative model is a special case that helps to discover a particular set of informational constraints; those informational constraints define a much wider domain of non\u2010neutral generative processes that attract to the same neutral pattern.",
            "referenceCount": 60,
            "citationCount": 189,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1420-9101.2009.01775.x",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Biology",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2009-06-18",
            "journal": {
                "name": "Journal of Evolutionary Biology",
                "volume": "22"
            },
            "citationStyles": {
                "bibtex": "@Article{Frank2009TheCP,\n author = {S. Frank},\n booktitle = {Journal of Evolutionary Biology},\n journal = {Journal of Evolutionary Biology},\n title = {The common patterns of nature},\n volume = {22},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d181ee5ea23ce57b0e673dfc5724dcc316013429",
            "@type": "ScholarlyArticle",
            "paperId": "d181ee5ea23ce57b0e673dfc5724dcc316013429",
            "corpusId": 3039898,
            "url": "https://www.semanticscholar.org/paper/d181ee5ea23ce57b0e673dfc5724dcc316013429",
            "title": "Why are deep nets reversible: A simple theory, with implications for training",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/AroraLM15",
                "ArXiv": "1511.05653",
                "MAG": "2178462512",
                "CorpusId": 3039898
            },
            "abstract": "Generative models for deep learning are promising both to improve understanding of the model, and yield training methods requiring fewer labeled samples. \nRecent works use generative model approaches to produce the deep net's input given the value of a hidden layer several levels above. However, there is no accompanying \"proof of correctness\" for the generative model, showing that the feedforward deep net is the correct inference method for recovering the hidden layer given the input. Furthermore, these models are complicated. \nThe current paper takes a more theoretical tack. It presents a very simple generative model for RELU deep nets, with the following characteristics: (i) The generative model is just the reverse of the feedforward net: if the forward transformation at a layer is $A$ then the reverse transformation is $A^T$. (This can be seen as an explanation of the old weight tying idea for denoising autoencoders.) (ii) Its correctness can be proven under a clean theoretical assumption: the edge weights in real-life deep nets behave like random numbers. Under this assumption ---which is experimentally tested on real-life nets like AlexNet--- it is formally proved that feed forward net is a correct inference method for recovering the hidden layer. \nThe generative model suggests a simple modification for training: use the generative model to produce synthetic data with labels and include it in the training set. Experiments are shown to support this theory of random-like deep nets; and that it helps the training.",
            "referenceCount": 25,
            "citationCount": 52,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-11-18",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1511.05653"
            },
            "citationStyles": {
                "bibtex": "@Article{Arora2015WhyAD,\n author = {Sanjeev Arora and Yingyu Liang and Tengyu Ma},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Why are deep nets reversible: A simple theory, with implications for training},\n volume = {abs/1511.05653},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a9f7e6743220a3d3f1a86921cc61bceb4ece0918",
            "@type": "ScholarlyArticle",
            "paperId": "a9f7e6743220a3d3f1a86921cc61bceb4ece0918",
            "corpusId": 43329106,
            "url": "https://www.semanticscholar.org/paper/a9f7e6743220a3d3f1a86921cc61bceb4ece0918",
            "title": "Bayesian PCA",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 1998,
            "externalIds": {
                "MAG": "2294460823",
                "DBLP": "conf/nips/Bishop98",
                "CorpusId": 43329106
            },
            "abstract": "The technique of principal component analysis (PCA) has recently been expressed as the maximum likelihood solution for a generative latent variable model. In this paper we use this probabilistic reformulation as the basis for a Bayesian treatment of PCA. Our key result is that effective dimensionality of the latent space (equivalent to the number of retained principal components) can be determined automatically as part of the Bayesian inference procedure. An important application of this framework is to mixtures of probabilistic PCA models, in which each component can determine its own effective complexity.",
            "referenceCount": 2,
            "citationCount": 345,
            "influentialCitationCount": 50,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1998-12-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bishop1998BayesianP,\n author = {Charles M. Bishop},\n booktitle = {Neural Information Processing Systems},\n pages = {382-388},\n title = {Bayesian PCA},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:765e503b4f37e40ff3a2c06deb7ec8ad305623a4",
            "@type": "ScholarlyArticle",
            "paperId": "765e503b4f37e40ff3a2c06deb7ec8ad305623a4",
            "corpusId": 101281,
            "url": "https://www.semanticscholar.org/paper/765e503b4f37e40ff3a2c06deb7ec8ad305623a4",
            "title": "Using PageRank to Characterize Web Structure",
            "venue": "Internet Mathematics",
            "publicationVenue": {
                "id": "urn:research:4f96108e-f62c-48be-a31a-b3d1ad831330",
                "name": "Internet Mathematics",
                "alternate_names": [
                    "Internet Math"
                ],
                "issn": "1542-7951",
                "url": "http://www.tandfonline.com/loi/uinm20"
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2170582301",
                "DBLP": "journals/im/PanduranganRU06",
                "DOI": "10.1080/15427951.2006.10129114",
                "CorpusId": 101281
            },
            "abstract": "Recent work on modeling the web graph has dwelt on capturing the degree distributions observed on the web. Pointing out that this represents a heavy reliance on \"local\" properties of the web graph, we study the distribution of PageRank values on the web. Our measurements suggest that PageRank values on the web follow a power law. We then develop generative models for the web graph that explain this observation and moreover remain faithful to previously studied degree distributions. We analyze these models and compare the analysis to both snapshots from the web and to graphs generated by simulations on the new models. To our knowledge this represents the first modeling of the web that goes beyond fitting degree distributions on the web.",
            "referenceCount": 29,
            "citationCount": 274,
            "influentialCitationCount": 26,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://projecteuclid.org/journals/internet-mathematics/volume-3/issue-1/Using-PageRank-to-characterize-web-structure/im/1175266365.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2002-08-15",
            "journal": {
                "name": "Internet Mathematics",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Pandurangan2002UsingPT,\n author = {Gopal Pandurangan and P. Raghavan and E. Upfal},\n booktitle = {Internet Mathematics},\n journal = {Internet Mathematics},\n pages = {1 - 20},\n title = {Using PageRank to Characterize Web Structure},\n volume = {3},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dffd149be34e7533d4c5663b7e0b819bb4537749",
            "@type": "ScholarlyArticle",
            "paperId": "dffd149be34e7533d4c5663b7e0b819bb4537749",
            "corpusId": 212405,
            "url": "https://www.semanticscholar.org/paper/dffd149be34e7533d4c5663b7e0b819bb4537749",
            "title": "Discriminative density propagation for 3D human motion estimation",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "conf/cvpr/SminchisescuKLM05",
                "MAG": "2158638750",
                "DOI": "10.1109/CVPR.2005.132",
                "CorpusId": 212405
            },
            "abstract": "We describe a mixture density propagation algorithm to estimate 3D human motion in monocular video sequences based on observations encoding the appearance of image silhouettes. Our approach is discriminative rather than generative, therefore it does not require the probabilistic inversion of a predictive observation model. Instead, it uses a large human motion capture data-base and a 3D computer graphics human model in order to synthesize training pairs of typical human configurations together with their realistically rendered 2D silhouettes. These are used to directly learn to predict the conditional state distributions required for 3D body pose tracking and thus avoid using the generative 3D model for inference (the learned discriminative predictors can also be used, complementary, as importance samplers in order to improve mixing or initialize generative inference algorithms). We aim for probabilistically motivated tracking algorithms and for models that can represent complex multivalued mappings common in inverse, uncertain perception inferences. Our paper has three contributions: (1) we establish the density propagation rules for discriminative inference in continuous, temporal chain models; (2) we propose flexible algorithms for learning multimodal state distributions based on compact, conditional Bayesian mixture of experts models; and (3) we demonstrate the algorithms empirically on real and motion capture-based test sequences and compare against nearest-neighbor and regression methods.",
            "referenceCount": 30,
            "citationCount": 281,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2005-06-20",
            "journal": {
                "name": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Sminchisescu2005DiscriminativeDP,\n author = {C. Sminchisescu and Atul Kanaujia and Zhiguo Li and Dimitris N. Metaxas},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},\n pages = {390-397 vol. 1},\n title = {Discriminative density propagation for 3D human motion estimation},\n volume = {1},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e722dd04fede7f024c0d0931fc353bfed39489ed",
            "@type": "ScholarlyArticle",
            "paperId": "e722dd04fede7f024c0d0931fc353bfed39489ed",
            "corpusId": 1046547,
            "url": "https://www.semanticscholar.org/paper/e722dd04fede7f024c0d0931fc353bfed39489ed",
            "title": "Structured Discriminative Model For Dialog State Tracking",
            "venue": "SIGDIAL Conference",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "ACL": "W13-4069",
                "MAG": "2251149342",
                "DBLP": "conf/sigdial/Lee13",
                "CorpusId": 1046547
            },
            "abstract": "Many dialog state tracking algorithms have been limited to generative modeling due to the influence of the Partially Observable Markov Decision Process framework. Recent analyses, however, raised fundamental questions on the effectiveness of the generative formulation. In this paper, we present a structured discriminative model for dialog state tracking as an alternative. Unlike generative models, the proposed method affords the incorporation of features without having to consider dependencies between observations. It also provides a flexible mechanism for imposing relational constraints. To verify the effectiveness of the proposed method, we applied it to the Let\u2019s Go domain (Raux et al., 2005). The results show that the proposed model is superior to the baseline and generative model-based systems in accuracy, discrimination, and robustness to mismatches between training and test datasets.",
            "referenceCount": 33,
            "citationCount": 57,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-08-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lee2013StructuredDM,\n author = {Sungjin Lee},\n booktitle = {SIGDIAL Conference},\n pages = {442-451},\n title = {Structured Discriminative Model For Dialog State Tracking},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:31f836b64ec71215f8b3e00cfbb31473b0f7127b",
            "@type": "ScholarlyArticle",
            "paperId": "31f836b64ec71215f8b3e00cfbb31473b0f7127b",
            "corpusId": 37229964,
            "url": "https://www.semanticscholar.org/paper/31f836b64ec71215f8b3e00cfbb31473b0f7127b",
            "title": "Contributing to others, contributing to oneself: perceptions of generativity and health in later life.",
            "venue": "The journals of gerontology. Series B, Psychological sciences and social sciences",
            "publicationVenue": {
                "id": "urn:research:ae36e72f-b788-43da-9c0a-c2a590d4866a",
                "name": "The journals of gerontology. Series B, Psychological sciences and social sciences",
                "alternate_names": [
                    "j gerontol Ser B Psychol sci soc sci",
                    "J Gerontol Ser B-psychological Sci Soc Sci",
                    "The Journals of Gerontology: Series B",
                    "Journals of Gerontology Series B-psychological Sciences and Social Sciences",
                    "J Gerontol Ser B"
                ],
                "issn": "1079-5014",
                "url": "http://psychsoc.gerontologyjournals.org/"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2116903059",
                "DOI": "10.1093/geronb/gbs034",
                "CorpusId": 37229964,
                "PubMed": "22454386"
            },
            "abstract": "OBJECTIVES\nTo examine whether perceptions of generativity predict the likelihood of increases in levels of impairment in activities of daily living (ADLs) or of dying over a 10-year period in older adults aged 60-75 from the Study of Midlife in the United States (MIDUS).\n\n\nMETHOD\nPerceptions of generativity and current generative contributions as well as select sociodemographic, health status, health behavior, and psychosocial factors, assessed at a baseline exam, were examined as predictors of change in ADL disability level or mortality over the 10-year period between the baseline and follow-up waves of the MIDUS Study.\n\n\nRESULTS\nGreater levels of generativity and generative contributions at baseline predicted lower odds of experiencing increases in ADL disability (2 or more new domains of impairment; generativity odds ratio [OR] = 0.93 and generative contributions OR = 0.87), or of dying (generativity OR = 0.94 and generative contributions OR = 0.88), over the 10-year follow-up in models adjusted for sociodemographics and baseline health and disability. Associations remained relatively unchanged with the inclusion of different sets of health behavior and psychosocial variables in analytic models.\n\n\nDISCUSSION\nFindings indicate that greater perceptions of generativity are associated with more favorable trajectories of physical functioning and longevity over time in older adults.",
            "referenceCount": 23,
            "citationCount": 112,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc3478723?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-11-01",
            "journal": {
                "name": "The journals of gerontology. Series B, Psychological sciences and social sciences",
                "volume": "67 6"
            },
            "citationStyles": {
                "bibtex": "@Article{Gruenewald2012ContributingTO,\n author = {T. Gruenewald and D. Liao and T. Seeman},\n booktitle = {The journals of gerontology. Series B, Psychological sciences and social sciences},\n journal = {The journals of gerontology. Series B, Psychological sciences and social sciences},\n pages = {\n          660-5\n        },\n title = {Contributing to others, contributing to oneself: perceptions of generativity and health in later life.},\n volume = {67 6},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d7cf17d04b16165ec74e6e754757dc17fddc1666",
            "@type": "ScholarlyArticle",
            "paperId": "d7cf17d04b16165ec74e6e754757dc17fddc1666",
            "corpusId": 803811,
            "url": "https://www.semanticscholar.org/paper/d7cf17d04b16165ec74e6e754757dc17fddc1666",
            "title": "Efficient, Feature-based, Conditional Random Field Parsing",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2008,
            "externalIds": {
                "DBLP": "conf/acl/FinkelKM08",
                "MAG": "2134275125",
                "ACL": "P08-1109",
                "CorpusId": 803811
            },
            "abstract": "Discriminative feature-based methods are widely used in natural language processing, but sentence parsing is still dominated by generative methods. While prior feature-based dynamic programming parsers have restricted training and evaluation to artificially short sentences, we present the first general, featurerich discriminative parser, based on a conditional random field model, which has been successfully scaled to the full WSJ parsing data. Our efficiency is primarily due to the use of stochastic optimization techniques, as well as parallelization and chart prefiltering. On WSJ15, we attain a state-of-the-art F-score of 90.9%, a 14% relative reduction in error over previous models, while being two orders of magnitude faster. On sentences of length 40, our system achieves an F-score of 89.0%, a 36% relative reduction in error over a generative baseline.",
            "referenceCount": 23,
            "citationCount": 215,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-06-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Finkel2008EfficientFC,\n author = {J. Finkel and A. Kleeman and Christopher D. Manning},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {959-967},\n title = {Efficient, Feature-based, Conditional Random Field Parsing},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:24b20f7b118588055346f4ac5cdb1fe22e886dda",
            "@type": "ScholarlyArticle",
            "paperId": "24b20f7b118588055346f4ac5cdb1fe22e886dda",
            "corpusId": 5881111,
            "url": "https://www.semanticscholar.org/paper/24b20f7b118588055346f4ac5cdb1fe22e886dda",
            "title": "Interpolating between types and tokens by estimating power-law generators",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "conf/nips/GoldwaterGJ05",
                "MAG": "2159399018",
                "CorpusId": 5881111
            },
            "abstract": "Standard statistical models of language fail to capture one of the most striking properties of natural languages: the power-law distribution in the frequencies of word tokens. We present a framework for developing statistical models that generically produce power-laws, augmenting standard generative models with an adaptor that produces the appropriate pattern of token frequencies. We show that taking a particular stochastic process - the Pitman-Yor process - as an adaptor justifies the appearance of type frequencies in formal analyses of natural language, and improves the performance of a model for unsupervised learning of morphology.",
            "referenceCount": 17,
            "citationCount": 228,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2005-12-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Goldwater2005InterpolatingBT,\n author = {S. Goldwater and T. Griffiths and Mark Johnson},\n booktitle = {Neural Information Processing Systems},\n pages = {459-466},\n title = {Interpolating between types and tokens by estimating power-law generators},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3f324eec80f61d7f7c1511e80bef802a47efc984",
            "@type": "ScholarlyArticle",
            "paperId": "3f324eec80f61d7f7c1511e80bef802a47efc984",
            "corpusId": 7976912,
            "url": "https://www.semanticscholar.org/paper/3f324eec80f61d7f7c1511e80bef802a47efc984",
            "title": "Co-evolution of social and affiliation networks",
            "venue": "Knowledge Discovery and Data Mining",
            "publicationVenue": {
                "id": "urn:research:a0edb93b-1e95-4128-a295-6b1659149cef",
                "name": "Knowledge Discovery and Data Mining",
                "alternate_names": [
                    "KDD",
                    "Knowl Discov Data Min"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigkdd/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2036248440",
                "DBLP": "conf/kdd/ZhelevaSG09",
                "DOI": "10.1145/1557019.1557128",
                "CorpusId": 7976912
            },
            "abstract": "In our work, we address the problem of modeling social network generation which explains both link and group formation. Recent studies on social network evolution propose generative models which capture the statistical properties of real-world networks related only to node-to-node link formation. We propose a novel model which captures the co-evolution of social and affiliation networks. We provide surprising insights into group formation based on observations in several real-world networks, showing that users often join groups for reasons other than their friends. Our experiments show that the model is able to capture both the newly observed and previously studied network properties. This work is the first to propose a generative model which captures the statistical properties of these complex networks. The proposed model facilitates controlled experiments which study the effect of actors' behavior on the evolution of affiliation networks, and it allows the generation of realistic synthetic datasets.",
            "referenceCount": 11,
            "citationCount": 140,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2009-06-28",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zheleva2009CoevolutionOS,\n author = {E. Zheleva and Hossam Sharara and L. Getoor},\n booktitle = {Knowledge Discovery and Data Mining},\n pages = {1007-1016},\n title = {Co-evolution of social and affiliation networks},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:23c479a93f598f9e01d3b4e3d79d011ac91319b1",
            "@type": "ScholarlyArticle",
            "paperId": "23c479a93f598f9e01d3b4e3d79d011ac91319b1",
            "corpusId": 7835262,
            "url": "https://www.semanticscholar.org/paper/23c479a93f598f9e01d3b4e3d79d011ac91319b1",
            "title": "Speaker verification using sequence discriminant support vector machines",
            "venue": "IEEE Transactions on Speech and Audio Processing",
            "publicationVenue": {
                "id": "urn:research:cd5799dd-1165-414f-87b0-ea5e184781c0",
                "name": "IEEE Transactions on Speech and Audio Processing",
                "alternate_names": [
                    "IEEE Trans Speech Audio Process"
                ],
                "issn": "1063-6676",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=89"
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2189342046",
                "DBLP": "journals/taslp/WanR05",
                "DOI": "10.1109/TSA.2004.841042",
                "CorpusId": 7835262
            },
            "abstract": "This paper presents a text-independent speaker verification system using support vector machines (SVMs) with score-space kernels. Score-space kernels generalize Fisher kernels and are based on underlying generative models such as Gaussian mixture models (GMMs). This approach provides direct discrimination between whole sequences, in contrast with the frame-level approaches at the heart of most current systems. The resultant SVMs have a very high dimensionality since it is related to the number of parameters in the underlying generative model. To address problems that arise in the resultant optimization we introduce a technique called spherical normalization that preconditions the Hessian matrix. We have performed speaker verification experiments using the PolyVar database. The SVM system presented here reduces the relative error rates by 34% compared to a GMM likelihood ratio system.",
            "referenceCount": 28,
            "citationCount": 220,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://eprints.whiterose.ac.uk/813/1/wanv1.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2005-02-22",
            "journal": {
                "name": "IEEE Transactions on Speech and Audio Processing",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Wan2005SpeakerVU,\n author = {V. Wan and S. Renals},\n booktitle = {IEEE Transactions on Speech and Audio Processing},\n journal = {IEEE Transactions on Speech and Audio Processing},\n pages = {203-210},\n title = {Speaker verification using sequence discriminant support vector machines},\n volume = {13},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:80c330eee12decb84aaebcc85dc7ce414134ad61",
            "@type": "ScholarlyArticle",
            "paperId": "80c330eee12decb84aaebcc85dc7ce414134ad61",
            "corpusId": 2054939,
            "url": "https://www.semanticscholar.org/paper/80c330eee12decb84aaebcc85dc7ce414134ad61",
            "title": "Modeling image patches with a directed hierarchy of Markov random fields",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2007,
            "externalIds": {
                "DBLP": "conf/nips/OsinderoH07",
                "MAG": "2134653808",
                "CorpusId": 2054939
            },
            "abstract": "We describe an efficient learning procedure for multilayer generative models that combine the best aspects of Markov random fields and deep, directed belief nets. The generative models can be learned one layer at a time and when learning is complete they have a very fast inference procedure for computing a good approximation to the posterior distribution in all of the hidden layers. Each hidden layer has its own MRF whose energy function is modulated by the top-down directed connections from the layer above. To generate from the model, each layer in turn must settle to equilibrium given its top-down input. We show that this type of model is good at capturing the statistics of patches of natural images.",
            "referenceCount": 18,
            "citationCount": 142,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2007-12-03",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Osindero2007ModelingIP,\n author = {Simon Osindero and Geoffrey E. Hinton},\n booktitle = {Neural Information Processing Systems},\n pages = {1121-1128},\n title = {Modeling image patches with a directed hierarchy of Markov random fields},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8eefd28eb47e72794bb0355d8abcbebaac9d8ab1",
            "@type": "ScholarlyArticle",
            "paperId": "8eefd28eb47e72794bb0355d8abcbebaac9d8ab1",
            "corpusId": 256574,
            "url": "https://www.semanticscholar.org/paper/8eefd28eb47e72794bb0355d8abcbebaac9d8ab1",
            "title": "Semi-Supervised Text Classification Using EM",
            "venue": "Semi-Supervised Learning",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2486125749",
                "DBLP": "books/mit/06/NigamMM06",
                "DOI": "10.7551/mitpress/9780262033589.003.0003",
                "CorpusId": 256574
            },
            "abstract": "For several decades, statisticians have advocated using a combination of labeled and unlabeled data to train classifiers by estimating parameters of a generative model through iterative Expectation-Maximization (EM) techniques. This chapter explores the effectiveness of this approach when applied to the domain of text classification. Text documents are represented here with a bag-of-words model, which leads to a generative classification model based on a mixture of multinomials. This model is an extremely simplistic representation of the complexities of written text. This chapter explains and illustrates three key points about semi-supervised learning for text classification with generative models. First, despite the simplistic representation, some text domains have a high positive correlation between generative model probability and classification accuracy. In these domains, a straightforward application of EM with the naive Bayes text model works well. Second, some text domains do not have this correlation. Here we can adopt a more expressive and appropriate generative model that does have a positive correlation. In these domains, semi-supervised learning again improves classification accuracy. Finally, EM suffers from the problem of local maxima, especially in high dimension domains such as text classification. We demonstrate that deterministic annealing, a variant of EM, can help overcome the problem of local maxima and increase classification accuracy further when the generative model is appropriate.",
            "referenceCount": 11,
            "citationCount": 166,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Nigam2006SemiSupervisedTC,\n author = {K. Nigam and A. McCallum and Tom Michael Mitchell},\n booktitle = {Semi-Supervised Learning},\n pages = {32-55},\n title = {Semi-Supervised Text Classification Using EM},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5bb45289802f3991b368e99b3e0e3d30e4838855",
            "@type": "ScholarlyArticle",
            "paperId": "5bb45289802f3991b368e99b3e0e3d30e4838855",
            "corpusId": 62147006,
            "url": "https://www.semanticscholar.org/paper/5bb45289802f3991b368e99b3e0e3d30e4838855",
            "title": "Queueing theory in manufacturing systems analysis and design",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1993,
            "externalIds": {
                "MAG": "2067935958",
                "CorpusId": 62147006
            },
            "abstract": "Preface. Part 1: Manufacturing system design. Queueing theory: a review. Part 2: Modelling flexible manufacturing systems using queueing network models. Modelling production lines using queueing network models. Modelling transfer lines using queueing network models. Part 3: Generative models for inventory control problems in manufacturing systems. Part 4: Simulation of manufacturing systems",
            "referenceCount": 0,
            "citationCount": 271,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Atkinson1993QueueingTI,\n author = {B. Atkinson},\n title = {Queueing theory in manufacturing systems analysis and design},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cee30e5fe700b98bc408bc40ea9ec396520b473a",
            "@type": "ScholarlyArticle",
            "paperId": "cee30e5fe700b98bc408bc40ea9ec396520b473a",
            "corpusId": 6186704,
            "url": "https://www.semanticscholar.org/paper/cee30e5fe700b98bc408bc40ea9ec396520b473a",
            "title": "A Discriminative Framework for Bilingual Word Alignment",
            "venue": "Human Language Technology - The Baltic Perspectiv",
            "publicationVenue": {
                "id": "urn:research:f8e3f8d0-0f40-48c0-b3c0-0c540237b859",
                "name": "Human Language Technology - The Baltic Perspectiv",
                "alternate_names": [
                    "Human Language Technology",
                    "HLT",
                    "Hum Lang Technol",
                    "Hum Lang Technol  Balt Perspect"
                ],
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "ACL": "H05-1011",
                "DBLP": "conf/naacl/Moore05",
                "MAG": "2124810114",
                "DOI": "10.3115/1220575.1220586",
                "CorpusId": 6186704
            },
            "abstract": "Bilingual word alignment forms the foundation of most approaches to statistical machine translation. Current word alignment methods are predominantly based on generative models. In this paper, we demonstrate a discriminative approach to training simple word alignment models that are comparable in accuracy to the more complex generative models normally used. These models have the the advantages that they are easy to add features to and they allow fast optimization of model parameters using small amounts of annotated data.",
            "referenceCount": 14,
            "citationCount": 181,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=1220586&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2005-10-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Moore2005ADF,\n author = {Robert C. Moore},\n booktitle = {Human Language Technology - The Baltic Perspectiv},\n pages = {81-88},\n title = {A Discriminative Framework for Bilingual Word Alignment},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6389de20cc616501acf1a7032b2a8c4ab6defd31",
            "@type": "ScholarlyArticle",
            "paperId": "6389de20cc616501acf1a7032b2a8c4ab6defd31",
            "corpusId": 143864608,
            "url": "https://www.semanticscholar.org/paper/6389de20cc616501acf1a7032b2a8c4ab6defd31",
            "title": "Instrument mediated activity: from subject development to anthropocentric design",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "1976821753",
                "DOI": "10.1080/14639220500078179",
                "CorpusId": 143864608
            },
            "abstract": "The aim of this article is to present the \u2018instrument-mediated activity\u2019 approach, which is part of a \u2018generative model\u2019. A group of principles liable to contribute to the epistemological unity of generative models is put forward as well as a theoretical framework that conceptualizes what an instrument is for the subject. The article develops the idea that the instrument is a mixed entity born of both the subject and the artifact. The artifact is not an instrument in itself. It is the subject who grants it the status of a means for his/her action. Processes of design in usage by users are defined as \u2018instrumental geneses\u2019. Finally, the consequences of this model on the organization of design processes are examined, in taking into account instrumental geneses as resources for design.",
            "referenceCount": 84,
            "citationCount": 202,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2005-09-01",
            "journal": {
                "name": "Theoretical Issues in Ergonomics Science",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Rabardel2005InstrumentMA,\n author = {P. Rabardel and P. B\u00e9guin},\n journal = {Theoretical Issues in Ergonomics Science},\n pages = {429 - 461},\n title = {Instrument mediated activity: from subject development to anthropocentric design},\n volume = {6},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6eb2f6953573c7419eadc077ece18e63f2d11704",
            "@type": "ScholarlyArticle",
            "paperId": "6eb2f6953573c7419eadc077ece18e63f2d11704",
            "corpusId": 5245012,
            "url": "https://www.semanticscholar.org/paper/6eb2f6953573c7419eadc077ece18e63f2d11704",
            "title": "A Conditional Random Field for Discriminatively-trained Finite-state String Edit Distance",
            "venue": "Conference on Uncertainty in Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:f9af8000-42f8-410d-a622-e8811e41660a",
                "name": "Conference on Uncertainty in Artificial Intelligence",
                "alternate_names": [
                    "Uncertainty in Artificial Intelligence",
                    "UAI",
                    "Conf Uncertain Artif Intell",
                    "Uncertain Artif Intell"
                ],
                "issn": null,
                "url": "http://www.auai.org/"
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "conf/uai/McCallumBP05",
                "MAG": "2952137874",
                "ArXiv": "1207.1406",
                "DOI": "10.21236/ada440386",
                "CorpusId": 5245012
            },
            "abstract": "The need to measure sequence similarity arises in information extraction, object identity, data mining, biological sequence analysis, and other domains. This paper presents discriminative string-edit CRFs, a finite-state conditional random field model for edit sequences between strings. Conditional random fields have advantages over generative approaches to this problem, such as pair HMMs or the work of Ristad and Yianilos, because as conditionally-trained methods, they enable the use of complex, arbitrary actions and features of the input strings. As in generative models, the training data does not have to specify the edit sequences between the given string pairs. Unlike generative models, however, our model is trained on both positive and negative instances of string pairs. We present positive experimental results on several data sets.",
            "referenceCount": 28,
            "citationCount": 151,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1207.1406",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2005-07-26",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{McCallum2005ACR,\n author = {A. McCallum and Kedar Bellare and Fernando C Pereira},\n booktitle = {Conference on Uncertainty in Artificial Intelligence},\n pages = {388-395},\n title = {A Conditional Random Field for Discriminatively-trained Finite-state String Edit Distance},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:50c56af1eb05cfb6ec81e84a6924fb46cb202747",
            "@type": "ScholarlyArticle",
            "paperId": "50c56af1eb05cfb6ec81e84a6924fb46cb202747",
            "corpusId": 15161133,
            "url": "https://www.semanticscholar.org/paper/50c56af1eb05cfb6ec81e84a6924fb46cb202747",
            "title": "Using unlabeled data to improve text classification",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2122520221",
                "CorpusId": 15161133
            },
            "abstract": "One key difficulty with text classification learning algorithms is that they require many hand-labeled examples to learn accurately. This dissertation demonstrates that supervised learning algorithms that use a small number of labeled examples and many inexpensive unlabeled examples can create high-accuracy text classifiers. By assuming that documents are created by a parametric generative model, Expectation-Maximization (EM) finds local maximum a posteriori models and classifiers from all the data\u2014labeled and unlabeled. These generative models do not capture all the intricacies of text; however on some domains this technique substantially improves classification accuracy, especially when labeled data are sparse. \nTwo problems arise from this basic approach. First, unlabeled data can hurt performance in domains where the generative modeling assumptions are too strongly violated. In this case the assumptions can be made more representative in two ways: by modeling sub-topic class structure, and by modeling super-topic hierarchical class relationships. By doing so, model probability and classification accuracy come into correspondence, allowing unlabeled data to improve classification performance. The second problem is that even with a representative model, the improvements given by unlabeled data do not sufficiently compensate for a paucity of labeled data. Here, limited labeled data provide EM initializations that lead to low-probability models. Performance can be significantly improved by using active learning to select high-quality initializations, and by using alternatives to EM that avoid low-probability local maxima.",
            "referenceCount": 129,
            "citationCount": 171,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Nigam2001UsingUD,\n author = {K. Nigam and Tom Michael Mitchell},\n pages = {124-124},\n title = {Using unlabeled data to improve text classification},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:80382ab7ca41fff77e525c68a72174415647fbec",
            "@type": "ScholarlyArticle",
            "paperId": "80382ab7ca41fff77e525c68a72174415647fbec",
            "corpusId": 6637448,
            "url": "https://www.semanticscholar.org/paper/80382ab7ca41fff77e525c68a72174415647fbec",
            "title": "A Hierarchical Bayesian Model of Human Decision-Making on an Optimal Stopping Problem",
            "venue": "Cognitive Sciences",
            "publicationVenue": {
                "id": "urn:research:c33b01b0-31b4-470e-a9f9-8432e02c3cb9",
                "name": "Cognitive Sciences",
                "alternate_names": [
                    "Cognitive Science",
                    "Cogn Sci"
                ],
                "issn": "1935-8059",
                "url": "http://www.informaworld.com/openurl?genre=journal&issn=1551-6709"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "journals/cogsci/Lee06",
                "MAG": "2139863081",
                "DOI": "10.1207/s15516709cog0000_69",
                "CorpusId": 6637448,
                "PubMed": "21702820"
            },
            "abstract": "We consider human performance on an optimal stopping problem where people are presented with a list of numbers independently chosen from a uniform distribution. People are told how many numbers are in the list, and how they were chosen. People are then shown the numbers one at a time, and are instructed to choose the maximum, subject to the constraint that they must choose a number at the time it is presented, and any choice below the maximum is incorrect. We present empirical evidence that suggests people use threshold-based models to make decisions, choosing the first currently maximal number that exceeds a fixed threshold for that position in the list. We then develop a hierarchical generative account of this model family, and use Bayesian methods to learn about the parameters of the generative process, making inferences about the threshold decision models people use. We discuss the interesting aspects of human performance on the task, including the lack of learning, and the presence of large individual differences, and consider the possibility of extending the modeling framework to account for individual differences. We also use the modeling results to discuss the merits of hierarchical, generative and Bayesian models of cognitive processes more generally.",
            "referenceCount": 37,
            "citationCount": 141,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1207/s15516709cog0000_69",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Psychology",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-05-06",
            "journal": {
                "name": "Cognitive science",
                "volume": "30 3"
            },
            "citationStyles": {
                "bibtex": "@Article{Lee2006AHB,\n author = {M. Lee},\n booktitle = {Cognitive Sciences},\n journal = {Cognitive science},\n pages = {\n          1-26\n        },\n title = {A Hierarchical Bayesian Model of Human Decision-Making on an Optimal Stopping Problem},\n volume = {30 3},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b5820da066e9cd449f073dac3474210b590ba96d",
            "@type": "ScholarlyArticle",
            "paperId": "b5820da066e9cd449f073dac3474210b590ba96d",
            "corpusId": 6339052,
            "url": "https://www.semanticscholar.org/paper/b5820da066e9cd449f073dac3474210b590ba96d",
            "title": "A Reactive Planner for a Model-based Executive",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 1997,
            "externalIds": {
                "DBLP": "conf/ijcai/WilliamsN97",
                "MAG": "1533012984",
                "CorpusId": 6339052
            },
            "abstract": "A new generation of reactive, model-based executives are emerging that make extensive use of componentbased declarative models to analyze anomalous situations and generate novel sequences for the internal control of complex autonomous systems. Burton, a generative, model-based planner offers a core element that bridges the gap between current and target states within the reactive loop. Burton is a sound, complete, reactive planner that generates a single control action of a valid plan in average case constant time, and compensates for anomalies at every step. Burton will not generate irreversible, potentially damaging sequences, except to effect repairs. We present model compilation, causal analysis, and online policy construction methods that are key to Burton's performance.",
            "referenceCount": 11,
            "citationCount": 196,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1997-08-23",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Williams1997ARP,\n author = {B. Williams and P. Nayak},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {1178-1185},\n title = {A Reactive Planner for a Model-based Executive},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1af67fb5c15470c9e8954cae66702293dd66bae8",
            "@type": "ScholarlyArticle",
            "paperId": "1af67fb5c15470c9e8954cae66702293dd66bae8",
            "corpusId": 15133267,
            "url": "https://www.semanticscholar.org/paper/1af67fb5c15470c9e8954cae66702293dd66bae8",
            "title": "Learning Joint Top-Down and Bottom-up Processes for 3D Visual Inference",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2132026986",
                "DBLP": "conf/cvpr/SminchisescuKM06",
                "DOI": "10.1109/CVPR.2006.169",
                "CorpusId": 15133267
            },
            "abstract": "We present an algorithm for jointly learning a consistent bidirectional generative-recognition model that combines top-down and bottom-up processing for monocular 3d human motion reconstruction. Learning progresses in alternative stages of self-training that optimize the probability of the image evidence: the recognition model is tunned using samples from the generative model and the generative model is optimized to produce inferences close to the ones predicted by the current recognition model. At equilibrium, the two models are consistent. During on-line inference, we scan the image at multiple locations and predict 3d human poses using the recognition model. But this implicitly includes one-shot generative consistency feedback. The framework provides a uniform treatment of human detection, 3d initialization and 3d recovery from transient failure. Our experimental results show that this procedure is promising for the automatic reconstruction of human motion in more natural scene settings with background clutter and occlusion.",
            "referenceCount": 33,
            "citationCount": 121,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cs.toronto.edu/~crismin/PAPERS/sm_learn_cvpr06.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-06-17",
            "journal": {
                "name": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Sminchisescu2006LearningJT,\n author = {C. Sminchisescu and Atul Kanaujia and Dimitris N. Metaxas},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},\n pages = {1743-1752},\n title = {Learning Joint Top-Down and Bottom-up Processes for 3D Visual Inference},\n volume = {2},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f4d1d9cff89e8b8a875001b85c11cd98bff391d6",
            "@type": "ScholarlyArticle",
            "paperId": "f4d1d9cff89e8b8a875001b85c11cd98bff391d6",
            "corpusId": 9245003,
            "url": "https://www.semanticscholar.org/paper/f4d1d9cff89e8b8a875001b85c11cd98bff391d6",
            "title": "Bhattacharyya and Expected Likelihood Kernels",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "CorpusId": 9245003
            },
            "abstract": "We introduce a new class of kernels between distributions. These induce a kernel on the input space between data points by associating to each datum a generative model fit to the data point individually. The kernel is then computed by integrating the product of the two generative models corresponding to two data points. This kernel permits discriminative estimation via, for instance, support vector machines, while exploiting the properties, assumptions, and invariances inherent in the choice of generative model. It satisfies Mercer\u2019s condition and can be computed in closed form for a large class of models, including exponential family models, mixtures, hidden Markov models and Bayesian networks. For other models the kernel can be approximated by sampling methods. Experiments are shown for multinomial models in text classification and for hidden Markov models for protein sequence classification.",
            "referenceCount": 34,
            "citationCount": 110,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Jebara2003BhattacharyyaAE,\n author = {T. Jebara and R. Kondor},\n title = {Bhattacharyya and Expected Likelihood Kernels},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bd6b6bb05302687c9dccd05c588c9c5907978965",
            "@type": "ScholarlyArticle",
            "paperId": "bd6b6bb05302687c9dccd05c588c9c5907978965",
            "corpusId": 3246603,
            "url": "https://www.semanticscholar.org/paper/bd6b6bb05302687c9dccd05c588c9c5907978965",
            "title": "Statistical Modeling and Conceptualization of Visual Patterns",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2003,
            "externalIds": {
                "DBLP": "journals/pami/Zhu03",
                "MAG": "2168239404",
                "DOI": "10.1109/TPAMI.2003.1201820",
                "CorpusId": 3246603
            },
            "abstract": "Natural images contain an overwhelming number of visual patterns generated by diverse stochastic processes. Defining and modeling these patterns is of fundamental importance for generic vision tasks, such as perceptual organization, segmentation, and recognition. The objective of this epistemological paper is to summarize various threads of research in the literature and to pursue a unified framework for conceptualization, modeling, learning, and computing visual patterns. This paper starts with reviewing four research streams: 1) the study of image statistics, 2) the analysis of image components, 3) the grouping of image elements, and 4) the modeling of visual patterns. The models from these research streams are then divided into four categories according to their semantic structures: 1) descriptive models, i.e., Markov random fields (MRF) or Gibbs, 2) variants of descriptive models (causal MRF and \"pseudodescriptive\" models), 3) generative models, and 4) discriminative models. The objectives, principles, theories, and typical models are reviewed in each category and the relationships between the four types of models are studied. Two central themes emerge from the relationship studies. 1) In representation, the integration of descriptive and generative models is the future direction for statistical modeling and should lead to richer and more advanced classes of vision models. 2) To make visual models computationally tractable, discriminative models are used as computational heuristics for inferring generative models. Thus, the roles of four types of models are clarified.",
            "referenceCount": 99,
            "citationCount": 130,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.stat.ucla.edu/~sczhu/papers/conceptualization.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2003-06-01",
            "journal": {
                "name": "IEEE Trans. Pattern Anal. Mach. Intell.",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhu2003StatisticalMA,\n author = {Song-Chun Zhu},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Trans. Pattern Anal. Mach. Intell.},\n pages = {691-712},\n title = {Statistical Modeling and Conceptualization of Visual Patterns},\n volume = {25},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:53db1adf5f3943e107a6064efe801667501ae9f8",
            "@type": "ScholarlyArticle",
            "paperId": "53db1adf5f3943e107a6064efe801667501ae9f8",
            "corpusId": 7433743,
            "url": "https://www.semanticscholar.org/paper/53db1adf5f3943e107a6064efe801667501ae9f8",
            "title": "Getting the Structure Right for Word Alignment: LEAF",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2007,
            "externalIds": {
                "MAG": "2102607778",
                "DBLP": "conf/emnlp/FraserM07",
                "ACL": "D07-1006",
                "CorpusId": 7433743
            },
            "abstract": "Word alignment is the problem of annotating parallel text with translational correspondence. Previous generative word alignment models have made structural assumptions such as the 1-to-1, 1-to-N, or phrase-based consecutive word assumptions, while previous discriminative models have either made such an assumption directly or used features derived from a generative model making one of these assumptions. We present a new generative alignment model which avoids these structural limitations, and show that it is effective when trained using both unsupervised and semi-supervised training methods.",
            "referenceCount": 30,
            "citationCount": 75,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2007-06-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Fraser2007GettingTS,\n author = {Alexander M. Fraser and D. Marcu},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {51-60},\n title = {Getting the Structure Right for Word Alignment: LEAF},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca799ce56badd32b2c5ea9a80428c9e4f75df423",
            "@type": "ScholarlyArticle",
            "paperId": "ca799ce56badd32b2c5ea9a80428c9e4f75df423",
            "corpusId": 6869955,
            "url": "https://www.semanticscholar.org/paper/ca799ce56badd32b2c5ea9a80428c9e4f75df423",
            "title": "A MODEL OF GROWTH AND GROWTH CONTROL IN MATHEMATICAL TERMS",
            "venue": "The Journal of General Physiology",
            "publicationVenue": {
                "id": "urn:research:eb5b7fda-8fd6-48a1-bfed-2aac4b99cbee",
                "name": "The Journal of General Physiology",
                "alternate_names": [
                    "J Gen Physiol"
                ],
                "issn": "0022-1295",
                "url": "http://www.pubmedcentral.nih.gov/tocrender.fcgi?action=archive&journal=484"
            },
            "year": 1957,
            "externalIds": {
                "PubMedCentral": "2194824",
                "MAG": "2186323258",
                "DOI": "10.1085/JGP.41.1.1",
                "CorpusId": 6869955,
                "PubMed": "13463267"
            },
            "abstract": "A practicable model of the growth process, which gives better definition to the problem of growth and growth regulation and greater precision to related experimental work than do earlier models, is developed on the basis of the following assumptions: \"Growth\" is the net balance of mass produced and retained over mass destroyed and otherwise lost, implying continual metabolic degradation and replacement. Terminal size represents stationary equilibrium between incremental and decremental components. The mass of an organic system consists of two functionally different components,\u2014generative and differentiated. Generative mass increases by the catalytic action of key compounds (\"templates\") characteristic of each cell type. Each cell also produces specific freely diffusible compounds antagonistic to these templates (\"antitemplates\"). Growth regulation occurs automatically by a negative \"feedback\" in which increasing numbers of antitemplates progressively block the corresponding templates. Differential equations expressing these interrelationships are formulated, integrated, and the solutions evaluated for the case of chick growth. These specific solutions lead to descriptions of the normal growth of a biological system which are in good agreement with known facts, and to predictions of the course of automatic growth regulations after experimental or pathological disturbances which reproduce adequately biological observations in this domain.",
            "referenceCount": 33,
            "citationCount": 285,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://rupress.org/jgp/article-pdf/41/1/1/1803243/1.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1957-09-20",
            "journal": {
                "name": "The Journal of General Physiology",
                "volume": "41"
            },
            "citationStyles": {
                "bibtex": "@Article{Weiss1957AMO,\n author = {P. Weiss and J. Kavanau},\n booktitle = {The Journal of General Physiology},\n journal = {The Journal of General Physiology},\n pages = {1 - 47},\n title = {A MODEL OF GROWTH AND GROWTH CONTROL IN MATHEMATICAL TERMS},\n volume = {41},\n year = {1957}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cd88b55c426385147631f09cd3b695045c715ce9",
            "@type": "ScholarlyArticle",
            "paperId": "cd88b55c426385147631f09cd3b695045c715ce9",
            "corpusId": 60785973,
            "url": "https://www.semanticscholar.org/paper/cd88b55c426385147631f09cd3b695045c715ce9",
            "title": "Agile model driven development is good enough",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "1983235239",
                "DOI": "10.1109/MS.2003.1231156",
                "CorpusId": 60785973
            },
            "abstract": "I'm not all that sure about the direction that model-driven development appears to be taking. Don't get me wrong-I'm a firm believer in modeling. It's just that I think that there's a lot more to development than this. Here's my point: We need to distinguish between generative MDD and Agile MDD. Generative MDD, epitomized by the Object Management Group's Model Driven Architecture, is based on the idea that people will use very sophisticated modeling tools to create very sophisticated models that they can automatically \"transform\" with those tools to reflect the realities of various deployment platforms. Great theory-as was the idea that the world is flat. In my opinion, generative MDD is a lost cause for the current generation of developers. Agile MDD will be a struggle to pull off, but at least it has a chance of succeeding.",
            "referenceCount": 0,
            "citationCount": 79,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2003-09-01",
            "journal": {
                "name": "IEEE Software",
                "volume": "20"
            },
            "citationStyles": {
                "bibtex": "@Article{Ambler2003AgileMD,\n author = {S. Ambler},\n journal = {IEEE Software},\n pages = {71-73},\n title = {Agile model driven development is good enough},\n volume = {20},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2c3cac0f568ae9261ff9c80eeda55a13e83ae7fb",
            "@type": "ScholarlyArticle",
            "paperId": "2c3cac0f568ae9261ff9c80eeda55a13e83ae7fb",
            "corpusId": 14904115,
            "url": "https://www.semanticscholar.org/paper/2c3cac0f568ae9261ff9c80eeda55a13e83ae7fb",
            "title": "A discriminative framework for modelling object classes",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "conf/cvpr/HolubP05",
                "MAG": "2105231718",
                "DOI": "10.1109/CVPR.2005.25",
                "CorpusId": 14904115
            },
            "abstract": "Here we explore a discriminative learning method on underlying generative models for the purpose of discriminating between object categories. Visual recognition algorithms learn models from a set of training examples. Generative models learn their representations by considering data from a single class. Generative models are popular in computer vision for many reasons, including their ability to elegantly incorporate prior knowledge and to handle correspondences between object parts and detected features. However, generative models are often inferior to discriminative models during classification tasks. We study a discriminative approach to learning object categories which maintains the representational power of generative learning, but trains the generative models in a discriminative manner. The discriminatively trained models perform better during classification tasks as a result of selecting discriminative sets of features. We conclude by proposing a multi-class object recognition system which initially trains object classes in a generative manner, identifies subsets of similar classes with high confusion, and finally trains models for these subsets in a discriminative manner to realize gains in classification performance.",
            "referenceCount": 17,
            "citationCount": 66,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2005-06-20",
            "journal": {
                "name": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Holub2005ADF,\n author = {Alex Holub and P. Perona},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},\n pages = {664-671 vol. 1},\n title = {A discriminative framework for modelling object classes},\n volume = {1},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cbb0362cbfef094dbed0907329e6057dc5d09714",
            "@type": "ScholarlyArticle",
            "paperId": "cbb0362cbfef094dbed0907329e6057dc5d09714",
            "corpusId": 2527241,
            "url": "https://www.semanticscholar.org/paper/cbb0362cbfef094dbed0907329e6057dc5d09714",
            "title": "Does the Wake-sleep Algorithm Produce Good Density Estimators?",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 1995,
            "externalIds": {
                "MAG": "2170858534",
                "DBLP": "conf/nips/FreyHD95",
                "CorpusId": 2527241
            },
            "abstract": "The wake-sleep algorithm (Hinton, Dayan, Frey and Neal 1995) is a relatively efficient method of fitting a multilayer stochastic generative model to high-dimensional data. In addition to the top-down connections in the generative model, it makes use of bottom-up connections for approximating the probability distribution over the hidden units given the data, and it trains these bottom-up connections using a simple delta rule. We use a variety of synthetic and real data sets to compare the performance of the wake-sleep algorithm with Monte Carlo and mean field methods for fitting the same generative model and also compare it with other models that are less powerful but easier to fit.",
            "referenceCount": 7,
            "citationCount": 63,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1995-11-27",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Frey1995DoesTW,\n author = {B. Frey and Geoffrey E. Hinton and P. Dayan},\n booktitle = {Neural Information Processing Systems},\n pages = {661-667},\n title = {Does the Wake-sleep Algorithm Produce Good Density Estimators?},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c68796f833a7151f0a63d1d1608dc902b4fdc9b6",
            "@type": "ScholarlyArticle",
            "paperId": "c68796f833a7151f0a63d1d1608dc902b4fdc9b6",
            "corpusId": 10319744,
            "url": "https://www.semanticscholar.org/paper/c68796f833a7151f0a63d1d1608dc902b4fdc9b6",
            "title": "GENERATIVE ADVERSARIAL NETS",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "CorpusId": 10319744
            },
            "abstract": "Estimating individualized treatment effects (ITE) is a challenging task due to the need for an individual\u2019s potential outcomes to be learned from biased data and without having access to the counterfactuals. We propose a novel method for inferring ITE based on the Generative Adversarial Nets (GANs) framework. Our method, termed Generative Adversarial Nets for inference of Individualized Treatment Effects (GANITE), is motivated by the possibility that we can capture the uncertainty in the counterfactual distributions by attempting to learn them using a GAN. We generate proxies of the counterfactual outcomes using a counterfactual generator, G, and then pass these proxies to an ITE generator, I, in order to train it. By modeling both of these using the GAN framework, we are able to infer based on the factual data, while still accounting for the unseen counterfactuals. We test our method on three real-world datasets (with both binary and multiple treatments) and show that GANITE outperforms state-of-the-art methods.",
            "referenceCount": 24,
            "citationCount": 7761,
            "influentialCitationCount": 1221,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Treat2018GENERATIVEAN,\n author = {Individualized Treat and Jinsung Yoon},\n title = {GENERATIVE ADVERSARIAL NETS},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:acd87843a451d18b4dc6474ddce1ae946429eaf1",
            "@type": "ScholarlyArticle",
            "paperId": "acd87843a451d18b4dc6474ddce1ae946429eaf1",
            "corpusId": 2057420,
            "url": "https://www.semanticscholar.org/paper/acd87843a451d18b4dc6474ddce1ae946429eaf1",
            "title": "Wasserstein Generative Adversarial Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2739748921",
                "DBLP": "conf/icml/ArjovskyCB17",
                "CorpusId": 2057420
            },
            "abstract": "We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.",
            "referenceCount": 26,
            "citationCount": 6226,
            "influentialCitationCount": 1149,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-07-17",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Arjovsky2017WassersteinGA,\n author = {Mart\u00edn Arjovsky and Soumith Chintala and L. Bottou},\n booktitle = {International Conference on Machine Learning},\n pages = {214-223},\n title = {Wasserstein Generative Adversarial Networks},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:633e2fbfc0b21e959a244100937c5853afca4853",
            "@type": "ScholarlyArticle",
            "paperId": "633e2fbfc0b21e959a244100937c5853afca4853",
            "corpusId": 227209335,
            "url": "https://www.semanticscholar.org/paper/633e2fbfc0b21e959a244100937c5853afca4853",
            "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2011-13456",
                "ArXiv": "2011.13456",
                "MAG": "3110257065",
                "CorpusId": 227209335
            },
            "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reverse-time SDE depends only on the time-dependent gradient field (\\aka, score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model.",
            "referenceCount": 66,
            "citationCount": 2144,
            "influentialCitationCount": 556,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-11-26",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2011.13456"
            },
            "citationStyles": {
                "bibtex": "@Article{Song2020ScoreBasedGM,\n author = {Yang Song and Jascha Narain Sohl-Dickstein and Diederik P. Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Score-Based Generative Modeling through Stochastic Differential Equations},\n volume = {abs/2011.13456},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:df0402517a7338ae28bc54acaac400de6b456a46",
            "@type": "ScholarlyArticle",
            "paperId": "df0402517a7338ae28bc54acaac400de6b456a46",
            "corpusId": 6254678,
            "url": "https://www.semanticscholar.org/paper/df0402517a7338ae28bc54acaac400de6b456a46",
            "title": "WaveNet: A Generative Model for Raw Audio",
            "venue": "Speech Synthesis Workshop",
            "publicationVenue": {
                "id": "urn:research:3eb7999c-8390-439e-b358-8b9ce5edd9e3",
                "name": "Speech Synthesis Workshop",
                "alternate_names": [
                    "SSW",
                    "Speech Synth Workshop"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2519091744",
                "DBLP": "conf/ssw/OordDZSVGKSK16",
                "ArXiv": "1609.03499",
                "CorpusId": 6254678
            },
            "abstract": "This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.",
            "referenceCount": 65,
            "citationCount": 6181,
            "influentialCitationCount": 920,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-12",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1609.03499"
            },
            "citationStyles": {
                "bibtex": "@Article{Oord2016WaveNetAG,\n author = {A\u00e4ron van den Oord and S. Dieleman and H. Zen and K. Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and A. Senior and K. Kavukcuoglu},\n booktitle = {Speech Synthesis Workshop},\n journal = {ArXiv},\n title = {WaveNet: A Generative Model for Raw Audio},\n volume = {abs/1609.03499},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2cfc26b4af99f195b433fa7aa00f221b111c7cd4",
            "@type": "ScholarlyArticle",
            "paperId": "2cfc26b4af99f195b433fa7aa00f221b111c7cd4",
            "corpusId": 254222077,
            "url": "https://www.semanticscholar.org/paper/2cfc26b4af99f195b433fa7aa00f221b111c7cd4",
            "title": "Illuminating protein space with a programmable generative model",
            "venue": "bioRxiv",
            "publicationVenue": {
                "id": "urn:research:027ffd21-ebb0-4af8-baf5-911124292fd0",
                "name": "bioRxiv",
                "alternate_names": null,
                "issn": null,
                "url": "http://biorxiv.org/"
            },
            "year": 2022,
            "externalIds": {
                "PubMedCentral": "10686827",
                "DOI": "10.1038/s41586-023-06728-8",
                "CorpusId": 254222077,
                "PubMed": "37968394"
            },
            "abstract": null,
            "referenceCount": 126,
            "citationCount": 73,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41586-023-06728-8.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2022-12-02",
            "journal": {
                "name": "Nature",
                "volume": "623"
            },
            "citationStyles": {
                "bibtex": "@Article{Ingraham2022IlluminatingPS,\n author = {John Ingraham and Max Baranov and Zak Costello and Vincent Frappier and Ahmed Ismail and Shan Tie and Wujie Wang and Vincent Xue and F. Obermeyer and Andrew Beam and G. Grigoryan},\n booktitle = {bioRxiv},\n journal = {Nature},\n pages = {1070 - 1078},\n title = {Illuminating protein space with a programmable generative model},\n volume = {623},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7c39adb2049e79951dd6b92c970abaa4d81819b1",
            "@type": "ScholarlyArticle",
            "paperId": "7c39adb2049e79951dd6b92c970abaa4d81819b1",
            "corpusId": 231749922,
            "url": "https://www.semanticscholar.org/paper/7c39adb2049e79951dd6b92c970abaa4d81819b1",
            "title": "On Generative Spoken Language Modeling from Raw Audio",
            "venue": "Transactions of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:e0dbf116-86aa-418d-859f-a49952d7e44a",
                "name": "Transactions of the Association for Computational Linguistics",
                "alternate_names": [
                    "Trans Assoc Comput Linguistics",
                    "TACL"
                ],
                "issn": "2307-387X",
                "url": "https://www.mitpressjournals.org/loi/tacl"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2102.01192",
                "DBLP": "journals/corr/abs-2102-01192",
                "DOI": "10.1162/tacl_a_00430",
                "CorpusId": 231749922
            },
            "abstract": "Abstract We introduce Generative Spoken Language Modeling, the task of learning the acoustic and linguistic characteristics of a language from raw audio (no text, no labels), and a set of metrics to automatically evaluate the learned representations at acoustic and linguistic levels for both encoding and generation. We set up baseline systems consisting of a discrete speech encoder (returning pseudo-text units), a generative language model (trained on pseudo- text), and a speech decoder (generating a waveform from pseudo-text) all trained without supervision and validate the proposed metrics with human evaluation. Across 3 speech encoders (CPC, wav2vec 2.0, HuBERT), we find that the number of discrete units (50, 100, or 200) matters in a task-dependent and encoder- dependent way, and that some combinations approach text-based systems.1",
            "referenceCount": 79,
            "citationCount": 186,
            "influentialCitationCount": 33,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://inria.hal.science/hal-03329219/document",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-02-01",
            "journal": {
                "name": "Transactions of the Association for Computational Linguistics",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Lakhotia2021OnGS,\n author = {Kushal Lakhotia and Evgeny Kharitonov and Wei-Ning Hsu and Yossi Adi and A. Polyak and Benjamin Bolte and Tu Nguyen and Jade Copet and Alexei Baevski and A. Mohamed and Emmanuel Dupoux},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {1336-1354},\n title = {On Generative Spoken Language Modeling from Raw Audio},\n volume = {9},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2103a87d7902ed63629f7f3589610fb818ed6b61",
            "@type": "ScholarlyArticle",
            "paperId": "2103a87d7902ed63629f7f3589610fb818ed6b61",
            "corpusId": 235294278,
            "url": "https://www.semanticscholar.org/paper/2103a87d7902ed63629f7f3589610fb818ed6b61",
            "title": "Diffusion Schr\u00f6dinger Bridge with Applications to Score-Based Generative Modeling",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2106.01357",
                "DBLP": "conf/nips/BortoliTHD21",
                "CorpusId": 235294278
            },
            "abstract": "Progressively applying Gaussian noise transforms complex data distributions to approximately Gaussian. Reversing this dynamic defines a generative model. When the forward noising process is given by a Stochastic Differential Equation (SDE), Song et al. (2021) demonstrate how the time inhomogeneous drift of the associated reverse-time SDE may be estimated using score-matching. A limitation of this approach is that the forward-time SDE must be run for a sufficiently long time for the final distribution to be approximately Gaussian. In contrast, solving the Schr\\\"odinger Bridge problem (SB), i.e. an entropy-regularized optimal transport problem on path spaces, yields diffusions which generate samples from the data distribution in finite time. We present Diffusion SB (DSB), an original approximation of the Iterative Proportional Fitting (IPF) procedure to solve the SB problem, and provide theoretical analysis along with generative modeling experiments. The first DSB iteration recovers the methodology proposed by Song et al. (2021), with the flexibility of using shorter time intervals, as subsequent DSB iterations reduce the discrepancy between the final-time marginal of the forward (resp. backward) SDE with respect to the prior (resp. data) distribution. Beyond generative modeling, DSB offers a widely applicable computational optimal transport tool as the continuous state-space analogue of the popular Sinkhorn algorithm (Cuturi, 2013).",
            "referenceCount": 94,
            "citationCount": 185,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-06-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bortoli2021DiffusionSB,\n author = {Valentin De Bortoli and James Thornton and J. Heng and A. Doucet},\n booktitle = {Neural Information Processing Systems},\n pages = {17695-17709},\n title = {Diffusion Schr\u00f6dinger Bridge with Applications to Score-Based Generative Modeling},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a8f3dc53e321fbb2565f5925def4365b9f68d1af",
            "@type": "ScholarlyArticle",
            "paperId": "a8f3dc53e321fbb2565f5925def4365b9f68d1af",
            "corpusId": 46898260,
            "url": "https://www.semanticscholar.org/paper/a8f3dc53e321fbb2565f5925def4365b9f68d1af",
            "title": "Self-Attention Generative Adversarial Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1805.08318",
                "MAG": "2950893734",
                "DBLP": "journals/corr/abs-1805-08318",
                "CorpusId": 46898260
            },
            "abstract": "In this paper, we propose the Self-Attention Generative Adversarial Network (SAGAN) which allows attention-driven, long-range dependency modeling for image generation tasks. Traditional convolutional GANs generate high-resolution details as a function of only spatially local points in lower-resolution feature maps. In SAGAN, details can be generated using cues from all feature locations. Moreover, the discriminator can check that highly detailed features in distant portions of the image are consistent with each other. Furthermore, recent work has shown that generator conditioning affects GAN performance. Leveraging this insight, we apply spectral normalization to the GAN generator and find that this improves training dynamics. The proposed SAGAN achieves the state-of-the-art results, boosting the best published Inception score from 36.8 to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the challenging ImageNet dataset. Visualization of the attention layers shows that the generator leverages neighborhoods that correspond to object shapes rather than local regions of fixed shape.",
            "referenceCount": 54,
            "citationCount": 3035,
            "influentialCitationCount": 293,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-05-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1805.08318"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018SelfAttentionGA,\n author = {Han Zhang and I. Goodfellow and Dimitris N. Metaxas and Augustus Odena},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Self-Attention Generative Adversarial Networks},\n volume = {abs/1805.08318},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:62d337dbaead376ca042f23d62c0d4b65ec98546",
            "@type": "ScholarlyArticle",
            "paperId": "62d337dbaead376ca042f23d62c0d4b65ec98546",
            "corpusId": 220364071,
            "url": "https://www.semanticscholar.org/paper/62d337dbaead376ca042f23d62c0d4b65ec98546",
            "title": "GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2007-02442",
                "ArXiv": "2007.02442",
                "MAG": "3101267796",
                "CorpusId": 220364071
            },
            "abstract": "While 2D generative adversarial networks have enabled high-resolution image synthesis, they largely lack an understanding of the 3D world and the image formation process. Thus, they do not provide precise control over camera viewpoint or object pose. To address this problem, several recent approaches leverage intermediate voxel-based representations in combination with differentiable rendering. However, existing methods either produce low image resolution or fall short in disentangling camera and scene properties, e.g., the object identity may vary with the viewpoint. In this paper, we propose a generative model for radiance fields which have recently proven successful for novel view synthesis of a single scene. In contrast to voxel-based representations, radiance fields are not confined to a coarse discretization of the 3D space, yet allow for disentangling camera and scene properties while degrading gracefully in the presence of reconstruction ambiguity. By introducing a multi-scale patch-based discriminator, we demonstrate synthesis of high-resolution images while training our model from unposed 2D images alone. We systematically analyze our approach on several challenging synthetic and real-world datasets. Our experiments reveal that radiance fields are a powerful representation for generative image synthesis, leading to 3D consistent models that render with high fidelity.",
            "referenceCount": 78,
            "citationCount": 607,
            "influentialCitationCount": 64,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-07-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2007.02442"
            },
            "citationStyles": {
                "bibtex": "@Article{Schwarz2020GRAFGR,\n author = {Katja Schwarz and Yiyi Liao and Michael Niemeyer and Andreas Geiger},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis},\n volume = {abs/2007.02442},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:04faf433934486c41d082e8d75ccfe5dc2f69fef",
            "@type": "ScholarlyArticle",
            "paperId": "04faf433934486c41d082e8d75ccfe5dc2f69fef",
            "corpusId": 220250007,
            "url": "https://www.semanticscholar.org/paper/04faf433934486c41d082e8d75ccfe5dc2f69fef",
            "title": "GPT-GNN: Generative Pre-Training of Graph Neural Networks",
            "venue": "Knowledge Discovery and Data Mining",
            "publicationVenue": {
                "id": "urn:research:a0edb93b-1e95-4128-a295-6b1659149cef",
                "name": "Knowledge Discovery and Data Mining",
                "alternate_names": [
                    "KDD",
                    "Knowl Discov Data Min"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigkdd/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2006-15437",
                "ArXiv": "2006.15437",
                "MAG": "3080997787",
                "DOI": "10.1145/3394486.3403237",
                "CorpusId": 220250007
            },
            "abstract": "Graph neural networks (GNNs) have been demonstrated to be powerful in modeling graph-structured data. However, training GNNs requires abundant task-specific labeled data, which is often arduously expensive to obtain. One effective way to reduce the labeling effort is to pre-train an expressive GNN model on unlabelled data with self-supervision and then transfer the learned model to downstream tasks with only a few labels. In this paper, we present the GPT-GNN framework to initialize GNNs by generative pre-training. GPT-GNN introduces a self-supervised attributed graph generation task to pre-train a GNN so that it can capture the structural and semantic properties of the graph. We factorize the likelihood of graph generation into two components: 1) attribute generation and 2) edge generation. By modeling both components, GPT-GNN captures the inherent dependency between node attributes and graph structure during the generative process. Comprehensive experiments on the billion-scale open academic graph and Amazon recommendation data demonstrate that GPT-GNN significantly outperforms state-of-the-art GNN models without pre-training by up to 9.1% across various downstream tasks?",
            "referenceCount": 45,
            "citationCount": 330,
            "influentialCitationCount": 50,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3394486.3403237",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2020-06-27",
            "journal": {
                "name": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hu2020GPTGNNGP,\n author = {Ziniu Hu and Yuxiao Dong and Kuansan Wang and Kai-Wei Chang and Yizhou Sun},\n booktitle = {Knowledge Discovery and Data Mining},\n journal = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining},\n title = {GPT-GNN: Generative Pre-Training of Graph Neural Networks},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4f5a194ee365b074dcb0434e9c2eb976f6f32298",
            "@type": "ScholarlyArticle",
            "paperId": "4f5a194ee365b074dcb0434e9c2eb976f6f32298",
            "corpusId": 232092571,
            "url": "https://www.semanticscholar.org/paper/4f5a194ee365b074dcb0434e9c2eb976f6f32298",
            "title": "Generative Adversarial Transformers",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2103-01209",
                "ArXiv": "2103.01209",
                "CorpusId": 232092571
            },
            "abstract": "We introduce the GANformer, a novel and efficient type of transformer, and explore it for the task of visual generative modeling. The network employs a bipartite structure that enables long-range interactions across the image, while maintaining computation of linear efficiency, that can readily scale to high-resolution synthesis. It iteratively propagates information from a set of latent variables to the evolving visual features and vice versa, to support the refinement of each in light of the other and encourage the emergence of compositional representations of objects and scenes. In contrast to the classic transformer architecture, it utilizes multiplicative integration that allows flexible region-based modulation, and can thus be seen as a generalization of the successful StyleGAN network. We demonstrate the model's strength and robustness through a careful evaluation over a range of datasets, from simulated multi-object environments to rich real-world indoor and outdoor scenes, showing it achieves state-of-the-art results in terms of image quality and diversity, while enjoying fast learning and better data-efficiency. Further qualitative and quantitative experiments offer us an insight into the model's inner workings, revealing improved interpretability and stronger disentanglement, and illustrating the benefits and efficacy of our approach. An implementation of the model is available at https://github.com/dorarad/gansformer.",
            "referenceCount": 80,
            "citationCount": 130,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-03-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2103.01209"
            },
            "citationStyles": {
                "bibtex": "@Article{Hudson2021GenerativeAT,\n author = {Drew A. Hudson and C. L. Zitnick},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Generative Adversarial Transformers},\n volume = {abs/2103.01209},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6c7f040a150abf21dbcefe1f22e0f98fa184f41a",
            "@type": "ScholarlyArticle",
            "paperId": "6c7f040a150abf21dbcefe1f22e0f98fa184f41a",
            "corpusId": 1563370,
            "url": "https://www.semanticscholar.org/paper/6c7f040a150abf21dbcefe1f22e0f98fa184f41a",
            "title": "Generative Adversarial Text to Image Synthesis",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/ReedAYLSL16",
                "ArXiv": "1605.05396",
                "MAG": "2949999304",
                "CorpusId": 1563370
            },
            "abstract": "Automatic synthesis of realistic images from text would be interesting and useful, but current AI systems are still far from this goal. However, in recent years generic and powerful recurrent neural network architectures have been developed to learn discriminative text feature representations. Meanwhile, deep convolutional generative adversarial networks (GANs) have begun to generate highly compelling images of specific categories, such as faces, album covers, and room interiors. In this work, we develop a novel deep architecture and GAN formulation to effectively bridge these advances in text and image modeling, translating visual concepts from characters to pixels. We demonstrate the capability of our model to generate plausible images of birds and flowers from detailed text descriptions.",
            "referenceCount": 42,
            "citationCount": 2733,
            "influentialCitationCount": 217,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-05-17",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Reed2016GenerativeAT,\n author = {Scott E. Reed and Zeynep Akata and Xinchen Yan and Lajanugen Logeswaran and B. Schiele and Honglak Lee},\n booktitle = {International Conference on Machine Learning},\n pages = {1060-1069},\n title = {Generative Adversarial Text to Image Synthesis},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:011fbfe79c738b84c1bfcdabcd752977524b1363",
            "@type": "ScholarlyArticle",
            "paperId": "011fbfe79c738b84c1bfcdabcd752977524b1363",
            "corpusId": 231627872,
            "url": "https://www.semanticscholar.org/paper/011fbfe79c738b84c1bfcdabcd752977524b1363",
            "title": "Counterfactual Generative Networks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2101-06046",
                "ArXiv": "2101.06046",
                "CorpusId": 231627872
            },
            "abstract": "Neural networks are prone to learning shortcuts -- they often model simple correlations, ignoring more complex ones that potentially generalize better. Prior works on image classification show that instead of learning a connection to object shape, deep classifiers tend to exploit spurious correlations with low-level texture or the background for solving the classification task. In this work, we take a step towards more robust and interpretable classifiers that explicitly expose the task's causal structure. Building on current advances in deep generative modeling, we propose to decompose the image generation process into independent causal mechanisms that we train without direct supervision. By exploiting appropriate inductive biases, these mechanisms disentangle object shape, object texture, and background; hence, they allow for generating counterfactual images. We demonstrate the ability of our model to generate such images on MNIST and ImageNet. Further, we show that the counterfactual images can improve out-of-distribution robustness with a marginal drop in performance on the original classification task, despite being synthetic. Lastly, our generative model can be trained efficiently on a single GPU, exploiting common pre-trained models as inductive biases.",
            "referenceCount": 53,
            "citationCount": 88,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-01-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2101.06046"
            },
            "citationStyles": {
                "bibtex": "@Article{Sauer2021CounterfactualGN,\n author = {Axel Sauer and Andreas Geiger},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Counterfactual Generative Networks},\n volume = {abs/2101.06046},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5278a8eb2ba2429d4029745caf4e661080073c81",
            "@type": "ScholarlyArticle",
            "paperId": "5278a8eb2ba2429d4029745caf4e661080073c81",
            "corpusId": 258040990,
            "url": "https://www.semanticscholar.org/paper/5278a8eb2ba2429d4029745caf4e661080073c81",
            "title": "Generative Agents: Interactive Simulacra of Human Behavior",
            "venue": "ACM Symposium on User Interface Software and Technology",
            "publicationVenue": {
                "id": "urn:research:c62b1316-0733-4b4c-8017-c07e18afa954",
                "name": "ACM Symposium on User Interface Software and Technology",
                "alternate_names": [
                    "User Interface Software and Technology",
                    "ACM Symp User Interface Softw Technol",
                    "User Interface Softw Technol",
                    "UIST"
                ],
                "issn": null,
                "url": "http://www.acm.org/uist/"
            },
            "year": 2023,
            "externalIds": {
                "DBLP": "journals/corr/abs-2304-03442",
                "ArXiv": "2304.03442",
                "DOI": "10.1145/3586183.3606763",
                "CorpusId": 258040990
            },
            "abstract": "Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent\u2019s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine\u2019s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture\u2014observation, planning, and reflection\u2014each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.",
            "referenceCount": 112,
            "citationCount": 308,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2304.03442",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2023-04-07",
            "journal": {
                "name": "Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Park2023GenerativeAI,\n author = {J. Park and Joseph C. O'Brien and Carrie J. Cai and M. Morris and Percy Liang and Michael S. Bernstein},\n booktitle = {ACM Symposium on User Interface Software and Technology},\n journal = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},\n title = {Generative Agents: Interactive Simulacra of Human Behavior},\n year = {2023}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9afa46cbb91408280b741cd4fd95021c21cdf7d4",
            "@type": "ScholarlyArticle",
            "paperId": "9afa46cbb91408280b741cd4fd95021c21cdf7d4",
            "corpusId": 235210365,
            "url": "https://www.semanticscholar.org/paper/9afa46cbb91408280b741cd4fd95021c21cdf7d4",
            "title": "Generative Adversarial Networks",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2106.03785",
                "DBLP": "journals/corr/abs-2106-03785",
                "DOI": "10.1145/3459992",
                "CorpusId": 235210365
            },
            "abstract": "Generative Adversarial Networks (GANs) have promoted a variety of applications in computer vision and natural language processing, among others, due to its generative model\u2019s compelling ability to generate realistic examples plausibly drawn from an existing distribution of samples. GAN not only provides impressive performance on data generation-based tasks but also stimulates fertilization for privacy and security oriented research because of its game theoretic optimization strategy. Unfortunately, there are no comprehensive surveys on GAN in privacy and security, which motivates this survey to summarize systematically. The existing works are classified into proper categories based on privacy and security functions, and this survey conducts a comprehensive analysis of their advantages and drawbacks. Considering that GAN in privacy and security is still at a very initial stage and has imposed unique challenges that are yet to be well addressed, this article also sheds light on some potential privacy and security applications with GAN and elaborates on some future research directions.",
            "referenceCount": 161,
            "citationCount": 111,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-06-07",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "54"
            },
            "citationStyles": {
                "bibtex": "@Article{Cai2021GenerativeAN,\n author = {Zhipeng Cai and Zuobin Xiong and Honghui Xu and Peng Wang and Wei Li and Yi-Lun Pan},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 38},\n title = {Generative Adversarial Networks},\n volume = {54},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:67dea28495cab71703993d0d52ca4733b9a66077",
            "@type": "ScholarlyArticle",
            "paperId": "67dea28495cab71703993d0d52ca4733b9a66077",
            "corpusId": 218470180,
            "url": "https://www.semanticscholar.org/paper/67dea28495cab71703993d0d52ca4733b9a66077",
            "title": "Jukebox: A Generative Model for Music",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2005-00341",
                "ArXiv": "2005.00341",
                "MAG": "3021164770",
                "CorpusId": 218470180
            },
            "abstract": "We introduce Jukebox, a model that generates music with singing in the raw audio domain. We tackle the long context of raw audio using a multi-scale VQ-VAE to compress it to discrete codes, and modeling those using autoregressive Transformers. We show that the combined model at scale can generate high-fidelity and diverse songs with coherence up to multiple minutes. We can condition on artist and genre to steer the musical and vocal style, and on unaligned lyrics to make the singing more controllable. We are releasing thousands of non cherry-picked samples at this https URL, along with model weights and code at this https URL",
            "referenceCount": 86,
            "citationCount": 437,
            "influentialCitationCount": 68,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-04-30",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2005.00341"
            },
            "citationStyles": {
                "bibtex": "@Article{Dhariwal2020JukeboxAG,\n author = {Prafulla Dhariwal and Heewoo Jun and Christine Payne and Jong Wook Kim and Alec Radford and Ilya Sutskever},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Jukebox: A Generative Model for Music},\n volume = {abs/2005.00341},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:388e2fcdcefbe0834e153ab2a0be127092f9674d",
            "@type": "ScholarlyArticle",
            "paperId": "388e2fcdcefbe0834e153ab2a0be127092f9674d",
            "corpusId": 207869708,
            "url": "https://www.semanticscholar.org/paper/388e2fcdcefbe0834e153ab2a0be127092f9674d",
            "title": "DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1911.00536",
                "ACL": "2020.acl-demos.30",
                "DBLP": "journals/corr/abs-1911-00536",
                "MAG": "2988937804",
                "DOI": "10.18653/V1/2020.ACL-DEMOS.30",
                "CorpusId": 207869708
            },
            "abstract": "We present a large, tunable neural conversational response generation model, DIALOGPT (dialogue generative pre-trained transformer). Trained on 147M conversation-like exchanges extracted from Reddit comment chains over a period spanning from 2005 through 2017, DialoGPT extends the Hugging Face PyTorch transformer to attain a performance close to human both in terms of automatic and human evaluation in single-turn dialogue settings. We show that conversational systems that leverage DialoGPT generate more relevant, contentful and context-consistent responses than strong baseline systems. The pre-trained model and training pipeline are publicly released to facilitate research into neural response generation and the development of more intelligent open-domain dialogue systems.",
            "referenceCount": 32,
            "citationCount": 1130,
            "influentialCitationCount": 284,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/2020.acl-demos.30.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-11-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1911.00536"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2019DIALOGPTL,\n author = {Yizhe Zhang and Siqi Sun and Michel Galley and Yen-Chun Chen and Chris Brockett and Xiang Gao and Jianfeng Gao and Jingjing Liu and W. Dolan},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation},\n volume = {abs/1911.00536},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6b0bbf3e7df725cc3b781d2648e41782cb3d8539",
            "@type": "ScholarlyArticle",
            "paperId": "6b0bbf3e7df725cc3b781d2648e41782cb3d8539",
            "corpusId": 4072789,
            "url": "https://www.semanticscholar.org/paper/6b0bbf3e7df725cc3b781d2648e41782cb3d8539",
            "title": "Generative Image Inpainting with Contextual Attention",
            "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2950547757",
                "ArXiv": "1801.07892",
                "DBLP": "conf/cvpr/Yu0YSLH18",
                "DOI": "10.1109/CVPR.2018.00577",
                "CorpusId": 4072789
            },
            "abstract": "Recent deep learning based approaches have shown promising results for the challenging task of inpainting large missing regions in an image. These methods can generate visually plausible image structures and textures, but often create distorted structures or blurry textures inconsistent with surrounding areas. This is mainly due to ineffectiveness of convolutional neural networks in explicitly borrowing or copying information from distant spatial locations. On the other hand, traditional texture and patch synthesis approaches are particularly suitable when it needs to borrow textures from the surrounding regions. Motivated by these observations, we propose a new deep generative model-based approach which can not only synthesize novel image structures but also explicitly utilize surrounding image features as references during network training to make better predictions. The model is a feedforward, fully convolutional neural network which can process images with multiple holes at arbitrary locations and with variable sizes during the test time. Experiments on multiple datasets including faces (CelebA, CelebA-HQ), textures (DTD) and natural images (ImageNet, Places2) demonstrate that our proposed approach generates higher-quality inpainting results than existing ones. Code, demo and models are available at: https://github.com/JiahuiYu/generative_inpainting.",
            "referenceCount": 48,
            "citationCount": 1881,
            "influentialCitationCount": 325,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1801.07892",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-01-24",
            "journal": {
                "name": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yu2018GenerativeII,\n author = {Jiahui Yu and Zhe L. Lin and Jimei Yang and Xiaohui Shen and Xin Lu and Thomas S. Huang},\n booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n pages = {5505-5514},\n title = {Generative Image Inpainting with Contextual Attention},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4ab53de69372ec2cd2d90c126b6a100165dc8ed1",
            "@type": "ScholarlyArticle",
            "paperId": "4ab53de69372ec2cd2d90c126b6a100165dc8ed1",
            "corpusId": 16153365,
            "url": "https://www.semanticscholar.org/paper/4ab53de69372ec2cd2d90c126b6a100165dc8ed1",
            "title": "Generative Adversarial Imitation Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/HoE16",
                "MAG": "2949080919",
                "ArXiv": "1606.03476",
                "CorpusId": 16153365
            },
            "abstract": "Consider learning a policy from example expert behavior, without interaction with the expert or access to reinforcement signal. One approach is to recover the expert's cost function with inverse reinforcement learning, then extract a policy from that cost function with reinforcement learning. This approach is indirect and can be slow. We propose a new general framework for directly extracting a policy from data, as if it were obtained by reinforcement learning following inverse reinforcement learning. We show that a certain instantiation of our framework draws an analogy between imitation learning and generative adversarial networks, from which we derive a model-free imitation learning algorithm that obtains significant performance gains over existing model-free methods in imitating complex behaviors in large, high-dimensional environments.",
            "referenceCount": 32,
            "citationCount": 2327,
            "influentialCitationCount": 499,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-10",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ho2016GenerativeAI,\n author = {Jonathan Ho and Stefano Ermon},\n booktitle = {Neural Information Processing Systems},\n pages = {4565-4573},\n title = {Generative Adversarial Imitation Learning},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:49c076bbc21ab76720b610ab3840c15ce3dc4e6c",
            "@type": "ScholarlyArticle",
            "paperId": "49c076bbc21ab76720b610ab3840c15ce3dc4e6c",
            "corpusId": 4461350,
            "url": "https://www.semanticscholar.org/paper/49c076bbc21ab76720b610ab3840c15ce3dc4e6c",
            "title": "Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks",
            "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2951873879",
                "ArXiv": "1803.10892",
                "DBLP": "conf/cvpr/GuptaJFSA18",
                "DOI": "10.1109/CVPR.2018.00240",
                "CorpusId": 4461350
            },
            "abstract": "Understanding human motion behavior is critical for autonomous moving platforms (like self-driving cars and social robots) if they are to navigate human-centric environments. This is challenging because human motion is inherently multimodal: given a history of human motion paths, there are many socially plausible ways that people could move in the future. We tackle this problem by combining tools from sequence prediction and generative adversarial networks: a recurrent sequence-to-sequence model observes motion histories and predicts future behavior, using a novel pooling mechanism to aggregate information across people. We predict socially plausible futures by training adversarially against a recurrent discriminator, and encourage diverse predictions with a novel variety loss. Through experiments on several datasets we demonstrate that our approach outperforms prior work in terms of accuracy, variety, collision avoidance, and computational complexity.",
            "referenceCount": 50,
            "citationCount": 1404,
            "influentialCitationCount": 405,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1803.10892",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-03-29",
            "journal": {
                "name": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gupta2018SocialGS,\n author = {Agrim Gupta and Justin Johnson and Li Fei-Fei and S. Savarese and Alexandre Alahi},\n booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n pages = {2255-2264},\n title = {Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5947715535cbe84ee62bd00c1d3fe9929d3f84c7",
            "@type": "ScholarlyArticle",
            "paperId": "5947715535cbe84ee62bd00c1d3fe9929d3f84c7",
            "corpusId": 204915831,
            "url": "https://www.semanticscholar.org/paper/5947715535cbe84ee62bd00c1d3fe9929d3f84c7",
            "title": "Parallel Wavegan: A Fast Waveform Generation Model Based on Generative Adversarial Networks with Multi-Resolution Spectrogram",
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "publicationVenue": {
                "id": "urn:research:0d6f7fba-7092-46b3-8039-93458dba736b",
                "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                "alternate_names": [
                    "Int Conf Acoust Speech Signal Process",
                    "IEEE Int Conf Acoust Speech Signal Process",
                    "ICASSP",
                    "International Conference on Acoustics, Speech, and Signal Processing"
                ],
                "issn": null,
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1910-11480",
                "MAG": "3015338123",
                "ArXiv": "1910.11480",
                "DOI": "10.1109/ICASSP40776.2020.9053795",
                "CorpusId": 204915831
            },
            "abstract": "We propose Parallel WaveGAN, a distillation-free, fast, and small-footprint waveform generation method using a generative adversarial network. In the proposed method, a non-autoregressive WaveNet is trained by jointly optimizing multi-resolution spectrogram and adversarial loss functions, which can effectively capture the time-frequency distribution of the realistic speech waveform. As our method does not require density distillation used in the conventional teacher-student framework, the entire model can be easily trained. Furthermore, our model is able to generate high-fidelity speech even with its compact architecture. In particular, the proposed Parallel WaveGAN has only 1.44 M parameters and can generate 24 kHz speech waveform 28.68 times faster than real-time on a single GPU environment. Perceptual listening test results verify that our proposed method achieves 4.16 mean opinion score within a Transformer-based text-to-speech framework, which is comparative to the best distillation-based Parallel WaveNet system.",
            "referenceCount": 31,
            "citationCount": 596,
            "influentialCitationCount": 130,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1910.11480",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-10-25",
            "journal": {
                "name": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yamamoto2019ParallelWA,\n author = {Ryuichi Yamamoto and Eunwoo Song and Jae-Min Kim},\n booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},\n journal = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n pages = {6199-6203},\n title = {Parallel Wavegan: A Fast Waveform Generation Model Based on Generative Adversarial Networks with Multi-Resolution Spectrogram},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ccaf15d4ad006171061508ca0a99c73814671501",
            "@type": "ScholarlyArticle",
            "paperId": "ccaf15d4ad006171061508ca0a99c73814671501",
            "corpusId": 145052179,
            "url": "https://www.semanticscholar.org/paper/ccaf15d4ad006171061508ca0a99c73814671501",
            "title": "SinGAN: Learning a Generative Model From a Single Natural Image",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2942890911",
                "DBLP": "conf/iccv/ShahamDM19",
                "ArXiv": "1905.01164",
                "DOI": "10.1109/ICCV.2019.00467",
                "CorpusId": 145052179
            },
            "abstract": "We introduce SinGAN, an unconditional generative model that can be learned from a single natural image. Our model is trained to capture the internal distribution of patches within the image, and is then able to generate high quality, diverse samples that carry the same visual content as the image. SinGAN contains a pyramid of fully convolutional GANs, each responsible for learning the patch distribution at a different scale of the image. This allows generating new samples of arbitrary size and aspect ratio, that have significant variability, yet maintain both the global structure and the fine textures of the training image. In contrast to previous single image GAN schemes, our approach is not limited to texture images, and is not conditional (i.e. it generates samples from noise). User studies confirm that the generated samples are commonly confused to be real images. We illustrate the utility of SinGAN in a wide range of image manipulation tasks.",
            "referenceCount": 70,
            "citationCount": 661,
            "influentialCitationCount": 115,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1905.01164",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-05-02",
            "journal": {
                "name": "2019 IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shaham2019SinGANLA,\n author = {Tamar Rott Shaham and Tali Dekel and T. Michaeli},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},\n pages = {4569-4579},\n title = {SinGAN: Learning a Generative Model From a Single Natural Image},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ab995f96722969a0dfc6dc9139eef4c9b13c0524",
            "@type": "ScholarlyArticle",
            "paperId": "ab995f96722969a0dfc6dc9139eef4c9b13c0524",
            "corpusId": 91183909,
            "url": "https://www.semanticscholar.org/paper/ab995f96722969a0dfc6dc9139eef4c9b13c0524",
            "title": "DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-To-Image Synthesis",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1904-01310",
                "MAG": "2931831966",
                "ArXiv": "1904.01310",
                "DOI": "10.1109/CVPR.2019.00595",
                "CorpusId": 91183909
            },
            "abstract": "In this paper, we focus on generating realistic images from text descriptions. Current methods first generate an initial image with rough shape and color, and then refine the initial image to a high-resolution one. Most existing text-to-image synthesis methods have two main problems. (1) These methods depend heavily on the quality of the initial images. If the initial image is not well initialized, the following processes can hardly refine the image to a satisfactory quality. (2) Each word contributes a different level of importance when depicting different image contents, however, unchanged text representation is used in existing image refinement processes. In this paper, we propose the Dynamic Memory Generative Adversarial Network (DM-GAN) to generate high-quality images. The proposed method introduces a dynamic memory module to refine fuzzy image contents, when the initial images are not well generated. A memory writing gate is designed to select the important text information based on the initial image content, which enables our method to accurately generate images from the text description. We also utilize a response gate to adaptively fuse the information read from the memories and the image features. We evaluate the DM-GAN model on the Caltech-UCSD Birds 200 dataset and the Microsoft Common Objects in Context dataset. Experimental results demonstrate that our DM-GAN model performs favorably against the state-of-the-art approaches.",
            "referenceCount": 34,
            "citationCount": 425,
            "influentialCitationCount": 90,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://opus.lib.uts.edu.au/bitstream/10453/148141/3/DMGAN%20Dynamic%20Memory.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-02",
            "journal": {
                "name": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhu2019DMGANDM,\n author = {Minfeng Zhu and Pingbo Pan and Wei Chen and Yi Yang},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {5795-5803},\n title = {DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-To-Image Synthesis},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8b35c00edfa4edfd7a99d816e671023d2c000d55",
            "@type": "ScholarlyArticle",
            "paperId": "8b35c00edfa4edfd7a99d816e671023d2c000d55",
            "corpusId": 8858625,
            "url": "https://www.semanticscholar.org/paper/8b35c00edfa4edfd7a99d816e671023d2c000d55",
            "title": "AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks",
            "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/cvpr/XuZHZGH018",
                "MAG": "2771088323",
                "ArXiv": "1711.10485",
                "DOI": "10.1109/CVPR.2018.00143",
                "CorpusId": 8858625
            },
            "abstract": "In this paper, we propose an Attentional Generative Adversarial Network (AttnGAN) that allows attention-driven, multi-stage refinement for fine-grained text-to-image generation. With a novel attentional generative network, the AttnGAN can synthesize fine-grained details at different sub-regions of the image by paying attentions to the relevant words in the natural language description. In addition, a deep attentional multimodal similarity model is proposed to compute a fine-grained image-text matching loss for training the generator. The proposed AttnGAN significantly outperforms the previous state of the art, boosting the best reported inception score by 14.14% on the CUB dataset and 170.25% on the more challenging COCO dataset. A detailed analysis is also performed by visualizing the attention layers of the AttnGAN. It for the first time shows that the layered attentional GAN is able to automatically select the condition at the word level for generating different parts of the image.",
            "referenceCount": 41,
            "citationCount": 1296,
            "influentialCitationCount": 273,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1711.10485",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-11-28",
            "journal": {
                "name": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Xu2017AttnGANFT,\n author = {Tao Xu and Pengchuan Zhang and Qiuyuan Huang and Han Zhang and Zhe Gan and Xiaolei Huang and Xiaodong He},\n booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n pages = {1316-1324},\n title = {AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7437fb168cea92e1df8332ac618f7f07b071aca8",
            "@type": "ScholarlyArticle",
            "paperId": "7437fb168cea92e1df8332ac618f7f07b071aca8",
            "corpusId": 219861141,
            "url": "https://www.semanticscholar.org/paper/7437fb168cea92e1df8332ac618f7f07b071aca8",
            "title": "Generative-Discriminative Feature Representations for Open-Set Recognition",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "conf/cvpr/PereraMJMWOP20",
                "MAG": "3035224069",
                "DOI": "10.1109/cvpr42600.2020.01183",
                "CorpusId": 219861141
            },
            "abstract": "We address the problem of open-set recognition, where the goal is to determine if a given sample belongs to one of the classes used for training a model (known classes). The main challenge in open-set recognition is to disentangle open-set samples that produce high class activations from known-set samples. We propose two techniques to force class activations of open-set samples to be low. First, we train a generative model for all known classes and then augment the input with the representation obtained from the generative model to learn a classifier. This network learns to associate high classification probabilities both when image content is from the correct class as well as when the input and the reconstructed image are consistent with each other. Second, we use self-supervision to force the network to learn more informative featues when assigning class scores to improve separation of classes from each other and from open-set samples. We evaluate the performance of the proposed method with recent open-set recognition works across three datasets, where we obtain state-of-the-art results.",
            "referenceCount": 30,
            "citationCount": 131,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-06-01",
            "journal": {
                "name": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Perera2020GenerativeDiscriminativeFR,\n author = {Pramuditha Perera and Vlad I. Morariu and R. Jain and Varun Manjunatha and Curtis Wigington and Vicente Ordonez and Vishal M. Patel},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {11811-11820},\n title = {Generative-Discriminative Feature Representations for Open-Set Recognition},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4f2bf0eb913557459d05574867c712042f3741ee",
            "@type": "ScholarlyArticle",
            "paperId": "4f2bf0eb913557459d05574867c712042f3741ee",
            "corpusId": 86526816,
            "url": "https://www.semanticscholar.org/paper/4f2bf0eb913557459d05574867c712042f3741ee",
            "title": "Probabilistic Representation and Inverse Design of Metamaterials Based on a Deep Generative Model with Semi\u2010Supervised Learning Strategy",
            "venue": "Advances in Materials",
            "publicationVenue": {
                "id": "urn:research:71697426-616f-45b4-b9d8-d647335a32e6",
                "name": "Advances in Materials",
                "alternate_names": [
                    "Adv Mater",
                    "Advanced Materials"
                ],
                "issn": "2327-2503",
                "url": "http://www.sciencepublishinggroup.com/journal/archive.aspx?amp;issueid=-1&journalid=129"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2914973752",
                "ArXiv": "1901.10819",
                "DOI": "10.1002/adma.201901111",
                "CorpusId": 86526816,
                "PubMed": "31259443"
            },
            "abstract": "The research of metamaterials has achieved enormous success in the manipulation of light in a prescribed manner using delicately designed subwavelength structures, so\u2010called meta\u2010atoms. Even though modern numerical methods allow for the accurate calculation of the optical response of complex structures, the inverse design of metamaterials, which aims to retrieve the optimal structure according to given requirements, is still a challenging task owing to the nonintuitive and nonunique relationship between physical structures and optical responses. To better unveil this implicit relationship and thus facilitate metamaterial designs, it is proposed to represent metamaterials and model the inverse design problem in a probabilistically generative manner, enabling to elegantly investigate the complex structure\u2013performance relationship in an interpretable way, and solve the one\u2010to\u2010many mapping issue that is intractable in a deterministic model. Moreover, to alleviate the burden of numerical calculations when collecting data, a semisupervised learning strategy is developed that allows the model to utilize unlabeled data in addition to labeled data in an end\u2010to\u2010end training. On a data\u2010driven basis, the proposed deep generative model can serve as a comprehensive and efficient tool that accelerates the design, characterization, and even new discovery in the research domain of metamaterials, and photonics in general.",
            "referenceCount": 65,
            "citationCount": 302,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/1901.10819",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Materials Science",
                "Physics",
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Materials Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-01-30",
            "journal": {
                "name": "Advanced Materials",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Ma2019ProbabilisticRA,\n author = {Wei Ma and Feng Cheng and Yihao Xu and Qinlong Wen and Yongmin Liu},\n booktitle = {Advances in Materials},\n journal = {Advanced Materials},\n title = {Probabilistic Representation and Inverse Design of Metamaterials Based on a Deep Generative Model with Semi\u2010Supervised Learning Strategy},\n volume = {31},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ed5d6be2eb8fc1d42f9a0e3c50abaf5439bbd8dd",
            "@type": "ScholarlyArticle",
            "paperId": "ed5d6be2eb8fc1d42f9a0e3c50abaf5439bbd8dd",
            "corpusId": 53643161,
            "url": "https://www.semanticscholar.org/paper/ed5d6be2eb8fc1d42f9a0e3c50abaf5439bbd8dd",
            "title": "Deep Generative Modeling for Single-cell Transcriptomics",
            "venue": "Nature Methods",
            "publicationVenue": {
                "id": "urn:research:099483df-e8f2-4bee-805d-8a69f07b6cbf",
                "name": "Nature Methods",
                "alternate_names": [
                    "Nat Method"
                ],
                "issn": "1548-7091",
                "url": "http://www.nature.com/"
            },
            "year": 2018,
            "externalIds": {
                "PubMedCentral": "6289068",
                "MAG": "2901677030",
                "DOI": "10.1038/s41592-018-0229-2",
                "CorpusId": 53643161,
                "PubMed": "30504886"
            },
            "abstract": null,
            "referenceCount": 57,
            "citationCount": 1003,
            "influentialCitationCount": 55,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc6289068?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-10-31",
            "journal": {
                "name": "Nature methods",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Lopez2018DeepGM,\n author = {Romain Lopez and J. Regier and Michael Cole and Michael I. Jordan and N. Yosef},\n booktitle = {Nature Methods},\n journal = {Nature methods},\n pages = {1053 - 1058},\n title = {Deep Generative Modeling for Single-cell Transcriptomics},\n volume = {15},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:238c4e99e35be88f2dfec16860338395277dc1f2",
            "@type": "ScholarlyArticle",
            "paperId": "238c4e99e35be88f2dfec16860338395277dc1f2",
            "corpusId": 218889650,
            "url": "https://www.semanticscholar.org/paper/238c4e99e35be88f2dfec16860338395277dc1f2",
            "title": "Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "conf/nips/0005WCG020a",
                "MAG": "3102674085",
                "ArXiv": "2005.12900",
                "DOI": "10.1287/opre.2023.2451",
                "CorpusId": 218889650
            },
            "abstract": "This paper studies a central issue in modern reinforcement learning, the sample efficiency, and makes progress toward solving an idealistic scenario that assumes access to a generative model or a simulator. Despite a large number of prior works tackling this problem, a complete picture of the trade-offs between sample complexity and statistical accuracy has yet to be determined. In particular, all prior results suffer from a severe sample size barrier in the sense that their claimed statistical guarantees hold only when the sample size exceeds some enormous threshold. The current paper overcomes this barrier and fully settles this problem; more specifically, we establish the minimax optimality of the model-based approach for any given target accuracy level. To the best of our knowledge, this work delivers the first minimax-optimal guarantees that accommodate the entire range of sample sizes (beyond which finding a meaningful policy is information theoretically infeasible).",
            "referenceCount": 75,
            "citationCount": 101,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2005.12900",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-05-26",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2005.12900"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2020BreakingTS,\n author = {Gen Li and Yuting Wei and Yuejie Chi and Yuantao Gu and Yuxin Chen},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model},\n volume = {abs/2005.12900},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e157b90ab9c50907f76aa22558ee1c04749728a3",
            "@type": "ScholarlyArticle",
            "paperId": "e157b90ab9c50907f76aa22558ee1c04749728a3",
            "corpusId": 218582078,
            "url": "https://www.semanticscholar.org/paper/e157b90ab9c50907f76aa22558ee1c04749728a3",
            "title": "Generative Adversarial Networks and Its Applications in Biomedical Informatics",
            "venue": "Frontiers in Public Health",
            "publicationVenue": {
                "id": "urn:research:d3dd5449-daa1-4d57-9412-9add6037584f",
                "name": "Frontiers in Public Health",
                "alternate_names": [
                    "Front Public Health"
                ],
                "issn": "2296-2565",
                "url": "https://www.frontiersin.org/journals/public-health"
            },
            "year": 2020,
            "externalIds": {
                "PubMedCentral": "7235323",
                "MAG": "3024756171",
                "DOI": "10.3389/fpubh.2020.00164",
                "CorpusId": 218582078,
                "PubMed": "32478029"
            },
            "abstract": "The basic Generative Adversarial Networks (GAN) model is composed of the input vector, generator, and discriminator. Among them, the generator and discriminator are implicit function expressions, usually implemented by deep neural networks. GAN can learn the generative model of any data distribution through adversarial methods with excellent performance. It has been widely applied to different areas since it was proposed in 2014. In this review, we introduced the origin, specific working principle, and development history of GAN, various applications of GAN in digital image processing, Cycle-GAN, and its application in medical imaging analysis, as well as the latest applications of GAN in medical informatics and bioinformatics.",
            "referenceCount": 108,
            "citationCount": 106,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.frontiersin.org/articles/10.3389/fpubh.2020.00164/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2020-05-12",
            "journal": {
                "name": "Frontiers in Public Health",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Lan2020GenerativeAN,\n author = {L. Lan and Lei You and Zeyang Zhang and Zhiwei Fan and Weiling Zhao and Nianyin Zeng and Yidong Chen and Xiaobo Zhou},\n booktitle = {Frontiers in Public Health},\n journal = {Frontiers in Public Health},\n title = {Generative Adversarial Networks and Its Applications in Biomedical Informatics},\n volume = {8},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7eb2cde1e7fb03363232d7574aba60ef0479d228",
            "@type": "ScholarlyArticle",
            "paperId": "7eb2cde1e7fb03363232d7574aba60ef0479d228",
            "corpusId": 210982078,
            "url": "https://www.semanticscholar.org/paper/7eb2cde1e7fb03363232d7574aba60ef0479d228",
            "title": "Assessing the impact of generative AI on medicinal chemistry",
            "venue": "Nature Biotechnology",
            "publicationVenue": {
                "id": "urn:research:458166b3-de17-4bf3-bbbb-e53782de2f0f",
                "name": "Nature Biotechnology",
                "alternate_names": [
                    "Nat Biotechnol"
                ],
                "issn": "1087-0156",
                "url": "http://www.nature.com/nbt/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3003906593",
                "DOI": "10.1038/s41587-020-0418-2",
                "CorpusId": 210982078,
                "PubMed": "32001834"
            },
            "abstract": null,
            "referenceCount": 23,
            "citationCount": 105,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "LettersAndComments"
            ],
            "publicationDate": "2020-01-30",
            "journal": {
                "name": "Nature Biotechnology",
                "volume": "38"
            },
            "citationStyles": {
                "bibtex": "@Article{Walters2020AssessingTI,\n author = {W. Walters and M. Murcko},\n booktitle = {Nature Biotechnology},\n journal = {Nature Biotechnology},\n pages = {143 - 145},\n title = {Assessing the impact of generative AI on medicinal chemistry},\n volume = {38},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3ef4ea883e28d76ae1bad0085bb182a8e07cbe25",
            "@type": "ScholarlyArticle",
            "paperId": "3ef4ea883e28d76ae1bad0085bb182a8e07cbe25",
            "corpusId": 213740950,
            "url": "https://www.semanticscholar.org/paper/3ef4ea883e28d76ae1bad0085bb182a8e07cbe25",
            "title": "Generative modeling of brain maps with spatial autocorrelation",
            "venue": "NeuroImage",
            "publicationVenue": {
                "id": "urn:research:fd4c7628-c16e-4b50-8555-3ac3ad6da2d7",
                "name": "NeuroImage",
                "alternate_names": null,
                "issn": "1053-8119",
                "url": "http://www.elsevier.com/locate/ynimg"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/neuroimage/BurtHSAM20",
                "MAG": "3008893008",
                "DOI": "10.1016/j.neuroimage.2020.117038",
                "CorpusId": 213740950,
                "PubMed": "32585343"
            },
            "abstract": null,
            "referenceCount": 62,
            "citationCount": 180,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-02-19",
            "journal": {
                "name": "NeuroImage",
                "volume": "220"
            },
            "citationStyles": {
                "bibtex": "@Article{Burt2020GenerativeMO,\n author = {J. Burt and Markus Helmer and Maxwell Shinn and A. Anticevic and J. Murray},\n booktitle = {NeuroImage},\n journal = {NeuroImage},\n title = {Generative modeling of brain maps with spatial autocorrelation},\n volume = {220},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1076a77834f11810fdcd100b21d90ca7bc1f9095",
            "@type": "ScholarlyArticle",
            "paperId": "1076a77834f11810fdcd100b21d90ca7bc1f9095",
            "corpusId": 219406915,
            "url": "https://www.semanticscholar.org/paper/1076a77834f11810fdcd100b21d90ca7bc1f9095",
            "title": "A case study of conditional deep convolutional generative adversarial networks in machine fault diagnosis",
            "venue": "Journal of Intelligent Manufacturing",
            "publicationVenue": {
                "id": "urn:research:9c5296b3-9225-4538-9b2d-f8f178534aad",
                "name": "Journal of Intelligent Manufacturing",
                "alternate_names": [
                    "J Intell Manuf"
                ],
                "issn": "0956-5515",
                "url": "http://www.springer.com/business+&+management/production/journal/10845?changeHeader="
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/jim/LuoHL21",
                "MAG": "3025967384",
                "DOI": "10.1007/s10845-020-01579-w",
                "CorpusId": 219406915
            },
            "abstract": null,
            "referenceCount": 39,
            "citationCount": 92,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-05-12",
            "journal": {
                "name": "Journal of Intelligent Manufacturing",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Luo2020ACS,\n author = {Jia Luo and Jinying Huang and Hongmei Li},\n booktitle = {Journal of Intelligent Manufacturing},\n journal = {Journal of Intelligent Manufacturing},\n pages = {1-19},\n title = {A case study of conditional deep convolutional generative adversarial networks in machine fault diagnosis},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:32f0c95cee39eba143452d6a0fe93283575257e6",
            "@type": "ScholarlyArticle",
            "paperId": "32f0c95cee39eba143452d6a0fe93283575257e6",
            "corpusId": 4718798,
            "url": "https://www.semanticscholar.org/paper/32f0c95cee39eba143452d6a0fe93283575257e6",
            "title": "Generative Adversarial Networks for Extreme Learned Image Compression",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1804.02958",
                "DBLP": "journals/corr/abs-1804-02958",
                "MAG": "2795709826",
                "DOI": "10.1109/ICCV.2019.00031",
                "CorpusId": 4718798
            },
            "abstract": "We present a learned image compression system based on GANs, operating at extremely low bitrates. Our proposed framework combines an encoder, decoder/generator and a multi-scale discriminator, which we train jointly for a generative learned compression objective. The model synthesizes details it cannot afford to store, obtaining visually pleasing results at bitrates where previous methods fail and show strong artifacts. Furthermore, if a semantic label map of the original image is available, our method can fully synthesize unimportant regions in the decoded image such as streets and trees from the label map, proportionally reducing the storage cost. A user study confirms that for low bitrates, our approach is preferred to state-of-the-art methods, even when they use more than double the bits.",
            "referenceCount": 58,
            "citationCount": 441,
            "influentialCitationCount": 47,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.research-collection.ethz.ch/bitstream/20.500.11850/407174/1/Agustsson_Generative_Adversarial_Networks_for_Extreme_Learned_Image_Compression_ICCV_2019_paper.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-04-09",
            "journal": {
                "name": "2019 IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Agustsson2018GenerativeAN,\n author = {E. Agustsson and M. Tschannen and Fabian Mentzer and R. Timofte and L. Gool},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},\n pages = {221-231},\n title = {Generative Adversarial Networks for Extreme Learned Image Compression},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fc7822f56dd255a872326b9536a0821bbf0277dd",
            "@type": "ScholarlyArticle",
            "paperId": "fc7822f56dd255a872326b9536a0821bbf0277dd",
            "corpusId": 14924561,
            "url": "https://www.semanticscholar.org/paper/fc7822f56dd255a872326b9536a0821bbf0277dd",
            "title": "Generative Visual Manipulation on the Natural Image Manifold",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2951021768",
                "ArXiv": "1609.03552",
                "DBLP": "journals/corr/ZhuKSE16",
                "DOI": "10.1007/978-3-319-46454-1_36",
                "CorpusId": 14924561
            },
            "abstract": null,
            "referenceCount": 51,
            "citationCount": 1283,
            "influentialCitationCount": 71,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1609.03552",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-09-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhu2016GenerativeVM,\n author = {Jun-Yan Zhu and Philipp Kr\u00e4henb\u00fchl and Eli Shechtman and Alexei A. Efros},\n booktitle = {European Conference on Computer Vision},\n pages = {597-613},\n title = {Generative Visual Manipulation on the Natural Image Manifold},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f8d43ff00585c53f65eb04e15477113c2d2b758b",
            "@type": "ScholarlyArticle",
            "paperId": "f8d43ff00585c53f65eb04e15477113c2d2b758b",
            "corpusId": 12054873,
            "url": "https://www.semanticscholar.org/paper/f8d43ff00585c53f65eb04e15477113c2d2b758b",
            "title": "SEGAN: Speech Enhancement Generative Adversarial Network",
            "venue": "Interspeech",
            "publicationVenue": {
                "id": "urn:research:af90489e-312f-4514-bea2-bcb399cb8ece",
                "name": "Interspeech",
                "alternate_names": [
                    "Conf Int Speech Commun Assoc",
                    "INTERSPEECH",
                    "Conference of the International Speech Communication Association"
                ],
                "issn": "2308-457X",
                "url": "https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963341071",
                "DBLP": "conf/interspeech/PascualBS17",
                "ArXiv": "1703.09452",
                "DOI": "10.21437/Interspeech.2017-1428",
                "CorpusId": 12054873
            },
            "abstract": "Current speech enhancement techniques operate on the spectral domain and/or exploit some higher-level feature. The majority of them tackle a limited number of noise conditions and rely on first-order statistics. To circumvent these issues, deep networks are being increasingly used, thanks to their ability to learn complex functions from large example sets. In this work, we propose the use of generative adversarial networks for speech enhancement. In contrast to current techniques, we operate at the waveform level, training the model end-to-end, and incorporate 28 speakers and 40 different noise conditions into the same model, such that model parameters are shared across them. We evaluate the proposed model using an independent, unseen test set with two speakers and 20 alternative noise conditions. The enhanced samples confirm the viability of the proposed model, and both objective and subjective evaluations confirm the effectiveness of it. With that, we open the exploration of generative architectures for speech enhancement, which may progressively incorporate further speech-centric design choices to improve their performance.",
            "referenceCount": 37,
            "citationCount": 991,
            "influentialCitationCount": 171,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1703.09452",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-28",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Pascual2017SEGANSE,\n author = {Santiago Pascual and A. Bonafonte and J. Serr\u00e0},\n booktitle = {Interspeech},\n pages = {3642-3646},\n title = {SEGAN: Speech Enhancement Generative Adversarial Network},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:aa6f7ad0a06b52a8be89dbd8d056561418276ff2",
            "@type": "ScholarlyArticle",
            "paperId": "aa6f7ad0a06b52a8be89dbd8d056561418276ff2",
            "corpusId": 9957731,
            "url": "https://www.semanticscholar.org/paper/aa6f7ad0a06b52a8be89dbd8d056561418276ff2",
            "title": "BEGAN: Boundary Equilibrium Generative Adversarial Networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2605195953",
                "ArXiv": "1703.10717",
                "DBLP": "journals/corr/BerthelotSM17",
                "CorpusId": 9957731
            },
            "abstract": "We propose a new equilibrium enforcing method paired with a loss derived from the Wasserstein distance for training auto-encoder based Generative Adversarial Networks. This method balances the generator and discriminator during training. Additionally, it provides a new approximate convergence measure, fast and stable training and high visual quality. We also derive a way of controlling the trade-off between image diversity and visual quality. We focus on the image generation task, setting a new milestone in visual quality, even at higher resolutions. This is achieved while using a relatively simple model architecture and a standard training procedure.",
            "referenceCount": 21,
            "citationCount": 1093,
            "influentialCitationCount": 167,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.10717"
            },
            "citationStyles": {
                "bibtex": "@Article{Berthelot2017BEGANBE,\n author = {David Berthelot and Tom Schumm and Luke Metz},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {BEGAN: Boundary Equilibrium Generative Adversarial Networks},\n volume = {abs/1703.10717},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fe9cd683c3b8ebdfd8efd1109a857cdbf9edc364",
            "@type": "ScholarlyArticle",
            "paperId": "fe9cd683c3b8ebdfd8efd1109a857cdbf9edc364",
            "corpusId": 4117071,
            "url": "https://www.semanticscholar.org/paper/fe9cd683c3b8ebdfd8efd1109a857cdbf9edc364",
            "title": "Data Augmentation Generative Adversarial Networks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2951224694",
                "ArXiv": "1711.04340",
                "DBLP": "journals/corr/abs-1711-04340",
                "CorpusId": 4117071
            },
            "abstract": "Effective training of neural networks requires much data. In the low-data regime, parameters are underdetermined, and learnt networks generalise poorly. Data Augmentation alleviates this by using existing data more effectively. However standard data augmentation produces only limited plausible alternative data. Given there is potential to generate a much broader set of augmentations, we design and train a generative model to do data augmentation. The model, based on image conditional Generative Adversarial Networks, takes data from a source domain and learns to take any data item and generalise it to generate other within-class data items. As this generative process does not depend on the classes themselves, it can be applied to novel unseen classes of data. We show that a Data Augmentation Generative Adversarial Network (DAGAN) augments standard vanilla classifiers well. We also show a DAGAN can enhance few-shot learning systems such as Matching Networks. We demonstrate these approaches on Omniglot, on EMNIST having learnt the DAGAN on Omniglot, and VGG-Face data. In our experiments we can see over 13% increase in accuracy in the low-data regime experiments in Omniglot (from 69% to 82%), EMNIST (73.9% to 76%) and VGG-Face (4.5% to 12%); in Matching Networks for Omniglot we observe an increase of 0.5% (from 96.9% to 97.4%) and an increase of 1.8% in EMNIST (from 59.5% to 61.3%).",
            "referenceCount": 41,
            "citationCount": 886,
            "influentialCitationCount": 78,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-12",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1711.04340"
            },
            "citationStyles": {
                "bibtex": "@Article{Antoniou2017DataAG,\n author = {Antreas Antoniou and A. Storkey and Harrison Edwards},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Data Augmentation Generative Adversarial Networks},\n volume = {abs/1711.04340},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:22a979553afa02093cb1b084d1185d8d75a1e0c8",
            "@type": "ScholarlyArticle",
            "paperId": "22a979553afa02093cb1b084d1185d8d75a1e0c8",
            "corpusId": 51989956,
            "url": "https://www.semanticscholar.org/paper/22a979553afa02093cb1b084d1185d8d75a1e0c8",
            "title": "Image Blind Denoising with Generative Adversarial Network Based Noise Modeling",
            "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2798278116",
                "DBLP": "conf/cvpr/ChenCCY18",
                "DOI": "10.1109/CVPR.2018.00333",
                "CorpusId": 51989956
            },
            "abstract": "In this paper, we consider a typical image blind denoising problem, which is to remove unknown noise from noisy images. As we all know, discriminative learning based methods, such as DnCNN, can achieve state-of-the-art denoising results, but they are not applicable to this problem due to the lack of paired training data. To tackle the barrier, we propose a novel two-step framework. First, a Generative Adversarial Network (GAN) is trained to estimate the noise distribution over the input noisy images and to generate noise samples. Second, the noise patches sampled from the first step are utilized to construct a paired training dataset, which is used, in turn, to train a deep Convolutional Neural Network (CNN) for denoising. Extensive experiments have been done to demonstrate the superiority of our approach in image blind denoising.",
            "referenceCount": 38,
            "citationCount": 430,
            "influentialCitationCount": 30,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2018ImageBD,\n author = {Jingwen Chen and Jiawei Chen and Hongyang Chao and Ming Yang},\n booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n pages = {3155-3164},\n title = {Image Blind Denoising with Generative Adversarial Network Based Noise Modeling},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d4a560b617175d20c9dbd063c5dc2e8f7478e2a6",
            "@type": "ScholarlyArticle",
            "paperId": "d4a560b617175d20c9dbd063c5dc2e8f7478e2a6",
            "corpusId": 52112233,
            "url": "https://www.semanticscholar.org/paper/d4a560b617175d20c9dbd063c5dc2e8f7478e2a6",
            "title": "Generative Adversarial Networks for Hyperspectral Image Classification",
            "venue": "IEEE Transactions on Geoscience and Remote Sensing",
            "publicationVenue": {
                "id": "urn:research:70628d6a-97aa-4571-9701-bc0eb3989c32",
                "name": "IEEE Transactions on Geoscience and Remote Sensing",
                "alternate_names": [
                    "IEEE Trans Geosci Remote Sens"
                ],
                "issn": "0196-2892",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=36"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2791006446",
                "DBLP": "journals/tgrs/ZhuCGB18",
                "DOI": "10.1109/TGRS.2018.2805286",
                "CorpusId": 52112233
            },
            "abstract": "A generative adversarial network (GAN) usually contains a generative network and a discriminative network in competition with each other. The GAN has shown its capability in a variety of applications. In this paper, the usefulness and effectiveness of GAN for classification of hyperspectral images (HSIs) are explored for the first time. In the proposed GAN, a convolutional neural network (CNN) is designed to discriminate the inputs and another CNN is used to generate so-called fake inputs. The aforementioned CNNs are trained together: the generative CNN tries to generate fake inputs that are as real as possible, and the discriminative CNN tries to classify the real and fake inputs. This kind of adversarial training improves the generalization capability of the discriminative CNN, which is really important when the training samples are limited. Specifically, we propose two schemes: 1) a well-designed 1D-GAN as a spectral classifier and 2) a robust 3D-GAN as a spectral\u2013spatial classifier. Furthermore, the generated adversarial samples are used with real training samples to fine-tune the discriminative CNN, which improves the final classification performance. The proposed classifiers are carried out on three widely used hyperspectral data sets: Salinas, Indiana Pines, and Kennedy Space Center. The obtained results reveal that the proposed models provide competitive results compared to the state-of-the-art methods. In addition, the proposed GANs open new opportunities in the remote sensing community for the challenging task of HSI classification and also reveal the huge potential of GAN-based methods for the analysis of such complex and inherently nonlinear data.",
            "referenceCount": 54,
            "citationCount": 430,
            "influentialCitationCount": 34,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://elib.dlr.de/119294/1/FINAL%20VERSION.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-03-06",
            "journal": {
                "name": "IEEE Transactions on Geoscience and Remote Sensing",
                "volume": "56"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhu2018GenerativeAN,\n author = {Lin Zhu and Yushi Chen and Pedram Ghamisi and J. Benediktsson},\n booktitle = {IEEE Transactions on Geoscience and Remote Sensing},\n journal = {IEEE Transactions on Geoscience and Remote Sensing},\n pages = {5046-5063},\n title = {Generative Adversarial Networks for Hyperspectral Image Classification},\n volume = {56},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3e9901bccd0b210daff1fbeff758cea3cc0ec7f9",
            "@type": "ScholarlyArticle",
            "paperId": "3e9901bccd0b210daff1fbeff758cea3cc0ec7f9",
            "corpusId": 214693030,
            "url": "https://www.semanticscholar.org/paper/3e9901bccd0b210daff1fbeff758cea3cc0ec7f9",
            "title": "Weakly-Supervised Action Localization by Generative Attention Modeling",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2003.12424",
                "DBLP": "conf/cvpr/ShiDMW20",
                "MAG": "3035585099",
                "DOI": "10.1109/CVPR42600.2020.00109",
                "CorpusId": 214693030
            },
            "abstract": "Weakly-supervised temporal action localization is a problem of learning an action localization model with only video-level action labeling available. The general framework largely relies on the classification activation, which employs an attention model to identify the action-related frames and then categorizes them into different classes. Such method results in the action-context confusion issue: context frames near action clips tend to be recognized as action frames themselves, since they are closely related to the specific classes. To solve the problem, in this paper we propose to model the class-agnostic frame-wise probability conditioned on the frame attention using conditional Variational Auto-Encoder (VAE). With the observation that the context exhibits notable difference from the action at representation level, a probabilistic model, i.e., conditional VAE, is learned to model the likelihood of each frame given the attention. By maximizing the conditional probability with respect to the attention, the action and non-action frames are well separated. Experiments on THUMOS14 and ActivityNet1.2 demonstrate advantage of our method and effectiveness in handling action-context confusion problem. Code is now available on GitHub.",
            "referenceCount": 60,
            "citationCount": 119,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2003.12424",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-03-27",
            "journal": {
                "name": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shi2020WeaklySupervisedAL,\n author = {Baifeng Shi and Qi Dai and Yadong Mu and Jingdong Wang},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1006-1016},\n title = {Weakly-Supervised Action Localization by Generative Attention Modeling},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5babbf2ed9f6e36b83ed246927b270db320fe866",
            "@type": "ScholarlyArticle",
            "paperId": "5babbf2ed9f6e36b83ed246927b270db320fe866",
            "corpusId": 53977298,
            "url": "https://www.semanticscholar.org/paper/5babbf2ed9f6e36b83ed246927b270db320fe866",
            "title": "A Simple Convolutional Generative Network for Next Item Recommendation",
            "venue": "Web Search and Data Mining",
            "publicationVenue": {
                "id": "urn:research:ea38228f-6ed3-4222-a3ce-d963d8cc9516",
                "name": "Web Search and Data Mining",
                "alternate_names": [
                    "Web Search Data Min",
                    "WSDM"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=3158"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1808.05163",
                "MAG": "2949472174",
                "DBLP": "conf/wsdm/YuanKAJ019",
                "DOI": "10.1145/3289600.3290975",
                "CorpusId": 53977298
            },
            "abstract": "Convolutional Neural Networks (CNNs) have been recently introduced in the domain of session-based next item recommendation. An ordered collection of past items the user has interacted with in a session (or sequence) are embedded into a 2-dimensional latent matrix, and treated as an image. The convolution and pooling operations are then applied to the mapped item embeddings. In this paper, we first examine the typical session-based CNN recommender and show that both the generative model and network architecture are suboptimal when modeling long-range dependencies in the item sequence. To address the issues, we introduce a simple, but very effective generative model that is capable of learning high-level representation from both short- and long-range item dependencies. The network architecture of the proposed model is formed of a stack of holed convolutional layers, which can efficiently increase the receptive fields without relying on the pooling operation. Another contribution is the effective use of residual block structure in recommender systems, which can ease the optimization for much deeper networks. The proposed generative model attains state-of-the-art accuracy with less training time in the next item recommendation task. It accordingly can be used as a powerful recommendation baseline to beat in future, especially when there are long sequences of user feedback.",
            "referenceCount": 40,
            "citationCount": 382,
            "influentialCitationCount": 37,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://zenodo.org/record/3355450/files/1808.05163.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2018-08-15",
            "journal": {
                "name": "Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Yuan2018ASC,\n author = {Fajie Yuan and Alexandros Karatzoglou and I. Arapakis and J. Jose and Xiangnan He},\n booktitle = {Web Search and Data Mining},\n journal = {Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},\n title = {A Simple Convolutional Generative Network for Next Item Recommendation},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:641f0891e63ea033332be6428fa815beaecb61e2",
            "@type": "ScholarlyArticle",
            "paperId": "641f0891e63ea033332be6428fa815beaecb61e2",
            "corpusId": 3571422,
            "url": "https://www.semanticscholar.org/paper/641f0891e63ea033332be6428fa815beaecb61e2",
            "title": "A Variational Inequality Perspective on Generative Adversarial Networks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1802.10551",
                "MAG": "2964249351",
                "DBLP": "conf/iclr/GidelBVVL19",
                "CorpusId": 3571422
            },
            "abstract": "Generative adversarial networks (GANs) form a generative modeling approach known for producing appealing samples, but they are notably difficult to train. One common way to tackle this issue has been to propose new formulations of the GAN objective. Yet, surprisingly few studies have looked at optimization methods designed for this adversarial training. In this work, we cast GAN optimization problems in the general variational inequality framework. Tapping into the mathematical programming literature, we counter some common misconceptions about the difficulties of saddle point optimization and propose to extend techniques designed for variational inequalities to the training of GANs. We apply averaging, extrapolation and a computationally cheaper variant that we call extrapolation from the past to the stochastic gradient method (SGD) and Adam.",
            "referenceCount": 67,
            "citationCount": 315,
            "influentialCitationCount": 62,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-28",
            "journal": {
                "name": "arXiv: Learning",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Gidel2018AVI,\n author = {Gauthier Gidel and Hugo Berard and Pascal Vincent and Simon Lacoste-Julien},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Learning},\n title = {A Variational Inequality Perspective on Generative Adversarial Networks},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:13f36daef8ed8f0e913095d983f820a4ae069c5f",
            "@type": "ScholarlyArticle",
            "paperId": "13f36daef8ed8f0e913095d983f820a4ae069c5f",
            "corpusId": 52155890,
            "url": "https://www.semanticscholar.org/paper/13f36daef8ed8f0e913095d983f820a4ae069c5f",
            "title": "Unsupervised Image Super-Resolution Using Cycle-in-Cycle Generative Adversarial Networks",
            "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2892111734",
                "DBLP": "journals/corr/abs-1809-00437",
                "ArXiv": "1809.00437",
                "DOI": "10.1109/CVPRW.2018.00113",
                "CorpusId": 52155890
            },
            "abstract": "We consider the single image super-resolution problem in a more general case that the low-/high-resolution pairs and the down-sampling process are unavailable. Different from traditional super-resolution formulation, the low-resolution input is further degraded by noises and blurring. This complicated setting makes supervised learning and accurate kernel estimation impossible. To solve this problem, we resort to unsupervised learning without paired data, inspired by the recent successful image-to-image translation applications. With generative adversarial networks (GAN) as the basic component, we propose a Cycle-in-Cycle network structure to tackle the problem within three steps. First, the noisy and blurry input is mapped to a noise-free low-resolution space. Then the intermediate image is up-sampled with a pre-trained deep model. Finally, we fine-tune the two modules in an end-to-end manner to get the high-resolution output. Experiments on NTIRE2018 datasets demonstrate that the proposed unsupervised method achieves comparable results as the state-of-the-art supervised models.",
            "referenceCount": 35,
            "citationCount": 363,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1809.00437",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yuan2018UnsupervisedIS,\n author = {Yuan Yuan and Siyuan Liu and Jiawei Zhang and Yongbing Zhang and Chao Dong and Liang Lin},\n booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},\n journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},\n pages = {814-81409},\n title = {Unsupervised Image Super-Resolution Using Cycle-in-Cycle Generative Adversarial Networks},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:920f0c070701caabf023c600f3e310f1906ca818",
            "@type": "ScholarlyArticle",
            "paperId": "920f0c070701caabf023c600f3e310f1906ca818",
            "corpusId": 11922819,
            "url": "https://www.semanticscholar.org/paper/920f0c070701caabf023c600f3e310f1906ca818",
            "title": "Image De-Raining Using a Conditional Generative Adversarial Network",
            "venue": "IEEE transactions on circuits and systems for video technology (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963017889",
                "DBLP": "journals/corr/ZhangSP17",
                "ArXiv": "1701.05957",
                "DOI": "10.1109/TCSVT.2019.2920407",
                "CorpusId": 11922819
            },
            "abstract": "Severe weather conditions, such as rain and snow, adversely affect the visual quality of images captured under such conditions, thus rendering them useless for further usage and sharing. In addition, such degraded images drastically affect the performance of vision systems. Hence, it is important to address the problem of single image de-raining. However, the inherent ill-posed nature of the problem presents several challenges. We attempt to leverage powerful generative modeling capabilities of the recently introduced conditional generative adversarial networks (CGAN) by enforcing an additional constraint that the de-rained image must be indistinguishable from its corresponding ground truth clean image. The adversarial loss from GAN provides additional regularization and helps to achieve superior results. In addition to presenting a new approach to de-rain images, we introduce a new refined loss function and architectural novelties in the generator\u2013discriminator pair for achieving improved results. The loss function is aimed at reducing artifacts introduced by GANs and ensure better visual quality. The generator sub-network is constructed using the recently introduced densely connected networks, whereas the discriminator is designed to leverage global and local information to decide if an image is real/fake. Based on this, we propose a novel single image de-raining method called image de-raining conditional generative adversarial network (ID-CGAN) that considers quantitative, visual, and also discriminative performance into the objective function. The experiments evaluated on synthetic and real images show that the proposed method outperforms many recent state-of-the-art single image de-raining methods in terms of quantitative and visual performances. Furthermore, the experimental results evaluated on object detection datasets using the Faster-RCNN also demonstrate the effectiveness of proposed method in improving the detection performance on images degraded by rain.",
            "referenceCount": 90,
            "citationCount": 812,
            "influentialCitationCount": 135,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1701.05957",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-01-21",
            "journal": {
                "name": "IEEE Transactions on Circuits and Systems for Video Technology",
                "volume": "30"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2017ImageDU,\n author = {He Zhang and Vishwanath A. Sindagi and Vishal M. Patel},\n booktitle = {IEEE transactions on circuits and systems for video technology (Print)},\n journal = {IEEE Transactions on Circuits and Systems for Video Technology},\n pages = {3943-3956},\n title = {Image De-Raining Using a Conditional Generative Adversarial Network},\n volume = {30},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2ba23d9b46027e47b4483243871760e315213ffe",
            "@type": "ScholarlyArticle",
            "paperId": "2ba23d9b46027e47b4483243871760e315213ffe",
            "corpusId": 15876696,
            "url": "https://www.semanticscholar.org/paper/2ba23d9b46027e47b4483243871760e315213ffe",
            "title": "Energy-based Generative Adversarial Network",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1609.03126",
                "MAG": "2521028896",
                "DBLP": "conf/iclr/ZhaoML17",
                "CorpusId": 15876696
            },
            "abstract": "We introduce the \"Energy-based Generative Adversarial Network\" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. Similar to the probabilistic GANs, a generator is seen as being trained to produce contrastive samples with minimal energies, while the discriminator is trained to assign high energies to these generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary classifier with logistic output. Among them, we show one instantiation of EBGAN framework as using an auto-encoder architecture, with the energy being the reconstruction error, in place of the discriminator. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images.",
            "referenceCount": 34,
            "citationCount": 1031,
            "influentialCitationCount": 95,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-11",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1609.03126"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhao2016EnergybasedGA,\n author = {J. Zhao and Micha\u00ebl Mathieu and Yann LeCun},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Energy-based Generative Adversarial Network},\n volume = {abs/1609.03126},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f8d07e7e0d353cb537eefc97dea5744a615d7dc3",
            "@type": "ScholarlyArticle",
            "paperId": "f8d07e7e0d353cb537eefc97dea5744a615d7dc3",
            "corpusId": 206749807,
            "url": "https://www.semanticscholar.org/paper/f8d07e7e0d353cb537eefc97dea5744a615d7dc3",
            "title": "A Generative Model for Inverse Design of Metamaterials",
            "venue": "Nano letters (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1805-10181",
                "MAG": "2803281408",
                "ArXiv": "1805.10181",
                "DOI": "10.1021/acs.nanolett.8b03171",
                "CorpusId": 206749807,
                "PubMed": "30207735"
            },
            "abstract": "The advent of metasurfaces in recent years has ushered in a revolutionary means to manipulate the behavior of light on the nanoscale. The design of such structures, to date, has relied on the expertise of an optical scientist to guide a progression of electromagnetic simulations that iteratively solve Maxwell's equations until a locally optimized solution can be attained. In this work, we identify a solution to circumvent this conventional design procedure by means of a deep learning architecture. When fed an input set of customer-defined optical spectra, the constructed generative network generates candidate patterns that match the on-demand spectra with high fidelity. This approach reveals an opportunity to expedite the discovery and design of metasurfaces for tailored optical responses in a systematic, inverse-design manner.",
            "referenceCount": 34,
            "citationCount": 375,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1805.10181",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Materials Science",
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Materials Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-05-25",
            "journal": {
                "name": "Nano letters",
                "volume": "18 10"
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2018AGM,\n author = {Zhaocheng Liu and Dayu Zhu and S. Rodrigues and Kyu-Tae Lee and W. Cai},\n booktitle = {Nano letters (Print)},\n journal = {Nano letters},\n pages = {\n          6570-6576\n        },\n title = {A Generative Model for Inverse Design of Metamaterials},\n volume = {18 10},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:91ee6164bfbe7a75eaccf79283da54200cb30c93",
            "@type": "ScholarlyArticle",
            "paperId": "91ee6164bfbe7a75eaccf79283da54200cb30c93",
            "corpusId": 141509818,
            "url": "https://www.semanticscholar.org/paper/91ee6164bfbe7a75eaccf79283da54200cb30c93",
            "title": "Electrocardiogram generation with a bidirectional LSTM-CNN generative adversarial network",
            "venue": "Scientific Reports",
            "publicationVenue": {
                "id": "urn:research:f99f77b7-b1b6-44d3-984a-f288e9884b9b",
                "name": "Scientific Reports",
                "alternate_names": [
                    "Sci Rep"
                ],
                "issn": "2045-2322",
                "url": "http://www.nature.com/srep/"
            },
            "year": 2019,
            "externalIds": {
                "PubMedCentral": "6494992",
                "MAG": "2943118732",
                "DOI": "10.1038/s41598-019-42516-z",
                "CorpusId": 141509818,
                "PubMed": "31043666"
            },
            "abstract": null,
            "referenceCount": 40,
            "citationCount": 229,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41598-019-42516-z.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-05-01",
            "journal": {
                "name": "Scientific Reports",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhu2019ElectrocardiogramGW,\n author = {Fei Zhu and Fei Ye and Yuchen Fu and QUAN LIU and Bairong Shen},\n booktitle = {Scientific Reports},\n journal = {Scientific Reports},\n title = {Electrocardiogram generation with a bidirectional LSTM-CNN generative adversarial network},\n volume = {9},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0e984ccc4fbfc748836b2dde6fb1bdb5f9bf071a",
            "@type": "ScholarlyArticle",
            "paperId": "0e984ccc4fbfc748836b2dde6fb1bdb5f9bf071a",
            "corpusId": 54024655,
            "url": "https://www.semanticscholar.org/paper/0e984ccc4fbfc748836b2dde6fb1bdb5f9bf071a",
            "title": "Multivariate Time Series Imputation with Generative Adversarial Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2890686416",
                "DBLP": "conf/nips/LuoCZXY18",
                "CorpusId": 54024655
            },
            "abstract": "Multivariate time series usually contain a large number of missing values, which hinders the application of advanced analysis methods on multivariate time series data. Conventional approaches to addressing the challenge of missing values, including mean/zero imputation, case deletion, and matrix factorization-based imputation, are all incapable of modeling the temporal dependencies and the nature of complex distribution in multivariate time series. In this paper, we treat the problem of missing value imputation as data generation. Inspired by the success of Generative Adversarial Networks (GAN) in image generation, we propose to learn the overall distribution of a multivariate time series dataset with GAN, which is further used to generate the missing values for each sample. Different from the image data, the time series data are usually incomplete due to the nature of data recording process. A modified Gate Recurrent Unit is employed in GAN to model the temporal irregularity of the incomplete time series. Experiments on two multivariate time series datasets show that the proposed model outperformed the baselines in terms of accuracy of imputation. Experimental results also showed that a simple model on the imputed data can achieve state-of-the-art results on the prediction tasks, demonstrating the benefits of our model in downstream applications.",
            "referenceCount": 46,
            "citationCount": 308,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Luo2018MultivariateTS,\n author = {Yonghong Luo and Xiangrui Cai and Y. Zhang and Jun Xu and Xiaojie Yuan},\n booktitle = {Neural Information Processing Systems},\n pages = {1603-1614},\n title = {Multivariate Time Series Imputation with Generative Adversarial Networks},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:10f2b0f9744aec689b2fc75740bf8d9d9c1896e3",
            "@type": "ScholarlyArticle",
            "paperId": "10f2b0f9744aec689b2fc75740bf8d9d9c1896e3",
            "corpusId": 214802519,
            "url": "https://www.semanticscholar.org/paper/10f2b0f9744aec689b2fc75740bf8d9d9c1896e3",
            "title": "Model-Based Reinforcement Learning with a Generative Model is Minimax Optimal",
            "venue": "Annual Conference Computational Learning Theory",
            "publicationVenue": {
                "id": "urn:research:24b0721b-0592-414a-ac79-7271515aaab0",
                "name": "Annual Conference Computational Learning Theory",
                "alternate_names": [
                    "Conf Learn Theory",
                    "COLT",
                    "Conference on Learning Theory",
                    "Annu Conf Comput Learn Theory"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=536"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1906.03804",
                "MAG": "3046692137",
                "DBLP": "conf/colt/AgarwalKY20",
                "CorpusId": 214802519
            },
            "abstract": "This work considers the sample and computational complexity of obtaining an $\\epsilon$-optimal policy in a discounted Markov Decision Process (MDP), given only access to a generative model. In this work, we study the effectiveness of the most natural plug-in approach to model-based planning: we build the maximum likelihood estimate of the transition model in the MDP from observations and then find an optimal policy in this empirical MDP. We ask arguably the most basic and unresolved question in model based planning: is the naive \"plug-in\" approach, non-asymptotically, minimax optimal in the quality of the policy it finds, given a fixed sample size? Here, the non-asymptotic regime refers to when the sample size is sublinear in the model size. \nWith access to a generative model, we resolve this question in the strongest possible sense: our main result shows that \\emph{any} high accuracy solution in the plug-in model constructed with $N$ samples, provides an $\\epsilon$-optimal policy in the true underlying MDP (where $\\epsilon$ is the minimax accuracy with $N$ samples at every state, action pair). In comparison, all prior (non-asymptotically) minimax optimal results use model free approaches, such as the Variance Reduced Q-value iteration algorithm (Sidford et al 2018), while the best known model-based results (e.g. Azar et al 2013) require larger sample sizes in their dependence on the planning horizon or the state space. Notably, we show that the model-based approach allows the use of \\emph{any} efficient planning algorithm in the empirical MDP, which simplifies algorithm design as this approach does not tie the algorithm to the sampling procedure. The core of our analysis is avnovel \"absorbing MDP\" construction to address the statistical dependency issues that arise in the analysis of model-based planning approaches, a construction which may be helpful more generally.",
            "referenceCount": 26,
            "citationCount": 141,
            "influentialCitationCount": 42,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-06-10",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Agarwal2019ModelBasedRL,\n author = {Alekh Agarwal and S. Kakade and Lin F. Yang},\n booktitle = {Annual Conference Computational Learning Theory},\n pages = {67-83},\n title = {Model-Based Reinforcement Learning with a Generative Model is Minimax Optimal},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0566f82cba99258dde002751ac6184636cbc19b4",
            "@type": "ScholarlyArticle",
            "paperId": "0566f82cba99258dde002751ac6184636cbc19b4",
            "corpusId": 238008391,
            "url": "https://www.semanticscholar.org/paper/0566f82cba99258dde002751ac6184636cbc19b4",
            "title": "Unleashing Generative Modeling",
            "venue": "Generating a New Reality",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "MAG": "3185659950",
                "DOI": "10.1007/978-1-4842-7092-9_2",
                "CorpusId": 238008391
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Generating a New Reality",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lanham2021UnleashingGM,\n author = {Micheal Lanham},\n booktitle = {Generating a New Reality},\n journal = {Generating a New Reality},\n title = {Unleashing Generative Modeling},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:508eb5a6156b8fa1b4547b611e85969438116fa2",
            "@type": "ScholarlyArticle",
            "paperId": "508eb5a6156b8fa1b4547b611e85969438116fa2",
            "corpusId": 6704804,
            "url": "https://www.semanticscholar.org/paper/508eb5a6156b8fa1b4547b611e85969438116fa2",
            "title": "Perceptual Generative Adversarial Networks for Small Object Detection",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/cvpr/LiLWXFY17",
                "ArXiv": "1706.05274",
                "MAG": "2951649776",
                "DOI": "10.1109/CVPR.2017.211",
                "CorpusId": 6704804
            },
            "abstract": "Detecting small objects is notoriously challenging due to their low resolution and noisy representation. Existing object detection pipelines usually detect small objects through learning representations of all the objects at multiple scales. However, the performance gain of such ad hoc architectures is usually limited to pay off the computational cost. In this work, we address the small object detection problem by developing a single architecture that internally lifts representations of small objects to super-resolved ones, achieving similar characteristics as large objects and thus more discriminative for detection. For this purpose, we propose a new Perceptual Generative Adversarial Network (Perceptual GAN) model that improves small object detection through narrowing representation difference of small objects from the large ones. Specifically, its generator learns to transfer perceived poor representations of the small objects to super-resolved ones that are similar enough to real large objects to fool a competing discriminator. Meanwhile its discriminator competes with the generator to identify the generated representation and imposes an additional perceptual requirement - generated representations of small objects must be beneficial for detection purpose - on the generator. Extensive evaluations on the challenging Tsinghua-Tencent 100K [45] and the Caltech [9] benchmark well demonstrate the superiority of Perceptual GAN in detecting small objects, including traffic signs and pedestrians, over well-established state-of-the-arts.",
            "referenceCount": 47,
            "citationCount": 593,
            "influentialCitationCount": 36,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1706.05274",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-06-16",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Li2017PerceptualGA,\n author = {Jianan Li and Xiaodan Liang and Yunchao Wei and Tingfa Xu and Jiashi Feng and Shuicheng Yan},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1951-1959},\n title = {Perceptual Generative Adversarial Networks for Small Object Detection},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b0351087a2b85f70e60fc79dfa4110b4985cc00a",
            "@type": "ScholarlyArticle",
            "paperId": "b0351087a2b85f70e60fc79dfa4110b4985cc00a",
            "corpusId": 9459250,
            "url": "https://www.semanticscholar.org/paper/b0351087a2b85f70e60fc79dfa4110b4985cc00a",
            "title": "Generative Face Completion",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2611104282",
                "DBLP": "journals/corr/LiLY017",
                "ArXiv": "1704.05838",
                "DOI": "10.1109/CVPR.2017.624",
                "CorpusId": 9459250
            },
            "abstract": "In this paper, we propose an effective face completion algorithm using a deep generative model. Different from well-studied background completion, the face completion task is more challenging as it often requires to generate semantically new pixels for the missing key components (e.g., eyes and mouths) that contain large appearance variations. Unlike existing nonparametric algorithms that search for patches to synthesize, our algorithm directly generates contents for missing regions based on a neural network. The model is trained with a combination of a reconstruction loss, two adversarial losses and a semantic parsing loss, which ensures pixel faithfulness and local-global contents consistency. With extensive experimental results, we demonstrate qualitatively and quantitatively that our model is able to deal with a large area of missing pixels in arbitrary shapes and generate realistic face completion results.",
            "referenceCount": 29,
            "citationCount": 554,
            "influentialCitationCount": 53,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1704.05838",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-04-19",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Li2017GenerativeFC,\n author = {Yijun Li and Sifei Liu and Jimei Yang and Ming-Hsuan Yang},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {5892-5900},\n title = {Generative Face Completion},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5320c90d52541d5581f0a8c4b75d9b2da81299ce",
            "@type": "ScholarlyArticle",
            "paperId": "5320c90d52541d5581f0a8c4b75d9b2da81299ce",
            "corpusId": 7739761,
            "url": "https://www.semanticscholar.org/paper/5320c90d52541d5581f0a8c4b75d9b2da81299ce",
            "title": "Generating Multi-label Discrete Patient Records using Generative Adversarial Networks",
            "venue": "Machine Learning in Health Care",
            "publicationVenue": {
                "id": "urn:research:6171bcff-8306-41c7-af12-fa1d87117cf1",
                "name": "Machine Learning in Health Care",
                "alternate_names": [
                    "MLHC",
                    "Mach Learn Health Care"
                ],
                "issn": null,
                "url": "http://mucmd.org"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2604918751",
                "ArXiv": "1703.06490",
                "DBLP": "conf/mlhc/ChoiBMDSS17",
                "CorpusId": 7739761
            },
            "abstract": "Access to electronic health record (EHR) data has motivated computational advances in medical research. However, various concerns, particularly over privacy, can limit access to and collaborative use of EHR data. Sharing synthetic EHR data could mitigate risk. In this paper, we propose a new approach, medical Generative Adversarial Network (medGAN), to generate realistic synthetic patient records. Based on input real patient records, medGAN can generate high-dimensional discrete variables (e.g., binary and count features) via a combination of an autoencoder and generative adversarial networks. We also propose minibatch averaging to efficiently avoid mode collapse, and increase the learning efficiency with batch normalization and shortcut connections. To demonstrate feasibility, we showed that medGAN generates synthetic patient records that achieve comparable performance to real data on many experiments including distribution statistics, predictive modeling tasks and a medical expert review. We also empirically observe a limited privacy risk in both identity and attribute disclosure using medGAN.",
            "referenceCount": 54,
            "citationCount": 413,
            "influentialCitationCount": 52,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-03-19",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Choi2017GeneratingMD,\n author = {E. Choi and Siddharth Biswal and B. Malin and J. Duke and W. Stewart and Jimeng Sun},\n booktitle = {Machine Learning in Health Care},\n pages = {286-305},\n title = {Generating Multi-label Discrete Patient Records using Generative Adversarial Networks},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4652e86e535a15b191fcbe5c047e5ee0b9c86f09",
            "@type": "ScholarlyArticle",
            "paperId": "4652e86e535a15b191fcbe5c047e5ee0b9c86f09",
            "corpusId": 3898199,
            "url": "https://www.semanticscholar.org/paper/4652e86e535a15b191fcbe5c047e5ee0b9c86f09",
            "title": "Compressed Sensing MRI Reconstruction Using a Generative Adversarial Network With a Cyclic Loss",
            "venue": "IEEE Transactions on Medical Imaging",
            "publicationVenue": {
                "id": "urn:research:e0cda45d-3074-4ac0-80b8-e5250df00b89",
                "name": "IEEE Transactions on Medical Imaging",
                "alternate_names": [
                    "IEEE Trans Med Imaging"
                ],
                "issn": "0278-0062",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=42"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/tmi/QuanNJ18",
                "ArXiv": "1709.00753",
                "MAG": "3105445098",
                "DOI": "10.1109/TMI.2018.2820120",
                "CorpusId": 3898199,
                "PubMed": "29870376"
            },
            "abstract": "Compressed sensing magnetic resonance imaging (CS-MRI) has provided theoretical foundations upon which the time-consuming MRI acquisition process can be accelerated. However, it primarily relies on iterative numerical solvers, which still hinders their adaptation in time-critical applications. In addition, recent advances in deep neural networks have shown their potential in computer vision and image processing, but their adaptation to MRI reconstruction is still in an early stage. In this paper, we propose a novel deep learning-based generative adversarial model, <italic>RefineGAN</italic>, for fast and accurate CS-MRI reconstruction. The proposed model is a variant of fully-residual convolutional autoencoder and generative adversarial networks (GANs), specifically designed for CS-MRI formulation; it employs deeper generator and discriminator networks with cyclic data consistency loss for faithful interpolation in the given under-sampled <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula>-space data. In addition, our solution leverages a chained network to further enhance the reconstruction quality. <italic>RefineGAN</italic> is fast and accurate\u2014the reconstruction process is extremely rapid, as low as tens of milliseconds for reconstruction of a <inline-formula> <tex-math notation=\"LaTeX\">$256\\times 256$ </tex-math></inline-formula> image, because it is one-way deployment on a feed-forward network, and the image quality is superior even for extremely low sampling rate (as low as 10%) due to the data-driven nature of the method. We demonstrate that <italic>RefineGAN</italic> outperforms the state-of-the-art CS-MRI methods by a large margin in terms of both running time and image quality via evaluation using several open-source MRI databases.",
            "referenceCount": 55,
            "citationCount": 469,
            "influentialCitationCount": 32,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1709.00753",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-09-03",
            "journal": {
                "name": "IEEE Transactions on Medical Imaging",
                "volume": "37"
            },
            "citationStyles": {
                "bibtex": "@Article{Quan2017CompressedSM,\n author = {Tran Minh Quan and Thanh Nguyen-Duc and W. Jeong},\n booktitle = {IEEE Transactions on Medical Imaging},\n journal = {IEEE Transactions on Medical Imaging},\n pages = {1488-1497},\n title = {Compressed Sensing MRI Reconstruction Using a Generative Adversarial Network With a Cyclic Loss},\n volume = {37},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3bd6e4f596d99a47e1e70504e0fc51267ab213e9",
            "@type": "ScholarlyArticle",
            "paperId": "3bd6e4f596d99a47e1e70504e0fc51267ab213e9",
            "corpusId": 17579179,
            "url": "https://www.semanticscholar.org/paper/3bd6e4f596d99a47e1e70504e0fc51267ab213e9",
            "title": "Triple Generative Adversarial Nets",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/LiXZZ17",
                "ArXiv": "1703.02291",
                "MAG": "2964218010",
                "CorpusId": 17579179
            },
            "abstract": "Generative Adversarial Nets (GANs) have shown promise in image generation and semi-supervised learning (SSL). However, existing GANs in SSL have two problems: (1) the generator and the discriminator (i.e. the classifier) may not be optimal at the same time; and (2) the generator cannot control the semantics of the generated samples. The problems essentially arise from the two-player formulation, where a single discriminator shares incompatible roles of identifying fake samples and predicting labels and it only estimates the data without considering the labels. To address the problems, we present triple generative adversarial net (Triple-GAN), which consists of three players---a generator, a discriminator and a classifier. The generator and the classifier characterize the conditional distributions between images and labels, and the discriminator solely focuses on identifying fake image-label pairs. We design compatible utilities to ensure that the distributions characterized by the classifier and the generator both converge to the data distribution. Our results on various datasets demonstrate that Triple-GAN as a unified model can simultaneously (1) achieve the state-of-the-art classification results among deep generative models, and (2) disentangle the classes and styles of the input and transfer smoothly in the data space via interpolation in the latent space class-conditionally.",
            "referenceCount": 36,
            "citationCount": 402,
            "influentialCitationCount": 52,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-07",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.02291"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2017TripleGA,\n author = {Chongxuan Li and T. Xu and Jun Zhu and Bo Zhang},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Triple Generative Adversarial Nets},\n volume = {abs/1703.02291},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:80beec251b5d9f4f78fca2ea2016cf9d763b844c",
            "@type": "ScholarlyArticle",
            "paperId": "80beec251b5d9f4f78fca2ea2016cf9d763b844c",
            "corpusId": 203593936,
            "url": "https://www.semanticscholar.org/paper/80beec251b5d9f4f78fca2ea2016cf9d763b844c",
            "title": "Hamiltonian Generative Networks",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2976349204",
                "ArXiv": "1909.13789",
                "DBLP": "journals/corr/abs-1909-13789",
                "CorpusId": 203593936
            },
            "abstract": "The Hamiltonian formalism plays a central role in classical and quantum physics. Hamiltonians are the main tool for modelling the continuous time evolution of systems with conserved quantities, and they come equipped with many useful properties, like time reversibility and smooth interpolation in time. These properties are important for many machine learning problems - from sequence prediction to reinforcement learning and density modelling - but are not typically provided out of the box by standard tools such as recurrent neural networks. In this paper, we introduce the Hamiltonian Generative Network (HGN), the first approach capable of consistently learning Hamiltonian dynamics from high-dimensional observations (such as images) without restrictive domain assumptions. Once trained, we can use HGN to sample new trajectories, perform rollouts both forward and backward in time and even speed up or slow down the learned dynamics. We demonstrate how a simple modification of the network architecture turns HGN into a powerful normalising flow model, called Neural Hamiltonian Flow (NHF), that uses Hamiltonian dynamics to model expressive densities. We hope that our work serves as a first practical demonstration of the value that the Hamiltonian formalism can bring to deep learning.",
            "referenceCount": 35,
            "citationCount": 170,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-09-30",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1909.13789"
            },
            "citationStyles": {
                "bibtex": "@Article{Toth2019HamiltonianGN,\n author = {Peter Toth and Danilo Jimenez Rezende and Andrew Jaegle and S. Racani\u00e8re and Aleksandar Botev and I. Higgins},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Hamiltonian Generative Networks},\n volume = {abs/1909.13789},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:20b248b56af9a0d1abbda300f0a275a874c7148c",
            "@type": "ScholarlyArticle",
            "paperId": "20b248b56af9a0d1abbda300f0a275a874c7148c",
            "corpusId": 208607481,
            "url": "https://www.semanticscholar.org/paper/20b248b56af9a0d1abbda300f0a275a874c7148c",
            "title": "A de novo molecular generation method using latent vector based generative adversarial network",
            "venue": "Journal of Cheminformatics",
            "publicationVenue": {
                "id": "urn:research:fd4675fe-4136-446c-aefd-3658aae698ac",
                "name": "Journal of Cheminformatics",
                "alternate_names": [
                    "J Cheminformatics"
                ],
                "issn": "1758-2946",
                "url": "https://jcheminf.biomedcentral.com/"
            },
            "year": 2019,
            "externalIds": {
                "PubMedCentral": "6892210",
                "MAG": "2991736596",
                "DBLP": "journals/jcheminf/PrykhodkoJKABEC19",
                "DOI": "10.1186/s13321-019-0397-9",
                "CorpusId": 208607481,
                "PubMed": "33430938"
            },
            "abstract": null,
            "referenceCount": 68,
            "citationCount": 203,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://jcheminf.biomedcentral.com/track/pdf/10.1186/s13321-019-0397-9",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-20",
            "journal": {
                "name": "Journal of Cheminformatics",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Prykhodko2019ADN,\n author = {Oleksii Prykhodko and Simon Johansson and Panagiotis-Christos Kotsias and Josep Ar\u00fas\u2010Pous and E. Bjerrum and O. Engkvist and Hongming Chen},\n booktitle = {Journal of Cheminformatics},\n journal = {Journal of Cheminformatics},\n title = {A de novo molecular generation method using latent vector based generative adversarial network},\n volume = {11},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:553a566dee3438ddff7d97a91e91d8a7b0caad66",
            "@type": "ScholarlyArticle",
            "paperId": "553a566dee3438ddff7d97a91e91d8a7b0caad66",
            "corpusId": 6598262,
            "url": "https://www.semanticscholar.org/paper/553a566dee3438ddff7d97a91e91d8a7b0caad66",
            "title": "Learning a Predictable and Generative Vector Representation for Objects",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/eccv/GirdharFRG16",
                "MAG": "2964137676",
                "ArXiv": "1603.08637",
                "DOI": "10.1007/978-3-319-46466-4_29",
                "CorpusId": 6598262
            },
            "abstract": null,
            "referenceCount": 44,
            "citationCount": 643,
            "influentialCitationCount": 58,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1603.08637",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-03-29",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1603.08637"
            },
            "citationStyles": {
                "bibtex": "@Article{Girdhar2016LearningAP,\n author = {Rohit Girdhar and D. Fouhey and Mikel D. Rodriguez and A. Gupta},\n booktitle = {European Conference on Computer Vision},\n journal = {ArXiv},\n title = {Learning a Predictable and Generative Vector Representation for Objects},\n volume = {abs/1603.08637},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a9d83b30c3e615286d3e24b6a2e2228872b39bc8",
            "@type": "ScholarlyArticle",
            "paperId": "a9d83b30c3e615286d3e24b6a2e2228872b39bc8",
            "corpusId": 16173204,
            "url": "https://www.semanticscholar.org/paper/a9d83b30c3e615286d3e24b6a2e2228872b39bc8",
            "title": "Semi-Supervised Learning with Generative Adversarial Networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2412510955",
                "DBLP": "journals/corr/Odena16a",
                "ArXiv": "1606.01583",
                "CorpusId": 16173204
            },
            "abstract": "We extend Generative Adversarial Networks (GANs) to the semi-supervised context by forcing the discriminator network to output class labels. We train a generative model G and a discriminator D on a dataset with inputs belonging to one of N classes. At training time, D is made to predict which of N+1 classes the input belongs to, where an extra class is added to correspond to the outputs of G. We show that this method can be used to create a more data-efficient classifier and that it allows for generating higher quality samples than a regular GAN.",
            "referenceCount": 14,
            "citationCount": 614,
            "influentialCitationCount": 67,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-06-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1606.01583"
            },
            "citationStyles": {
                "bibtex": "@Article{Odena2016SemiSupervisedLW,\n author = {Augustus Odena},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Semi-Supervised Learning with Generative Adversarial Networks},\n volume = {abs/1606.01583},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9c763df6843aba88d7fb3ab3c55a5937a5f39276",
            "@type": "ScholarlyArticle",
            "paperId": "9c763df6843aba88d7fb3ab3c55a5937a5f39276",
            "corpusId": 1541706,
            "url": "https://www.semanticscholar.org/paper/9c763df6843aba88d7fb3ab3c55a5937a5f39276",
            "title": "Generative Image Modeling Using Style and Structure Adversarial Networks",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1603.05631",
                "MAG": "2952134811",
                "DBLP": "journals/corr/WangG16",
                "DOI": "10.1007/978-3-319-46493-0_20",
                "CorpusId": 1541706
            },
            "abstract": null,
            "referenceCount": 66,
            "citationCount": 581,
            "influentialCitationCount": 20,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/978-3-319-46493-0_20.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-03-17",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1603.05631"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2016GenerativeIM,\n author = {X. Wang and A. Gupta},\n booktitle = {European Conference on Computer Vision},\n journal = {ArXiv},\n title = {Generative Image Modeling Using Style and Structure Adversarial Networks},\n volume = {abs/1603.05631},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9ec59d3b0320fc8abfaf297be45f0da6fdeef3d7",
            "@type": "ScholarlyArticle",
            "paperId": "9ec59d3b0320fc8abfaf297be45f0da6fdeef3d7",
            "corpusId": 14803274,
            "url": "https://www.semanticscholar.org/paper/9ec59d3b0320fc8abfaf297be45f0da6fdeef3d7",
            "title": "Stacked Generative Adversarial Networks",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2952010110",
                "ArXiv": "1612.04357",
                "DBLP": "conf/cvpr/HuangLPHB17",
                "DOI": "10.1109/CVPR.2017.202",
                "CorpusId": 14803274
            },
            "abstract": "In this paper, we propose a novel generative model named Stacked Generative Adversarial Networks (SGAN), which is trained to invert the hierarchical representations of a bottom-up discriminative network. Our model consists of a top-down stack of GANs, each learned to generate lower-level representations conditioned on higher-level representations. A representation discriminator is introduced at each feature hierarchy to encourage the representation manifold of the generator to align with that of the bottom-up discriminative network, leveraging the powerful discriminative representations to guide the generative model. In addition, we introduce a conditional loss that encourages the use of conditional information from the layer above, and a novel entropy loss that maximizes a variational lower bound on the conditional entropy of generator outputs. We first train each stack independently, and then train the whole model end-to-end. Unlike the original GAN that uses a single noise vector to represent all the variations, our SGAN decomposes variations into multiple levels and gradually resolves uncertainties in the top-down generative process. Based on visual inspection, Inception scores and visual Turing test, we demonstrate that SGAN is able to generate images of much higher quality than GANs without stacking.",
            "referenceCount": 80,
            "citationCount": 434,
            "influentialCitationCount": 31,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1612.04357",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-12-13",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2016StackedGA,\n author = {Xun Huang and Yixuan Li and Omid Poursaeed and J. Hopcroft and Serge J. Belongie},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1866-1875},\n title = {Stacked Generative Adversarial Networks},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:57e72da5765157f72e216054f64280dbf3f8d865",
            "@type": "ScholarlyArticle",
            "paperId": "57e72da5765157f72e216054f64280dbf3f8d865",
            "corpusId": 208139117,
            "url": "https://www.semanticscholar.org/paper/57e72da5765157f72e216054f64280dbf3f8d865",
            "title": "Learning with Good Feature Representations in Bandits and in RL with a Generative Model",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2987587823",
                "DBLP": "journals/corr/abs-1911-07676",
                "ArXiv": "1911.07676",
                "CorpusId": 208139117
            },
            "abstract": "The construction by Du et al. (2019) implies that even if a learner is given linear features in $\\mathbb R^d$ that approximate the rewards in a bandit with a uniform error of $\\epsilon$, then searching for an action that is optimal up to $O(\\epsilon)$ requires examining essentially all actions. We use the Kiefer-Wolfowitz theorem to prove a positive result that by checking only a few actions, a learner can always find an action that is suboptimal with an error of at most $O(\\epsilon \\sqrt{d})$. Thus, features are useful when the approximation error is small relative to the dimensionality of the features. The idea is applied to stochastic bandits and reinforcement learning with a generative model where the learner has access to $d$-dimensional linear features that approximate the action-value functions for all policies to an accuracy of $\\epsilon$. For linear bandits, we prove a bound on the regret of order $\\sqrt{dn \\log(k)} + \\epsilon n \\sqrt{d} \\log(n)$ with $k$ the number of actions and $n$ the horizon. For RL we show that approximate policy iteration can learn a policy that is optimal up to an additive error of order $\\epsilon \\sqrt{d}/(1 - \\gamma)^2$ and using $d/(\\epsilon^2(1 - \\gamma)^4)$ samples from a generative model. These bounds are independent of the finer details of the features. We also investigate how the structure of the feature set impacts the tradeoff between sample complexity and estimation error.",
            "referenceCount": 26,
            "citationCount": 138,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-11-18",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lattimore2019LearningWG,\n author = {Tor Lattimore and Csaba Szepesvari},\n booktitle = {International Conference on Machine Learning},\n pages = {5662-5670},\n title = {Learning with Good Feature Representations in Bandits and in RL with a Generative Model},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8f9d03f85a3daf54daa455668cd503bcf9fa73b4",
            "@type": "ScholarlyArticle",
            "paperId": "8f9d03f85a3daf54daa455668cd503bcf9fa73b4",
            "corpusId": 199466115,
            "url": "https://www.semanticscholar.org/paper/8f9d03f85a3daf54daa455668cd503bcf9fa73b4",
            "title": "E\u00b2GAN: End-to-End Generative Adversarial Network for Multivariate Time Series Imputation",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/ijcai/Luo0CY19",
                "MAG": "2964425131",
                "DOI": "10.24963/ijcai.2019/429",
                "CorpusId": 199466115
            },
            "abstract": "The missing values, appear in most of multivariate time series, prevent advanced analysis of multivariate time series data. Existing imputation approaches try to deal with missing values by deletion, statistical imputation, machine learning based imputation and generative imputation. However, these methods are either incapable of dealing with temporal information or multi-stage. This paper proposes an end-to-end generative model E\u00b2GAN to impute missing values in multivariate time series. With the help of the discriminative loss and the squared error loss, E\u00b2GAN can impute the incomplete time series by the nearest generated complete time series at one stage. Experiments on multiple real-world datasets show that our model outperforms the baselines on the imputation accuracy and achieves state-of-the-art classification/regression results on the downstream applications. Additionally, our method also gains better time efficiency than multi-stage method on the training of neural networks.",
            "referenceCount": 32,
            "citationCount": 135,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.ijcai.org/proceedings/2019/0429.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-08-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Luo2019E\u00b2GANEG,\n author = {Yonghong Luo and Ying Zhang and Xiangrui Cai and Xiaojie Yuan},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {3094-3100},\n title = {E\u00b2GAN: End-to-End Generative Adversarial Network for Multivariate Time Series Imputation},\n year = {2019}\n}\n"
            }
        }
    }
]