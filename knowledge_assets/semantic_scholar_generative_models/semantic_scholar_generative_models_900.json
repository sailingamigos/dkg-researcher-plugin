[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ad22b61cb977377cc422b0b39a0bc5c58f1ab1ea",
            "@type": "ScholarlyArticle",
            "paperId": "ad22b61cb977377cc422b0b39a0bc5c58f1ab1ea",
            "corpusId": 2957616,
            "url": "https://www.semanticscholar.org/paper/ad22b61cb977377cc422b0b39a0bc5c58f1ab1ea",
            "title": "Natural speech reveals the semantic maps that tile human cerebral cortex",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/nature/HuthHGTG16",
                "PubMedCentral": "4852309",
                "MAG": "2344975321",
                "DOI": "10.1038/nature17637",
                "CorpusId": 2957616,
                "PubMed": "27121839"
            },
            "abstract": null,
            "referenceCount": 78,
            "citationCount": 948,
            "influentialCitationCount": 53,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc4852309?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-03-08",
            "journal": {
                "name": "Nature",
                "volume": "532"
            },
            "citationStyles": {
                "bibtex": "@Article{Huth2016NaturalSR,\n author = {Alexander G. Huth and Wendy A. de Heer and T. Griffiths and F. Theunissen and J. Gallant},\n booktitle = {Nature},\n journal = {Nature},\n pages = {453 - 458},\n title = {Natural speech reveals the semantic maps that tile human cerebral cortex},\n volume = {532},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6745c95b88ff9b12401a9ba6f4007f036be591a0",
            "@type": "ScholarlyArticle",
            "paperId": "6745c95b88ff9b12401a9ba6f4007f036be591a0",
            "corpusId": 3833554,
            "url": "https://www.semanticscholar.org/paper/6745c95b88ff9b12401a9ba6f4007f036be591a0",
            "title": "Wasserstein Auto-Encoders",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2951235461",
                "ArXiv": "1711.01558",
                "DBLP": "conf/iclr/TolstikhinBGS18",
                "CorpusId": 3833554
            },
            "abstract": "We propose the Wasserstein Auto-Encoder (WAE)---a new algorithm for building a generative model of the data distribution. WAE minimizes a penalized form of the Wasserstein distance between the model distribution and the target distribution, which leads to a different regularizer than the one used by the Variational Auto-Encoder (VAE). This regularizer encourages the encoded training distribution to match the prior. We compare our algorithm with several other techniques and show that it is a generalization of adversarial auto-encoders (AAE). Our experiments show that WAE shares many of the properties of VAEs (stable training, encoder-decoder architecture, nice latent manifold structure) while generating samples of better quality, as measured by the FID score.",
            "referenceCount": 38,
            "citationCount": 841,
            "influentialCitationCount": 166,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1711.01558"
            },
            "citationStyles": {
                "bibtex": "@Article{Tolstikhin2017WassersteinA,\n author = {Ilya O. Tolstikhin and Olivier Bousquet and Sylvain Gelly and B. Sch\u00f6lkopf},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Wasserstein Auto-Encoders},\n volume = {abs/1711.01558},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9873d43696165b50fab955d27b9dde838c0a0152",
            "@type": "ScholarlyArticle",
            "paperId": "9873d43696165b50fab955d27b9dde838c0a0152",
            "corpusId": 26580409,
            "url": "https://www.semanticscholar.org/paper/9873d43696165b50fab955d27b9dde838c0a0152",
            "title": "Machine learning applications in genetics and genomics",
            "venue": "Nature reviews genetics",
            "publicationVenue": {
                "id": "urn:research:f44976b5-2cb9-402a-bc59-6a174239987b",
                "name": "Nature reviews genetics",
                "alternate_names": [
                    "Nature Reviews Genetics",
                    "Nat rev genet",
                    "Nat Rev Genet"
                ],
                "issn": "1471-0056",
                "url": "https://www.nature.com/nrg/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1505191356",
                "DOI": "10.1038/nrg3920",
                "CorpusId": 26580409,
                "PubMed": "25948244"
            },
            "abstract": null,
            "referenceCount": 81,
            "citationCount": 1334,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc5204302?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2015-05-07",
            "journal": {
                "name": "Nature Reviews Genetics",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Libbrecht2015MachineLA,\n author = {Maxwell W. Libbrecht and William Stafford Noble},\n booktitle = {Nature reviews genetics},\n journal = {Nature Reviews Genetics},\n pages = {321-332},\n title = {Machine learning applications in genetics and genomics},\n volume = {16},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4a57168f335b1cca5620e82b7f1c062cd9fa334a",
            "@type": "ScholarlyArticle",
            "paperId": "4a57168f335b1cca5620e82b7f1c062cd9fa334a",
            "corpusId": 153845082,
            "url": "https://www.semanticscholar.org/paper/4a57168f335b1cca5620e82b7f1c062cd9fa334a",
            "title": "Market Orientation, Generative Learning, Innovation Strategy and Business Performance Inter-Relationships in Bioscience Firms",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2023927111",
                "DOI": "10.1111/j.1467-6486.2008.00778.x",
                "CorpusId": 153845082
            },
            "abstract": "We propose conceptual arguments to establish relationships between market orientation and generative learning and their respective impact on exploitative innovation strategy and explorative innovation strategy. We then consider the ambidextrous association between both forms of innovation strategy and business performance. This model is subject to an empirical test using data generated from 160 bioscience firms. Using structural equation modelling, two mutually exclusive paths are specified where market orientation leads to exploitative innovation strategy, while generative learning leads to explorative innovation strategy. We then find that the ambidexterity exhibited by firms in the form of exploitative innovation strategy and explorative innovation strategy significantly explains improvements in firms\u2019 business performance. Discussion is given to these findings and managerial implications are presented along with avenues for further research.",
            "referenceCount": 107,
            "citationCount": 282,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Economics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Economics",
                    "source": "external"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2008-11-21",
            "journal": {
                "name": "Entrepreneurship",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Morgan2008MarketOG,\n author = {R. Morgan and P. Berthon},\n journal = {Entrepreneurship},\n title = {Market Orientation, Generative Learning, Innovation Strategy and Business Performance Inter-Relationships in Bioscience Firms},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9a592e2dd099aa42b5595b243b71a2c6fc6257f8",
            "@type": "ScholarlyArticle",
            "paperId": "9a592e2dd099aa42b5595b243b71a2c6fc6257f8",
            "corpusId": 9769108,
            "url": "https://www.semanticscholar.org/paper/9a592e2dd099aa42b5595b243b71a2c6fc6257f8",
            "title": "Generative and discriminative algorithms for spoken language understanding",
            "venue": "Interspeech",
            "publicationVenue": {
                "id": "urn:research:af90489e-312f-4514-bea2-bcb399cb8ece",
                "name": "Interspeech",
                "alternate_names": [
                    "Conf Int Speech Commun Assoc",
                    "INTERSPEECH",
                    "Conference of the International Speech Communication Association"
                ],
                "issn": "2308-457X",
                "url": "https://www.isca-speech.org/iscaweb/index.php/conferences/interspeech"
            },
            "year": 2007,
            "externalIds": {
                "MAG": "2166293310",
                "DBLP": "conf/interspeech/RaymondR07",
                "DOI": "10.21437/Interspeech.2007-448",
                "CorpusId": 9769108
            },
            "abstract": "Spoken Language Understanding (SLU) for conversational systems (SDS) aims at extracting concept and their relations from spontaneous speech. Previous approaches to SLU have modeled concept relations as stochastic semantic networks ranging from generative approach to discriminative. As spoken dialog systems complexity increases, SLU needs to perform understanding based on a richer set of features ranging from a-priori knowledge, long dependency, dialog history, system belief, etc. This paper studies generative and discriminative approaches to modeling the sentence segmentation and concept labeling. We evaluate algorithms based on Finite State Transducers (FST) as well as discriminative algorithms based on Support Vector Machine sequence classifier based and Conditional Random Fields (CRF). We compare them in terms of concept accuracy, generalization and robustness to annotation ambiguities. We also show how non-local non-lexical features (e.g. a-priori knowledge) can be modeled with CRF which is the best performing algorithm across tasks. The evaluation is carried out on two SLU tasks of different complexity, namely ATIS and MEDIA corpora.",
            "referenceCount": 11,
            "citationCount": 323,
            "influentialCitationCount": 35,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://hal.inria.fr/hal-02949194/document",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Raymond2007GenerativeAD,\n author = {C. Raymond and G. Riccardi},\n booktitle = {Interspeech},\n pages = {1605-1608},\n title = {Generative and discriminative algorithms for spoken language understanding},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bb1a17010254abfa5e1f2a17553582ce449f8e16",
            "@type": "ScholarlyArticle",
            "paperId": "bb1a17010254abfa5e1f2a17553582ce449f8e16",
            "corpusId": 1731857,
            "url": "https://www.semanticscholar.org/paper/bb1a17010254abfa5e1f2a17553582ce449f8e16",
            "title": "Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2950564096",
                "DBLP": "conf/nips/WatterSBR15",
                "ArXiv": "1506.07365",
                "CorpusId": 1731857
            },
            "abstract": "We introduce Embed to Control (E2C), a method for model learning and control of non-linear dynamical systems from raw pixel images. E2C consists of a deep generative model, belonging to the family of variational autoencoders, that learns to generate image trajectories from a latent space in which the dynamics is constrained to be locally linear. Our model is derived directly from an optimal control formulation in latent space, supports long-term prediction of image sequences and exhibits strong performance on a variety of complex control problems.",
            "referenceCount": 49,
            "citationCount": 739,
            "influentialCitationCount": 70,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-06-24",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1506.07365"
            },
            "citationStyles": {
                "bibtex": "@Article{Watter2015EmbedTC,\n author = {Manuel Watter and J. T. Springenberg and J. Boedecker and Martin A. Riedmiller},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},\n volume = {abs/1506.07365},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e",
            "@type": "ScholarlyArticle",
            "paperId": "62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e",
            "corpusId": 8289133,
            "url": "https://www.semanticscholar.org/paper/62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e",
            "title": "Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2463955103",
                "DBLP": "journals/corr/VinyalsTBE16",
                "ArXiv": "1609.06647",
                "DOI": "10.1109/TPAMI.2016.2587640",
                "CorpusId": 8289133,
                "PubMed": "28055847"
            },
            "abstract": "Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. Finally, given the recent surge of interest in this task, a competition was organized in 2015 using the newly released COCO dataset. We describe and analyze the various improvements we applied to our own baseline and show the resulting performance in the competition, which we won ex-aequo with a team from Microsoft Research.",
            "referenceCount": 55,
            "citationCount": 766,
            "influentialCitationCount": 104,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1609.06647",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-21",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "39"
            },
            "citationStyles": {
                "bibtex": "@Article{Vinyals2016ShowAT,\n author = {Oriol Vinyals and Alexander Toshev and Samy Bengio and D. Erhan},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {652-663},\n title = {Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge},\n volume = {39},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cd1758d3b86c4f1caf01ec222b45daf15888d1a8",
            "@type": "ScholarlyArticle",
            "paperId": "cd1758d3b86c4f1caf01ec222b45daf15888d1a8",
            "corpusId": 4685015,
            "url": "https://www.semanticscholar.org/paper/cd1758d3b86c4f1caf01ec222b45daf15888d1a8",
            "title": "MMD GAN: Towards Deeper Understanding of Moment Matching Network",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2962892300",
                "ArXiv": "1705.08584",
                "DBLP": "conf/nips/LiCCYP17",
                "CorpusId": 4685015
            },
            "abstract": "Generative moment matching network (GMMN) is a deep generative model that differs from Generative Adversarial Network (GAN) by replacing the discriminator in GAN with a two-sample test based on kernel maximum mean discrepancy (MMD). Although some theoretical guarantees of MMD have been studied, the empirical performance of GMMN is still not as competitive as that of GAN on challenging and large benchmark datasets. The computational efficiency of GMMN is also less desirable in comparison with GAN, partially due to its requirement for a rather large batch size during the training. In this paper, we propose to improve both the model expressiveness of GMMN and its computational efficiency by introducing adversarial kernel learning techniques, as the replacement of a fixed Gaussian kernel in the original GMMN. The new approach combines the key ideas in both GMMN and GAN, hence we name it MMD GAN. The new distance measure in MMD GAN is a meaningful loss that enjoys the advantage of weak topology and can be optimized via gradient descent with relatively small batch sizes. In our evaluation on multiple benchmark datasets, including MNIST, CIFAR- 10, CelebA and LSUN, the performance of MMD-GAN significantly outperforms GMMN, and is competitive with other representative GAN works.",
            "referenceCount": 39,
            "citationCount": 615,
            "influentialCitationCount": 104,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-05-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Li2017MMDGT,\n author = {Chun-Liang Li and Wei-Cheng Chang and Yu Cheng and Yiming Yang and B. P\u00f3czos},\n booktitle = {Neural Information Processing Systems},\n pages = {2203-2213},\n title = {MMD GAN: Towards Deeper Understanding of Moment Matching Network},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d77bc27d16a362e5e1b727904c3789355dda6062",
            "@type": "ScholarlyArticle",
            "paperId": "d77bc27d16a362e5e1b727904c3789355dda6062",
            "corpusId": 2978311,
            "url": "https://www.semanticscholar.org/paper/d77bc27d16a362e5e1b727904c3789355dda6062",
            "title": "Molecular de-novo design through deep reinforcement learning",
            "venue": "Journal of Cheminformatics",
            "publicationVenue": {
                "id": "urn:research:fd4675fe-4136-446c-aefd-3658aae698ac",
                "name": "Journal of Cheminformatics",
                "alternate_names": [
                    "J Cheminformatics"
                ],
                "issn": "1758-2946",
                "url": "https://jcheminf.biomedcentral.com/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2949437520",
                "DBLP": "journals/corr/OlivecronaBEC17",
                "PubMedCentral": "5583141",
                "ArXiv": "1704.07555",
                "DOI": "10.1186/s13321-017-0235-x",
                "CorpusId": 2978311,
                "PubMed": "29086083"
            },
            "abstract": null,
            "referenceCount": 48,
            "citationCount": 754,
            "influentialCitationCount": 53,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://jcheminf.biomedcentral.com/track/pdf/10.1186/s13321-017-0235-x",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-04-25",
            "journal": {
                "name": "Journal of Cheminformatics",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Olivecrona2017MolecularDD,\n author = {Marcus Olivecrona and T. Blaschke and O. Engkvist and Hongming Chen},\n booktitle = {Journal of Cheminformatics},\n journal = {Journal of Cheminformatics},\n title = {Molecular de-novo design through deep reinforcement learning},\n volume = {9},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fe2aaad872a2cf08c09dd52ca972f323666306db",
            "@type": "ScholarlyArticle",
            "paperId": "fe2aaad872a2cf08c09dd52ca972f323666306db",
            "corpusId": 15725489,
            "url": "https://www.semanticscholar.org/paper/fe2aaad872a2cf08c09dd52ca972f323666306db",
            "title": "Robust object tracking via sparsity-based collaborative model",
            "venue": "2012 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "conf/cvpr/ZhongLY12",
                "MAG": "2016075127",
                "DOI": "10.1109/CVPR.2012.6247882",
                "CorpusId": 15725489
            },
            "abstract": "In this paper we propose a robust object tracking algorithm using a collaborative model. As the main challenge for object tracking is to account for drastic appearance change, we propose a robust appearance model that exploits both holistic templates and local representations. We develop a sparsity-based discriminative classifier (SD-C) and a sparsity-based generative model (SGM). In the S-DC module, we introduce an effective method to compute the confidence value that assigns more weights to the foreground than the background. In the SGM module, we propose a novel histogram-based method that takes the spatial information of each patch into consideration with an occlusion handing scheme. Furthermore, the update scheme considers both the latest observations and the original template, thereby enabling the tracker to deal with appearance change effectively and alleviate the drift problem. Numerous experiments on various challenging videos demonstrate that the proposed tracker performs favorably against several state-of-the-art algorithms.",
            "referenceCount": 35,
            "citationCount": 1019,
            "influentialCitationCount": 183,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://faculty.ucmerced.edu/mhyang/papers/cvpr12b.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-06-16",
            "journal": {
                "name": "2012 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhong2012RobustOT,\n author = {Wei Zhong and Huchuan Lu and Ming-Hsuan Yang},\n booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {1838-1845},\n title = {Robust object tracking via sparsity-based collaborative model},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:29afab1cb2d8ad8d37bd6f4a1adec42e131799fe",
            "@type": "ScholarlyArticle",
            "paperId": "29afab1cb2d8ad8d37bd6f4a1adec42e131799fe",
            "corpusId": 18500294,
            "url": "https://www.semanticscholar.org/paper/29afab1cb2d8ad8d37bd6f4a1adec42e131799fe",
            "title": "Invertible Conditional GANs for image editing",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2552611751",
                "ArXiv": "1611.06355",
                "DBLP": "journals/corr/PerarnauWRA16",
                "CorpusId": 18500294
            },
            "abstract": "Generative Adversarial Networks (GANs) have recently demonstrated to successfully approximate complex data distributions. A relevant extension of this model is conditional GANs (cGANs), where the introduction of external information allows to determine specific representations of the generated images. In this work, we evaluate encoders to inverse the mapping of a cGAN, i.e., mapping a real image into a latent space and a conditional representation. This allows, for example, to reconstruct and modify real images of faces conditioning on arbitrary attributes. Additionally, we evaluate the design of cGANs. The combination of an encoder with a cGAN, which we call Invertible cGAN (IcGAN), enables to re-generate real images with deterministic complex modifications.",
            "referenceCount": 21,
            "citationCount": 604,
            "influentialCitationCount": 61,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-19",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1611.06355"
            },
            "citationStyles": {
                "bibtex": "@Article{Perarnau2016InvertibleCG,\n author = {Guim Perarnau and Joost van de Weijer and B. Raducanu and J. \u00c1lvarez},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Invertible Conditional GANs for image editing},\n volume = {abs/1611.06355},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:750cc7813da3559dfd653cfbbf56ca3356b3162f",
            "@type": "ScholarlyArticle",
            "paperId": "750cc7813da3559dfd653cfbbf56ca3356b3162f",
            "corpusId": 7036324,
            "url": "https://www.semanticscholar.org/paper/750cc7813da3559dfd653cfbbf56ca3356b3162f",
            "title": "Deep Convolutional Neural Network for Image Deconvolution",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2124964692",
                "DBLP": "conf/nips/XuRLJ14",
                "CorpusId": 7036324
            },
            "abstract": "Many fundamental image-related problems involve deconvolution operators. Real blur degradation seldom complies with an ideal linear convolution model due to camera noise, saturation, image compression, to name a few. Instead of perfectly modeling outliers, which is rather challenging from a generative model perspective, we develop a deep convolutional neural network to capture the characteristics of degradation. We note directly applying existing deep neural networks does not produce reasonable results. Our solution is to establish the connection between traditional optimization-based schemes and a neural network architecture where a novel, separable structure is introduced as a reliable support for robust deconvolution against artifacts. Our network contains two submodules, both trained in a supervised manner with proper initialization. They yield decent performance on non-blind image deconvolution compared to previous generative-model based methods.",
            "referenceCount": 27,
            "citationCount": 855,
            "influentialCitationCount": 39,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-12-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Xu2014DeepCN,\n author = {Li Xu and Jimmy S. J. Ren and Ce Liu and Jiaya Jia},\n booktitle = {Neural Information Processing Systems},\n pages = {1790-1798},\n title = {Deep Convolutional Neural Network for Image Deconvolution},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eeecea3097cf5629eb72a06e5caaf24d774adce7",
            "@type": "ScholarlyArticle",
            "paperId": "eeecea3097cf5629eb72a06e5caaf24d774adce7",
            "corpusId": 131777002,
            "url": "https://www.semanticscholar.org/paper/eeecea3097cf5629eb72a06e5caaf24d774adce7",
            "title": "Unsupervised label noise modeling and loss correction",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/icml/ArazoOAOM19",
                "MAG": "2952361104",
                "ArXiv": "1904.11238",
                "CorpusId": 131777002
            },
            "abstract": "Despite being robust to small amounts of label noise, convolutional neural networks trained with stochastic gradient methods have been shown to easily fit random labels. When there are a mixture of correct and mislabelled targets, networks \ntend to fit the former before the latter. This suggests using a suitable two-component mixture model as an unsupervised generative model of sample loss values during training to allow online estimation of the probability that a sample is mislabelled. Specifically, we propose a beta mixture to estimate this probability and correct the loss by relying on the network prediction (the so-called bootstrapping loss). We further adapt mixup augmentation to drive our approach a step further. Experiments on CIFAR-10/100 and TinyImageNet demonstrate a robustness to label noise that substantially outperforms recent state-of-the-art. Source code is available at https://git.io/fjsvE and Appendix at https://arxiv.org/abs/1904.11238.",
            "referenceCount": 44,
            "citationCount": 444,
            "influentialCitationCount": 64,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1904.11238"
            },
            "citationStyles": {
                "bibtex": "@Article{Sanchez2019UnsupervisedLN,\n author = {Eric Arazo Sanchez and Diego Ortego and Paul Albert and N. O\u2019Connor and Kevin McGuinness},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Unsupervised label noise modeling and loss correction},\n volume = {abs/1904.11238},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1d6b8803f6f6b188802275210eb5d7839644a8b5",
            "@type": "ScholarlyArticle",
            "paperId": "1d6b8803f6f6b188802275210eb5d7839644a8b5",
            "corpusId": 128358697,
            "url": "https://www.semanticscholar.org/paper/1d6b8803f6f6b188802275210eb5d7839644a8b5",
            "title": "DAG-GNN: DAG Structure Learning with Graph Neural Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1904-10098",
                "MAG": "2949607454",
                "ArXiv": "1904.10098",
                "CorpusId": 128358697
            },
            "abstract": "Learning a faithful directed acyclic graph (DAG) from samples of a joint distribution is a challenging combinatorial problem, owing to the intractable search space superexponential in the number of graph nodes. A recent breakthrough formulates the problem as a continuous optimization with a structural constraint that ensures acyclicity (Zheng et al., 2018). The authors apply the approach to the linear structural equation model (SEM) and the least-squares loss function that are statistically well justified but nevertheless limited. Motivated by the widespread success of deep learning that is capable of capturing complex nonlinear mappings, in this work we propose a deep generative model and apply a variant of the structural constraint to learn the DAG. At the heart of the generative model is a variational autoencoder parameterized by a novel graph neural network architecture, which we coin DAG-GNN. In addition to the richer capacity, an advantage of the proposed model is that it naturally handles discrete variables as well as vector-valued ones. We demonstrate that on synthetic data sets, the proposed method learns more accurate graphs for nonlinearly generated samples; and on benchmark data sets with discrete variables, the learned graphs are reasonably close to the global optima. The code is available at \\url{this https URL}.",
            "referenceCount": 54,
            "citationCount": 311,
            "influentialCitationCount": 86,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-22",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yu2019DAGGNNDS,\n author = {Yue Yu and Jie Chen and Tian Gao and Mo Yu},\n booktitle = {International Conference on Machine Learning},\n pages = {7154-7163},\n title = {DAG-GNN: DAG Structure Learning with Graph Neural Networks},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:913f0771782023e2bf400e4d344eab7d2a674d23",
            "@type": "ScholarlyArticle",
            "paperId": "913f0771782023e2bf400e4d344eab7d2a674d23",
            "corpusId": 199552250,
            "url": "https://www.semanticscholar.org/paper/913f0771782023e2bf400e4d344eab7d2a674d23",
            "title": "Online Continual Learning with Maximally Interfered Retrieval",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/nips/AljundiBTCCLP19",
                "MAG": "2971176100",
                "ArXiv": "1908.04742",
                "CorpusId": 199552250
            },
            "abstract": "Continual learning, the setting where a learning agent is faced with a never ending stream of data, continues to be a great challenge for modern machine learning systems. In particular the online or \"single-pass through the data\" setting has gained attention recently as a natural setting that is difficult to tackle. Methods based on replay, either generative or from a stored memory, have been shown to be effective approaches for continual learning, matching or exceeding the state of the art in a number of standard benchmarks. These approaches typically rely on randomly selecting samples from the replay memory or from a generative model, which is suboptimal. In this work, we consider a controlled sampling of memories for replay. We retrieve the samples which are most interfered, i.e. whose prediction will be most negatively impacted by the foreseen parameters update. We show a formulation for this sampling criterion in both the generative replay and the experience replay setting, producing consistent gains in performance and greatly reduced forgetting. We release an implementation of our method at this https URL.",
            "referenceCount": 42,
            "citationCount": 343,
            "influentialCitationCount": 91,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-08-11",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1908.04742"
            },
            "citationStyles": {
                "bibtex": "@Article{Aljundi2019OnlineCL,\n author = {Rahaf Aljundi and Lucas Caccia and Eugene Belilovsky and Massimo Caccia and Min Lin and Laurent Charlin and T. Tuytelaars},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Online Continual Learning with Maximally Interfered Retrieval},\n volume = {abs/1908.04742},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c6bd5bdfa2c633273eced669715051abd7275081",
            "@type": "ScholarlyArticle",
            "paperId": "c6bd5bdfa2c633273eced669715051abd7275081",
            "corpusId": 1203477,
            "url": "https://www.semanticscholar.org/paper/c6bd5bdfa2c633273eced669715051abd7275081",
            "title": "Online Tracking and Reacquisition Using Co-trained Generative and Discriminative Trackers",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2161160446",
                "DBLP": "conf/eccv/YuDM08",
                "DOI": "10.1007/978-3-540-88688-4_50",
                "CorpusId": 1203477
            },
            "abstract": null,
            "referenceCount": 34,
            "citationCount": 248,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-10-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yu2008OnlineTA,\n author = {Qian Yu and T. Dinh and G. Medioni},\n booktitle = {European Conference on Computer Vision},\n pages = {678-691},\n title = {Online Tracking and Reacquisition Using Co-trained Generative and Discriminative Trackers},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8978cf7574ceb35f4c3096be768c7547b28a35d0",
            "@type": "ScholarlyArticle",
            "paperId": "8978cf7574ceb35f4c3096be768c7547b28a35d0",
            "corpusId": 2309950,
            "url": "https://www.semanticscholar.org/paper/8978cf7574ceb35f4c3096be768c7547b28a35d0",
            "title": "A Fast Learning Algorithm for Deep Belief Nets",
            "venue": "Neural Computation",
            "publicationVenue": {
                "id": "urn:research:69b9bcdd-8229-4a00-a6e0-00f0e99a2bf3",
                "name": "Neural Computation",
                "alternate_names": [
                    "Neural Comput"
                ],
                "issn": "0899-7667",
                "url": "http://cognet.mit.edu/library/journals/journal?issn=08997667"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "journals/neco/HintonOT06",
                "MAG": "2136922672",
                "DOI": "10.1162/neco.2006.18.7.1527",
                "CorpusId": 2309950,
                "PubMed": "16764513"
            },
            "abstract": "We show how to use complementary priors to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.",
            "referenceCount": 32,
            "citationCount": 15154,
            "influentialCitationCount": 1269,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-07-01",
            "journal": {
                "name": "Neural Computation",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Hinton2006AFL,\n author = {Geoffrey E. Hinton and Simon Osindero and Y. Teh},\n booktitle = {Neural Computation},\n journal = {Neural Computation},\n pages = {1527-1554},\n title = {A Fast Learning Algorithm for Deep Belief Nets},\n volume = {18},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:355d44f53428b1ac4fb2ab468d593c720640e5bd",
            "@type": "ScholarlyArticle",
            "paperId": "355d44f53428b1ac4fb2ab468d593c720640e5bd",
            "corpusId": 14201947,
            "url": "https://www.semanticscholar.org/paper/355d44f53428b1ac4fb2ab468d593c720640e5bd",
            "title": "Greedy Layer-Wise Training of Deep Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2110798204",
                "DBLP": "conf/nips/BengioLPL06",
                "DOI": "10.7551/mitpress/7503.003.0024",
                "CorpusId": 14201947
            },
            "abstract": "Complexity theory of circuits strongly suggests that deep architectures can be much more efficient (sometimes exponentially) than shallow architectures, in terms of computational elements required to represent some functions. Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization appears to often get stuck in poor solutions. Hinton et al. recently introduced a greedy layer-wise unsupervised learning algorithm for Deep Belief Networks (DBN), a generative model with many layers of hidden causal variables. In the context of the above optimization problem, we study this algorithm empirically and explore variants to better understand its success and extend it to cases where the inputs are continuous or where the structure of the input distribution is not revealing enough about the variable to be predicted in a supervised task. Our experiments also confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization.",
            "referenceCount": 18,
            "citationCount": 4369,
            "influentialCitationCount": 240,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.iro.umontreal.ca/~lisa/pointeurs/BengioNips2006All.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-12-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bengio2006GreedyLT,\n author = {Yoshua Bengio and Pascal Lamblin and D. Popovici and H. Larochelle},\n booktitle = {Neural Information Processing Systems},\n pages = {153-160},\n title = {Greedy Layer-Wise Training of Deep Networks},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:76ad25c4d0693d17710fb4f334c6ef68b732a624",
            "@type": "ScholarlyArticle",
            "paperId": "76ad25c4d0693d17710fb4f334c6ef68b732a624",
            "corpusId": 44203020,
            "url": "https://www.semanticscholar.org/paper/76ad25c4d0693d17710fb4f334c6ef68b732a624",
            "title": "Emotion regulation: affective, cognitive, and social consequences.",
            "venue": "Psychophysiology",
            "publicationVenue": {
                "id": "urn:research:95dce940-1e26-496f-8a8b-9f9692c5c75c",
                "name": "Psychophysiology",
                "alternate_names": null,
                "issn": "0048-5772",
                "url": "http://www.wiley.com/bw/journal.asp?ref=0048-5772"
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2128126978",
                "DOI": "10.1017/S0048577201393198",
                "CorpusId": 44203020,
                "PubMed": "12212647"
            },
            "abstract": "One of life's great challenges is successfully regulating emotions. Do some emotion regulation strategies have more to recommend them than others? According to Gross's (1998, Review of General Psychology, 2, 271-299) process model of emotion regulation, strategies that act early in the emotion-generative process should have a different profile of consequences than strategies that act later on. This review focuses on two commonly used strategies for down-regulating emotion. The first, reappraisal, comes early in the emotion-generative process. It consists of changing the way a situation is construed so as to decrease its emotional impact. The second, suppression, comes later in the emotion-generative process. It consists of inhibiting the outward signs of inner feelings. Experimental and individual-difference studies find reappraisal is often more effective than suppression. Reappraisal decreases emotion experience and behavioral expression, and has no impact on memory. By contrast, suppression decreases behavioral expression, but fails to decrease emotion experience, and actually impairs memory. Suppression also increases physiological responding for suppressors and their social partners. This review concludes with a consideration of five important directions for future research on emotion regulation processes.",
            "referenceCount": 82,
            "citationCount": 3720,
            "influentialCitationCount": 323,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1017/S0048577201393198",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2002-05-01",
            "journal": {
                "name": "Psychophysiology",
                "volume": "39 3"
            },
            "citationStyles": {
                "bibtex": "@Article{Gross2002EmotionRA,\n author = {J. Gross},\n booktitle = {Psychophysiology},\n journal = {Psychophysiology},\n pages = {\n          281-91\n        },\n title = {Emotion regulation: affective, cognitive, and social consequences.},\n volume = {39 3},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c492df10235da26b3dbe574fbdbae73e6f7de52d",
            "@type": "ScholarlyArticle",
            "paperId": "c492df10235da26b3dbe574fbdbae73e6f7de52d",
            "corpusId": 686980,
            "url": "https://www.semanticscholar.org/paper/c492df10235da26b3dbe574fbdbae73e6f7de52d",
            "title": "Text Classification from Labeled and Unlabeled Documents using EM",
            "venue": "Machine-mediated learning",
            "publicationVenue": {
                "id": "urn:research:22c9862f-a25e-40cd-9d31-d09e68a293e6",
                "name": "Machine-mediated learning",
                "alternate_names": [
                    "Mach learn",
                    "Machine Learning",
                    "Mach Learn"
                ],
                "issn": "0732-6718",
                "url": "http://www.springer.com/computer/artificial/journal/10994"
            },
            "year": 2000,
            "externalIds": {
                "DBLP": "journals/ml/NigamMTM00",
                "MAG": "2097089247",
                "DOI": "10.1023/A:1007692713085",
                "CorpusId": 686980
            },
            "abstract": null,
            "referenceCount": 63,
            "citationCount": 3192,
            "influentialCitationCount": 217,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1023/A:1007692713085.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2000-05-01",
            "journal": {
                "name": "Machine Learning",
                "volume": "39"
            },
            "citationStyles": {
                "bibtex": "@Article{Nigam2000TextCF,\n author = {K. Nigam and A. McCallum and S. Thrun and Tom Michael Mitchell},\n booktitle = {Machine-mediated learning},\n journal = {Machine Learning},\n pages = {103-134},\n title = {Text Classification from Labeled and Unlabeled Documents using EM},\n volume = {39},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:baf822e8e772853e88170a37f1c3d32018adf7f1",
            "@type": "ScholarlyArticle",
            "paperId": "baf822e8e772853e88170a37f1c3d32018adf7f1",
            "corpusId": 6236938,
            "url": "https://www.semanticscholar.org/paper/baf822e8e772853e88170a37f1c3d32018adf7f1",
            "title": "The Emerging Field of Emotion Regulation: An Integrative Review",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "MAG": "2096423181",
                "DOI": "10.1037/1089-2680.2.3.271",
                "CorpusId": 6236938
            },
            "abstract": "The emerging field of emotion regulation studies how individuals influence which emotions they have, when they have them, and how they experience and express them. This review takes an evolutionary perspective and characterizes emotion in terms of response tendencies. Emotion regulation is defined and distinguished from coping, mood regulation, defense, and affect regulation. In the increasingly specialized discipline of psychology, the field of emotion regulation cuts across traditional boundaries and provides common ground. According to a process model of emotion regulation, emotion may be regulated at five points in the emotion generative process: (a) selection of the situation, (b) modification of the situation, (c) deployment of attention, (d) change of cognitions, and (e) modulation of responses. The field of emotion regulation promises new insights into age-old questions about how people manage their emotions.",
            "referenceCount": 380,
            "citationCount": 7276,
            "influentialCitationCount": 941,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1998-09-01",
            "journal": {
                "name": "Review of General Psychology",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Gross1998TheEF,\n author = {J. Gross},\n journal = {Review of General Psychology},\n pages = {271 - 299},\n title = {The Emerging Field of Emotion Regulation: An Integrative Review},\n volume = {2},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e99f196cf21e0781ef1e119d14e6db45cd71bf3b",
            "@type": "ScholarlyArticle",
            "paperId": "e99f196cf21e0781ef1e119d14e6db45cd71bf3b",
            "corpusId": 15671300,
            "url": "https://www.semanticscholar.org/paper/e99f196cf21e0781ef1e119d14e6db45cd71bf3b",
            "title": "Finding scientific topics",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2001082470",
                "DOI": "10.1073/PNAS.0307752101",
                "CorpusId": 15671300,
                "PubMed": "14872004"
            },
            "abstract": "A first step in identifying the content of a document is determining which topics that document addresses. We describe a generative model for documents, introduced by Blei, Ng, and Jordan [Blei, D. M., Ng, A. Y. & Jordan, M. I. (2003) J. Machine Learn. Res. 3, 993-1022], in which each document is generated by choosing a distribution over topics and then choosing each word in the document from a topic selected according to this distribution. We then present a Markov chain Monte Carlo algorithm for inference in this model. We use this algorithm to analyze abstracts from PNAS by using Bayesian model selection to establish the number of topics. We show that the extracted topics capture meaningful structure in the data, consistent with the class designations provided by the authors of the articles, and outline further applications of this analysis, including identifying \u201chot topics\u201d by examining temporal dynamics and tagging abstracts to illustrate semantic content.",
            "referenceCount": 19,
            "citationCount": 6102,
            "influentialCitationCount": 660,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc387300?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2004-04-06",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "volume": "101"
            },
            "citationStyles": {
                "bibtex": "@Article{Griffiths2004FindingST,\n author = {T. Griffiths and M. Steyvers},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences of the United States of America},\n pages = {5228 - 5235},\n title = {Finding scientific topics},\n volume = {101},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:573dfd36d62d4619196888e27beb946b3747716b",
            "@type": "ScholarlyArticle",
            "paperId": "573dfd36d62d4619196888e27beb946b3747716b",
            "corpusId": 1299275,
            "url": "https://www.semanticscholar.org/paper/573dfd36d62d4619196888e27beb946b3747716b",
            "title": "Independent Component Analysis",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "MAG": "1548802052",
                "DBLP": "books/wi/HyvarinenKO01",
                "DOI": "10.1002/0471221317",
                "CorpusId": 1299275
            },
            "abstract": "In this chapter, we discuss a statistical generative model called independent component analysis. It is basically a proper probabilistic formulation of the ideas underpinning sparse coding. It shows how sparse coding can be interpreted as providing a Bayesian prior, and answers some questions which were not properly answered in the sparse coding framework.",
            "referenceCount": 33,
            "citationCount": 5862,
            "influentialCitationCount": 984,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://hal.archives-ouvertes.fr/hal-00346684/file/Comon92-elsevier.pdf",
                "status": "CLOSED"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2001-05-18",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Choi2001IndependentCA,\n author = {Seungjin Choi},\n pages = {1-475},\n title = {Independent Component Analysis},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e6dd83b2aa34c806596fc619ff3fbccf5f9830ab",
            "@type": "ScholarlyArticle",
            "paperId": "e6dd83b2aa34c806596fc619ff3fbccf5f9830ab",
            "corpusId": 7605995,
            "url": "https://www.semanticscholar.org/paper/e6dd83b2aa34c806596fc619ff3fbccf5f9830ab",
            "title": "Unsupervised Learning by Probabilistic Latent Semantic Analysis",
            "venue": "Machine-mediated learning",
            "publicationVenue": {
                "id": "urn:research:22c9862f-a25e-40cd-9d31-d09e68a293e6",
                "name": "Machine-mediated learning",
                "alternate_names": [
                    "Mach learn",
                    "Machine Learning",
                    "Mach Learn"
                ],
                "issn": "0732-6718",
                "url": "http://www.springer.com/computer/artificial/journal/10994"
            },
            "year": 2004,
            "externalIds": {
                "DBLP": "journals/ml/Hofmann01",
                "MAG": "2134731454",
                "DOI": "10.1023/A:1007617005950",
                "CorpusId": 7605995
            },
            "abstract": null,
            "referenceCount": 25,
            "citationCount": 2585,
            "influentialCitationCount": 315,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1023/A:1007617005950.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Machine Learning",
                "volume": "42"
            },
            "citationStyles": {
                "bibtex": "@Article{Hofmann2004UnsupervisedLB,\n author = {Thomas Hofmann},\n booktitle = {Machine-mediated learning},\n journal = {Machine Learning},\n pages = {177-196},\n title = {Unsupervised Learning by Probabilistic Latent Semantic Analysis},\n volume = {42},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7457defc6df5e78c9e923681edd52adaa6582d91",
            "@type": "ScholarlyArticle",
            "paperId": "7457defc6df5e78c9e923681edd52adaa6582d91",
            "corpusId": 7758453,
            "url": "https://www.semanticscholar.org/paper/7457defc6df5e78c9e923681edd52adaa6582d91",
            "title": "A revisit of Generative Model for Automatic Image Annotation using Markov Random Fields",
            "venue": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2122829955",
                "DBLP": "conf/cvpr/XiangZCN09",
                "DOI": "10.1109/CVPR.2009.5206518",
                "CorpusId": 7758453
            },
            "abstract": "Much research effort on automatic image annotation (AIA) has been focused on generative model, due to its well formed theory and competitive performance as compared with many well designed and sophisticated methods. However, when considering semantic context for annotation, the model suffers from the weak learning ability. This is mainly due to the lack of parameter setting and appropriate learning strategy for characterizing the semantic context in the traditional generative model. In this paper, we present a new approach based on multiple Markov random fields (MRF) for semantic context modeling and learning. Differing from previous MRF related AIA approach; we explore the optimal parameter estimation and model inference systematically to leverage the learning power of traditional generative model. Specifically, we propose new potential function for site modeling based on generative model and build local graphs for each annotation keyword. The parameter estimation and model inference is performed in local optimal sense. We conduct experiments on commonly used benchmarks. On Corel 5000 images, we achieved 0.36 and 0.31 in recall and precision respectively on 263 keywords. This is a very significant improvement over the best reported result of the current state-of-the-art approaches.",
            "referenceCount": 17,
            "citationCount": 78,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2009-06-20",
            "journal": {
                "name": "2009 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Xiang2009ARO,\n author = {Yu Xiang and Xiangdong Zhou and Tat-Seng Chua and C. Ngo},\n booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2009 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {1153-1160},\n title = {A revisit of Generative Model for Automatic Image Annotation using Markov Random Fields},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8209a8703d8c48aaca1523cfa307dd1c069e58f3",
            "@type": "ScholarlyArticle",
            "paperId": "8209a8703d8c48aaca1523cfa307dd1c069e58f3",
            "corpusId": 53170360,
            "url": "https://www.semanticscholar.org/paper/8209a8703d8c48aaca1523cfa307dd1c069e58f3",
            "title": "ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2963101081",
                "DBLP": "journals/corr/abs-1811-00146",
                "ArXiv": "1811.00146",
                "DOI": "10.1609/AAAI.V33I01.33013027",
                "CorpusId": 53170360
            },
            "abstract": "We present ATOMIC, an atlas of everyday commonsense reasoning, organized through 877k textual descriptions of inferential knowledge. Compared to existing resources that center around taxonomic knowledge, ATOMIC focuses on inferential knowledge organized as typed if-then relations with variables (e.g., \u201cif X pays Y a compliment, then Y will likely return the compliment\u201d). We propose nine if-then relation types to distinguish causes vs. effects, agents vs. themes, voluntary vs. involuntary events, and actions vs. mental states. By generatively training on the rich inferential knowledge described in ATOMIC, we show that neural models can acquire simple commonsense capabilities and reason about previously unseen events. Experimental results demonstrate that multitask models that incorporate the hierarchical structure of if-then relation types lead to more accurate inference compared to models trained in isolation, as measured by both automatic and human evaluation.",
            "referenceCount": 29,
            "citationCount": 669,
            "influentialCitationCount": 174,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/4160/4038",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": null,
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1811.00146"
            },
            "citationStyles": {
                "bibtex": "@Article{Sap2019ATOMICAA,\n author = {Maarten Sap and Ronan Le Bras and Emily Allaway and Chandra Bhagavatula and Nicholas Lourie and Hannah Rashkin and Brendan Roof and Noah A. Smith and Yejin Choi},\n booktitle = {AAAI Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning},\n volume = {abs/1811.00146},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8a79ceca9606b20ce3c31f6552f7abd793696e94",
            "@type": "ScholarlyArticle",
            "paperId": "8a79ceca9606b20ce3c31f6552f7abd793696e94",
            "corpusId": 2482245,
            "url": "https://www.semanticscholar.org/paper/8a79ceca9606b20ce3c31f6552f7abd793696e94",
            "title": "MoFA: Model-Based Deep Convolutional Face Autoencoder for Unsupervised Monocular Reconstruction",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/iccv/TewariZK0BPT17",
                "ArXiv": "1703.10580",
                "MAG": "2952080583",
                "DOI": "10.1109/ICCV.2017.401",
                "CorpusId": 2482245
            },
            "abstract": "In this work we propose a novel model-based deep convolutional autoencoder that addresses the highly challenging problem of reconstructing a 3D human face from a single in-the-wild color image. To this end, we combine a convolutional encoder network with an expert-designed generative model that serves as decoder. The core innovation is the differentiable parametric decoder that encapsulates image formation analytically based on a generative model. Our decoder takes as input a code vector with exactly defined semantic meaning that encodes detailed face pose, shape, expression, skin reflectance and scene illumination. Due to this new way of combining CNN-based with model-based face reconstruction, the CNN-based encoder learns to extract semantically meaningful parameters from a single monocular input image. For the first time, a CNN encoder and an expert-designed generative model can be trained end-to-end in an unsupervised manner, which renders training on very large (unlabeled) real world data feasible. The obtained reconstructions compare favorably to current state-of-the-art approaches in terms of quality and richness of representation.",
            "referenceCount": 68,
            "citationCount": 493,
            "influentialCitationCount": 67,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1703.10580",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-30",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tewari2017MoFAMD,\n author = {A. Tewari and M. Zollh\u00f6fer and Hyeongwoo Kim and Pablo Garrido and Florian Bernard and P. P\u00e9rez and C. Theobalt},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2017 IEEE International Conference on Computer Vision (ICCV)},\n pages = {3735-3744},\n title = {MoFA: Model-Based Deep Convolutional Face Autoencoder for Unsupervised Monocular Reconstruction},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:23694b6d61668e62bb11f17c1d75dde3b4951948",
            "@type": "ScholarlyArticle",
            "paperId": "23694b6d61668e62bb11f17c1d75dde3b4951948",
            "corpusId": 12795415,
            "url": "https://www.semanticscholar.org/paper/23694b6d61668e62bb11f17c1d75dde3b4951948",
            "title": "Fisher Kernels on Visual Vocabularies for Image Categorization",
            "venue": "2007 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2007,
            "externalIds": {
                "DBLP": "conf/cvpr/PerronninD07",
                "MAG": "2147238549",
                "DOI": "10.1109/CVPR.2007.383266",
                "CorpusId": 12795415
            },
            "abstract": "Within the field of pattern classification, the Fisher kernel is a powerful framework which combines the strengths of generative and discriminative approaches. The idea is to characterize a signal with a gradient vector derived from a generative probability model and to subsequently feed this representation to a discriminative classifier. We propose to apply this framework to image categorization where the input signals are images and where the underlying generative model is a visual vocabulary: a Gaussian mixture model which approximates the distribution of low-level features in images. We show that Fisher kernels can actually be understood as an extension of the popular bag-of-visterms. Our approach demonstrates excellent performance on two challenging databases: an in-house database of 19 object/scene categories and the recently released VOC 2006 database. It is also very practical: it has low computational needs both at training and test time and vocabularies trained on one set of categories can be applied to another set without any significant loss in performance.",
            "referenceCount": 20,
            "citationCount": 1695,
            "influentialCitationCount": 179,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2007-06-17",
            "journal": {
                "name": "2007 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Perronnin2007FisherKO,\n author = {F. Perronnin and C. Dance},\n booktitle = {2007 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2007 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {1-8},\n title = {Fisher Kernels on Visual Vocabularies for Image Categorization},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c99046549cc75c057cc69caec7cbeeadb1641410",
            "@type": "ScholarlyArticle",
            "paperId": "c99046549cc75c057cc69caec7cbeeadb1641410",
            "corpusId": 143556967,
            "url": "https://www.semanticscholar.org/paper/c99046549cc75c057cc69caec7cbeeadb1641410",
            "title": "Learning as a Generative Process",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1974,
            "externalIds": {
                "MAG": "2005528162",
                "DOI": "10.1080/00461520903433554",
                "CorpusId": 143556967
            },
            "abstract": "A cognitive model of human learning with understanding is introduced. Empirical research supporting the model, which is called the generative model, is summarized. The model is used to suggest a way to integrate some of the research in cognitive development, human learning, human abilities, information processing, and aptitude-treatment interactions around the notion of transfer of experience and abilities.",
            "referenceCount": 17,
            "citationCount": 831,
            "influentialCitationCount": 36,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1974-11-01",
            "journal": {
                "name": "Educational Psychologist",
                "volume": "45"
            },
            "citationStyles": {
                "bibtex": "@Article{Wittrock1974LearningAA,\n author = {M. Wittrock},\n journal = {Educational Psychologist},\n pages = {40 - 45},\n title = {Learning as a Generative Process},\n volume = {45},\n year = {1974}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1959544588decb79a0b693d055aa7663eb776541",
            "@type": "ScholarlyArticle",
            "paperId": "1959544588decb79a0b693d055aa7663eb776541",
            "corpusId": 220845384,
            "url": "https://www.semanticscholar.org/paper/1959544588decb79a0b693d055aa7663eb776541",
            "title": "On the Quantum versus Classical Learnability of Discrete Distributions",
            "venue": "Quantum",
            "publicationVenue": {
                "id": "urn:research:15e7785d-fff7-4214-bf1d-bb4ded7ed461",
                "name": "Quantum",
                "alternate_names": null,
                "issn": "2521-327X",
                "url": "https://quantum-journal.org/"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2007.14451",
                "MAG": "3046071764",
                "DBLP": "journals/corr/abs-2007-14451",
                "DOI": "10.22331/Q-2021-03-23-417",
                "CorpusId": 220845384
            },
            "abstract": "Here we study the comparative power of classical and quantum learners for generative modelling within the Probably Approximately Correct (PAC) framework. More specifically we consider the following task: Given samples from some unknown discrete probability distribution, output with high probability an efficient algorithm for generating new samples from a good approximation of the original distribution. Our primary result is the explicit construction of a class of discrete probability distributions which, under the decisional Diffie-Hellman assumption, is provably not efficiently PAC learnable by a classical generative modelling algorithm, but for which we construct an efficient quantum learner. This class of distributions therefore provides a concrete example of a generative modelling problem for which quantum learners exhibit a provable advantage over classical learning algorithms. In addition, we discuss techniques for proving classical generative modelling hardness results, as well as the relationship between the PAC learnability of Boolean functions and the PAC learnability of discrete probability distributions.",
            "referenceCount": 70,
            "citationCount": 74,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://quantum-journal.org/papers/q-2021-03-23-417/pdf/",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-07-28",
            "journal": {
                "name": "Quantum",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Sweke2020OnTQ,\n author = {R. Sweke and Jean-Pierre Seifert and D. Hangleiter and J. Eisert},\n booktitle = {Quantum},\n journal = {Quantum},\n pages = {417},\n title = {On the Quantum versus Classical Learnability of Discrete Distributions},\n volume = {5},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c5c1229bc7126d7afaf73b571effe9211050c1b3",
            "@type": "ScholarlyArticle",
            "paperId": "c5c1229bc7126d7afaf73b571effe9211050c1b3",
            "corpusId": 182952603,
            "url": "https://www.semanticscholar.org/paper/c5c1229bc7126d7afaf73b571effe9211050c1b3",
            "title": "Global optimization of dielectric metasurfaces using a physics-driven neural network",
            "venue": "Nano letters (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1906-04157",
                "MAG": "2956449284",
                "ArXiv": "1906.04157",
                "DOI": "10.1021/acs.nanolett.9b01857",
                "CorpusId": 182952603,
                "PubMed": "31294997"
            },
            "abstract": "We present a global optimizer, based on a conditional generative neural network, which can output ensembles of highly efficient topology-optimized metasurfaces operating across a range of parameters. A key feature of the network is that it initially generates a distribution of devices that broadly samples the design space, and then shifts and refines this distribution towards favorable design space regions over the course of optimization. Training is performed by calculating the forward and adjoint electromagnetic simulations of outputted devices and using the subsequent efficiency gradients for backpropagation. With metagratings operating across a range of wavelengths and angles as a model system, we show that devices produced from the trained generative network have efficiencies comparable to or better than the best devices produced by adjoint-based topology optimization, while requiring less computational cost. Our reframing of adjoint-based optimization to the training of a generative neural network applies generally to physical systems that can utilize gradients to improve performance.",
            "referenceCount": 38,
            "citationCount": 247,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1906.04157",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-05-13",
            "journal": {
                "name": "Nano letters",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Jiang2019GlobalOO,\n author = {Jiaqi Jiang and Jonathan A. Fan},\n booktitle = {Nano letters (Print)},\n journal = {Nano letters},\n title = {Global optimization of dielectric metasurfaces using a physics-driven neural network},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2bee61b9a277f84592c7b3acc3d480b2c1ccb71b",
            "@type": "ScholarlyArticle",
            "paperId": "2bee61b9a277f84592c7b3acc3d480b2c1ccb71b",
            "corpusId": 10309149,
            "url": "https://www.semanticscholar.org/paper/2bee61b9a277f84592c7b3acc3d480b2c1ccb71b",
            "title": "A generative, probabilistic model of local protein structure",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2056568469",
                "DOI": "10.1073/pnas.0801715105",
                "CorpusId": 10309149,
                "PubMed": "18579771"
            },
            "abstract": "Despite significant progress in recent years, protein structure prediction maintains its status as one of the prime unsolved problems in computational biology. One of the key remaining challenges is an efficient probabilistic exploration of the structural space that correctly reflects the relative conformational stabilities. Here, we present a fully probabilistic, continuous model of local protein structure in atomic detail. The generative model makes efficient conformational sampling possible and provides a framework for the rigorous analysis of local sequence\u2013structure correlations in the native state. Our method represents a significant theoretical and practical improvement over the widely used fragment assembly technique by avoiding the drawbacks associated with a discrete and nonprobabilistic approach.",
            "referenceCount": 32,
            "citationCount": 159,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-07-01",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences",
                "volume": "105"
            },
            "citationStyles": {
                "bibtex": "@Article{Boomsma2008AGP,\n author = {Wouter Boomsma and K. Mardia and C. Taylor and J. Ferkinghoff-Borg and A. Krogh and T. Hamelryck},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {8932 - 8937},\n title = {A generative, probabilistic model of local protein structure},\n volume = {105},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:11e0b8c73127e2bd264a9e67bb9c9879b2e3fcc5",
            "@type": "ScholarlyArticle",
            "paperId": "11e0b8c73127e2bd264a9e67bb9c9879b2e3fcc5",
            "corpusId": 18629501,
            "url": "https://www.semanticscholar.org/paper/11e0b8c73127e2bd264a9e67bb9c9879b2e3fcc5",
            "title": "A Generative Shape Regularization Model for Robust Face Alignment",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2008,
            "externalIds": {
                "DBLP": "conf/eccv/GuK08",
                "MAG": "1499329969",
                "DOI": "10.1007/978-3-540-88682-2_32",
                "CorpusId": 18629501
            },
            "abstract": null,
            "referenceCount": 26,
            "citationCount": 159,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2F978-3-540-88682-2_32.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-10-20",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gu2008AGS,\n author = {Leon Gu and T. Kanade},\n booktitle = {European Conference on Computer Vision},\n pages = {413-426},\n title = {A Generative Shape Regularization Model for Robust Face Alignment},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:080ff994ebb101ac340e446344215f834eae0f6c",
            "@type": "ScholarlyArticle",
            "paperId": "080ff994ebb101ac340e446344215f834eae0f6c",
            "corpusId": 14885103,
            "url": "https://www.semanticscholar.org/paper/080ff994ebb101ac340e446344215f834eae0f6c",
            "title": "Generative Image Segmentation Using Random Walks with Restart",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2008,
            "externalIds": {
                "DBLP": "conf/eccv/KimLL08",
                "MAG": "2103423579",
                "DOI": "10.1007/978-3-540-88690-7_20",
                "CorpusId": 14885103
            },
            "abstract": null,
            "referenceCount": 17,
            "citationCount": 153,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/978-3-540-88690-7_20.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-10-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kim2008GenerativeIS,\n author = {Tae Hoon Kim and Kyoung Mu Lee and Sang Uk Lee},\n booktitle = {European Conference on Computer Vision},\n pages = {264-275},\n title = {Generative Image Segmentation Using Random Walks with Restart},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:14e2aec7e25d8880a851a547cf8d27a9721f8e6c",
            "@type": "ScholarlyArticle",
            "paperId": "14e2aec7e25d8880a851a547cf8d27a9721f8e6c",
            "corpusId": 635609,
            "url": "https://www.semanticscholar.org/paper/14e2aec7e25d8880a851a547cf8d27a9721f8e6c",
            "title": "Modeling Annotators: A Generative Approach to Learning from Annotator Rationales",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2008,
            "externalIds": {
                "ACL": "D08-1004",
                "DBLP": "conf/emnlp/ZaidanE08",
                "MAG": "2091144449",
                "DOI": "10.3115/1613715.1613721",
                "CorpusId": 635609
            },
            "abstract": "A human annotator can provide hints to a machine learner by highlighting contextual \"rationales\" for each of his or her annotations (Zaidan et al., 2007). How can one exploit this side information to better learn the desired parameters \u03b8? We present a generative model of how a given annotator, knowing the true \u03b8, stochastically chooses rationales. Thus, observing the rationales helps us infer the true \u03b8. We collect substring rationales for a sentiment classification task (Pang and Lee, 2004) and use them to obtain significant accuracy improvements for each annotator. Our new generative approach exploits the rationales more effectively than our previous \"masking SVM\" approach. It is also more principled, and could be adapted to help learn other kinds of probabilistic classifiers for quite different tasks.",
            "referenceCount": 13,
            "citationCount": 152,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=1613721&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-10-25",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zaidan2008ModelingAA,\n author = {Omar Zaidan and Jason Eisner},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {31-40},\n title = {Modeling Annotators: A Generative Approach to Learning from Annotator Rationales},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:485552d2711868b54d5fcddc92c746b09afeab07",
            "@type": "ScholarlyArticle",
            "paperId": "485552d2711868b54d5fcddc92c746b09afeab07",
            "corpusId": 3389583,
            "url": "https://www.semanticscholar.org/paper/485552d2711868b54d5fcddc92c746b09afeab07",
            "title": "Long Text Generation via Adversarial Training with Leaked Information",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/abs-1709-08624",
                "MAG": "2949061076",
                "ArXiv": "1709.08624",
                "DOI": "10.1609/aaai.v32i1.11957",
                "CorpusId": 3389583
            },
            "abstract": "\n \n Automatically generating coherent and semantically meaningful text has many applications in machine translation, dialogue systems, image captioning, etc. Recently, by combining with policy gradient, Generative Adversarial Nets(GAN) that use a discriminative model to guide the training of the generative model as a reinforcement learning policy has shown promising results in text generation. However, the scalar guiding signal is only available after the entire text has been generated and lacks intermediate information about text structure during the generative process. As such, it limits its success when the length of the generated text samples is long (more than 20 words). In this paper, we propose a new framework, called LeakGAN, to address the problem for long text generation. We allow the discriminative net to leak its own high-level extracted features to the generative net to further help the guidance. The generator incorporates such informative signals into all generation steps through an additional MANAGER module, which takes the extracted features of current generated words and outputs a latent vector to guide the WORKER module for next-word generation.Our extensive experiments on synthetic data and various real-world tasks with Turing test demonstrate that LeakGAN is highly effective in long text generation and also improves the performance in short text generation scenarios. More importantly, without any supervision, LeakGAN would be able to implicitly learn sentence structures only through the interaction between MANAGER and WORKER.\n \n",
            "referenceCount": 31,
            "citationCount": 417,
            "influentialCitationCount": 61,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/11957/11816",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-09-24",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1709.08624"
            },
            "citationStyles": {
                "bibtex": "@Article{Guo2017LongTG,\n author = {Jiaxian Guo and Sidi Lu and Han Cai and Weinan Zhang and Yong Yu and Jun Wang},\n booktitle = {AAAI Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {Long Text Generation via Adversarial Training with Leaked Information},\n volume = {abs/1709.08624},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cb3e87412d2fa52441e40bff3db2135dec9de3b9",
            "@type": "ScholarlyArticle",
            "paperId": "cb3e87412d2fa52441e40bff3db2135dec9de3b9",
            "corpusId": 4013011,
            "url": "https://www.semanticscholar.org/paper/cb3e87412d2fa52441e40bff3db2135dec9de3b9",
            "title": "Neural Voice Cloning with a Few Samples",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2788357188",
                "DBLP": "conf/nips/ArikCPPZ18",
                "ArXiv": "1802.06006",
                "CorpusId": 4013011
            },
            "abstract": "Voice cloning is a highly desired feature for personalized speech interfaces. Neural network based speech synthesis has been shown to generate high quality speech for a large number of speakers. In this paper, we introduce a neural voice cloning system that takes a few audio samples as input. We study two approaches: speaker adaptation and speaker encoding. Speaker adaptation is based on fine-tuning a multi-speaker generative model with a few cloning samples. Speaker encoding is based on training a separate model to directly infer a new speaker embedding from cloning audios and to be used with a multi-speaker generative model. In terms of naturalness of the speech and its similarity to original speaker, both approaches can achieve good performance, even with very few cloning audios. While speaker adaptation can achieve better naturalness and similarity, the cloning time or required memory for the speaker encoding approach is significantly less, making it favorable for low-resource deployment.",
            "referenceCount": 50,
            "citationCount": 291,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-14",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1802.06006"
            },
            "citationStyles": {
                "bibtex": "@Article{Arik2018NeuralVC,\n author = {Sercan \u00d6. Arik and Jitong Chen and Kainan Peng and Wei Ping and Yanqi Zhou},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Neural Voice Cloning with a Few Samples},\n volume = {abs/1802.06006},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:df096e221cc92c481d34443f4788c96ee412b189",
            "@type": "ScholarlyArticle",
            "paperId": "df096e221cc92c481d34443f4788c96ee412b189",
            "corpusId": 52855313,
            "url": "https://www.semanticscholar.org/paper/df096e221cc92c481d34443f4788c96ee412b189",
            "title": "Facial Expression Recognition by De-expression Residue Learning",
            "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/cvpr/YangCY18",
                "MAG": "2798583514",
                "DOI": "10.1109/CVPR.2018.00231",
                "CorpusId": 52855313
            },
            "abstract": "A facial expression is a combination of an expressive component and a neutral component of a person. In this paper, we propose to recognize facial expressions by extracting information of the expressive component through a de-expression learning procedure, called De-expression Residue Learning (DeRL). First, a generative model is trained by cGAN. This model generates the corresponding neutral face image for any input face image. We call this procedure de-expression because the expressive information is filtered out by the generative model; however, the expressive information is still recorded in the intermediate layers. Given the neutral face image, unlike previous works using pixel-level or feature-level difference for facial expression classification, our new method learns the deposition (or residue) that remains in the intermediate layers of the generative model. Such a residue is essential as it contains the expressive component deposited in the generative model from any input facial expression images. Seven public facial expression databases are employed in our experiments. With two databases (BU-4DFE and BP4D-spontaneous) for pre-training, the DeRL method has been evaluated on five databases, CK+, Oulu-CASIA, MMI, BU-3DFE, and BP4D+. The experimental results demonstrate the superior performance of the proposed method.",
            "referenceCount": 37,
            "citationCount": 285,
            "influentialCitationCount": 27,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2018FacialER,\n author = {Huiyuan Yang and U. Ciftci and L. Yin},\n booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n pages = {2168-2177},\n title = {Facial Expression Recognition by De-expression Residue Learning},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f01efc7e1515243b8b80a3b2230b6bc6f6247ef3",
            "@type": "ScholarlyArticle",
            "paperId": "f01efc7e1515243b8b80a3b2230b6bc6f6247ef3",
            "corpusId": 259842,
            "url": "https://www.semanticscholar.org/paper/f01efc7e1515243b8b80a3b2230b6bc6f6247ef3",
            "title": "C-RNN-GAN: Continuous recurrent neural networks with adversarial training",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/Mogren16",
                "MAG": "2559110679",
                "ArXiv": "1611.09904",
                "CorpusId": 259842
            },
            "abstract": "Generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks. We propose a generative adversarial model that works on continuous sequential data, and apply it by training it on a collection of classical music. We conclude that it generates music that sounds better and better as the model is trained, report statistics on generated music, and let the reader judge the quality by downloading the generated songs.",
            "referenceCount": 15,
            "citationCount": 417,
            "influentialCitationCount": 45,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-29",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1611.09904"
            },
            "citationStyles": {
                "bibtex": "@Article{Mogren2016CRNNGANCR,\n author = {Olof Mogren},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {C-RNN-GAN: Continuous recurrent neural networks with adversarial training},\n volume = {abs/1611.09904},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f6a40655c3f8aad3c70ce54f68d1b017a1e9bc2f",
            "@type": "ScholarlyArticle",
            "paperId": "f6a40655c3f8aad3c70ce54f68d1b017a1e9bc2f",
            "corpusId": 7105458,
            "url": "https://www.semanticscholar.org/paper/f6a40655c3f8aad3c70ce54f68d1b017a1e9bc2f",
            "title": "Multiple Object Class Detection with a Generative Model",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2153565331",
                "DBLP": "conf/cvpr/MikolajczykLS06",
                "DOI": "10.1109/CVPR.2006.202",
                "CorpusId": 7105458
            },
            "abstract": "In this paper we propose an approach capable of simultaneous recognition and localization of multiple object classes using a generative model. A novel hierarchical representation allows to represent individual images as well as various objects classes in a single, scale and rotation invariant model. The recognition method is based on a codebook representation where appearance clusters built from edge based features are shared among several object classes. A probabilistic model allows for reliable detection of various objects in the same image. The approach is highly efficient due to fast clustering and matching methods capable of dealing with millions of high dimensional features. The system shows excellent performance on several object categories over a wide range of scales, in-plane rotations, background clutter, and partial occlusions. The performance of the proposed multi-object class detection approach is competitive to state of the art approaches dedicated to a single object class recognition problem.",
            "referenceCount": 27,
            "citationCount": 285,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://openresearch.surrey.ac.uk/view/delivery/44SUR_INST/12138713710002346/13140431260002346",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-06-17",
            "journal": {
                "name": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Mikolajczyk2006MultipleOC,\n author = {K. Mikolajczyk and B. Leibe and B. Schiele},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},\n pages = {26-36},\n title = {Multiple Object Class Detection with a Generative Model},\n volume = {1},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c311778adb9484c86250e915aecd9714f4206050",
            "@type": "ScholarlyArticle",
            "paperId": "c311778adb9484c86250e915aecd9714f4206050",
            "corpusId": 444032,
            "url": "https://www.semanticscholar.org/paper/c311778adb9484c86250e915aecd9714f4206050",
            "title": "Aspect and sentiment unification model for online review analysis",
            "venue": "Web Search and Data Mining",
            "publicationVenue": {
                "id": "urn:research:ea38228f-6ed3-4222-a3ce-d963d8cc9516",
                "name": "Web Search and Data Mining",
                "alternate_names": [
                    "Web Search Data Min",
                    "WSDM"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=3158"
            },
            "year": 2011,
            "externalIds": {
                "DBLP": "conf/wsdm/JoO11",
                "MAG": "2044429219",
                "DOI": "10.1145/1935826.1935932",
                "CorpusId": 444032
            },
            "abstract": "User-generated reviews on the Web contain sentiments about detailed aspects of products and services. However, most of the reviews are plain text and thus require much effort to obtain information about relevant details. In this paper, we tackle the problem of automatically discovering what aspects are evaluated in reviews and how sentiments for different aspects are expressed. We first propose Sentence-LDA (SLDA), a probabilistic generative model that assumes all words in a single sentence are generated from one aspect. We then extend SLDA to Aspect and Sentiment Unification Model (ASUM), which incorporates aspect and sentiment together to model sentiments toward different aspects. ASUM discovers pairs of {aspect, sentiment} which we call senti-aspects. We applied SLDA and ASUM to reviews of electronic devices and restaurants. The results show that the aspects discovered by SLDA match evaluative details of the reviews, and the senti-aspects found by ASUM capture important aspects that are closely coupled with a sentiment. The results of sentiment classification show that ASUM outperforms other generative models and comes close to supervised classification methods. One important advantage of ASUM is that it does not require any sentiment labels of the reviews, which are often expensive to obtain.",
            "referenceCount": 25,
            "citationCount": 792,
            "influentialCitationCount": 89,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2011-02-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Jo2011AspectAS,\n author = {Yohan Jo and Alice H. Oh},\n booktitle = {Web Search and Data Mining},\n pages = {815-824},\n title = {Aspect and sentiment unification model for online review analysis},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:236b40f3144b95cd84779484c8269092122920aa",
            "@type": "ScholarlyArticle",
            "paperId": "236b40f3144b95cd84779484c8269092122920aa",
            "corpusId": 4476190,
            "url": "https://www.semanticscholar.org/paper/236b40f3144b95cd84779484c8269092122920aa",
            "title": "Tactics of Adversarial Attack on Deep Reinforcement Learning Agents",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2952603690",
                "DBLP": "conf/iclr/LinHLS0S17",
                "ArXiv": "1703.06748",
                "DOI": "10.24963/ijcai.2017/525",
                "CorpusId": 4476190
            },
            "abstract": "We introduce two tactics, namely the strategically-timed attack and the enchanting attack, to attack reinforcement learning agents trained by deep reinforcement learning algorithms using adversarial examples. In the strategically-timed attack, the adversary aims at minimizing the agent's reward by only attacking the agent at a small subset of time steps in an episode. Limiting the attack activity to this subset helps prevent detection of the attack by the agent. We propose a novel method to determine when an adversarial example should be crafted and applied. In the enchanting attack, the adversary aims at luring the agent to a designated target state. This is achieved by combining a generative model and a planning algorithm: while the generative model predicts the future states, the planning algorithm generates a preferred sequence of actions for luring the agent. A sequence of adversarial examples is then crafted to lure the agent to take the preferred sequence of actions. We apply the proposed tactics to the agents trained by the state-of-the-art deep reinforcement learning algorithm including DQN and A3C. In 5 Atari games, our strategically-timed attack reduces as much reward as the uniform attack (i.e., attacking at every time step) does by attacking the agent 4 times less often. Our enchanting attack lures the agent toward designated target states with a more than 70% success rate. Example videos are available at http://yclin.me/adversarial_attack_RL/.",
            "referenceCount": 21,
            "citationCount": 340,
            "influentialCitationCount": 32,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.ijcai.org/proceedings/2017/0525.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lin2017TacticsOA,\n author = {Yen-Chen Lin and Zhang-Wei Hong and Yuan-Hong Liao and Meng-Li Shih and Ming-Yu Liu and Min Sun},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {3756-3762},\n title = {Tactics of Adversarial Attack on Deep Reinforcement Learning Agents},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:363e59b5aee9a4968dcc4fe4959efc5acfcf37b4",
            "@type": "ScholarlyArticle",
            "paperId": "363e59b5aee9a4968dcc4fe4959efc5acfcf37b4",
            "corpusId": 3010189,
            "url": "https://www.semanticscholar.org/paper/363e59b5aee9a4968dcc4fe4959efc5acfcf37b4",
            "title": "Concern for generativity and its relation to implicit pro-social power motivation, generative goals, and satisfaction with life: a cross-cultural investigation.",
            "venue": "Journal of Personality",
            "publicationVenue": {
                "id": "urn:research:d6746d0b-4df1-4abe-997d-ce10035a9654",
                "name": "Journal of Personality",
                "alternate_names": [
                    "J Personal"
                ],
                "issn": "0022-3506",
                "url": "http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)1467-6494"
            },
            "year": 2007,
            "externalIds": {
                "MAG": "2162886941",
                "DOI": "10.1111/j.1467-6494.2007.00478.x",
                "CorpusId": 3010189,
                "PubMed": "18186709"
            },
            "abstract": "So far, cross-cultural research on generativity has been lacking. The present study tests the cross-cultural applicability of an integrative model of generativity proposed by McAdams and de St. Aubin. Measures of implicit pro-social power motivation, a general disposition for generativity, generative goals, and life satisfaction were administered to adults in Cameroon, Costa Rica, and Germany. These measures cover the intrapersonal part of the generativity model. After examining the comparability of the measures across the three cultures, cultural differences in the level of each variable were inspected. Finally, the hypothesized model was tested via structural equation modeling. Results show that the model can be successfully applied in all three cultural samples. This finding has interesting implications for the further investigation of generativity, particularly its social antecedents and behavioral consequences.",
            "referenceCount": 89,
            "citationCount": 143,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study"
            ],
            "publicationDate": "2007-12-07",
            "journal": {
                "name": "Journal of personality",
                "volume": "76 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Hofer2007ConcernFG,\n author = {Jan Hofer and Holger Busch and A. Chasiotis and Joscha K\u00e4rtner and D. Campos},\n booktitle = {Journal of Personality},\n journal = {Journal of personality},\n pages = {\n          1-30\n        },\n title = {Concern for generativity and its relation to implicit pro-social power motivation, generative goals, and satisfaction with life: a cross-cultural investigation.},\n volume = {76 1},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b36643e9400f75ca50618d240b1e898e44310556",
            "@type": "ScholarlyArticle",
            "paperId": "b36643e9400f75ca50618d240b1e898e44310556",
            "corpusId": 970749,
            "url": "https://www.semanticscholar.org/paper/b36643e9400f75ca50618d240b1e898e44310556",
            "title": "Repair Theory: A Generative Theory of Bugs in Procedural Skills",
            "venue": "Cognitive Sciences",
            "publicationVenue": {
                "id": "urn:research:c33b01b0-31b4-470e-a9f9-8432e02c3cb9",
                "name": "Cognitive Sciences",
                "alternate_names": [
                    "Cognitive Science",
                    "Cogn Sci"
                ],
                "issn": "1935-8059",
                "url": "http://www.informaworld.com/openurl?genre=journal&issn=1551-6709"
            },
            "year": 1980,
            "externalIds": {
                "MAG": "2586016832",
                "DBLP": "journals/cogsci/BrownV80",
                "DOI": "10.1207/s15516709cog0404_3",
                "CorpusId": 970749
            },
            "abstract": "This paper describes a generative theory of bugs. It claims that all bugs of a procedural skill can be derived by a highly constrained form of problem solving acting on incomplete procedures. These procedures are characterized by formal deletion operations that model incomplete learning and forgetting. The problem solver and the deletion operator have been constrained to make it impossible to derive \u201cstar-bugs\u201d\u2014algorithms that are so absurd that expert diagnosticians agree that the alogorithm will never be observed as a bug. Hence, the theory not only generates the observed bugs, it fails to generate star-bugs. \n \nThe theory has been tested on an extensive data base of bugs for multidigit subtraction that was collected with the aid of the diagnostic systems buggy and debuggy. In addition to predicting bug occurrence, by adoption of additional hypotheses, the theory also makes predictions about the frequency and stability of bugs, as well as the occurrence of certain latencies in processing time during testing. Arguments are given that the theory can be applied to domains other than subtraction and that it can be extended to provide a theory of procedural learning that accounts for bug acquisition. Lastly, particular care has been taken to make the theory principled so that it can not be tailored to fit any possible data.",
            "referenceCount": 17,
            "citationCount": 610,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1207/s15516709cog0404_3",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1980-10-01",
            "journal": {
                "name": "Cogn. Sci.",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Brown1980RepairTA,\n author = {J. Brown and K. VanLehn},\n booktitle = {Cognitive Sciences},\n journal = {Cogn. Sci.},\n pages = {379-426},\n title = {Repair Theory: A Generative Theory of Bugs in Procedural Skills},\n volume = {4},\n year = {1980}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dc6a5d898996f2c221752806aeab449c24c9b1b7",
            "@type": "ScholarlyArticle",
            "paperId": "dc6a5d898996f2c221752806aeab449c24c9b1b7",
            "corpusId": 33871107,
            "url": "https://www.semanticscholar.org/paper/dc6a5d898996f2c221752806aeab449c24c9b1b7",
            "title": "Emotion Regulation in Adulthood: Timing Is Everything",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2101630796",
                "DOI": "10.1111/1467-8721.00152",
                "CorpusId": 33871107
            },
            "abstract": "Emotions seem to come and go as they please. However, we actually hold considerable sway over our emotions: We influence which emotions we have and how we experience and express these emotions. The process model of emotion regulation described here suggests that how we regulate our emotions matters. Regulatory strategies that act early in the emotion-generative process should have quite different outcomes than strategies that act later. This review focuses on two widely used strategies for down-regulating emotion. The first, reappraisal, comes early in the emotion-generative process. It consists of changing how we think about a situation in order to decrease its emotional impact. The second, suppression, comes later in the emotion-generative process. It involves inhibiting the outward signs of emotion. Theory and research suggest that reappraisal is more effective than suppression. Reappraisal decreases the experience and behavioral expression of emotion, and has no impact on memory. By contrast, suppression decreases behavioral expression, but fails to decrease the experience of emotion, and actually impairs memory. Suppression also increases physiological responding in both the suppressors and their social partners.",
            "referenceCount": 19,
            "citationCount": 1211,
            "influentialCitationCount": 124,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2001-12-01",
            "journal": {
                "name": "Current Directions in Psychological Science",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Gross2001EmotionRI,\n author = {J. Gross},\n journal = {Current Directions in Psychological Science},\n pages = {214 - 219},\n title = {Emotion Regulation in Adulthood: Timing Is Everything},\n volume = {10},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b04d03b72892c97908858a6006186db8987764d1",
            "@type": "ScholarlyArticle",
            "paperId": "b04d03b72892c97908858a6006186db8987764d1",
            "corpusId": 15151944,
            "url": "https://www.semanticscholar.org/paper/b04d03b72892c97908858a6006186db8987764d1",
            "title": "A Spatially Constrained Generative Model and an EM Algorithm for Image Segmentation",
            "venue": "IEEE Transactions on Neural Networks",
            "publicationVenue": {
                "id": "urn:research:2ac50919-507e-41c7-93a8-721c4b804757",
                "name": "IEEE Transactions on Neural Networks",
                "alternate_names": [
                    "IEEE Trans Neural Netw"
                ],
                "issn": "1045-9227",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=72"
            },
            "year": 2007,
            "externalIds": {
                "MAG": "2115296699",
                "DBLP": "journals/tnn/DiplarosVG07",
                "DOI": "10.1109/TNN.2007.891190",
                "CorpusId": 15151944,
                "PubMed": "17526345"
            },
            "abstract": "In this paper, we present a novel spatially constrained generative model and an expectation-maximization (EM) algorithm for model-based image segmentation. The generative model assumes that the unobserved class labels of neighboring pixels in the image are generated by prior distributions with similar parameters, where similarity is defined by entropic quantities relating to the neighboring priors. In order to estimate model parameters from observations, we derive a spatially constrained EM algorithm that iteratively maximizes a lower bound on the data log-likelihood, where the penalty term is data-dependent. Our algorithm is very easy to implement and is similar to the standard EM algorithm for Gaussian mixtures with the main difference that the labels posteriors are \"smoothed\" over pixels between each E- and M-step by a standard image filter. Experiments on synthetic and real images show that our algorithm achieves competitive segmentation results compared to other Markov-based methods, and is in general faster",
            "referenceCount": 38,
            "citationCount": 123,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://staff.science.uva.nl/~gevers/pub/DiplarosTNN07.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2007-05-01",
            "journal": {
                "name": "IEEE Transactions on Neural Networks",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Diplaros2007ASC,\n author = {A. Diplaros and N. Vlassis and T. Gevers},\n booktitle = {IEEE Transactions on Neural Networks},\n journal = {IEEE Transactions on Neural Networks},\n pages = {798-808},\n title = {A Spatially Constrained Generative Model and an EM Algorithm for Image Segmentation},\n volume = {18},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d6df29390c678eff7f03a28bfd2c85bbf6a16d07",
            "@type": "ScholarlyArticle",
            "paperId": "d6df29390c678eff7f03a28bfd2c85bbf6a16d07",
            "corpusId": 15788070,
            "url": "https://www.semanticscholar.org/paper/d6df29390c678eff7f03a28bfd2c85bbf6a16d07",
            "title": "Asymptotic analysis of the stochastic block model for modular networks and its algorithmic applications",
            "venue": "Physical review. E, Statistical, nonlinear, and soft matter physics",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2004531067",
                "ArXiv": "1109.3041",
                "DBLP": "journals/corr/abs-1109-3041",
                "DOI": "10.1103/PhysRevE.84.066106",
                "CorpusId": 15788070,
                "PubMed": "22304154"
            },
            "abstract": "In this paper we extend our previous work on the stochastic block model, a commonly used generative model for social and biological networks, and the problem of inferring functional groups or communities from the topology of the network. We use the cavity method of statistical physics to obtain an asymptotically exact analysis of the phase diagram. We describe in detail properties of the detectability-undetectability phase transition and the easy-hard phase transition for the community detection problem. Our analysis translates naturally into a belief propagation algorithm for inferring the group memberships of the nodes in an optimal way, i.e., that maximizes the overlap with the underlying group memberships, and learning the underlying parameters of the block model. Finally, we apply the algorithm to two examples of real-world networks and discuss its performance.",
            "referenceCount": 78,
            "citationCount": 732,
            "influentialCitationCount": 87,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1109.3041",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Physics",
                "Computer Science",
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2011-09-14",
            "journal": {
                "name": "Physical review. E, Statistical, nonlinear, and soft matter physics",
                "volume": "84 6 Pt 2"
            },
            "citationStyles": {
                "bibtex": "@Article{Decelle2011AsymptoticAO,\n author = {A. Decelle and F. Krzakala and Cristopher Moore and L. Zdeborov\u00e1},\n booktitle = {Physical review. E, Statistical, nonlinear, and soft matter physics},\n journal = {Physical review. E, Statistical, nonlinear, and soft matter physics},\n pages = {\n          066106\n        },\n title = {Asymptotic analysis of the stochastic block model for modular networks and its algorithmic applications},\n volume = {84 6 Pt 2},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9762f5d2ca8c2132942d10ef6b064bf370262585",
            "@type": "ScholarlyArticle",
            "paperId": "9762f5d2ca8c2132942d10ef6b064bf370262585",
            "corpusId": 9830566,
            "url": "https://www.semanticscholar.org/paper/9762f5d2ca8c2132942d10ef6b064bf370262585",
            "title": "A Latent Variable Model for Generative Dependency Parsing",
            "venue": "Trends in Parsing Technology",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2007,
            "externalIds": {
                "MAG": "2128791906",
                "DBLP": "books/daglib/p/TitovH10",
                "ACL": "W07-2218",
                "DOI": "10.1007/978-90-481-9352-3_3",
                "CorpusId": 9830566
            },
            "abstract": null,
            "referenceCount": 49,
            "citationCount": 110,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://acl.ldc.upenn.edu/w/w07/W07-2218.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2007-06-23",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Titov2007ALV,\n author = {Ivan Titov and James Henderson},\n booktitle = {Trends in Parsing Technology},\n pages = {144-155},\n title = {A Latent Variable Model for Generative Dependency Parsing},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:63303c61889dae39895a08b8d910e4511cd2a545",
            "@type": "ScholarlyArticle",
            "paperId": "63303c61889dae39895a08b8d910e4511cd2a545",
            "corpusId": 4253493,
            "url": "https://www.semanticscholar.org/paper/63303c61889dae39895a08b8d910e4511cd2a545",
            "title": "Probabilistic Linear Discriminant Analysis for Inferences About Identity",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2007,
            "externalIds": {
                "MAG": "2121812409",
                "DBLP": "conf/iccv/PrinceE07",
                "DOI": "10.1109/ICCV.2007.4409052",
                "CorpusId": 4253493
            },
            "abstract": "Many current face recognition algorithms perform badly when the lighting or pose of the probe and gallery images differ. In this paper we present a novel algorithm designed for these conditions. We describe face data as resulting from a generative model which incorporates both within-individual and between-individual variation. In recognition we calculate the likelihood that the differences between face images are entirely due to within-individual variability. We extend this to the non-linear case where an arbitrary face manifold can be described and noise is position-dependent. We also develop a \"tied\" version of the algorithm that allows explicit comparison across quite different viewing conditions. We demonstrate that our model produces state of the art results for (i) frontal face recognition (ii) face recognition under varying pose.",
            "referenceCount": 21,
            "citationCount": 1110,
            "influentialCitationCount": 221,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2007-12-26",
            "journal": {
                "name": "2007 IEEE 11th International Conference on Computer Vision",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Prince2007ProbabilisticLD,\n author = {S. Prince and J. Elder},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2007 IEEE 11th International Conference on Computer Vision},\n pages = {1-8},\n title = {Probabilistic Linear Discriminant Analysis for Inferences About Identity},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1d83aa9ac9f26cd117d50d845743260f3a87250b",
            "@type": "ScholarlyArticle",
            "paperId": "1d83aa9ac9f26cd117d50d845743260f3a87250b",
            "corpusId": 12973135,
            "url": "https://www.semanticscholar.org/paper/1d83aa9ac9f26cd117d50d845743260f3a87250b",
            "title": "Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2698857938",
                "ArXiv": "1706.07036",
                "DBLP": "journals/corr/LinKL17",
                "DOI": "10.1609/aaai.v32i1.12278",
                "CorpusId": 12973135
            },
            "abstract": "\n \n Conventional methods of 3D object generative modeling learn volumetric predictions using deep networks with 3D convolutional operations, which are direct analogies to classical 2D ones. However, these methods are computationally wasteful in attempt to predict 3D shapes, where information is rich only on the surfaces. In this paper, we propose a novel 3D generative modeling framework to efficiently generate object shapes in the form of dense point clouds. We use 2D convolutional operations to predict the 3D structure from multiple viewpoints and jointly apply geometric reasoning with 2D projection optimization. We introduce the pseudo-renderer, a differentiable module to approximate the true rendering operation, to synthesize novel depth maps for optimization. Experimental results for single-image 3D object reconstruction tasks show that we outperforms state-of-the-art methods in terms of shape similarity and prediction density.\n \n",
            "referenceCount": 36,
            "citationCount": 342,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/12278/12137",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-06-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1706.07036"
            },
            "citationStyles": {
                "bibtex": "@Article{Lin2017LearningEP,\n author = {Chen-Hsuan Lin and Chen Kong and S. Lucey},\n booktitle = {AAAI Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction},\n volume = {abs/1706.07036},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a1b3d8a94323122d63a1ec31c1d722d30c509cb4",
            "@type": "ScholarlyArticle",
            "paperId": "a1b3d8a94323122d63a1ec31c1d722d30c509cb4",
            "corpusId": 15140030,
            "url": "https://www.semanticscholar.org/paper/a1b3d8a94323122d63a1ec31c1d722d30c509cb4",
            "title": "Semantic Image Inpainting with Perceptual and Contextual Losses",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2479644247",
                "DBLP": "journals/corr/YehCLHD16",
                "CorpusId": 15140030
            },
            "abstract": "In this paper, we propose a novel method for image inpainting based on a Deep Convolutional Generative Adversarial Network (DCGAN). We define a loss function consisting of two parts: (1) a contextual loss that preserves similarity between the input corrupted image and the recovered image, and (2) a perceptual loss that ensures a perceptually realistic output image. Given a corrupted image with missing values, we use back-propagation on this loss to map the corrupted image to a smaller latent space. The mapped vector is then passed through the generative model to predict the missing content. The proposed framework is evaluated on the CelebA and SVHN datasets for two challenging inpainting tasks with random 80% corruption and large blocky corruption. Experiments show that our method can successfully predict semantic information in the missing region and achieve pixel-level photorealism, which is impossible by almost all existing methods.",
            "referenceCount": 26,
            "citationCount": 352,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-07-26",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1607.07539"
            },
            "citationStyles": {
                "bibtex": "@Article{Yeh2016SemanticII,\n author = {Raymond A. Yeh and Chen Chen and Teck-Yian Lim and M. Hasegawa-Johnson and M. Do},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Semantic Image Inpainting with Perceptual and Contextual Losses},\n volume = {abs/1607.07539},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:23d17cf651ced54ae538ce994ccb83b7ea2a94d3",
            "@type": "ScholarlyArticle",
            "paperId": "23d17cf651ced54ae538ce994ccb83b7ea2a94d3",
            "corpusId": 9119991,
            "url": "https://www.semanticscholar.org/paper/23d17cf651ced54ae538ce994ccb83b7ea2a94d3",
            "title": "Robust Object Tracking via Sparse Collaborative Appearance Model",
            "venue": "IEEE Transactions on Image Processing",
            "publicationVenue": {
                "id": "urn:research:e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                "name": "IEEE Transactions on Image Processing",
                "alternate_names": [
                    "IEEE Trans Image Process"
                ],
                "issn": "1057-7149",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/tip/ZhongLY14",
                "MAG": "2094274531",
                "DOI": "10.1109/TIP.2014.2313227",
                "CorpusId": 9119991,
                "PubMed": "24686280"
            },
            "abstract": "In this paper, we propose a robust object tracking algorithm based on a sparse collaborative model that exploits both holistic templates and local representations to account for drastic appearance changes. Within the proposed collaborative appearance model, we develop a sparse discriminative classifier (SDC) and sparse generative model (SGM) for object tracking. In the SDC module, we present a classifier that separates the foreground object from the background based on holistic templates. In the SGM module, we propose a histogram-based method that takes the spatial information of each local patch into consideration. The update scheme considers both the most recent observations and original templates, thereby enabling the proposed algorithm to deal with appearance changes effectively and alleviate the tracking drift problem. Numerous experiments on various challenging videos demonstrate that the proposed tracker performs favorably against several state-of-the-art algorithms.",
            "referenceCount": 37,
            "citationCount": 333,
            "influentialCitationCount": 53,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://faculty.ucmerced.edu/mhyang/papers/tip14_scm.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-03-24",
            "journal": {
                "name": "IEEE Transactions on Image Processing",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhong2014RobustOT,\n author = {Wei Zhong and Huchuan Lu and Ming-Hsuan Yang},\n booktitle = {IEEE Transactions on Image Processing},\n journal = {IEEE Transactions on Image Processing},\n pages = {2356-2368},\n title = {Robust Object Tracking via Sparse Collaborative Appearance Model},\n volume = {23},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1ae265be8ccf396115ef06405f3b8421851998a9",
            "@type": "ScholarlyArticle",
            "paperId": "1ae265be8ccf396115ef06405f3b8421851998a9",
            "corpusId": 384205,
            "url": "https://www.semanticscholar.org/paper/1ae265be8ccf396115ef06405f3b8421851998a9",
            "title": "Learning to Compose Domain-Specific Transformations for Data Augmentation",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2963543962",
                "DBLP": "journals/corr/abs-1709-01643",
                "ArXiv": "1709.01643",
                "CorpusId": 384205,
                "PubMed": "29375240"
            },
            "abstract": "Data augmentation is a ubiquitous technique for increasing the size of labeled training sets by leveraging task-specific data transformations that preserve class labels. While it is often easy for domain experts to specify individual transformations, constructing and tuning the more sophisticated compositions typically needed to achieve state-of-the-art results is a time-consuming manual task in practice. We propose a method for automating this process by learning a generative sequence model over user-specified transformation functions using a generative adversarial approach. Our method can make use of arbitrary, non-deterministic transformation functions, is robust to misspecified user input, and is trained on unlabeled data. The learned transformation model can then be used to perform data augmentation for any end discriminative model. In our experiments, we show the efficacy of our approach on both image and text datasets, achieving improvements of 4.0 accuracy points on CIFAR-10, 1.4 F1 points on the ACE relation extraction task, and 3.4 accuracy points when using domain-specific transformation operations on a medical imaging dataset as compared to standard heuristic augmentation approaches.",
            "referenceCount": 36,
            "citationCount": 303,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-09-06",
            "journal": {
                "name": "Advances in neural information processing systems",
                "volume": "30"
            },
            "citationStyles": {
                "bibtex": "@Article{Ratner2017LearningTC,\n author = {Alexander J. Ratner and Henry R. Ehrenberg and Zeshan Hussain and Jared A. Dunnmon and C. R\u00e9},\n booktitle = {Neural Information Processing Systems},\n journal = {Advances in neural information processing systems},\n pages = {\n          3239-3249\n        },\n title = {Learning to Compose Domain-Specific Transformations for Data Augmentation},\n volume = {30},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:07d61392606dade00c08704e78f1c19b66d75261",
            "@type": "ScholarlyArticle",
            "paperId": "07d61392606dade00c08704e78f1c19b66d75261",
            "corpusId": 7524689,
            "url": "https://www.semanticscholar.org/paper/07d61392606dade00c08704e78f1c19b66d75261",
            "title": "Multicamera People Tracking with a Probabilistic Occupancy Map",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2158634074",
                "DBLP": "journals/pami/FleuretBLF08",
                "DOI": "10.1109/TPAMI.2007.1174",
                "CorpusId": 7524689,
                "PubMed": "18084058"
            },
            "abstract": "Given two to four synchronized video streams taken at eye level and from different angles, we show that we can effectively combine a generative model with dynamic programming to accurately follow up to six individuals across thousands of frames in spite of significant occlusions and lighting changes. In addition, we also derive metrically accurate trajectories for each of them. Our contribution is twofold. First, we demonstrate that our generative model can effectively handle occlusions in each time frame independently, even when the only data available comes from the output of a simple background subtraction algorithm and when the number of individuals is unknown a priori. Second, we show that multiperson tracking can be reliably achieved by processing individual trajectories separately over long sequences, provided that a reasonable heuristic is used to rank these individuals and that we avoid confusing them with one another.",
            "referenceCount": 29,
            "citationCount": 864,
            "influentialCitationCount": 115,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://infoscience.epfl.ch/record/145991/files/FleuretBLF08.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-02-01",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "30"
            },
            "citationStyles": {
                "bibtex": "@Article{Fleuret2008MulticameraPT,\n author = {F. Fleuret and J. Berclaz and R. Lengagne and P. Fua},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {267-282},\n title = {Multicamera People Tracking with a Probabilistic Occupancy Map},\n volume = {30},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:afc68658553bfb7bf6c265efece16b20bbcdf510",
            "@type": "ScholarlyArticle",
            "paperId": "afc68658553bfb7bf6c265efece16b20bbcdf510",
            "corpusId": 206765269,
            "url": "https://www.semanticscholar.org/paper/afc68658553bfb7bf6c265efece16b20bbcdf510",
            "title": "3D Traffic Scene Understanding From Movable Platforms",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/pami/GeigerLWSU14",
                "MAG": "2137097255",
                "DOI": "10.1109/TPAMI.2013.185",
                "CorpusId": 206765269,
                "PubMed": "26353233"
            },
            "abstract": "In this paper, we present a novel probabilistic generative model for multi-object traffic scene understanding from movable platforms which reasons jointly about the 3D scene layout as well as the location and orientation of objects in the scene. In particular, the scene topology, geometry, and traffic activities are inferred from short video sequences. Inspired by the impressive driving capabilities of humans, our model does not rely on GPS, lidar, or map knowledge. Instead, it takes advantage of a diverse set of visual cues in the form of vehicle tracklets, vanishing points, semantic scene labels, scene flow, and occupancy grids. For each of these cues, we propose likelihood functions that are integrated into a probabilistic generative model. We learn all model parameters from training data using contrastive divergence. Experiments conducted on videos of 113 representative intersections show that our approach successfully infers the correct layout in a variety of very challenging scenarios. To evaluate the importance of each feature cue, experiments using different feature combinations are conducted. Furthermore, we show how by employing context derived from the proposed method we are able to improve over the state-of-the-art in terms of object detection and object orientation estimation in challenging and cluttered urban environments.",
            "referenceCount": 65,
            "citationCount": 407,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.mrt.kit.edu/z/publ/download/2014/GeigerLauerWojekStillerUrtasun2014pami.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-05-01",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{Geiger20143DTS,\n author = {Andreas Geiger and M. Lauer and C. Wojek and C. Stiller and R. Urtasun},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {1012-1025},\n title = {3D Traffic Scene Understanding From Movable Platforms},\n volume = {36},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1279163ee31bb8c1b4a7f4422b6c80164261e8c2",
            "@type": "ScholarlyArticle",
            "paperId": "1279163ee31bb8c1b4a7f4422b6c80164261e8c2",
            "corpusId": 579052,
            "url": "https://www.semanticscholar.org/paper/1279163ee31bb8c1b4a7f4422b6c80164261e8c2",
            "title": "A generative model for music transcription",
            "venue": "IEEE Transactions on Audio, Speech, and Language Processing",
            "publicationVenue": {
                "id": "urn:research:96b92082-eb93-4682-be66-0a8fa5f2511c",
                "name": "IEEE Transactions on Audio, Speech, and Language Processing",
                "alternate_names": [
                    "IEEE Trans Audio Speech Lang Process"
                ],
                "issn": "1558-7916",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=10376"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "journals/taslp/CemgilKB06",
                "MAG": "2118292600",
                "DOI": "10.1109/TSA.2005.852985",
                "CorpusId": 579052
            },
            "abstract": "In this paper, we present a graphical model for polyphonic music transcription. Our model, formulated as a dynamical Bayesian network, embodies a transparent and computationally tractable approach to this acoustic analysis problem. An advantage of our approach is that it places emphasis on explicitly modeling the sound generation procedure. It provides a clear framework in which both high level (cognitive) prior information on music structure can be coupled with low level (acoustic physical) information in a principled manner to perform the analysis. The model is a special case of the, generally intractable, switching Kalman filter model. Where possible, we derive, exact polynomial time inference procedures, and otherwise efficient approximations. We argue that our generative model based approach is computationally feasible for many music applications and is readily extensible to more general auditory scene analysis scenarios.",
            "referenceCount": 58,
            "citationCount": 146,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://discovery.ucl.ac.uk/12192/1/12192.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-12-01",
            "journal": {
                "name": "IEEE Transactions on Audio, Speech, and Language Processing",
                "volume": "14"
            },
            "citationStyles": {
                "bibtex": "@Article{Cemgil2006AGM,\n author = {A. Cemgil and H. Kappen and D. Barber},\n booktitle = {IEEE Transactions on Audio, Speech, and Language Processing},\n journal = {IEEE Transactions on Audio, Speech, and Language Processing},\n pages = {679-694},\n title = {A generative model for music transcription},\n volume = {14},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:74a6c2b6408fb1a14664b08c018fefa6aee22dc7",
            "@type": "ScholarlyArticle",
            "paperId": "74a6c2b6408fb1a14664b08c018fefa6aee22dc7",
            "corpusId": 7587278,
            "url": "https://www.semanticscholar.org/paper/74a6c2b6408fb1a14664b08c018fefa6aee22dc7",
            "title": "Galileo: Perceiving Physical Object Properties by Integrating a Physics Engine with Deep Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "conf/nips/WuYLFT15",
                "MAG": "2181623680",
                "CorpusId": 7587278
            },
            "abstract": "Humans demonstrate remarkable abilities to predict physical events in dynamic scenes, and to infer the physical properties of objects from static images. We propose a generative model for solving these problems of physical scene understanding from real-world videos and images. At the core of our generative model is a 3D physics engine, operating on an object-based representation of physical properties, including mass, position, 3D shape, and friction. We can infer these latent properties using relatively brief runs of MCMC, which drive simulations in the physics engine to fit key features of visual observations. We further explore directly mapping visual inputs to physical properties, inverting a part of the generative process using deep learning. We name our model Galileo, and evaluate it on a video dataset with simple yet physically rich scenarios. Results show that Galileo is able to infer the physical properties of objects and predict the outcome of a variety of physical events, with an accuracy comparable to human subjects. Our study points towards an account of human vision with generative physical knowledge at its core, and various recognition models as helpers leading to efficient inference.",
            "referenceCount": 14,
            "citationCount": 326,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-12-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2015GalileoPP,\n author = {Jiajun Wu and Ilker Yildirim and Joseph J. Lim and Bill Freeman and J. Tenenbaum},\n booktitle = {Neural Information Processing Systems},\n pages = {127-135},\n title = {Galileo: Perceiving Physical Object Properties by Integrating a Physics Engine with Deep Learning},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c3453ef6e19bf44ec35becd6d37c6910efd7a6d7",
            "@type": "ScholarlyArticle",
            "paperId": "c3453ef6e19bf44ec35becd6d37c6910efd7a6d7",
            "corpusId": 3327460,
            "url": "https://www.semanticscholar.org/paper/c3453ef6e19bf44ec35becd6d37c6910efd7a6d7",
            "title": "Diversified Texture Synthesis with Feed-Forward Networks",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2952849295",
                "ArXiv": "1703.01664",
                "DBLP": "journals/corr/LiFYWL017",
                "DOI": "10.1109/CVPR.2017.36",
                "CorpusId": 3327460
            },
            "abstract": "Recent progresses on deep discriminative and generative modeling have shown promising results on texture synthesis. However, existing feed-forward based methods trade off generality for efficiency, which suffer from many issues, such as shortage of generality (i.e., build one network per texture), lack of diversity (i.e., always produce visually identical output) and suboptimality (i.e., generate less satisfying visual effects). In this work, we focus on solving these issues for improved texture synthesis. We propose a deep generative feed-forward network which enables efficient synthesis of multiple textures within one single network and meaningful interpolation between them. Meanwhile, a suite of important techniques are introduced to achieve better convergence and diversity. With extensive experiments, we demonstrate the effectiveness of the proposed model and techniques for synthesizing a large number of textures and show its applications with the stylization.",
            "referenceCount": 35,
            "citationCount": 238,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1703.01664",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-05",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Li2017DiversifiedTS,\n author = {Yijun Li and Chen Fang and Jimei Yang and Zhaowen Wang and Xin Lu and Ming-Hsuan Yang},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {266-274},\n title = {Diversified Texture Synthesis with Feed-Forward Networks},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4112c641f6338801adf3e846b19d4addea1dcda1",
            "@type": "ScholarlyArticle",
            "paperId": "4112c641f6338801adf3e846b19d4addea1dcda1",
            "corpusId": 7352545,
            "url": "https://www.semanticscholar.org/paper/4112c641f6338801adf3e846b19d4addea1dcda1",
            "title": "Be Your Own Prada: Fashion Synthesis with Structural Coherence",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1710.07346",
                "MAG": "2964318046",
                "DBLP": "conf/iccv/ZhuFULL17",
                "DOI": "10.1109/ICCV.2017.186",
                "CorpusId": 7352545
            },
            "abstract": "We present a novel and effective approach for generating new clothing on a wearer through generative adversarial learning. Given an input image of a person and a sentence describing a different outfit, our model \u201credresses\u201d the person as desired, while at the same time keeping the wearer and her/his pose unchanged. Generating new outfits with precise regions conforming to a language description while retaining wearer\u2019s body structure is a new challenging task. Existing generative adversarial networks are not ideal in ensuring global coherence of structure given both the input photograph and language description as conditions. We address this challenge by decomposing the complex generative process into two conditional stages. In the first stage, we generate a plausible semantic segmentation map that obeys the wearer\u2019s pose as a latent spatial arrangement. An effective spatial constraint is formulated to guide the generation of this semantic segmentation map. In the second stage, a generative model with a newly proposed compositional mapping layer is used to render the final image with precise regions and textures conditioned on this map. We extended the DeepFashion dataset [8] by collecting sentence descriptions for 79K images. We demonstrate the effectiveness of our approach through both quantitative and qualitative evaluations. A user study is also conducted.",
            "referenceCount": 20,
            "citationCount": 237,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1710.07346",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Art",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-10-01",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhu2017BeYO,\n author = {Shizhan Zhu and S. Fidler and R. Urtasun and Dahua Lin and Chen Change Loy},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2017 IEEE International Conference on Computer Vision (ICCV)},\n pages = {1689-1697},\n title = {Be Your Own Prada: Fashion Synthesis with Structural Coherence},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:29a6c8f788ebdd46eeb8f01785cb4f2bacb85fbb",
            "@type": "ScholarlyArticle",
            "paperId": "29a6c8f788ebdd46eeb8f01785cb4f2bacb85fbb",
            "corpusId": 1409719,
            "url": "https://www.semanticscholar.org/paper/29a6c8f788ebdd46eeb8f01785cb4f2bacb85fbb",
            "title": "Pixel-Level Domain Transfer",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1603.07442",
                "MAG": "2953083657",
                "DBLP": "journals/corr/YooKPPK16",
                "DOI": "10.1007/978-3-319-46484-8_31",
                "CorpusId": 1409719
            },
            "abstract": null,
            "referenceCount": 29,
            "citationCount": 290,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1603.07442",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-03-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yoo2016PixelLevelDT,\n author = {Donggeun Yoo and Namil Kim and Sunggyun Park and Anthony S. Paek and In-So Kweon},\n booktitle = {European Conference on Computer Vision},\n pages = {517-532},\n title = {Pixel-Level Domain Transfer},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ab1d44fe7ee9165974a2487b6d10ddaba6c26549",
            "@type": "ScholarlyArticle",
            "paperId": "ab1d44fe7ee9165974a2487b6d10ddaba6c26549",
            "corpusId": 3833836,
            "url": "https://www.semanticscholar.org/paper/ab1d44fe7ee9165974a2487b6d10ddaba6c26549",
            "title": "De Novo Design of Bioactive Small Molecules by Artificial Intelligence",
            "venue": "Molecular Informatics",
            "publicationVenue": {
                "id": "urn:research:5b118ecf-59a2-431d-8c47-4656f9e92e08",
                "name": "Molecular Informatics",
                "alternate_names": [
                    "Mol Informatics"
                ],
                "issn": "1868-1743",
                "url": "http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1868-1751"
            },
            "year": 2018,
            "externalIds": {
                "PubMedCentral": "5838524",
                "MAG": "2784270883",
                "DOI": "10.1002/minf.201700153",
                "CorpusId": 3833836,
                "PubMed": "29319225"
            },
            "abstract": "Generative artificial intelligence offers a fresh view on molecular design. We present the first\u2010time prospective application of a deep learning model for designing new druglike compounds with desired activities. For this purpose, we trained a recurrent neural network to capture the constitution of a large set of known bioactive compounds represented as SMILES strings. By transfer learning, this general model was fine\u2010tuned on recognizing retinoid X and peroxisome proliferator\u2010activated receptor agonists. We synthesized five top\u2010ranking compounds designed by the generative model. Four of the compounds revealed nanomolar to low\u2010micromolar receptor modulatory activity in cell\u2010based assays. Apparently, the computational model intrinsically captured relevant chemical and biological knowledge without the need for explicit rules. The results of this study advocate generative artificial intelligence for prospective de novo molecular design, and demonstrate the potential of these methods for future medicinal chemistry.",
            "referenceCount": 19,
            "citationCount": 230,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/minf.201700153",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-01-01",
            "journal": {
                "name": "Molecular Informatics",
                "volume": "37"
            },
            "citationStyles": {
                "bibtex": "@Article{Merk2018DeND,\n author = {D. Merk and Lukas Friedrich and F. Grisoni and G. Schneider},\n booktitle = {Molecular Informatics},\n journal = {Molecular Informatics},\n title = {De Novo Design of Bioactive Small Molecules by Artificial Intelligence},\n volume = {37},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e09f6b0ddee0f7cfd1a7e2d56899f2d8d8774e77",
            "@type": "ScholarlyArticle",
            "paperId": "e09f6b0ddee0f7cfd1a7e2d56899f2d8d8774e77",
            "corpusId": 203568679,
            "url": "https://www.semanticscholar.org/paper/e09f6b0ddee0f7cfd1a7e2d56899f2d8d8774e77",
            "title": "Generalised free energy and active inference",
            "venue": "Biological cybernetics",
            "publicationVenue": {
                "id": "urn:research:57cada26-a03e-494e-929e-a71ac35f2ad0",
                "name": "Biological cybernetics",
                "alternate_names": [
                    "Biological cybern",
                    "Biological Cybern",
                    "Biological Cybernetics"
                ],
                "issn": "0340-1200",
                "url": "http://link.springer.com/journal/422"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/bc/ParrF19",
                "PubMedCentral": "6848054",
                "MAG": "2976973594",
                "DOI": "10.1007/s00422-019-00805-w",
                "CorpusId": 203568679,
                "PubMed": "31562544"
            },
            "abstract": null,
            "referenceCount": 95,
            "citationCount": 128,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s00422-019-00805-w.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-09-27",
            "journal": {
                "name": "Biological Cybernetics",
                "volume": "113"
            },
            "citationStyles": {
                "bibtex": "@Article{Parr2019GeneralisedFE,\n author = {Thomas Parr and Karl J. Friston},\n booktitle = {Biological cybernetics},\n journal = {Biological Cybernetics},\n pages = {495 - 513},\n title = {Generalised free energy and active inference},\n volume = {113},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8a532fddea4e335b82b6e1e6002014922ca2f800",
            "@type": "ScholarlyArticle",
            "paperId": "8a532fddea4e335b82b6e1e6002014922ca2f800",
            "corpusId": 5183931,
            "url": "https://www.semanticscholar.org/paper/8a532fddea4e335b82b6e1e6002014922ca2f800",
            "title": "Generative Programming for Embedded Software: An Industrial Experience Report",
            "venue": "International Conference on Generative Programming: Concepts and Experiences",
            "publicationVenue": {
                "id": "urn:research:42ba2c5a-a60c-4306-988d-ff0928f95afa",
                "name": "International Conference on Generative Programming: Concepts and Experiences",
                "alternate_names": [
                    "Generative Programming and Component Engineering",
                    "Gener Program Compon Eng",
                    "GPCE",
                    "Int Conf Gener Program Concept Exp"
                ],
                "issn": null,
                "url": "https://dl.acm.org/conference/gpce"
            },
            "year": 2002,
            "externalIds": {
                "MAG": "1530679938",
                "DBLP": "conf/gpce/CzarneckiBUE02",
                "DOI": "10.1007/3-540-45821-2_10",
                "CorpusId": 5183931
            },
            "abstract": null,
            "referenceCount": 19,
            "citationCount": 180,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2002-10-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Czarnecki2002GenerativePF,\n author = {K. Czarnecki and Thomas Bednasch and P. Unger and U. Eisenecker},\n booktitle = {International Conference on Generative Programming: Concepts and Experiences},\n pages = {156-172},\n title = {Generative Programming for Embedded Software: An Industrial Experience Report},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ba932d4e1b73784f432c9e54bf6fa51c34bf5dfe",
            "@type": "ScholarlyArticle",
            "paperId": "ba932d4e1b73784f432c9e54bf6fa51c34bf5dfe",
            "corpusId": 143071163,
            "url": "https://www.semanticscholar.org/paper/ba932d4e1b73784f432c9e54bf6fa51c34bf5dfe",
            "title": "The Generative Society: Caring for Future Generations",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "1807127505",
                "DOI": "10.1037/10622-000",
                "CorpusId": 143071163
            },
            "abstract": "The Generative Society - An Introduction, Ed de St Aubin, Dan P. McAdams, Tae-Chang Kim What is Generativity? Dan P. McAdams, Regina L. Logan Generativity and Culture - What Meaning Can Do, John Kotre Reflections On Generativity and Society - A Sociologist's Perspective, Kai Erikson The Propagation of Genes and Memes - Generativity Through Culture in Japan and the USA, Ed de St Aubin Generativity as Social Responsibility - The Role Of Generations in Societal Continuity and Change, Takatoshi Imada The Generative Life Cycle Model - Integration of Japanese Folk Images and Generativity, Yoko Yamada Rope of Ashes - Global Ageing, Generativity and Education, Ronald Manheimer Generativity Behind Bars - Some \"Redemptive Truth\" About Prison Society, Shadd Marun, Thomas P. LeBel, Charles S. Lanier Religion, Cultural Change and Generativity in American Society, Michele Dillon, Paul Wink Generativity and Gender - The Politics of Care, Bonnie J. Miller-McLemore Guarding the Next Generation - The Politics of Generativity, Bill E. Peterson Generativity and The Politics of Intergenerational Fairness, Takeshi Sasaki Generativity and The Psychology of Volunteerism, Mark Snyder, E. Gil Clary An Ethical Analysis of Erikson's Concept of Generativity, Don Browning Erikson on Generativity - A Biographer's Perspective, Lawrence J. Friendman Generative Society - An Epilogue, Ed de St Augin, Dan P. McAdams, Tae-Chang Kim.",
            "referenceCount": 0,
            "citationCount": 159,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Sociology",
                    "source": "external"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2003-08-31",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Aubin2003TheGS,\n author = {Ed de St. Aubin and D. McAdams and Tae-Chang Kim},\n title = {The Generative Society: Caring for Future Generations},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:522e300f2f51e9124057ef597e2f00c4678f287b",
            "@type": "ScholarlyArticle",
            "paperId": "522e300f2f51e9124057ef597e2f00c4678f287b",
            "corpusId": 9821240,
            "url": "https://www.semanticscholar.org/paper/522e300f2f51e9124057ef597e2f00c4678f287b",
            "title": "The Tradeoff Between Generative and Discriminative Classifiers",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2231077521",
                "CorpusId": 9821240
            },
            "abstract": "Given any generative classifier based on an inexact density model, we can define a discriminative counterpart that reduces its asymptotic error rate. We introduce a family of classifiers that interpolate the two approaches, thus providing a new way to compare them and giving an estimation procedure whose classification performance is well balanced between the bias of generative classifiers and the variance of discriminative ones. We show that an intermediate trade-off between the two strategies is often preferable, both theoretically and in experiments on real data.",
            "referenceCount": 7,
            "citationCount": 170,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2004-08-23",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Bouchard2004TheTB,\n author = {Guillaume Bouchard and B. Triggs},\n title = {The Tradeoff Between Generative and Discriminative Classifiers},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eef58d85880ab19737f4880fcff19fdc7ec1db99",
            "@type": "ScholarlyArticle",
            "paperId": "eef58d85880ab19737f4880fcff19fdc7ec1db99",
            "corpusId": 13349289,
            "url": "https://www.semanticscholar.org/paper/eef58d85880ab19737f4880fcff19fdc7ec1db99",
            "title": "When Does Non-Negative Matrix Factorization Give a Correct Decomposition into Parts?",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2003,
            "externalIds": {
                "DBLP": "conf/nips/DonohoS03",
                "MAG": "2140318696",
                "DOI": "10.7916/D88D05N7",
                "CorpusId": 13349289
            },
            "abstract": "We interpret non-negative matrix factorization geometrically, as the problem of finding a simplicial cone which contains a cloud of data points and which is contained in the positive orthant. We show that under certain conditions, basically requiring that some of the data are spread across the faces of the positive orthant, there is a unique such simplicial cone. We give examples of synthetic image articulation databases which obey these conditions; these require separated support and factorial sampling. For such databases there is a generative model in terms of 'parts' and NMF correctly identifies the 'parts'. We show that our theoretical results are predictive of the performance of published NMF code, by running the published algorithms on one of our synthetic image articulation databases.",
            "referenceCount": 9,
            "citationCount": 917,
            "influentialCitationCount": 65,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2003-12-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Donoho2003WhenDN,\n author = {D. Donoho and V. Stodden},\n booktitle = {Neural Information Processing Systems},\n pages = {1141-1148},\n title = {When Does Non-Negative Matrix Factorization Give a Correct Decomposition into Parts?},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cf0b953baf42df871c614ed9a9524ac3d3bb607a",
            "@type": "ScholarlyArticle",
            "paperId": "cf0b953baf42df871c614ed9a9524ac3d3bb607a",
            "corpusId": 18928729,
            "url": "https://www.semanticscholar.org/paper/cf0b953baf42df871c614ed9a9524ac3d3bb607a",
            "title": "Generative mesh modeling",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "phd/de/Havemann2005",
                "MAG": "2294967900",
                "DOI": "10.2312/8171",
                "CorpusId": 18928729
            },
            "abstract": "Die generative Modellierung ist ein alternativer Ansatz zur Beschreibung von dreidimensionaler Form. Zugrunde liegt die Idee, ein Modell nicht wie ublich durch eine Ansammlung geometrischer Primitive (Dreiecke, Punkte, NURBS-Patches) zu beschreiben, sondern durch Funktionen. Der Paradigmenwechsel von Objekten zu Geometrie-erzeugenden Operationen ermoglicht es, prozedurale Modelle auch prozedural zu reprasentieren. Statt das Resultat eines 3D-Konstruktionsprozesses zu speichern, kann so der Konstruktionsprozess selber reprasentiert werden. Der generative Ansatz eroffnet unter anderem ganzlich neue Perspektiven fur das Wissensmanagement im 3D-Bereich. Er ermoglicht etwa, auf einen Fundus bereits geloster Konstruktions-Aufgaben zuruckzugreifen, um sie in ahnlichen, aber leicht variierten Situationen wiederverwenden zu konnen. Das Konstruktions-Wissen kann dazu in Form von Bibliotheken parametrisierter, Domanen-spezifischer Modellier-Werkzeuge gesammelt werden. Konkret wird dazu eine neue allgemeine Modell-Beschreibungs-Sprache vorgeschlagen, die \"Generative Modeling Language\" GML. Als Turing-machtige \"Programmiersprache fur Form\" stellt sie eine echte Verallgemeinerung existierender Primitiv-basierter 3D-Modellformate dar. Zusammen mit ihrer Runtime-Engine erlaubt die GML, - hochkomplexe 3D-Objekte extrem kompakt zu beschreiben, - die Beschreibung innerhalb von Sekundenbruchteilen auszuwerten, - das Modell adaptiv darzustellen und interaktiv zu betrachten, - und die Modell-Parameter interaktiv zu verandern.",
            "referenceCount": 9,
            "citationCount": 130,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Philosophy"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Philosophy",
                    "source": "external"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2005-11-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Havemann2005GenerativeMM,\n author = {Sven Havemann},\n pages = {1-295},\n title = {Generative mesh modeling},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:05fd5aa1926c99ce0b658d4a85803f9f7bda1eb3",
            "@type": "ScholarlyArticle",
            "paperId": "05fd5aa1926c99ce0b658d4a85803f9f7bda1eb3",
            "corpusId": 34343512,
            "url": "https://www.semanticscholar.org/paper/05fd5aa1926c99ce0b658d4a85803f9f7bda1eb3",
            "title": "Discriminative, generative and imitative learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2002,
            "externalIds": {
                "MAG": "1553830511",
                "CorpusId": 34343512
            },
            "abstract": "I propose a common framework that combines three different paradigms in machine learning: generative, discriminative and imitative learning. A generative probabilistic distribution is a principled way to model many machine learning and machine perception problems. Therein, one provides domain specific knowledge in terms of structure and parameter priors over the joint space of variables. Bayesian networks and Bayesian statistics provide a rich and flexible language for specifying this knowledge and subsequently refining it with data and observations. The final result is a distribution that is a good generator of novel exemplars. Conversely, discriminative algorithms adjust a possibly non-distributional model to data optimizing for a specific task, such as classification or prediction. This typically leads to superior performance yet compromises the flexibility of generative modeling. I present Maximum Entropy Discrimination (MED) as a framework to combine both discriminative estimation and generative probability densities. Calculations involve distributions over parameters, margins, and priors and are provably and uniquely solvable for the exponential family. Extensions include regression, feature selection, and transduction. SVMs are also naturally subsumed and can be augmented with, for example, feature selection, to obtain substantial improvements. To extend to mixtures of exponential families, I derive a discriminative variant of the ExpectationMaximization (EM) algorithm for latent discriminative learning (or latent MED). While EM and Jensen lower bound log-likelihood, a dual upper bound is made possible via a novel reverse-Jensen inequality. The variational upper bound on latent log-likelihood has the same form as EM bounds, is computable efficiently and is globally guaranteed. It permits powerful discriminative learning with the wide range of contemporary probabilistic mixture models (mixtures of Gaussians, mixtures of multinomials and hidden Markov models). We provide empirical results on standardized data sets that demonstrate the viability of the hybrid discriminative-generative approaches of MED and reverse-Jensen bounds over state of the art discriminative techniques or generative approaches. Subsequently, imitative learning is presented as another variation on generative modeling which also learns from exemplars from an observed data source. However, the distinction is that the generative model is an agent that is interacting in a much more complex surrounding external world. It is not efficient to model the aggregate space in a generative setting. I demonstrate that imitative learning (under appropriate conditions) can be adequately addressed as a discriminative prediction task which outperforms the usual generative approach. This discriminative-imitative learning approach is applied with a generative perceptual system to synthesize a real-time agent that learns to engage in social interactive behavior. Thesis Supervisor: Alex Pentland Title: Toshiba Professor of Media Arts and Sciences, MIT Media Lab Discriminative, Generative and Imitative Learning",
            "referenceCount": 185,
            "citationCount": 111,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Jebara2002DiscriminativeGA,\n author = {T. Jebara and A. Pentland},\n title = {Discriminative, generative and imitative learning},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:de51d1ce6124c29a914d21f1878893cd52cfeda3",
            "@type": "ScholarlyArticle",
            "paperId": "de51d1ce6124c29a914d21f1878893cd52cfeda3",
            "corpusId": 2111087,
            "url": "https://www.semanticscholar.org/paper/de51d1ce6124c29a914d21f1878893cd52cfeda3",
            "title": "Adaptive Discriminative Generative Model and Its Applications",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2128027845",
                "DBLP": "conf/nips/LinRLY04",
                "CorpusId": 2111087
            },
            "abstract": "This paper presents an adaptive discriminative generative model that generalizes the conventional Fisher Linear Discriminant algorithm and renders a proper probabilistic interpretation. Within the context of object tracking, we aim to find a discriminative generative model that best separates the target from the background. We present a computationally efficient algorithm to constantly update this discriminative model as time progresses. While most tracking algorithms operate on the premise that the object appearance or ambient lighting condition does not significantly change as time progresses, our method adapts a discriminative generative model to reflect appearance variation of the target and background, thereby facilitating the tracking task in ever-changing environments. Numerous experiments show that our method is able to learn a discriminative generative model for tracking target objects undergoing large pose and lighting changes.",
            "referenceCount": 9,
            "citationCount": 93,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2004-12-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lin2004AdaptiveDG,\n author = {Ruei-Sung Lin and David A. Ross and Jongwoo Lim and Ming-Hsuan Yang},\n booktitle = {Neural Information Processing Systems},\n pages = {801-808},\n title = {Adaptive Discriminative Generative Model and Its Applications},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6a0b0a3dde4b3eda04090a86a56f8854c72938ea",
            "@type": "ScholarlyArticle",
            "paperId": "6a0b0a3dde4b3eda04090a86a56f8854c72938ea",
            "corpusId": 122441017,
            "url": "https://www.semanticscholar.org/paper/6a0b0a3dde4b3eda04090a86a56f8854c72938ea",
            "title": "Generative and non-linear phonology",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1989,
            "externalIds": {
                "MAG": "2123307154",
                "DOI": "10.4324/9781315846903",
                "CorpusId": 122441017
            },
            "abstract": "Part 1 Introduction: scope of this book from classical phonemics to generative phonology phonemes or features? levels of representation aspects of a standard generative analysis of Midi French phonology within the model of grammar. Part 2 The theory of distinctive features: some general assumptions the phonetic features and their articulatory correlates universalism revisited the acoustic/auditory basis of DFs invariance and distinctive features. Part 3 Binarism, full and partial specification, markedness and gestures: binarism multivalued features contrastivity, archiphonemes and redundancy rules markedness theory gestures. Part 4 The derivational issue - aspects of the abstractness-concreteness debate: aspects of the segmental phonology of English objections to the vowel shift and velar softening natural generative phonology (NGP) in defence of the vowel shift. Part 5 Underspecification theory and lexical phonology: underspecification theory (UT) Yawelmani vowels and underspecification lexical phonology. Part 6 Metrical structures: syllable structure stress and prominence. Part 7 Autosegmental and multidimensional phonology: tone in the SPE framework the skeletal tier further geometrical extensions universal phonology and the \"no rule\" approach. Part 8 An outline of dependency phonology: suprasegmental representations infrasegmental representations back unrounded vowels. Appendix: phonetic symbols.",
            "referenceCount": 0,
            "citationCount": 198,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Durand1989GenerativeAN,\n author = {J. Durand},\n title = {Generative and non-linear phonology},\n year = {1989}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9da429ce36afc75f2c457880a9d7129220ac9225",
            "@type": "ScholarlyArticle",
            "paperId": "9da429ce36afc75f2c457880a9d7129220ac9225",
            "corpusId": 52847135,
            "url": "https://www.semanticscholar.org/paper/9da429ce36afc75f2c457880a9d7129220ac9225",
            "title": "Joint Pose and Expression Modeling for Facial Expression Recognition",
            "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/cvpr/ZhangZMX18",
                "MAG": "2798553619",
                "DOI": "10.1109/CVPR.2018.00354",
                "CorpusId": 52847135
            },
            "abstract": "Facial expression recognition (FER) is a challenging task due to different expressions under arbitrary poses. Most conventional approaches either perform face frontalization on a non-frontal facial image or learn separate classifiers for each pose. Different from existing methods, in this paper, we propose an end-to-end deep learning model by exploiting different poses and expressions jointly for simultaneous facial image synthesis and pose-invariant facial expression recognition. The proposed model is based on generative adversarial network (GAN) and enjoys several merits. First, the encoder-decoder structure of the generator can learn a generative and discriminative identity representation for face images. Second, the identity representation is explicitly disentangled from both expression and pose variations through the expression and pose codes. Third, our model can automatically generate face images with different expressions under arbitrary poses to enlarge and enrich the training set for FER. Quantitative and qualitative evaluations on both controlled and in-the-wild datasets demonstrate that the proposed algorithm performs favorably against state-of-the-art methods.",
            "referenceCount": 65,
            "citationCount": 183,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018JointPA,\n author = {Feifei Zhang and Tianzhu Zhang and Qi-rong Mao and Changsheng Xu},\n booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n pages = {3359-3368},\n title = {Joint Pose and Expression Modeling for Facial Expression Recognition},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ba2a4b0a6a51f74793c5da6cffbc08fbd142e001",
            "@type": "ScholarlyArticle",
            "paperId": "ba2a4b0a6a51f74793c5da6cffbc08fbd142e001",
            "corpusId": 102353856,
            "url": "https://www.semanticscholar.org/paper/ba2a4b0a6a51f74793c5da6cffbc08fbd142e001",
            "title": "The Born supremacy: quantum advantage and training of an Ising Born machine",
            "venue": "npj Quantum Information",
            "publicationVenue": {
                "id": "urn:research:f8411b17-d726-4af8-a6ae-1ee0b6a5877f",
                "name": "npj Quantum Information",
                "alternate_names": [
                    "npj Quantum Inf"
                ],
                "issn": "2056-6387",
                "url": "http://www.nature.com/npjqi/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1904.02214",
                "MAG": "2926552232",
                "DBLP": "journals/corr/abs-1904-02214",
                "DOI": "10.1038/S41534-020-00288-9",
                "CorpusId": 102353856
            },
            "abstract": null,
            "referenceCount": 121,
            "citationCount": 110,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41534-020-00288-9.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-04-03",
            "journal": {
                "name": "npj Quantum Information",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Coyle2019TheBS,\n author = {Brian Coyle and Daniel Mills and V. Danos and E. Kashefi},\n booktitle = {npj Quantum Information},\n journal = {npj Quantum Information},\n pages = {1-11},\n title = {The Born supremacy: quantum advantage and training of an Ising Born machine},\n volume = {6},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4bb1aea1dcc109087ce607128c6e4127f97adc0f",
            "@type": "ScholarlyArticle",
            "paperId": "4bb1aea1dcc109087ce607128c6e4127f97adc0f",
            "corpusId": 144675099,
            "url": "https://www.semanticscholar.org/paper/4bb1aea1dcc109087ce607128c6e4127f97adc0f",
            "title": "Generative Teaching of Comprehension",
            "venue": "The Elementary school journal",
            "publicationVenue": {
                "id": "urn:research:ae0003f3-2fe8-4446-a7e4-50cf7fc628b8",
                "name": "The Elementary school journal",
                "alternate_names": [
                    "Elementary Sch J",
                    "Elementary sch j",
                    "Elementary School Journal"
                ],
                "issn": "0013-5984",
                "url": "http://www.journals.uchicago.edu/esj"
            },
            "year": 1991,
            "externalIds": {
                "MAG": "2066589994",
                "DOI": "10.1086/461686",
                "CorpusId": 144675099
            },
            "abstract": "This article presents a model of the teaching of comprehension. The model of generative teaching of comprehension consists of 4 related parts: (1) students' knowledge base and preconceptions, (2) motivation, (3) attention, and (4) generation. Research on the teaching of science and reading comprehension that underlies the model is discussed first. The 4 components of the model are presented next. The article concludes with a discussion of generative teaching procedures appropriate for facilitating comprehension in elementary school. These procedures begin with an emphasis on direct instruction focused on comprehension, followed by increasing involvement of student-generated comprehension procedures, and conclude with the teaching and learning of metacognitive procedures.",
            "referenceCount": 39,
            "citationCount": 126,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1991-11-01",
            "journal": {
                "name": "The Elementary School Journal",
                "volume": "92"
            },
            "citationStyles": {
                "bibtex": "@Article{Wittrock1991GenerativeTO,\n author = {M. Wittrock},\n booktitle = {The Elementary school journal},\n journal = {The Elementary School Journal},\n pages = {169 - 184},\n title = {Generative Teaching of Comprehension},\n volume = {92},\n year = {1991}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9f834ee11902ada79b874e7fe5072159d72a0f9f",
            "@type": "ScholarlyArticle",
            "paperId": "9f834ee11902ada79b874e7fe5072159d72a0f9f",
            "corpusId": 1968269,
            "url": "https://www.semanticscholar.org/paper/9f834ee11902ada79b874e7fe5072159d72a0f9f",
            "title": "Unsupervised Learning of the Morphology of a Natural Language",
            "venue": "International Conference on Computational Logic",
            "publicationVenue": {
                "id": "urn:research:30a8645d-22d4-42e2-b3f6-304bf4ce3a02",
                "name": "International Conference on Computational Logic",
                "alternate_names": [
                    "CL",
                    "Int Conf Comput Log"
                ],
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "DBLP": "journals/coling/Goldsmith01",
                "ACL": "J01-2001",
                "MAG": "2101711363",
                "DOI": "10.1162/089120101750300490",
                "CorpusId": 1968269
            },
            "abstract": "This study reports the results of using minimum description length (MDL) analysis to model unsupervised learning of the morphological segmentation of European languages, using corpora ranging in size from 5,000 words to 500,000 words. We develop a set of heuristics that rapidly develop a probabilistic morphological grammar, and use MDL as our primary tool to determine whether the modifications proposed by the heuristics will be adopted or not. The resulting grammar matches well the analysis that would be developed by a human morphologist. In the final section, we discuss the relationship of this style of MDL grammatical analysis to the notion of evaluation metric in early generative grammar.",
            "referenceCount": 60,
            "citationCount": 867,
            "influentialCitationCount": 83,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.mitpressjournals.org/doi/pdf/10.1162/089120101750300490",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2001-06-01",
            "journal": {
                "name": "Computational Linguistics",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Goldsmith2001UnsupervisedLO,\n author = {J. Goldsmith},\n booktitle = {International Conference on Computational Logic},\n journal = {Computational Linguistics},\n pages = {153-198},\n title = {Unsupervised Learning of the Morphology of a Natural Language},\n volume = {27},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1d6e6adc7a841393fc10b78dc0018e550aff589d",
            "@type": "ScholarlyArticle",
            "paperId": "1d6e6adc7a841393fc10b78dc0018e550aff589d",
            "corpusId": 8049057,
            "url": "https://www.semanticscholar.org/paper/1d6e6adc7a841393fc10b78dc0018e550aff589d",
            "title": "Provable Bounds for Learning Some Deep Representations",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/icml/AroraBGM14",
                "MAG": "2143915663",
                "ArXiv": "1310.6343",
                "CorpusId": 8049057
            },
            "abstract": "We give algorithms with provable guarantees that learn a class of deep nets in the generative model view popularized by Hinton and others. Our generative model is an n node multilayer network that has degree at most n\u03b3 for some \u03b3 < 1 and each edge has a random edge weight in [-1, 1]. Our algorithm learns almost all networks in this class with polynomial running time. The sample complexity is quadratic or cubic depending upon the details of the model. \n \nThe algorithm uses layerwise learning. It is based upon a novel idea of observing correlations among features and using these to infer the underlying edge structure via a global graph recovery procedure. The analysis of the algorithm reveals interesting structure of neural nets with random edge weights.",
            "referenceCount": 26,
            "citationCount": 323,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-10-23",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Arora2013ProvableBF,\n author = {Sanjeev Arora and Aditya Bhaskara and Rong Ge and Tengyu Ma},\n booktitle = {International Conference on Machine Learning},\n pages = {584-592},\n title = {Provable Bounds for Learning Some Deep Representations},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1d52330930ad15dddfe0a27b4e047f266bceb92c",
            "@type": "ScholarlyArticle",
            "paperId": "1d52330930ad15dddfe0a27b4e047f266bceb92c",
            "corpusId": 145637080,
            "url": "https://www.semanticscholar.org/paper/1d52330930ad15dddfe0a27b4e047f266bceb92c",
            "title": "The Teaching of Reading Comprehension according to the Model of Generative Learning.",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1981,
            "externalIds": {
                "MAG": "2077378076",
                "DOI": "10.2307/747248",
                "CorpusId": 145637080
            },
            "abstract": "AN INSTRUCTIONAL SEQUENCE derived from Wittrock's model of generative learning was presented in classrooms for three days to 58 ten-year-old children. The purpose of the study was to determine the utility of the model for teaching reading in elementary school classrooms. Employing a unifactor, four-treatment design with participants individually and randomly assigned to the treatments, the data supported (p<.01) the hypothesis that, with time held constant, children instructed to generate associations for the text during reading show greater comprehension of that text than do children not instructed to generate the associations. The findings also confirm the hypothesis that these instructions to generate associations for the text increased the number of text-related associations produced during learning, which apparently led to increases in fact retention and story comprehension. The data support predictions from the model of generative learning and indicate its utility for improving the teaching of reading in elementary schools.",
            "referenceCount": 14,
            "citationCount": 132,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Reading Research Quarterly",
                "volume": "17"
            },
            "citationStyles": {
                "bibtex": "@Article{Linden1981TheTO,\n author = {Michele A Linden and M. Wittrock},\n journal = {Reading Research Quarterly},\n pages = {44-57},\n title = {The Teaching of Reading Comprehension according to the Model of Generative Learning.},\n volume = {17},\n year = {1981}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ed8adc34f92e11edde3660de870bbd238eef697f",
            "@type": "ScholarlyArticle",
            "paperId": "ed8adc34f92e11edde3660de870bbd238eef697f",
            "corpusId": 227321150,
            "url": "https://www.semanticscholar.org/paper/ed8adc34f92e11edde3660de870bbd238eef697f",
            "title": "A Generative Model of Mathematics Learning.",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1974,
            "externalIds": {
                "MAG": "2000606989",
                "DOI": "10.5951/JRESEMATHEDUC.5.4.0181",
                "CorpusId": 227321150
            },
            "abstract": "meaning for mathematics education, this paper will begin with a hypothesis about human learning that has been developed from the investigator's research in cognition, discovery learning, and instruction in schools. It will then present a sample of the empirical studies that led to the generation of the hypothesis. Finally, some of the meaning of this research for mathematics learning will be discussed. The first point to emerge will be that we can be proud of the research in the learning of mathematics, including the development of curricular materials. The second point will be a recommendation that research in mathematics learning should increasingly be devoted to studying the stepby-step specific and higher-order intellectual processes that students engage in when they learn mathematics; such as when they are adding, subtracting, differentiating, and integrating. The hypothesis and empirical studies presented in this paper focus on the cognitive, generative processes that are involved in the learning of mathematics. These processes could perhaps be presented in simpler S-R terminology. The cognitive model emphasizes the learner's active, stepby-step processing of information, and is more compatible with the author's point of view. The data to be discussed will probably arouse recollections of the This is a slightly edited version of a paper commissioned by the ERIC Information Analysis Center for Science, Mathematics, and Environmental Education and presented at a session of the Special Interest Group for Research in Mathematics Education. The session, held 28 February 1973, was in conjunction with the AERA Annual Meeting. The paper was prepared pursuant to a contract with the Office of Education, U.S. Department of Health, Education, and Welfare. Contractors undertaking such projects under government sponsorship are encouraged to express freely their judgment in professional and technical matters. Points of view or opinions do not, therefore, necessarily represent official Office of Education position or policy.",
            "referenceCount": 27,
            "citationCount": 89,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1974-11-01",
            "journal": {
                "name": "Journal for Research in Mathematics Education",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Wittrock1974AGM,\n author = {M. Wittrock},\n journal = {Journal for Research in Mathematics Education},\n pages = {181-196},\n title = {A Generative Model of Mathematics Learning.},\n volume = {5},\n year = {1974}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:85c8f5345c29b3016cf1ebdcb99d2e65c062a439",
            "@type": "ScholarlyArticle",
            "paperId": "85c8f5345c29b3016cf1ebdcb99d2e65c062a439",
            "corpusId": 145262960,
            "url": "https://www.semanticscholar.org/paper/85c8f5345c29b3016cf1ebdcb99d2e65c062a439",
            "title": "The Generative Learning Model and Its Implications for Science Education.",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1985,
            "externalIds": {
                "MAG": "2091190366",
                "DOI": "10.1080/03057268508559923",
                "CorpusId": 145262960
            },
            "abstract": null,
            "referenceCount": 100,
            "citationCount": 379,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Studies in Science Education",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Osborne1985TheGL,\n author = {R. Osborne and M. Wittrock},\n journal = {Studies in Science Education},\n pages = {59-87},\n title = {The Generative Learning Model and Its Implications for Science Education.},\n volume = {12},\n year = {1985}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e0485ca5fc4600740edd1372fe81b419d1409ad4",
            "@type": "ScholarlyArticle",
            "paperId": "e0485ca5fc4600740edd1372fe81b419d1409ad4",
            "corpusId": 2516262,
            "url": "https://www.semanticscholar.org/paper/e0485ca5fc4600740edd1372fe81b419d1409ad4",
            "title": "3D Shape Induction from 2D Views of Multiple Objects",
            "venue": "International Conference on 3D Vision",
            "publicationVenue": {
                "id": "urn:research:4b02e809-1c26-4203-b9ba-311a418f664b",
                "name": "International Conference on 3D Vision",
                "alternate_names": [
                    "Int Conf 3D Vis",
                    "3DV"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2951733136",
                "DBLP": "conf/3dim/GadelhaMW17",
                "ArXiv": "1612.05872",
                "DOI": "10.1109/3DV.2017.00053",
                "CorpusId": 2516262
            },
            "abstract": "In this paper we investigate the problem of inducing a distribution over three-dimensional structures given two-dimensional views of multiple objects taken from unknown viewpoints. Our approach called \"projective generative adversarial networks\" (PrGANs) trains a deep generative model of 3D shapes whose projections match the distributions of the input 2D views. The addition of a projection module allows us to infer the underlying 3D shape distribution without using any 3D, viewpoint information, or annotation during the learning phase. We show that our approach produces 3D shapes of comparable quality to GANs trained on 3D data for a number of shape categories including chairs, airplanes, and cars. Experiments also show that the disentangled representation of 2D shapes into geometry and viewpoint leads to a good generative model of 2D shapes. The key advantage is that our model allows us to predict 3D, viewpoint, and generate novel views from an input image in a completely unsupervised manner.",
            "referenceCount": 39,
            "citationCount": 250,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1612.05872",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-12-18",
            "journal": {
                "name": "2017 International Conference on 3D Vision (3DV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gadelha20163DSI,\n author = {Matheus Gadelha and Subhransu Maji and Rui Wang},\n booktitle = {International Conference on 3D Vision},\n journal = {2017 International Conference on 3D Vision (3DV)},\n pages = {402-411},\n title = {3D Shape Induction from 2D Views of Multiple Objects},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4714f863564b32be86dab6f2cd7ef8fbecc9bafb",
            "@type": "ScholarlyArticle",
            "paperId": "4714f863564b32be86dab6f2cd7ef8fbecc9bafb",
            "corpusId": 16003169,
            "url": "https://www.semanticscholar.org/paper/4714f863564b32be86dab6f2cd7ef8fbecc9bafb",
            "title": "Robust Brain Extraction Across Datasets and Comparison With Publicly Available Methods",
            "venue": "IEEE Transactions on Medical Imaging",
            "publicationVenue": {
                "id": "urn:research:e0cda45d-3074-4ac0-80b8-e5250df00b89",
                "name": "IEEE Transactions on Medical Imaging",
                "alternate_names": [
                    "IEEE Trans Med Imaging"
                ],
                "issn": "0278-0062",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=42"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2145661921",
                "DBLP": "journals/tmi/IglesiasLTT11",
                "DOI": "10.1109/TMI.2011.2138152",
                "CorpusId": 16003169,
                "PubMed": "21880566"
            },
            "abstract": "Automatic whole-brain extraction from magnetic resonance images (MRI), also known as skull stripping, is a key component in most neuroimage pipelines. As the first element in the chain, its robustness is critical for the overall performance of the system. Many skull stripping methods have been proposed, but the problem is not considered to be completely solved yet. Many systems in the literature have good performance on certain datasets (mostly the datasets they were trained/tuned on), but fail to produce satisfactory results when the acquisition conditions or study populations are different. In this paper we introduce a robust, learning-based brain extraction system (ROBEX). The method combines a discriminative and a generative model to achieve the final result. The discriminative model is a Random Forest classifier trained to detect the brain boundary; the generative model is a point distribution model that ensures that the result is plausible. When a new image is presented to the system, the generative model is explored to find the contour with highest likelihood according to the discriminative model. Because the target shape is in general not perfectly represented by the generative model, the contour is refined using graph cuts to obtain the final segmentation. Both models were trained using 92 scans from a proprietary dataset but they achieve a high degree of robustness on a variety of other datasets. ROBEX was compared with six other popular, publicly available methods (BET, BSE, FreeSurfer, AFNI, BridgeBurner, and GCUT) on three publicly available datasets (IBSR, LPBA40, and OASIS, 137 scans in total) that include a wide range of acquisition hardware and a highly variable population (different age groups, healthy/diseased). The results show that ROBEX provides significantly improved performance measures for almost every method/dataset combination.",
            "referenceCount": 49,
            "citationCount": 515,
            "influentialCitationCount": 48,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study"
            ],
            "publicationDate": "2011-04-05",
            "journal": {
                "name": "IEEE Transactions on Medical Imaging",
                "volume": "30"
            },
            "citationStyles": {
                "bibtex": "@Article{Iglesias2011RobustBE,\n author = {J. E. Iglesias and Cheng-Yi Liu and P. Thompson and Z. Tu},\n booktitle = {IEEE Transactions on Medical Imaging},\n journal = {IEEE Transactions on Medical Imaging},\n pages = {1617-1634},\n title = {Robust Brain Extraction Across Datasets and Comparison With Publicly Available Methods},\n volume = {30},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:90e71b7678c30e02e464b83d815bfae683ca58a9",
            "@type": "ScholarlyArticle",
            "paperId": "90e71b7678c30e02e464b83d815bfae683ca58a9",
            "corpusId": 148609552,
            "url": "https://www.semanticscholar.org/paper/90e71b7678c30e02e464b83d815bfae683ca58a9",
            "title": "The Morningside Model of Generative Instruction",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2752853474",
                "DOI": "10.1016/B978-012506041-7/50015-2",
                "CorpusId": 148609552
            },
            "abstract": null,
            "referenceCount": 72,
            "citationCount": 113,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Johnson2004TheMM,\n author = {Kent Johnson and E. Street},\n pages = {247-265},\n title = {The Morningside Model of Generative Instruction},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dec1e718aa2929c7c95870b87131361b257710f6",
            "@type": "ScholarlyArticle",
            "paperId": "dec1e718aa2929c7c95870b87131361b257710f6",
            "corpusId": 5937822,
            "url": "https://www.semanticscholar.org/paper/dec1e718aa2929c7c95870b87131361b257710f6",
            "title": "Generative model-based clustering of directional data",
            "venue": "Knowledge Discovery and Data Mining",
            "publicationVenue": {
                "id": "urn:research:a0edb93b-1e95-4128-a295-6b1659149cef",
                "name": "Knowledge Discovery and Data Mining",
                "alternate_names": [
                    "KDD",
                    "Knowl Discov Data Min"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigkdd/"
            },
            "year": 2003,
            "externalIds": {
                "DBLP": "conf/kdd/BanerjeeDGS03",
                "MAG": "2123504323",
                "DOI": "10.1145/956750.956757",
                "CorpusId": 5937822
            },
            "abstract": "High dimensional directional data is becoming increasingly important in contemporary applications such as analysis of text and gene-expression data. A natural model for multi-variate directional data is provided by the von Mises-Fisher (vMF) distribution on the unit hypersphere that is analogous to the multi-variate Gaussian distribution in Rd. In this paper, we propose modeling complex directional data as a mixture of vMF distributions. We derive and analyze two variants of the Expectation Maximization (EM) framework for estimating the parameters of this mixture. We also propose two clustering algorithms corresponding to these variants. An interesting aspect of our methodology is that the spherical kmeans algorithm (kmeans with cosine similarity) can be shown to be a special case of both our algorithms. Thus, modeling text data by vMF distributions lends theoretical validity to the use of cosine similarity which has been widely used by the information retrieval community. As part of experimental validation, we present results on modeling high-dimensional text and gene-expression data as a mixture of vMF distributions. The results indicate that our approach yields superior clusterings especially for difficult clustering tasks in high-dimensional spaces.",
            "referenceCount": 30,
            "citationCount": 125,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.ideal.ece.utexas.edu/pdfs/116.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2003-08-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Banerjee2003GenerativeMC,\n author = {A. Banerjee and I. Dhillon and Joydeep Ghosh and S. Sra},\n booktitle = {Knowledge Discovery and Data Mining},\n pages = {19-28},\n title = {Generative model-based clustering of directional data},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7ac58552d17190ccdfc3313833911b3d758b8c58",
            "@type": "ScholarlyArticle",
            "paperId": "7ac58552d17190ccdfc3313833911b3d758b8c58",
            "corpusId": 7849677,
            "url": "https://www.semanticscholar.org/paper/7ac58552d17190ccdfc3313833911b3d758b8c58",
            "title": "DeepHawkes: Bridging the Gap between Prediction and Understanding of Information Cascades",
            "venue": "International Conference on Information and Knowledge Management",
            "publicationVenue": {
                "id": "urn:research:7431ff67-91dc-41fa-b322-1b1ca657025f",
                "name": "International Conference on Information and Knowledge Management",
                "alternate_names": [
                    "Conference on Information and Knowledge Management",
                    "Conf Inf Knowl Manag",
                    "Int Conf Inf Knowl Manag",
                    "CIKM"
                ],
                "issn": null,
                "url": "http://www.cikm.org/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2767220239",
                "DBLP": "conf/cikm/CaoSCOC17",
                "DOI": "10.1145/3132847.3132973",
                "CorpusId": 7849677
            },
            "abstract": "Online social media remarkably facilitates the production and delivery of information, intensifying the competition among vast information for users' attention and highlighting the importance of predicting the popularity of information. Existing approaches for popularity prediction fall into two paradigms: feature-based approaches and generative approaches. Feature-based approaches extract various features (e.g., user, content, structural, and temporal features), and predict the future popularity of information by training a regression/classification model. Their predictive performance heavily depends on the quality of hand-crafted features. In contrast, generative approaches devote to characterizing and modeling the process that a piece of information accrues attentions, offering us high ease to understand the underlying mechanisms governing the popularity dynamics of information cascades. But they have less desirable predictive power since they are not optimized for popularity prediction. In this paper, we propose DeepHawkes to combat the defects of existing methods, leveraging end-to-end deep learning to make an analogy to interpretable factors of Hawkes process --- a widely-used generative process to model information cascade. DeepHawkes inherits the high interpretability of Hawkes process and possesses the high predictive power of deep learning methods, bridging the gap between prediction and understanding of information cascades. We verify the effectiveness of DeepHawkes by applying it to predict retweet cascades of Sina Weibo and citation cascades of a longitudinal citation dataset. Experimental results demonstrate that DeepHawkes outperforms both feature-based and generative approaches.",
            "referenceCount": 38,
            "citationCount": 181,
            "influentialCitationCount": 32,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2017-11-06",
            "journal": {
                "name": "Proceedings of the 2017 ACM on Conference on Information and Knowledge Management",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cao2017DeepHawkesBT,\n author = {Qi Cao and Huawei Shen and Keting Cen and W. Ouyang and Xueqi Cheng},\n booktitle = {International Conference on Information and Knowledge Management},\n journal = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},\n title = {DeepHawkes: Bridging the Gap between Prediction and Understanding of Information Cascades},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a44038cceb09003c59d0d7c27a7f30cf3ae909b2",
            "@type": "ScholarlyArticle",
            "paperId": "a44038cceb09003c59d0d7c27a7f30cf3ae909b2",
            "corpusId": 56913733,
            "url": "https://www.semanticscholar.org/paper/a44038cceb09003c59d0d7c27a7f30cf3ae909b2",
            "title": "Generative modeling for computer graphics and CAD",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1993,
            "externalIds": {
                "MAG": "2921080332",
                "DOI": "10.1016/0378-4754(93)90023-N",
                "CorpusId": 56913733
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 76,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1993-04-01",
            "journal": {
                "name": "Mathematics and Computers in Simulation",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Ames1993GenerativeMF,\n author = {W. Ames and C. Brezinski},\n journal = {Mathematics and Computers in Simulation},\n pages = {189-189},\n title = {Generative modeling for computer graphics and CAD},\n volume = {35},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:69eec600696dce2dcf411fd2f932382cf9ed1738",
            "@type": "ScholarlyArticle",
            "paperId": "69eec600696dce2dcf411fd2f932382cf9ed1738",
            "corpusId": 7282120,
            "url": "https://www.semanticscholar.org/paper/69eec600696dce2dcf411fd2f932382cf9ed1738",
            "title": "Generative model for feedback networks.",
            "venue": "Physical review. E, Statistical, nonlinear, and soft matter physics",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2123642213",
                "ArXiv": "cond-mat/0508028",
                "DOI": "10.1103/PhysRevE.73.016119",
                "CorpusId": 7282120,
                "PubMed": "16486228"
            },
            "abstract": "We propose a model for network formation and study some of its statistical properties. The motivation for the model comes from the growth of several kinds of real networks (i.e., kinship and trading networks, networks of corporate alliances, networks of autocatalytic chemical reactions). These networks grow either by establishing closer connections by adding links in the existing network or by adding new nodes. A node in these networks lacks the information of the entire network. In order to establish a closer connection to other nodes it starts a search in the neighboring part of the network and waits for a possible feedback from a distant node that received the \"searching signal.\" Our model imitates this behavior by growing the network via the addition of a link that creates a cycle in the network or via the addition of a new node with a link to the network. The forming of a cycle creates feedback between the two ending nodes. After choosing a starting node, a search is made for another node at a suitable distance; if such a node is found, a link is established between this and the starting node, otherwise (such a node cannot be found) a new node is added and is linked to the starting node. We simulate this algorithm and find that we cannot reject the hypothesis that the empirical degree distribution is a q-exponential function, which has been used to model long-range processes in nonequilibrium statistical mechanics.",
            "referenceCount": 54,
            "citationCount": 61,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/cond-mat/0508028",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Physics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2005-07-31",
            "journal": {
                "name": "Physical review. E, Statistical, nonlinear, and soft matter physics",
                "volume": "73 1 Pt 2"
            },
            "citationStyles": {
                "bibtex": "@Article{White2005GenerativeMF,\n author = {D. R. White and N. Kej\u017ear and C. Tsallis and D. Farmer and Scott White},\n booktitle = {Physical review. E, Statistical, nonlinear, and soft matter physics},\n journal = {Physical review. E, Statistical, nonlinear, and soft matter physics},\n pages = {\n          016119\n        },\n title = {Generative model for feedback networks.},\n volume = {73 1 Pt 2},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7f94da5bfdfb74d5820c78656cd47ac746cd29f3",
            "@type": "ScholarlyArticle",
            "paperId": "7f94da5bfdfb74d5820c78656cd47ac746cd29f3",
            "corpusId": 1401840,
            "url": "https://www.semanticscholar.org/paper/7f94da5bfdfb74d5820c78656cd47ac746cd29f3",
            "title": "3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2742468459",
                "DBLP": "journals/corr/abs-1708-01648",
                "ArXiv": "1708.01648",
                "DOI": "10.1109/ICCV.2017.103",
                "CorpusId": 1401840
            },
            "abstract": "The success of various applications including robotics, digital content creation, and visualization demand a structured and abstract representation of the 3D world from limited sensor data. Inspired by the nature of human perception of 3D shapes as a collection of simple parts, we explore such an abstract shape representation based on primitives. Given a single depth image of an object, we present 3DPRNN, a generative recurrent neural network that synthesizes multiple plausible shapes composed of a set of primitives. Our generative model encodes symmetry characteristics of common man-made objects, preserves long-range structural coherence, and describes objects of varying complexity with a compact representation. We also propose a method based on Gaussian Fields to generate a large scale dataset of primitive-based shape representations to train our network. We evaluate our approach on a wide range of examples and show that it outperforms nearest-neighbor based shape retrieval methods and is on-par with voxelbased generative models while using a significantly reduced parameter space.",
            "referenceCount": 48,
            "citationCount": 169,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1708.01648",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-08-04",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zou20173DPRNNGS,\n author = {Chuhang Zou and Ersin Yumer and Jimei Yang and Duygu Ceylan and Derek Hoiem},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2017 IEEE International Conference on Computer Vision (ICCV)},\n pages = {900-909},\n title = {3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:497a80b2813cffb17f46af50e621a71505094528",
            "@type": "ScholarlyArticle",
            "paperId": "497a80b2813cffb17f46af50e621a71505094528",
            "corpusId": 14962437,
            "url": "https://www.semanticscholar.org/paper/497a80b2813cffb17f46af50e621a71505094528",
            "title": "Modeling Human Motion Using Binary Latent Variables",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "conf/nips/TaylorHR06",
                "MAG": "2158164339",
                "DOI": "10.7551/mitpress/7503.003.0173",
                "CorpusId": 14962437
            },
            "abstract": "We propose a non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued \"visible\" variables that represent joint angles. The latent and visible variables at each time step receive directed connections from the visible variables at the last few time-steps. Such an architecture makes on-line inference efficient and allows us to use a simple approximate learning procedure. After training, the model finds a single set of parameters that simultaneously capture several different kinds of motion. We demonstrate the power of our approach by synthesizing various motion sequences and by performing on-line filling in of data lost during motion capture.",
            "referenceCount": 14,
            "citationCount": 675,
            "influentialCitationCount": 59,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-12-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Taylor2006ModelingHM,\n author = {Graham W. Taylor and Geoffrey E. Hinton and S. Roweis},\n booktitle = {Neural Information Processing Systems},\n pages = {1345-1352},\n title = {Modeling Human Motion Using Binary Latent Variables},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0e991df08b00cb5d2af0b2324a64304bce4677b0",
            "@type": "ScholarlyArticle",
            "paperId": "0e991df08b00cb5d2af0b2324a64304bce4677b0",
            "corpusId": 14100875,
            "url": "https://www.semanticscholar.org/paper/0e991df08b00cb5d2af0b2324a64304bce4677b0",
            "title": "Application of Quantum Annealing to Training of Deep Neural Networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1510.06356",
                "DBLP": "journals/corr/AdachiH15",
                "MAG": "2120802379",
                "CorpusId": 14100875
            },
            "abstract": "In Deep Learning, a well-known approach for training a Deep Neural Network starts by training a generative Deep Belief Network model, typically using Contrastive Divergence (CD), then fine-tuning the weights using backpropagation or other discriminative techniques. However, the generative training can be time-consuming due to the slow mixing of Gibbs sampling. We investigated an alternative approach that estimates model expectations of Restricted Boltzmann Machines using samples from a D-Wave quantum annealing machine. We tested this method on a coarse-grained version of the MNIST data set. In our tests we found that the quantum sampling-based training approach achieves comparable or better accuracy with significantly fewer iterations of generative training than conventional CD-based training. Further investigation is needed to determine whether similar improvements can be achieved for other data sets, and to what extent these improvements can be attributed to quantum effects.",
            "referenceCount": 24,
            "citationCount": 222,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-10-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1510.06356"
            },
            "citationStyles": {
                "bibtex": "@Article{Adachi2015ApplicationOQ,\n author = {S. Adachi and Maxwell P. Henderson},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Application of Quantum Annealing to Training of Deep Neural Networks},\n volume = {abs/1510.06356},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b2d5e26faa76520244748d633c18ea1a70bd262d",
            "@type": "ScholarlyArticle",
            "paperId": "b2d5e26faa76520244748d633c18ea1a70bd262d",
            "corpusId": 119034689,
            "url": "https://www.semanticscholar.org/paper/b2d5e26faa76520244748d633c18ea1a70bd262d",
            "title": "A Generative Model of Intonation",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1983,
            "externalIds": {
                "MAG": "179489684",
                "DOI": "10.1007/978-3-642-69103-4_2",
                "CorpusId": 119034689
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 73,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{G\u00e5rding1983AGM,\n author = {E. G\u00e5rding},\n pages = {11-25},\n title = {A Generative Model of Intonation},\n year = {1983}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:573784d61ae23bc72186ce3bc38fe452b23d3031",
            "@type": "ScholarlyArticle",
            "paperId": "573784d61ae23bc72186ce3bc38fe452b23d3031",
            "corpusId": 1043470,
            "url": "https://www.semanticscholar.org/paper/573784d61ae23bc72186ce3bc38fe452b23d3031",
            "title": "Model-based feedback in the language modeling approach to information retrieval",
            "venue": "International Conference on Information and Knowledge Management",
            "publicationVenue": {
                "id": "urn:research:7431ff67-91dc-41fa-b322-1b1ca657025f",
                "name": "International Conference on Information and Knowledge Management",
                "alternate_names": [
                    "Conference on Information and Knowledge Management",
                    "Conf Inf Knowl Manag",
                    "Int Conf Inf Knowl Manag",
                    "CIKM"
                ],
                "issn": null,
                "url": "http://www.cikm.org/"
            },
            "year": 2001,
            "externalIds": {
                "DBLP": "conf/cikm/ZhaiL01",
                "MAG": "1964348731",
                "DOI": "10.1145/502585.502654",
                "CorpusId": 1043470
            },
            "abstract": "The language modeling approach to retrieval has been shown to perform well empirically. One advantage of this new approach is its statistical foundations. However, feedback, as one important component in a retrieval system, has only been dealt with heuristically in this new retrieval approach: the original query is usually literally expanded by adding additional terms to it. Such expansion-based feedback creates an inconsistent interpretation of the original and the expanded query. In this paper, we present a more principled approach to feedback in the language modeling approach. Specifically, we treat feedback as updating the query language model based on the extra evidence carried by the feedback documents. Such a model-based feedback strategy easily fits into an extension of the language modeling approach. We propose and evaluate two different approaches to updating a query language model based on feedback documents, one based on a generative probabilistic model of feedback documents and one based on minimization of the KL-divergence over feedback documents. Experiment results show that both approaches are effective and outperform the Rocchio feedback approach.",
            "referenceCount": 18,
            "citationCount": 852,
            "influentialCitationCount": 105,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2001-10-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhai2001ModelbasedFI,\n author = {ChengXiang Zhai and J. Lafferty},\n booktitle = {International Conference on Information and Knowledge Management},\n pages = {403-410},\n title = {Model-based feedback in the language modeling approach to information retrieval},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c9573b704088d1d026bf7869030fc4a9d320ab55",
            "@type": "ScholarlyArticle",
            "paperId": "c9573b704088d1d026bf7869030fc4a9d320ab55",
            "corpusId": 102351463,
            "url": "https://www.semanticscholar.org/paper/c9573b704088d1d026bf7869030fc4a9d320ab55",
            "title": "An Integrated Approach for Keyphrase Generation via Exploring the Power of Retrieval and Extraction",
            "venue": "North American Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:01103732-3808-4930-b8e4-7e9e68d5c68d",
                "name": "North American Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "North Am Chapter Assoc Comput Linguistics",
                    "NAACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/naacl"
            },
            "year": 2019,
            "externalIds": {
                "ACL": "N19-1292",
                "ArXiv": "1904.03454",
                "MAG": "2932847124",
                "DBLP": "journals/corr/abs-1904-03454",
                "DOI": "10.18653/v1/N19-1292",
                "CorpusId": 102351463
            },
            "abstract": "In this paper, we present a novel integrated approach for keyphrase generation (KG). Unlike previous works which are purely extractive or generative, we first propose a new multi-task learning framework that jointly learns an extractive model and a generative model. Besides extracting keyphrases, the output of the extractive model is also employed to rectify the copy probability distribution of the generative model, such that the generative model can better identify important contents from the given document. Moreover, we retrieve similar documents with the given document from training data and use their associated keyphrases as external knowledge for the generative model to produce more accurate keyphrases. For further exploiting the power of extraction and retrieval, we propose a neural-based merging module to combine and re-rank the predicted keyphrases from the enhanced generative model, the extractive model, and the retrieved keyphrases. Experiments on the five KG benchmarks demonstrate that our integrated approach outperforms the state-of-the-art methods.",
            "referenceCount": 40,
            "citationCount": 51,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1904.03454",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1904.03454"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2019AnIA,\n author = {Wang Chen and Hou Pong Chan and Piji Li and Lidong Bing and Irwin King},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {An Integrated Approach for Keyphrase Generation via Exploring the Power of Retrieval and Extraction},\n volume = {abs/1904.03454},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d62a9746861aecbfb689745abb860c1c773a12b1",
            "@type": "ScholarlyArticle",
            "paperId": "d62a9746861aecbfb689745abb860c1c773a12b1",
            "corpusId": 14282237,
            "url": "https://www.semanticscholar.org/paper/d62a9746861aecbfb689745abb860c1c773a12b1",
            "title": "Variational Recurrent Auto-Encoders",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1933340426",
                "ArXiv": "1412.6581",
                "DBLP": "journals/corr/FabiusAK14",
                "CorpusId": 14282237
            },
            "abstract": "In this paper we propose a model that combines the strengths of RNNs and SGVB: the Variational Recurrent Auto-Encoder (VRAE). Such a model can be used for efficient, large scale unsupervised learning on time series data, mapping the time series data to a latent vector representation. The model is generative, such that data can be generated from samples of the latent space. An important contribution of this work is that the model can make use of unlabeled data in order to facilitate supervised training of RNNs by initialising the weights and network state.",
            "referenceCount": 12,
            "citationCount": 201,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-12-19",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1412.6581"
            },
            "citationStyles": {
                "bibtex": "@Article{Fabius2014VariationalRA,\n author = {Otto Fabius and Joost R. van Amersfoort and Diederik P. Kingma},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Variational Recurrent Auto-Encoders},\n volume = {abs/1412.6581},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:695a2c95eacdbccb7a73d2f1e90e7b35b4b3d864",
            "@type": "ScholarlyArticle",
            "paperId": "695a2c95eacdbccb7a73d2f1e90e7b35b4b3d864",
            "corpusId": 14576846,
            "url": "https://www.semanticscholar.org/paper/695a2c95eacdbccb7a73d2f1e90e7b35b4b3d864",
            "title": "Deep AutoRegressive Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/icml/GregorDMBW14",
                "ArXiv": "1310.8499",
                "MAG": "2949595773",
                "CorpusId": 14576846
            },
            "abstract": "We introduce a deep, generative autoencoder capable of learning hierarchies of distributed representations from data. Successive deep stochastic hidden layers are equipped with autoregressive connections, which enable the model to be sampled from quickly and exactly via ancestral sampling. We derive an efficient approximate parameter estimation method based on the minimum description length (MDL) principle, which can be seen as maximising a variational lower bound on the log-likelihood, with a feedforward neural network implementing approximate inference. We demonstrate state-of-the-art generative performance on a number of classic data sets, including several UCI data sets, MNIST and Atari 2600 games.",
            "referenceCount": 29,
            "citationCount": 240,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-10-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1310.8499"
            },
            "citationStyles": {
                "bibtex": "@Article{Gregor2013DeepAN,\n author = {Karol Gregor and Ivo Danihelka and A. Mnih and C. Blundell and Daan Wierstra},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Deep AutoRegressive Networks},\n volume = {abs/1310.8499},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2fbfd6a9daa73756196ec663d65019a7a9b58600",
            "@type": "ScholarlyArticle",
            "paperId": "2fbfd6a9daa73756196ec663d65019a7a9b58600",
            "corpusId": 1041733,
            "url": "https://www.semanticscholar.org/paper/2fbfd6a9daa73756196ec663d65019a7a9b58600",
            "title": "Cosegmentation of Image Pairs by Histogram Matching - Incorporating a Global Constraint into MRFs",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2527686042",
                "DBLP": "conf/cvpr/RotherMBK06",
                "DOI": "10.1109/CVPR.2006.91",
                "CorpusId": 1041733
            },
            "abstract": "We introduce the term cosegmentation which denotes the task of segmenting simultaneously the common parts of an image pair. A generative model for cosegmentation is presented. Inference in the model leads to minimizing an energy with an MRF term encoding spatial coherency and a global constraint which attempts to match the appearance histograms of the common parts. This energy has not been proposed previously and its optimization is challenging and NP-hard. For this problem a novel optimization scheme which we call trust region graph cuts is presented. We demonstrate that this framework has the potential to improve a wide range of research: Object driven image retrieval, video tracking and segmentation, and interactive image editing. The power of the framework lies in its generality, the common part can be a rigid/non-rigid object (or scene), observed from different viewpoints or even similar objects of the same class.",
            "referenceCount": 23,
            "citationCount": 588,
            "influentialCitationCount": 64,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-06-17",
            "journal": {
                "name": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Rother2006CosegmentationOI,\n author = {C. Rother and T. Minka and A. Blake and V. Kolmogorov},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},\n pages = {993-1000},\n title = {Cosegmentation of Image Pairs by Histogram Matching - Incorporating a Global Constraint into MRFs},\n volume = {1},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:41e6727bd2163b2d094873701f919db315f45001",
            "@type": "ScholarlyArticle",
            "paperId": "41e6727bd2163b2d094873701f919db315f45001",
            "corpusId": 3329316,
            "url": "https://www.semanticscholar.org/paper/41e6727bd2163b2d094873701f919db315f45001",
            "title": "WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2787803546",
                "ArXiv": "1803.01328",
                "DBLP": "conf/iclr/Zhang0GZ18",
                "CorpusId": 3329316
            },
            "abstract": "To train an inference network jointly with a deep generative topic model, making it both scalable to big corpora and fast in out-of-sample prediction, we develop Weibull hybrid autoencoding inference (WHAI) for deep latent Dirichlet allocation, which infers posterior samples via a hybrid of stochastic-gradient MCMC and autoencoding variational Bayes. The generative network of WHAI has a hierarchy of gamma distributions, while the inference network of WHAI is a Weibull upward-downward variational autoencoder, which integrates a deterministic-upward deep neural network, and a stochastic-downward deep generative model based on a hierarchy of Weibull distributions. The Weibull distribution can be used to well approximate a gamma distribution with an analytic Kullback-Leibler divergence, and has a simple reparameterization via the uniform noise, which help efficiently compute the gradients of the evidence lower bound with respect to the parameters of the inference network. The effectiveness and efficiency of WHAI are illustrated with experiments on big corpora.",
            "referenceCount": 37,
            "citationCount": 99,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": "arXiv: Machine Learning",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2018WHAIWH,\n author = {Hao Zhang and Bo Chen and D. Guo and Mingyuan Zhou},\n booktitle = {International Conference on Learning Representations},\n journal = {arXiv: Machine Learning},\n title = {WHAI: Weibull Hybrid Autoencoding Inference for Deep Topic Modeling},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0e870469f332b3f787559b1ecc54909e41307d73",
            "@type": "ScholarlyArticle",
            "paperId": "0e870469f332b3f787559b1ecc54909e41307d73",
            "corpusId": 1903062,
            "url": "https://www.semanticscholar.org/paper/0e870469f332b3f787559b1ecc54909e41307d73",
            "title": "A probabilistic model for component-based shape synthesis",
            "venue": "ACM Transactions on Graphics",
            "publicationVenue": {
                "id": "urn:research:aab03e41-f80d-48b3-89bd-60eeeceafc7d",
                "name": "ACM Transactions on Graphics",
                "alternate_names": [
                    "ACM Trans Graph"
                ],
                "issn": "0730-0301",
                "url": "http://www.acm.org/tog/"
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "journals/tog/KalogerakisCKK12",
                "MAG": "2092773680",
                "DOI": "10.1145/2185520.2185551",
                "CorpusId": 1903062
            },
            "abstract": "We present an approach to synthesizing shapes from complex domains, by identifying new plausible combinations of components from existing shapes. Our primary contribution is a new generative model of component-based shape structure. The model represents probabilistic relationships between properties of shape components, and relates them to learned underlying causes of structural variability within the domain. These causes are treated as latent variables, leading to a compact representation that can be effectively learned without supervision from a set of compatibly segmented shapes. We evaluate the model on a number of shape datasets with complex structural variability and demonstrate its application to amplification of shape databases and to interactive shape synthesis.",
            "referenceCount": 41,
            "citationCount": 367,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://people.cs.umass.edu/~kalo/papers/ShapeSynthesis/ShapeSynthesis.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-07-01",
            "journal": {
                "name": "ACM Transactions on Graphics (TOG)",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Kalogerakis2012APM,\n author = {E. Kalogerakis and S. Chaudhuri and D. Koller and V. Koltun},\n booktitle = {ACM Transactions on Graphics},\n journal = {ACM Transactions on Graphics (TOG)},\n pages = {1 - 11},\n title = {A probabilistic model for component-based shape synthesis},\n volume = {31},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d250fc92d4d29923f968ef3b60b2ceb92808712e",
            "@type": "ScholarlyArticle",
            "paperId": "d250fc92d4d29923f968ef3b60b2ceb92808712e",
            "corpusId": 34275422,
            "url": "https://www.semanticscholar.org/paper/d250fc92d4d29923f968ef3b60b2ceb92808712e",
            "title": "Wavenet Based Low Rate Speech Coding",
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "publicationVenue": {
                "id": "urn:research:0d6f7fba-7092-46b3-8039-93458dba736b",
                "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                "alternate_names": [
                    "Int Conf Acoust Speech Signal Process",
                    "IEEE Int Conf Acoust Speech Signal Process",
                    "ICASSP",
                    "International Conference on Acoustics, Speech, and Signal Processing"
                ],
                "issn": null,
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2775336875",
                "ArXiv": "1712.01120",
                "DBLP": "conf/icassp/KleijnLLSSWW18",
                "DOI": "10.1109/ICASSP.2018.8462529",
                "CorpusId": 34275422
            },
            "abstract": "Traditional parametric coding of speech facilitates low rate but provides poor reconstruction quality because of the inadequacy of the model used. We describe how a WaveNet generative speech model can be used to generate high quality speech from the bit stream of a standard parametric coder operating at 2.4 kb/s. We compare this parametric coder with a waveform coder based on the same generative model and show that approximating the signal waveform incurs a large rate penalty. Our experiments confirm the high performance of the WaveNet based coder and show that the speech produced by the system is able to additionally perform implicit bandwidth extension and does not significantly impair recognition of the original speaker for the human listener, even when that speaker has not been used during the training of the generative model.",
            "referenceCount": 34,
            "citationCount": 111,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1712.01120",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-12-01",
            "journal": {
                "name": "2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kleijn2017WavenetBL,\n author = {W. Kleijn and Felicia S. C. Lim and Alejandro Luebs and J. Skoglund and Florian Stimberg and Quan Wang and Thomas C. Walters},\n booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},\n journal = {2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n pages = {676-680},\n title = {Wavenet Based Low Rate Speech Coding},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:00cd1dab559a9671b692f39f14c1573ab2d1416b",
            "@type": "ScholarlyArticle",
            "paperId": "00cd1dab559a9671b692f39f14c1573ab2d1416b",
            "corpusId": 9383489,
            "url": "https://www.semanticscholar.org/paper/00cd1dab559a9671b692f39f14c1573ab2d1416b",
            "title": "Efficient Learning of Deep Boltzmann Machines",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "MAG": "177847060",
                "DBLP": "journals/jmlr/SalakhutdinovL10",
                "CorpusId": 9383489
            },
            "abstract": "We present a new approximate inference algorithm for Deep Boltzmann Machines (DBM\u2019s), a generative model with many layers of hidden variables. The algorithm learns a separate \u201crecognition\u201d model that is used to quickly initialize, in a single bottom-up pass, the values of the latent variables in all hidden layers. We show that using such a recognition model, followed by a combined top-down and bottom-up pass, it is possible to efficiently learn a good generative model of high-dimensional highly-structured sensory input. We show that the additional computations required by incorporating a top-down feedback plays a critical role in the performance of a DBM, both as a generative and discriminative model. Moreover, inference is only at most three times slower compared to the approximate inference in a Deep Belief Network (DBN), making large-scale learning of DBM\u2019s practical. Finally, we demonstrate that the DBM\u2019s trained using the proposed approximate inference algorithm perform well compared to DBN\u2019s and SVM\u2019s on the MNIST handwritten digit, OCR English letters, and NORB visual object recognition tasks.",
            "referenceCount": 18,
            "citationCount": 393,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-03-31",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Salakhutdinov2010EfficientLO,\n author = {R. Salakhutdinov and H. Larochelle},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n pages = {693-700},\n title = {Efficient Learning of Deep Boltzmann Machines},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:814b36fedfe7f7ce10eaa72bddb3c7ea7a663f37",
            "@type": "ScholarlyArticle",
            "paperId": "814b36fedfe7f7ce10eaa72bddb3c7ea7a663f37",
            "corpusId": 19562686,
            "url": "https://www.semanticscholar.org/paper/814b36fedfe7f7ce10eaa72bddb3c7ea7a663f37",
            "title": "End-to-End Differentiable Adversarial Imitation Learning",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2740210681",
                "DBLP": "conf/icml/BaramACM17",
                "CorpusId": 19562686
            },
            "abstract": "Generative Adversarial Networks (GANs) have been successfully applied to the problem of policy imitation in a model-free setup. However, the computation graph of GANs, that include a stochastic policy as the generative model, is no longer differentiable end-to-end, which requires the use of high-variance gradient estimation. In this paper, we introduce the Modelbased Generative Adversarial Imitation Learning (MGAIL) algorithm. We show how to use a forward model to make the computation fully differentiable, which enables training policies using the exact gradient of the discriminator. The resulting algorithm trains competent policies using relatively fewer expert samples and interactions with the environment. We test it on both discrete and continuous action domains and report results that surpass the state-of-the-art.",
            "referenceCount": 35,
            "citationCount": 87,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-07-17",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Baram2017EndtoEndDA,\n author = {Nir Baram and Oron Anschel and I. Caspi and Shie Mannor},\n booktitle = {International Conference on Machine Learning},\n pages = {390-399},\n title = {End-to-End Differentiable Adversarial Imitation Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a814c1b2f461d054dfed2d3c7b8a078653a8170d",
            "@type": "ScholarlyArticle",
            "paperId": "a814c1b2f461d054dfed2d3c7b8a078653a8170d",
            "corpusId": 13514150,
            "url": "https://www.semanticscholar.org/paper/a814c1b2f461d054dfed2d3c7b8a078653a8170d",
            "title": "A Psychovisual Quality Metric in Free-Energy Principle",
            "venue": "IEEE Transactions on Image Processing",
            "publicationVenue": {
                "id": "urn:research:e117fa7f-05b7-4dd6-b64b-0a0a7c0393d8",
                "name": "IEEE Transactions on Image Processing",
                "alternate_names": [
                    "IEEE Trans Image Process"
                ],
                "issn": "1057-7149",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=83"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2158546915",
                "DBLP": "journals/tip/ZhaiWYLZ12",
                "DOI": "10.1109/TIP.2011.2161092",
                "CorpusId": 13514150,
                "PubMed": "21724508"
            },
            "abstract": "In this paper, we propose a new psychovisual quality metric of images based on recent developments in brain theory and neuroscience, particularly the free-energy principle. The perception and understanding of an image is modeled as an active inference process, in which the brain tries to explain the scene using an internal generative model. The psychovisual quality is thus closely related to how accurately visual sensory data can be explained by the generative model, and the upper bound of the discrepancy between the image signal and its best internal description is given by the free energy of the cognition process. Therefore, the perceptual quality of an image can be quantified using the free energy. Constructively, we develop a reduced-reference free-energy-based distortion metric (FEDM) and a no-reference free-energy-based quality metric (NFEQM). The FEDM and the NFEQM are nearly invariant to many global systematic deviations in geometry and illumination that hardly affect visual quality, for which existing image quality metrics wrongly predict severe quality degradation. Although with very limited or even without information on the reference image, the FEDM and the NFEQM are highly competitive compared with the full-reference SSIM image quality metric on images in the popular LIVE database. Moreover, FEDM and NFEQM can measure correctly the visual quality of some model-based image processing algorithms, for which the competing metrics often contradict with viewers' opinions.",
            "referenceCount": 37,
            "citationCount": 243,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Transactions on Image Processing",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhai2012APQ,\n author = {Guangtao Zhai and Xiaolin Wu and Xiaokang Yang and Weisi Lin and Wenjun Zhang},\n booktitle = {IEEE Transactions on Image Processing},\n journal = {IEEE Transactions on Image Processing},\n pages = {41-52},\n title = {A Psychovisual Quality Metric in Free-Energy Principle},\n volume = {21},\n year = {2012}\n}\n"
            }
        }
    }
]