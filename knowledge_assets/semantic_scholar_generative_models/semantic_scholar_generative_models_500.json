[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa",
            "@type": "ScholarlyArticle",
            "paperId": "1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa",
            "corpusId": 235212350,
            "url": "https://www.semanticscholar.org/paper/1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa",
            "title": "CogView: Mastering Text-to-Image Generation via Transformers",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/nips/DingYHZZYLZSYT21",
                "ArXiv": "2105.13290",
                "CorpusId": 235212350
            },
            "abstract": "Text-to-Image generation in the general domain has long been an open problem, which requires both a powerful generative model and cross-modal understanding. We propose CogView, a 4-billion-parameter Transformer with VQ-VAE tokenizer to advance this problem. We also demonstrate the finetuning strategies for various downstream tasks, e.g. style learning, super-resolution, text-image ranking and fashion design, and methods to stabilize pretraining, e.g. eliminating NaN losses. CogView achieves the state-of-the-art FID on the blurred MS COCO dataset, outperforming previous GAN-based models and a recent similar work DALL-E.",
            "referenceCount": 58,
            "citationCount": 411,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-05-26",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ding2021CogViewMT,\n author = {Ming Ding and Zhuoyi Yang and Wenyi Hong and Wendi Zheng and Chang Zhou and Da Yin and Junyang Lin and Xu Zou and Zhou Shao and Hongxia Yang and Jie Tang},\n booktitle = {Neural Information Processing Systems},\n pages = {19822-19835},\n title = {CogView: Mastering Text-to-Image Generation via Transformers},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:232148b97bd0543613ffd98fb4edcff79434ce1a",
            "@type": "ScholarlyArticle",
            "paperId": "232148b97bd0543613ffd98fb4edcff79434ce1a",
            "corpusId": 6775391,
            "url": "https://www.semanticscholar.org/paper/232148b97bd0543613ffd98fb4edcff79434ce1a",
            "title": "End-to-end Optimized Image Compression",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/BalleLS16a",
                "MAG": "2951383350",
                "ArXiv": "1611.01704",
                "CorpusId": 6775391
            },
            "abstract": "We describe an image compression method, consisting of a nonlinear analysis transformation, a uniform quantizer, and a nonlinear synthesis transformation. The transforms are constructed in three successive stages of convolutional linear filters and nonlinear activation functions. Unlike most convolutional neural networks, the joint nonlinearity is chosen to implement a form of local gain control, inspired by those used to model biological neurons. Using a variant of stochastic gradient descent, we jointly optimize the entire model for rate-distortion performance over a database of training images, introducing a continuous proxy for the discontinuous loss function arising from the quantizer. Under certain conditions, the relaxed loss function may be interpreted as the log likelihood of a generative model, as implemented by a variational autoencoder. Unlike these models, however, the compression model must operate at any given point along the rate-distortion curve, as specified by a trade-off parameter. Across an independent set of test images, we find that the optimized method generally exhibits better rate-distortion performance than the standard JPEG and JPEG 2000 compression methods. More importantly, we observe a dramatic improvement in visual quality for all images at all bit rates, which is supported by objective quality estimates using MS-SSIM.",
            "referenceCount": 44,
            "citationCount": 1207,
            "influentialCitationCount": 259,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1611.01704"
            },
            "citationStyles": {
                "bibtex": "@Article{Ball\u00e92016EndtoendOI,\n author = {J. Ball\u00e9 and Valero Laparra and Eero P. Simoncelli},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {End-to-end Optimized Image Compression},\n volume = {abs/1611.01704},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1",
            "@type": "ScholarlyArticle",
            "paperId": "ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1",
            "corpusId": 9933254,
            "url": "https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1",
            "title": "Generating Videos with Scene Dynamics",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2520707650",
                "ArXiv": "1609.02612",
                "DBLP": "conf/nips/VondrickPT16",
                "DOI": "10.13016/M26GIH-TNYZ",
                "CorpusId": 9933254
            },
            "abstract": "We capitalize on large amounts of unlabeled video in order to learn a model of scene dynamics for both video recognition tasks (e.g. action classification) and video generation tasks (e.g. future prediction). We propose a generative adversarial network for video with a spatio-temporal convolutional architecture that untangles the scene's foreground from the background. Experiments suggest this model can generate tiny videos up to a second at full frame rate better than simple baselines, and we show its utility at predicting plausible futures of static images. Moreover, experiments and visualizations show the model internally learns useful features for recognizing actions with minimal supervision, suggesting scene dynamics are a promising signal for representation learning. We believe generative video models can impact many applications in video understanding and simulation.",
            "referenceCount": 60,
            "citationCount": 1321,
            "influentialCitationCount": 145,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-09-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Vondrick2016GeneratingVW,\n author = {Carl Vondrick and H. Pirsiavash and A. Torralba},\n booktitle = {Neural Information Processing Systems},\n pages = {613-621},\n title = {Generating Videos with Scene Dynamics},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:68cb9fce1e6af2740377494350b650533c9a29e1",
            "@type": "ScholarlyArticle",
            "paperId": "68cb9fce1e6af2740377494350b650533c9a29e1",
            "corpusId": 8229065,
            "url": "https://www.semanticscholar.org/paper/68cb9fce1e6af2740377494350b650533c9a29e1",
            "title": "Learning from Simulated and Unsupervised Images through Adversarial Training",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2567101557",
                "DBLP": "conf/cvpr/ShrivastavaPTSW17",
                "ArXiv": "1612.07828",
                "DOI": "10.1109/CVPR.2017.241",
                "CorpusId": 8229065
            },
            "abstract": "With recent progress in graphics, it has become more tractable to train models on synthetic images, potentially avoiding the need for expensive annotations. However, learning from synthetic images may not achieve the desired performance due to a gap between synthetic and real image distributions. To reduce this gap, we propose Simulated+Unsupervised (S+U) learning, where the task is to learn a model to improve the realism of a simulators output using unlabeled real data, while preserving the annotation information from the simulator. We develop a method for S+U learning that uses an adversarial network similar to Generative Adversarial Networks (GANs), but with synthetic images as inputs instead of random vectors. We make several key modifications to the standard GAN algorithm to preserve annotations, avoid artifacts, and stabilize training: (i) a self-regularization term, (ii) a local adversarial loss, and (iii) updating the discriminator using a history of refined images. We show that this enables generation of highly realistic images, which we demonstrate both qualitatively and with a user study. We quantitatively evaluate the generated images by training models for gaze estimation and hand pose estimation. We show a significant improvement over using synthetic images, and achieve state-of-the-art results on the MPIIGaze dataset without any labeled real data.",
            "referenceCount": 52,
            "citationCount": 1685,
            "influentialCitationCount": 128,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1612.07828",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-12-22",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shrivastava2016LearningFS,\n author = {A. Shrivastava and Tomas Pfister and Oncel Tuzel and J. Susskind and Wenda Wang and Russ Webb},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {2242-2251},\n title = {Learning from Simulated and Unsupervised Images through Adversarial Training},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1cb789ab8925bda02758bcb69eb0ed1547b5f4b9",
            "@type": "ScholarlyArticle",
            "paperId": "1cb789ab8925bda02758bcb69eb0ed1547b5f4b9",
            "corpusId": 27688749,
            "url": "https://www.semanticscholar.org/paper/1cb789ab8925bda02758bcb69eb0ed1547b5f4b9",
            "title": "Generating Focused Molecule Libraries for Drug Discovery with Recurrent Neural Networks",
            "venue": "ACS Central Science",
            "publicationVenue": {
                "id": "urn:research:df882f0f-d88c-4139-8462-219dcb05d97c",
                "name": "ACS Central Science",
                "alternate_names": [
                    "AC Central Sci",
                    "ACS central science",
                    "AC central sci"
                ],
                "issn": "2374-7943",
                "url": "https://pubs.acs.org/journal/acscii"
            },
            "year": 2017,
            "externalIds": {
                "PubMedCentral": "5785775",
                "MAG": "2578240541",
                "DOI": "10.1021/acscentsci.7b00512",
                "CorpusId": 27688749,
                "PubMed": "29392184"
            },
            "abstract": "In de novo drug design, computational strategies are used to generate novel molecules with good affinity to the desired biological target. In this work, we show that recurrent neural networks can be trained as generative models for molecular structures, similar to statistical language models in natural language processing. We demonstrate that the properties of the generated molecules correlate very well with the properties of the molecules used to train the model. In order to enrich libraries with molecules active toward a given biological target, we propose to fine-tune the model with small sets of molecules, which are known to be active against that target. Against Staphylococcus aureus, the model reproduced 14% of 6051 hold-out test molecules that medicinal chemists designed, whereas against Plasmodium falciparum (Malaria), it reproduced 28% of 1240 test molecules. When coupled with a scoring function, our model can perform the complete de novo drug design cycle to generate large sets of novel molecules for drug discovery.",
            "referenceCount": 76,
            "citationCount": 979,
            "influentialCitationCount": 44,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://pubs.acs.org/doi/pdf/10.1021/acscentsci.7b00512",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-12-28",
            "journal": {
                "name": "ACS Central Science",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Segler2017GeneratingFM,\n author = {Marwin H. S. Segler and T. Kogej and C. Tyrchan and M. Waller},\n booktitle = {ACS Central Science},\n journal = {ACS Central Science},\n pages = {120 - 131},\n title = {Generating Focused Molecule Libraries for Drug Discovery with Recurrent Neural Networks},\n volume = {4},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:90f72fbbe5f0a29e627db28999e01a30a9655bc6",
            "@type": "ScholarlyArticle",
            "paperId": "90f72fbbe5f0a29e627db28999e01a30a9655bc6",
            "corpusId": 1399080,
            "url": "https://www.semanticscholar.org/paper/90f72fbbe5f0a29e627db28999e01a30a9655bc6",
            "title": "MADE: Masked Autoencoder for Distribution Estimation",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/GermainGML15",
                "ArXiv": "1502.03509",
                "MAG": "2952838738",
                "CorpusId": 1399080
            },
            "abstract": "There has been a lot of recent interest in designing neural network models to estimate a distribution from a set of examples. We introduce a simple modification for autoencoder neural networks that yields powerful generative models. Our method masks the autoencoder's parameters to respect autoregressive constraints: each input is reconstructed only from previous inputs in a given ordering. Constrained this way, the autoencoder outputs can be interpreted as a set of conditional probabilities, and their product, the full joint probability. We can also train a single network that can decompose the joint probability in multiple different orderings. Our simple framework can be applied to multiple architectures, including deep ones. Vectorized implementations, such as on GPUs, are simple and fast. Experiments demonstrate that this approach is competitive with state-of-the-art tractable distribution estimators. At test time, the method is significantly faster and scales better than other autoregressive estimators.",
            "referenceCount": 23,
            "citationCount": 695,
            "influentialCitationCount": 122,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-02-11",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1502.03509"
            },
            "citationStyles": {
                "bibtex": "@Article{Germain2015MADEMA,\n author = {M. Germain and Karol Gregor and Iain Murray and H. Larochelle},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {MADE: Masked Autoencoder for Distribution Estimation},\n volume = {abs/1502.03509},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:37acbbbcfe9d8eb89e5b01da28dac6d44c3903ee",
            "@type": "ScholarlyArticle",
            "paperId": "37acbbbcfe9d8eb89e5b01da28dac6d44c3903ee",
            "corpusId": 14141965,
            "url": "https://www.semanticscholar.org/paper/37acbbbcfe9d8eb89e5b01da28dac6d44c3903ee",
            "title": "Data Programming: Creating Large Training Sets, Quickly",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2953310344",
                "ArXiv": "1605.07723",
                "DBLP": "journals/corr/RatnerSWSR16",
                "CorpusId": 14141965,
                "PubMed": "29872252"
            },
            "abstract": "Large labeled training sets are the critical building blocks of supervised learning methods and are key enablers of deep learning techniques. For some applications, creating labeled training sets is the most time-consuming and expensive part of applying machine learning. We therefore propose a paradigm for the programmatic creation of training sets called data programming in which users express weak supervision strategies or domain heuristics as labeling functions, which are programs that label subsets of the data, but that are noisy and may conflict. We show that by explicitly representing this training set labeling process as a generative model, we can \"denoise\" the generated training set, and establish theoretically that we can recover the parameters of these generative models in a handful of settings. We then show how to modify a discriminative loss function to make it noise-aware, and demonstrate our method over a range of discriminative models including logistic regression and LSTMs. Experimentally, on the 2014 TAC-KBP Slot Filling challenge, we show that data programming would have led to a new winning score, and also show that applying data programming to an LSTM model leads to a TAC-KBP score almost 6 F1 points over a state-of-the-art LSTM baseline (and into second place in the competition). Additionally, in initial user studies we observed that data programming may be an easier way for non-experts to create machine learning models when training data is limited or unavailable.",
            "referenceCount": 34,
            "citationCount": 618,
            "influentialCitationCount": 96,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-05-25",
            "journal": {
                "name": "Advances in neural information processing systems",
                "volume": "29"
            },
            "citationStyles": {
                "bibtex": "@Article{Ratner2016DataPC,\n author = {Alexander J. Ratner and Christopher De Sa and Sen Wu and Daniel Selsam and C. R\u00e9},\n booktitle = {Neural Information Processing Systems},\n journal = {Advances in neural information processing systems},\n pages = {\n          3567-3575\n        },\n title = {Data Programming: Creating Large Training Sets, Quickly},\n volume = {29},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:609e0f0e60ddfe83fdc71bf5397205323888289d",
            "@type": "ScholarlyArticle",
            "paperId": "609e0f0e60ddfe83fdc71bf5397205323888289d",
            "corpusId": 14857825,
            "url": "https://www.semanticscholar.org/paper/609e0f0e60ddfe83fdc71bf5397205323888289d",
            "title": "A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2399880602",
                "ArXiv": "1605.06069",
                "DBLP": "journals/corr/SerbanSLCPCB16",
                "DOI": "10.1609/aaai.v31i1.10983",
                "CorpusId": 14857825
            },
            "abstract": "\n \n Sequential data often possesses hierarchical structures with complex dependencies between sub-sequences, such as found between the utterances in a dialogue. To model these dependencies in a generative framework, we propose a neural network-based generative architecture, with stochastic latent variables that span a variable number of time steps. We apply the proposed model to the task of dialogue response generation and compare it with other recent neural-network architectures. We evaluate the model performance through a human evaluation study. The experiments demonstrate that our model improves upon recently proposed models and that the latent variables facilitate both the generation of meaningful, long and diverse responses and maintaining dialogue state.\n \n",
            "referenceCount": 43,
            "citationCount": 1038,
            "influentialCitationCount": 152,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/10983/10842",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-05-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1605.06069"
            },
            "citationStyles": {
                "bibtex": "@Article{Serban2016AHL,\n author = {Iulian Serban and Alessandro Sordoni and Ryan Lowe and Laurent Charlin and Joelle Pineau and Aaron C. Courville and Yoshua Bengio},\n booktitle = {AAAI Conference on Artificial Intelligence},\n journal = {ArXiv},\n title = {A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues},\n volume = {abs/1605.06069},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dee83f176dba9e70641115124c0829523cb32630",
            "@type": "ScholarlyArticle",
            "paperId": "dee83f176dba9e70641115124c0829523cb32630",
            "corpusId": 17969052,
            "url": "https://www.semanticscholar.org/paper/dee83f176dba9e70641115124c0829523cb32630",
            "title": "FAB-MAP: Probabilistic Localization and Mapping in the Space of Appearance",
            "venue": "Int. J. Robotics Res.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2144824356",
                "DBLP": "journals/ijrr/CumminsN08",
                "DOI": "10.1177/0278364908090961",
                "CorpusId": 17969052
            },
            "abstract": "This paper describes a probabilistic approach to the problem of recognizing places based on their appearance. The system we present is not limited to localization, but can determine that a new observation comes from a previously unseen place, and so augment its map. Effectively this is a SLAM system in the space of appearance. Our probabilistic approach allows us to explicitly account for perceptual aliasing in the environment\u2014identical but indistinctive observations receive a low probability of having come from the same place. We achieve this by learning a generative model of place appearance. By partitioning the learning problem into two parts, new place models can be learned online from only a single observation of a place. The algorithm complexity is linear in the number of places in the map, and is particularly suitable for online loop closure detection in mobile robotics.",
            "referenceCount": 47,
            "citationCount": 1502,
            "influentialCitationCount": 246,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-06-01",
            "journal": {
                "name": "The International Journal of Robotics Research",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Cummins2008FABMAPPL,\n author = {M. Cummins and P. Newman},\n booktitle = {Int. J. Robotics Res.},\n journal = {The International Journal of Robotics Research},\n pages = {647 - 665},\n title = {FAB-MAP: Probabilistic Localization and Mapping in the Space of Appearance},\n volume = {27},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:222928303a72d1389b0add8032a31abccbba41b3",
            "@type": "ScholarlyArticle",
            "paperId": "222928303a72d1389b0add8032a31abccbba41b3",
            "corpusId": 7648414,
            "url": "https://www.semanticscholar.org/paper/222928303a72d1389b0add8032a31abccbba41b3",
            "title": "Grammar Variational Autoencoder",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2949743074",
                "ArXiv": "1703.01925",
                "DBLP": "conf/icml/KusnerPH17",
                "CorpusId": 7648414
            },
            "abstract": "Deep generative models have been wildly successful at learning coherent latent representations for continuous data such as video and audio. However, generative modeling of discrete data such as arithmetic expressions and molecular structures still poses significant challenges. Crucially, state-of-the-art methods often produce outputs that are not valid. We make the key observation that frequently, discrete data can be represented as a parse tree from a context-free grammar. We propose a variational autoencoder which encodes and decodes directly to and from these parse trees, ensuring the generated outputs are always valid. Surprisingly, we show that not only does our model more often generate valid outputs, it also learns a more coherent latent space in which nearby points decode to similar discrete outputs. We demonstrate the effectiveness of our learned models by showing their improved performance in Bayesian optimization for symbolic regression and molecular synthesis.",
            "referenceCount": 46,
            "citationCount": 680,
            "influentialCitationCount": 91,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kusner2017GrammarVA,\n author = {Matt J. Kusner and Brooks Paige and Jos\u00e9 Miguel Hern\u00e1ndez-Lobato},\n booktitle = {International Conference on Machine Learning},\n pages = {1945-1954},\n title = {Grammar Variational Autoencoder},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:639937b3a1b8bded3f7e9a40e85bd3770016cf3c",
            "@type": "ScholarlyArticle",
            "paperId": "639937b3a1b8bded3f7e9a40e85bd3770016cf3c",
            "corpusId": 11021348,
            "url": "https://www.semanticscholar.org/paper/639937b3a1b8bded3f7e9a40e85bd3770016cf3c",
            "title": "A 3D Face Model for Pose and Illumination Invariant Face Recognition",
            "venue": "2009 Sixth IEEE International Conference on Advanced Video and Signal Based Surveillance",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "DBLP": "conf/avss/PaysanKARV09",
                "MAG": "2107037917",
                "DOI": "10.1109/AVSS.2009.58",
                "CorpusId": 11021348
            },
            "abstract": "Generative 3D face models are a powerful tool in computer vision. They provide pose and illumination invariance by modeling the space of 3D faces and the imaging process. The power of these models comes at the cost of an expensive and tedious construction process, which has led the community to focus on more easily constructed but less powerful models. With this paper we publish a generative 3D shape and texture model, the Basel Face Model (BFM), and demonstrate its application to several face recognition task. We improve on previous models by offering higher shape and texture accuracy due to a better scanning device and less correspondence artifacts due to an improved registration algorithm. The same 3D face model can be fit to 2D or 3D images acquired under different situations and with different sensors using an analysis by synthesis method. The resulting model parameters separate pose, lighting, imaging and identity parameters, which facilitates invariant face recognition across sensors and data sets by comparing only the identity parameters. We hope that the availability of this registered face model will spur research in generative models. Together with the model we publish a set of detailed recognition and reconstruction results on standard databases to allow complete algorithm comparisons.",
            "referenceCount": 24,
            "citationCount": 1186,
            "influentialCitationCount": 191,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2009-09-02",
            "journal": {
                "name": "2009 Sixth IEEE International Conference on Advanced Video and Signal Based Surveillance",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Paysan2009A3F,\n author = {P. Paysan and Reinhard Knothe and Brian Amberg and S. Romdhani and T. Vetter},\n booktitle = {2009 Sixth IEEE International Conference on Advanced Video and Signal Based Surveillance},\n journal = {2009 Sixth IEEE International Conference on Advanced Video and Signal Based Surveillance},\n pages = {296-301},\n title = {A 3D Face Model for Pose and Illumination Invariant Face Recognition},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:69a2479a49154e3bd51e44e636ab5692ed20b142",
            "@type": "ScholarlyArticle",
            "paperId": "69a2479a49154e3bd51e44e636ab5692ed20b142",
            "corpusId": 10648980,
            "url": "https://www.semanticscholar.org/paper/69a2479a49154e3bd51e44e636ab5692ed20b142",
            "title": "Probabilistic Latent Semantic Indexing",
            "venue": "SIGIR Forum",
            "publicationVenue": {
                "id": "urn:research:b2ff135b-16c2-40a9-a068-c27761bfda08",
                "name": "SIGIR Forum",
                "alternate_names": [
                    "Sigir Forum"
                ],
                "issn": "0163-5840",
                "url": "http://rave.ohiolink.edu/ejournals/issn/01635840/"
            },
            "year": 1999,
            "externalIds": {
                "MAG": "2107743791",
                "DBLP": "journals/sigir/Hofmann17",
                "DOI": "10.1145/3130348.3130370",
                "CorpusId": 10648980
            },
            "abstract": "Probabilistic Latent Semantic Indexing is a novel approach to automated document indexing which is based on a statistical latent class model for factor analysis of count data. Fitted from a training corpus of text documents by a generalization of the Expectation Maximization algorithm, the utilized model is able to deal with domain{specific synonymy as well as with polysemous words. In contrast to standard Latent Semantic Indexing (LSI) by Singular Value Decomposition, the probabilistic variant has a solid statistical foundation and defines a proper generative data model. Retrieval experiments on a number of test collections indicate substantial performance gains over direct term matching methods as well as over LSI. In particular, the combination of models with different dimensionalities has proven to be advantageous.",
            "referenceCount": 18,
            "citationCount": 2026,
            "influentialCitationCount": 176,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1999-08-01",
            "journal": {
                "name": "ACM SIGIR Forum",
                "volume": "51"
            },
            "citationStyles": {
                "bibtex": "@Article{Hofmann1999ProbabilisticLS,\n author = {Thomas Hofmann},\n booktitle = {SIGIR Forum},\n journal = {ACM SIGIR Forum},\n pages = {211 - 218},\n title = {Probabilistic Latent Semantic Indexing},\n volume = {51},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2deb56ed7eb9566b33cab3ea69796c7c71cb4387",
            "@type": "ScholarlyArticle",
            "paperId": "2deb56ed7eb9566b33cab3ea69796c7c71cb4387",
            "corpusId": 1326429,
            "url": "https://www.semanticscholar.org/paper/2deb56ed7eb9566b33cab3ea69796c7c71cb4387",
            "title": "PHONOLOGY AND LANGUAGE USE",
            "venue": "Studies in Second Language Acquisition",
            "publicationVenue": {
                "id": "urn:research:67facdb8-b4af-406e-80a2-e1c892256564",
                "name": "Studies in Second Language Acquisition",
                "alternate_names": [
                    "Stud Second Lang Acquis"
                ],
                "issn": "0272-2631",
                "url": "https://www.cambridge.org/core/journals/studies-in-second-language-acquisition"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2093322913",
                "DOI": "10.1017/S0272263104213067",
                "CorpusId": 1326429
            },
            "abstract": "PHONOLOGY AND LANGUAGE USE. Joan Bybee. New York: Cambridge University Press, 2001. Pp. xviii + 237. $80.00 cloth, $32.00 paper. Bybee is concerned with providing an understanding of a vast amount of evidence from language use that remains unaccounted for in the usual models of generative phonology, including its currently popular descendant, Optimality Theory.",
            "referenceCount": 1,
            "citationCount": 1481,
            "influentialCitationCount": 120,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology",
                "Sociology",
                "History"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Sociology",
                    "source": "external"
                },
                {
                    "category": "History",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2004-09-01",
            "journal": {
                "name": "Studies in Second Language Acquisition",
                "volume": "26"
            },
            "citationStyles": {
                "bibtex": "@Article{Wenden2004PHONOLOGYAL,\n author = {A. Wenden},\n booktitle = {Studies in Second Language Acquisition},\n journal = {Studies in Second Language Acquisition},\n pages = {499 - 499},\n title = {PHONOLOGY AND LANGUAGE USE},\n volume = {26},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:176f1d608b918eec8dc4b75e7b6e0acaba84a447",
            "@type": "ScholarlyArticle",
            "paperId": "176f1d608b918eec8dc4b75e7b6e0acaba84a447",
            "corpusId": 98180,
            "url": "https://www.semanticscholar.org/paper/176f1d608b918eec8dc4b75e7b6e0acaba84a447",
            "title": "Adversarial Learning for Neural Dialogue Generation",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1701.06547",
                "ACL": "D17-1230",
                "DBLP": "journals/corr/LiMSRJ17",
                "MAG": "2951520714",
                "DOI": "10.18653/v1/D17-1230",
                "CorpusId": 98180
            },
            "abstract": "We apply adversarial training to open-domain dialogue generation, training a system to produce sequences that are indistinguishable from human-generated dialogue utterances. We cast the task as a reinforcement learning problem where we jointly train two systems: a generative model to produce response sequences, and a discriminator\u2014analagous to the human evaluator in the Turing test\u2014 to distinguish between the human-generated dialogues and the machine-generated ones. In this generative adversarial network approach, the outputs from the discriminator are used to encourage the system towards more human-like dialogue. Further, we investigate models for adversarial evaluation that uses success in fooling an adversary as a dialogue evaluation metric, while avoiding a number of potential pitfalls. Experimental results on several metrics, including adversarial evaluation, demonstrate that the adversarially-trained system generates higher-quality responses than previous baselines",
            "referenceCount": 52,
            "citationCount": 862,
            "influentialCitationCount": 114,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/D17-1230.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-01-23",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1701.06547"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2017AdversarialLF,\n author = {Jiwei Li and Will Monroe and Tianlin Shi and S\u00e9bastien Jean and Alan Ritter and Dan Jurafsky},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Adversarial Learning for Neural Dialogue Generation},\n volume = {abs/1701.06547},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d475f695dedd94e96771fdaa1e5c075fd01d11cf",
            "@type": "ScholarlyArticle",
            "paperId": "d475f695dedd94e96771fdaa1e5c075fd01d11cf",
            "corpusId": 13570924,
            "url": "https://www.semanticscholar.org/paper/d475f695dedd94e96771fdaa1e5c075fd01d11cf",
            "title": "Variational Continual Learning",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1710.10628",
                "MAG": "2951799616",
                "DBLP": "conf/iclr/NguyenLBT18",
                "DOI": "10.17863/CAM.35471",
                "CorpusId": 13570924
            },
            "abstract": "This paper develops variational continual learning (VCL), a simple but general framework for continual learning that fuses online variational inference (VI) and recent advances in Monte Carlo VI for neural networks. The framework can successfully train both deep discriminative models and deep generative models in complex continual learning settings where existing tasks evolve over time and entirely new tasks emerge. Experimental results show that VCL outperforms state-of-the-art continual learning methods on a variety of tasks, avoiding catastrophic forgetting in a fully automatic way.",
            "referenceCount": 45,
            "citationCount": 592,
            "influentialCitationCount": 91,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-29",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1710.10628"
            },
            "citationStyles": {
                "bibtex": "@Article{Nguyen2017VariationalCL,\n author = {Cuong V Nguyen and Yingzhen Li and T. Bui and Richard E. Turner},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Variational Continual Learning},\n volume = {abs/1710.10628},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e7f3478fd8aac6940a4bf4f5eb60ac38f6b0b85b",
            "@type": "ScholarlyArticle",
            "paperId": "e7f3478fd8aac6940a4bf4f5eb60ac38f6b0b85b",
            "corpusId": 195767064,
            "url": "https://www.semanticscholar.org/paper/e7f3478fd8aac6940a4bf4f5eb60ac38f6b0b85b",
            "title": "Modeling Tabular data using Conditional GAN",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2970533824",
                "ArXiv": "1907.00503",
                "DBLP": "conf/nips/XuSCV19",
                "CorpusId": 195767064
            },
            "abstract": "Modeling the probability distribution of rows in tabular data and generating realistic synthetic data is a non-trivial task. Tabular data usually contains a mix of discrete and continuous columns. Continuous columns may have multiple modes whereas discrete columns are sometimes imbalanced making the modeling difficult. Existing statistical and deep neural network models fail to properly model this type of data. We design TGAN, which uses a conditional generative adversarial network to address these challenges. To aid in a fair and thorough comparison, we design a benchmark with 7 simulated and 8 real datasets and several Bayesian network baselines. TGAN outperforms Bayesian methods on most of the real datasets whereas other deep learning methods could not.",
            "referenceCount": 32,
            "citationCount": 586,
            "influentialCitationCount": 162,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-07-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Xu2019ModelingTD,\n author = {Lei Xu and Maria Skoularidou and Alfredo Cuesta-Infante and K. Veeramachaneni},\n booktitle = {Neural Information Processing Systems},\n pages = {7333-7343},\n title = {Modeling Tabular data using Conditional GAN},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2d0363a3ebda56d91d704d5ff5458a527775b609",
            "@type": "ScholarlyArticle",
            "paperId": "2d0363a3ebda56d91d704d5ff5458a527775b609",
            "corpusId": 7577075,
            "url": "https://www.semanticscholar.org/paper/2d0363a3ebda56d91d704d5ff5458a527775b609",
            "title": "Attribute2Image: Conditional Image Generation from Visual Attributes",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2952910462",
                "DBLP": "journals/corr/YanYSL15",
                "ArXiv": "1512.00570",
                "DOI": "10.1007/978-3-319-46493-0_47",
                "CorpusId": 7577075
            },
            "abstract": null,
            "referenceCount": 64,
            "citationCount": 728,
            "influentialCitationCount": 63,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/978-3-319-46493-0_47.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-12-02",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yan2015Attribute2ImageCI,\n author = {Xinchen Yan and Jimei Yang and Kihyuk Sohn and Honglak Lee},\n booktitle = {European Conference on Computer Vision},\n pages = {776-791},\n title = {Attribute2Image: Conditional Image Generation from Visual Attributes},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:81d5740cac256489978c2751e867128e97620eae",
            "@type": "ScholarlyArticle",
            "paperId": "81d5740cac256489978c2751e867128e97620eae",
            "corpusId": 9302801,
            "url": "https://www.semanticscholar.org/paper/81d5740cac256489978c2751e867128e97620eae",
            "title": "VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2617539464",
                "ArXiv": "1705.07761",
                "DBLP": "conf/nips/SrivastavaVRGS17",
                "CorpusId": 9302801
            },
            "abstract": "Deep generative models provide powerful tools for distributions over complicated manifolds, such as those of natural images. But many of these methods, including generative adversarial networks (GANs), can be difficult to train, in part because they are prone to mode collapse, which means that they characterize only a few modes of the true distribution. To address this, we introduce VEEGAN, which features a reconstructor network, reversing the action of the generator by mapping from data to noise. Our training objective retains the original asymptotic consistency guarantee of GANs, and can be interpreted as a novel autoencoder loss over the noise. In sharp contrast to a traditional autoencoder over data points, VEEGAN does not require specifying a loss function over the data, but rather only over the representations, which are standard normal by assumption. On an extensive set of synthetic and real world image datasets, VEEGAN indeed resists mode collapsing to a far greater extent than other recent GAN variants, and produces more realistic samples.",
            "referenceCount": 23,
            "citationCount": 570,
            "influentialCitationCount": 76,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-05-22",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Srivastava2017VEEGANRM,\n author = {Akash Srivastava and Lazar Valkov and Chris Russell and Michael U Gutmann and Charles Sutton},\n booktitle = {Neural Information Processing Systems},\n pages = {3308-3318},\n title = {VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9065d03256bcc962938f81eb795e70db214c459c",
            "@type": "ScholarlyArticle",
            "paperId": "9065d03256bcc962938f81eb795e70db214c459c",
            "corpusId": 678258,
            "url": "https://www.semanticscholar.org/paper/9065d03256bcc962938f81eb795e70db214c459c",
            "title": "Exploring Content Models for Multi-Document Summarization",
            "venue": "North American Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:01103732-3808-4930-b8e4-7e9e68d5c68d",
                "name": "North American Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "North Am Chapter Assoc Comput Linguistics",
                    "NAACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/naacl"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "1975579663",
                "DBLP": "conf/naacl/HaghighiV09",
                "ACL": "N09-1041",
                "DOI": "10.3115/1620754.1620807",
                "CorpusId": 678258
            },
            "abstract": "We present an exploration of generative probabilistic models for multi-document summarization. Beginning with a simple word frequency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way. Our final model, HierSum, utilizes a hierarchical LDA-style model (Blei et al., 2004) to represent content specificity as a hierarchy of topic vocabulary distributions. At the task of producing generic DUC-style summaries, HierSum yields state-of-the-art ROUGE performance and in pairwise user evaluation strongly outperforms Toutanova et al. (2007)'s state-of-the-art discriminative system. We also explore HierSum's capacity to produce multiple 'topical summaries' in order to facilitate content discovery and navigation.",
            "referenceCount": 24,
            "citationCount": 518,
            "influentialCitationCount": 41,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.5555/1620754.1620807",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2009-05-31",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Haghighi2009ExploringCM,\n author = {A. Haghighi and Lucy Vanderwende},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {362-370},\n title = {Exploring Content Models for Multi-Document Summarization},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:520ec00dc35475e0554dbb72f27bd2eeb6f4191d",
            "@type": "ScholarlyArticle",
            "paperId": "520ec00dc35475e0554dbb72f27bd2eeb6f4191d",
            "corpusId": 170076423,
            "url": "https://www.semanticscholar.org/paper/520ec00dc35475e0554dbb72f27bd2eeb6f4191d",
            "title": "The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks",
            "venue": "USENIX Security Symposium",
            "publicationVenue": {
                "id": "urn:research:54649c1d-6bcc-4232-9cd1-aa446867b8d0",
                "name": "USENIX Security Symposium",
                "alternate_names": [
                    "USENIX Secur Symp"
                ],
                "issn": null,
                "url": "http://www.usenix.org/events/bytopic/security.html"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2965267010",
                "ArXiv": "1802.08232",
                "DBLP": "conf/uss/Carlini0EKS19",
                "CorpusId": 170076423
            },
            "abstract": "This paper describes a testing methodology for quantitatively assessing the risk that rare or unique training-data sequences are unintentionally memorized by generative sequence models---a common type of machine-learning model. Because such models are sometimes trained on sensitive data (e.g., the text of users' private messages), this methodology can benefit privacy by allowing deep-learning practitioners to select means of training that minimize such memorization. \nIn experiments, we show that unintended memorization is a persistent, hard-to-avoid issue that can have serious consequences. Specifically, for models trained without consideration of memorization, we describe new, efficient procedures that can extract unique, secret sequences, such as credit card numbers. We show that our testing strategy is a practical and easy-to-use first line of defense, e.g., by describing its application to quantitatively limit data exposure in Google's Smart Compose, a commercial text-completion neural network trained on millions of users' email messages.",
            "referenceCount": 72,
            "citationCount": 732,
            "influentialCitationCount": 68,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-22",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Carlini2018TheSS,\n author = {Nicholas Carlini and Chang Liu and \u00da. Erlingsson and Jernej Kos and D. Song},\n booktitle = {USENIX Security Symposium},\n pages = {267-284},\n title = {The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:06b26678cda5f243338f43b18b7532228273a7f0",
            "@type": "ScholarlyArticle",
            "paperId": "06b26678cda5f243338f43b18b7532228273a7f0",
            "corpusId": 1327363,
            "url": "https://www.semanticscholar.org/paper/06b26678cda5f243338f43b18b7532228273a7f0",
            "title": "Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1611.02648",
                "MAG": "2556467266",
                "DBLP": "journals/corr/DilokthanakulMG16",
                "CorpusId": 1327363
            },
            "abstract": "We study a variant of the variational autoencoder model (VAE) with a Gaussian mixture as a prior distribution, with the goal of performing unsupervised clustering through deep generative models. We observe that the known problem of over-regularisation that has been shown to arise in regular VAEs also manifests itself in our model and leads to cluster degeneracy. We show that a heuristic called minimum information constraint that has been shown to mitigate this effect in VAEs can also be applied to improve unsupervised clustering performance with our model. Furthermore we analyse the effect of this heuristic and provide an intuition of the various processes with the help of visualizations. Finally, we demonstrate the performance of our model on synthetic data, MNIST and SVHN, showing that the obtained clusters are distinct, interpretable and result in achieving competitive performance on unsupervised clustering to the state-of-the-art results.",
            "referenceCount": 34,
            "citationCount": 544,
            "influentialCitationCount": 73,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1611.02648"
            },
            "citationStyles": {
                "bibtex": "@Article{Dilokthanakul2016DeepUC,\n author = {Nat Dilokthanakul and P. Mediano and M. Garnelo and M. J. Lee and Hugh Salimbeni and Kai Arulkumaran and M. Shanahan},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders},\n volume = {abs/1611.02648},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2aaea1114397155e952a870edf8586d376e69b2f",
            "@type": "ScholarlyArticle",
            "paperId": "2aaea1114397155e952a870edf8586d376e69b2f",
            "corpusId": 6740766,
            "url": "https://www.semanticscholar.org/paper/2aaea1114397155e952a870edf8586d376e69b2f",
            "title": "Reconfigurable models for scene recognition",
            "venue": "2012 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "conf/cvpr/PariziOF12",
                "MAG": "2087164515",
                "DOI": "10.1109/CVPR.2012.6248001",
                "CorpusId": 6740766
            },
            "abstract": "We propose a new latent variable model for scene recognition. Our approach represents a scene as a collection of region models (\u201cparts\u201d) arranged in a reconfigurable pattern. We partition an image into a predefined set of regions and use a latent variable to specify which region model is assigned to each image region. In our current implementation we use a bag of words representation to capture the appearance of an image region. The resulting method generalizes a spatial bag of words approach that relies on a fixed model for the bag of words in each image region. Our models can be trained using both generative and discriminative methods. In the generative setting we use the Expectation-Maximization (EM) algorithm to estimate model parameters from a collection of images with category labels. In the discriminative setting we use a latent structural SVM (LSSVM). We note that LSSVMs can be very sensitive to initialization and demonstrate that generative training with EM provides a good initialization for discriminative training with LSSVM.",
            "referenceCount": 17,
            "citationCount": 178,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cs.brown.edu/%7Epff/papers/latent-scene.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-06-16",
            "journal": {
                "name": "2012 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Parizi2012ReconfigurableMF,\n author = {S. N. Parizi and John G. Oberlin and Pedro F. Felzenszwalb},\n booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {2775-2782},\n title = {Reconfigurable models for scene recognition},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:add5f3f820b393e7ce5ed467814253824ecc484b",
            "@type": "ScholarlyArticle",
            "paperId": "add5f3f820b393e7ce5ed467814253824ecc484b",
            "corpusId": 235262511,
            "url": "https://www.semanticscholar.org/paper/add5f3f820b393e7ce5ed467814253824ecc484b",
            "title": "Argmax Flows and Multinomial Diffusion: Learning Categorical Distributions",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/nips/HoogeboomNJFW21",
                "ArXiv": "2102.05379",
                "CorpusId": 235262511
            },
            "abstract": "Generative flows and diffusion models have been predominantly trained on ordinal data, for example natural images. This paper introduces two extensions of flows and diffusion for categorical data such as language or image segmentation: Argmax Flows and Multinomial Diffusion. Argmax Flows are defined by a composition of a continuous distribution (such as a normalizing flow), and an argmax function. To optimize this model, we learn a probabilistic inverse for the argmax that lifts the categorical data to a continuous space. Multinomial Diffusion gradually adds categorical noise in a diffusion process, for which the generative denoising process is learned. We demonstrate that our method outperforms existing dequantization approaches on text modelling and modelling on image segmentation maps in log-likelihood.",
            "referenceCount": 39,
            "citationCount": 176,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-02-10",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hoogeboom2021ArgmaxFA,\n author = {E. Hoogeboom and Didrik Nielsen and P. Jaini and Patrick Forr'e and M. Welling},\n booktitle = {Neural Information Processing Systems},\n pages = {12454-12465},\n title = {Argmax Flows and Multinomial Diffusion: Learning Categorical Distributions},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bebfd1e9f14616aeaeae0ab6cc9ff6f8127a7127",
            "@type": "ScholarlyArticle",
            "paperId": "bebfd1e9f14616aeaeae0ab6cc9ff6f8127a7127",
            "corpusId": 5644766,
            "url": "https://www.semanticscholar.org/paper/bebfd1e9f14616aeaeae0ab6cc9ff6f8127a7127",
            "title": "Transfer learning for collaborative filtering via a rating-matrix generative model",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2118338035",
                "DBLP": "conf/icml/LiYX09",
                "DOI": "10.1145/1553374.1553454",
                "CorpusId": 5644766
            },
            "abstract": "Cross-domain collaborative filtering solves the sparsity problem by transferring rating knowledge across multiple domains. In this paper, we propose a rating-matrix generative model (RMGM) for effective cross-domain collaborative filtering. We first show that the relatedness across multiple rating matrices can be established by finding a shared implicit cluster-level rating matrix, which is next extended to a cluster-level rating model. Consequently, a rating matrix of any related task can be viewed as drawing a set of users and items from a user-item joint mixture model as well as drawing the corresponding ratings from the cluster-level rating model. The combination of these two models gives the RMGM, which can be used to fill the missing ratings for both existing and new users. A major advantage of RMGM is that it can share the knowledge by pooling the rating data from multiple tasks even when the users and items of these tasks do not overlap. We evaluate the RMGM empirically on three real-world collaborative filtering data sets to show that RMGM can outperform the individual models trained separately.",
            "referenceCount": 16,
            "citationCount": 360,
            "influentialCitationCount": 42,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-06-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Li2009TransferLF,\n author = {Bin Li and Qiang Yang and X. Xue},\n booktitle = {International Conference on Machine Learning},\n pages = {617-624},\n title = {Transfer learning for collaborative filtering via a rating-matrix generative model},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c2872fb23b02597034a179f4adb82a00d6ffda8d",
            "@type": "ScholarlyArticle",
            "paperId": "c2872fb23b02597034a179f4adb82a00d6ffda8d",
            "corpusId": 14925035,
            "url": "https://www.semanticscholar.org/paper/c2872fb23b02597034a179f4adb82a00d6ffda8d",
            "title": "Probabilistic latent semantic indexing",
            "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
            "publicationVenue": {
                "id": "urn:research:8dce23a9-44e0-4381-a39e-2acc1edff700",
                "name": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
                "alternate_names": [
                    "International ACM SIGIR Conference on Research and Development in Information Retrieval",
                    "Int ACM SIGIR Conf Res Dev Inf Retr",
                    "SIGIR",
                    "Annu Int ACM SIGIR Conf Res Dev Inf Retr"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigir/"
            },
            "year": 1999,
            "externalIds": {
                "DBLP": "conf/sigir/Hofmann99",
                "DOI": "10.1145/312624.312649",
                "CorpusId": 14925035
            },
            "abstract": "Probabilistic Latent Semantic Indexing is a novel approach to automated document indexing which is based on a statistical latent class model for factor analysis of count data. Fitted from a training corpus of text documents by a generalization of the Expectation Maximization algorithm, the utilized model is able to deal with domain{speci c synonymy as well as with polysemous words. In contrast to standard Latent Semantic Indexing (LSI) by Singular Value Decomposition, the probabilistic variant has a solid statistical foundation and de nes a proper generative data model. Retrieval experiments on a number of test collections indicate substantial performance gains over direct term matching methods as well as over LSI. In particular, the combination of models with di erent dimensionalities has proven to be advantageous.",
            "referenceCount": 13,
            "citationCount": 1378,
            "influentialCitationCount": 155,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/312624.312649",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hofmann1999ProbabilisticLS,\n author = {Thomas Hofmann},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n pages = {50-57},\n title = {Probabilistic latent semantic indexing},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e9cc8502ef2ca8e4ca6c7be45e67416f8d25a947",
            "@type": "ScholarlyArticle",
            "paperId": "e9cc8502ef2ca8e4ca6c7be45e67416f8d25a947",
            "corpusId": 10715191,
            "url": "https://www.semanticscholar.org/paper/e9cc8502ef2ca8e4ca6c7be45e67416f8d25a947",
            "title": "Social cognitive theory of personality.",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1999,
            "externalIds": {
                "MAG": "66576854",
                "CorpusId": 10715191
            },
            "abstract": "and Creative Modeling Modeling is not simply a process of response mimicry as commonly believed. Modeled judgments and actions may differ in specific content but embody the same rule. For example, a model may deal with moral dilemmas that differ widely in the nature of the activity but apply the same moral standard to them. Modeled activities thus convey rules for generative and innovative behavior. This higher level learning is achieved through abstract modeling. Once observers extract the rules underlying the modeled activities they can generate new behaviors that go beyond what they have seen or heard. Creativeness rarely springs entirely from individual inventiveness. A lot of modeling goes on in creativity. By refining preexisting innovations, synthesizing them into new ways and adding novel elements to them something new is created. When exposed to models of differing styles of thinking and behaving, observers vary in what they adopt from the different sources and thereby create new blends of personal characteristics that differ from the individual models (Bandura, Ross & Ross, 1963). Modeling influences that exemplify new perspectives and innovative styles of thinking also foster creativity by weakening conventional mind sets (Belcher, 1975; Harris & Evans, 1973).",
            "referenceCount": 179,
            "citationCount": 1329,
            "influentialCitationCount": 149,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Bandura1999SocialCT,\n author = {A. Bandura},\n title = {Social cognitive theory of personality.},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fd26c7254eb81124148e84e3cf02dbd88bbc5623",
            "@type": "ScholarlyArticle",
            "paperId": "fd26c7254eb81124148e84e3cf02dbd88bbc5623",
            "corpusId": 8226656,
            "url": "https://www.semanticscholar.org/paper/fd26c7254eb81124148e84e3cf02dbd88bbc5623",
            "title": "Formal models for expert finding in enterprise corpora",
            "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
            "publicationVenue": {
                "id": "urn:research:8dce23a9-44e0-4381-a39e-2acc1edff700",
                "name": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
                "alternate_names": [
                    "International ACM SIGIR Conference on Research and Development in Information Retrieval",
                    "Int ACM SIGIR Conf Res Dev Inf Retr",
                    "SIGIR",
                    "Annu Int ACM SIGIR Conf Res Dev Inf Retr"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigir/"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "conf/sigir/BalogAR06",
                "MAG": "2126226055",
                "DOI": "10.1145/1148170.1148181",
                "CorpusId": 8226656
            },
            "abstract": "Searching an organization's document repositories for experts provides a cost effective solution for the task of expert finding. We present two general strategies to expert searching given a document collection which are formalized using generative probabilistic models. The first of these directly models an expert's knowledge based on the documents that they are associated with, whilst the second locates documents on topic, and then finds the associated expert. Forming reliable associations is crucial to the performance of expert finding systems. Consequently, in our evaluation we compare the different approaches, exploring a variety of associations along with other operational parameters (such as topicality). Using the TREC Enterprise corpora, we show that the second strategy consistently outperforms the first. A comparison against other unsupervised techniques, reveals that our second model delivers excellent performance.",
            "referenceCount": 20,
            "citationCount": 701,
            "influentialCitationCount": 63,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://strathprints.strath.ac.uk/57972/1/Balog_etal_SIGIR_2006_Formal_models_for_expert_finding_in_enterprise_corpora.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-08-06",
            "journal": {
                "name": "Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Balog2006FormalMF,\n author = {K. Balog and L. Azzopardi and M. de Rijke},\n booktitle = {Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},\n journal = {Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval},\n title = {Formal models for expert finding in enterprise corpora},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:80d9a586c49ac6ec6a0b304ec1bb10d3f09fb526",
            "@type": "ScholarlyArticle",
            "paperId": "80d9a586c49ac6ec6a0b304ec1bb10d3f09fb526",
            "corpusId": 6635779,
            "url": "https://www.semanticscholar.org/paper/80d9a586c49ac6ec6a0b304ec1bb10d3f09fb526",
            "title": "Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/LiW16",
                "ArXiv": "1601.04589",
                "MAG": "2952139859",
                "DOI": "10.1109/CVPR.2016.272",
                "CorpusId": 6635779
            },
            "abstract": "This paper studies a combination of generative Markov random field (MRF) models and discriminatively trained deep convolutional neural networks (dCNNs) for synthesizing 2D images. The generative MRF acts on higher-levels of a dCNN feature pyramid, controlling the image layout at an abstract level. We apply the method to both photographic and non-photo-realistic (artwork) synthesis tasks. The MRF regularizer prevents over-excitation artifacts and reduces implausible feature mixtures common to previous dCNN inversion approaches, permitting synthesizing photographic content with increased visual plausibility. Unlike standard MRF-based texture synthesis, the combined system can both match and adapt local features with considerable variability, yielding results far out of reach of classic generative MRF methods.",
            "referenceCount": 33,
            "citationCount": 686,
            "influentialCitationCount": 97,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1601.04589",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Art",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-01-18",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Li2016CombiningMR,\n author = {Chuan Li and Michael Wand},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {2479-2486},\n title = {Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9eb50914621312edf12fc96ee6d2fbe501388f67",
            "@type": "ScholarlyArticle",
            "paperId": "9eb50914621312edf12fc96ee6d2fbe501388f67",
            "corpusId": 2063572,
            "url": "https://www.semanticscholar.org/paper/9eb50914621312edf12fc96ee6d2fbe501388f67",
            "title": "Learning a Generative Model of Images by Factoring Appearance and Shape",
            "venue": "Neural Computation",
            "publicationVenue": {
                "id": "urn:research:69b9bcdd-8229-4a00-a6e0-00f0e99a2bf3",
                "name": "Neural Computation",
                "alternate_names": [
                    "Neural Comput"
                ],
                "issn": "0899-7667",
                "url": "http://cognet.mit.edu/library/journals/journal?issn=08997667"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2171145682",
                "DBLP": "journals/neco/RouxHSW11",
                "DOI": "10.1162/NECO_a_00086",
                "CorpusId": 2063572,
                "PubMed": "21162663"
            },
            "abstract": "Computer vision has grown tremendously in the past two decades. Despite all efforts, existing attempts at matching parts of the human visual system's extraordinary ability to understand visual scenes lack either scope or power. By combining the advantages of general low-level generative models and powerful layer-based and hierarchical models, this work aims at being a first step toward richer, more flexible models of images. After comparing various types of restricted Boltzmann machines (RBMs) able to model continuous-valued data, we introduce our basic model, the masked RBM, which explicitly models occlusion boundaries in image patches by factoring the appearance of any patch region from its shape. We then propose a generative model of larger images using a field of such RBMs. Finally, we discuss how masked RBMs could be stacked to form a deep model able to generate more complicated structures and suitable for various tasks such as segmentation or object recognition.",
            "referenceCount": 45,
            "citationCount": 97,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2011-03-01",
            "journal": {
                "name": "Neural Computation",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Roux2011LearningAG,\n author = {Nicolas Le Roux and N. Heess and J. Shotton and J. Winn},\n booktitle = {Neural Computation},\n journal = {Neural Computation},\n pages = {593-650},\n title = {Learning a Generative Model of Images by Factoring Appearance and Shape},\n volume = {23},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bb17ff968ae1dbd772ac337f469d1ca915cb4c03",
            "@type": "ScholarlyArticle",
            "paperId": "bb17ff968ae1dbd772ac337f469d1ca915cb4c03",
            "corpusId": 3614357,
            "url": "https://www.semanticscholar.org/paper/bb17ff968ae1dbd772ac337f469d1ca915cb4c03",
            "title": "MINE: Mutual Information Neural Estimation",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2915380248",
                "DBLP": "journals/corr/abs-1801-04062",
                "CorpusId": 3614357
            },
            "abstract": "This paper presents a Mutual Information Neural Estimator (MINE) that is linearly scalable in dimensionality as well as in sample size. MINE is back-propable and we prove that it is strongly consistent. We illustrate a handful of applications in which MINE is succesfully applied to enhance the property of generative models in both unsupervised and supervised settings. We apply our framework to estimate the information bottleneck, and apply it in tasks related to supervised classification problems. Our results demonstrate substantial added flexibility and improvement in these settings.",
            "referenceCount": 65,
            "citationCount": 515,
            "influentialCitationCount": 112,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1801.04062"
            },
            "citationStyles": {
                "bibtex": "@Article{Belghazi2018MINEMI,\n author = {Ishmael Belghazi and Sai Rajeswar and A. Baratin and R. Devon Hjelm and Aaron C. Courville},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {MINE: Mutual Information Neural Estimation},\n volume = {abs/1801.04062},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8d65ee7aa0a9dac3957093985e9179e1ccb9bd3b",
            "@type": "ScholarlyArticle",
            "paperId": "8d65ee7aa0a9dac3957093985e9179e1ccb9bd3b",
            "corpusId": 11664683,
            "url": "https://www.semanticscholar.org/paper/8d65ee7aa0a9dac3957093985e9179e1ccb9bd3b",
            "title": "Early results for Named Entity Recognition with Conditional Random Fields, Feature Induction and Web-Enhanced Lexicons",
            "venue": "Conference on Computational Natural Language Learning",
            "publicationVenue": {
                "id": "urn:research:3779a5a7-9119-4f69-84fe-f7eef193eb49",
                "name": "Conference on Computational Natural Language Learning",
                "alternate_names": [
                    "CoNLL",
                    "Conf Comput Nat Lang Learn"
                ],
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "DBLP": "conf/conll/McCallum003",
                "MAG": "2141099517",
                "ACL": "W03-0430",
                "DOI": "10.3115/1119176.1119206",
                "CorpusId": 11664683
            },
            "abstract": "Models for many natural language tasks benefit from the flexibility to use overlapping, non-independent features. For example, the need for labeled data can be drastically reduced by taking advantage of domain knowledge in the form of word lists, part-of-speech tags, character n-grams, and capitalization patterns. While it is difficult to capture such inter-dependent features with a generative probabilistic model, conditionally-trained models, such as conditional maximum entropy models, handle them well. There has been significant work with such models for greedy sequence modeling in NLP (Ratnaparkhi, 1996; Borthwick et al., 1998).",
            "referenceCount": 11,
            "citationCount": 1323,
            "influentialCitationCount": 91,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/1119176.1119206",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2003-05-31",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{McCallum2003EarlyRF,\n author = {A. McCallum and Wei Li},\n booktitle = {Conference on Computational Natural Language Learning},\n pages = {188-191},\n title = {Early results for Named Entity Recognition with Conditional Random Fields, Feature Induction and Web-Enhanced Lexicons},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:73e8633886dc380a46fc02f2e1ec5bf68dba0734",
            "@type": "ScholarlyArticle",
            "paperId": "73e8633886dc380a46fc02f2e1ec5bf68dba0734",
            "corpusId": 10796,
            "url": "https://www.semanticscholar.org/paper/73e8633886dc380a46fc02f2e1ec5bf68dba0734",
            "title": "Neural Variational Inference for Text Processing",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2015,
            "externalIds": {
                "ArXiv": "1511.06038",
                "MAG": "2173681125",
                "DBLP": "journals/corr/MiaoYB15",
                "CorpusId": 10796
            },
            "abstract": "Recent advances in neural variational inference have spawned a renaissance in deep latent variable models. In this paper we introduce a generic variational inference framework for generative and conditional models of text. While traditional variational methods derive an analytic approximation for the intractable distributions over latent variables, here we construct an inference network conditioned on the discrete text input to provide the variational distribution. We validate this framework on two very different text modelling applications, generative document modelling and supervised question answering. Our neural variational document model combines a continuous stochastic document representation with a bag-of-words generative model and achieves the lowest reported perplexities on two standard test corpora. The neural answer selection model employs a stochastic representation layer within an attention mechanism to extract the semantics between a question and answer pair. On two question answering benchmarks this model exceeds all previous published benchmarks.",
            "referenceCount": 51,
            "citationCount": 548,
            "influentialCitationCount": 103,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-11-19",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1511.06038"
            },
            "citationStyles": {
                "bibtex": "@Article{Miao2015NeuralVI,\n author = {Yishu Miao and Lei Yu and Phil Blunsom},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Neural Variational Inference for Text Processing},\n volume = {abs/1511.06038},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7fc604e1a3e45cd2d2742f96d62741930a363efa",
            "@type": "ScholarlyArticle",
            "paperId": "7fc604e1a3e45cd2d2742f96d62741930a363efa",
            "corpusId": 8531544,
            "url": "https://www.semanticscholar.org/paper/7fc604e1a3e45cd2d2742f96d62741930a363efa",
            "title": "A Tutorial on Energy-Based Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2161914416",
                "CorpusId": 8531544
            },
            "abstract": "Energy-Based Models (EBMs) capture dependencies between variables by associating a scalar energy to each configuration of the variab les. Inference consists in clamping the value of observed variables and finding config urations of the remaining variables that minimize the energy. Learning consists in finding an energy function in which observed configurations of the variables a re given lower energies than unobserved ones. The EBM approach provides a common theoretical framework for many learning models, including traditional discr iminative and generative approaches, as well as graph-transformer networks, co nditional random fields, maximum margin Markov networks, and several manifold learning methods. Probabilistic models must be properly normalized, which sometimes requires evaluating intractable integrals over the space of all poss ible variable configurations. Since EBMs have no requirement for proper normalization, this problem is naturally circumvented. EBMs can be viewed as a form of non-probabilistic factor graphs, and they provide considerably more flexibility in th e design of architectures and training criteria than probabilistic approaches .",
            "referenceCount": 71,
            "citationCount": 1153,
            "influentialCitationCount": 114,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{LeCun2006ATO,\n author = {Yann LeCun and S. Chopra and R. Hadsell and Aurelio Ranzato and Fu Jie Huang},\n title = {A Tutorial on Energy-Based Learning},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7f91c91c817ee1488f70264ecc22cee0f6908260",
            "@type": "ScholarlyArticle",
            "paperId": "7f91c91c817ee1488f70264ecc22cee0f6908260",
            "corpusId": 220280381,
            "url": "https://www.semanticscholar.org/paper/7f91c91c817ee1488f70264ecc22cee0f6908260",
            "title": "Swapping Autoencoder for Deep Image Manipulation",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2007-00653",
                "ArXiv": "2007.00653",
                "MAG": "3101956722",
                "CorpusId": 220280381
            },
            "abstract": "Deep generative models have become increasingly effective at producing realistic images from randomly sampled seeds, but using such models for controllable manipulation of existing images remains challenging. We propose the Swapping Autoencoder, a deep model designed specifically for image manipulation, rather than random sampling. The key idea is to encode an image with two independent components and enforce that any swapped combination maps to a realistic image. In particular, we encourage the components to represent structure and texture, by enforcing one component to encode co-occurrent patch statistics across different parts of an image. As our method is trained with an encoder, finding the latent codes for a new input image becomes trivial, rather than cumbersome. As a result, it can be used to manipulate real input images in various ways, including texture swapping, local and global editing, and latent code vector arithmetic. Experiments on multiple datasets show that our model produces better results and is substantially more efficient compared to recent generative models.",
            "referenceCount": 101,
            "citationCount": 258,
            "influentialCitationCount": 38,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-07-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2007.00653"
            },
            "citationStyles": {
                "bibtex": "@Article{Park2020SwappingAF,\n author = {Taesung Park and Jun-Yan Zhu and Oliver Wang and Jingwan Lu and Eli Shechtman and Alexei A. Efros and Richard Zhang},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Swapping Autoencoder for Deep Image Manipulation},\n volume = {abs/2007.00653},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4edd98e3947d8406ec95518c294721757afffb5d",
            "@type": "ScholarlyArticle",
            "paperId": "4edd98e3947d8406ec95518c294721757afffb5d",
            "corpusId": 38125055,
            "url": "https://www.semanticscholar.org/paper/4edd98e3947d8406ec95518c294721757afffb5d",
            "title": "Deep reinforcement learning for de novo drug design",
            "venue": "Science Advances",
            "publicationVenue": {
                "id": "urn:research:cb30f0c9-2980-4b7d-bbcb-68fc5472b97c",
                "name": "Science Advances",
                "alternate_names": [
                    "Sci Adv"
                ],
                "issn": "2375-2548",
                "url": "http://www.scienceadvances.org/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "3100751385",
                "DBLP": "journals/corr/abs-1711-10907",
                "PubMedCentral": "6059760",
                "ArXiv": "1711.10907",
                "DOI": "10.1126/sciadv.aap7885",
                "CorpusId": 38125055,
                "PubMed": "30050984"
            },
            "abstract": "We introduce an artificial intelligence approach to de novo design of molecules with desired physical or biological properties. We have devised and implemented a novel computational strategy for de novo design of molecules with desired properties termed ReLeaSE (Reinforcement Learning for Structural Evolution). On the basis of deep and reinforcement learning (RL) approaches, ReLeaSE integrates two deep neural networks\u2014generative and predictive\u2014that are trained separately but are used jointly to generate novel targeted chemical libraries. ReLeaSE uses simple representation of molecules by their simplified molecular-input line-entry system (SMILES) strings only. Generative models are trained with a stack-augmented memory network to produce chemically feasible SMILES strings, and predictive models are derived to forecast the desired properties of the de novo\u2013generated compounds. In the first phase of the method, generative and predictive models are trained separately with a supervised learning algorithm. In the second phase, both models are trained jointly with the RL approach to bias the generation of new chemical structures toward those with the desired physical and/or biological properties. In the proof-of-concept study, we have used the ReLeaSE method to design chemical libraries with a bias toward structural complexity or toward compounds with maximal, minimal, or specific range of physical properties, such as melting point or hydrophobicity, or toward compounds with inhibitory activity against Janus protein kinase 2. The approach proposed herein can find a general use for generating targeted chemical libraries of novel compounds optimized for either a single desired property or multiple properties.",
            "referenceCount": 83,
            "citationCount": 781,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://advances.sciencemag.org/content/advances/4/7/eaap7885.full.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-29",
            "journal": {
                "name": "Science Advances",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Popova2017DeepRL,\n author = {Mariya Popova and O. Isayev and A. Tropsha},\n booktitle = {Science Advances},\n journal = {Science Advances},\n title = {Deep reinforcement learning for de novo drug design},\n volume = {4},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7c1a89a59c0c61f3459a53c8d8f72caa9466fcc3",
            "@type": "ScholarlyArticle",
            "paperId": "7c1a89a59c0c61f3459a53c8d8f72caa9466fcc3",
            "corpusId": 15565327,
            "url": "https://www.semanticscholar.org/paper/7c1a89a59c0c61f3459a53c8d8f72caa9466fcc3",
            "title": "Kronecker Graphs: An Approach to Modeling Networks",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2112681514",
                "DBLP": "journals/jmlr/LeskovecCKFG10",
                "ArXiv": "0812.4905",
                "DOI": "10.5555/1756006.1756039",
                "CorpusId": 15565327
            },
            "abstract": "How can we generate realistic networks? In addition, how can we do so with a mathematically tractable model that allows for rigorous analysis of network properties? Real networks exhibit a long list of surprising properties: Heavy tails for the in- and out-degree distribution, heavy tails for the eigenvalues and eigenvectors, small diameters, and densification and shrinking diameters over time. Current network models and generators either fail to match several of the above properties, are complicated to analyze mathematically, or both. Here we propose a generative model for networks that is both mathematically tractable and can generate networks that have all the above mentioned structural properties. Our main idea here is to use a non-standard matrix operation, the Kronecker product, to generate graphs which we refer to as \"Kronecker graphs\". \n \nFirst, we show that Kronecker graphs naturally obey common network properties. In fact, we rigorously prove that they do so. We also provide empirical evidence showing that Kronecker graphs can effectively model the structure of real networks. \n \nWe then present KRONFIT, a fast and scalable algorithm for fitting the Kronecker graph generation model to large real networks. A naive approach to fitting would take super-exponential time. In contrast, KRONFIT takes linear time, by exploiting the structure of Kronecker matrix multiplication and by using statistical simulation techniques. \n \nExperiments on a wide range of large real and synthetic networks show that KRONFIT finds accurate parameters that very well mimic the properties of target networks. In fact, using just four parameters we can accurately model several aspects of global network structure. Once fitted, the model parameters can be used to gain insights about the network structure, and the resulting synthetic graphs can be used for null-models, anonymization, extrapolations, and graph summarization.",
            "referenceCount": 96,
            "citationCount": 1024,
            "influentialCitationCount": 135,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-12-29",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/0812.4905"
            },
            "citationStyles": {
                "bibtex": "@Article{Leskovec2008KroneckerGA,\n author = {J. Leskovec and Deepayan Chakrabarti and J. Kleinberg and C. Faloutsos and Zoubin Ghahramani},\n booktitle = {Journal of machine learning research},\n journal = {ArXiv},\n title = {Kronecker Graphs: An Approach to Modeling Networks},\n volume = {abs/0812.4905},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5feca7d699227265f607baee1f74b5449994a6b7",
            "@type": "ScholarlyArticle",
            "paperId": "5feca7d699227265f607baee1f74b5449994a6b7",
            "corpusId": 1174898,
            "url": "https://www.semanticscholar.org/paper/5feca7d699227265f607baee1f74b5449994a6b7",
            "title": "Topic modeling: beyond bag-of-words",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "conf/icml/Wallach06",
                "MAG": "2104210067",
                "DOI": "10.1145/1143844.1143967",
                "CorpusId": 1174898
            },
            "abstract": "Some models of textual corpora employ text generation methods involving n-gram statistics, while others use latent topic variables inferred using the \"bag-of-words\" assumption, in which word order is ignored. Previously, these methods have not been combined. In this work, I explore a hierarchical generative probabilistic model that incorporates both n-gram statistics and latent topic variables by extending a unigram topic model to include properties of a hierarchical Dirichlet bigram language model. The model hyperparameters are inferred using a Gibbs EM algorithm. On two data sets, each of 150 documents, the new model exhibits better predictive accuracy than either a hierarchical Dirichlet bigram language model or a unigram topic model. Additionally, the inferred topics are less dominated by function words than are topics discovered using unigram statistics, potentially making them more meaningful.",
            "referenceCount": 10,
            "citationCount": 1187,
            "influentialCitationCount": 53,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-06-25",
            "journal": {
                "name": "Proceedings of the 23rd international conference on Machine learning",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Wallach2006TopicMB,\n author = {Hanna M. Wallach},\n booktitle = {International Conference on Machine Learning},\n journal = {Proceedings of the 23rd international conference on Machine learning},\n title = {Topic modeling: beyond bag-of-words},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2c37b3e50f8375c431302a8c5e0a50f55bd7dace",
            "@type": "ScholarlyArticle",
            "paperId": "2c37b3e50f8375c431302a8c5e0a50f55bd7dace",
            "corpusId": 53295271,
            "url": "https://www.semanticscholar.org/paper/2c37b3e50f8375c431302a8c5e0a50f55bd7dace",
            "title": "Invertible Residual Networks",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1811-00995",
                "MAG": "2963540976",
                "ArXiv": "1811.00995",
                "CorpusId": 53295271
            },
            "abstract": "We show that standard ResNet architectures can be made invertible, allowing the same model to be used for classification, density estimation, and generation. Typically, enforcing invertibility requires partitioning dimensions or restricting network architectures. In contrast, our approach only requires adding a simple normalization step during training, already available in standard frameworks. Invertible ResNets define a generative model which can be trained by maximum likelihood on unlabeled data. To compute likelihoods, we introduce a tractable approximation to the Jacobian log-determinant of a residual block. Our empirical evaluation shows that invertible ResNets perform competitively with both state-of-the-art image classifiers and flow-based generative models, something that has not been previously achieved with a single architecture.",
            "referenceCount": 55,
            "citationCount": 496,
            "influentialCitationCount": 80,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-11-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Behrmann2018InvertibleRN,\n author = {Jens Behrmann and D. Duvenaud and J. Jacobsen},\n booktitle = {International Conference on Machine Learning},\n pages = {573-582},\n title = {Invertible Residual Networks},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cde35c87aaabbc617d38f9cfaa2721a2e166d750",
            "@type": "ScholarlyArticle",
            "paperId": "cde35c87aaabbc617d38f9cfaa2721a2e166d750",
            "corpusId": 195820291,
            "url": "https://www.semanticscholar.org/paper/cde35c87aaabbc617d38f9cfaa2721a2e166d750",
            "title": "Large Scale Adversarial Representation Learning",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1907-02544",
                "ArXiv": "1907.02544",
                "MAG": "2970241862",
                "CorpusId": 195820291
            },
            "abstract": "Adversarially trained generative models (GANs) have recently achieved compelling image synthesis results. But despite early successes in using GANs for unsupervised representation learning, they have since been superseded by approaches based on self-supervision. In this work we show that progress in image generation quality translates to substantially improved representation learning performance. Our approach, BigBiGAN, builds upon the state-of-the-art BigGAN model, extending it to representation learning by adding an encoder and modifying the discriminator. We extensively evaluate the representation learning and generation capabilities of these BigBiGAN models, demonstrating that these generation-based models achieve the state of the art in unsupervised representation learning on ImageNet, as well as in unconditional image generation. Pretrained BigBiGAN models -- including image generators and encoders -- are available on TensorFlow Hub (https://tfhub.dev/s?publisher=deepmind&q=bigbigan).",
            "referenceCount": 42,
            "citationCount": 470,
            "influentialCitationCount": 40,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-07-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Donahue2019LargeSA,\n author = {Jeff Donahue and K. Simonyan},\n booktitle = {Neural Information Processing Systems},\n pages = {10541-10551},\n title = {Large Scale Adversarial Representation Learning},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fcabf1c0f4a26431d4df95ddeec2b1dff9b3e928",
            "@type": "ScholarlyArticle",
            "paperId": "fcabf1c0f4a26431d4df95ddeec2b1dff9b3e928",
            "corpusId": 16991836,
            "url": "https://www.semanticscholar.org/paper/fcabf1c0f4a26431d4df95ddeec2b1dff9b3e928",
            "title": "Semantic Segmentation using Adversarial Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1611.08408",
                "DBLP": "journals/corr/LucCCV16",
                "MAG": "2950040358",
                "CorpusId": 16991836
            },
            "abstract": "Adversarial training has been shown to produce state of the art results for generative image modeling. In this paper we propose an adversarial training approach to train semantic segmentation models. We train a convolutional semantic segmentation network along with an adversarial network that discriminates segmentation maps coming either from the ground truth or from the segmentation network. The motivation for our approach is that it can detect and correct higher-order inconsistencies between ground truth segmentation maps and the ones produced by the segmentation net. Our experiments show that our adversarial training approach leads to improved accuracy on the Stanford Background and PASCAL VOC 2012 datasets.",
            "referenceCount": 36,
            "citationCount": 662,
            "influentialCitationCount": 48,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-11-25",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1611.08408"
            },
            "citationStyles": {
                "bibtex": "@Article{Luc2016SemanticSU,\n author = {Pauline Luc and C. Couprie and Soumith Chintala and Jakob Verbeek},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Semantic Segmentation using Adversarial Networks},\n volume = {abs/1611.08408},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd",
            "@type": "ScholarlyArticle",
            "paperId": "f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd",
            "corpusId": 2665144,
            "url": "https://www.semanticscholar.org/paper/f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd",
            "title": "Variational Autoencoder for Deep Learning of Images, Labels and Captions",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/PuGHYLSC16",
                "MAG": "2527569769",
                "ArXiv": "1609.08976",
                "CorpusId": 2665144
            },
            "abstract": "A novel variational autoencoder is developed to model images, as well as associated labels or captions. The Deep Generative Deconvolutional Network (DGDN) is used as a decoder of the latent image features, and a deep Convolutional Neural Network (CNN) is used as an image encoder; the CNN is used to approximate a distribution for the latent DGDN features/code. The latent code is also linked to generative models for labels (Bayesian support vector machine) or captions (recurrent neural network). When predicting a label/caption for a new image at test, averaging is performed across the distribution of latent codes; this is computationally efficient as a consequence of the learned CNN-based encoder. Since the framework is capable of modeling the image in the presence/absence of associated labels/captions, a new semi-supervised setting is manifested for CNN learning with images; the framework even allows unsupervised CNN learning, based on images alone.",
            "referenceCount": 37,
            "citationCount": 636,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-09-28",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Pu2016VariationalAF,\n author = {Yunchen Pu and Zhe Gan and Ricardo Henao and Xin Yuan and Chunyuan Li and Andrew Stevens and L. Carin},\n booktitle = {Neural Information Processing Systems},\n pages = {2352-2360},\n title = {Variational Autoencoder for Deep Learning of Images, Labels and Captions},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:605402e235bd62437baf3c9ebefe77fb4d92ee95",
            "@type": "ScholarlyArticle",
            "paperId": "605402e235bd62437baf3c9ebefe77fb4d92ee95",
            "corpusId": 1890561,
            "url": "https://www.semanticscholar.org/paper/605402e235bd62437baf3c9ebefe77fb4d92ee95",
            "title": "The Helmholtz Machine",
            "venue": "Neural Computation",
            "publicationVenue": {
                "id": "urn:research:69b9bcdd-8229-4a00-a6e0-00f0e99a2bf3",
                "name": "Neural Computation",
                "alternate_names": [
                    "Neural Comput"
                ],
                "issn": "0899-7667",
                "url": "http://cognet.mit.edu/library/journals/journal?issn=08997667"
            },
            "year": 1995,
            "externalIds": {
                "MAG": "2026799324",
                "DBLP": "journals/neco/DayanHNZ95",
                "DOI": "10.1162/neco.1995.7.5.889",
                "CorpusId": 1890561,
                "PubMed": "7584891"
            },
            "abstract": "Discovering the structure inherent in a set of patterns is a fundamental aim of statistical inference or learning. One fruitful approach is to build a parameterized stochastic generative model, independent draws from which are likely to produce the patterns. For all but the simplest generative models, each pattern can be generated in exponentially many ways. It is thus intractable to adjust the parameters to maximize the probability of the observed patterns. We describe a way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations. Our method can be viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways.",
            "referenceCount": 38,
            "citationCount": 1269,
            "influentialCitationCount": 68,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1995-09-01",
            "journal": {
                "name": "Neural Computation",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Dayan1995TheHM,\n author = {P. Dayan and Geoffrey E. Hinton and Radford M. Neal and R. Zemel},\n booktitle = {Neural Computation},\n journal = {Neural Computation},\n pages = {889-904},\n title = {The Helmholtz Machine},\n volume = {7},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1eeb265595e250cf66751ef9032524386d7a9b32",
            "@type": "ScholarlyArticle",
            "paperId": "1eeb265595e250cf66751ef9032524386d7a9b32",
            "corpusId": 182952446,
            "url": "https://www.semanticscholar.org/paper/1eeb265595e250cf66751ef9032524386d7a9b32",
            "title": "Neural Spline Flows",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2948659923",
                "DBLP": "conf/nips/DurkanB0P19",
                "ArXiv": "1906.04032",
                "CorpusId": 182952446
            },
            "abstract": "A normalizing flow models a complex probability density as an invertible transformation of a simple base density. Flows based on either coupling or autoregressive transforms both offer exact density evaluation and sampling, but rely on the parameterization of an easily invertible elementwise transformation, whose choice determines the flexibility of these models. Building upon recent work, we propose a fully-differentiable module based on monotonic rational-quadratic splines, which enhances the flexibility of both coupling and autoregressive transforms while retaining analytic invertibility. We demonstrate that neural spline flows improve density estimation, variational inference, and generative modeling of images.",
            "referenceCount": 65,
            "citationCount": 520,
            "influentialCitationCount": 89,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-10",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1906.04032"
            },
            "citationStyles": {
                "bibtex": "@Article{Durkan2019NeuralSF,\n author = {Conor Durkan and Artur Bekasov and Iain Murray and G. Papamakarios},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Neural Spline Flows},\n volume = {abs/1906.04032},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3502b5ef1afb16f76bcae33db17179195bbcdaae",
            "@type": "ScholarlyArticle",
            "paperId": "3502b5ef1afb16f76bcae33db17179195bbcdaae",
            "corpusId": 3513418,
            "url": "https://www.semanticscholar.org/paper/3502b5ef1afb16f76bcae33db17179195bbcdaae",
            "title": "Generating Natural Adversarial Examples",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1710.11342",
                "MAG": "2962713901",
                "DBLP": "conf/iclr/ZhaoDS18",
                "CorpusId": 3513418
            },
            "abstract": "Due to their complex nature, it is hard to characterize the ways in which machine learning models can misbehave or be exploited when deployed. Recent work on adversarial examples, i.e. inputs with minor perturbations that result in substantially different model predictions, is helpful in evaluating the robustness of these models by exposing the adversarial scenarios where they fail. However, these malicious perturbations are often unnatural, not semantically meaningful, and not applicable to complicated domains such as language. In this paper, we propose a framework to generate natural and legible adversarial examples that lie on the data manifold, by searching in semantic space of dense and continuous data representation, utilizing the recent advances in generative adversarial networks. We present generated adversaries to demonstrate the potential of the proposed approach for black-box classifiers for a wide range of applications such as image classification, textual entailment, and machine translation. We include experiments to show that the generated adversaries are natural, legible to humans, and useful in evaluating and analyzing black-box classifiers.",
            "referenceCount": 35,
            "citationCount": 528,
            "influentialCitationCount": 52,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-10-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1710.11342"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhao2017GeneratingNA,\n author = {Zhengli Zhao and Dheeru Dua and Sameer Singh},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Generating Natural Adversarial Examples},\n volume = {abs/1710.11342},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a56759300364982894bad81ab08ca3642cf6b06d",
            "@type": "ScholarlyArticle",
            "paperId": "a56759300364982894bad81ab08ca3642cf6b06d",
            "corpusId": 231942400,
            "url": "https://www.semanticscholar.org/paper/a56759300364982894bad81ab08ca3642cf6b06d",
            "title": "Contrastive Learning Inverts the Data Generating Process",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/icml/ZimmermannSSBB21",
                "ArXiv": "2102.08850",
                "CorpusId": 231942400
            },
            "abstract": "Contrastive learning has recently seen tremendous success in self-supervised learning. So far, however, it is largely unclear why the learned representations generalize so effectively to a large variety of downstream tasks. We here prove that feedforward models trained with objectives belonging to the commonly used InfoNCE family learn to implicitly invert the underlying generative model of the observed data. While the proofs make certain statistical assumptions about the generative model, we observe empirically that our findings hold even if these assumptions are severely violated. Our theory highlights a fundamental connection between contrastive learning, generative modeling, and nonlinear independent component analysis, thereby furthering our understanding of the learned representations as well as providing a theoretical foundation to derive more effective contrastive losses.",
            "referenceCount": 64,
            "citationCount": 129,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-02-17",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zimmermann2021ContrastiveLI,\n author = {Roland S. Zimmermann and Yash Sharma and Steffen Schneider and M. Bethge and Wieland Brendel},\n booktitle = {International Conference on Machine Learning},\n pages = {12979-12990},\n title = {Contrastive Learning Inverts the Data Generating Process},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cad4ac0d2389a89cf1955dd4788278c1e8ac1af9",
            "@type": "ScholarlyArticle",
            "paperId": "cad4ac0d2389a89cf1955dd4788278c1e8ac1af9",
            "corpusId": 1515901,
            "url": "https://www.semanticscholar.org/paper/cad4ac0d2389a89cf1955dd4788278c1e8ac1af9",
            "title": "Learning What and Where to Draw",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/nips/ReedAMTSL16",
                "ArXiv": "1610.02454",
                "MAG": "2952434594",
                "CorpusId": 1515901
            },
            "abstract": "Generative Adversarial Networks (GANs) have recently demonstrated the capability to synthesize compelling real-world images, such as room interiors, album covers, manga, faces, birds, and flowers. While existing models can synthesize images based on global constraints such as a class label or caption, they do not provide control over pose or object location. We propose a new model, the Generative Adversarial What-Where Network (GAWWN), that synthesizes images given instructions describing what content to draw in which location. We show high-quality 128 x 128 image synthesis on the Caltech-UCSD Birds dataset, conditioned on both informal text descriptions and also object location. Our system exposes control over both the bounding box around the bird and its constituent parts. By modeling the conditional distributions over part locations, our system also enables conditioning on arbitrary subsets of parts (e.g. only the beak and tail), yielding an efficient interface for picking part locations.",
            "referenceCount": 27,
            "citationCount": 558,
            "influentialCitationCount": 50,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-10-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1610.02454"
            },
            "citationStyles": {
                "bibtex": "@Article{Reed2016LearningWA,\n author = {Scott E. Reed and Zeynep Akata and S. Mohan and Samuel Tenka and B. Schiele and Honglak Lee},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Learning What and Where to Draw},\n volume = {abs/1610.02454},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b68c34c55925a75804f97491b745de66b1ffc4be",
            "@type": "ScholarlyArticle",
            "paperId": "b68c34c55925a75804f97491b745de66b1ffc4be",
            "corpusId": 15310495,
            "url": "https://www.semanticscholar.org/paper/b68c34c55925a75804f97491b745de66b1ffc4be",
            "title": "Learning Deep Energy Models",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2185528074",
                "DBLP": "conf/icml/NgiamCKN11",
                "CorpusId": 15310495
            },
            "abstract": "Deep generative models with multiple hidden layers have been shown to be able to learn meaningful and compact representations of data. In this work we propose deep energy models, which use deep feedforward neural networks to model the energy landscapes that define probabilistic models. We are able to efficiently train all layers of our model simultaneously, allowing the lower layers of the model to adapt to the training of the higher layers, and thereby producing better generative models. We evaluate the generative performance of our models on natural images and demonstrate that this joint training of multiple layers yields qualitative and quantitative improvements over greedy layerwise training. We further generalize our models beyond the commonly used sigmoidal neural networks and show how a deep extension of the product of Student-t distributions model achieves good generative performance. Finally, we introduce a discriminative extension of our model and demonstrate that it outperforms other fully-connected models on object recognition on the NORB dataset.",
            "referenceCount": 31,
            "citationCount": 185,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2011-06-28",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ngiam2011LearningDE,\n author = {Jiquan Ngiam and Zhenghao Chen and Pang Wei Koh and A. Ng},\n booktitle = {International Conference on Machine Learning},\n pages = {1105-1112},\n title = {Learning Deep Energy Models},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b437b5a0445f17b06b12791bc48aeb8110e95dc5",
            "@type": "ScholarlyArticle",
            "paperId": "b437b5a0445f17b06b12791bc48aeb8110e95dc5",
            "corpusId": 15960930,
            "url": "https://www.semanticscholar.org/paper/b437b5a0445f17b06b12791bc48aeb8110e95dc5",
            "title": "Learning to generate chairs with convolutional neural networks",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1893585201",
                "DBLP": "journals/corr/DosovitskiySB14",
                "ArXiv": "1411.5928",
                "DOI": "10.1109/CVPR.2015.7298761",
                "CorpusId": 15960930
            },
            "abstract": "We train a generative convolutional neural network which is able to generate images of objects given object type, viewpoint, and color. We train the network in a supervised manner on a dataset of rendered 3D chair models. Our experiments show that the network does not merely learn all images by heart, but rather finds a meaningful representation of a 3D chair model allowing it to assess the similarity of different chairs, interpolate between given viewpoints to generate the missing ones, or invent new chair styles by interpolating between chairs from the training set. We show that the network can be used to find correspondences between different chairs from the dataset, outperforming existing approaches on this task.",
            "referenceCount": 36,
            "citationCount": 670,
            "influentialCitationCount": 38,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://lmb.informatik.uni-freiburg.de/Publications/2014/DB14a/Generate_Chairs_arxiv.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-11-21",
            "journal": {
                "name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Dosovitskiy2014LearningTG,\n author = {A. Dosovitskiy and J. T. Springenberg and T. Brox},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1538-1546},\n title = {Learning to generate chairs with convolutional neural networks},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:97c01b6cef7d7d88ec7eda488bfdc46fd601e76a",
            "@type": "ScholarlyArticle",
            "paperId": "97c01b6cef7d7d88ec7eda488bfdc46fd601e76a",
            "corpusId": 3697399,
            "url": "https://www.semanticscholar.org/paper/97c01b6cef7d7d88ec7eda488bfdc46fd601e76a",
            "title": "Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/icml/EngelRRDNES17",
                "ArXiv": "1704.01279",
                "MAG": "2606176153",
                "CorpusId": 3697399
            },
            "abstract": "Generative models in vision have seen rapid progress due to algorithmic improvements and the availability of high-quality image datasets. In this paper, we offer contributions in both these areas to enable similar progress in audio modeling. First, we detail a powerful new WaveNet-style autoencoder model that conditions an autoregressive decoder on temporal codes learned from the raw audio waveform. Second, we introduce NSynth, a large-scale and high-quality dataset of musical notes that is an order of magnitude larger than comparable public datasets. Using NSynth, we demonstrate improved qualitative and quantitative performance of the WaveNet autoencoder over a well-tuned spectral autoencoder baseline. Finally, we show that the model learns a manifold of embeddings that allows for morphing between instruments, meaningfully interpolating in timbre to create new types of sounds that are realistic and expressive.",
            "referenceCount": 37,
            "citationCount": 503,
            "influentialCitationCount": 64,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-04-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1704.01279"
            },
            "citationStyles": {
                "bibtex": "@Article{Engel2017NeuralAS,\n author = {Jesse Engel and Cinjon Resnick and Adam Roberts and S. Dieleman and Mohammad Norouzi and D. Eck and K. Simonyan},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders},\n volume = {abs/1704.01279},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e3d5ee10d0489c768e943546038e3f53e7697349",
            "@type": "ScholarlyArticle",
            "paperId": "e3d5ee10d0489c768e943546038e3f53e7697349",
            "corpusId": 215416317,
            "url": "https://www.semanticscholar.org/paper/e3d5ee10d0489c768e943546038e3f53e7697349",
            "title": "State of the Art on Neural Rendering",
            "venue": "Computer graphics forum (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2004-03805",
                "ArXiv": "2004.03805",
                "MAG": "3016007010",
                "DOI": "10.1111/cgf.14022",
                "CorpusId": 215416317
            },
            "abstract": "Efficient rendering of photo\u2010realistic virtual worlds is a long standing effort of computer graphics. Modern graphics techniques have succeeded in synthesizing photo\u2010realistic images from hand\u2010crafted scene representations. However, the automatic generation of shape, materials, lighting, and other aspects of scenes remains a challenging problem that, if solved, would make photo\u2010realistic computer graphics more widely accessible. Concurrently, progress in computer vision and machine learning have given rise to a new approach to image synthesis and editing, namely deep generative models. Neural rendering is a new and rapidly emerging field that combines generative machine learning techniques with physical knowledge from computer graphics, e.g., by the integration of differentiable rendering into network training. With a plethora of applications in computer graphics and vision, neural rendering is poised to become a new area in the graphics community, yet no survey of this emerging field exists. This state\u2010of\u2010the\u2010art report summarizes the recent trends and applications of neural rendering. We focus on approaches that combine classic computer graphics techniques with deep generative models to obtain controllable and photorealistic outputs. Starting with an overview of the underlying computer graphics and machine learning concepts, we discuss critical aspects of neural rendering approaches. Specifically, our emphasis is on the type of control, i.e., how the control is provided, which parts of the pipeline are learned, explicit vs. implicit control, generalization, and stochastic vs. deterministic synthesis. The second half of this state\u2010of\u2010the\u2010art report is focused on the many important use cases for the described algorithms such as novel view synthesis, semantic photo manipulation, facial and body reenactment, relighting, free\u2010viewpoint video, and the creation of photo\u2010realistic avatars for virtual and augmented reality telepresence. Finally, we conclude with a discussion of the social implications of such technology and investigate open research problems.",
            "referenceCount": 233,
            "citationCount": 355,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://rss.onlinelibrary.wiley.com/doi/am-pdf/10.1111/cgf.14022",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-04-08",
            "journal": {
                "name": "Computer Graphics Forum",
                "volume": "39"
            },
            "citationStyles": {
                "bibtex": "@Article{Tewari2020StateOT,\n author = {A. Tewari and Ohad Fried and Justus Thies and V. Sitzmann and Stephen Lombardi and Kalyan Sunkavalli and Ricardo Martin-Brualla and T. Simon and Jason M. Saragih and M. Nie\u00dfner and Rohit Pandey and S. Fanello and Gordon Wetzstein and Jun-Yan Zhu and C. Theobalt and Maneesh Agrawala and Eli Shechtman and Dan B. Goldman and Michael Zollhofer},\n booktitle = {Computer graphics forum (Print)},\n journal = {Computer Graphics Forum},\n title = {State of the Art on Neural Rendering},\n volume = {39},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:da4e3270085fe5f59d9e89c072345c6600e7eb9a",
            "@type": "ScholarlyArticle",
            "paperId": "da4e3270085fe5f59d9e89c072345c6600e7eb9a",
            "corpusId": 38384342,
            "url": "https://www.semanticscholar.org/paper/da4e3270085fe5f59d9e89c072345c6600e7eb9a",
            "title": "A Note on the Inception Score",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1801-01973",
                "MAG": "2782980316",
                "ArXiv": "1801.01973",
                "CorpusId": 38384342
            },
            "abstract": "Deep generative models are powerful tools that have produced impressive results in recent years. These advances have been for the most part empirically driven, making it essential that we use high quality evaluation metrics. In this paper, we provide new insights into the Inception Score, a recently proposed and widely used evaluation metric for generative models, and demonstrate that it fails to provide useful guidance when comparing models. We discuss both suboptimalities of the metric itself and issues with its application. Finally, we call for researchers to be more systematic and careful when evaluating and comparing generative models, as the advancement of the field depends upon it.",
            "referenceCount": 28,
            "citationCount": 523,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-01-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1801.01973"
            },
            "citationStyles": {
                "bibtex": "@Article{Barratt2018ANO,\n author = {Shane T. Barratt and Rishi Sharma},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {A Note on the Inception Score},\n volume = {abs/1801.01973},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e75e1b1f446e91323f77af8529bd57b44dfe55c7",
            "@type": "ScholarlyArticle",
            "paperId": "e75e1b1f446e91323f77af8529bd57b44dfe55c7",
            "corpusId": 30730027,
            "url": "https://www.semanticscholar.org/paper/e75e1b1f446e91323f77af8529bd57b44dfe55c7",
            "title": "Communication dynamics in complex brain networks",
            "venue": "Nature Reviews Neuroscience",
            "publicationVenue": {
                "id": "urn:research:74b0478a-292c-4fe3-bb2f-71f438f00cc7",
                "name": "Nature Reviews Neuroscience",
                "alternate_names": [
                    "Nat Rev Neurosci"
                ],
                "issn": "1471-003X",
                "url": "http://www.nature.com/nrn/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2774446342",
                "DOI": "10.1038/nrn.2017.149",
                "CorpusId": 30730027,
                "PubMed": "29238085"
            },
            "abstract": null,
            "referenceCount": 203,
            "citationCount": 532,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-12-14",
            "journal": {
                "name": "Nature Reviews Neuroscience",
                "volume": "19"
            },
            "citationStyles": {
                "bibtex": "@Article{Avena-Koenigsberger2017CommunicationDI,\n author = {Andrea Avena-Koenigsberger and B. Mi\u0161i\u0107 and O. Sporns},\n booktitle = {Nature Reviews Neuroscience},\n journal = {Nature Reviews Neuroscience},\n pages = {17-33},\n title = {Communication dynamics in complex brain networks},\n volume = {19},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:509e166d5e66df10675a0e15063daad518dcc5ad",
            "@type": "ScholarlyArticle",
            "paperId": "509e166d5e66df10675a0e15063daad518dcc5ad",
            "corpusId": 239050236,
            "url": "https://www.semanticscholar.org/paper/509e166d5e66df10675a0e15063daad518dcc5ad",
            "title": "Likelihood Training of Schr\u00f6dinger Bridge using Forward-Backward SDEs Theory",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/iclr/ChenLT22",
                "ArXiv": "2110.11291",
                "CorpusId": 239050236
            },
            "abstract": "Schr\\\"odinger Bridge (SB) is an entropy-regularized optimal transport problem that has received increasing attention in deep generative modeling for its mathematical flexibility compared to the Scored-based Generative Model (SGM). However, it remains unclear whether the optimization principle of SB relates to the modern training of deep generative models, which often rely on constructing log-likelihood objectives.This raises questions on the suitability of SB models as a principled alternative for generative applications. In this work, we present a novel computational framework for likelihood training of SB models grounded on Forward-Backward Stochastic Differential Equations Theory - a mathematical methodology appeared in stochastic optimal control that transforms the optimality condition of SB into a set of SDEs. Crucially, these SDEs can be used to construct the likelihood objectives for SB that, surprisingly, generalizes the ones for SGM as special cases. This leads to a new optimization principle that inherits the same SB optimality yet without losing applications of modern generative training techniques, and we show that the resulting training algorithm achieves comparable results on generating realistic images on MNIST, CelebA, and CIFAR10. Our code is available at https://github.com/ghliu/SB-FBSDE.",
            "referenceCount": 73,
            "citationCount": 71,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-10-21",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2110.11291"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2021LikelihoodTO,\n author = {T. Chen and Guan-Horng Liu and Evangelos A. Theodorou},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Likelihood Training of Schr\u00f6dinger Bridge using Forward-Backward SDEs Theory},\n volume = {abs/2110.11291},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8ccb88958358ea59bdc9b76f660b01c8f631b2c0",
            "@type": "ScholarlyArticle",
            "paperId": "8ccb88958358ea59bdc9b76f660b01c8f631b2c0",
            "corpusId": 91184364,
            "url": "https://www.semanticscholar.org/paper/8ccb88958358ea59bdc9b76f660b01c8f631b2c0",
            "title": "HoloGAN: Unsupervised Learning of 3D Representations From Natural Images",
            "venue": "2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2933283236",
                "DBLP": "conf/iccvw/Nguyen-PhuocLTR19",
                "DOI": "10.1109/ICCVW.2019.00255",
                "CorpusId": 91184364
            },
            "abstract": "We propose a novel generative adversarial network (GAN) for the task of unsupervised learning of 3D representations from natural images. Most generative models rely on 2D kernels to generate images and make few assumptions about the 3D world. These models therefore tend to create blurry images or artefacts in tasks that require a strong 3D understanding, such as novel-view synthesis. HoloGAN instead learns a 3D representation of the world, and to render this representation in a realistic manner. Unlike other GANs, HoloGAN provides explicit control over the pose of generated objects through rigid-body transformations of the learnt 3D features. Our experiments show that using explicit 3D features enables HoloGAN to disentangle 3D pose and identity, which is further decomposed into shape and appearance, while still being able to generate images with similar or higher visual quality than other generative models. HoloGAN can be trained end-to-end from unlabelled 2D images only. Particularly, we do not require pose labels, 3D shapes, or multiple views of the same objects. This shows that HoloGAN is the first generative model that learns 3D representations from natural images in an entirely unsupervised manner.",
            "referenceCount": 66,
            "citationCount": 427,
            "influentialCitationCount": 58,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://purehost.bath.ac.uk/ws/files/216883001/holoGAN_iccv19.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-02",
            "journal": {
                "name": "2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Nguyen-Phuoc2019HoloGANUL,\n author = {Thu Nguyen-Phuoc and Chuan Li and Lucas Theis and Christian Richardt and Yong-Liang Yang},\n booktitle = {2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)},\n journal = {2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)},\n pages = {2037-2040},\n title = {HoloGAN: Unsupervised Learning of 3D Representations From Natural Images},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0fa6e474dbf7f645413bf81b4887ada78ace47ed",
            "@type": "ScholarlyArticle",
            "paperId": "0fa6e474dbf7f645413bf81b4887ada78ace47ed",
            "corpusId": 6075871,
            "url": "https://www.semanticscholar.org/paper/0fa6e474dbf7f645413bf81b4887ada78ace47ed",
            "title": "Weighted Constraints in Generative Linguistics",
            "venue": "Cognitive Sciences",
            "publicationVenue": {
                "id": "urn:research:c33b01b0-31b4-470e-a9f9-8432e02c3cb9",
                "name": "Cognitive Sciences",
                "alternate_names": [
                    "Cognitive Science",
                    "Cogn Sci"
                ],
                "issn": "1935-8059",
                "url": "http://www.informaworld.com/openurl?genre=journal&issn=1551-6709"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2142772987",
                "DBLP": "journals/cogsci/Pater09",
                "DOI": "10.1111/j.1551-6709.2009.01047.x",
                "CorpusId": 6075871,
                "PubMed": "21585494"
            },
            "abstract": "Harmonic Grammar (HG) and Optimality Theory (OT) are closely related formal frameworks for the study of language. In both, the structure of a given language is determined by the relative strengths of a set of constraints. They differ in how these strengths are represented: as numerical weights (HG) or as ranks (OT). Weighted constraints have advantages for the construction of accounts of language learning and other cognitive processes, partly because they allow for the adaptation of connectionist and statistical models. HG has been little studied in generative linguistics, however, largely due to influential claims that weighted constraints make incorrect predictions about the typology of natural languages, predictions that are not shared by the more popular OT. This paper makes the case that HG is in fact a promising framework for typological research, and reviews and extends the existing arguments for weighted over ranked constraints.",
            "referenceCount": 125,
            "citationCount": 280,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1551-6709.2009.01047.x",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2009-08-01",
            "journal": {
                "name": "Cognitive science",
                "volume": "33 6"
            },
            "citationStyles": {
                "bibtex": "@Article{Pater2009WeightedCI,\n author = {Joe Pater},\n booktitle = {Cognitive Sciences},\n journal = {Cognitive science},\n pages = {\n          999-1035\n        },\n title = {Weighted Constraints in Generative Linguistics},\n volume = {33 6},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b3acb6f183b5f4b651f53c0eec5cb5c805224ac1",
            "@type": "ScholarlyArticle",
            "paperId": "b3acb6f183b5f4b651f53c0eec5cb5c805224ac1",
            "corpusId": 3305321,
            "url": "https://www.semanticscholar.org/paper/b3acb6f183b5f4b651f53c0eec5cb5c805224ac1",
            "title": "Efficient GAN-Based Anomaly Detection",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1802.06222",
                "DBLP": "journals/corr/abs-1802-06222",
                "MAG": "2787947370",
                "CorpusId": 3305321
            },
            "abstract": "Generative adversarial networks (GANs) are able to model the complex highdimensional distributions of real-world data, which suggests they could be effective for anomaly detection. However, few works have explored the use of GANs for the anomaly detection task. We leverage recently developed GAN models for anomaly detection, and achieve state-of-the-art performance on image and network intrusion datasets, while being several hundred-fold faster at test time than the only published GAN-based method.",
            "referenceCount": 21,
            "citationCount": 485,
            "influentialCitationCount": 71,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-12",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1802.06222"
            },
            "citationStyles": {
                "bibtex": "@Article{Zenati2018EfficientGA,\n author = {Houssam Zenati and Chuan-Sheng Foo and Bruno Lecouat and Gaurav Manek and V. Chandrasekhar},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Efficient GAN-Based Anomaly Detection},\n volume = {abs/1802.06222},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7345843e87c81e24e42264859b214d26042f8d51",
            "@type": "ScholarlyArticle",
            "paperId": "7345843e87c81e24e42264859b214d26042f8d51",
            "corpusId": 1949831,
            "url": "https://www.semanticscholar.org/paper/7345843e87c81e24e42264859b214d26042f8d51",
            "title": "Recurrent Neural Network Grammars",
            "venue": "North American Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:01103732-3808-4930-b8e4-7e9e68d5c68d",
                "name": "North American Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "North Am Chapter Assoc Comput Linguistics",
                    "NAACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/naacl"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2963073938",
                "DBLP": "journals/corr/DyerKBS16",
                "ACL": "N16-1024",
                "ArXiv": "1602.07776",
                "DOI": "10.18653/v1/N16-1024",
                "CorpusId": 1949831
            },
            "abstract": "We introduce recurrent neural network grammars, probabilistic models of sentences with explicit phrase structure. We explain efficient inference procedures that allow application to both parsing and language modeling. Experiments show that they provide better parsing in English than any single previously published supervised generative model and better language modeling than state-of-the-art sequential RNNs in English and Chinese.",
            "referenceCount": 55,
            "citationCount": 495,
            "influentialCitationCount": 106,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/N16-1024.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-02-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Dyer2016RecurrentNN,\n author = {Chris Dyer and A. Kuncoro and Miguel Ballesteros and Noah A. Smith},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n pages = {199-209},\n title = {Recurrent Neural Network Grammars},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:97cd86d8d8c0f27cd3e64c6ca5cfdeb957ee39f4",
            "@type": "ScholarlyArticle",
            "paperId": "97cd86d8d8c0f27cd3e64c6ca5cfdeb957ee39f4",
            "corpusId": 208857409,
            "url": "https://www.semanticscholar.org/paper/97cd86d8d8c0f27cd3e64c6ca5cfdeb957ee39f4",
            "title": "Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1912.03263",
                "DBLP": "conf/iclr/GrathwohlWJD0S20",
                "MAG": "2994434574",
                "CorpusId": 208857409
            },
            "abstract": "We propose to reinterpret a standard discriminative classifier of p(y|x) as an energy based model for the joint distribution p(x,y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x|y). Within this framework, standard discriminative architectures may beused and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, andout-of-distribution detection while also enabling our models to generate samplesrivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and presentan approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-artin both generative and discriminative learning within one hybrid model.",
            "referenceCount": 52,
            "citationCount": 408,
            "influentialCitationCount": 85,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-12-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1912.03263"
            },
            "citationStyles": {
                "bibtex": "@Article{Grathwohl2019YourCI,\n author = {Will Grathwohl and Kuan-Chieh Jackson Wang and J. Jacobsen and D. Duvenaud and Mohammad Norouzi and Kevin Swersky},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One},\n volume = {abs/1912.03263},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d5f47453a6d00ede2881dfb65fc7ea141a50deeb",
            "@type": "ScholarlyArticle",
            "paperId": "d5f47453a6d00ede2881dfb65fc7ea141a50deeb",
            "corpusId": 195886143,
            "url": "https://www.semanticscholar.org/paper/d5f47453a6d00ede2881dfb65fc7ea141a50deeb",
            "title": "Topic Modeling in Embedding Spaces",
            "venue": "Transactions of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:e0dbf116-86aa-418d-859f-a49952d7e44a",
                "name": "Transactions of the Association for Computational Linguistics",
                "alternate_names": [
                    "Trans Assoc Comput Linguistics",
                    "TACL"
                ],
                "issn": "2307-387X",
                "url": "https://www.mitpressjournals.org/loi/tacl"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/tacl/DiengRB20",
                "ArXiv": "1907.04907",
                "MAG": "3045464143",
                "DOI": "10.1162/tacl_a_00325",
                "CorpusId": 195886143
            },
            "abstract": "Abstract Topic modeling analyzes documents to learn meaningful patterns of words. However, existing topic models fail to learn interpretable topics when working with large and heavy-tailed vocabularies. To this end, we develop the embedded topic model (etm), a generative model of documents that marries traditional topic models with word embeddings. More specifically, the etm models each word with a categorical distribution whose natural parameter is the inner product between the word\u2019s embedding and an embedding of its assigned topic. To fit the etm, we develop an efficient amortized variational inference algorithm. The etm discovers interpretable topics even with large vocabularies that include rare words and stop words. It outperforms existing document models, such as latent Dirichlet allocation, in terms of both topic quality and predictive performance.",
            "referenceCount": 58,
            "citationCount": 370,
            "influentialCitationCount": 76,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00325/1923074/tacl_a_00325.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-07-08",
            "journal": {
                "name": "Transactions of the Association for Computational Linguistics",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Dieng2019TopicMI,\n author = {Adji B. Dieng and Francisco J. R. Ruiz and D. Blei},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {439-453},\n title = {Topic Modeling in Embedding Spaces},\n volume = {8},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3dd5fcec294ee8e5693dd100b6c9f4a94c1a0ba3",
            "@type": "ScholarlyArticle",
            "paperId": "3dd5fcec294ee8e5693dd100b6c9f4a94c1a0ba3",
            "corpusId": 212747811,
            "url": "https://www.semanticscholar.org/paper/3dd5fcec294ee8e5693dd100b6c9f4a94c1a0ba3",
            "title": "DLow: Diversifying Latent Flows for Diverse Human Motion Prediction",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3012402011",
                "DBLP": "journals/corr/abs-2003-08386",
                "ArXiv": "2003.08386",
                "DOI": "10.1007/978-3-030-58545-7_20",
                "CorpusId": 212747811
            },
            "abstract": null,
            "referenceCount": 80,
            "citationCount": 153,
            "influentialCitationCount": 44,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2003.08386",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-03-18",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yuan2020DLowDL,\n author = {Ye Yuan and Kris M. Kitani},\n booktitle = {European Conference on Computer Vision},\n pages = {346-364},\n title = {DLow: Diversifying Latent Flows for Diverse Human Motion Prediction},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f54a53ca1e1aab8bbf640695936b62b79115cbd7",
            "@type": "ScholarlyArticle",
            "paperId": "f54a53ca1e1aab8bbf640695936b62b79115cbd7",
            "corpusId": 244575754,
            "url": "https://www.semanticscholar.org/paper/f54a53ca1e1aab8bbf640695936b62b79115cbd7",
            "title": "Multi-constraint molecular generation based on conditional transformer, knowledge distillation and reinforcement learning",
            "venue": "Nature Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:6457124b-39bf-4d02-bff4-73752ff21562",
                "name": "Nature Machine Intelligence",
                "alternate_names": [
                    "Nat Mach Intell"
                ],
                "issn": "2522-5839",
                "url": "https://www.nature.com/natmachintell/"
            },
            "year": 2021,
            "externalIds": {
                "MAG": "3207373390",
                "DBLP": "journals/natmi/WangHWWWJLZYHCC21",
                "DOI": "10.1038/s42256-021-00403-1",
                "CorpusId": 244575754
            },
            "abstract": null,
            "referenceCount": 58,
            "citationCount": 67,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-10-01",
            "journal": {
                "name": "Nature Machine Intelligence",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2021MulticonstraintMG,\n author = {Jike Wang and Chang-Yu Hsieh and Mingyang Wang and Xiaorui Wang and Zhenxing Wu and Dejun Jiang and B. Liao and Xujun Zhang and Bo Yang and Qiaojun He and Dongsheng Cao and Xi Chen and Tingjun Hou},\n booktitle = {Nature Machine Intelligence},\n journal = {Nature Machine Intelligence},\n pages = {914 - 922},\n title = {Multi-constraint molecular generation based on conditional transformer, knowledge distillation and reinforcement learning},\n volume = {3},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4159b7d284db0fceb176c2cc2d833efef7f31793",
            "@type": "ScholarlyArticle",
            "paperId": "4159b7d284db0fceb176c2cc2d833efef7f31793",
            "corpusId": 2256302,
            "url": "https://www.semanticscholar.org/paper/4159b7d284db0fceb176c2cc2d833efef7f31793",
            "title": "A Latent Variable Model for Geographic Lexical Variation",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "conf/emnlp/EisensteinOSX10",
                "ACL": "D10-1124",
                "MAG": "2142889507",
                "CorpusId": 2256302
            },
            "abstract": "The rapid growth of geotagged social media raises new computational possibilities for investigating geographic linguistic variation. In this paper, we present a multi-level generative model that reasons jointly about latent topics and geographical regions. High-level topics such as \"sports\" or \"entertainment\" are rendered differently in each geographic region, revealing topic-specific regional distinctions. Applied to a new dataset of geotagged microblogs, our model recovers coherent topics and their regional variants, while identifying geographic areas of linguistic consistency. The model also enables prediction of an author's geographic location from raw text, outperforming both text regression and supervised topic models.",
            "referenceCount": 36,
            "citationCount": 713,
            "influentialCitationCount": 76,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Geography",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2010-10-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Eisenstein2010ALV,\n author = {Jacob Eisenstein and Brendan T. O'Connor and Noah A. Smith and E. Xing},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {1277-1287},\n title = {A Latent Variable Model for Geographic Lexical Variation},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:50ba65f0dc271c4af6a8423dc6a9c4d91eaf37da",
            "@type": "ScholarlyArticle",
            "paperId": "50ba65f0dc271c4af6a8423dc6a9c4d91eaf37da",
            "corpusId": 935718,
            "url": "https://www.semanticscholar.org/paper/50ba65f0dc271c4af6a8423dc6a9c4d91eaf37da",
            "title": "A data-driven reflectance model",
            "venue": "ACM Transactions on Graphics",
            "publicationVenue": {
                "id": "urn:research:aab03e41-f80d-48b3-89bd-60eeeceafc7d",
                "name": "ACM Transactions on Graphics",
                "alternate_names": [
                    "ACM Trans Graph"
                ],
                "issn": "0730-0301",
                "url": "http://www.acm.org/tog/"
            },
            "year": 2003,
            "externalIds": {
                "DBLP": "journals/tog/MatusikPBM03",
                "MAG": "2150810898",
                "DOI": "10.1145/1201775.882343",
                "CorpusId": 935718
            },
            "abstract": "We present a generative model for isotropic bidirectional reflectance distribution functions (BRDFs) based on acquired reflectance data. Instead of using analytical reflectance models, we represent each BRDF as a dense set of measurements. This allows us to interpolate and extrapolate in the space of acquired BRDFs to create new BRDFs. We treat each acquired BRDF as a single high-dimensional vector taken from a space of all possible BRDFs. We apply both linear (subspace) and non-linear (manifold) dimensionality reduction tools in an effort to discover a lower-dimensional representation that characterizes our measurements. We let users define perceptually meaningful parametrization directions to navigate in the reduced-dimension BRDF space. On the low-dimensional manifold, movement along these directions produces novel but valid BRDFs.",
            "referenceCount": 61,
            "citationCount": 907,
            "influentialCitationCount": 110,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dspace.mit.edu/bitstream/1721.1/87454/2/54927347-MIT.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book"
            ],
            "publicationDate": "2003-07-01",
            "journal": {
                "name": "ACM SIGGRAPH 2003 Papers",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Matusik2003ADR,\n author = {W. Matusik},\n booktitle = {ACM Transactions on Graphics},\n journal = {ACM SIGGRAPH 2003 Papers},\n title = {A data-driven reflectance model},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:712b580acb523e90b4e0306672afbbbfcb41f531",
            "@type": "ScholarlyArticle",
            "paperId": "712b580acb523e90b4e0306672afbbbfcb41f531",
            "corpusId": 1002373,
            "url": "https://www.semanticscholar.org/paper/712b580acb523e90b4e0306672afbbbfcb41f531",
            "title": "Bayesian Inference for Nonnegative Matrix Factorisation Models",
            "venue": "Computational Intelligence and Neuroscience",
            "publicationVenue": {
                "id": "urn:research:f32b7322-b69c-4e63-801d-8f50784ef778",
                "name": "Computational Intelligence and Neuroscience",
                "alternate_names": [
                    "Comput Intell Neurosci"
                ],
                "issn": "1687-5265",
                "url": "https://www.hindawi.com/journals/cin/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2031696998",
                "DBLP": "journals/cin/Cemgil09",
                "PubMedCentral": "2688815",
                "DOI": "10.1155/2009/785152",
                "CorpusId": 1002373,
                "PubMed": "19536273"
            },
            "abstract": "We describe nonnegative matrix factorisation (NMF) with a Kullback-Leibler (KL) error measure in a statistical framework, with a hierarchical generative model consisting of an observation and a prior component. Omitting the prior leads to the standard KL-NMF algorithms as special cases, where maximum likelihood parameter estimation is carried out via the Expectation-Maximisation (EM) algorithm. Starting from this view, we develop full Bayesian inference via variational Bayes or Monte Carlo. Our construction retains conjugacy and enables us to develop more powerful models while retaining attractive features of standard NMF such as monotonic convergence and easy implementation. We illustrate our approach on model order selection and image reconstruction.",
            "referenceCount": 36,
            "citationCount": 406,
            "influentialCitationCount": 56,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://downloads.hindawi.com/journals/cin/2009/785152.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-05-27",
            "journal": {
                "name": "Computational Intelligence and Neuroscience",
                "volume": "2009"
            },
            "citationStyles": {
                "bibtex": "@Article{Cemgil2009BayesianIF,\n author = {A. Cemgil},\n booktitle = {Computational Intelligence and Neuroscience},\n journal = {Computational Intelligence and Neuroscience},\n title = {Bayesian Inference for Nonnegative Matrix Factorisation Models},\n volume = {2009},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6f88397a7df1861d18303b19a77d6453ed32621e",
            "@type": "ScholarlyArticle",
            "paperId": "6f88397a7df1861d18303b19a77d6453ed32621e",
            "corpusId": 34051459,
            "url": "https://www.semanticscholar.org/paper/6f88397a7df1861d18303b19a77d6453ed32621e",
            "title": "InfoVAE: Information Maximizing Variational Autoencoders",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/ZhaoSE17b",
                "ArXiv": "1706.02262",
                "MAG": "2622563070",
                "CorpusId": 34051459
            },
            "abstract": "A key advance in learning generative models is the use of amortized inference distributions that are jointly trained with the models. We find that existing training objectives for variational autoencoders can lead to inaccurate amortized inference distributions and, in some cases, improving the objective provably degrades the inference quality. In addition, it has been observed that variational autoencoders tend to ignore the latent variables when combined with a decoding distribution that is too flexible. We again identify the cause in existing training criteria and propose a new class of objectives (InfoVAE) that mitigate these problems. We show that our model can significantly improve the quality of the variational posterior and can make effective use of the latent features regardless of the flexibility of the decoding distribution. Through extensive qualitative and quantitative analyses, we demonstrate that our models outperform competing approaches on multiple performance metrics.",
            "referenceCount": 43,
            "citationCount": 382,
            "influentialCitationCount": 50,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-06-07",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1706.02262"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhao2017InfoVAEIM,\n author = {Shengjia Zhao and Jiaming Song and Stefano Ermon},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {InfoVAE: Information Maximizing Variational Autoencoders},\n volume = {abs/1706.02262},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7f1637319a9ecf74f8afdeac4baaa6bb48fd7eb2",
            "@type": "ScholarlyArticle",
            "paperId": "7f1637319a9ecf74f8afdeac4baaa6bb48fd7eb2",
            "corpusId": 219792684,
            "url": "https://www.semanticscholar.org/paper/7f1637319a9ecf74f8afdeac4baaa6bb48fd7eb2",
            "title": "MoFlow: An Invertible Flow Model for Generating Molecular Graphs",
            "venue": "Knowledge Discovery and Data Mining",
            "publicationVenue": {
                "id": "urn:research:a0edb93b-1e95-4128-a295-6b1659149cef",
                "name": "Knowledge Discovery and Data Mining",
                "alternate_names": [
                    "KDD",
                    "Knowl Discov Data Min"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigkdd/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2006-10137",
                "MAG": "3099414221",
                "ArXiv": "2006.10137",
                "DOI": "10.1145/3394486.3403104",
                "CorpusId": 219792684
            },
            "abstract": "Generating molecular graphs with desired chemical properties driven by deep graph generative models provides a very promising way to accelerate drug discovery process. Such graph generative models usually consist of two steps: learning latent representations and generation of molecular graphs. However, to generate novel and chemically-valid molecular graphs from latent representations is very challenging because of the chemical constraints and combinatorial complexity of molecular graphs. In this paper, we propose MoFlow, a flow-based graph generative model to learn invertible mappings between molecular graphs and their latent representations. To generate molecular graphs, our MoFlow first generates bonds (edges) through a Glow based model, then generates atoms (nodes) given bonds by a novel graph conditional flow, and finally assembles them into a chemically valid molecular graph with a posthoc validity correction. Our MoFlow has merits including exact and tractable likelihood training, efficient one-pass embedding and generation, chemical validity guarantees, 100% reconstruction of training data, and good generalization ability. We validate our model by four tasks: molecular graph generation and reconstruction, visualization of the continuous latent space, property optimization, and constrained property optimization. Our MoFlow achieves state-of-the-art performance, which implies its potential efficiency and effectiveness to explore large chemical space for drug discovery.",
            "referenceCount": 37,
            "citationCount": 157,
            "influentialCitationCount": 26,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3394486.3403104",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-06-17",
            "journal": {
                "name": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Zang2020MoFlowAI,\n author = {Chengxi Zang and Fei Wang},\n booktitle = {Knowledge Discovery and Data Mining},\n journal = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining},\n title = {MoFlow: An Invertible Flow Model for Generating Molecular Graphs},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0cfc3ad63b8846edca9116bbef604310cacd0864",
            "@type": "ScholarlyArticle",
            "paperId": "0cfc3ad63b8846edca9116bbef604310cacd0864",
            "corpusId": 215827485,
            "url": "https://www.semanticscholar.org/paper/0cfc3ad63b8846edca9116bbef604310cacd0864",
            "title": "Multi-Objective Molecule Generation using Interpretable Substructures",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3016329018",
                "DBLP": "conf/icml/JinBJ20a",
                "CorpusId": 215827485
            },
            "abstract": "Drug discovery aims to find novel compounds with specified chemical property profiles. In terms of generative modeling, the goal is to learn to sample molecules in the intersection of multiple property constraints. This task becomes increasingly challenging when there are many property constraints. We propose to offset this complexity by composing molecules from a vocabulary of substructures that we call molecular rationales. These rationales are identified from molecules as substructures that are likely responsible for each property of interest. We then learn to expand rationales into a full molecule using graph generative models. Our final generative model composes molecules as mixtures of multiple rationale completions, and this mixture is fine-tuned to preserve the properties of interest. We evaluate our model on various drug design tasks and demonstrate significant improvements over state-of-the-art baselines in terms of accuracy, diversity, and novelty of generated compounds.",
            "referenceCount": 50,
            "citationCount": 130,
            "influentialCitationCount": 30,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-02-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Jin2020MultiObjectiveMG,\n author = {Wengong Jin and R. Barzilay and T. Jaakkola},\n booktitle = {International Conference on Machine Learning},\n pages = {4849-4859},\n title = {Multi-Objective Molecule Generation using Interpretable Substructures},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4fa24cc5b17e8ff1eb5a01fd37a9d267a57ac563",
            "@type": "ScholarlyArticle",
            "paperId": "4fa24cc5b17e8ff1eb5a01fd37a9d267a57ac563",
            "corpusId": 222341902,
            "url": "https://www.semanticscholar.org/paper/4fa24cc5b17e8ff1eb5a01fd37a9d267a57ac563",
            "title": "Recipes for Safety in Open-domain Chatbots",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2010-07079",
                "ArXiv": "2010.07079",
                "MAG": "3093233911",
                "CorpusId": 222341902
            },
            "abstract": "Models trained on large unlabeled corpora of human interactions will learn patterns and mimic behaviors therein, which include offensive or otherwise toxic behavior and unwanted biases. We investigate a variety of methods to mitigate these issues in the context of open-domain generative dialogue models. We introduce a new human-and-model-in-the-loop framework for both training safer models and for evaluating them, as well as a novel method to distill safety considerations inside generative models without the use of an external classifier at deployment time. We conduct experiments comparing these methods and find our new techniques are (i) safer than existing models as measured by automatic and human evaluations while (ii) maintaining usability metrics such as engagingness relative to the state of the art. We then discuss the limitations of this work by analyzing failure cases of our models.",
            "referenceCount": 75,
            "citationCount": 167,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-10-14",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2010.07079"
            },
            "citationStyles": {
                "bibtex": "@Article{Xu2020RecipesFS,\n author = {Jing Xu and Da Ju and Margaret Li and Y-Lan Boureau and J. Weston and Emily Dinan},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Recipes for Safety in Open-domain Chatbots},\n volume = {abs/2010.07079},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e7c98a4e938f2866cf17de9e565c4d18ee3274bd",
            "@type": "ScholarlyArticle",
            "paperId": "e7c98a4e938f2866cf17de9e565c4d18ee3274bd",
            "corpusId": 9597191,
            "url": "https://www.semanticscholar.org/paper/e7c98a4e938f2866cf17de9e565c4d18ee3274bd",
            "title": "Active interoceptive inference and the emotional brain",
            "venue": "Philosophical Transactions of the Royal Society B: Biological Sciences",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2530226740",
                "PubMedCentral": "5062097",
                "DOI": "10.1098/rstb.2016.0007",
                "CorpusId": 9597191,
                "PubMed": "28080966"
            },
            "abstract": "We review a recent shift in conceptions of interoception and its relationship to hierarchical inference in the brain. The notion of interoceptive inference means that bodily states are regulated by autonomic reflexes that are enslaved by descending predictions from deep generative models of our internal and external milieu. This re-conceptualization illuminates several issues in cognitive and clinical neuroscience with implications for experiences of selfhood and emotion. We first contextualize interoception in terms of active (Bayesian) inference in the brain, highlighting its enactivist (embodied) aspects. We then consider the key role of uncertainty or precision and how this might translate into neuromodulation. We next examine the implications for understanding the functional anatomy of the emotional brain, surveying recent observations on agranular cortex. Finally, we turn to theoretical issues, namely, the role of interoception in shaping a sense of embodied self and feelings. We will draw links between physiological homoeostasis and allostasis, early cybernetic ideas of predictive control and hierarchical generative models in predictive processing. The explanatory scope of interoceptive inference ranges from explanations for autism and depression, through to consciousness. We offer a brief survey of these exciting developments. This article is part of the themed issue \u2018Interoception beyond homeostasis: affect, cognition and mental health\u2019.",
            "referenceCount": 110,
            "citationCount": 494,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.2016.0007",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2016-11-19",
            "journal": {
                "name": "Philosophical Transactions of the Royal Society B: Biological Sciences",
                "volume": "371"
            },
            "citationStyles": {
                "bibtex": "@Article{Seth2016ActiveII,\n author = {A. Seth and Karl J. Friston},\n booktitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},\n journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},\n title = {Active interoceptive inference and the emotional brain},\n volume = {371},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:697743250a6ab36b35262f22fb231bc0d0636006",
            "@type": "ScholarlyArticle",
            "paperId": "697743250a6ab36b35262f22fb231bc0d0636006",
            "corpusId": 12317957,
            "url": "https://www.semanticscholar.org/paper/697743250a6ab36b35262f22fb231bc0d0636006",
            "title": "Topic Models Conditioned on Arbitrary Features with Dirichlet-multinomial Regression",
            "venue": "Conference on Uncertainty in Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:f9af8000-42f8-410d-a622-e8811e41660a",
                "name": "Conference on Uncertainty in Artificial Intelligence",
                "alternate_names": [
                    "Uncertainty in Artificial Intelligence",
                    "UAI",
                    "Conf Uncertain Artif Intell",
                    "Uncertain Artif Intell"
                ],
                "issn": null,
                "url": "http://www.auai.org/"
            },
            "year": 2008,
            "externalIds": {
                "ArXiv": "1206.3278",
                "DBLP": "journals/corr/abs-1206-3278",
                "MAG": "1947594277",
                "CorpusId": 12317957
            },
            "abstract": "Although fully generative models have been successfully used to model the contents of text documents, they are often awkward to apply to combinations of text data and document metadata. In this paper we propose a Dirichlet-multinomial regression (DMR) topic model that includes a log-linear prior on document-topic distributions that is a function of observed features of the document, such as author, publication venue, references, and dates. We show that by selecting appropriate features, DMR topic models can meet or exceed the performance of several previously published topic models designed for specific data.",
            "referenceCount": 18,
            "citationCount": 413,
            "influentialCitationCount": 48,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-07-09",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1206.3278"
            },
            "citationStyles": {
                "bibtex": "@Article{Mimno2008TopicMC,\n author = {David Mimno and A. McCallum},\n booktitle = {Conference on Uncertainty in Artificial Intelligence},\n journal = {ArXiv},\n title = {Topic Models Conditioned on Arbitrary Features with Dirichlet-multinomial Regression},\n volume = {abs/1206.3278},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:47364dceef11cb6f36af8b68b127b74da45a0978",
            "@type": "ScholarlyArticle",
            "paperId": "47364dceef11cb6f36af8b68b127b74da45a0978",
            "corpusId": 53317989,
            "url": "https://www.semanticscholar.org/paper/47364dceef11cb6f36af8b68b127b74da45a0978",
            "title": "In Ictu Oculi: Exposing AI Created Fake Videos by Detecting Eye Blinking",
            "venue": "International Workshop on Information Forensics and Security",
            "publicationVenue": {
                "id": "urn:research:c2a5c6f3-a097-43df-8125-ed95587f4651",
                "name": "International Workshop on Information Forensics and Security",
                "alternate_names": [
                    "WIFS",
                    "Int Workshop Inf Forensics Secur"
                ],
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/wifs/LiCL18",
                "MAG": "2914447220",
                "DOI": "10.1109/WIFS.2018.8630787",
                "CorpusId": 53317989
            },
            "abstract": "The new developments in deep generative networks have significantly improve the quality and efficiency in generating realistically-looking fake face videos. In this work, we describe a new method to expose fake face videos generated with deep neural network models. Our method is based on detection of eye blinking in the videos, which is a physiological signal that is not well presented in the synthesized fake videos. Our method is evaluated over benchmarks of eye-blinking detection datasets and shows promising performance on detecting videos generated with DNN based software DeepFake.",
            "referenceCount": 36,
            "citationCount": 465,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-12-01",
            "journal": {
                "name": "2018 IEEE International Workshop on Information Forensics and Security (WIFS)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Li2018InIO,\n author = {Yuezun Li and Ming-Ching Chang and Siwei Lyu},\n booktitle = {International Workshop on Information Forensics and Security},\n journal = {2018 IEEE International Workshop on Information Forensics and Security (WIFS)},\n pages = {1-7},\n title = {In Ictu Oculi: Exposing AI Created Fake Videos by Detecting Eye Blinking},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ff81ff15be185a2d59a8ce599d34c97d4a62e1b8",
            "@type": "ScholarlyArticle",
            "paperId": "ff81ff15be185a2d59a8ce599d34c97d4a62e1b8",
            "corpusId": 3112504,
            "url": "https://www.semanticscholar.org/paper/ff81ff15be185a2d59a8ce599d34c97d4a62e1b8",
            "title": "A generative perspective on MRFs in low-level vision",
            "venue": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "conf/cvpr/SchmidtGR10",
                "MAG": "2075674485",
                "DOI": "10.1109/CVPR.2010.5539844",
                "CorpusId": 3112504
            },
            "abstract": "Markov random fields (MRFs) are popular and generic probabilistic models of prior knowledge in low-level vision. Yet their generative properties are rarely examined, while application-specific models and non-probabilistic learning are gaining increased attention. In this paper we revisit the generative aspects of MRFs, and analyze the quality of common image priors in a fully application-neutral setting. Enabled by a general class of MRFs with flexible potentials and an efficient Gibbs sampler, we find that common models do not capture the statistics of natural images well. We show how to remedy this by exploiting the efficient sampler for learning better generative MRFs based on flexible potentials. We perform image restoration with these models by computing the Bayesian minimum mean squared error estimate (MMSE) using sampling. This addresses a number of shortcomings that have limited generative MRFs so far, and leads to substantially improved performance over maximum a-posteriori (MAP) estimation. We demonstrate that combining our learned generative models with sampling-based MMSE estimation yields excellent application results that can compete with recent discriminative methods.",
            "referenceCount": 32,
            "citationCount": 141,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2010-06-13",
            "journal": {
                "name": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Schmidt2010AGP,\n author = {Uwe Schmidt and Q. Gao and S. Roth},\n booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},\n journal = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},\n pages = {1751-1758},\n title = {A generative perspective on MRFs in low-level vision},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5dce96b15fed603fc191bfbce912a33d21143c8d",
            "@type": "ScholarlyArticle",
            "paperId": "5dce96b15fed603fc191bfbce912a33d21143c8d",
            "corpusId": 202783404,
            "url": "https://www.semanticscholar.org/paper/5dce96b15fed603fc191bfbce912a33d21143c8d",
            "title": "Efficient Graph Generation with Graph Recurrent Attention Networks",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1910-00760",
                "ArXiv": "1910.00760",
                "MAG": "2978498781",
                "CorpusId": 202783404
            },
            "abstract": "We propose a new family of efficient and expressive deep generative models of graphs, called Graph Recurrent Attention Networks (GRANs). Our model generates graphs one block of nodes and associated edges at a time. The block size and sampling stride allow us to trade off sample quality for efficiency. Compared to previous RNN-based graph generative models, our framework better captures the auto-regressive conditioning between the already-generated and to-be-generated parts of the graph using Graph Neural Networks (GNNs) with attention. This not only reduces the dependency on node ordering but also bypasses the long-term bottleneck caused by the sequential nature of RNNs. Moreover, we parameterize the output distribution per block using a mixture of Bernoulli, which captures the correlations among generated edges within the block. Finally, we propose to handle node orderings in generation by marginalizing over a family of canonical orderings. On standard benchmarks, we achieve state-of-the-art time efficiency and sample quality compared to previous models. Additionally, we show our model is capable of generating large graphs of up to 5K nodes with good quality. Our code is released at: \\url{https://github.com/lrjconan/GRAN}.",
            "referenceCount": 40,
            "citationCount": 240,
            "influentialCitationCount": 60,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-10-02",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Liao2019EfficientGG,\n author = {Renjie Liao and Yujia Li and Yang Song and Shenlong Wang and C. Nash and William L. Hamilton and D. Duvenaud and R. Urtasun and R. Zemel},\n booktitle = {Neural Information Processing Systems},\n pages = {4257-4267},\n title = {Efficient Graph Generation with Graph Recurrent Attention Networks},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:405c31c85a324942811f3c9dc53ce3528f9284df",
            "@type": "ScholarlyArticle",
            "paperId": "405c31c85a324942811f3c9dc53ce3528f9284df",
            "corpusId": 4994434,
            "url": "https://www.semanticscholar.org/paper/405c31c85a324942811f3c9dc53ce3528f9284df",
            "title": "Towards a Neural Statistician",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1606.02185",
                "DBLP": "conf/iclr/EdwardsS17",
                "MAG": "2412589713",
                "CorpusId": 4994434
            },
            "abstract": "An efficient learner is one who reuses what they already know to tackle a new problem. For a machine learner, this means understanding the similarities amongst datasets. In order to do this, one must take seriously the idea of working with datasets, rather than datapoints, as the key objects to model. Towards this goal, we demonstrate an extension of a variational autoencoder that can learn a method for computing representations, or statistics, of datasets in an unsupervised fashion. The network is trained to produce statistics that encapsulate a generative model for each dataset. Hence the network enables efficient learning from new datasets for both unsupervised and supervised tasks. We show that we are able to learn statistics that can be used for: clustering datasets, transferring generative models to new datasets, selecting representative samples of datasets and classifying previously unseen classes. We refer to our model as a neural statistician, and by this we mean a neural network that can learn to compute summary statistics of datasets without supervision.",
            "referenceCount": 41,
            "citationCount": 385,
            "influentialCitationCount": 39,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-06-07",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1606.02185"
            },
            "citationStyles": {
                "bibtex": "@Article{Edwards2016TowardsAN,\n author = {Harrison Edwards and A. Storkey},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Towards a Neural Statistician},\n volume = {abs/1606.02185},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7dd434b3799a6c8c346a1d7ee77d37980a4ef5b9",
            "@type": "ScholarlyArticle",
            "paperId": "7dd434b3799a6c8c346a1d7ee77d37980a4ef5b9",
            "corpusId": 3543617,
            "url": "https://www.semanticscholar.org/paper/7dd434b3799a6c8c346a1d7ee77d37980a4ef5b9",
            "title": "Syntax-Directed Variational Autoencoder for Structured Data",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2963124123",
                "DBLP": "conf/iclr/DaiTDSS18",
                "ArXiv": "1802.08786",
                "CorpusId": 3543617
            },
            "abstract": "Deep generative models have been enjoying success in modeling continuous data. However it remains challenging to capture the representations for discrete structures with formal grammars and semantics, e.g., computer programs and molecular structures. How to generate both syntactically and semantically correct data still remains largely an open problem. Inspired by the theory of compiler where the syntax and semantics check is done via syntax-directed translation (SDT), we propose a novel syntax-directed variational autoencoder (SD-VAE) by introducing stochastic lazy attributes. This approach converts the offline SDT check into on-the-fly generated guidance for constraining the decoder. Comparing to the state-of-the-art methods, our approach enforces constraints on the output space so that the output will be not only syntactically valid, but also semantically reasonable. We evaluate the proposed model with applications in programming language and molecules, including reconstruction and program/molecule optimization. The results demonstrate the effectiveness in incorporating syntactic and semantic constraints in discrete generative models, which is significantly better than current state-of-the-art approaches.",
            "referenceCount": 28,
            "citationCount": 282,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1802.08786"
            },
            "citationStyles": {
                "bibtex": "@Article{Dai2018SyntaxDirectedVA,\n author = {H. Dai and Yingtao Tian and Bo Dai and S. Skiena and Le Song},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Syntax-Directed Variational Autoencoder for Structured Data},\n volume = {abs/1802.08786},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:155f4899a4904ebdb06f166e625ff3e4618ed371",
            "@type": "ScholarlyArticle",
            "paperId": "155f4899a4904ebdb06f166e625ff3e4618ed371",
            "corpusId": 11153233,
            "url": "https://www.semanticscholar.org/paper/155f4899a4904ebdb06f166e625ff3e4618ed371",
            "title": "Generative Local Metric Learning for Nearest Neighbor Classification",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "journals/pami/NohZL18",
                "MAG": "2151565710",
                "DOI": "10.1109/TPAMI.2017.2666151",
                "CorpusId": 11153233,
                "PubMed": "28186880"
            },
            "abstract": "We consider the problem of learning a local metric in order to enhance the performance of nearest neighbor classification. Conventional metric learning methods attempt to separate data distributions in a purely discriminative manner; here we show how to take advantage of information from parametric generative models. We focus on the bias in the information-theoretic error arising from finite sampling effects, and find an appropriate local metric that maximally reduces the bias based upon knowledge from generative models. As a byproduct, the asymptotic theoretical analysis in this work relates metric learning to dimensionality reduction from a novel perspective, which was not understood from previous discriminative approaches. Empirical experiments show that this learned local metric enhances the discriminative nearest neighbor performance on various datasets using simple class conditional generative models such as a Gaussian.",
            "referenceCount": 46,
            "citationCount": 74,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-12-06",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "40"
            },
            "citationStyles": {
                "bibtex": "@Article{Noh2010GenerativeLM,\n author = {Yung-Kyun Noh and Byoung-Tak Zhang and Daniel D. Lee},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {106-118},\n title = {Generative Local Metric Learning for Nearest Neighbor Classification},\n volume = {40},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:622e392f8c5da161cf61582af434f6976094dfc4",
            "@type": "ScholarlyArticle",
            "paperId": "622e392f8c5da161cf61582af434f6976094dfc4",
            "corpusId": 88517649,
            "url": "https://www.semanticscholar.org/paper/622e392f8c5da161cf61582af434f6976094dfc4",
            "title": "From Variational to Deterministic Autoencoders",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1903-12436",
                "MAG": "2994610548",
                "ArXiv": "1903.12436",
                "CorpusId": 88517649
            },
            "abstract": "Variational Autoencoders (VAEs) provide a theoretically-backed and popular framework for deep generative models. However, learning a VAE from data poses still unanswered theoretical questions and considerable practical challenges. In this work, we propose an alternative framework for generative modeling that is simpler, easier to train, and deterministic, yet has many of the advantages of VAEs. We observe that sampling a stochastic encoder in a Gaussian VAE can be interpreted as simply injecting noise into the input of a deterministic decoder. We investigate how substituting this kind of stochasticity, with other explicit and implicit regularization schemes, can lead to an equally smooth and meaningful latent space without forcing it to conform to an arbitrarily chosen prior. To retrieve a generative mechanism to sample new data, we introduce an ex-post density estimation step that can be readily applied also to existing VAEs, improving their sample quality. We show, in a rigorous empirical study, that the proposed regularized deterministic autoencoders are able to generate samples that are comparable to, or better than, those of VAEs and more powerful alternatives when applied to images as well as to structured data such as molecules. \\footnote{An implementation is available at: \\url{this https URL}}",
            "referenceCount": 65,
            "citationCount": 227,
            "influentialCitationCount": 51,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-29",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1903.12436"
            },
            "citationStyles": {
                "bibtex": "@Article{Ghosh2019FromVT,\n author = {Partha Ghosh and Mehdi S. M. Sajjadi and Antonio Vergari and Michael J. Black and B. Scholkopf},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {From Variational to Deterministic Autoencoders},\n volume = {abs/1903.12436},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:47cbd8cfd6fcba83d3b3714faef480260bc9d5de",
            "@type": "ScholarlyArticle",
            "paperId": "47cbd8cfd6fcba83d3b3714faef480260bc9d5de",
            "corpusId": 212628513,
            "url": "https://www.semanticscholar.org/paper/47cbd8cfd6fcba83d3b3714faef480260bc9d5de",
            "title": "Likelihood Regret: An Out-of-Distribution Detection Score For Variational Auto-encoder",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3009328596",
                "DBLP": "journals/corr/abs-2003-02977",
                "ArXiv": "2003.02977",
                "CorpusId": 212628513
            },
            "abstract": "Deep probabilistic generative models enable modeling the likelihoods of very high dimensional data. An important application of generative modeling should be the ability to detect out-of-distribution (OOD) samples by setting a threshold on the likelihood. However, a recent study shows that probabilistic generative models can, in some cases, assign higher likelihoods on certain types of OOD samples, making the OOD detection rules based on likelihood threshold problematic. To address this issue, several OOD detection methods have been proposed for deep generative models. In this paper, we make the observation that some of these methods fail when applied to generative models based on Variational Auto-encoders (VAE). As an alternative, we propose Likelihood Regret, an efficient OOD score for VAEs. We benchmark our proposed method over existing approaches, and empirical results suggest that our method obtains the best overall OOD detection performances compared with other OOD method applied on VAE.",
            "referenceCount": 55,
            "citationCount": 120,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-03-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2003.02977"
            },
            "citationStyles": {
                "bibtex": "@Article{Xiao2020LikelihoodRA,\n author = {Zhisheng Xiao and Qing Yan and Y. Amit},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Likelihood Regret: An Out-of-Distribution Detection Score For Variational Auto-encoder},\n volume = {abs/2003.02977},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:89e7593359c4e07b34a02644bfd9a2b5dd6c36f6",
            "@type": "ScholarlyArticle",
            "paperId": "89e7593359c4e07b34a02644bfd9a2b5dd6c36f6",
            "corpusId": 15578083,
            "url": "https://www.semanticscholar.org/paper/89e7593359c4e07b34a02644bfd9a2b5dd6c36f6",
            "title": "Deep Kalman Filters",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/KrishnanSS15",
                "MAG": "2176035349",
                "ArXiv": "1511.05121",
                "CorpusId": 15578083
            },
            "abstract": "Kalman Filters are one of the most influential models of time-varying phenomena. They admit an intuitive probabilistic interpretation, have a simple functional form, and enjoy widespread adoption in a variety of disciplines. Motivated by recent variational methods for learning deep generative models, we introduce a unified algorithm to efficiently learn a broad spectrum of Kalman filters. Of particular interest is the use of temporal generative models for counterfactual inference. We investigate the efficacy of such models for counterfactual inference, and to that end we introduce the \"Healing MNIST\" dataset where long-term structure, noise and actions are applied to sequences of digits. We show the efficacy of our method for modeling this dataset. We further show how our model can be used for counterfactual inference for patients, based on electronic health record data of 8,000 patients over 4.5 years.",
            "referenceCount": 35,
            "citationCount": 323,
            "influentialCitationCount": 46,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-11-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1511.05121"
            },
            "citationStyles": {
                "bibtex": "@Article{Krishnan2015DeepKF,\n author = {R. G. Krishnan and Uri Shalit and D. Sontag},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Deep Kalman Filters},\n volume = {abs/1511.05121},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7f82a44909d634ab3d158e89c354388f720cbe3d",
            "@type": "ScholarlyArticle",
            "paperId": "7f82a44909d634ab3d158e89c354388f720cbe3d",
            "corpusId": 3128663,
            "url": "https://www.semanticscholar.org/paper/7f82a44909d634ab3d158e89c354388f720cbe3d",
            "title": "Postcolonial computing: a lens on design and development",
            "venue": "International Conference on Human Factors in Computing Systems",
            "publicationVenue": {
                "id": "urn:research:b55b50b1-aae7-47a7-b042-8aecc930073d",
                "name": "International Conference on Human Factors in Computing Systems",
                "alternate_names": [
                    "CHI",
                    "Int Conf Hum Factor Comput Syst",
                    "Human Factors in Computing Systems",
                    "Conference on Human Interface",
                    "Conf Hum Interface",
                    "Hum Factor Comput Syst"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigchi/"
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2130645129",
                "DBLP": "conf/chi/IraniVDPG10",
                "DOI": "10.1145/1753326.1753522",
                "CorpusId": 3128663
            },
            "abstract": "As our technologies travel to new cultural contexts and our designs and methods engage new constituencies, both our design and analytical practices face significant challenges. We offer postcolonial computing as an analytical orientation to better understand these challenges. This analytic orientation inspires four key shifts in our approach to HCI4D efforts: generative models of culture, development as a historical program, uneven economic relations, and cultural epistemologies. Then, through reconsideration of the practices of engagement, articulation and translation in other contexts, we offer designers and researchers ways of understanding use and design practice to respond to global connectivity and movement.",
            "referenceCount": 40,
            "citationCount": 575,
            "influentialCitationCount": 54,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2010-04-10",
            "journal": {
                "name": "Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Irani2010PostcolonialCA,\n author = {L. Irani and J. Vertesi and P. Dourish and K. Philip and Rebecca E. Grinter},\n booktitle = {International Conference on Human Factors in Computing Systems},\n journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},\n title = {Postcolonial computing: a lens on design and development},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2a8a076c26875208d52c66e07aa7f6db9a4f34b7",
            "@type": "ScholarlyArticle",
            "paperId": "2a8a076c26875208d52c66e07aa7f6db9a4f34b7",
            "corpusId": 11927782,
            "url": "https://www.semanticscholar.org/paper/2a8a076c26875208d52c66e07aa7f6db9a4f34b7",
            "title": "Representational Power of Restricted Boltzmann Machines and Deep Belief Networks",
            "venue": "Neural Computation",
            "publicationVenue": {
                "id": "urn:research:69b9bcdd-8229-4a00-a6e0-00f0e99a2bf3",
                "name": "Neural Computation",
                "alternate_names": [
                    "Neural Comput"
                ],
                "issn": "0899-7667",
                "url": "http://cognet.mit.edu/library/journals/journal?issn=08997667"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2064630666",
                "DBLP": "journals/neco/RouxB08",
                "DOI": "10.1162/neco.2008.04-07-510",
                "CorpusId": 11927782,
                "PubMed": "18254699"
            },
            "abstract": "Deep belief networks (DBN) are generative neural network models with many layers of hidden explanatory factors, recently introduced by Hinton, Osindero, and Teh (2006) along with a greedy layer-wise unsupervised learning algorithm. The building block of a DBN is a probabilistic model called a restricted Boltzmann machine (RBM), used to represent one layer of the model. Restricted Boltzmann machines are interesting because inference is easy in them and because they have been successfully used as building blocks for training deeper models. We first prove that adding hidden units yields strictly improved modeling power, while a second theorem shows that RBMs are universal approximators of discrete distributions. We then study the question of whether DBNs with more layers are strictly more powerful in terms of representational power. This suggests a new and less greedy criterion for training RBMs within DBNs.",
            "referenceCount": 20,
            "citationCount": 758,
            "influentialCitationCount": 45,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.iro.umontreal.ca/%7Elisa/pointeurs/rbm_universality_techreport.pdf",
                "status": "CLOSED"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-06-01",
            "journal": {
                "name": "Neural Computation",
                "volume": "20"
            },
            "citationStyles": {
                "bibtex": "@Article{Roux2008RepresentationalPO,\n author = {Nicolas Le Roux and Yoshua Bengio},\n booktitle = {Neural Computation},\n journal = {Neural Computation},\n pages = {1631-1649},\n title = {Representational Power of Restricted Boltzmann Machines and Deep Belief Networks},\n volume = {20},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:45b4dde8e0945912a39666f2715cdf10a4445b1c",
            "@type": "ScholarlyArticle",
            "paperId": "45b4dde8e0945912a39666f2715cdf10a4445b1c",
            "corpusId": 1768942,
            "url": "https://www.semanticscholar.org/paper/45b4dde8e0945912a39666f2715cdf10a4445b1c",
            "title": "Expectation-Propogation for the Generative Aspect Model",
            "venue": "Conference on Uncertainty in Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:f9af8000-42f8-410d-a622-e8811e41660a",
                "name": "Conference on Uncertainty in Artificial Intelligence",
                "alternate_names": [
                    "Uncertainty in Artificial Intelligence",
                    "UAI",
                    "Conf Uncertain Artif Intell",
                    "Uncertain Artif Intell"
                ],
                "issn": null,
                "url": "http://www.auai.org/"
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2104924585",
                "DBLP": "journals/corr/abs-1301-0588",
                "ArXiv": "1301.0588",
                "CorpusId": 1768942
            },
            "abstract": "The generative aspect model is an extension of the multinomial model for text that allows word probabilities to vary stochastically across documents. Previous results with aspect models have been promising, but hindered by the computational difficulty of carrying out inference and learning. This paper demonstrates that the simple variational methods of Blei et al. (2001) can lead to inaccurate inferences and biased learning for the generative aspect model. We develop an alternative approach that leads to higher accuracy at comparable cost. An extension of Expectation-Propagation is used for inference and then embedded in an EM algorithm for learning. Experimental results are presented for both synthetic and real data sets.",
            "referenceCount": 12,
            "citationCount": 563,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2002-08-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Minka2002ExpectationPropogationFT,\n author = {T. Minka and J. Lafferty},\n booktitle = {Conference on Uncertainty in Artificial Intelligence},\n pages = {352-359},\n title = {Expectation-Propogation for the Generative Aspect Model},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:86e5827087e11dc929d592ee7b3d7581fc48265e",
            "@type": "ScholarlyArticle",
            "paperId": "86e5827087e11dc929d592ee7b3d7581fc48265e",
            "corpusId": 4316147,
            "url": "https://www.semanticscholar.org/paper/86e5827087e11dc929d592ee7b3d7581fc48265e",
            "title": "Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN",
            "venue": "International Conference on Data Mining and Big Data",
            "publicationVenue": {
                "id": "urn:research:92c8fa0a-d112-4d5c-a54e-750716b7201f",
                "name": "International Conference on Data Mining and Big Data",
                "alternate_names": [
                    "DMBD",
                    "Int Conf Data Min Big Data"
                ],
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/HuT17",
                "ArXiv": "1702.05983",
                "MAG": "2591788621",
                "DOI": "10.1007/978-981-19-8991-9_29",
                "CorpusId": 4316147
            },
            "abstract": null,
            "referenceCount": 29,
            "citationCount": 391,
            "influentialCitationCount": 45,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1702.05983",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-02-20",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1702.05983"
            },
            "citationStyles": {
                "bibtex": "@Article{Hu2017GeneratingAM,\n author = {Weiwei Hu and Ying Tan},\n booktitle = {International Conference on Data Mining and Big Data},\n journal = {ArXiv},\n title = {Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN},\n volume = {abs/1702.05983},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:05b16031728e1a218ac95a1cef914df73c4204ae",
            "@type": "ScholarlyArticle",
            "paperId": "05b16031728e1a218ac95a1cef914df73c4204ae",
            "corpusId": 129945241,
            "url": "https://www.semanticscholar.org/paper/05b16031728e1a218ac95a1cef914df73c4204ae",
            "title": "The Trajectron: Probabilistic Multi-Agent Trajectory Modeling With Dynamic Spatiotemporal Graphs",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2940718442",
                "DBLP": "conf/iccv/IvanovicP19",
                "DOI": "10.1109/ICCV.2019.00246",
                "CorpusId": 129945241
            },
            "abstract": "Developing safe human-robot interaction systems is a necessary step towards the widespread integration of autonomous agents in society. A key component of such systems is the ability to reason about the many potential futures (e.g. trajectories) of other agents in the scene. Towards this end, we present the Trajectron, a graph-structured model that predicts many potential future trajectories of multiple agents simultaneously in both highly dynamic and multimodal scenarios (i.e. where the number of agents in the scene is time-varying and there are many possible highly-distinct futures for each agent). It combines tools from recurrent sequence modeling and variational deep generative modeling to produce a distribution of future trajectories for each agent in a scene. We demonstrate the performance of our model on several datasets, obtaining state-of-the-art results on standard trajectory prediction metrics as well as introducing a new metric for comparing models that output distributions.",
            "referenceCount": 51,
            "citationCount": 311,
            "influentialCitationCount": 37,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1810.05993",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-10-14",
            "journal": {
                "name": "2019 IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ivanovic2018TheTP,\n author = {B. Ivanovic and M. Pavone},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},\n pages = {2375-2384},\n title = {The Trajectron: Probabilistic Multi-Agent Trajectory Modeling With Dynamic Spatiotemporal Graphs},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7395e325914b1f5caea18ea8446ef8db05662318",
            "@type": "ScholarlyArticle",
            "paperId": "7395e325914b1f5caea18ea8446ef8db05662318",
            "corpusId": 52353,
            "url": "https://www.semanticscholar.org/paper/7395e325914b1f5caea18ea8446ef8db05662318",
            "title": "Fast Exact Inference with a Factored Model for Natural Language Parsing",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2167072947",
                "DBLP": "conf/nips/KleinM02",
                "CorpusId": 52353
            },
            "abstract": "We present a novel generative model for natural language tree structures in which semantic (lexical dependency) and syntactic (PCFG) structures are scored with separate models. This factorization provides conceptual simplicity, straightforward opportunities for separately improving the component models, and a level of performance comparable to similar, non-factored models. Most importantly, unlike other modern parsing models, the factored model admits an extremely effective A* parsing algorithm, which enables efficient, exact inference.",
            "referenceCount": 22,
            "citationCount": 909,
            "influentialCitationCount": 62,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Klein2002FastEI,\n author = {D. Klein and Christopher D. Manning},\n booktitle = {Neural Information Processing Systems},\n pages = {3-10},\n title = {Fast Exact Inference with a Factored Model for Natural Language Parsing},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:09d2f3467f171f253499773d8c1d71f21ac4f983",
            "@type": "ScholarlyArticle",
            "paperId": "09d2f3467f171f253499773d8c1d71f21ac4f983",
            "corpusId": 5395254,
            "url": "https://www.semanticscholar.org/paper/09d2f3467f171f253499773d8c1d71f21ac4f983",
            "title": "Unsupervised Learning of 3D Structure from Images",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/RezendeEMBJH16",
                "MAG": "2963730200",
                "ArXiv": "1607.00662",
                "CorpusId": 5395254
            },
            "abstract": "A key goal of computer vision is to recover the underlying 3D structure from 2D observations of the world. In this paper we learn strong deep generative models of 3D structures, and recover these structures from 3D and 2D images via probabilistic inference. We demonstrate high-quality samples and report log-likelihoods on several datasets, including ShapeNet [2], and establish the first benchmarks in the literature. We also show how these models and their inference networks can be trained end-to-end from 2D images. This demonstrates for the first time the feasibility of learning to infer 3D representations of the world in a purely unsupervised manner.",
            "referenceCount": 41,
            "citationCount": 376,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-07-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Rezende2016UnsupervisedLO,\n author = {Danilo Jimenez Rezende and S. Eslami and S. Mohamed and P. Battaglia and Max Jaderberg and N. Heess},\n booktitle = {Neural Information Processing Systems},\n pages = {4997-5005},\n title = {Unsupervised Learning of 3D Structure from Images},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5e4d2e73e71806e9147afbedcd504424721fa059",
            "@type": "ScholarlyArticle",
            "paperId": "5e4d2e73e71806e9147afbedcd504424721fa059",
            "corpusId": 9010805,
            "url": "https://www.semanticscholar.org/paper/5e4d2e73e71806e9147afbedcd504424721fa059",
            "title": "Geometric GAN",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1705.02894",
                "MAG": "3037695135",
                "DBLP": "journals/corr/LimY17",
                "CorpusId": 9010805
            },
            "abstract": "Generative Adversarial Nets (GANs) represent an important milestone for effective generative models, which has inspired numerous variants seemingly different from each other. One of the main contributions of this paper is to reveal a unified geometric structure in GAN and its variants. Specifically, we show that the adversarial generative model training can be decomposed into three geometric steps: separating hyperplane search, discriminator parameter update away from the separating hyperplane, and the generator update along the normal vector direction of the separating hyperplane. This geometric intuition reveals the limitations of the existing approaches and leads us to propose a new formulation called geometric GAN using SVM separating hyperplane that maximizes the margin. Our theoretical analysis shows that the geometric GAN converges to a Nash equilibrium between the discriminator and generator. In addition, extensive numerical results show that the superior performance of geometric GAN.",
            "referenceCount": 22,
            "citationCount": 382,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-05-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1705.02894"
            },
            "citationStyles": {
                "bibtex": "@Article{Lim2017GeometricG,\n author = {Jae Hyun Lim and J. C. Ye},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Geometric GAN},\n volume = {abs/1705.02894},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7d77a29f2e1dc796d202d6cf01f299da7c197c22",
            "@type": "ScholarlyArticle",
            "paperId": "7d77a29f2e1dc796d202d6cf01f299da7c197c22",
            "corpusId": 1696516,
            "url": "https://www.semanticscholar.org/paper/7d77a29f2e1dc796d202d6cf01f299da7c197c22",
            "title": "Improved Variational Autoencoders for Text Modeling using Dilated Convolutions",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1702.08139",
                "DBLP": "conf/icml/YangHSB17",
                "MAG": "2963600562",
                "CorpusId": 1696516
            },
            "abstract": "Recent work on generative modeling of text has found that variational auto-encoders (VAE) incorporating LSTM decoders perform worse than simpler LSTM language models (Bowman et al., 2015). This negative result is so far poorly understood, but has been attributed to the propensity of LSTM decoders to ignore conditioning information from the encoder. In this paper, we experiment with a new type of decoder for VAE: a dilated CNN. By changing the decoder's dilation architecture, we control the effective context from previously generated words. In experiments, we find that there is a trade off between the contextual capacity of the decoder and the amount of encoding information used. We show that with the right decoder, VAE can outperform LSTM language models. We demonstrate perplexity gains on two datasets, representing the first positive experimental result on the use VAE for generative modeling of text. Further, we conduct an in-depth investigation of the use of VAE (with our new decoding architecture) for semi-supervised and unsupervised labeling tasks, demonstrating gains over several strong baselines.",
            "referenceCount": 42,
            "citationCount": 350,
            "influentialCitationCount": 46,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-02-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1702.08139"
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2017ImprovedVA,\n author = {Zichao Yang and Zhiting Hu and R. Salakhutdinov and Taylor Berg-Kirkpatrick},\n booktitle = {International Conference on Machine Learning},\n journal = {ArXiv},\n title = {Improved Variational Autoencoders for Text Modeling using Dilated Convolutions},\n volume = {abs/1702.08139},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8fc012941dccba5017bfd73dfd40e414001b74c4",
            "@type": "ScholarlyArticle",
            "paperId": "8fc012941dccba5017bfd73dfd40e414001b74c4",
            "corpusId": 7362323,
            "url": "https://www.semanticscholar.org/paper/8fc012941dccba5017bfd73dfd40e414001b74c4",
            "title": "Complex Graphs and Networks",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "638149299",
                "DOI": "10.1090/CBMS/107",
                "CorpusId": 7362323
            },
            "abstract": "Graph theory in the information age Old and new concentration inequalities A generative model--the preferential attachment scheme Duplication models for biological networks Random graphs with given expected degrees The rise of the giant component Average distance and the diameter Eigenvalues of the adjacency matrix of $G(\\mathbf{w})$ The semi-circle law for $G(\\mathbf{w})$ Coupling on-line and off-line analyses of random graphs The configuration model for power law graphs The small world phenomenon in hybrid graphs Bibliography Index.",
            "referenceCount": 8,
            "citationCount": 774,
            "influentialCitationCount": 53,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2006-08-28",
            "journal": {
                "name": "",
                "volume": "107"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Chung2006ComplexGA,\n author = {F. Chung and Linyuan Lu},\n title = {Complex Graphs and Networks},\n volume = {107},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca2858b2040724ae9f29ba601df12aae2e539596",
            "@type": "ScholarlyArticle",
            "paperId": "ca2858b2040724ae9f29ba601df12aae2e539596",
            "corpusId": 1364249,
            "url": "https://www.semanticscholar.org/paper/ca2858b2040724ae9f29ba601df12aae2e539596",
            "title": "Corpus-Based Induction of Syntactic Structure: Models of Dependency and Constituency",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2153568660",
                "DBLP": "conf/acl/KleinM04",
                "ACL": "P04-1061",
                "DOI": "10.3115/1218955.1219016",
                "CorpusId": 1364249
            },
            "abstract": "We present a generative model for the unsupervised learning of dependency structures. We also describe the multiplicative combination of this dependency model with a model of linear constituency. The product model outperforms both components on their respective evaluation metrics, giving the best published figures for unsupervised dependency parsing and unsupervised constituency parsing. We also demonstrate that the combined model works and is robust cross-linguistically, being able to exploit either attachment or distributional regularities that are salient in the data.",
            "referenceCount": 26,
            "citationCount": 566,
            "influentialCitationCount": 104,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/1218955.1219016",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2004-07-21",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Klein2004CorpusBasedIO,\n author = {D. Klein and Christopher D. Manning},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {478-485},\n title = {Corpus-Based Induction of Syntactic Structure: Models of Dependency and Constituency},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8262bd0fb41956f136dd2bc04ff4863584a43ce7",
            "@type": "ScholarlyArticle",
            "paperId": "8262bd0fb41956f136dd2bc04ff4863584a43ce7",
            "corpusId": 15334151,
            "url": "https://www.semanticscholar.org/paper/8262bd0fb41956f136dd2bc04ff4863584a43ce7",
            "title": "A Hybrid Discriminative/Generative Approach for Modeling Human Activities",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "conf/ijcai/LesterCKBH05",
                "MAG": "1491797991",
                "CorpusId": 15334151
            },
            "abstract": "Accurate recognition and tracking of human activities is an important goal of ubiquitous computing. Recent advances in the development of multi-modal wearable sensors enable us to gather rich datasets of human activities. However, the problem of automatically identifying the most useful features for modeling such activities remains largely unsolved. In this paper we present a hybrid approach to recognizing activities, which combines boosting to discriminatively select useful features and learn an ensemble of static classifiers to recognize different activities, with hidden Markov models (HMMs) to capture the temporal regularities and smoothness of activities. We tested the activity recognition system using over 12 hours of wearable-sensor data collected by volunteers in natural unconstrained environments. The models succeeded in identifying a small set of maximally informative features, and were able identify ten different human activities with an accuracy of 95%.",
            "referenceCount": 20,
            "citationCount": 491,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2005-07-30",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lester2005AHD,\n author = {Jonathan Lester and Tanzeem Choudhury and Nicky Kern and G. Borriello and B. Hannaford},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {766-772},\n title = {A Hybrid Discriminative/Generative Approach for Modeling Human Activities},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:69c51cb5d61910a8ad80751a45b1a1e90fe3f386",
            "@type": "ScholarlyArticle",
            "paperId": "69c51cb5d61910a8ad80751a45b1a1e90fe3f386",
            "corpusId": 55701876,
            "url": "https://www.semanticscholar.org/paper/69c51cb5d61910a8ad80751a45b1a1e90fe3f386",
            "title": "Memory Replay GANs: learning to generate images from new categories without forgetting",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1809.02058",
                "DBLP": "conf/nips/WuHLWWR18",
                "MAG": "2892234010",
                "CorpusId": 55701876
            },
            "abstract": "Previous works on sequential learning address the problem of forgetting in discriminative models. In this paper we consider the case of generative models. In particular, we investigate generative adversarial networks (GANs) in the task of learning new categories in a sequential fashion. We first show that sequential fine tuning renders the network unable to properly generate images from previous categories (i.e. forgetting). Addressing this problem, we propose Memory Replay GANs (MeRGANs), a conditional GAN framework that integrates a memory replay generator. We study two methods to prevent forgetting by leveraging these replays, namely joint training with replay and replay alignment. Qualitative and quantitative experimental results in MNIST, SVHN and LSUN datasets show that our memory replay approach can generate competitive images while significantly mitigating the forgetting of previous categories.",
            "referenceCount": 33,
            "citationCount": 244,
            "influentialCitationCount": 27,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2018MemoryRG,\n author = {Chenshen Wu and Luis Herranz and Xialei Liu and Yaxing Wang and Joost van de Weijer and B. Raducanu},\n booktitle = {Neural Information Processing Systems},\n pages = {5966-5976},\n title = {Memory Replay GANs: learning to generate images from new categories without forgetting},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:12c37cb419121cdb43f2c6620303932f43e2e1b7",
            "@type": "ScholarlyArticle",
            "paperId": "12c37cb419121cdb43f2c6620303932f43e2e1b7",
            "corpusId": 204087649,
            "url": "https://www.semanticscholar.org/paper/12c37cb419121cdb43f2c6620303932f43e2e1b7",
            "title": "Adversarial Video Generation on Complex Datasets",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2976617189",
                "CorpusId": 204087649
            },
            "abstract": "Generative models of natural images have progressed towards high fidelity samples by the strong leveraging of scale. We attempt to carry this success to the field of video modeling by showing that large Generative Adversarial Networks trained on the complex Kinetics-600 dataset are able to produce video samples of substantially higher complexity and fidelity than previous work. Our proposed model, Dual Video Discriminator GAN (DVD-GAN), scales to longer and higher resolution videos by leveraging a computationally efficient decomposition of its discriminator. We evaluate on the related tasks of video synthesis and video prediction, and achieve new state-of-the-art Frechet Inception Distance for prediction for Kinetics-600, as well as state-of-the-art Inception Score for synthesis on the UCF-101 dataset, alongside establishing a strong baseline for synthesis on Kinetics-600.",
            "referenceCount": 69,
            "citationCount": 186,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-09-25",
            "journal": {
                "name": "arXiv: Computer Vision and Pattern Recognition",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Clark2019AdversarialVG,\n author = {Aidan Clark and Jeff Donahue and K. Simonyan},\n journal = {arXiv: Computer Vision and Pattern Recognition},\n title = {Adversarial Video Generation on Complex Datasets},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:034f1c5589644a6b42f50bf61b1628a1c5607fd9",
            "@type": "ScholarlyArticle",
            "paperId": "034f1c5589644a6b42f50bf61b1628a1c5607fd9",
            "corpusId": 49303347,
            "url": "https://www.semanticscholar.org/paper/034f1c5589644a6b42f50bf61b1628a1c5607fd9",
            "title": "Learning Factorized Multimodal Representations",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/corr/abs-1806-06176",
                "ArXiv": "1806.06176",
                "MAG": "2951575728",
                "CorpusId": 49303347
            },
            "abstract": "Learning multimodal representations is a fundamentally complex research problem due to the presence of multiple heterogeneous sources of information. Although the presence of multiple modalities provides additional valuable information, there are two key challenges to address when learning from multimodal data: 1) models must learn the complex intra-modal and cross-modal interactions for prediction and 2) models must be robust to unexpected missing or noisy modalities during testing. In this paper, we propose to optimize for a joint generative-discriminative objective across multimodal data and labels. We introduce a model that factorizes representations into two sets of independent factors: multimodal discriminative and modality-specific generative factors. Multimodal discriminative factors are shared across all modalities and contain joint multimodal features required for discriminative tasks such as sentiment prediction. Modality-specific generative factors are unique for each modality and contain the information required for generating data. Experimental results show that our model is able to learn meaningful multimodal representations that achieve state-of-the-art or competitive performance on six multimodal datasets. Our model demonstrates flexible generative capabilities by conditioning on independent factors and can reconstruct missing modalities without significantly impacting performance. Lastly, we interpret our factorized representations to understand the interactions that influence multimodal learning.",
            "referenceCount": 81,
            "citationCount": 267,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-06-16",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1806.06176"
            },
            "citationStyles": {
                "bibtex": "@Article{Tsai2018LearningFM,\n author = {Yao-Hung Hubert Tsai and P. Liang and Amir Zadeh and Louis-Philippe Morency and R. Salakhutdinov},\n booktitle = {International Conference on Learning Representations},\n journal = {ArXiv},\n title = {Learning Factorized Multimodal Representations},\n volume = {abs/1806.06176},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eab5eaba0034a538394753edfa462a407102d1de",
            "@type": "ScholarlyArticle",
            "paperId": "eab5eaba0034a538394753edfa462a407102d1de",
            "corpusId": 158046789,
            "url": "https://www.semanticscholar.org/paper/eab5eaba0034a538394753edfa462a407102d1de",
            "title": "Texture Fields: Learning Texture Representations in Function Space",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2946540550",
                "DBLP": "conf/iccv/OechsleMNSG19",
                "ArXiv": "1905.07259",
                "DOI": "10.1109/ICCV.2019.00463",
                "CorpusId": 158046789
            },
            "abstract": "In recent years, substantial progress has been achieved in learning-based reconstruction of 3D objects. At the same time, generative models were proposed that can generate highly realistic images. However, despite this success in these closely related tasks, texture reconstruction of 3D objects has received little attention from the research community and state-of-the-art methods are either limited to comparably low resolution or constrained experimental setups. A major reason for these limitations is that common representations of texture are inefficient or hard to interface for modern deep learning techniques. In this paper, we propose Texture Fields, a novel texture representation which is based on regressing a continuous 3D function parameterized with a neural network. Our approach circumvents limiting factors like shape discretization and parameterization, as the proposed texture representation is independent of the shape representation of the 3D object. We show that Texture Fields are able to represent high frequency texture and naturally blend with modern deep learning techniques. Experimentally, we find that Texture Fields compare favorably to state-of-the-art methods for conditional texture reconstruction of 3D objects and enable learning of probabilistic generative models for texturing unseen 3D models. We believe that Texture Fields will become an important building block for the next generation of generative 3D models.",
            "referenceCount": 51,
            "citationCount": 228,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1905.07259",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-05-17",
            "journal": {
                "name": "2019 IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Oechsle2019TextureFL,\n author = {Michael Oechsle and L. Mescheder and Michael Niemeyer and Thilo Strauss and Andreas Geiger},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},\n pages = {4530-4539},\n title = {Texture Fields: Learning Texture Representations in Function Space},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5673b556a5179d3718bfd9b581877e447ec4e3ce",
            "@type": "ScholarlyArticle",
            "paperId": "5673b556a5179d3718bfd9b581877e447ec4e3ce",
            "corpusId": 142551609,
            "url": "https://www.semanticscholar.org/paper/5673b556a5179d3718bfd9b581877e447ec4e3ce",
            "title": "Unlocking the Hidden Value of Concepts: A Cognitive Approach to Business Model Innovation",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1552495738",
                "DOI": "10.1002/SEJ.1191",
                "CorpusId": 142551609
            },
            "abstract": "We advance a theory of how business models can be innovated proactively in the absence of exogenous changes, through processes of generative cognition. We contribute to the cognitive perspective in strategy by analyzing business models as schemas that organize managerial understandings about the design of firms' value-creating activities and exchanges and by theorizing how they can be innovated through processes for proactive schema change. Drawing on cognitive psychology research on two major cognitive processes through which individuals change their schema to cope with novelty, analogical reasoning and conceptual combination, we theorize firm-level strategic processes for designing innovative business models. Copyright \u00a9 2015 Strategic Management Society.",
            "referenceCount": 77,
            "citationCount": 401,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2015-03-01",
            "journal": {
                "name": "Strategic Entrepreneurship Journal",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Martins2015UnlockingTH,\n author = {L. Martins and V. Rindova and Bruce Greenbaum},\n journal = {Strategic Entrepreneurship Journal},\n pages = {99-117},\n title = {Unlocking the Hidden Value of Concepts: A Cognitive Approach to Business Model Innovation},\n volume = {9},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d598a92795437ebde8d03a50df5a8afe8f339746",
            "@type": "ScholarlyArticle",
            "paperId": "d598a92795437ebde8d03a50df5a8afe8f339746",
            "corpusId": 6511376,
            "url": "https://www.semanticscholar.org/paper/d598a92795437ebde8d03a50df5a8afe8f339746",
            "title": "Flowing waters or teeming crowds: Mental models of electricity",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1982,
            "externalIds": {
                "MAG": "1528369519",
                "DOI": "10.4324/9781315802725-10",
                "CorpusId": 6511376
            },
            "abstract": "Abstract : Analogical comparisons are commonly used in the discussion and teaching of scientific topics. This paper explores the conceptual role of analogy. We compare two position: (1) the generative analogy hypothesis, that analogies are an imported determinant of the way people think about a domain; (2) the surface terminology hypothesis, that analogies merely provide a convenient vocabulary for describing concepts in the domain. We present evidence from interviews and experimental studies in the domain of simple electronics that when using analogies, people map conceptual structures from one domain to another. This important conceptual structure is shown to influence inferences a person makes about the target domain. These results support the generative analogy hypothesis.",
            "referenceCount": 48,
            "citationCount": 883,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1982-05-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Gentner1982FlowingWO,\n author = {D. Gentner and D. Gentner},\n pages = {107-138},\n title = {Flowing waters or teeming crowds: Mental models of electricity},\n year = {1982}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cb8f1840a018fddcc7a453dd73cc082ebea82e7b",
            "@type": "ScholarlyArticle",
            "paperId": "cb8f1840a018fddcc7a453dd73cc082ebea82e7b",
            "corpusId": 334803,
            "url": "https://www.semanticscholar.org/paper/cb8f1840a018fddcc7a453dd73cc082ebea82e7b",
            "title": "Semi-Amortized Variational Autoencoders",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/icml/KimWMSR18",
                "ArXiv": "1802.02550",
                "MAG": "2952471899",
                "CorpusId": 334803
            },
            "abstract": "Amortized variational inference (AVI) replaces instance-specific local inference with a global inference network. While AVI has enabled efficient training of deep generative models such as variational autoencoders (VAE), recent empirical work suggests that inference networks can produce suboptimal variational parameters. We propose a hybrid approach, to use AVI to initialize the variational parameters and run stochastic variational inference (SVI) to refine them. Crucially, the local SVI procedure is itself differentiable, so the inference network and generative model can be trained end-to-end with gradient-based optimization. This semi-amortized approach enables the use of rich generative models without experiencing the posterior-collapse phenomenon common in training VAEs for problems like text generation. Experiments show this approach outperforms strong autoregressive and variational baselines on standard text and image datasets.",
            "referenceCount": 65,
            "citationCount": 207,
            "influentialCitationCount": 37,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-02-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kim2018SemiAmortizedVA,\n author = {Yoon Kim and Sam Wiseman and Andrew C. Miller and D. Sontag and Alexander M. Rush},\n booktitle = {International Conference on Machine Learning},\n pages = {2683-2692},\n title = {Semi-Amortized Variational Autoencoders},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:adfef97814b292a09520d8c78a141e7a4baf8726",
            "@type": "ScholarlyArticle",
            "paperId": "adfef97814b292a09520d8c78a141e7a4baf8726",
            "corpusId": 3262717,
            "url": "https://www.semanticscholar.org/paper/adfef97814b292a09520d8c78a141e7a4baf8726",
            "title": "Three New Probabilistic Models for Dependency Parsing: An Exploration",
            "venue": "International Conference on Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:f51ff783-cdff-4e22-94fb-28e6336d17b3",
                "name": "International Conference on Computational Linguistics",
                "alternate_names": [
                    "Int Conf Comput Linguistics",
                    "COLING"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/coling/"
            },
            "year": 1996,
            "externalIds": {
                "DBLP": "journals/corr/cmp-lg-9706003",
                "ACL": "C96-1058",
                "MAG": "2052449326",
                "ArXiv": "cmp-lg/9706003",
                "DOI": "10.3115/992628.992688",
                "CorpusId": 3262717
            },
            "abstract": "After presenting a novel O(n3) parsing algorithm for dependency grammar, we develop three contrasting ways to stochasticize it. We propose (a) a lexical affinity model where words struggle to modify each other, (b) a sense tagging model where words fluctuate randomly in their selectional preferences, and (c) a generative model where the speaker fleshes out each word's syntactic and conceptual structure without regard to the implications for the hearer. We also give preliminary empirical results from evaluating the three models' parsing performance on annotated Wall Street Journal training text (derived from the Penn Treebank). In these results, the generative model performs significantly better than the others, and does about equally well at assigning part-of-speech tags.",
            "referenceCount": 20,
            "citationCount": 729,
            "influentialCitationCount": 77,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=992688&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1996-08-05",
            "journal": {
                "name": "ArXiv",
                "volume": "cmp-lg/9706003"
            },
            "citationStyles": {
                "bibtex": "@Article{Eisner1996ThreeNP,\n author = {Jason Eisner},\n booktitle = {International Conference on Computational Linguistics},\n journal = {ArXiv},\n title = {Three New Probabilistic Models for Dependency Parsing: An Exploration},\n volume = {cmp-lg/9706003},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0875fc92cce33df5cf7df169590dbf0ca00d2652",
            "@type": "ScholarlyArticle",
            "paperId": "0875fc92cce33df5cf7df169590dbf0ca00d2652",
            "corpusId": 9996719,
            "url": "https://www.semanticscholar.org/paper/0875fc92cce33df5cf7df169590dbf0ca00d2652",
            "title": "Generating Images from Captions with Attention",
            "venue": "International Conference on Learning Representations",
            "publicationVenue": {
                "id": "urn:research:939c6e1d-0d17-4d6e-8a82-66d960df0e40",
                "name": "International Conference on Learning Representations",
                "alternate_names": [
                    "Int Conf Learn Represent",
                    "ICLR"
                ],
                "issn": null,
                "url": "https://iclr.cc/"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/corr/MansimovPBS15",
                "MAG": "2952033389",
                "ArXiv": "1511.02793",
                "CorpusId": 9996719
            },
            "abstract": "Motivated by the recent progress in generative models, we introduce a model that generates images from natural language descriptions. The proposed model iteratively draws patches on a canvas, while attending to the relevant words in the description. After training on Microsoft COCO, we compare our model with several baseline generative models on image generation and retrieval tasks. We demonstrate that our model produces higher quality samples than other approaches and generates images with novel scene compositions corresponding to previously unseen captions in the dataset.",
            "referenceCount": 31,
            "citationCount": 370,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-11-09",
            "journal": {
                "name": "CoRR",
                "volume": "abs/1511.02793"
            },
            "citationStyles": {
                "bibtex": "@Article{Mansimov2015GeneratingIF,\n author = {Elman Mansimov and Emilio Parisotto and Jimmy Ba and R. Salakhutdinov},\n booktitle = {International Conference on Learning Representations},\n journal = {CoRR},\n title = {Generating Images from Captions with Attention},\n volume = {abs/1511.02793},\n year = {2015}\n}\n"
            }
        }
    }
]