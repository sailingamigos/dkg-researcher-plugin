[
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01460v1",
            "title": "Implicit Chain of Thought Reasoning via Knowledge Distillation",
            "updated": "2023-11-02T17:59:49Z",
            "published": "2023-11-02T17:59:49Z",
            "summary": "To augment language models with the ability to reason, researchers usually\nprompt or finetune them to produce chain of thought reasoning steps before\nproducing the final answer. However, although people use natural language to\nreason effectively, it may be that LMs could reason more effectively with some\nintermediate computation that is not in natural language. In this work, we\nexplore an alternative reasoning approach: instead of explicitly producing the\nchain of thought reasoning steps, we use the language model's internal hidden\nstates to perform implicit reasoning. The implicit reasoning steps are\ndistilled from a teacher model trained on explicit chain-of-thought reasoning,\nand instead of doing reasoning \"horizontally\" by producing intermediate words\none-by-one, we distill it such that the reasoning happens \"vertically\" among\nthe hidden states in different layers. We conduct experiments on a multi-digit\nmultiplication task and a grade school math problem dataset and find that this\napproach enables solving tasks previously not solvable without explicit\nchain-of-thought, at a speed comparable to no chain-of-thought.",
            "author": [
                "Yuntian Deng",
                "Kiran Prasad",
                "Roland Fernandez",
                "Paul Smolensky",
                "Vishrav Chaudhary",
                "Stuart Shieber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01460v1",
                "http://arxiv.org/pdf/2311.01460v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01459v1",
            "title": "Align Your Prompts: Test-Time Prompting with Distribution Alignment for\n  Zero-Shot Generalization",
            "updated": "2023-11-02T17:59:32Z",
            "published": "2023-11-02T17:59:32Z",
            "summary": "The promising zero-shot generalization of vision-language models such as CLIP\nhas led to their adoption using prompt learning for numerous downstream tasks.\nPrevious works have shown test-time prompt tuning using entropy minimization to\nadapt text prompts for unseen domains. While effective, this overlooks the key\ncause for performance degradation to unseen domains -- distribution shift. In\nthis work, we explicitly handle this problem by aligning the\nout-of-distribution (OOD) test sample statistics to those of the source data\nusing prompt tuning. We use a single test sample to adapt multi-modal prompts\nat test time by minimizing the feature distribution shift to bridge the gap in\nthe test domain. Evaluating against the domain generalization benchmark, our\nmethod improves zero-shot top- 1 accuracy beyond existing prompt-learning\ntechniques, with a 3.08% improvement over the baseline MaPLe. In cross-dataset\ngeneralization with unseen categories across 10 datasets, our method improves\nconsistently across all datasets compared to the existing state-of-the-art. Our\nsource code and models are available at\nhttps://jameelhassan.github.io/promptalign.",
            "author": [
                "Jameel Hassan",
                "Hanan Gani",
                "Noor Hussein",
                "Muhammad Uzair Khattak",
                "Muzammal Naseer",
                "Fahad Shahbaz Khan",
                "Salman Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01459v1",
                "http://arxiv.org/pdf/2311.01459v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01458v1",
            "title": "Detecting Deepfakes Without Seeing Any",
            "updated": "2023-11-02T17:59:31Z",
            "published": "2023-11-02T17:59:31Z",
            "summary": "Deepfake attacks, malicious manipulation of media containing people, are a\nserious concern for society. Conventional deepfake detection methods train\nsupervised classifiers to distinguish real media from previously encountered\ndeepfakes. Such techniques can only detect deepfakes similar to those\npreviously seen, but not zero-day (previously unseen) attack types. As current\ndeepfake generation techniques are changing at a breathtaking pace, new attack\ntypes are proposed frequently, making this a major issue. Our main observations\nare that: i) in many effective deepfake attacks, the fake media must be\naccompanied by false facts i.e. claims about the identity, speech, motion, or\nappearance of the person. For instance, when impersonating Obama, the attacker\nexplicitly or implicitly claims that the fake media show Obama; ii) current\ngenerative techniques cannot perfectly synthesize the false facts claimed by\nthe attacker. We therefore introduce the concept of \"fact checking\", adapted\nfrom fake news detection, for detecting zero-day deepfake attacks. Fact\nchecking verifies that the claimed facts (e.g. identity is Obama), agree with\nthe observed media (e.g. is the face really Obama's?), and thus can\ndifferentiate between real and fake media. Consequently, we introduce FACTOR, a\npractical recipe for deepfake fact checking and demonstrate its power in\ncritical attack settings: face swapping and audio-visual synthesis. Although it\nis training-free, relies exclusively on off-the-shelf features, is very easy to\nimplement, and does not see any deepfakes, it achieves better than\nstate-of-the-art accuracy.",
            "author": [
                "Tal Reiss",
                "Bar Cavia",
                "Yedid Hoshen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01458v1",
                "http://arxiv.org/pdf/2311.01458v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01457v1",
            "title": "Conformal Policy Learning for Sensorimotor Control Under Distribution\n  Shifts",
            "updated": "2023-11-02T17:59:30Z",
            "published": "2023-11-02T17:59:30Z",
            "summary": "This paper focuses on the problem of detecting and reacting to changes in the\ndistribution of a sensorimotor controller's observables. The key idea is the\ndesign of switching policies that can take conformal quantiles as input, which\nwe define as conformal policy learning, that allows robots to detect\ndistribution shifts with formal statistical guarantees. We show how to design\nsuch policies by using conformal quantiles to switch between base policies with\ndifferent characteristics, e.g. safety or speed, or directly augmenting a\npolicy observation with a quantile and training it with reinforcement learning.\nTheoretically, we show that such policies achieve the formal convergence\nguarantees in finite time. In addition, we thoroughly evaluate their advantages\nand limitations on two compelling use cases: simulated autonomous driving and\nactive perception with a physical quadruped. Empirical results demonstrate that\nour approach outperforms five baselines. It is also the simplest of the\nbaseline strategies besides one ablation. Being easy to use, flexible, and with\nformal guarantees, our work demonstrates how conformal prediction can be an\neffective tool for sensorimotor learning under uncertainty.",
            "author": [
                "Huang Huang",
                "Satvik Sharma",
                "Antonio Loquercio",
                "Anastasios Angelopoulos",
                "Ken Goldberg",
                "Jitendra Malik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01457v1",
                "http://arxiv.org/pdf/2311.01457v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01455v2",
            "title": "RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning\n  via Generative Simulation",
            "updated": "2023-11-13T18:40:10Z",
            "published": "2023-11-02T17:59:21Z",
            "summary": "We present RoboGen, a generative robotic agent that automatically learns\ndiverse robotic skills at scale via generative simulation. RoboGen leverages\nthe latest advancements in foundation and generative models. Instead of\ndirectly using or adapting these models to produce policies or low-level\nactions, we advocate for a generative scheme, which uses these models to\nautomatically generate diversified tasks, scenes, and training supervisions,\nthereby scaling up robotic skill learning with minimal human supervision. Our\napproach equips a robotic agent with a self-guided propose-generate-learn\ncycle: the agent first proposes interesting tasks and skills to develop, and\nthen generates corresponding simulation environments by populating pertinent\nobjects and assets with proper spatial configurations. Afterwards, the agent\ndecomposes the proposed high-level task into sub-tasks, selects the optimal\nlearning approach (reinforcement learning, motion planning, or trajectory\noptimization), generates required training supervision, and then learns\npolicies to acquire the proposed skill. Our work attempts to extract the\nextensive and versatile knowledge embedded in large-scale models and transfer\nthem to the field of robotics. Our fully generative pipeline can be queried\nrepeatedly, producing an endless stream of skill demonstrations associated with\ndiverse tasks and environments.",
            "author": [
                "Yufei Wang",
                "Zhou Xian",
                "Feng Chen",
                "Tsun-Hsuan Wang",
                "Yian Wang",
                "Zackory Erickson",
                "David Held",
                "Chuang Gan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01455v2",
                "http://arxiv.org/pdf/2311.01455v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01454v1",
            "title": "NOIR: Neural Signal Operated Intelligent Robots for Everyday Activities",
            "updated": "2023-11-02T17:59:06Z",
            "published": "2023-11-02T17:59:06Z",
            "summary": "We present Neural Signal Operated Intelligent Robots (NOIR), a\ngeneral-purpose, intelligent brain-robot interface system that enables humans\nto command robots to perform everyday activities through brain signals. Through\nthis interface, humans communicate their intended objects of interest and\nactions to the robots using electroencephalography (EEG). Our novel system\ndemonstrates success in an expansive array of 20 challenging, everyday\nhousehold activities, including cooking, cleaning, personal care, and\nentertainment. The effectiveness of the system is improved by its synergistic\nintegration of robot learning algorithms, allowing for NOIR to adapt to\nindividual users and predict their intentions. Our work enhances the way humans\ninteract with robots, replacing traditional channels of interaction with\ndirect, neural communication. Project website: https://noir-corl.github.io/.",
            "author": [
                "Ruohan Zhang",
                "Sharon Lee",
                "Minjune Hwang",
                "Ayano Hiranaka",
                "Chen Wang",
                "Wensi Ai",
                "Jin Jie Ryan Tan",
                "Shreya Gupta",
                "Yilun Hao",
                "Gabrael Levine",
                "Ruohan Gao",
                "Anthony Norcia",
                "Li Fei-Fei",
                "Jiajun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01454v1",
                "http://arxiv.org/pdf/2311.01454v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01453v1",
            "title": "PPI++: Efficient Prediction-Powered Inference",
            "updated": "2023-11-02T17:59:04Z",
            "published": "2023-11-02T17:59:04Z",
            "summary": "We present PPI++: a computationally lightweight methodology for estimation\nand inference based on a small labeled dataset and a typically much larger\ndataset of machine-learning predictions. The methods automatically adapt to the\nquality of available predictions, yielding easy-to-compute confidence sets --\nfor parameters of any dimensionality -- that always improve on classical\nintervals using only the labeled data. PPI++ builds on prediction-powered\ninference (PPI), which targets the same problem setting, improving its\ncomputational and statistical efficiency. Real and synthetic experiments\ndemonstrate the benefits of the proposed adaptations.",
            "author": [
                "Anastasios N. Angelopoulos",
                "John C. Duchi",
                "Tijana Zrnic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01453v1",
                "http://arxiv.org/pdf/2311.01453v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01491v1",
            "title": "Investigating the Behavior of Diffusion Models for Accelerating\n  Electronic Structure Calculations",
            "updated": "2023-11-02T17:58:37Z",
            "published": "2023-11-02T17:58:37Z",
            "summary": "We present an investigation into diffusion models for molecular generation,\nwith the aim of better understanding how their predictions compare to the\nresults of physics-based calculations. The investigation into these models is\ndriven by their potential to significantly accelerate electronic structure\ncalculations using machine learning, without requiring expensive\nfirst-principles datasets for training interatomic potentials. We find that the\ninference process of a popular diffusion model for de novo molecular generation\nis divided into an exploration phase, where the model chooses the atomic\nspecies, and a relaxation phase, where it adjusts the atomic coordinates to\nfind a low-energy geometry. As training proceeds, we show that the model\ninitially learns about the first-order structure of the potential energy\nsurface, and then later learns about higher-order structure. We also find that\nthe relaxation phase of the diffusion model can be re-purposed to sample the\nBoltzmann distribution over conformations and to carry out structure\nrelaxations. For structure relaxations, the model finds geometries with ~10x\nlower energy than those produced by a classical force field for small organic\nmolecules. Initializing a density functional theory (DFT) relaxation at the\ndiffusion-produced structures yields a >2x speedup to the DFT relaxation when\ncompared to initializing at structures relaxed with a classical force field.",
            "author": [
                "Daniel Rothchild",
                "Andrew S. Rosen",
                "Eric Taw",
                "Connie Robinson",
                "Joseph E. Gonzalez",
                "Aditi S. Krishnapriyan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01491v1",
                "http://arxiv.org/pdf/2311.01491v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cond-mat.mtrl-sci",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01452v1",
            "title": "Time Series Anomaly Detection using Diffusion-based Models",
            "updated": "2023-11-02T17:58:09Z",
            "published": "2023-11-02T17:58:09Z",
            "summary": "Diffusion models have been recently used for anomaly detection (AD) in\nimages. In this paper we investigate whether they can also be leveraged for AD\non multivariate time series (MTS). We test two diffusion-based models and\ncompare them to several strong neural baselines. We also extend the PA%K\nprotocol, by computing a ROCK-AUC metric, which is agnostic to both the\ndetection threshold and the ratio K of correctly detected points. Our models\noutperform the baselines on synthetic datasets and are competitive on\nreal-world datasets, illustrating the potential of diffusion-based methods for\nAD in multivariate time series.",
            "author": [
                "Ioana Pintilie",
                "Andrei Manolache",
                "Florin Brad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01452v1",
                "http://arxiv.org/pdf/2311.01452v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01450v1",
            "title": "DreamSmooth: Improving Model-based Reinforcement Learning via Reward\n  Smoothing",
            "updated": "2023-11-02T17:57:38Z",
            "published": "2023-11-02T17:57:38Z",
            "summary": "Model-based reinforcement learning (MBRL) has gained much attention for its\nability to learn complex behaviors in a sample-efficient way: planning actions\nby generating imaginary trajectories with predicted rewards. Despite its\nsuccess, we found that surprisingly, reward prediction is often a bottleneck of\nMBRL, especially for sparse rewards that are challenging (or even ambiguous) to\npredict. Motivated by the intuition that humans can learn from rough reward\nestimates, we propose a simple yet effective reward smoothing approach,\nDreamSmooth, which learns to predict a temporally-smoothed reward, instead of\nthe exact reward at the given timestep. We empirically show that DreamSmooth\nachieves state-of-the-art performance on long-horizon sparse-reward tasks both\nin sample efficiency and final performance without losing performance on common\nbenchmarks, such as Deepmind Control Suite and Atari benchmarks.",
            "author": [
                "Vint Lee",
                "Pieter Abbeel",
                "Youngwoon Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01450v1",
                "http://arxiv.org/pdf/2311.01450v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01448v1",
            "title": "UltraLiDAR: Learning Compact Representations for LiDAR Completion and\n  Generation",
            "updated": "2023-11-02T17:57:03Z",
            "published": "2023-11-02T17:57:03Z",
            "summary": "LiDAR provides accurate geometric measurements of the 3D world.\nUnfortunately, dense LiDARs are very expensive and the point clouds captured by\nlow-beam LiDAR are often sparse. To address these issues, we present\nUltraLiDAR, a data-driven framework for scene-level LiDAR completion, LiDAR\ngeneration, and LiDAR manipulation. The crux of UltraLiDAR is a compact,\ndiscrete representation that encodes the point cloud's geometric structure, is\nrobust to noise, and is easy to manipulate. We show that by aligning the\nrepresentation of a sparse point cloud to that of a dense point cloud, we can\ndensify the sparse point clouds as if they were captured by a real high-density\nLiDAR, drastically reducing the cost. Furthermore, by learning a prior over the\ndiscrete codebook, we can generate diverse, realistic LiDAR point clouds for\nself-driving. We evaluate the effectiveness of UltraLiDAR on sparse-to-dense\nLiDAR completion and LiDAR generation. Experiments show that densifying\nreal-world point clouds with our approach can significantly improve the\nperformance of downstream perception systems. Compared to prior art on LiDAR\ngeneration, our approach generates much more realistic point clouds. According\nto A/B test, over 98.5\\% of the time human participants prefer our results over\nthose of previous methods.",
            "author": [
                "Yuwen Xiong",
                "Wei-Chiu Ma",
                "Jingkang Wang",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01448v1",
                "http://arxiv.org/pdf/2311.01448v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01447v1",
            "title": "CADSim: Robust and Scalable in-the-wild 3D Reconstruction for\n  Controllable Sensor Simulation",
            "updated": "2023-11-02T17:56:59Z",
            "published": "2023-11-02T17:56:59Z",
            "summary": "Realistic simulation is key to enabling safe and scalable development of %\nself-driving vehicles. A core component is simulating the sensors so that the\nentire autonomy system can be tested in simulation. Sensor simulation involves\nmodeling traffic participants, such as vehicles, with high quality appearance\nand articulated geometry, and rendering them in real time. The self-driving\nindustry has typically employed artists to build these assets. However, this is\nexpensive, slow, and may not reflect reality. Instead, reconstructing assets\nautomatically from sensor data collected in the wild would provide a better\npath to generating a diverse and large set with good real-world coverage.\nNevertheless, current reconstruction approaches struggle on in-the-wild sensor\ndata, due to its sparsity and noise. To tackle these issues, we present CADSim,\nwhich combines part-aware object-class priors via a small set of CAD models\nwith differentiable rendering to automatically reconstruct vehicle geometry,\nincluding articulated wheels, with high-quality appearance. Our experiments\nshow our method recovers more accurate shapes from sparse data compared to\nexisting approaches. Importantly, it also trains and renders efficiently. We\ndemonstrate our reconstructed vehicles in several applications, including\naccurate testing of autonomy perception systems.",
            "author": [
                "Jingkang Wang",
                "Sivabalan Manivasagam",
                "Yun Chen",
                "Ze Yang",
                "Ioan Andrei B\u00e2rsan",
                "Anqi Joyce Yang",
                "Wei-Chiu Ma",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01447v1",
                "http://arxiv.org/pdf/2311.01447v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01446v1",
            "title": "Adv3D: Generating Safety-Critical 3D Objects through Closed-Loop\n  Simulation",
            "updated": "2023-11-02T17:56:44Z",
            "published": "2023-11-02T17:56:44Z",
            "summary": "Self-driving vehicles (SDVs) must be rigorously tested on a wide range of\nscenarios to ensure safe deployment. The industry typically relies on\nclosed-loop simulation to evaluate how the SDV interacts on a corpus of\nsynthetic and real scenarios and verify it performs properly. However, they\nprimarily only test the system's motion planning module, and only consider\nbehavior variations. It is key to evaluate the full autonomy system in\nclosed-loop, and to understand how variations in sensor data based on scene\nappearance, such as the shape of actors, affect system performance. In this\npaper, we propose a framework, Adv3D, that takes real world scenarios and\nperforms closed-loop sensor simulation to evaluate autonomy performance, and\nfinds vehicle shapes that make the scenario more challenging, resulting in\nautonomy failures and uncomfortable SDV maneuvers. Unlike prior works that add\ncontrived adversarial shapes to vehicle roof-tops or roadside to harm\nperception only, we optimize a low-dimensional shape representation to modify\nthe vehicle shape itself in a realistic manner to degrade autonomy performance\n(e.g., perception, prediction, and motion planning). Moreover, we find that the\nshape variations found with Adv3D optimized in closed-loop are much more\neffective than those in open-loop, demonstrating the importance of finding\nscene appearance variations that affect autonomy in the interactive setting.",
            "author": [
                "Jay Sarva",
                "Jingkang Wang",
                "James Tu",
                "Yuwen Xiong",
                "Sivabalan Manivasagam",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01446v1",
                "http://arxiv.org/pdf/2311.01446v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01444v1",
            "title": "LabelFormer: Object Trajectory Refinement for Offboard Perception from\n  LiDAR Point Clouds",
            "updated": "2023-11-02T17:56:06Z",
            "published": "2023-11-02T17:56:06Z",
            "summary": "A major bottleneck to scaling-up training of self-driving perception systems\nare the human annotations required for supervision. A promising alternative is\nto leverage \"auto-labelling\" offboard perception models that are trained to\nautomatically generate annotations from raw LiDAR point clouds at a fraction of\nthe cost. Auto-labels are most commonly generated via a two-stage approach --\nfirst objects are detected and tracked over time, and then each object\ntrajectory is passed to a learned refinement model to improve accuracy. Since\nexisting refinement models are overly complex and lack advanced temporal\nreasoning capabilities, in this work we propose LabelFormer, a simple,\nefficient, and effective trajectory-level refinement approach. Our approach\nfirst encodes each frame's observations separately, then exploits\nself-attention to reason about the trajectory with full temporal context, and\nfinally decodes the refined object size and per-frame poses. Evaluation on both\nurban and highway datasets demonstrates that LabelFormer outperforms existing\nworks by a large margin. Finally, we show that training on a dataset augmented\nwith auto-labels generated by our method leads to improved downstream detection\nperformance compared to existing methods. Please visit the project website for\ndetails https://waabi.ai/labelformer",
            "author": [
                "Anqi Joyce Yang",
                "Sergio Casas",
                "Nikita Dvornik",
                "Sean Segal",
                "Yuwen Xiong",
                "Jordan Sir Kwang Hu",
                "Carter Fang",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01444v1",
                "http://arxiv.org/pdf/2311.01444v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01442v3",
            "title": "Deep Double Descent for Time Series Forecasting: Avoiding Undertrained\n  Models",
            "updated": "2023-11-30T06:51:26Z",
            "published": "2023-11-02T17:55:41Z",
            "summary": "Deep learning models, particularly Transformers, have achieved impressive\nresults in various domains, including time series forecasting. While existing\ntime series literature primarily focuses on model architecture modifications\nand data augmentation techniques, this paper explores the training schema of\ndeep learning models for time series; how models are trained regardless of\ntheir architecture. We perform extensive experiments to investigate the\noccurrence of deep double descent in several Transformer models trained on\npublic time series data sets. We demonstrate epoch-wise deep double descent and\nthat overfitting can be reverted using more epochs. Leveraging these findings,\nwe achieve state-of-the-art results for long sequence time series forecasting\nin nearly 70% of the 72 benchmarks tested. This suggests that many models in\nthe literature may possess untapped potential. Additionally, we introduce a\ntaxonomy for classifying training schema modifications, covering data\naugmentation, model inputs, model targets, time series per model, and\ncomputational budget.",
            "author": [
                "Valentino Assandri",
                "Sam Heshmati",
                "Burhaneddin Yaman",
                "Anton Iakovlev",
                "Ariel Emiliano Repetur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01442v3",
                "http://arxiv.org/pdf/2311.01442v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01443v1",
            "title": "Filaments of The Slime Mold Cosmic Web And How They Affect Galaxy\n  Evolution",
            "updated": "2023-11-02T17:55:41Z",
            "published": "2023-11-02T17:55:41Z",
            "summary": "We present a novel method for identifying cosmic web filaments using the\nIllustrisTNG (TNG100) cosmological simulations and investigate the impact of\nfilaments on galaxies. We compare the use of cosmic density field estimates\nfrom the Delaunay Tessellation Field Estimator (DTFE) and the Monte Carlo\nPhysarum Machine (MCPM), which is inspired by the slime mold organism, in the\nDisPerSE structure identification framework. The MCPM-based reconstruction\nidentifies filaments with higher fidelity, finding more low-prominence/diffuse\nfilaments and better tracing the true underlying matter distribution than the\nDTFE-based reconstruction. Using our new filament catalogs, we find that most\ngalaxies are located within 1.5-2.5 Mpc of a filamentary spine, with little\nchange in the median specific star formation rate and the median galactic gas\nfraction with distance to the nearest filament. Instead, we introduce the\nfilament line density, {\\Sigma}fil(MCPM), as the total MCPM overdensity per\nunit length of a local filament segment, and find that this parameter is a\nsuperior predictor of galactic gas supply and quenching. Our results indicate\nthat most galaxies are quenched and gas-poor near high-line density filaments\nat z<=1. At z=0, quenching in log(M*/Msun)>10.5 galaxies is mainly driven by\nmass, while lower-mass galaxies are significantly affected by the filament line\ndensity. In high-line density filaments, satellites are strongly quenched,\nwhereas centrals have reduced star formation, but not gas fraction, at z<=0.5.\nWe discuss the prospect of applying our new filament identification method to\ngalaxy surveys with SDSS, DESI, Subaru PFS, etc. to elucidate the effect of\nlarge-scale structure on galaxy formation.",
            "author": [
                "Farhanul Hasan",
                "Joseph N. Burchett",
                "Douglas Hellinger",
                "Oskar Elek",
                "Daisuke Nagai",
                "S. M. Faber",
                "Joel R. Primack",
                "David C. Koo",
                "Nir Mandelker",
                "Joanna Woo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01443v1",
                "http://arxiv.org/pdf/2311.01443v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01441v1",
            "title": "Distilling Out-of-Distribution Robustness from Vision-Language\n  Foundation Models",
            "updated": "2023-11-02T17:55:13Z",
            "published": "2023-11-02T17:55:13Z",
            "summary": "We propose a conceptually simple and lightweight framework for improving the\nrobustness of vision models through the combination of knowledge distillation\nand data augmentation. We address the conjecture that larger models do not make\nfor better teachers by showing strong gains in out-of-distribution robustness\nwhen distilling from pretrained foundation models. Following this finding, we\npropose Discrete Adversarial Distillation (DAD), which leverages a robust\nteacher to generate adversarial examples and a VQGAN to discretize them,\ncreating more informative samples than standard data augmentation techniques.\nWe provide a theoretical framework for the use of a robust teacher in the\nknowledge distillation with data augmentation setting and demonstrate strong\ngains in out-of-distribution robustness and clean accuracy across different\nstudent architectures. Notably, our method adds minor computational overhead\ncompared to similar techniques and can be easily combined with other data\naugmentations for further improvements.",
            "author": [
                "Andy Zhou",
                "Jindong Wang",
                "Yu-Xiong Wang",
                "Haohan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01441v1",
                "http://arxiv.org/pdf/2311.01441v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01435v1",
            "title": "Contrastive Moments: Unsupervised Halfspace Learning in Polynomial Time",
            "updated": "2023-11-02T17:51:10Z",
            "published": "2023-11-02T17:51:10Z",
            "summary": "We give a polynomial-time algorithm for learning high-dimensional halfspaces\nwith margins in $d$-dimensional space to within desired TV distance when the\nambient distribution is an unknown affine transformation of the $d$-fold\nproduct of an (unknown) symmetric one-dimensional logconcave distribution, and\nthe halfspace is introduced by deleting at least an $\\epsilon$ fraction of the\ndata in one of the component distributions. Notably, our algorithm does not\nneed labels and establishes the unique (and efficient) identifiability of the\nhidden halfspace under this distributional assumption. The sample and time\ncomplexity of the algorithm are polynomial in the dimension and $1/\\epsilon$.\nThe algorithm uses only the first two moments of suitable re-weightings of the\nempirical distribution, which we call contrastive moments; its analysis uses\nclassical facts about generalized Dirichlet polynomials and relies crucially on\na new monotonicity property of the moment ratio of truncations of logconcave\ndistributions. Such algorithms, based only on first and second moments were\nsuggested in earlier work, but hitherto eluded rigorous guarantees.\n  Prior work addressed the special case when the underlying distribution is\nGaussian via Non-Gaussian Component Analysis. We improve on this by providing\npolytime guarantees based on Total Variation (TV) distance, in place of\nexisting moment-bound guarantees that can be super-polynomial. Our work is also\nthe first to go beyond Gaussians in this setting.",
            "author": [
                "Xinyuan Cao",
                "Santosh S. Vempala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01435v1",
                "http://arxiv.org/pdf/2311.01435v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.PR",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01434v1",
            "title": "Tailoring Mixup to Data using Kernel Warping functions",
            "updated": "2023-11-02T17:48:28Z",
            "published": "2023-11-02T17:48:28Z",
            "summary": "Data augmentation is an essential building block for learning efficient deep\nlearning models. Among all augmentation techniques proposed so far, linear\ninterpolation of training data points, also called mixup, has found to be\neffective for a large panel of applications. While the majority of works have\nfocused on selecting the right points to mix, or applying complex non-linear\ninterpolation, we are interested in mixing similar points more frequently and\nstrongly than less similar ones. To this end, we propose to dynamically change\nthe underlying distribution of interpolation coefficients through warping\nfunctions, depending on the similarity between data points to combine. We\ndefine an efficient and flexible framework to do so without losing in\ndiversity. We provide extensive experiments for classification and regression\ntasks, showing that our proposed method improves both performance and\ncalibration of models. Code available in\nhttps://github.com/ENSTA-U2IS/torch-uncertainty",
            "author": [
                "Quentin Bouniot",
                "Pavlo Mozharovskyi",
                "Florence d'Alch\u00e9-Buc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01434v1",
                "http://arxiv.org/pdf/2311.01434v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01428v1",
            "title": "Identifying Alzheimer Disease Dementia Levels Using Machine Learning\n  Methods",
            "updated": "2023-11-02T17:44:28Z",
            "published": "2023-11-02T17:44:28Z",
            "summary": "Dementia, a prevalent neurodegenerative condition, is a major manifestation\nof Alzheimer's disease (AD). As the condition progresses from mild to severe,\nit significantly impairs the individual's ability to perform daily tasks\nindependently, necessitating the need for timely and accurate AD\nclassification. Machine learning or deep learning models have emerged as\neffective tools for this purpose. In this study, we suggested an approach for\nclassifying the four stages of dementia using RF, SVM, and CNN algorithms,\naugmented with watershed segmentation for feature extraction from MRI images.\nOur results reveal that SVM with watershed features achieves an impressive\naccuracy of 96.25%, surpassing other classification methods. The ADNI dataset\nis utilized to evaluate the effectiveness of our method, and we observed that\nthe inclusion of watershed segmentation contributes to the enhanced performance\nof the models.",
            "author": [
                "Md Gulzar Hussain",
                "Ye Shiren"
            ],
            "link": [
                "http://dx.doi.org/10.18103/mra.v11i7.1.4039",
                "http://arxiv.org/abs/2311.01428v1",
                "http://arxiv.org/pdf/2311.01428v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01425v1",
            "title": "Exploring Deep Learning Techniques for Glaucoma Detection: A\n  Comprehensive Review",
            "updated": "2023-11-02T17:39:40Z",
            "published": "2023-11-02T17:39:40Z",
            "summary": "Glaucoma is one of the primary causes of vision loss around the world,\nnecessitating accurate and efficient detection methods. Traditional manual\ndetection approaches have limitations in terms of cost, time, and subjectivity.\nRecent developments in deep learning approaches demonstrate potential in\nautomating glaucoma detection by detecting relevant features from retinal\nfundus images. This article provides a comprehensive overview of cutting-edge\ndeep learning methods used for the segmentation, classification, and detection\nof glaucoma. By analyzing recent studies, the effectiveness and limitations of\nthese techniques are evaluated, key findings are highlighted, and potential\nareas for further research are identified. The use of deep learning algorithms\nmay significantly improve the efficacy, usefulness, and accuracy of glaucoma\ndetection. The findings from this research contribute to the ongoing\nadvancements in automated glaucoma detection and have implications for\nimproving patient outcomes and reducing the global burden of glaucoma.",
            "author": [
                "Aized Amin Soofi",
                "Fazal-e-Amin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01425v1",
                "http://arxiv.org/pdf/2311.01425v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01423v2",
            "title": "CenterRadarNet: Joint 3D Object Detection and Tracking Framework using\n  4D FMCW Radar",
            "updated": "2023-11-04T21:30:42Z",
            "published": "2023-11-02T17:36:40Z",
            "summary": "Robust perception is a vital component for ensuring safe autonomous and\nassisted driving. Automotive radar (77 to 81 GHz), which offers\nweather-resilient sensing, provides a complementary capability to the vision-\nor LiDAR-based autonomous driving systems. Raw radio-frequency (RF) radar\ntensors contain rich spatiotemporal semantics besides 3D location information.\nThe majority of previous methods take in 3D (Doppler-range-azimuth) RF radar\ntensors, allowing prediction of an object's location, heading angle, and size\nin bird's-eye-view (BEV). However, they lack the ability to at the same time\ninfer objects' size, orientation, and identity in the 3D space. To overcome\nthis limitation, we propose an efficient joint architecture called\nCenterRadarNet, designed to facilitate high-resolution representation learning\nfrom 4D (Doppler-range-azimuth-elevation) radar data for 3D object detection\nand re-identification (re-ID) tasks. As a single-stage 3D object detector,\nCenterRadarNet directly infers the BEV object distribution confidence maps,\ncorresponding 3D bounding box attributes, and appearance embedding for each\npixel. Moreover, we build an online tracker utilizing the learned appearance\nembedding for re-ID. CenterRadarNet achieves the state-of-the-art result on the\nK-Radar 3D object detection benchmark. In addition, we present the first 3D\nobject-tracking result using radar on the K-Radar dataset V2. In diverse\ndriving scenarios, CenterRadarNet shows consistent, robust performance,\nemphasizing its wide applicability.",
            "author": [
                "Jen-Hao Cheng",
                "Sheng-Yao Kuan",
                "Hugo Latapie",
                "Gaowen Liu",
                "Jenq-Neng Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01423v2",
                "http://arxiv.org/pdf/2311.01423v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01420v1",
            "title": "Holistic Transfer: Towards Non-Disruptive Fine-Tuning with Partial\n  Target Data",
            "updated": "2023-11-02T17:35:16Z",
            "published": "2023-11-02T17:35:16Z",
            "summary": "We propose a learning problem involving adapting a pre-trained source model\nto the target domain for classifying all classes that appeared in the source\ndata, using target data that covers only a partial label space. This problem is\npractical, as it is unrealistic for the target end-users to collect data for\nall classes prior to adaptation. However, it has received limited attention in\nthe literature. To shed light on this issue, we construct benchmark datasets\nand conduct extensive experiments to uncover the inherent challenges. We found\na dilemma -- on the one hand, adapting to the new target domain is important to\nclaim better performance; on the other hand, we observe that preserving the\nclassification accuracy of classes missing in the target adaptation data is\nhighly challenging, let alone improving them. To tackle this, we identify two\nkey directions: 1) disentangling domain gradients from classification\ngradients, and 2) preserving class relationships. We present several effective\nsolutions that maintain the accuracy of the missing classes and enhance the\noverall performance, establishing solid baselines for holistic transfer of\npre-trained models with partial target data.",
            "author": [
                "Cheng-Hao Tu",
                "Hong-You Chen",
                "Zheda Mai",
                "Jike Zhong",
                "Vardaan Pahuja",
                "Tanya Berger-Wolf",
                "Song Gao",
                "Charles Stewart",
                "Yu Su",
                "Wei-Lun Chao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01420v1",
                "http://arxiv.org/pdf/2311.01420v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01419v1",
            "title": "Constrained-Context Conditional Diffusion Models for Imitation Learning",
            "updated": "2023-11-02T17:33:47Z",
            "published": "2023-11-02T17:33:47Z",
            "summary": "Offline Imitation Learning (IL) is a powerful paradigm to learn visuomotor\nskills, especially for high-precision manipulation tasks. However, IL methods\nare prone to spurious correlation - expressive models may focus on distractors\nthat are irrelevant to action prediction - and are thus fragile in real-world\ndeployment. Prior methods have addressed this challenge by exploring different\nmodel architectures and action representations. However, none were able to\nbalance between sample efficiency, robustness against distractors, and solving\nhigh-precision manipulation tasks with complex action space. To this end, we\npresent $\\textbf{C}$onstrained-$\\textbf{C}$ontext $\\textbf{C}$onditional\n$\\textbf{D}$iffusion $\\textbf{M}$odel (C3DM), a diffusion model policy for\nsolving 6-DoF robotic manipulation tasks with high precision and ability to\nignore distractions. A key component of C3DM is a fixation step that helps the\naction denoiser to focus on task-relevant regions around the predicted action\nwhile ignoring distractors in the context. We empirically show that C3DM is\nable to consistently achieve high success rate on a wide array of tasks,\nranging from table top manipulation to industrial kitting, that require varying\nlevels of precision and robustness to distractors. For details, please visit\nthis https://sites.google.com/view/c3dm-imitation-learning",
            "author": [
                "Vaibhav Saxena",
                "Yotto Koga",
                "Danfei Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01419v1",
                "http://arxiv.org/pdf/2311.01419v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01414v3",
            "title": "A Dynamic Temporal Logic for Quality of Service in Choreographic Models",
            "updated": "2023-11-06T16:54:34Z",
            "published": "2023-11-02T17:30:51Z",
            "summary": "We propose a framework for expressing and analyzing the Quality of Service\n(QoS) of message-passing systems using a choreographic model that consists of\ng-choreographies and Communicating Finite State machines (CFSMs). The following\nare our three main contributions: (I) an extension of CFSMs with non-functional\ncontracts to specify quantitative constraints of local computations, (II) a\ndynamic temporal logic capable of expressing QoS, properties of systems\nrelative to the g-choreography that specifies the communication protocol, (III)\nthe semi-decidability of our logic which enables a bounded model-checking\napproach to verify QoS property of communicating systems.",
            "author": [
                "Carlos G. Lopez Pombo",
                "Agust\u00edn E. Martinez Su\u00f1\u00e9",
                "Emilio Tuosto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01414v3",
                "http://arxiv.org/pdf/2311.01414v3"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "68U07",
                "D.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01412v1",
            "title": "Castor: Causal Temporal Regime Structure Learning",
            "updated": "2023-11-02T17:26:49Z",
            "published": "2023-11-02T17:26:49Z",
            "summary": "The task of uncovering causal relationships among multivariate time series\ndata stands as an essential and challenging objective that cuts across a broad\narray of disciplines ranging from climate science to healthcare. Such data\nentails linear or non-linear relationships, and usually follow multiple a\npriori unknown regimes. Existing causal discovery methods can infer summary\ncausal graphs from heterogeneous data with known regimes, but they fall short\nin comprehensively learning both regimes and the corresponding causal graph. In\nthis paper, we introduce CASTOR, a novel framework designed to learn causal\nrelationships in heterogeneous time series data composed of various regimes,\neach governed by a distinct causal graph. Through the maximization of a score\nfunction via the EM algorithm, CASTOR infers the number of regimes and learns\nlinear or non-linear causal relationships in each regime. We demonstrate the\nrobust convergence properties of CASTOR, specifically highlighting its\nproficiency in accurately identifying unique regimes. Empirical evidence,\ngarnered from exhaustive synthetic experiments and two real-world benchmarks,\nconfirm CASTOR's superior performance in causal discovery compared to baseline\nmethods. By learning a full temporal causal graph for each regime, CASTOR\nestablishes itself as a distinctly interpretable method for causal discovery in\nheterogeneous time series.",
            "author": [
                "Abdellah Rahmani",
                "Pascal Frossard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01412v1",
                "http://arxiv.org/pdf/2311.01412v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01410v1",
            "title": "The Blessing of Randomness: SDE Beats ODE in General Diffusion-based\n  Image Editing",
            "updated": "2023-11-02T17:23:14Z",
            "published": "2023-11-02T17:23:14Z",
            "summary": "We present a unified probabilistic formulation for diffusion-based image\nediting, where a latent variable is edited in a task-specific manner and\ngenerally deviates from the corresponding marginal distribution induced by the\noriginal stochastic or ordinary differential equation (SDE or ODE). Instead, it\ndefines a corresponding SDE or ODE for editing. In the formulation, we prove\nthat the Kullback-Leibler divergence between the marginal distributions of the\ntwo SDEs gradually decreases while that for the ODEs remains as the time\napproaches zero, which shows the promise of SDE in image editing. Inspired by\nit, we provide the SDE counterparts for widely used ODE baselines in various\ntasks including inpainting and image-to-image translation, where SDE shows a\nconsistent and substantial improvement. Moreover, we propose SDE-Drag -- a\nsimple yet effective method built upon the SDE formulation for point-based\ncontent dragging. We build a challenging benchmark (termed DragBench) with\nopen-set natural, art, and AI-generated images for evaluation. A user study on\nDragBench indicates that SDE-Drag significantly outperforms our ODE baseline,\nexisting diffusion-based methods, and the renowned DragGAN. Our results\ndemonstrate the superiority and versatility of SDE in image editing and push\nthe boundary of diffusion-based editing methods.",
            "author": [
                "Shen Nie",
                "Hanzhong Allan Guo",
                "Cheng Lu",
                "Yuhao Zhou",
                "Chenyu Zheng",
                "Chongxuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01410v1",
                "http://arxiv.org/pdf/2311.01410v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01409v1",
            "title": "A Coreset-based, Tempered Variational Posterior for Accurate and\n  Scalable Stochastic Gaussian Process Inference",
            "updated": "2023-11-02T17:22:22Z",
            "published": "2023-11-02T17:22:22Z",
            "summary": "We present a novel stochastic variational Gaussian process ($\\mathcal{GP}$)\ninference method, based on a posterior over a learnable set of weighted pseudo\ninput-output points (coresets). Instead of a free-form variational family, the\nproposed coreset-based, variational tempered family for $\\mathcal{GP}$s (CVTGP)\nis defined in terms of the $\\mathcal{GP}$ prior and the data-likelihood; hence,\naccommodating the modeling inductive biases. We derive CVTGP's lower bound for\nthe log-marginal likelihood via marginalization of the proposed posterior over\nlatent $\\mathcal{GP}$ coreset variables, and show it is amenable to stochastic\noptimization. CVTGP reduces the learnable parameter size to $\\mathcal{O}(M)$,\nenjoys numerical stability, and maintains $\\mathcal{O}(M^3)$ time- and\n$\\mathcal{O}(M^2)$ space-complexity, by leveraging a coreset-based tempered\nposterior that, in turn, provides sparse and explainable representations of the\ndata. Results on simulated and real-world regression problems with Gaussian\nobservation noise validate that CVTGP provides better evidence lower-bound\nestimates and predictive root mean squared error than alternative stochastic\n$\\mathcal{GP}$ inference methods.",
            "author": [
                "Mert Ketenci",
                "Adler Perotte",
                "No\u00e9mie Elhadad",
                "I\u00f1igo Urteaga"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01409v1",
                "http://arxiv.org/pdf/2311.01409v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01406v1",
            "title": "Analysis of Information Propagation in Ethereum Network Using Combined\n  Graph Attention Network and Reinforcement Learning to Optimize Network\n  Efficiency and Scalability",
            "updated": "2023-11-02T17:19:45Z",
            "published": "2023-11-02T17:19:45Z",
            "summary": "Blockchain technology has revolutionized the way information is propagated in\ndecentralized networks. Ethereum plays a pivotal role in facilitating smart\ncontracts and decentralized applications. Understanding information propagation\ndynamics in Ethereum is crucial for ensuring network efficiency, security, and\nscalability. In this study, we propose an innovative approach that utilizes\nGraph Convolutional Networks (GCNs) to analyze the information propagation\npatterns in the Ethereum network. The first phase of our research involves data\ncollection from the Ethereum blockchain, consisting of blocks, transactions,\nand node degrees. We construct a transaction graph representation using\nadjacency matrices to capture the node embeddings; while our major contribution\nis to develop a combined Graph Attention Network (GAT) and Reinforcement\nLearning (RL) model to optimize the network efficiency and scalability. It\nlearns the best actions to take in various network states, ultimately leading\nto improved network efficiency, throughput, and optimize gas limits for block\nprocessing. In the experimental evaluation, we analyze the performance of our\nmodel on a large-scale Ethereum dataset. We investigate effectively aggregating\ninformation from neighboring nodes capturing graph structure and updating node\nembeddings using GCN with the objective of transaction pattern prediction,\naccounting for varying network loads and number of blocks. Not only we design a\ngas limit optimization model and provide the algorithm, but also to address\nscalability, we demonstrate the use and implementation of sparse matrices in\nGraphConv, GraphSAGE, and GAT. The results indicate that our designed GAT-RL\nmodel achieves superior results compared to other GCN models in terms of\nperformance. It effectively propagates information across the network,\noptimizing gas limits for block processing and improving network efficiency.",
            "author": [
                "Stefan Kambiz Behfar",
                "Jon Crowcroft"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01406v1",
                "http://arxiv.org/pdf/2311.01406v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01405v1",
            "title": "Learning to See Physical Properties with Active Sensing Motor Policies",
            "updated": "2023-11-02T17:19:18Z",
            "published": "2023-11-02T17:19:18Z",
            "summary": "Knowledge of terrain's physical properties inferred from color images can aid\nin making efficient robotic locomotion plans. However, unlike image\nclassification, it is unintuitive for humans to label image patches with\nphysical properties. Without labeled data, building a vision system that takes\nas input the observed terrain and predicts physical properties remains\nchallenging. We present a method that overcomes this challenge by\nself-supervised labeling of images captured by robots during real-world\ntraversal with physical property estimators trained in simulation. To ensure\naccurate labeling, we introduce Active Sensing Motor Policies (ASMP), which are\ntrained to explore locomotion behaviors that increase the accuracy of\nestimating physical parameters. For instance, the quadruped robot learns to\nswipe its foot against the ground to estimate the friction coefficient\naccurately. We show that the visual system trained with a small amount of\nreal-world traversal data accurately predicts physical parameters. The trained\nsystem is robust and works even with overhead images captured by a drone\ndespite being trained on data collected by cameras attached to a quadruped\nrobot walking on the ground.",
            "author": [
                "Gabriel B. Margolis",
                "Xiang Fu",
                "Yandong Ji",
                "Pulkit Agrawal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01405v1",
                "http://arxiv.org/pdf/2311.01405v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01404v2",
            "title": "Normalizing flows as approximations of optimal transport maps via\n  linear-control neural ODEs",
            "updated": "2023-11-17T11:06:52Z",
            "published": "2023-11-02T17:17:03Z",
            "summary": "The term \"Normalizing Flows\" is related to the task of constructing\ninvertible transport maps between probability measures by means of deep neural\nnetworks. In this paper, we consider the problem of recovering the\n$W_2$-optimal transport map $T$ between absolutely continuous measures\n$\\mu,\\nu\\in\\mathcal{P}(\\mathbb{R}^n)$ as the flow of a linear-control neural\nODE. We first show that, under suitable assumptions on $\\mu,\\nu$ and on the\ncontrolled vector fields, the optimal transport map is contained in the\n$C^0_c$-closure of the flows generated by the system. Assuming that discrete\napproximations $\\mu_N,\\nu_N$ of the original measures $\\mu,\\nu$ are available,\nwe use a discrete optimal coupling $\\gamma_N$ to define an optimal control\nproblem. With a $\\Gamma$-convergence argument, we prove that its solutions\ncorrespond to flows that approximate the optimal transport map $T$. Finally,\ntaking advantage of the Pontryagin Maximum Principle, we propose an iterative\nnumerical scheme for the resolution of the optimal control problem, resulting\nin an algorithm for the practical computation of the approximated optimal\ntransport map.",
            "author": [
                "Alessandro Scagliotti",
                "Sara Farinelli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01404v2",
                "http://arxiv.org/pdf/2311.01404v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "34H05, 49Q22, 49J45, 49M05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01401v1",
            "title": "Machine Learning Design of Perovskite Catalytic Properties",
            "updated": "2023-11-02T17:15:29Z",
            "published": "2023-11-02T17:15:29Z",
            "summary": "Discovering new materials that efficiently catalyze the oxygen reduction and\nevolution reactions is critical for facilitating the widespread adoption of\nsolid oxide fuel cell and electrolyzer (SOFC/SOEC) technologies. Here, we\ndevelop machine learning (ML) models to predict perovskite catalytic properties\ncritical for SOFC/SOEC applications, including oxygen surface exchange, oxygen\ndiffusivity, and area specific resistance (ASR). The models are based on\ntrivial-to-calculate elemental features and are more accurate and dramatically\nfaster than the best models based on ab initio-derived features, potentially\neliminating the need for ab initio calculations in descriptor-based screening.\nOur model of ASR enables temperature-dependent predictions, has well calibrated\nuncertainty estimates and online accessibility. Use of temporal\ncross-validation reveals our model to be effective at discovering new promising\nmaterials prior to their initial discovery, demonstrating our model can make\nmeaningful predictions. Using the SHapley Additive ExPlanations (SHAP)\napproach, we provide detailed discussion of different approaches of model\nfeaturization for ML property prediction. Finally, we use our model to screen\nmore than 19 million perovskites to develop a list of promising cheap,\nearth-abundant, stable, and high performing materials, and find some top\nmaterials contain mixtures of less-explored elements (e.g., K, Bi, Y, Ni, Cu)\nworth exploring in more detail.",
            "author": [
                "Ryan Jacobs",
                "Jian Liu",
                "Harry Abernathy",
                "Dane Morgan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01401v1",
                "http://arxiv.org/pdf/2311.01401v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01398v1",
            "title": "Server-side Rescoring of Spoken Entity-centric Knowledge Queries for\n  Virtual Assistants",
            "updated": "2023-11-02T17:07:23Z",
            "published": "2023-11-02T17:07:23Z",
            "summary": "On-device Virtual Assistants (VAs) powered by Automatic Speech Recognition\n(ASR) require effective knowledge integration for the challenging entity-rich\nquery recognition. In this paper, we conduct an empirical study of modeling\nstrategies for server-side rescoring of spoken information domain queries using\nvarious categories of Language Models (LMs) (N-gram word LMs, sub-word neural\nLMs). We investigate the combination of on-device and server-side signals, and\ndemonstrate significant WER improvements of 23%-35% on various entity-centric\nquery subpopulations by integrating various server-side LMs compared to\nperforming ASR on-device only. We also perform a comparison between LMs trained\non domain data and a GPT-3 variant offered by OpenAI as a baseline.\nFurthermore, we also show that model fusion of multiple server-side LMs trained\nfrom scratch most effectively combines complementary strengths of each model\nand integrates knowledge learned from domain-specific data to a VA ASR system.",
            "author": [
                "Youyuan Zhang",
                "Sashank Gondala",
                "Thiago Fraga-Silva",
                "Christophe Van Gysel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01398v1",
                "http://arxiv.org/pdf/2311.01398v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01394v1",
            "title": "Learning Realistic Traffic Agents in Closed-loop",
            "updated": "2023-11-02T16:55:23Z",
            "published": "2023-11-02T16:55:23Z",
            "summary": "Realistic traffic simulation is crucial for developing self-driving software\nin a safe and scalable manner prior to real-world deployment. Typically,\nimitation learning (IL) is used to learn human-like traffic agents directly\nfrom real-world observations collected offline, but without explicit\nspecification of traffic rules, agents trained from IL alone frequently display\nunrealistic infractions like collisions and driving off the road. This problem\nis exacerbated in out-of-distribution and long-tail scenarios. On the other\nhand, reinforcement learning (RL) can train traffic agents to avoid\ninfractions, but using RL alone results in unhuman-like driving behaviors. We\npropose Reinforcing Traffic Rules (RTR), a holistic closed-loop learning\nobjective to match expert demonstrations under a traffic compliance constraint,\nwhich naturally gives rise to a joint IL + RL approach, obtaining the best of\nboth worlds. Our method learns in closed-loop simulations of both nominal\nscenarios from real-world datasets as well as procedurally generated long-tail\nscenarios. Our experiments show that RTR learns more realistic and\ngeneralizable traffic simulation policies, achieving significantly better\ntradeoffs between human-like driving and traffic compliance in both nominal and\nlong-tail scenarios. Moreover, when used as a data generation tool for training\nprediction models, our learned traffic policy leads to considerably improved\ndownstream prediction metrics compared to baseline traffic agents. For more\ninformation, visit the project website: https://waabi.ai/rtr",
            "author": [
                "Chris Zhang",
                "James Tu",
                "Lunjun Zhang",
                "Kelvin Wong",
                "Simon Suo",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01394v1",
                "http://arxiv.org/pdf/2311.01394v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01489v1",
            "title": "Invariant Causal Imitation Learning for Generalizable Policies",
            "updated": "2023-11-02T16:52:36Z",
            "published": "2023-11-02T16:52:36Z",
            "summary": "Consider learning an imitation policy on the basis of demonstrated behavior\nfrom multiple environments, with an eye towards deployment in an unseen\nenvironment. Since the observable features from each setting may be different,\ndirectly learning individual policies as mappings from features to actions is\nprone to spurious correlations -- and may not generalize well. However, the\nexpert's policy is often a function of a shared latent structure underlying\nthose observable features that is invariant across settings. By leveraging data\nfrom multiple environments, we propose Invariant Causal Imitation Learning\n(ICIL), a novel technique in which we learn a feature representation that is\ninvariant across domains, on the basis of which we learn an imitation policy\nthat matches expert behavior. To cope with transition dynamics mismatch, ICIL\nlearns a shared representation of causal features (for all training\nenvironments), that is disentangled from the specific representations of noise\nvariables (for each of those environments). Moreover, to ensure that the\nlearned policy matches the observation distribution of the expert's policy,\nICIL estimates the energy of the expert's observations and uses a\nregularization term that minimizes the imitator policy's next state energy.\nExperimentally, we compare our methods against several benchmarks in control\nand healthcare tasks and show its effectiveness in learning imitation policies\ncapable of generalizing to unseen environments.",
            "author": [
                "Ioana Bica",
                "Daniel Jarrett",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01489v1",
                "http://arxiv.org/pdf/2311.01489v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01388v1",
            "title": "Time-series Generation by Contrastive Imitation",
            "updated": "2023-11-02T16:45:25Z",
            "published": "2023-11-02T16:45:25Z",
            "summary": "Consider learning a generative model for time-series data. The sequential\nsetting poses a unique challenge: Not only should the generator capture the\nconditional dynamics of (stepwise) transitions, but its open-loop rollouts\nshould also preserve the joint distribution of (multi-step) trajectories. On\none hand, autoregressive models trained by MLE allow learning and computing\nexplicit transition distributions, but suffer from compounding error during\nrollouts. On the other hand, adversarial models based on GAN training alleviate\nsuch exposure bias, but transitions are implicit and hard to assess. In this\nwork, we study a generative framework that seeks to combine the strengths of\nboth: Motivated by a moment-matching objective to mitigate compounding error,\nwe optimize a local (but forward-looking) transition policy, where the\nreinforcement signal is provided by a global (but stepwise-decomposable) energy\nmodel trained by contrastive estimation. At training, the two components are\nlearned cooperatively, avoiding the instabilities typical of adversarial\nobjectives. At inference, the learned policy serves as the generator for\niterative sampling, and the learned energy serves as a trajectory-level measure\nfor evaluating sample quality. By expressly training a policy to imitate\nsequential behavior of time-series features in a dataset, this approach\nembodies \"generation by imitation\". Theoretically, we illustrate the\ncorrectness of this formulation and the consistency of the algorithm.\nEmpirically, we evaluate its ability to generate predictively useful samples\nfrom real-world datasets, verifying that it performs at the standard of\nexisting benchmarks.",
            "author": [
                "Daniel Jarrett",
                "Ioana Bica",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01388v1",
                "http://arxiv.org/pdf/2311.01388v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01386v1",
            "title": "Can Language Models Be Tricked by Language Illusions? Easier with\n  Syntax, Harder with Semantics",
            "updated": "2023-11-02T16:44:24Z",
            "published": "2023-11-02T16:44:24Z",
            "summary": "Language models (LMs) have been argued to overlap substantially with human\nbeings in grammaticality judgment tasks. But when humans systematically make\nerrors in language processing, should we expect LMs to behave like cognitive\nmodels of language and mimic human behavior? We answer this question by\ninvestigating LMs' more subtle judgments associated with \"language illusions\"\n-- sentences that are vague in meaning, implausible, or ungrammatical but\nreceive unexpectedly high acceptability judgments by humans. We looked at three\nillusions: the comparative illusion (e.g. \"More people have been to Russia than\nI have\"), the depth-charge illusion (e.g. \"No head injury is too trivial to be\nignored\"), and the negative polarity item (NPI) illusion (e.g. \"The hunter who\nno villager believed to be trustworthy will ever shoot a bear\"). We found that\nprobabilities represented by LMs were more likely to align with human judgments\nof being \"tricked\" by the NPI illusion which examines a structural dependency,\ncompared to the comparative and the depth-charge illusions which require\nsophisticated semantic understanding. No single LM or metric yielded results\nthat are entirely consistent with human behavior. Ultimately, we show that LMs\nare limited both in their construal as cognitive models of human language\nprocessing and in their capacity to recognize nuanced but critical information\nin complicated language materials.",
            "author": [
                "Yuhan Zhang",
                "Edward Gibson",
                "Forrest Davis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01386v1",
                "http://arxiv.org/pdf/2311.01386v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01378v2",
            "title": "Vision-Language Foundation Models as Effective Robot Imitators",
            "updated": "2023-11-06T07:40:27Z",
            "published": "2023-11-02T16:34:33Z",
            "summary": "Recent progress in vision language foundation models has shown their ability\nto understand multimodal data and resolve complicated vision language tasks,\nincluding robotics manipulation. We seek a straightforward way of making use of\nexisting vision-language models (VLMs) with simple fine-tuning on robotics\ndata. To this end, we derive a simple and novel vision-language manipulation\nframework, dubbed RoboFlamingo, built upon the open-source VLMs, OpenFlamingo.\nUnlike prior works, RoboFlamingo utilizes pre-trained VLMs for single-step\nvision-language comprehension, models sequential history information with an\nexplicit policy head, and is slightly fine-tuned by imitation learning only on\nlanguage-conditioned manipulation datasets. Such a decomposition provides\nRoboFlamingo the flexibility for open-loop control and deployment on\nlow-performance platforms. By exceeding the state-of-the-art performance with a\nlarge margin on the tested benchmark, we show RoboFlamingo can be an effective\nand competitive alternative to adapt VLMs to robot control. Our extensive\nexperimental results also reveal several interesting conclusions regarding the\nbehavior of different pre-trained VLMs on manipulation tasks. We believe\nRoboFlamingo has the potential to be a cost-effective and easy-to-use solution\nfor robotics manipulation, empowering everyone with the ability to fine-tune\ntheir own robotics policy.",
            "author": [
                "Xinghang Li",
                "Minghuan Liu",
                "Hanbo Zhang",
                "Cunjun Yu",
                "Jie Xu",
                "Hongtao Wu",
                "Chilam Cheang",
                "Ya Jing",
                "Weinan Zhang",
                "Huaping Liu",
                "Hang Li",
                "Tao Kong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01378v2",
                "http://arxiv.org/pdf/2311.01378v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01377v1",
            "title": "Analysis of tidal flows through the Strait of Gibraltar using Dynamic\n  Mode Decomposition",
            "updated": "2023-11-02T16:34:31Z",
            "published": "2023-11-02T16:34:31Z",
            "summary": "The Strait of Gibraltar is a region characterized by intricate oceanic\nsub-mesoscale features, influenced by topography, tidal forces, instabilities,\nand nonlinear hydraulic processes, all governed by the nonlinear equations of\nfluid motion. In this study, we aim to uncover the underlying physics of these\nphenomena within 3D MIT general circulation model simulations, including waves,\neddies, and gyres. To achieve this, we employ Dynamic Mode Decomposition (DMD)\nto break down simulation snapshots into Koopman modes, with distinct\nexponential growth/decay rates and oscillation frequencies. Our objectives\nencompass evaluating DMD's efficacy in capturing known features, unveiling new\nelements, ranking modes, and exploring order reduction. We also introduce\nmodifications to enhance DMD's robustness, numerical accuracy, and robustness\nof eigenvalues. DMD analysis yields a comprehensive understanding of flow\npatterns, internal wave formation, and the dynamics of the Strait of Gibraltar,\nits meandering behaviors, and the formation of a secondary gyre, notably the\nWestern Alboran Gyre, as well as the propagation of Kelvin and coastal-trapped\nwaves along the African coast. In doing so, it significantly advances our\ncomprehension of intricate oceanographic phenomena and underscores the immense\nutility of DMD as an analytical tool for such complex datasets, suggesting that\nDMD could serve as a valuable addition to the toolkit of oceanographers.",
            "author": [
                "Sathsara Dias",
                "Sudam Surasinghe",
                "Kanaththa Priyankara",
                "Marko Budi\u0161i\u0107",
                "Larry Pratt",
                "Jos\u00e9 C. Sanchez-Garrido",
                "Erik M. Bollt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01377v1",
                "http://arxiv.org/pdf/2311.01377v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "physics.flu-dyn",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01375v1",
            "title": "Monotone Generative Modeling via a Gromov-Monge Embedding",
            "updated": "2023-11-02T16:33:35Z",
            "published": "2023-11-02T16:33:35Z",
            "summary": "Generative Adversarial Networks (GANs) are powerful tools for creating new\ncontent, but they face challenges such as sensitivity to starting conditions\nand mode collapse. To address these issues, we propose a deep generative model\nthat utilizes the Gromov-Monge embedding (GME). It helps identify the\nlow-dimensional structure of the underlying measure of the data and then maps\nit, while preserving its geometry, into a measure in a low-dimensional latent\nspace, which is then optimally transported to the reference measure. We\nguarantee the preservation of the underlying geometry by the GME and\n$c$-cyclical monotonicity of the generative map, where $c$ is an intrinsic\nembedding cost employed by the GME. The latter property is a first step in\nguaranteeing better robustness to initialization of parameters and mode\ncollapse. Numerical experiments demonstrate the effectiveness of our approach\nin generating high-quality images, avoiding mode collapse, and exhibiting\nrobustness to different starting conditions.",
            "author": [
                "Wonjun Lee",
                "Yifei Yang",
                "Dongmian Zou",
                "Gilad Lerman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01375v1",
                "http://arxiv.org/pdf/2311.01375v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01372v2",
            "title": "Data-Augmented and Retrieval-Augmented Context Enrichment in Chinese\n  Media Bias Detection",
            "updated": "2023-11-18T09:45:01Z",
            "published": "2023-11-02T16:29:49Z",
            "summary": "With the increasing pursuit of objective reports, automatically understanding\nmedia bias has drawn more attention in recent research. However, most of the\nprevious work examines media bias from Western ideology, such as the left and\nright in the political spectrum, which is not applicable to Chinese outlets.\nBased on the previous lexical bias and informational bias structure, we refine\nit from the Chinese perspective and go one step further to craft data with 7\nfine-grained labels. To be specific, we first construct a dataset with Chinese\nnews reports about COVID-19 which is annotated by our newly designed system,\nand then conduct substantial experiments on it to detect media bias. However,\nthe scale of the annotated data is not enough for the latest deep-learning\ntechnology, and the cost of human annotation in media bias, which needs a lot\nof professional knowledge, is too expensive. Thus, we explore some context\nenrichment methods to automatically improve these problems. In Data-Augmented\nContext Enrichment (DACE), we enlarge the training data; while in\nRetrieval-Augmented Context Enrichment (RACE), we improve information retrieval\nmethods to select valuable information and integrate it into our models to\nbetter understand bias. Extensive experiments are conducted on both our dataset\nand an English dataset BASIL. Our results show that both methods outperform our\nbaselines, while the RACE methods are more efficient and have more potential.",
            "author": [
                "Luyang Lin",
                "Jing Li",
                "Kam-Fai Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01372v2",
                "http://arxiv.org/pdf/2311.01372v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01367v1",
            "title": "Respiratory Anomaly Detection using Reflected Infrared Light-wave\n  Signals",
            "updated": "2023-11-02T16:23:13Z",
            "published": "2023-11-02T16:23:13Z",
            "summary": "In this study, we present a non-contact respiratory anomaly detection method\nusing incoherent light-wave signals reflected from the chest of a mechanical\nrobot that can breathe like human beings. In comparison to existing radar and\ncamera-based sensing systems for vitals monitoring, this technology uses only a\nlow-cost ubiquitous light source (e.g., infrared light emitting diode) and\nsensor (e.g., photodetector). This light-wave sensing (LWS) system recognizes\ndifferent breathing anomalies from the variations of light intensity reflected\nfrom the chest of the robot within a 0.5m-1.5m range. The anomaly detection\nmodel demonstrates up to 96.6% average accuracy in classifying 7 different\ntypes of breathing data using machine learning. The model can also detect\nfaulty data collected by the system that does not contain breathing\ninformation. The developed system can be utilized at home or healthcare\nfacilities as a smart, non-contact and discreet respiration monitoring method.",
            "author": [
                "Md Zobaer Islam",
                "Brenden Martin",
                "Carly Gotcher",
                "Tyler Martinez",
                "John F. O'Hara",
                "Sabit Ekin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01367v1",
                "http://arxiv.org/pdf/2311.01367v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04228v1",
            "title": "Graph Neural Networks for Topological Feature Extraction in ECG\n  Classification",
            "updated": "2023-11-02T16:14:34Z",
            "published": "2023-11-02T16:14:34Z",
            "summary": "The electrocardiogram (ECG) is a dependable instrument for assessing the\nfunction of the cardiovascular system. There has recently been much emphasis on\nprecisely classifying ECGs. While ECG situations have numerous similarities,\nlittle attention has been paid to categorizing ECGs using graph neural\nnetworks. In this study, we offer three distinct techniques for classifying\nheartbeats using deep graph neural networks to classify the ECG signals\naccurately. We suggest using different methods to extract topological features\nfrom the ECG signal and then using a branch of the graph neural network named\ngraph isomorphism network for classifying the ECGs. On the PTB Diagnostics data\nset, we tested the three proposed techniques. According to the findings, the\nthree proposed techniques are capable of making arrhythmia classification\npredictions with the accuracy of 99.38, 98.76, and 91.93 percent, respectively.",
            "author": [
                "Kamyar Zeinalipour",
                "Marco Gori"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-981-99-3592-5_2",
                "http://arxiv.org/abs/2311.04228v1",
                "http://arxiv.org/pdf/2311.04228v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01358v1",
            "title": "The Universal Statistical Structure and Scaling Laws of Chaos and\n  Turbulence",
            "updated": "2023-11-02T16:04:48Z",
            "published": "2023-11-02T16:04:48Z",
            "summary": "Turbulence is a complex spatial and temporal structure created by the strong\nnon-linear dynamics of fluid flows at high Reynolds numbers. Despite being an\nubiquitous phenomenon that has been studied for centuries, a full understanding\nof turbulence remained a formidable challenge. Here, we introduce tools from\nthe fields of quantum chaos and Random Matrix Theory (RMT) and present a\ndetailed analysis of image datasets generated from turbulence simulations of\nincompressible and compressible fluid flows. Focusing on two observables: the\ndata Gram matrix and the single image distribution, we study both the local and\nglobal eigenvalue statistics and compare them to classical chaos, uncorrelated\nnoise and natural images. We show that from the RMT perspective, the turbulence\nGram matrices lie in the same universality class as quantum chaotic rather than\nintegrable systems, and the data exhibits power-law scalings in the bulk of its\neigenvalues which are vastly different from uncorrelated classical chaos,\nrandom data, natural images. Interestingly, we find that the single sample\ndistribution only appears as fully RMT chaotic, but deviates from chaos at\nlarger correlation lengths, as well as exhibiting different scaling properties.",
            "author": [
                "Noam Levi",
                "Yaron Oz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01358v1",
                "http://arxiv.org/pdf/2311.01358v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "hep-th",
                "nlin.CD",
                "physics.flu-dyn",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01356v2",
            "title": "Upper and lower bounds for the Lipschitz constant of random neural\n  networks",
            "updated": "2023-12-01T17:40:35Z",
            "published": "2023-11-02T16:03:26Z",
            "summary": "Empirical studies have widely demonstrated that neural networks are highly\nsensitive to small, adversarial perturbations of the input. The worst-case\nrobustness against these so-called adversarial examples can be quantified by\nthe Lipschitz constant of the neural network. In this paper, we study upper and\nlower bounds for the Lipschitz constant of random ReLU neural networks.\nSpecifically, we assume that the weights and biases follow a generalization of\nthe He initialization, where general symmetric distributions for the biases are\npermitted. For shallow neural networks, we characterize the Lipschitz constant\nup to an absolute numerical constant. For deep networks with fixed depth and\nsufficiently large width, our established bounds differ by a factor that is\nlogarithmic in the width.",
            "author": [
                "Paul Geuchen",
                "Thomas Heindl",
                "Dominik St\u00f6ger",
                "Felix Voigtlaender"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01356v2",
                "http://arxiv.org/pdf/2311.01356v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.PR",
                "68T07, 26A16, 60B20, 60G15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01352v1",
            "title": "Deep learning based Image Compression for Microscopy Images: An\n  Empirical Study",
            "updated": "2023-11-02T16:00:32Z",
            "published": "2023-11-02T16:00:32Z",
            "summary": "With the fast development of modern microscopes and bioimaging techniques, an\nunprecedentedly large amount of imaging data are being generated, stored,\nanalyzed, and even shared through networks. The size of the data poses great\nchallenges for current data infrastructure. One common way to reduce the data\nsize is by image compression. This present study analyzes classic and deep\nlearning based image compression methods, and their impact on deep learning\nbased image processing models. Deep learning based label-free prediction models\n(i.e., predicting fluorescent images from bright field images) are used as an\nexample application for comparison and analysis. Effective image compression\nmethods could help reduce the data size significantly without losing necessary\ninformation, and therefore reduce the burden on data management infrastructure\nand permit fast transmission through the network for data sharing or cloud\ncomputing. To compress images in such a wanted way, multiple classical lossy\nimage compression techniques are compared to several AI-based compression\nmodels provided by and trained with the CompressAI toolbox using python. These\ndifferent compression techniques are compared in compression ratio, multiple\nimage similarity measures and, most importantly, the prediction accuracy from\nlabel-free models on compressed images. We found that AI-based compression\ntechniques largely outperform the classic ones and will minimally affect the\ndownstream label-free task in 2D cases. In the end, we hope the present study\ncould shed light on the potential of deep learning based image compression and\nthe impact of image compression on downstream deep learning based image\nanalysis models.",
            "author": [
                "Yu Zhou",
                "Jan Sollman",
                "Jianxu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01352v1",
                "http://arxiv.org/pdf/2311.01352v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01349v1",
            "title": "Unreading Race: Purging Protected Features from Chest X-ray Embeddings",
            "updated": "2023-11-02T15:59:00Z",
            "published": "2023-11-02T15:59:00Z",
            "summary": "Purpose: To analyze and remove protected feature effects in chest radiograph\nembeddings of deep learning models.\n  Materials and Methods: An orthogonalization is utilized to remove the\ninfluence of protected features (e.g., age, sex, race) in chest radiograph\nembeddings, ensuring feature-independent results. To validate the efficacy of\nthe approach, we retrospectively study the MIMIC and CheXpert datasets using\nthree pre-trained models, namely a supervised contrastive, a self-supervised\ncontrastive, and a baseline classifier model. Our statistical analysis involves\ncomparing the original versus the orthogonalized embeddings by estimating\nprotected feature influences and evaluating the ability to predict race, age,\nor sex using the two types of embeddings.\n  Results: Our experiments reveal a significant influence of protected features\non predictions of pathologies. Applying orthogonalization removes these feature\neffects. Apart from removing any influence on pathology classification, while\nmaintaining competitive predictive performance, orthogonalized embeddings\nfurther make it infeasible to directly predict protected attributes and\nmitigate subgroup disparities.\n  Conclusion: The presented work demonstrates the successful application and\nevaluation of the orthogonalization technique in the domain of chest X-ray\nclassification.",
            "author": [
                "Tobias Weber",
                "Michael Ingrisch",
                "Bernd Bischl",
                "David R\u00fcgamer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01349v1",
                "http://arxiv.org/pdf/2311.01349v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01344v1",
            "title": "Like an Open Book? Read Neural Network Architecture with Simple Power\n  Analysis on 32-bit Microcontrollers",
            "updated": "2023-11-02T15:55:20Z",
            "published": "2023-11-02T15:55:20Z",
            "summary": "Model extraction is a growing concern for the security of AI systems. For\ndeep neural network models, the architecture is the most important information\nan adversary aims to recover. Being a sequence of repeated computation blocks,\nneural network models deployed on edge-devices will generate distinctive\nside-channel leakages. The latter can be exploited to extract critical\ninformation when targeted platforms are physically accessible. By combining\ntheoretical knowledge about deep learning practices and analysis of a\nwidespread implementation library (ARM CMSIS-NN), our purpose is to answer this\ncritical question: how far can we extract architecture information by simply\nexamining an EM side-channel trace? For the first time, we propose an\nextraction methodology for traditional MLP and CNN models running on a high-end\n32-bit microcontroller (Cortex-M7) that relies only on simple pattern\nrecognition analysis. Despite few challenging cases, we claim that, contrary to\nparameters extraction, the complexity of the attack is relatively low and we\nhighlight the urgent need for practicable protections that could fit the strong\nmemory and latency requirements of such platforms.",
            "author": [
                "Raphael Joud",
                "Pierre-Alain Moellic",
                "Simon Pontie",
                "Jean-Baptiste Rigaud"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01344v1",
                "http://arxiv.org/pdf/2311.01344v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01343v3",
            "title": "Collaborative Large Language Model for Recommender Systems",
            "updated": "2023-11-08T05:02:06Z",
            "published": "2023-11-02T15:52:35Z",
            "summary": "Recently, there is a growing interest in developing next-generation\nrecommender systems (RSs) based on pretrained large language models (LLMs),\nfully utilizing their encoded knowledge and reasoning ability. However, the\nsemantic gap between natural language and recommendation tasks is still not\nwell addressed, leading to multiple issues such as spuriously-correlated\nuser/item descriptors, ineffective language modeling on user/item contents, and\ninefficient recommendations via auto-regression, etc. In this paper, we propose\nCLLM4Rec, the first generative RS that tightly integrates the LLM paradigm and\nID paradigm of RS, aiming to address the above challenges simultaneously. We\nfirst extend the vocabulary of pretrained LLMs with user/item ID tokens to\nfaithfully model the user/item collaborative and content semantics.\nAccordingly, in the pretraining stage, a novel soft+hard prompting strategy is\nproposed to effectively learn user/item collaborative/content token embeddings\nvia language modeling on RS-specific corpora established from user-item\ninteractions and user/item features, where each document is split into a prompt\nconsisting of heterogeneous soft (user/item) tokens and hard (vocab) tokens and\na main text consisting of homogeneous item tokens or vocab tokens that\nfacilitates stable and effective language modeling. In addition, a novel mutual\nregularization strategy is introduced to encourage the CLLM4Rec to capture\nrecommendation-oriented information from user/item contents. Finally, we\npropose a novel recommendation-oriented finetuning strategy for CLLM4Rec, where\nan item prediction head with multinomial likelihood is added to the pretrained\nCLLM4Rec backbone to predict hold-out items based on the soft+hard prompts\nestablished from masked user-item interaction history, where recommendations of\nmultiple items can be generated efficiently.",
            "author": [
                "Yaochen Zhu",
                "Liang Wu",
                "Qi Guo",
                "Liangjie Hong",
                "Jundong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01343v3",
                "http://arxiv.org/pdf/2311.01343v3"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01337v1",
            "title": "Adaptive Identification of SIS Models",
            "updated": "2023-11-02T15:47:33Z",
            "published": "2023-11-02T15:47:33Z",
            "summary": "Effective containment of spreading processes such as epidemics requires\naccurate knowledge of several key parameters that govern their dynamics. In\nthis work, we first show that the problem of identifying the underlying\nparameters of epidemiological spreading processes is often ill-conditioned and\nlacks the persistence of excitation required for the convergence of adaptive\nlearning schemes. To tackle this challenge, we leverage a relaxed property\ncalled initial excitation combined with a recursive least squares algorithm to\ndesign an online adaptive identifier to learn the parameters of the\nsusceptible-infected-susceptible (SIS) epidemic model from the knowledge of its\nstates. We prove that the iterates generated by the proposed algorithm minimize\nan auxiliary weighted least squares cost function. We illustrate the\nconvergence of the error of the estimated epidemic parameters via several\nnumerical case studies and compare it with results obtained using conventional\napproaches.",
            "author": [
                "Chi Ho Leung",
                "William E. Retnaraj",
                "Ashish R. Hota",
                "Philip E. Par\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01337v1",
                "http://arxiv.org/pdf/2311.01337v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01335v2",
            "title": "Automatic Robot Hand-Eye Calibration Enabled by Learning-Based 3D Vision",
            "updated": "2023-11-27T14:19:34Z",
            "published": "2023-11-02T15:45:09Z",
            "summary": "Hand-eye calibration, as a fundamental task in vision-based robotic systems,\naims to estimate the transformation matrix between the coordinate frame of the\ncamera and the robot flange. Most approaches to hand-eye calibration rely on\nexternal markers or human assistance. We proposed Look at Robot Base Once\n(LRBO), a novel methodology that addresses the hand-eye calibration problem\nwithout external calibration objects or human support, but with the robot base.\nUsing point clouds of the robot base, a transformation matrix from the\ncoordinate frame of the camera to the robot base is established as I=AXB. To\nthis end, we exploit learning-based 3D detection and registration algorithms to\nestimate the location and orientation of the robot base. The robustness and\naccuracy of the method are quantified by ground-truth-based evaluation, and the\naccuracy result is compared with other 3D vision-based calibration methods. To\nassess the feasibility of our methodology, we carried out experiments utilizing\na low-cost structured light scanner across varying joint configurations and\ngroups of experiments. The proposed hand-eye calibration method achieved a\ntranslation deviation of 0.930 mm and a rotation deviation of 0.265 degrees\naccording to the experimental results. Additionally, the 3D reconstruction\nexperiments demonstrated a rotation error of 0.994 degrees and a position error\nof 1.697 mm. Moreover, our method offers the potential to be completed in 1\nsecond, which is the fastest compared to other 3D hand-eye calibration methods.\nCode is released at github.com/leihui6/LRBO.",
            "author": [
                "Leihui Li",
                "Xingyu Yang",
                "Riwei Wang",
                "Xuping Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01335v2",
                "http://arxiv.org/pdf/2311.01335v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01334v1",
            "title": "Supervised Learning Based Real-Time Adaptive Beamforming On-board\n  Multibeam Satellites",
            "updated": "2023-11-02T15:45:00Z",
            "published": "2023-11-02T15:45:00Z",
            "summary": "Satellite communications (SatCom) are crucial for global connectivity,\nespecially in the era of emerging technologies like 6G and narrowing the\ndigital divide. Traditional SatCom systems struggle with efficient resource\nmanagement due to static multibeam configurations, hindering quality of service\n(QoS) amidst dynamic traffic demands. This paper introduces an innovative\nsolution - real-time adaptive beamforming on multibeam satellites with\nsoftware-defined payloads in geostationary orbit (GEO). Utilizing a Direct\nRadiating Array (DRA) with circular polarization in the 17.7 - 20.2 GHz band,\nthe paper outlines DRA design and a supervised learning-based algorithm for\non-board beamforming. This adaptive approach not only meets precise beam\nprojection needs but also dynamically adjusts beamwidth, minimizes sidelobe\nlevels (SLL), and optimizes effective isotropic radiated power (EIRP).",
            "author": [
                "Flor Ortiz",
                "Juan A. Vasquez-Peralvo",
                "Jorge Querol",
                "Eva Lagunas",
                "Jorge L. Gonzalez Rios",
                "Marcele O. K. Mendonca",
                "Luis Garces",
                "Victor Monzon Baeza",
                "Symeon Chatzinotas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01334v1",
                "http://arxiv.org/pdf/2311.01334v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01331v2",
            "title": "Offline Imitation from Observation via Primal Wasserstein State\n  Occupancy Matching",
            "updated": "2023-11-21T18:50:49Z",
            "published": "2023-11-02T15:41:57Z",
            "summary": "In real-world scenarios, arbitrary interactions with the environment can\noften be costly, and actions of expert demonstrations are not always available.\nTo reduce the need for both, Offline Learning from Observations (LfO) is\nextensively studied, where the agent learns to solve a task with only expert\nstates and \\textit{task-agnostic} non-expert state-action pairs. The\nstate-of-the-art DIstribution Correction Estimation (DICE) methods minimize the\nstate occupancy divergence between the learner and expert policies. However,\nthey are limited to either $f$-divergences (KL and $\\chi^2$) or Wasserstein\ndistance with Rubinstein duality, the latter of which constrains the underlying\ndistance metric crucial to the performance of Wasserstein-based solutions. To\naddress this problem, we propose Primal Wasserstein DICE (PW-DICE), which\nminimizes the primal Wasserstein distance between the expert and learner state\noccupancies with a pessimistic regularizer and leverages a contrastively\nlearned distance as the underlying metric for the Wasserstein distance.\nTheoretically, we prove that our framework is a generalization of the\nstate-of-the-art, SMODICE, and unifies $f$-divergence and Wasserstein\nminimization. Empirically, we find that PW-DICE improves upon several\nstate-of-the-art methods on multiple testbeds.",
            "author": [
                "Kai Yan",
                "Alexander G. Schwing",
                "Yu-xiong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01331v2",
                "http://arxiv.org/pdf/2311.01331v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01329v1",
            "title": "A Simple Solution for Offline Imitation from Observations and Examples\n  with Possibly Incomplete Trajectories",
            "updated": "2023-11-02T15:41:09Z",
            "published": "2023-11-02T15:41:09Z",
            "summary": "Offline imitation from observations aims to solve MDPs where only\ntask-specific expert states and task-agnostic non-expert state-action pairs are\navailable. Offline imitation is useful in real-world scenarios where arbitrary\ninteractions are costly and expert actions are unavailable. The\nstate-of-the-art \"DIstribution Correction Estimation\" (DICE) methods minimize\ndivergence of state occupancy between expert and learner policies and retrieve\na policy with weighted behavior cloning; however, their results are unstable\nwhen learning from incomplete trajectories, due to a non-robust optimization in\nthe dual domain. To address the issue, in this paper, we propose\nTrajectory-Aware Imitation Learning from Observations (TAILO). TAILO uses a\ndiscounted sum along the future trajectory as the weight for weighted behavior\ncloning. The terms for the sum are scaled by the output of a discriminator,\nwhich aims to identify expert states. Despite simplicity, TAILO works well if\nthere exist trajectories or segments of expert behavior in the task-agnostic\ndata, a common assumption in prior work. In experiments across multiple\ntestbeds, we find TAILO to be more robust and effective, particularly with\nincomplete trajectories.",
            "author": [
                "Kai Yan",
                "Alexander G. Schwing",
                "Yu-Xiong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01329v1",
                "http://arxiv.org/pdf/2311.01329v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01327v1",
            "title": "High-dimensional Linear Bandits with Knapsacks",
            "updated": "2023-11-02T15:40:33Z",
            "published": "2023-11-02T15:40:33Z",
            "summary": "We study the contextual bandits with knapsack (CBwK) problem under the\nhigh-dimensional setting where the dimension of the feature is large. The\nreward of pulling each arm equals the multiplication of a sparse\nhigh-dimensional weight vector and the feature of the current arrival, with\nadditional random noise. In this paper, we investigate how to exploit this\nsparsity structure to achieve improved regret for the CBwK problem. To this\nend, we first develop an online variant of the hard thresholding algorithm that\nperforms the sparse estimation in an online manner. We further combine our\nonline estimator with a primal-dual framework, where we assign a dual variable\nto each knapsack constraint and utilize an online learning algorithm to update\nthe dual variable, thereby controlling the consumption of the knapsack\ncapacity. We show that this integrated approach allows us to achieve a\nsublinear regret that depends logarithmically on the feature dimension, thus\nimproving the polynomial dependency established in the previous literature. We\nalso apply our framework to the high-dimension contextual bandit problem\nwithout the knapsack constraint and achieve optimal regret in both the\ndata-poor regime and the data-rich regime. We finally conduct numerical\nexperiments to show the efficient empirical performance of our algorithms under\nthe high dimensional setting.",
            "author": [
                "Wanteng Ma",
                "Dong Xia",
                "Jiashuo Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01327v1",
                "http://arxiv.org/pdf/2311.01327v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14683v1",
            "title": "Data Science for Social Good",
            "updated": "2023-11-02T15:40:20Z",
            "published": "2023-11-02T15:40:20Z",
            "summary": "Data science has been described as the fourth paradigm for scientific\ndiscovery. The latest wave of data science research, pertaining to machine\nlearning and artificial intelligence (AI), is growing exponentially and\ngarnering millions of annual citations. However, this growth has been\naccompanied by a diminishing emphasis on social good challenges - our analysis\nreveals that the proportion of data science research focusing on social good is\nless than it has ever been. At the same time, the proliferation of machine\nlearning and generative AI have sparked debates about the socio-technical\nprospects and challenges associated with data science for human flourishing,\norganizations, and society. Against this backdrop, we present a framework for\n\"data science for social good\" (DSSG) research that considers the interplay\nbetween relevant data science research genres, social good challenges, and\ndifferent levels of socio-technical abstraction. We perform an analysis of the\nliterature to empirically demonstrate the paucity of work on DSSG in\ninformation systems (and other related disciplines) and highlight current\nimpediments. We then use our proposed framework to introduce the articles\nappearing in the special issue. We hope that this article and the special issue\nwill spur future DSSG research and help reverse the alarming trend across data\nscience research over the past 30-plus years in which social good challenges\nare garnering proportionately less attention with each passing day.",
            "author": [
                "Ahmed Abbasi",
                "Roger H. L. Chiang",
                "Jennifer J. Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14683v1",
                "http://arxiv.org/pdf/2311.14683v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01326v1",
            "title": "Better Together: Enhancing Generative Knowledge Graph Completion with\n  Language Models and Neighborhood Information",
            "updated": "2023-11-02T15:38:39Z",
            "published": "2023-11-02T15:38:39Z",
            "summary": "Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which\nlimits their potential performance. Knowledge Graph Completion (KGC) techniques\naim to address this issue. However, traditional KGC methods are computationally\nintensive and impractical for large-scale KGs, necessitating the learning of\ndense node embeddings and computing pairwise distances. Generative\ntransformer-based language models (e.g., T5 and recent KGT5) offer a promising\nsolution as they can predict the tail nodes directly. In this study, we propose\nto include node neighborhoods as additional information to improve KGC methods\nbased on language models. We examine the effects of this imputation and show\nthat, on both inductive and transductive Wikidata subsets, our method\noutperforms KGT5 and conventional KGC approaches. We also provide an extensive\nanalysis of the impact of neighborhood on model prediction and show its\nimportance. Furthermore, we point the way to significantly improve KGC through\nmore effective neighborhood selection.",
            "author": [
                "Alla Chepurova",
                "Aydar Bulatov",
                "Yuri Kuratov",
                "Mikhail Burtsev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01326v1",
                "http://arxiv.org/pdf/2311.01326v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01323v1",
            "title": "Towards Evaluating Transfer-based Attacks Systematically, Practically,\n  and Fairly",
            "updated": "2023-11-02T15:35:58Z",
            "published": "2023-11-02T15:35:58Z",
            "summary": "The adversarial vulnerability of deep neural networks (DNNs) has drawn great\nattention due to the security risk of applying these models in real-world\napplications. Based on transferability of adversarial examples, an increasing\nnumber of transfer-based methods have been developed to fool black-box DNN\nmodels whose architecture and parameters are inaccessible. Although tremendous\neffort has been exerted, there still lacks a standardized benchmark that could\nbe taken advantage of to compare these methods systematically, fairly, and\npractically. Our investigation shows that the evaluation of some methods needs\nto be more reasonable and more thorough to verify their effectiveness, to\navoid, for example, unfair comparison and insufficient consideration of\npossible substitute/victim models. Therefore, we establish a transfer-based\nattack benchmark (TA-Bench) which implements 30+ methods. In this paper, we\nevaluate and compare them comprehensively on 25 popular substitute/victim\nmodels on ImageNet. New insights about the effectiveness of these methods are\ngained and guidelines for future evaluations are provided. Code at:\nhttps://github.com/qizhangli/TA-Bench.",
            "author": [
                "Qizhang Li",
                "Yiwen Guo",
                "Wangmeng Zuo",
                "Hao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01323v1",
                "http://arxiv.org/pdf/2311.01323v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01314v1",
            "title": "Recommendations by Concise User Profiles from Review Text",
            "updated": "2023-11-02T15:31:12Z",
            "published": "2023-11-02T15:31:12Z",
            "summary": "Recommender systems are most successful for popular items and users with\nample interactions (likes, ratings etc.). This work addresses the difficult and\nunderexplored case of supporting users who have very sparse interactions but\npost informative review texts. Our experimental studies address two book\ncommunities with these characteristics. We design a framework with\nTransformer-based representation learning, covering user-item interactions,\nitem content, and user-provided reviews. To overcome interaction sparseness, we\ndevise techniques for selecting the most informative cues to construct concise\nuser profiles. Comprehensive experiments, with datasets from Amazon and\nGoodreads, show that judicious selection of text snippets achieves the best\nperformance, even in comparison to ChatGPT-generated user profiles.",
            "author": [
                "Ghazaleh Haratinezhad Torbati",
                "Anna Tigunova",
                "Andrew Yates",
                "Gerhard Weikum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01314v1",
                "http://arxiv.org/pdf/2311.01314v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01310v2",
            "title": "Scattering Vision Transformer: Spectral Mixing Matters",
            "updated": "2023-11-20T13:08:27Z",
            "published": "2023-11-02T15:24:23Z",
            "summary": "Vision transformers have gained significant attention and achieved\nstate-of-the-art performance in various computer vision tasks, including image\nclassification, instance segmentation, and object detection. However,\nchallenges remain in addressing attention complexity and effectively capturing\nfine-grained information within images. Existing solutions often resort to\ndown-sampling operations, such as pooling, to reduce computational cost.\nUnfortunately, such operations are non-invertible and can result in information\nloss. In this paper, we present a novel approach called Scattering Vision\nTransformer (SVT) to tackle these challenges. SVT incorporates a spectrally\nscattering network that enables the capture of intricate image details. SVT\novercomes the invertibility issue associated with down-sampling operations by\nseparating low-frequency and high-frequency components. Furthermore, SVT\nintroduces a unique spectral gating network utilizing Einstein multiplication\nfor token and channel mixing, effectively reducing complexity. We show that SVT\nachieves state-of-the-art performance on the ImageNet dataset with a\nsignificant reduction in a number of parameters and FLOPS. SVT shows 2\\%\nimprovement over LiTv2 and iFormer. SVT-H-S reaches 84.2\\% top-1 accuracy,\nwhile SVT-H-B reaches 85.2\\% (state-of-art for base versions) and SVT-H-L\nreaches 85.7\\% (again state-of-art for large versions). SVT also shows\ncomparable results in other vision tasks such as instance segmentation. SVT\nalso outperforms other transformers in transfer learning on standard datasets\nsuch as CIFAR10, CIFAR100, Oxford Flower, and Stanford Car datasets. The\nproject page is available on this\nwebpage.\\url{https://badripatro.github.io/svt/}.",
            "author": [
                "Badri N. Patro",
                "Vijay Srinivas Agneeswaran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01310v2",
                "http://arxiv.org/pdf/2311.01310v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "eess.IV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01305v3",
            "title": "AWEQ: Post-Training Quantization with Activation-Weight Equalization for\n  Large Language Models",
            "updated": "2023-11-12T07:54:09Z",
            "published": "2023-11-02T15:18:22Z",
            "summary": "Large language models(LLMs) exhibit excellent performance across a variety of\ntasks, but they come with significant computational and storage costs.\nQuantizing these models is an effective way to alleviate this issue. However,\nexisting methods struggle to strike a balance between model accuracy and\nhardware efficiency. This is where we introduce AWEQ, a post-training method\nthat requires no additional training overhead. AWEQ excels in both\nultra-low-bit quantization and 8-bit weight and activation (W8A8) quantization.\nThere is an observation that weight quantization is less challenging than\nactivation quantization. AWEQ transfers the difficulty of activation\nquantization to weights using channel equalization, achieving a balance between\nthe quantization difficulties of both, and thereby maximizing performance. We\nhave further refined the equalization method to mitigate quantization bias\nerror, ensuring the robustness of the model. Extensive experiments on popular\nmodels such as LLaMA and OPT demonstrate that AWEQ outperforms all existing\npost-training quantization methods for large models.",
            "author": [
                "Baisong Li",
                "Xingwang Wang",
                "Haixiao Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01305v3",
                "http://arxiv.org/pdf/2311.01305v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01301v2",
            "title": "TRIALSCOPE: A Unifying Causal Framework for Scaling Real-World Evidence\n  Generation with Biomedical Language Models",
            "updated": "2023-11-06T11:29:30Z",
            "published": "2023-11-02T15:15:47Z",
            "summary": "The rapid digitization of real-world data offers an unprecedented opportunity\nfor optimizing healthcare delivery and accelerating biomedical discovery. In\npractice, however, such data is most abundantly available in unstructured\nforms, such as clinical notes in electronic medical records (EMRs), and it is\ngenerally plagued by confounders. In this paper, we present TRIALSCOPE, a\nunifying framework for distilling real-world evidence from population-level\nobservational data. TRIALSCOPE leverages biomedical language models to\nstructure clinical text at scale, employs advanced probabilistic modeling for\ndenoising and imputation, and incorporates state-of-the-art causal inference\ntechniques to combat common confounders. Using clinical trial specification as\ngeneric representation, TRIALSCOPE provides a turn-key solution to generate and\nreason with clinical hypotheses using observational data. In extensive\nexperiments and analyses on a large-scale real-world dataset with over one\nmillion cancer patients from a large US healthcare network, we show that\nTRIALSCOPE can produce high-quality structuring of real-world data and\ngenerates comparable results to marquee cancer trials. In addition to\nfacilitating in-silicon clinical trial design and optimization, TRIALSCOPE may\nbe used to empower synthetic controls, pragmatic trials, post-market\nsurveillance, as well as support fine-grained patient-like-me reasoning in\nprecision diagnosis and treatment.",
            "author": [
                "Javier Gonz\u00e1lez",
                "Cliff Wong",
                "Zelalem Gero",
                "Jass Bagga",
                "Risa Ueno",
                "Isabel Chien",
                "Eduard Oravkin",
                "Emre Kiciman",
                "Aditya Nori",
                "Roshanthi Weerasinghe",
                "Rom S. Leidner",
                "Brian Piening",
                "Tristan Naumann",
                "Carlo Bifulco",
                "Hoifung Poon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01301v2",
                "http://arxiv.org/pdf/2311.01301v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01295v1",
            "title": "DP-Mix: Mixup-based Data Augmentation for Differentially Private\n  Learning",
            "updated": "2023-11-02T15:12:12Z",
            "published": "2023-11-02T15:12:12Z",
            "summary": "Data augmentation techniques, such as simple image transformations and\ncombinations, are highly effective at improving the generalization of computer\nvision models, especially when training data is limited. However, such\ntechniques are fundamentally incompatible with differentially private learning\napproaches, due to the latter's built-in assumption that each training image's\ncontribution to the learned model is bounded. In this paper, we investigate why\nnaive applications of multi-sample data augmentation techniques, such as mixup,\nfail to achieve good performance and propose two novel data augmentation\ntechniques specifically designed for the constraints of differentially private\nlearning. Our first technique, DP-Mix_Self, achieves SoTA classification\nperformance across a range of datasets and settings by performing mixup on\nself-augmented data. Our second technique, DP-Mix_Diff, further improves\nperformance by incorporating synthetic data from a pre-trained diffusion model\ninto the mixup process. We open-source the code at\nhttps://github.com/wenxuan-Bao/DP-Mix.",
            "author": [
                "Wenxuan Bao",
                "Francesco Pittaluga",
                "Vijay Kumar B G",
                "Vincent Bindschaedler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01295v1",
                "http://arxiv.org/pdf/2311.01295v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01282v3",
            "title": "FlashDecoding++: Faster Large Language Model Inference on GPUs",
            "updated": "2023-11-10T01:43:51Z",
            "published": "2023-11-02T14:57:03Z",
            "summary": "As the Large Language Model (LLM) becomes increasingly important in various\ndomains. However, the following challenges still remain unsolved in\naccelerating LLM inference: (1) Synchronized partial softmax update. The\nsoftmax operation requires a synchronized update operation among each partial\nsoftmax result, leading to ~20% overheads for the attention computation in\nLLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices\nperforming GEMM in LLM inference is flat, leading to under-utilized computation\nand >50% performance loss after padding zeros in previous designs. (3)\nPerformance loss due to static dataflow. Kernel performance in LLM depends on\nvaried input data features, hardware configurations, etc. A single and static\ndataflow may lead to a 50.25% performance loss for GEMMs of different shapes in\nLLM inference.\n  We present FlashDecoding++, a fast LLM inference engine supporting mainstream\nLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++\ncreatively proposes: (1) Asynchronized softmax with unified max value.\nFlashDecoding++ introduces a unified max value technique for different partial\nsoftmax computations to avoid synchronization. (2) Flat GEMM optimization with\ndouble buffering. FlashDecoding++ points out that flat GEMMs with different\nshapes face varied bottlenecks. Then, techniques like double buffering are\nintroduced. (3) Heuristic dataflow with hardware resource adaptation.\nFlashDecoding++ heuristically optimizes dataflow using different hardware\nresource considering input dynamics. Due to the versatility of optimizations in\nFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on\nboth NVIDIA and AMD GPUs compared to Hugging Face implementations.\nFlashDecoding++ also achieves an average speedup of 1.37x compared to\nstate-of-the-art LLM inference engines on mainstream LLMs.",
            "author": [
                "Ke Hong",
                "Guohao Dai",
                "Jiaming Xu",
                "Qiuli Mao",
                "Xiuhong Li",
                "Jun Liu",
                "Kangdi Chen",
                "Yuhan Dong",
                "Yu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01282v3",
                "http://arxiv.org/pdf/2311.01282v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01483v2",
            "title": "FedSN: A General Federated Learning Framework over LEO Satellite\n  Networks",
            "updated": "2023-11-22T08:55:37Z",
            "published": "2023-11-02T14:47:06Z",
            "summary": "Recently, a large number of Low Earth Orbit (LEO) satellites have been\nlaunched and deployed successfully in space by commercial companies, such as\nSpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve\nnot only for communication but also for various machine learning applications,\nsuch as space modulation recognition, remote sensing image classification, etc.\nHowever, the ground station (GS) may be incapable of downloading such a large\nvolume of raw sensing data for centralized model training due to the limited\ncontact time with LEO satellites (e.g. 5 minutes). Therefore, federated\nlearning (FL) has emerged as the promising solution to address this problem via\non-device training. Unfortunately, to enable FL on LEO satellites, we still\nface three critical challenges that are i) heterogeneous computing and memory\ncapabilities, ii) limited uplink rate, and iii) model staleness. To this end,\nwe propose FedSN as a general FL framework to tackle the above challenges, and\nfully explore data diversity on LEO satellites. Specifically, we first present\na novel sub-structure scheme to enable heterogeneous local model training\nconsidering different computing, memory, and communication constraints on LEO\nsatellites. Additionally, we propose a pseudo-synchronous model aggregation\nstrategy to dynamically schedule model aggregation for compensating model\nstaleness. To further demonstrate the effectiveness of the FedSN, we evaluate\nit using space modulation recognition and remote sensing image classification\ntasks by leveraging the data from real-world satellite networks. Extensive\nexperimental results demonstrate that FedSN framework achieves higher accuracy,\nlower computing, and communication overhead than the state-of-the-art\nbenchmarks and the effectiveness of each components in FedSN.",
            "author": [
                "Zheng Lin",
                "Zhe Chen",
                "Zihan Fang",
                "Xianhao Chen",
                "Xiong Wang",
                "Yue Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01483v2",
                "http://arxiv.org/pdf/2311.01483v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01276v2",
            "title": "Long-Range Neural Atom Learning for Molecular Graphs",
            "updated": "2023-11-27T13:02:50Z",
            "published": "2023-11-02T14:44:50Z",
            "summary": "Graph Neural Networks (GNNs) have been widely adopted for drug discovery with\nmolecular graphs. Nevertheless, current GNNs are mainly good at leveraging\nshort-range interactions (SRI) but struggle to capture long-range interactions\n(LRI), both of which are crucial for determining molecular properties. To\ntackle this issue, we propose a method that implicitly projects all original\natoms into a few Neural Atoms, which abstracts the collective information of\natomic groups within a molecule. Specifically, we explicitly exchange the\ninformation among neural atoms and project them back to the atoms'\nrepresentations as an enhancement. With this mechanism, neural atoms establish\nthe communication channels among distant nodes, effectively reducing the\ninteraction scope of arbitrary node pairs into a single hop. To provide an\ninspection of our method from a physical perspective, we reveal its connection\nwith the traditional LRI calculation method, Ewald Summation. We conduct\nextensive experiments on three long-range graph benchmarks, covering both\ngraph-level and link-level tasks on molecular graphs. We empirically justify\nthat our method can be equipped with an arbitrary GNN and help to capture LRI.",
            "author": [
                "Xuan Li",
                "Zhanke Zhou",
                "Jiangchao Yao",
                "Yu Rong",
                "Lu Zhang",
                "Bo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01276v2",
                "http://arxiv.org/pdf/2311.01276v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01267v1",
            "title": "UniFolding: Towards Sample-efficient, Scalable, and Generalizable\n  Robotic Garment Folding",
            "updated": "2023-11-02T14:25:10Z",
            "published": "2023-11-02T14:25:10Z",
            "summary": "This paper explores the development of UniFolding, a sample-efficient,\nscalable, and generalizable robotic system for unfolding and folding various\ngarments. UniFolding employs the proposed UFONet neural network to integrate\nunfolding and folding decisions into a single policy model that is adaptable to\ndifferent garment types and states. The design of UniFolding is based on a\ngarment's partial point cloud, which aids in generalization and reduces\nsensitivity to variations in texture and shape. The training pipeline\nprioritizes low-cost, sample-efficient data collection. Training data is\ncollected via a human-centric process with offline and online stages. The\noffline stage involves human unfolding and folding actions via Virtual Reality,\nwhile the online stage utilizes human-in-the-loop learning to fine-tune the\nmodel in a real-world setting. The system is tested on two garment types:\nlong-sleeve and short-sleeve shirts. Performance is evaluated on 20 shirts with\nsignificant variations in textures, shapes, and materials. More experiments and\nvideos can be found in the supplementary materials and on the website:\nhttps://unifolding.robotflow.ai",
            "author": [
                "Han Xue",
                "Yutong Li",
                "Wenqiang Xu",
                "Huanyu Li",
                "Dongzhe Zheng",
                "Cewu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01267v1",
                "http://arxiv.org/pdf/2311.01267v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12866v1",
            "title": "Modular Blended Attention Network for Video Question Answering",
            "updated": "2023-11-02T14:22:17Z",
            "published": "2023-11-02T14:22:17Z",
            "summary": "In multimodal machine learning tasks, it is due to the complexity of the\nassignments that the network structure, in most cases, is assembled in a\nsophisticated way. The holistic architecture can be separated into several\nlogical parts according to the respective ends that the modules are devised to\nachieve. As the number of modalities of information representation increases,\nconstructing ad hoc subnetworks for processing the data from divergent\nmodalities while mediating the fusion of different information types has become\na cumbersome and expensive problem. In this paper, we present an approach to\nfacilitate the question with a reusable and composable neural unit; by\nconnecting the units in series or parallel, the arduous network constructing of\nmultimodal machine learning tasks will be accomplished in a much\nstraightforward way. Additionally, through parameter sharing (weights\nreplication) among the units, the space complexity will be significantly\nreduced. We have conducted experiments on three commonly used datasets; our\nmethod achieves impressive performance compared to several video QA baselines.",
            "author": [
                "Mingjie Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12866v1",
                "http://arxiv.org/pdf/2311.12866v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01258v1",
            "title": "Formal Methods for Autonomous Systems",
            "updated": "2023-11-02T14:18:43Z",
            "published": "2023-11-02T14:18:43Z",
            "summary": "Formal methods refer to rigorous, mathematical approaches to system\ndevelopment and have played a key role in establishing the correctness of\nsafety-critical systems. The main building blocks of formal methods are models\nand specifications, which are analogous to behaviors and requirements in system\ndesign and give us the means to verify and synthesize system behaviors with\nformal guarantees.\n  This monograph provides a survey of the current state of the art on\napplications of formal methods in the autonomous systems domain. We consider\ncorrect-by-construction synthesis under various formulations, including closed\nsystems, reactive, and probabilistic settings. Beyond synthesizing systems in\nknown environments, we address the concept of uncertainty and bound the\nbehavior of systems that employ learning using formal methods. Further, we\nexamine the synthesis of systems with monitoring, a mitigation technique for\nensuring that once a system deviates from expected behavior, it knows a way of\nreturning to normalcy. We also show how to overcome some limitations of formal\nmethods themselves with learning. We conclude with future directions for formal\nmethods in reinforcement learning, uncertainty, privacy, explainability of\nformal methods, and regulation and certification.",
            "author": [
                "Tichakorn Wongpiromsarn",
                "Mahsa Ghasemi",
                "Murat Cubuktepe",
                "Georgios Bakirtzis",
                "Steven Carr",
                "Mustafa O. Karabag",
                "Cyrus Neary",
                "Parham Gohari",
                "Ufuk Topcu"
            ],
            "link": [
                "http://dx.doi.org/10.1561/2600000029",
                "http://arxiv.org/abs/2311.01258v1",
                "http://arxiv.org/pdf/2311.01258v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01256v1",
            "title": "An energy-based comparative analysis of common approaches to text\n  classification in the Legal domain",
            "updated": "2023-11-02T14:16:48Z",
            "published": "2023-11-02T14:16:48Z",
            "summary": "Most Machine Learning research evaluates the best solutions in terms of\nperformance. However, in the race for the best performing model, many important\naspects are often overlooked when, on the contrary, they should be carefully\nconsidered. In fact, sometimes the gaps in performance between different\napproaches are neglectable, whereas factors such as production costs, energy\nconsumption, and carbon footprint must take into consideration. Large Language\nModels (LLMs) are extensively adopted to address NLP problems in academia and\nindustry. In this work, we present a detailed quantitative comparison of LLM\nand traditional approaches (e.g. SVM) on the LexGLUE benchmark, which takes\ninto account both performance (standard indices) and alternative metrics such\nas timing, power consumption and cost, in a word: the carbon-footprint. In our\nanalysis, we considered the prototyping phase (model selection by\ntraining-validation-test iterations) and in-production phases separately, since\nthey follow different implementation procedures and also require different\nresources. The results indicate that very often, the simplest algorithms\nachieve performance very close to that of large LLMs but with very low power\nconsumption and lower resource demands. The results obtained could suggest\ncompanies to include additional evaluations in the choice of Machine Learning\n(ML) solutions.",
            "author": [
                "Sinan Gultekin",
                "Achille Globo",
                "Andrea Zugarini",
                "Marco Ernandes",
                "Leonardo Rigutini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01256v1",
                "http://arxiv.org/pdf/2311.01256v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01254v1",
            "title": "Human participants in AI research: Ethics and transparency in practice",
            "updated": "2023-11-02T14:12:21Z",
            "published": "2023-11-02T14:12:21Z",
            "summary": "In recent years, research involving human participants has been critical to\nadvances in artificial intelligence (AI) and machine learning (ML),\nparticularly in the areas of conversational, human-compatible, and cooperative\nAI. For example, around 12% and 6% of publications at recent AAAI and NeurIPS\nconferences indicate the collection of original human data, respectively. Yet\nAI and ML researchers lack guidelines for ethical, transparent research\npractices with human participants. Fewer than one out of every four of these\nAAAI and NeurIPS papers provide details of ethical review, the collection of\ninformed consent, or participant compensation. This paper aims to bridge this\ngap by exploring normative similarities and differences between AI research and\nrelated fields that involve human participants. Though psychology,\nhuman-computer interaction, and other adjacent fields offer historic lessons\nand helpful insights, AI research raises several specific\nconcerns$\\unicode{x2014}$namely, participatory design, crowdsourced dataset\ndevelopment, and an expansive role of corporations$\\unicode{x2014}$that\nnecessitate a contextual ethics framework. To address these concerns, this\npaper outlines a set of guidelines for ethical and transparent practice with\nhuman participants in AI and ML research. These guidelines can be found in\nSection 4 on pp. 4$\\unicode{x2013}$7.",
            "author": [
                "Kevin R. McKee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01254v1",
                "http://arxiv.org/pdf/2311.01254v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01252v1",
            "title": "Sanitized Clustering against Confounding Bias",
            "updated": "2023-11-02T14:10:14Z",
            "published": "2023-11-02T14:10:14Z",
            "summary": "Real-world datasets inevitably contain biases that arise from different\nsources or conditions during data collection. Consequently, such inconsistency\nitself acts as a confounding factor that disturbs the cluster analysis.\nExisting methods eliminate the biases by projecting data onto the orthogonal\ncomplement of the subspace expanded by the confounding factor before\nclustering. Therein, the interested clustering factor and the confounding\nfactor are coarsely considered in the raw feature space, where the correlation\nbetween the data and the confounding factor is ideally assumed to be linear for\nconvenient solutions. These approaches are thus limited in scope as the data in\nreal applications is usually complex and non-linearly correlated with the\nconfounding factor. This paper presents a new clustering framework named\nSanitized Clustering Against confounding Bias (SCAB), which removes the\nconfounding factor in the semantic latent space of complex data through a\nnon-linear dependence measure. To be specific, we eliminate the bias\ninformation in the latent space by minimizing the mutual information between\nthe confounding factor and the latent representation delivered by Variational\nAuto-Encoder (VAE). Meanwhile, a clustering module is introduced to cluster\nover the purified latent representations. Extensive experiments on complex\ndatasets demonstrate that our SCAB achieves a significant gain in clustering\nperformance by removing the confounding bias. The code is available at\n\\url{https://github.com/EvaFlower/SCAB}.",
            "author": [
                "Yinghua Yao",
                "Yuangang Pan",
                "Jing Li",
                "Ivor W. Tsang",
                "Xin Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01252v1",
                "http://arxiv.org/pdf/2311.01252v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01253v1",
            "title": "A Concept for User-Centered Delegation of Abstract High-Level Tasks to\n  Cobots for Flexible Lot Sizes",
            "updated": "2023-11-02T14:10:14Z",
            "published": "2023-11-02T14:10:14Z",
            "summary": "Technical advances in collaborative robots (cobots) are making them\nincreasingly attractive to companies. However, many human operators are not\ntrained to program complex machines. Instead, humans are used to communicating\nwith each other on a task-based level rather than through specific\ninstructions, as is common with machines. The gap between low-level\ninstruction-based and high-level task-based communication leads to low values\nfor usability scores of teach pendant programming. As a solution, we propose a\ntask-based interaction concept that allows human operators to delegate a\ncomplex task to a machine without programming by specifying a task via\ntriplets. The concept is based on task decomposition and a reasoning system\nusing a cognitive architecture. The approach is evaluated in an industrial use\ncase where mineral cast basins have to be sanded by a cobot in a crafts\nenterprise.",
            "author": [
                "Moritz Schmidt",
                "Claudia Meitinger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01253v1",
                "http://arxiv.org/pdf/2311.01253v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01248v1",
            "title": "Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation\n  Learning with Force Matching",
            "updated": "2023-11-02T14:02:42Z",
            "published": "2023-11-02T14:02:42Z",
            "summary": "Optical tactile sensors have emerged as an effective means to acquire dense\ncontact information during robotic manipulation. A recently-introduced\n`see-through-your-skin' (STS) variant of this type of sensor has both visual\nand tactile modes, enabled by leveraging a semi-transparent surface and\ncontrollable lighting. In this work, we investigate the benefits of pairing\nvisuotactile sensing with imitation learning for contact-rich manipulation\ntasks. First, we use tactile force measurements and a novel algorithm during\nkinesthetic teaching to yield a force profile that better matches that of the\nhuman demonstrator. Second, we add visual/tactile STS mode switching as a\ncontrol policy output, simplifying the application of the sensor. Finally, we\nstudy multiple observation configurations to compare and contrast the value of\nvisual/tactile data (both with and without mode switching) with visual data\nfrom a wrist-mounted eye-in-hand camera. We perform an extensive series of\nexperiments on a real robotic manipulator with door-opening and closing tasks,\nincluding over 3,000 real test episodes. Our results highlight the importance\nof tactile sensing for imitation learning, both for data collection to allow\nforce matching, and for policy execution to allow accurate task feedback.",
            "author": [
                "Trevor Ablett",
                "Oliver Limoyo",
                "Adam Sigal",
                "Affan Jilani",
                "Jonathan Kelly",
                "Kaleem Siddiqi",
                "Francois Hogan",
                "Gregory Dudek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01248v1",
                "http://arxiv.org/pdf/2311.01248v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01241v1",
            "title": "Exploring Deep Learning Image Super-Resolution for Iris Recognition",
            "updated": "2023-11-02T13:57:48Z",
            "published": "2023-11-02T13:57:48Z",
            "summary": "In this work we test the ability of deep learning methods to provide an\nend-to-end mapping between low and high resolution images applying it to the\niris recognition problem. Here, we propose the use of two deep learning\nsingle-image super-resolution approaches: Stacked Auto-Encoders (SAE) and\nConvolutional Neural Networks (CNN) with the most possible lightweight\nstructure to achieve fast speed, preserve local information and reduce\nartifacts at the same time. We validate the methods with a database of 1.872\nnear-infrared iris images with quality assessment and recognition experiments\nshowing the superiority of deep learning approaches over the compared\nalgorithms.",
            "author": [
                "Eduardo Ribeiro",
                "Andreas Uhl",
                "Fernando Alonso-Fernandez",
                "Reuben A. Farrugia"
            ],
            "link": [
                "http://dx.doi.org/10.23919/EUSIPCO.2017.8081595",
                "http://arxiv.org/abs/2311.01241v1",
                "http://arxiv.org/pdf/2311.01241v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01240v2",
            "title": "FacadeNet: Conditional Facade Synthesis via Selective Editing",
            "updated": "2023-11-03T11:08:03Z",
            "published": "2023-11-02T13:57:43Z",
            "summary": "We introduce FacadeNet, a deep learning approach for synthesizing building\nfacade images from diverse viewpoints. Our method employs a conditional GAN,\ntaking a single view of a facade along with the desired viewpoint information\nand generates an image of the facade from the distinct viewpoint. To precisely\nmodify view-dependent elements like windows and doors while preserving the\nstructure of view-independent components such as walls, we introduce a\nselective editing module. This module leverages image embeddings extracted from\na pre-trained vision transformer. Our experiments demonstrated state-of-the-art\nperformance on building facade generation, surpassing alternative methods.",
            "author": [
                "Yiangos Georgiou",
                "Marios Loizou",
                "Tom Kelly",
                "Melinos Averkiou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01240v2",
                "http://arxiv.org/pdf/2311.01240v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02108v1",
            "title": "A Virtual Reality Training System for Automotive Engines Assembly and\n  Disassembly",
            "updated": "2023-11-02T13:37:46Z",
            "published": "2023-11-02T13:37:46Z",
            "summary": "Automotive engine assembly and disassembly are common and crucial programs in\nthe automotive industry. Traditional education trains students to learn\nautomotive engine assembly and disassembly in lecture courses and then to\noperate with physical engines, which are generally low effectiveness and high\ncost. In this work, we developed a multi-layer structured Virtual Reality (VR)\nsystem to provide students with training in automotive engine (Buick Verano)\nassembly and disassembly. We designed the VR training system with The VR\ntraining system is designed to have several major features, including\nreplaceable engine parts and reusable tools, friendly user interfaces and\nguidance, and bottom-up designed multi-layer architecture, which can be\nextended to various engine models. The VR system is evaluated with controlled\nexperiments of two groups of students. The results demonstrate that our VR\ntraining system provides remarkable usability in terms of effectiveness and\nefficiency. Currently, our VR system has been demonstrated and employed in the\ncourses of Chinese colleges to train students in automotive engine assembly and\ndisassembly. A free-to-use executable file (Microsoft Windows) and open-source\ncode are available at https://github.com/LadissonLai/SUSTech_VREngine for\nfacilitating the development of VR systems in the automotive industry. Finally,\na video describing the operations in our VR training system is available at\nhttps://www.youtube.com/watch?v=yZe4YTwwAC4",
            "author": [
                "Gongjin Lan",
                "Qiangqiang Lai",
                "Bing Bai",
                "Zirui Zhao",
                "Qi Hao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02108v1",
                "http://arxiv.org/pdf/2311.02108v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01230v1",
            "title": "Multi-Operational Mathematical Derivations in Latent Space",
            "updated": "2023-11-02T13:33:07Z",
            "published": "2023-11-02T13:33:07Z",
            "summary": "This paper investigates the possibility of approximating multiple\nmathematical operations in latent space for expression derivation. To this end,\nwe introduce different multi-operational representation paradigms, modelling\nmathematical operations as explicit geometric transformations. By leveraging a\nsymbolic engine, we construct a large-scale dataset comprising 1.7M derivation\nsteps stemming from 61K premises and 6 operators, analysing the properties of\neach paradigm when instantiated with state-of-the-art neural encoders.\nSpecifically, we investigate how different encoding mechanisms can approximate\nequational reasoning in latent space, exploring the trade-off between learning\ndifferent operators and specialising within single operations, as well as the\nability to support multi-step derivations and out-of-distribution\ngeneralisation. Our empirical analysis reveals that the multi-operational\nparadigm is crucial for disentangling different operators, while discriminating\nthe conclusions for a single operation is achievable in the original expression\nencoder. Moreover, we show that architectural choices can heavily affect the\ntraining dynamics, structural organisation, and generalisation of the latent\nspace, resulting in significant variations across paradigms and classes of\nencoders.",
            "author": [
                "Marco Valentino",
                "Jordan Meadows",
                "Lan Zhang",
                "Andr\u00e9 Freitas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01230v1",
                "http://arxiv.org/pdf/2311.01230v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01229v1",
            "title": "Theoretical Analysis of Impact of Delayed Updates on Decentralized\n  Federated Learning",
            "updated": "2023-11-02T13:29:23Z",
            "published": "2023-11-02T13:29:23Z",
            "summary": "Decentralized Federated learning is a distributed edge intelligence framework\nby exchanging parameter updates instead of training data among participators,\nin order to retrain or fine-tune deep learning models for mobile intelligent\napplications. Considering the various topologies of edge networks in mobile\ninternet, the impact of transmission delay of updates during model training is\nnon-negligible for data-intensive intelligent applications on mobile devices,\ne.g., intelligent medical services, automated driving vehicles, etc.. To\naddress this problem, we analyze the impact of delayed updates for\ndecentralized federated learning, and provide a theoretical bound for these\nupdates to achieve model convergence. Within the theoretical bound of updating\nperiod, the latest versions for the delayed updates are reused to continue\naggregation, in case the model parameters from a specific neighbor are not\ncollected or updated in time.",
            "author": [
                "Yong Zeng",
                "Siyuan Liu",
                "Zhiwei Xu",
                "Jie Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01229v1",
                "http://arxiv.org/pdf/2311.01229v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01227v1",
            "title": "Robust Feature Learning and Global Variance-Driven Classifier Alignment\n  for Long-Tail Class Incremental Learning",
            "updated": "2023-11-02T13:28:53Z",
            "published": "2023-11-02T13:28:53Z",
            "summary": "This paper introduces a two-stage framework designed to enhance long-tail\nclass incremental learning, enabling the model to progressively learn new\nclasses, while mitigating catastrophic forgetting in the context of long-tailed\ndata distributions. Addressing the challenge posed by the under-representation\nof tail classes in long-tail class incremental learning, our approach achieves\nclassifier alignment by leveraging global variance as an informative measure\nand class prototypes in the second stage. This process effectively captures\nclass properties and eliminates the need for data balancing or additional layer\ntuning. Alongside traditional class incremental learning losses in the first\nstage, the proposed approach incorporates mixup classes to learn robust feature\nrepresentations, ensuring smoother boundaries. The proposed framework can\nseamlessly integrate as a module with any class incremental learning method to\neffectively handle long-tail class incremental learning scenarios. Extensive\nexperimentation on the CIFAR-100 and ImageNet-Subset datasets validates the\napproach's efficacy, showcasing its superiority over state-of-the-art\ntechniques across various long-tail CIL settings.",
            "author": [
                "Jayateja Kalla",
                "Soma Biswas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01227v1",
                "http://arxiv.org/pdf/2311.01227v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01224v1",
            "title": "EISim: A Platform for Simulating Intelligent Edge Orchestration\n  Solutions",
            "updated": "2023-11-02T13:24:04Z",
            "published": "2023-11-02T13:24:04Z",
            "summary": "To support the stringent requirements of the future intelligent and\ninteractive applications, intelligence needs to become an essential part of the\nresource management in the edge environment. Developing intelligent\norchestration solutions is a challenging and arduous task, where the evaluation\nand comparison of the proposed solution is a focal point. Simulation is\ncommonly used to evaluate and compare proposed solutions. However, the\ncurrently existing, openly available simulators are lacking in terms of\nsupporting the research on intelligent edge orchestration methods. To address\nthis need, this article presents a simulation platform called Edge Intelligence\nSimulator (EISim), the purpose of which is to facilitate the research on\nintelligent edge orchestration solutions. EISim is extended from an existing\nfog simulator called PureEdgeSim. In its current form, EISim supports\nsimulating deep reinforcement learning based solutions and different\norchestration control topologies in scenarios related to task offloading and\nresource pricing on edge. The platform also includes additional tools for\ncreating simulation environments, running simulations for agent training and\nevaluation, and plotting results.",
            "author": [
                "Henna Kokkonen",
                "Susanna Pirttikangas",
                "Lauri Lov\u00e9n"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01224v1",
                "http://arxiv.org/pdf/2311.01224v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01223v1",
            "title": "Diffusion Models for Reinforcement Learning: A Survey",
            "updated": "2023-11-02T13:23:39Z",
            "published": "2023-11-02T13:23:39Z",
            "summary": "Diffusion models have emerged as a prominent class of generative models,\nsurpassing previous methods regarding sample quality and training stability.\nRecent works have shown the advantages of diffusion models in improving\nreinforcement learning (RL) solutions, including as trajectory planners,\nexpressive policy classes, data synthesizers, etc. This survey aims to provide\nan overview of the advancements in this emerging field and hopes to inspire new\navenues of research. First, we examine several challenges encountered by\ncurrent RL algorithms. Then, we present a taxonomy of existing methods based on\nthe roles played by diffusion models in RL and explore how the existing\nchallenges are addressed. We further outline successful applications of\ndiffusion models in various RL-related tasks while discussing the limitations\nof current approaches. Finally, we conclude the survey and offer insights into\nfuture research directions, focusing on enhancing model performance and\napplying diffusion models to broader tasks. We are actively maintaining a\nGitHub repository for papers and other related resources in applying diffusion\nmodels in RL: https://github.com/apexrl/Diff4RLSurvey .",
            "author": [
                "Zhengbang Zhu",
                "Hanye Zhao",
                "Haoran He",
                "Yichao Zhong",
                "Shenyu Zhang",
                "Yong Yu",
                "Weinan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01223v1",
                "http://arxiv.org/pdf/2311.01223v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04919v1",
            "title": "The Impact of Preference Agreement in Reinforcement Learning from Human\n  Feedback: A Case Study in Summarization",
            "updated": "2023-11-02T13:21:23Z",
            "published": "2023-11-02T13:21:23Z",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) can be used to capture\ncomplex and nuanced properties of text generation quality. As a result, the\ntask of text summarization has been identified as a good candidate for this\nprocess. In this paper, we explore how preference agreement impacts the\nefficacy of RLHF for summarization. We show that sampling human preferences to\ninclude a range of annotator agreement results in (1) higher accuracy reward\nmodels and (2) alters the characteristics of quality captured. We additionally\nshow improvements in downstream generation when using a reward model trained\nwith a range of preference agreements. Our contributions have implications for\nthe design of synthetic datasets as well as the importance of considering\nquality differentials in comparison-based data.",
            "author": [
                "Sian Gooding",
                "Hassan Mansoor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04919v1",
                "http://arxiv.org/pdf/2311.04919v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01217v1",
            "title": "The learning effects of subsidies to bundled goods: a semiparametric\n  approach",
            "updated": "2023-11-02T13:18:57Z",
            "published": "2023-11-02T13:18:57Z",
            "summary": "Can temporary subsidies to bundles induce long-run changes in demand due to\nlearning about the relative quality of one of its constituent goods? This paper\nprovides theoretical and experimental evidence on the role of this mechanism.\nTheoretically, we introduce a model where an agent learns about the quality of\nan innovation on an essential good through consumption. Our results show that\nthe contemporaneous effect of a one-off subsidy to a bundle that contains the\ninnovation may be decomposed into a direct price effect, and an indirect\nlearning motive, whereby an agent leverages the discount to increase the\ninformational bequest left to her future selves. We then assess the predictions\nof our theory in a randomised experiment in a ridesharing platform. The\nexperiment provided two-week discounts for car trips integrating with a train\nor metro station (a bundle). Given the heavy-tailed nature of our data, we\nfollow \\cite{Athey2023} and, motivated by our theory, propose a semiparametric\nmodel for treatment effects that enables the construction of more efficient\nestimators. We introduce a statistically efficient estimator for our model by\nrelying on L-moments, a robust alternative to standard moments. Our estimator\nimmediately yields a specification test for the semiparametric model; moreover,\nin our adopted parametrisation, it can be easily computed through generalized\nleast squares. Our empirical results indicate that a two-week 50\\% discount on\ncar trips integrating with train/metro leads to a contemporaneous increase in\nthe demand for integrated rides, and, consistent with our learning model,\npersistent changes in the mean and dispersion of nonintegrated rides. These\neffects persist for over four months after the discount. A simple calibration\nof our model shows that around 40\\% to 50\\% of the estimated contemporaneous\nincrease in integrated rides may be attributed to a learning motive.",
            "author": [
                "Luis Alvarez",
                "Ciro Biderman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01217v1",
                "http://arxiv.org/pdf/2311.01217v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01214v1",
            "title": "High-Quality Animatable Dynamic Garment Reconstruction from Monocular\n  Videos",
            "updated": "2023-11-02T13:16:27Z",
            "published": "2023-11-02T13:16:27Z",
            "summary": "Much progress has been made in reconstructing garments from an image or a\nvideo. However, none of existing works meet the expectations of digitizing\nhigh-quality animatable dynamic garments that can be adjusted to various unseen\nposes. In this paper, we propose the first method to recover high-quality\nanimatable dynamic garments from monocular videos without depending on scanned\ndata. To generate reasonable deformations for various unseen poses, we propose\na learnable garment deformation network that formulates the garment\nreconstruction task as a pose-driven deformation problem. To alleviate the\nambiguity estimating 3D garments from monocular videos, we design a\nmulti-hypothesis deformation module that learns spatial representations of\nmultiple plausible deformations. Experimental results on several public\ndatasets demonstrate that our method can reconstruct high-quality dynamic\ngarments with coherent surface details, which can be easily animated under\nunseen poses. The code will be provided for research purposes.",
            "author": [
                "Xiongzheng Li",
                "Jinsong Zhang",
                "Yu-Kun Lai",
                "Jingyu Yang",
                "Kun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01214v1",
                "http://arxiv.org/pdf/2311.01214v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16133v2",
            "title": "Effective Quantization for Diffusion Models on CPUs",
            "updated": "2023-11-29T08:24:57Z",
            "published": "2023-11-02T13:14:01Z",
            "summary": "Diffusion models have gained popularity for generating images from textual\ndescriptions. Nonetheless, the substantial need for computational resources\ncontinues to present a noteworthy challenge, contributing to time-consuming\nprocesses. Quantization, a technique employed to compress deep learning models\nfor enhanced efficiency, presents challenges when applied to diffusion models.\nThese models are notably more sensitive to quantization compared to other model\ntypes, potentially resulting in a degradation of image quality. In this paper,\nwe introduce a novel approach to quantize the diffusion models by leveraging\nboth quantization-aware training and distillation. Our results show the\nquantized models can maintain the high image quality while demonstrating the\ninference efficiency on CPUs. The code is publicly available at:\nhttps://github.com/intel/intel-extension-for-transformers.",
            "author": [
                "Hanwen Chang",
                "Haihao Shen",
                "Yiyang Cai",
                "Xinyu Ye",
                "Zhenzhong Xu",
                "Wenhua Cheng",
                "Kaokao Lv",
                "Weiwei Zhang",
                "Yintong Lu",
                "Heng Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16133v2",
                "http://arxiv.org/pdf/2311.16133v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01212v1",
            "title": "Multi-view Relation Learning for Cross-domain Few-shot Hyperspectral\n  Image Classification",
            "updated": "2023-11-02T13:06:03Z",
            "published": "2023-11-02T13:06:03Z",
            "summary": "Cross-domain few-shot hyperspectral image classification focuses on learning\nprior knowledge from a large number of labeled samples from source domain and\nthen transferring the knowledge to the tasks which contain only few labeled\nsamples in target domains. Following the metric-based manner, many current\nmethods first extract the features of the query and support samples, and then\ndirectly predict the classes of query samples according to their distance to\nthe support samples or prototypes. The relations between samples have not been\nfully explored and utilized. Different from current works, this paper proposes\nto learn sample relations from different views and take them into the model\nlearning process, to improve the cross-domain few-shot hyperspectral image\nclassification. Building on current DCFSL method which adopts a domain\ndiscriminator to deal with domain-level distribution difference, the proposed\nmethod applys contrastive learning to learn the class-level sample relations to\nobtain more discriminable sample features. In addition, it adopts a transformer\nbased cross-attention learning module to learn the set-level sample relations\nand acquire the attentions from query samples to support samples. Our\nexperimental results have demonstrated the contribution of the multi-view\nrelation learning mechanism for few-shot hyperspectral image classification\nwhen compared with the state of the art methods.",
            "author": [
                "Chun Liu",
                "Longwei Yang",
                "Zheng Li",
                "Wei Yang",
                "Zhigang Han",
                "Jianzhong Guo",
                "Junyong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01212v1",
                "http://arxiv.org/pdf/2311.01212v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01206v1",
            "title": "How Does China's Household Portfolio Selection Vary with Financial\n  Inclusion?",
            "updated": "2023-11-02T13:00:08Z",
            "published": "2023-11-02T13:00:08Z",
            "summary": "Portfolio underdiversification is one of the most costly losses accumulated\nover a household's life cycle. We provide new evidence on the impact of\nfinancial inclusion services on households' portfolio choice and investment\nefficiency using 2015, 2017, and 2019 survey data for Chinese households. We\nhypothesize that higher financial inclusion penetration encourages households\nto participate in the financial market, leading to better portfolio\ndiversification and investment efficiency. The results of the baseline model\nare consistent with our proposed hypothesis that higher accessibility to\nfinancial inclusion encourages households to invest in risky assets and\nincreases investment efficiency. We further estimate a dynamic double machine\nlearning model to quantitatively investigate the non-linear causal effects and\ntrack the dynamic change of those effects over time. We observe that the\nmarginal effect increases over time, and those effects are more pronounced\namong low-asset, less-educated households and those located in non-rural areas,\nexcept for investment efficiency for high-asset households.",
            "author": [
                "Yong Bian",
                "Xiqian Wang",
                "Qin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01206v1",
                "http://arxiv.org/pdf/2311.01206v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01205v1",
            "title": "Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go\n  Indifferent",
            "updated": "2023-11-02T12:59:32Z",
            "published": "2023-11-02T12:59:32Z",
            "summary": "Prior attacks on graph neural networks have mostly focused on graph poisoning\nand evasion, neglecting the network's weights and biases. Traditional\nweight-based fault injection attacks, such as bit flip attacks used for\nconvolutional neural networks, do not consider the unique properties of graph\nneural networks. We propose the Injectivity Bit Flip Attack, the first bit flip\nattack designed specifically for graph neural networks. Our attack targets the\nlearnable neighborhood aggregation functions in quantized message passing\nneural networks, degrading their ability to distinguish graph structures and\nlosing the expressivity of the Weisfeiler-Lehman test. Our findings suggest\nthat exploiting mathematical properties specific to certain graph neural\nnetwork architectures can significantly increase their vulnerability to bit\nflip attacks. Injectivity Bit Flip Attacks can degrade the maximal expressive\nGraph Isomorphism Networks trained on various graph property prediction\ndatasets to random output by flipping only a small fraction of the network's\nbits, demonstrating its higher destructive power compared to a bit flip attack\ntransferred from convolutional neural networks. Our attack is transparent and\nmotivated by theoretical insights which are confirmed by extensive empirical\nresults.",
            "author": [
                "Lorenz Kummer",
                "Samir Moustafa",
                "Nils N. Kriege",
                "Wilfried N. Gansterer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01205v1",
                "http://arxiv.org/pdf/2311.01205v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01202v1",
            "title": "Cross-Modal Information-Guided Network using Contrastive Learning for\n  Point Cloud Registration",
            "updated": "2023-11-02T12:56:47Z",
            "published": "2023-11-02T12:56:47Z",
            "summary": "The majority of point cloud registration methods currently rely on extracting\nfeatures from points. However, these methods are limited by their dependence on\ninformation obtained from a single modality of points, which can result in\ndeficiencies such as inadequate perception of global features and a lack of\ntexture information. Actually, humans can employ visual information learned\nfrom 2D images to comprehend the 3D world. Based on this fact, we present a\nnovel Cross-Modal Information-Guided Network (CMIGNet), which obtains global\nshape perception through cross-modal information to achieve precise and robust\npoint cloud registration. Specifically, we first incorporate the projected\nimages from the point clouds and fuse the cross-modal features using the\nattention mechanism. Furthermore, we employ two contrastive learning\nstrategies, namely overlapping contrastive learning and cross-modal contrastive\nlearning. The former focuses on features in overlapping regions, while the\nlatter emphasizes the correspondences between 2D and 3D features. Finally, we\npropose a mask prediction module to identify keypoints in the point clouds.\nExtensive experiments on several benchmark datasets demonstrate that our\nnetwork achieves superior registration performance.",
            "author": [
                "Yifan Xie",
                "Jihua Zhu",
                "Shiqi Li",
                "Pengcheng Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01202v1",
                "http://arxiv.org/pdf/2311.01202v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01201v1",
            "title": "Federated Learning on Edge Sensing Devices: A Review",
            "updated": "2023-11-02T12:55:26Z",
            "published": "2023-11-02T12:55:26Z",
            "summary": "The ability to monitor ambient characteristics, interact with them, and\nderive information about the surroundings has been made possible by the rapid\nproliferation of edge sensing devices like IoT, mobile, and wearable devices\nand their measuring capabilities with integrated sensors. Even though these\ndevices are small and have less capacity for data storage and processing, they\nproduce vast amounts of data. Some example application areas where sensor data\nis collected and processed include healthcare, environmental (including air\nquality and pollution levels), automotive, industrial, aerospace, and\nagricultural applications. These enormous volumes of sensing data collected\nfrom the edge devices are analyzed using a variety of Machine Learning (ML) and\nDeep Learning (DL) approaches. However, analyzing them on the cloud or a server\npresents challenges related to privacy, hardware, and connectivity limitations.\nFederated Learning (FL) is emerging as a solution to these problems while\npreserving privacy by jointly training a model without sharing raw data. In\nthis paper, we review the FL strategies from the perspective of edge sensing\ndevices to get over the limitations of conventional machine learning\ntechniques. We focus on the key FL principles, software frameworks, and\ntestbeds. We also explore the current sensor technologies, properties of the\nsensing devices and sensing applications where FL is utilized. We conclude with\na discussion on open issues and future research directions on FL for further\nstudies",
            "author": [
                "Berrenur Saylam",
                "\u00d6zlem Durmaz \u0130ncel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01201v1",
                "http://arxiv.org/pdf/2311.01201v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01200v1",
            "title": "A Study of Continual Learning Under Language Shift",
            "updated": "2023-11-02T12:54:50Z",
            "published": "2023-11-02T12:54:50Z",
            "summary": "The recent increase in data and model scale for language model pre-training\nhas led to huge training costs. In scenarios where new data become available\nover time, updating a model instead of fully retraining it would therefore\nprovide significant gains. In this paper, we study the benefits and downsides\nof updating a language model when new data comes from new languages - the case\nof continual learning under language shift. Starting from a monolingual English\nlanguage model, we incrementally add data from Norwegian and Icelandic to\ninvestigate how forward and backward transfer effects depend on the\npre-training order and characteristics of languages, for different model sizes\nand learning rate schedulers. Our results show that, while forward transfer is\nlargely positive and independent of language order, backward transfer can be\neither positive or negative depending on the order and characteristics of new\nlanguages. To explain these patterns we explore several language similarity\nmetrics and find that syntactic similarity appears to have the best correlation\nwith our results.",
            "author": [
                "Evangelia Gogoulou",
                "Timoth\u00e9e Lesort",
                "Magnus Boman",
                "Joakim Nivre"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01200v1",
                "http://arxiv.org/pdf/2311.01200v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01198v1",
            "title": "Gaussian Processes on Cellular Complexes",
            "updated": "2023-11-02T12:49:14Z",
            "published": "2023-11-02T12:49:14Z",
            "summary": "In recent years, there has been considerable interest in developing machine\nlearning models on graphs in order to account for topological inductive biases.\nIn particular, recent attention was given to Gaussian processes on such\nstructures since they can additionally account for uncertainty. However, graphs\nare limited to modelling relations between two vertices. In this paper, we go\nbeyond this dyadic setting and consider polyadic relations that include\ninteractions between vertices, edges and one of their generalisations, known as\ncells. Specifically, we propose Gaussian processes on cellular complexes, a\ngeneralisation of graphs that captures interactions between these higher-order\ncells. One of our key contributions is the derivation of two novel kernels, one\nthat generalises the graph Mat\\'ern kernel and one that additionally mixes\ninformation of different cell types.",
            "author": [
                "Mathieu Alain",
                "So Takao",
                "Brooks Paige",
                "Marc Peter Deisenroth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01198v1",
                "http://arxiv.org/pdf/2311.01198v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01196v1",
            "title": "Combating Bilateral Edge Noise for Robust Link Prediction",
            "updated": "2023-11-02T12:47:49Z",
            "published": "2023-11-02T12:47:49Z",
            "summary": "Although link prediction on graphs has achieved great success with the\ndevelopment of graph neural networks (GNNs), the potential robustness under the\nedge noise is still less investigated. To close this gap, we first conduct an\nempirical study to disclose that the edge noise bilaterally perturbs both input\ntopology and target label, yielding severe performance degradation and\nrepresentation collapse. To address this dilemma, we propose an\ninformation-theory-guided principle, Robust Graph Information Bottleneck\n(RGIB), to extract reliable supervision signals and avoid representation\ncollapse. Different from the basic information bottleneck, RGIB further\ndecouples and balances the mutual dependence among graph topology, target\nlabels, and representation, building new learning objectives for robust\nrepresentation against the bilateral noise. Two instantiations, RGIB-SSL and\nRGIB-REP, are explored to leverage the merits of different methodologies, i.e.,\nself-supervised learning and data reparameterization, for implicit and explicit\ndata denoising, respectively. Extensive experiments on six datasets and three\nGNNs with diverse noisy scenarios verify the effectiveness of our RGIB\ninstantiations. The code is publicly available at:\nhttps://github.com/tmlr-group/RGIB.",
            "author": [
                "Zhanke Zhou",
                "Jiangchao Yao",
                "Jiaxu Liu",
                "Xiawei Guo",
                "Quanming Yao",
                "Li He",
                "Liang Wang",
                "Bo Zheng",
                "Bo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01196v1",
                "http://arxiv.org/pdf/2311.01196v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01195v1",
            "title": "Batch Bayesian Optimization for Replicable Experimental Design",
            "updated": "2023-11-02T12:46:03Z",
            "published": "2023-11-02T12:46:03Z",
            "summary": "Many real-world experimental design problems (a) evaluate multiple\nexperimental conditions in parallel and (b) replicate each condition multiple\ntimes due to large and heteroscedastic observation noise. Given a fixed total\nbudget, this naturally induces a trade-off between evaluating more unique\nconditions while replicating each of them fewer times vs. evaluating fewer\nunique conditions and replicating each more times. Moreover, in these problems,\npractitioners may be risk-averse and hence prefer an input with both good\naverage performance and small variability. To tackle both challenges, we\npropose the Batch Thompson Sampling for Replicable Experimental Design\n(BTS-RED) framework, which encompasses three algorithms. Our BTS-RED-Known and\nBTS-RED-Unknown algorithms, for, respectively, known and unknown noise\nvariance, choose the number of replications adaptively rather than\ndeterministically such that an input with a larger noise variance is replicated\nmore times. As a result, despite the noise heteroscedasticity, both algorithms\nenjoy a theoretical guarantee and are asymptotically no-regret. Our\nMean-Var-BTS-RED algorithm aims at risk-averse optimization and is also\nasymptotically no-regret. We also show the effectiveness of our algorithms in\ntwo practical real-world applications: precision agriculture and AutoML.",
            "author": [
                "Zhongxiang Dai",
                "Quoc Phong Nguyen",
                "Sebastian Shenghong Tay",
                "Daisuke Urano",
                "Richalynn Leong",
                "Bryan Kian Hsiang Low",
                "Patrick Jaillet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01195v1",
                "http://arxiv.org/pdf/2311.01195v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01192v1",
            "title": "Semantic Scene Graph Generation Based on an Edge Dual Scene Graph and\n  Message Passing Neural Network",
            "updated": "2023-11-02T12:36:52Z",
            "published": "2023-11-02T12:36:52Z",
            "summary": "Along with generative AI, interest in scene graph generation (SGG), which\ncomprehensively captures the relationships and interactions between objects in\nan image and creates a structured graph-based representation, has significantly\nincreased in recent years. However, relying on object-centric and dichotomous\nrelationships, existing SGG methods have a limited ability to accurately\npredict detailed relationships. To solve these problems, a new approach to the\nmodeling multiobject relationships, called edge dual scene graph generation\n(EdgeSGG), is proposed herein. EdgeSGG is based on a edge dual scene graph and\nDual Message Passing Neural Network (DualMPNN), which can capture rich\ncontextual interactions between unconstrained objects. To facilitate the\nlearning of edge dual scene graphs with a symmetric graph structure, the\nproposed DualMPNN learns both object- and relation-centric features for more\naccurately predicting relation-aware contexts and allows fine-grained\nrelational updates between objects. A comparative experiment with\nstate-of-the-art (SoTA) methods was conducted using two public datasets for SGG\noperations and six metrics for three subtasks. Compared with SoTA approaches,\nthe proposed model exhibited substantial performance improvements across all\nSGG subtasks. Furthermore, experiment on long-tail distributions revealed that\nincorporating the relationships between objects effectively mitigates existing\nlong-tail problems.",
            "author": [
                "Hyeongjin Kim",
                "Sangwon Kim",
                "Jong Taek Lee",
                "Byoung Chul Ko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01192v1",
                "http://arxiv.org/pdf/2311.01192v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01191v1",
            "title": "VIGraph: Self-supervised Learning for Class-Imbalanced Node\n  Classification",
            "updated": "2023-11-02T12:36:19Z",
            "published": "2023-11-02T12:36:19Z",
            "summary": "Class imbalance in graph data poses significant challenges for node\nclassification. Existing methods, represented by SMOTE-based approaches,\npartially alleviate this issue but still exhibit limitations during imbalanced\nscenario construction. Self-supervised learning (SSL) offers a promising\nsolution by synthesizing minority nodes from the data itself, yet its potential\nremains unexplored. In this paper, we analyze the limitations of SMOTE-based\napproaches and introduce VIGraph, a novel SSL model based on the\nself-supervised Variational Graph Auto-Encoder (VGAE) that leverages\nVariational Inference (VI) to generate minority nodes. Specifically, VIGraph\nstrictly adheres to the concept of imbalance when constructing imbalanced\ngraphs and utilizes the generative VGAE to generate minority nodes. Moreover,\nVIGraph introduces a novel Siamese contrastive strategy at the decoding phase\nto improve the overall quality of generated nodes. VIGraph can generate\nhigh-quality nodes without reintegrating them into the original graph,\neliminating the \"Generating, Reintegrating, and Retraining\" process found in\nSMOTE-based methods. Experiments on multiple real-world datasets demonstrate\nthat VIGraph achieves promising results for class-imbalanced node\nclassification tasks.",
            "author": [
                "Yulan Hu",
                "Sheng Ouyang",
                "Zhirui Yang",
                "Yong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01191v1",
                "http://arxiv.org/pdf/2311.01191v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01188v1",
            "title": "Terrain-Informed Self-Supervised Learning: Enhancing Building Footprint\n  Extraction from LiDAR Data with Limited Annotations",
            "updated": "2023-11-02T12:34:23Z",
            "published": "2023-11-02T12:34:23Z",
            "summary": "Estimating building footprint maps from geospatial data is of paramount\nimportance in urban planning, development, disaster management, and various\nother applications. Deep learning methodologies have gained prominence in\nbuilding segmentation maps, offering the promise of precise footprint\nextraction without extensive post-processing. However, these methods face\nchallenges in generalization and label efficiency, particularly in remote\nsensing, where obtaining accurate labels can be both expensive and\ntime-consuming. To address these challenges, we propose terrain-aware\nself-supervised learning, tailored to remote sensing, using digital elevation\nmodels from LiDAR data. We propose to learn a model to differentiate between\nbare Earth and superimposed structures enabling the network to implicitly learn\ndomain-relevant features without the need for extensive pixel-level\nannotations. We test the effectiveness of our approach by evaluating building\nsegmentation performance on test datasets with varying label fractions.\nRemarkably, with only 1% of the labels (equivalent to 25 labeled examples), our\nmethod improves over ImageNet pre-training, showing the advantage of leveraging\nunlabeled data for feature extraction in the domain of remote sensing. The\nperformance improvement is more pronounced in few-shot scenarios and gradually\ncloses the gap with ImageNet pre-training as the label fraction increases. We\ntest on a dataset characterized by substantial distribution shifts and labeling\nerrors to demonstrate the generalizability of our approach. When compared to\nother baselines, including ImageNet pretraining and more complex architectures,\nour approach consistently performs better, demonstrating the efficiency and\neffectiveness of self-supervised terrain-aware feature learning.",
            "author": [
                "Anuja Vats",
                "David V\u00f6lgyes",
                "Martijn Vermeer",
                "Marius Pedersen",
                "Kiran Raja",
                "Daniele S. M. Fantin",
                "Jacob Alexander Hay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01188v1",
                "http://arxiv.org/pdf/2311.01188v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01186v1",
            "title": "Decentralized Federated Learning on the Edge over Wireless Mesh Networks",
            "updated": "2023-11-02T12:33:58Z",
            "published": "2023-11-02T12:33:58Z",
            "summary": "The rapid growth of Internet of Things (IoT) devices has generated vast\namounts of data, leading to the emergence of federated learning as a novel\ndistributed machine learning paradigm. Federated learning enables model\ntraining at the edge, leveraging the processing capacity of edge devices while\npreserving privacy and mitigating data transfer bottlenecks. However, the\nconventional centralized federated learning architecture suffers from a single\npoint of failure and susceptibility to malicious attacks. In this study, we\ndelve into an alternative approach called decentralized federated learning\n(DFL) conducted over a wireless mesh network as the communication backbone. We\nperform a comprehensive network performance analysis using stochastic geometry\ntheory and physical interference models, offering fresh insights into the\nconvergence analysis of DFL. Additionally, we conduct system simulations to\nassess the proposed decentralized architecture under various network parameters\nand different aggregator methods such as FedAvg, Krum and Median methods. Our\nmodel is trained on the widely recognized EMNIST dataset for benchmarking\nhandwritten digit classification. To minimize the model's size at the edge and\nreduce communication overhead, we employ a cutting-edge compression technique\nbased on genetic algorithms. Our simulation results reveal that the compressed\ndecentralized architecture achieves performance comparable to the baseline\ncentralized architecture and traditional DFL in terms of accuracy and average\nloss for our classification task. Moreover, it significantly reduces the size\nof shared models over the wireless channel by compressing participants' local\nmodel sizes to nearly half of their original size compared to the baselines,\neffectively reducing complexity and communication overhead.",
            "author": [
                "Abdelaziz Salama",
                "Achilleas Stergioulis",
                "Syed Ali Zaidi",
                "Des McLernon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01186v1",
                "http://arxiv.org/pdf/2311.01186v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01184v1",
            "title": "A correspondence between the time and space complexity",
            "updated": "2023-11-02T12:31:27Z",
            "published": "2023-11-02T12:31:27Z",
            "summary": "We investigate the correspondence between the time and space recognition\ncomplexity of languages; for this purpose, we will code the long-continued\ncomputations of deterministic two-tape Turing machines by the relatively\nshort-length quantified Boolean formulae. The modified Stockmeyer and Meyer\nmethod will appreciably be used for this simulation. It will be proved using\nthis modeling that the complexity classes $\\mathbf{EXP}$ and $\\mathbf{PSPACE}$\ncoincide; and more generally, the class $(k\\!+\\!1)$-fold Deterministic\nExponential Time equals to the class $k$-fold Deterministic Exponential Space\nfor each $k\\geqslant1$; the space complexity of the languages of the class\n$\\mathbf{P}$ will also be studied. Furthermore, this allows us to slightly\nimprove the early founded lower complexity bound of decidable theories that are\nnontrivial relative to some equivalence relation (this relation may be\nequality) -- each of these theories is consistent with the formula, which\nasserts that there are two non-equivalent elements.\n  Keywords: computational complexity, the coding of computations through\nformulae, exponential time, polynomial space, lower complexity bound of the\nlanguage recognition",
            "author": [
                "Ivan V. Latkin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01184v1",
                "http://arxiv.org/pdf/2311.01184v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.LO",
                "math.LO",
                "68Q15 (Primary), 68Q17, 03D15, 03B70 (Secondary)",
                "F.1.1; F.1.3; F.2.3; F.4.1; F.4.2; F.4.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01171v1",
            "title": "Memristor-based hardware and algorithms for higher-order Hopfield\n  optimization solver outperforming quadratic Ising machines",
            "updated": "2023-11-02T12:09:20Z",
            "published": "2023-11-02T12:09:20Z",
            "summary": "Ising solvers offer a promising physics-based approach to tackle the\nchallenging class of combinatorial optimization problems. However, typical\nsolvers operate in a quadratic energy space, having only pair-wise coupling\nelements which already dominate area and energy. We show that such\nquadratization can cause severe problems: increased dimensionality, a rugged\nsearch landscape, and misalignment with the original objective function. Here,\nwe design and quantify a higher-order Hopfield optimization solver, with 28nm\nCMOS technology and memristive couplings for lower area and energy\ncomputations. We combine algorithmic and circuit analysis to show quantitative\nadvantages over quadratic Ising Machines (IM)s, yielding 48x and 72x reduction\nin time-to-solution (TTS) and energy-to-solution (ETS) respectively for Boolean\nsatisfiability problems of 150 variables, with favorable scaling.",
            "author": [
                "Mohammad Hizzani",
                "Arne Heittmann",
                "George Hutchinson",
                "Dmitrii Dobrynin",
                "Thomas Van Vaerenbergh",
                "Tinish Bhattacharya",
                "Adrien Renaudineau",
                "Dmitri Strukov",
                "John Paul Strachan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01171v1",
                "http://arxiv.org/pdf/2311.01171v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01166v1",
            "title": "Generative Input: Towards Next-Generation Input Methods Paradigm",
            "updated": "2023-11-02T12:01:29Z",
            "published": "2023-11-02T12:01:29Z",
            "summary": "Since the release of ChatGPT, generative models have achieved tremendous\nsuccess and become the de facto approach for various NLP tasks. However, its\napplication in the field of input methods remains under-explored. Many neural\nnetwork approaches have been applied to the construction of Chinese input\nmethod engines(IMEs).Previous research often assumed that the input pinyin was\ncorrect and focused on Pinyin-to-character(P2C) task, which significantly falls\nshort of meeting users' demands. Moreover, previous research could not leverage\nuser feedback to optimize the model and provide personalized results. In this\nstudy, we propose a novel Generative Input paradigm named GeneInput. It uses\nprompts to handle all input scenarios and other intelligent auxiliary input\nfunctions, optimizing the model with user feedback to deliver personalized\nresults. The results demonstrate that we have achieved state-of-the-art\nperformance for the first time in the Full-mode Key-sequence to\nCharacters(FK2C) task. We propose a novel reward model training method that\neliminates the need for additional manual annotations and the performance\nsurpasses GPT-4 in tasks involving intelligent association and conversational\nassistance. Compared to traditional paradigms, GeneInput not only demonstrates\nsuperior performance but also exhibits enhanced robustness, scalability, and\nonline learning capabilities.",
            "author": [
                "Keyu Ding",
                "Yongcan Wang",
                "Zihang Xu",
                "Zhenzhen Jia",
                "Shijin Wang",
                "Cong Liu",
                "Enhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01166v1",
                "http://arxiv.org/pdf/2311.01166v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02107v1",
            "title": "Generative Artificial Intelligence in Healthcare: Ethical Considerations\n  and Assessment Checklist",
            "updated": "2023-11-02T11:55:07Z",
            "published": "2023-11-02T11:55:07Z",
            "summary": "The widespread use of ChatGPT and other emerging technology powered by\ngenerative artificial intelligence (AI) has drawn much attention to potential\nethical issues, especially in high-stakes applications such as healthcare.\nHowever, less clear is how to resolve such issues beyond following guidelines\nand regulations that are still under discussion and development. On the other\nhand, other types of generative AI have been used to synthesize images and\nother types of data for research and practical purposes, which have resolved\nsome ethical issues and exposed other ethical issues, but such technology is\nless often the focus of ongoing ethical discussions. Here we highlight gaps in\ncurrent ethical discussions of generative AI via a systematic scoping review of\nrelevant existing research in healthcare, and reduce the gaps by proposing an\nethics checklist for comprehensive assessment and transparent documentation of\nethical discussions in generative AI development. While the checklist can be\nreadily integrated into the current peer review and publication system to\nenhance generative AI research, it may also be used in broader settings to\ndisclose ethics-related considerations in generative AI-powered products (or\nreal-life applications of such products) to help users establish reasonable\ntrust in their capabilities.",
            "author": [
                "Yilin Ning",
                "Salinelat Teixayavong",
                "Yuqing Shang",
                "Julian Savulescu",
                "Vaishaanth Nagaraj",
                "Di Miao",
                "Mayli Mertens",
                "Daniel Shu Wei Ting",
                "Jasmine Chiat Ling Ong",
                "Mingxuan Liu",
                "Jiuwen Cao",
                "Michael Dunn",
                "Roger Vaughan",
                "Marcus Eng Hock Ong",
                "Joseph Jao-Yiu Sung",
                "Eric J Topol",
                "Nan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02107v1",
                "http://arxiv.org/pdf/2311.02107v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01163v1",
            "title": "PDRs4All VI: Probing the Photochemical Evolution of PAHs in the Orion\n  Bar Using Machine Learning Techniques",
            "updated": "2023-11-02T11:49:45Z",
            "published": "2023-11-02T11:49:45Z",
            "summary": "[Abridged] JWST observations of the Orion Bar have shown the incredible\nrichness of PAH bands and their variation on small scales. We aim to probe the\nphotochemical evolution of PAHs across the key zones of the photodissociation\nregion (PDR) that is the Orion Bar using unsupervised machine learning. We use\nNIRSpec and MIRI IFU data from the JWST ERS Program PDRs4All. We lever\nbisecting k-means clustering to generate detailed spatial maps of the spectral\nvariability in several wavelength regions. We discuss the variations in the\ncluster profiles and connect them to the local physical conditions. We\ninterpret these variations with respect to the key zones: the HII region, the\natomic PDR zone, and the three dissociation fronts. The PAH emission exhibits\nspectral variation that depends strongly on spatial position in the PDR. We\nfind the 8.6um band to behave differently than all other bands which vary\nsystematically with one another. We find uniform variation in the 3.4-3.6um\nbands and 3.4/3.3 intensity ratio. We attribute the carrier of the 3.4-3.6um\nbands to a single side group attached to very similarly sized PAHs. Cluster\nprofiles reveal a transition between characteristic profiles classes of the\n11.2um feature from the atomic to the molecular PDR zone. We find the carriers\nof each of the profile classes to be independent, and reason the latter to be\nPAH clusters existing solely deep in the molecular PDR. Clustering also reveals\na connection between the 11.2 and 6.2um bands; and that clusters generated from\nvariation in the 10.9-11.63um region can be used to recover those in the\n5.95-6.6um region. Clustering is a powerful tool for characterizing PAH\nvariability on both spatial and spectral scales. For individual bands as well\nas global spectral behaviours, we find UV-processing to be the most important\ndriver of the evolution of PAHs and their spectral signatures in the Orion Bar.",
            "author": [
                "S. Pasquini",
                "E. Peeters",
                "B. Schefter",
                "B. Khan",
                "A. Sidhu",
                "R. Chown",
                "J. Cami",
                "A. Tielens",
                "F. Alarcon",
                "A. Canin",
                "I. Schroetter",
                "B. Trahin",
                "D. Van De Putte",
                "C. Boersma",
                "E. Dartois",
                "T. Onaka",
                "A. Candian",
                "P. Hartigan",
                "T. S. -Y. Lai",
                "G. Rouille",
                "D. A. Sales",
                "Y. Zhang",
                "E. Habart",
                "O. Berne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01163v1",
                "http://arxiv.org/pdf/2311.01163v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01159v1",
            "title": "Search for Periodic Time Variations of the Solar $^8$B Neutrino Flux\n  Between 1996 and 2018 in Super-Kamiokande",
            "updated": "2023-11-02T11:41:51Z",
            "published": "2023-11-02T11:41:51Z",
            "summary": "We report a search for time variations of the solar $^8$B neutrino flux using\n5,804 live days of Super-Kamiokande data collected between May 31, 1996, and\nMay 30, 2018. Super-Kamiokande measured the precise time of each solar neutrino\ninteraction over 22 calendar years to search for solar neutrino flux\nmodulations with unprecedented precision. Periodic modulations are searched for\nin a data set comprised of five-day interval solar neutrino flux measurements\nwith a maximum likelihood method. We also applied the Lomb-Scargle method to\nthis data set to compare it with previous reports. The only significant\nmodulation found is due to the elliptic orbit of the Earth around the Sun. The\nobserved modulation is consistent with astronomical data: we measured an\neccentricity of (1.53$\\pm$0.35)\\,\\%, and a perihelion shift is\n($-$1.5$\\pm$13.5)\\,days.",
            "author": [
                "K. Abe",
                "C. Bronner",
                "Y. Hayato",
                "K. Hiraide",
                "K. Hosokawa",
                "K. Ieki",
                "M. Ikeda",
                "J. Kameda",
                "Y. Kanemura",
                "R. Kaneshima",
                "Y. Kashiwagi",
                "Y. Kataoka",
                "S. Miki",
                "S. Mine",
                "M. Miura",
                "S. Moriyama",
                "Y. Nakano",
                "M. Nakahata",
                "S. Nakayama",
                "Y. Noguchi",
                "K. Sato",
                "H. Sekiya",
                "H. Shiba",
                "K. Shimizu",
                "M. Shiozawa",
                "Y. Sonoda",
                "Y. Suzuki",
                "A. Takeda",
                "Y. Takemoto",
                "H. Tanaka",
                "T. Yano",
                "S. Han",
                "T. Kajita",
                "K. Okumura",
                "T. Tashiro",
                "T. Tomiya",
                "X. Wang",
                "S. Yoshida",
                "P. Fernandez",
                "L. Labarga",
                "N. Ospina",
                "B. Zaldivar",
                "B. W. Pointon",
                "E. Kearns",
                "J. L. Raaf",
                "L. Wan",
                "T. Wester",
                "J. Bian",
                "N. J. Griskevich",
                "S. Locke",
                "M. B. Smy",
                "H. W. Sobel",
                "V. Takhistov",
                "A. Yankelevich",
                "J. Hill",
                "S. H. Lee",
                "D. H. Moon",
                "R. G. Park",
                "M. C. Jang",
                "B. Bodur",
                "K. Scholberg",
                "C. W. Walter",
                "A. Beauchene",
                "O. Drapier",
                "A. Giampaolo",
                "Th. A. Mueller",
                "A. D. Santos",
                "P. Paganini",
                "B. Quilain",
                "T. Nakamura",
                "J. S. Jang",
                "L. N. Machado",
                "J. G. Learned",
                "K. Choi",
                "N. Iovine",
                "S. Cao",
                "L. H. V. Anthony",
                "D. Martin",
                "N. W. Prouse",
                "M. Scott",
                "A. A. Sztuc",
                "Y. Uchida",
                "V. Berardi",
                "M. G. Catanesi",
                "E. Radicioni",
                "N. F. Calabria",
                "A. Langella",
                "G. De Rosa",
                "G. Collazuol",
                "F. Iacob",
                "M. Mattiazzi",
                "L. Ludovici",
                "M. Gonin",
                "G. Pronost",
                "C. Fujisawa",
                "Y. Maekawa",
                "Y. Nishimura",
                "R. Okazaki",
                "R. Akutsu",
                "M. Friend",
                "T. Hasegawa",
                "T. Ishida",
                "T. Kobayashi",
                "M. Jakkapu",
                "T. Matsubara",
                "T. Nakadaira",
                "K. Nakamura",
                "Y. Oyama",
                "K. Sakashita",
                "T. Sekiguchi",
                "T. Tsukamoto",
                "N. Bhuiyan",
                "G. T. Burton",
                "F. Di Lodovico",
                "J. Gao",
                "A. Goldsack",
                "T. Katori",
                "J. Migenda",
                "Z. Xie",
                "R. M. Ramsden",
                "S. Zsoldos",
                "A. T. Suzuki",
                "Y. Takagi",
                "H. Zhong",
                "Y. Takeuchi",
                "J. Feng",
                "L. Feng",
                "J. R. Hu",
                "Z. Hu",
                "T. Kikawa",
                "M. Mori",
                "M. Kawaue",
                "T. Nakaya",
                "R. A. Wendell",
                "K. Yasutome",
                "S. J. Jenkins",
                "N. McCauley",
                "P. Mehta",
                "A. Tarant",
                "Y. Fukuda",
                "Y. Itow",
                "H. Menjo",
                "K. Ninomiya",
                "Y. Yoshioka",
                "J. Lagoda",
                "S. M. Lakshmi",
                "M. Mandal",
                "P. Mijakowski",
                "Y. S. Prabhu",
                "J. Zalipska",
                "M. Jia",
                "J. Jiang",
                "C. K. Jung",
                "M. J. Wilking",
                "C. Yanagisawa",
                "W. Shi",
                "M. Harada",
                "Y. Hino",
                "H. Ishino",
                "Y. Koshio",
                "F. Nakanishi",
                "S. Sakai",
                "T. Tada",
                "T. Tano",
                "T. Ishizuka",
                "G. Barr",
                "D. Barrow",
                "L. Cook",
                "S. Samani",
                "D. Wark",
                "A. Holin",
                "F. Nova",
                "B. S. Yang",
                "J. Y. Yang",
                "J. Yoo",
                "S. Jung",
                "J. E. P. Fannon",
                "L. Kneale",
                "M. Malek",
                "J. M. McElwee",
                "M. D. Thiesse",
                "L. F. Thompson",
                "S. T. Wilson",
                "H. Okazawa",
                "S. B. Kim",
                "E. Kwon",
                "J. W. Seo",
                "I. Yu",
                "A. K. Ichikawa",
                "K. D. Nakamura",
                "S. Tairafune",
                "K. Nishijima",
                "A. Eguchi",
                "K. Nakagiri",
                "Y. Nakajima",
                "S. Shima",
                "N. Taniuchi",
                "E. Watanabe",
                "M. Yokoyama",
                "P. de Perio",
                "S. Fujita",
                "K. Martens",
                "K. M. Tsui",
                "M. R. Vagins",
                "J. Xia",
                "S. Izumiyama",
                "M. Kuze",
                "R. Matsumoto",
                "M. Ishitsuka",
                "H. Ito",
                "Y. Ommura",
                "N. Shigeta",
                "M. Shinoki",
                "K. Yamauchi",
                "T. Yoshida",
                "R. Gaur",
                "V. Gousy-Leblanc",
                "M. Hartz",
                "A. Konaka",
                "X. Li",
                "S. Chen",
                "B. D. Xu",
                "B. Zhang",
                "M. Posiadala-Zezula",
                "S. B. Boyd",
                "R. Edwards",
                "D. Hadley",
                "M. Nicholson",
                "M. O Flaherty",
                "B. Richards",
                "A. Ali",
                "B. Jamieson",
                "S. Amanai",
                "Ll. Marti",
                "A. Minamino",
                "S. Suzuki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01159v1",
                "http://arxiv.org/pdf/2311.01159v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01156v1",
            "title": "Several Consequences of Optimality",
            "updated": "2023-11-02T11:33:51Z",
            "published": "2023-11-02T11:33:51Z",
            "summary": "Rationality is frequently associated with making the best possible decisions.\nIt's widely acknowledged that humans, as rational beings, have limitations in\ntheir decision-making capabilities. Nevertheless, recent advancements in\nfields, such as, computing, science and technology, combined with the\navailability of vast amounts of data, have sparked optimism that these\ndevelopments could potentially expand the boundaries of human bounded\nrationality through the augmentation of machine intelligence. In this paper,\nfindings from a computational model demonstrated that when an increasing number\nof agents independently strive to achieve global optimality, facilitated by\nimproved computing power, etc., they indirectly accelerated the occurrence of\nthe \"tragedy of the commons\" by depleting shared resources at a faster rate.\nFurther, as agents achieve optimality, there is a drop in information entropy\namong the solutions of the agents. Also, clear economic divide emerges among\nagents. Considering, two groups, one as producer and the other (the group\nagents searching for optimality) as consumer of the highest consumed resource,\nthe consumers seem to gain more than the producers. Thus, bounded rationality\ncould be seen as boon to sustainability.",
            "author": [
                "Dibakar Das"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01156v1",
                "http://arxiv.org/pdf/2311.01156v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01155v1",
            "title": "Learning Intra and Inter-Camera Invariance for Isolated Camera\n  Supervised Person Re-identification",
            "updated": "2023-11-02T11:32:40Z",
            "published": "2023-11-02T11:32:40Z",
            "summary": "Supervised person re-identification assumes that a person has images captured\nunder multiple cameras. However when cameras are placed in distance, a person\nrarely appears in more than one camera. This paper thus studies person re-ID\nunder such isolated camera supervised (ISCS) setting. Instead of trying to\ngenerate fake cross-camera features like previous methods, we explore a novel\nperspective by making efficient use of the variation in training data. Under\nISCS setting, a person only has limited images from a single camera, so the\ncamera bias becomes a critical issue confounding ID discrimination.\nCross-camera images are prone to being recognized as different IDs simply by\ncamera style. To eliminate the confounding effect of camera bias, we propose to\nlearn both intra- and inter-camera invariance under a unified framework. First,\nwe construct style-consistent environments via clustering, and perform\nprototypical contrastive learning within each environment. Meanwhile, strongly\naugmented images are contrasted with original prototypes to enforce\nintra-camera augmentation invariance. For inter-camera invariance, we further\ndesign a much improved variant of multi-camera negative loss that optimizes the\ndistance of multi-level negatives. The resulting model learns to be invariant\nto both subtle and severe style variation within and cross-camera. On multiple\nbenchmarks, we conduct extensive experiments and validate the effectiveness and\nsuperiority of the proposed method. Code will be available at\nhttps://github.com/Terminator8758/IICI.",
            "author": [
                "Menglin Wang",
                "Xiaojin Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01155v1",
                "http://arxiv.org/pdf/2311.01155v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01154v1",
            "title": "A Review of Digital Twins and their Application in Cybersecurity based\n  on Artificial Intelligence",
            "updated": "2023-11-02T11:31:53Z",
            "published": "2023-11-02T11:31:53Z",
            "summary": "The potential of digital twin technology is yet to be fully realized due to\nits diversity and untapped potential. Digital twins enable systems' analysis,\ndesign, optimization, and evolution to be performed digitally or in conjunction\nwith a cyber-physical approach to improve speed, accuracy, and efficiency over\ntraditional engineering methods. Industry 4.0, factories of the future, and\ndigital twins continue to benefit from the technology and provide enhanced\nefficiency within existing systems. Due to the lack of information and security\nstandards associated with the transition to cyber digitization, cybercriminals\nhave been able to take advantage of the situation. Access to a digital twin of\na product or service is equivalent to threatening the entire collection. There\nis a robust interaction between digital twins and artificial intelligence\ntools, which leads to strong interaction between these technologies, so it can\nbe used to improve the cybersecurity of these digital platforms based on their\nintegration with these technologies. This study aims to investigate the role of\nartificial intelligence in providing cybersecurity for digital twin versions of\nvarious industries, as well as the risks associated with these versions. In\naddition, this research serves as a road map for researchers and others\ninterested in cybersecurity and digital security.",
            "author": [
                "MohammadHossein Homaei",
                "Oscar Mogollon Gutierrez",
                "Jose Carlos Sancho Nunez",
                "Mar Avila Vegas",
                "Andres Caro Lindo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01154v1",
                "http://arxiv.org/pdf/2311.01154v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01139v1",
            "title": "Add and Thin: Diffusion for Temporal Point Processes",
            "updated": "2023-11-02T10:42:35Z",
            "published": "2023-11-02T10:42:35Z",
            "summary": "Autoregressive neural networks within the temporal point process (TPP)\nframework have become the standard for modeling continuous-time event data.\nEven though these models can expressively capture event sequences in a\none-step-ahead fashion, they are inherently limited for long-term forecasting\napplications due to the accumulation of errors caused by their sequential\nnature. To overcome these limitations, we derive ADD-THIN, a principled\nprobabilistic denoising diffusion model for TPPs that operates on entire event\nsequences. Unlike existing diffusion approaches, ADD-THIN naturally handles\ndata with discrete and continuous components. In experiments on synthetic and\nreal-world datasets, our model matches the state-of-the-art TPP models in\ndensity estimation and strongly outperforms them in forecasting.",
            "author": [
                "David L\u00fcdke",
                "Marin Bilo\u0161",
                "Oleksandr Shchur",
                "Marten Lienen",
                "Stephan G\u00fcnnemann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01139v1",
                "http://arxiv.org/pdf/2311.01139v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01138v1",
            "title": "AeroPath: An airway segmentation benchmark dataset with challenging\n  pathology",
            "updated": "2023-11-02T10:41:42Z",
            "published": "2023-11-02T10:41:42Z",
            "summary": "To improve the prognosis of patients suffering from pulmonary diseases, such\nas lung cancer, early diagnosis and treatment are crucial. The analysis of CT\nimages is invaluable for diagnosis, whereas high quality segmentation of the\nairway tree are required for intervention planning and live guidance during\nbronchoscopy. Recently, the Multi-domain Airway Tree Modeling (ATM'22)\nchallenge released a large dataset, both enabling training of deep-learning\nbased models and bringing substantial improvement of the state-of-the-art for\nthe airway segmentation task. However, the ATM'22 dataset includes few patients\nwith severe pathologies affecting the airway tree anatomy. In this study, we\nintroduce a new public benchmark dataset (AeroPath), consisting of 27 CT images\nfrom patients with pathologies ranging from emphysema to large tumors, with\ncorresponding trachea and bronchi annotations. Second, we present a multiscale\nfusion design for automatic airway segmentation. Models were trained on the\nATM'22 dataset, tested on the AeroPath dataset, and further evaluated against\ncompetitive open-source methods. The same performance metrics as used in the\nATM'22 challenge were used to benchmark the different considered approaches.\nLastly, an open web application is developed, to easily test the proposed model\non new data. The results demonstrated that our proposed architecture predicted\ntopologically correct segmentations for all the patients included in the\nAeroPath dataset. The proposed method is robust and able to handle various\nanomalies, down to at least the fifth airway generation. In addition, the\nAeroPath dataset, featuring patients with challenging pathologies, will\ncontribute to development of new state-of-the-art methods. The AeroPath dataset\nand the web application are made openly available.",
            "author": [
                "Karen-Helene St\u00f8verud",
                "David Bouget",
                "Andre Pedersen",
                "H\u00e5kon Olav Leira",
                "Thomas Lang\u00f8",
                "Erlend Fagertun Hofstad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01138v1",
                "http://arxiv.org/pdf/2311.01138v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01135v1",
            "title": "Generating QM1B with PySCF$_{\\text{IPU}}$",
            "updated": "2023-11-02T10:31:20Z",
            "published": "2023-11-02T10:31:20Z",
            "summary": "The emergence of foundation models in Computer Vision and Natural Language\nProcessing have resulted in immense progress on downstream tasks. This progress\nwas enabled by datasets with billions of training examples. Similar benefits\nare yet to be unlocked for quantum chemistry, where the potential of deep\nlearning is constrained by comparatively small datasets with 100k to 20M\ntraining examples. These datasets are limited in size because the labels are\ncomputed using the accurate (but computationally demanding) predictions of\nDensity Functional Theory (DFT). Notably, prior DFT datasets were created using\nCPU supercomputers without leveraging hardware acceleration. In this paper, we\ntake a first step towards utilising hardware accelerators by introducing the\ndata generator PySCF$_{\\text{IPU}}$ using Intelligence Processing Units (IPUs).\nThis allowed us to create the dataset QM1B with one billion training examples\ncontaining 9-11 heavy atoms. We demonstrate that a simple baseline neural\nnetwork (SchNet 9M) improves its performance by simply increasing the amount of\ntraining data without additional inductive biases. To encourage future\nresearchers to use QM1B responsibly, we highlight several limitations of QM1B\nand emphasise the low-resolution of our DFT options, which also serves as\nmotivation for even larger, more accurate datasets. Code and dataset are\navailable on Github: http://github.com/graphcore-research/pyscf-ipu",
            "author": [
                "Alexander Mathiasen",
                "Hatem Helal",
                "Kerstin Klaser",
                "Paul Balanca",
                "Josef Dean",
                "Carlo Luschi",
                "Dominique Beaini",
                "Andrew Fitzgibbon",
                "Dominic Masters"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01135v1",
                "http://arxiv.org/pdf/2311.01135v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph",
                "I.2.6; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01130v1",
            "title": "A deep learning experiment for semantic segmentation of overlapping\n  characters in palimpsests",
            "updated": "2023-11-02T10:25:47Z",
            "published": "2023-11-02T10:25:47Z",
            "summary": "Palimpsests refer to historical manuscripts where erased writings have been\npartially covered by the superimposition of a second writing. By employing\nimaging techniques, e.g., multispectral imaging, it becomes possible to\nidentify features that are imperceptible to the naked eye, including faded and\nerased inks. When dealing with overlapping inks, Artificial Intelligence\ntechniques can be utilized to disentangle complex nodes of overlapping letters.\nIn this work, we propose deep learning-based semantic segmentation as a method\nfor identifying and segmenting individual letters in overlapping characters.\nThe experiment was conceived as a proof of concept, focusing on the palimpsests\nof the Ars Grammatica by Prisciano as a case study. Furthermore, caveats and\nprospects of our approach combined with multispectral imaging are also\ndiscussed.",
            "author": [
                "Michela Perino",
                "Michele Ginolfi",
                "Anna Candida Felici",
                "Michela Rosellini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01130v1",
                "http://arxiv.org/pdf/2311.01130v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01125v1",
            "title": "Bi-Preference Learning Heterogeneous Hypergraph Networks for\n  Session-based Recommendation",
            "updated": "2023-11-02T10:16:28Z",
            "published": "2023-11-02T10:16:28Z",
            "summary": "Session-based recommendation intends to predict next purchased items based on\nanonymous behavior sequences. Numerous economic studies have revealed that item\nprice is a key factor influencing user purchase decisions. Unfortunately,\nexisting methods for session-based recommendation only aim at capturing user\ninterest preference, while ignoring user price preference. Actually, there are\nprimarily two challenges preventing us from accessing price preference.\nFirstly, the price preference is highly associated to various item features\n(i.e., category and brand), which asks us to mine price preference from\nheterogeneous information. Secondly, price preference and interest preference\nare interdependent and collectively determine user choice, necessitating that\nwe jointly consider both price and interest preference for intent modeling. To\nhandle above challenges, we propose a novel approach Bi-Preference Learning\nHeterogeneous Hypergraph Networks (BiPNet) for session-based recommendation.\nSpecifically, the customized heterogeneous hypergraph networks with a\ntriple-level convolution are devised to capture user price and interest\npreference from heterogeneous features of items. Besides, we develop a\nBi-Preference Learning schema to explore mutual relations between price and\ninterest preference and collectively learn these two preferences under the\nmulti-task learning architecture. Extensive experiments on multiple public\ndatasets confirm the superiority of BiPNet over competitive baselines.\nAdditional research also supports the notion that the price is crucial for the\ntask.",
            "author": [
                "Xiaokun Zhang",
                "Bo Xu",
                "Fenglong Ma",
                "Chenliang Li",
                "Yuan Lin",
                "Hongfei Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01125v1",
                "http://arxiv.org/pdf/2311.01125v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04918v1",
            "title": "Low-Resource Named Entity Recognition: Can One-vs-All AUC Maximization\n  Help?",
            "updated": "2023-11-02T10:14:52Z",
            "published": "2023-11-02T10:14:52Z",
            "summary": "Named entity recognition (NER), a task that identifies and categorizes named\nentities such as persons or organizations from text, is traditionally framed as\na multi-class classification problem. However, this approach often overlooks\nthe issues of imbalanced label distributions, particularly in low-resource\nsettings, which is common in certain NER contexts, like biomedical NER\n(bioNER). To address these issues, we propose an innovative reformulation of\nthe multi-class problem as a one-vs-all (OVA) learning problem and introduce a\nloss function based on the area under the receiver operating characteristic\ncurve (AUC). To enhance the efficiency of our OVA-based approach, we propose\ntwo training strategies: one groups labels with similar linguistic\ncharacteristics, and another employs meta-learning. The superiority of our\napproach is confirmed by its performance, which surpasses traditional NER\nlearning in varying NER settings.",
            "author": [
                "Ngoc Dang Nguyen",
                "Wei Tan",
                "Lan Du",
                "Wray Buntine",
                "Richard Beare",
                "Changyou Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04918v1",
                "http://arxiv.org/pdf/2311.04918v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02106v1",
            "title": "Efficient Machine Learning Ensemble Methods for Detecting Gravitational\n  Wave Glitches in LIGO Time Series",
            "updated": "2023-11-02T10:07:30Z",
            "published": "2023-11-02T10:07:30Z",
            "summary": "The phenomenon of Gravitational Wave (GW) analysis has grown in popularity as\ntechnology has advanced and the process of observing gravitational waves has\nbecome more precise. Although the sensitivity and the frequency of observation\nof GW signals are constantly improving, the possibility of noise in the\ncollected GW data remains. In this paper, we propose two new Machine and Deep\nlearning ensemble approaches (i.e., ShallowWaves and DeepWaves Ensembles) for\ndetecting different types of noise and patterns in datasets from GW\nobservatories. Our research also investigates various Machine and Deep Learning\ntechniques for multi-class classification and provides a comprehensive\nbenchmark, emphasizing the best results in terms of three commonly used\nperformance metrics (i.e., accuracy, precision, and recall). We train and test\nour models on a dataset consisting of annotated time series from real-world\ndata collected by the Advanced Laser Interferometer GW Observatory (LIGO). We\nempirically show that the best overall accuracy is obtained by the proposed\nDeepWaves Ensemble, followed close by the ShallowWaves Ensemble.",
            "author": [
                "Elena-Simona Apostol",
                "Ciprian-Octavian Truic\u0103"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02106v1",
                "http://arxiv.org/pdf/2311.02106v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "astro-ph.IM",
                "cs.AI",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01122v1",
            "title": "Deep Joint Source-Channel Coding for DNA Image Storage: A Novel Approach\n  with Enhanced Error Resilience and Biological Constraint Optimization",
            "updated": "2023-11-02T10:06:20Z",
            "published": "2023-11-02T10:06:20Z",
            "summary": "In the current era, DeoxyriboNucleic Acid (DNA) based data storage emerges as\nan intriguing approach, garnering substantial academic interest and\ninvestigation. This paper introduces a novel deep joint source-channel coding\n(DJSCC) scheme for DNA image storage, designated as DJSCC-DNA. This paradigm\ndistinguishes itself from conventional DNA storage techniques through three key\nmodifications: 1) it employs advanced deep learning methodologies, employing\nconvolutional neural networks for DNA encoding and decoding processes; 2) it\nseamlessly integrates DNA polymerase chain reaction (PCR) amplification into\nthe network architecture, thereby augmenting data recovery precision; and 3) it\nrestructures the loss function by targeting biological constraints for\noptimization. The performance of the proposed model is demonstrated via\nnumerical results from specific channel testing, suggesting that it surpasses\nconventional deep learning methodologies in terms of peak signal-to-noise ratio\n(PSNR) and structural similarity index (SSIM). Additionally, the model\neffectively ensures positive constraints on both homopolymer run-length and GC\ncontent.",
            "author": [
                "Wenfeng Wu",
                "Luping Xiang",
                "Qiang Liu",
                "Kun Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01122v1",
                "http://arxiv.org/pdf/2311.01122v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01118v1",
            "title": "AI for Interpretable Chemistry: Predicting Radical Mechanistic Pathways\n  via Contrastive Learning",
            "updated": "2023-11-02T09:47:27Z",
            "published": "2023-11-02T09:47:27Z",
            "summary": "Deep learning-based reaction predictors have undergone significant\narchitectural evolution. However, their reliance on reactions from the US\nPatent Office results in a lack of interpretable predictions and limited\ngeneralization capability to other chemistry domains, such as radical and\natmospheric chemistry. To address these challenges, we introduce a new reaction\npredictor system, RMechRP, that leverages contrastive learning in conjunction\nwith mechanistic pathways, the most interpretable representation of chemical\nreactions. Specifically designed for radical reactions, RMechRP provides\ndifferent levels of interpretation of chemical reactions. We develop and train\nmultiple deep-learning models using RMechDB, a public database of radical\nreactions, to establish the first benchmark for predicting radical reactions.\nOur results demonstrate the effectiveness of RMechRP in providing accurate and\ninterpretable predictions of radical reactions, and its potential for various\napplications in atmospheric chemistry.",
            "author": [
                "Mohammadamin Tavakoli",
                "Yin Ting T. Chiu",
                "Alexander Shmakov",
                "Ann Marie Carlton",
                "David Van Vranken",
                "Pierre Baldi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01118v1",
                "http://arxiv.org/pdf/2311.01118v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01117v1",
            "title": "Cheating Depth: Enhancing 3D Surface Anomaly Detection via Depth\n  Simulation",
            "updated": "2023-11-02T09:44:21Z",
            "published": "2023-11-02T09:44:21Z",
            "summary": "RGB-based surface anomaly detection methods have advanced significantly.\nHowever, certain surface anomalies remain practically invisible in RGB alone,\nnecessitating the incorporation of 3D information. Existing approaches that\nemploy point-cloud backbones suffer from suboptimal representations and reduced\napplicability due to slow processing. Re-training RGB backbones, designed for\nfaster dense input processing, on industrial depth datasets is hindered by the\nlimited availability of sufficiently large datasets. We make several\ncontributions to address these challenges. (i) We propose a novel Depth-Aware\nDiscrete Autoencoder (DADA) architecture, that enables learning a general\ndiscrete latent space that jointly models RGB and 3D data for 3D surface\nanomaly detection. (ii) We tackle the lack of diverse industrial depth datasets\nby introducing a simulation process for learning informative depth features in\nthe depth encoder. (iii) We propose a new surface anomaly detection method\n3DSR, which outperforms all existing state-of-the-art on the challenging\nMVTec3D anomaly detection benchmark, both in terms of accuracy and processing\nspeed. The experimental results validate the effectiveness and efficiency of\nour approach, highlighting the potential of utilizing depth information for\nimproved surface anomaly detection.",
            "author": [
                "Vitjan Zavrtanik",
                "Matej Kristan",
                "Danijel Sko\u010daj"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01117v1",
                "http://arxiv.org/pdf/2311.01117v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01111v1",
            "title": "H-NeXt: The next step towards roto-translation invariant networks",
            "updated": "2023-11-02T09:36:20Z",
            "published": "2023-11-02T09:36:20Z",
            "summary": "The widespread popularity of equivariant networks underscores the\nsignificance of parameter efficient models and effective use of training data.\nAt a time when robustness to unseen deformations is becoming increasingly\nimportant, we present H-NeXt, which bridges the gap between equivariance and\ninvariance. H-NeXt is a parameter-efficient roto-translation invariant network\nthat is trained without a single augmented image in the training set. Our\nnetwork comprises three components: an equivariant backbone for learning\nroto-translation independent features, an invariant pooling layer for\ndiscarding roto-translation information, and a classification layer. H-NeXt\noutperforms the state of the art in classification on unaugmented training sets\nand augmented test sets of MNIST and CIFAR-10.",
            "author": [
                "Tomas Karella",
                "Filip Sroubek",
                "Jan Flusser",
                "Jan Blazek",
                "Vasek Kosik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01111v1",
                "http://arxiv.org/pdf/2311.01111v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01108v1",
            "title": "Noise-Robust Fine-Tuning of Pretrained Language Models via External\n  Guidance",
            "updated": "2023-11-02T09:20:38Z",
            "published": "2023-11-02T09:20:38Z",
            "summary": "Adopting a two-stage paradigm of pretraining followed by fine-tuning,\nPretrained Language Models (PLMs) have achieved substantial advancements in the\nfield of natural language processing. However, in real-world scenarios, data\nlabels are often noisy due to the complex annotation process, making it\nessential to develop strategies for fine-tuning PLMs with such noisy labels. To\nthis end, we introduce an innovative approach for fine-tuning PLMs using noisy\nlabels, which incorporates the guidance of Large Language Models (LLMs) like\nChatGPT. This guidance assists in accurately distinguishing between clean and\nnoisy samples and provides supplementary information beyond the noisy labels,\nthereby boosting the learning process during fine-tuning PLMs. Extensive\nexperiments on synthetic and real-world noisy datasets further demonstrate the\nsuperior advantages of our framework over the state-of-the-art baselines.",
            "author": [
                "Song Wang",
                "Zhen Tan",
                "Ruocheng Guo",
                "Jundong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01108v1",
                "http://arxiv.org/pdf/2311.01108v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02105v1",
            "title": "Making Harmful Behaviors Unlearnable for Large Language Models",
            "updated": "2023-11-02T09:18:21Z",
            "published": "2023-11-02T09:18:21Z",
            "summary": "Large language models (LLMs) have shown great potential as general-purpose AI\nassistants in various domains. To meet the requirements of different\napplications, LLMs are often customized by further fine-tuning. However, the\npowerful learning ability of LLMs not only enables them to acquire new tasks\nbut also makes them susceptible to learning undesired behaviors. For example,\neven safety-aligned LLMs can be easily fine-tuned into harmful assistants as\nthe fine-tuning data often contains implicit or explicit harmful content. Can\nwe train LLMs on harmful data without learning harmful behaviors? This paper\nproposes a controllable training framework that makes harmful behaviors\nunlearnable during the fine-tuning process. Specifically, we introduce\n``security vectors'', a few new parameters that can be separated from the LLM,\nto ensure LLM's responses are consistent with the harmful behavior. Security\nvectors are activated during fine-tuning, the consistent behavior makes LLM\nbelieve that such behavior has already been learned, there is no need to\nfurther optimize for harmful data. During inference, we can deactivate security\nvectors to restore the LLM's normal behavior. The experimental results show\nthat the security vectors generated by 100 harmful samples are enough to\nprevent LLM from learning 1000 harmful samples, while preserving the ability to\nlearn other useful information.",
            "author": [
                "Xin Zhou",
                "Yi Lu",
                "Ruotian Ma",
                "Tao Gui",
                "Qi Zhang",
                "Xuanjing Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02105v1",
                "http://arxiv.org/pdf/2311.02105v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01107v1",
            "title": "GREEMA: Proposal and Experimental Verification of Growing Robot by\n  Eating Environmental MAterial for Landslide Disaster",
            "updated": "2023-11-02T09:16:15Z",
            "published": "2023-11-02T09:16:15Z",
            "summary": "In areas that are inaccessible to humans, such as the lunar surface and\nlandslide sites, there is a need for multiple autonomous mobile robot systems\nthat can replace human workers. In particular, at landslide sites such as river\nchannel blockages, robots are required to remove water and sediment from the\nsite as soon as possible. Conventionally, several construction machines have\nbeen deployed to the site for civil engineering work. However, because of the\nlarge size and weight of conventional construction equipment, it is difficult\nto move multiple units of construction equipment to the site, resulting in\nsignificant transportation costs and time. To solve such problems, this study\nproposes a novel growing robot by eating environmental material called GREEMA,\nwhich is lightweight and compact during transportation, but can function by\neating on environmental materials once it arrives at the site. GREEMA actively\ntakes in environmental materials such as water and sediment, uses them as its\nstructure, and removes them by moving itself. In this paper, we developed and\nexperimentally verified two types of GREEMAs. First, we developed a fin-type\nswimming robot that passively takes water into its body using a water-absorbing\npolymer and forms a body to express its swimming function. Second, we\nconstructed an arm-type robot that eats soil to increase the rigidity of its\nbody. We discuss the results of these two experiments from the viewpoint of\nExplicit-Implicit control and describe the design theory of GREEMA.",
            "author": [
                "Yusuke Tsunoda",
                "Yuya Sato",
                "Koichi Osuka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01107v1",
                "http://arxiv.org/pdf/2311.01107v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01106v1",
            "title": "In Defense of Softmax Parametrization for Calibrated and Consistent\n  Learning to Defer",
            "updated": "2023-11-02T09:15:52Z",
            "published": "2023-11-02T09:15:52Z",
            "summary": "Enabling machine learning classifiers to defer their decision to a downstream\nexpert when the expert is more accurate will ensure improved safety and\nperformance. This objective can be achieved with the learning-to-defer\nframework which aims to jointly learn how to classify and how to defer to the\nexpert. In recent studies, it has been theoretically shown that popular\nestimators for learning to defer parameterized with softmax provide unbounded\nestimates for the likelihood of deferring which makes them uncalibrated.\nHowever, it remains unknown whether this is due to the widely used softmax\nparameterization and if we can find a softmax-based estimator that is both\nstatistically consistent and possesses a valid probability estimator. In this\nwork, we first show that the cause of the miscalibrated and unbounded estimator\nin prior literature is due to the symmetric nature of the surrogate losses used\nand not due to softmax. We then propose a novel statistically consistent\nasymmetric softmax-based surrogate loss that can produce valid estimates\nwithout the issue of unboundedness. We further analyze the non-asymptotic\nproperties of our method and empirically validate its performance and\ncalibration on benchmark datasets.",
            "author": [
                "Yuzhou Cao",
                "Hussein Mozannar",
                "Lei Feng",
                "Hongxin Wei",
                "Bo An"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01106v1",
                "http://arxiv.org/pdf/2311.01106v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01099v1",
            "title": "Dissimilar thermal transport properties in $\u03ba$-Ga$_2$O$_3$ and\n  $\u03b2$-Ga$_2$O$_3$ revealed by machine-learning homogeneous nonequilibrium\n  molecular dynamics simulations",
            "updated": "2023-11-02T09:07:05Z",
            "published": "2023-11-02T09:07:05Z",
            "summary": "The lattice thermal conductivity (LTC) of Ga$_2$O$_3$ is an important\nproperty due to the challenge in the thermal management of high-power devices.\nWe develop machine-learned neuroevolution potentials for single-crystalline\n$\\beta$-Ga$_2$O$_3$ and $\\kappa$-Ga$_2$O$_3$, and apply them to perform\nhomogeneous nonequilibrium molecular dynamics simulations to predict their\nLTCs. The LTC of $\\beta$-Ga$_2$O$_3$ was determined to be 10.3 $\\pm$ 0.2 W/(m\nK), 19.9 $\\pm$ 0.2 W/(m K), and 12.6 $\\pm$ 0.2 W/(m K) along [100], [010], and\n[001], respectively, aligning with previous experimental measurements. For the\nfirst time, we predict the LTC of $\\kappa$-Ga$_2$O$_3$ along [100], [010], and\n[001] to be 4.5 $\\pm$ 0.0 W/(m K), 3.9 $\\pm$ 0.0 W/(m K), and 4.0 $\\pm$ 0.1\nW/(m K), respectively, showing a nearly isotropic thermal transport property.\nThe reduced LTC of $\\kappa$-Ga$_2$O$_3$ versus $\\beta$-Ga$_2$O$_3$ stems from\nits restricted low-frequency phonons up to 5 THz. Furthermore, we find that the\n$\\beta$ phase exhibits a typical temperature dependence slightly stronger than\n$\\sim T^{-1}$, whereas the $\\kappa$ phase shows a weaker temperature\ndependence, ranging from $\\sim T^{-0.5}$ to $\\sim T^{-0.7}$.",
            "author": [
                "Xiaonan Wang",
                "Jinfeng Yang",
                "Penghua Ying",
                "Zheyong Fan",
                "Jin Zhang",
                "Huarui Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01099v1",
                "http://arxiv.org/pdf/2311.01099v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01092v1",
            "title": "Learning A Multi-Task Transformer Via Unified And Customized Instruction\n  Tuning For Chest Radiograph Interpretation",
            "updated": "2023-11-02T08:55:48Z",
            "published": "2023-11-02T08:55:48Z",
            "summary": "The emergence of multi-modal deep learning models has made significant\nimpacts on clinical applications in the last decade. However, the majority of\nmodels are limited to single-tasking, without considering disease diagnosis is\nindeed a multi-task procedure. Here, we demonstrate a unified transformer model\nspecifically designed for multi-modal clinical tasks by incorporating\ncustomized instruction tuning. We first compose a multi-task training dataset\ncomprising 13.4 million instruction and ground-truth pairs (with approximately\none million radiographs) for the customized tuning, involving both image- and\npixel-level tasks. Thus, we can unify the various vision-intensive tasks in a\nsingle training framework with homogeneous model inputs and outputs to increase\nclinical interpretability in one reading. Finally, we demonstrate the overall\nsuperior performance of our model compared to prior arts on various chest X-ray\nbenchmarks across multi-tasks in both direct inference and finetuning settings.\nThree radiologists further evaluate the generated reports against the recorded\nones, which also exhibit the enhanced explainability of our multi-task model.",
            "author": [
                "Lijian Xu",
                "Ziyu Ni",
                "Xinglong Liu",
                "Xiaosong Wang",
                "Hongsheng Li",
                "Shaoting Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01092v1",
                "http://arxiv.org/pdf/2311.01092v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01090v1",
            "title": "Infusion: Internal Diffusion for Video Inpainting",
            "updated": "2023-11-02T08:55:11Z",
            "published": "2023-11-02T08:55:11Z",
            "summary": "Video inpainting is the task of filling a desired region in a video in a\nvisually convincing manner. It is a very challenging task due to the high\ndimensionality of the signal and the temporal consistency required for\nobtaining convincing results. Recently, diffusion models have shown impressive\nresults in modeling complex data distributions, including images and videos.\nDiffusion models remain nonetheless very expensive to train and perform\ninference with, which strongly restrict their application to video. We show\nthat in the case of video inpainting, thanks to the highly auto-similar nature\nof videos, the training of a diffusion model can be restricted to the video to\ninpaint and still produce very satisfying results. This leads us to adopt an\ninternal learning approch, which also allows for a greatly reduced network\nsize. We call our approach \"Infusion\": an internal learning algorithm for video\ninpainting through diffusion. Due to our frugal network, we are able to propose\nthe first video inpainting approach based purely on diffusion. Other methods\nrequire supporting elements such as optical flow estimation, which limits their\nperformance in the case of dynamic textures for example. We introduce a new\nmethod for efficient training and inference of diffusion models in the context\nof internal learning. We split the diffusion process into different learning\nintervals which greatly simplifies the learning steps. We show qualititative\nand quantitative results, demonstrating that our method reaches\nstate-of-the-art performance, in particular in the case of dynamic backgrounds\nand textures.",
            "author": [
                "Nicolas Cherel",
                "Andr\u00e9s Almansa",
                "Yann Gousseau",
                "Alasdair Newson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01090v1",
                "http://arxiv.org/pdf/2311.01090v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01089v1",
            "title": "Wash-in leptogenesis after the evaporation of primordial black holes",
            "updated": "2023-11-02T08:54:38Z",
            "published": "2023-11-02T08:54:38Z",
            "summary": "Wash-in leptogenesis is a powerful mechanism to generate the baryon asymmetry\nof the Universe that treats right-handed-neutrino interactions on the same\nfooting as electroweak sphaleron processes: as mere spectator processes acting\non the background of chemical potentials in the Standard Model plasma.\nSuccessful wash-in leptogenesis requires this chemical background to be\nCP-violating, which can be achieved by violating any of the more than ten\nglobal charges that are conserved in the Standard Model at very high\ntemperatures. In this paper, we demonstrate that the primordial charge\nasymmetries required for wash-in leptogenesis can be readily produced by\nevaporating primordial black holes (PBHs). Our argument is based on the fact\nthat the Hawking radiation emitted by PBHs contains more or less any state in\nthe particle spectrum. Therefore, if heavy states with CP-violating decays are\npresent in the ultraviolet, PBH evaporation will unavoidably lead to the\nproduction of these states. We illustrate this scenario by means of a simple\ntoy model where PBH evaporation leads to the production of heavy particles that\nwe call asymmetrons and whose decay results in a primordial charge asymmetry\nfor right-handed electrons, which in turn sets the initial conditions for\nwash-in leptogenesis. We focus on the parameter region where the decay of the\ninitial thermal asymmetron abundance occurs long before PBH evaporation and\nonly results in a negligible primordial charge asymmetry. PBH evaporation at\nlater times then serves as a mechanism to resurrect the asymmetron abundance\nand ensure the successful generation of the baryon asymmetry after all. We\nconclude that PBHs can act as asymmetry-producing machines that grant access to\nwhatever CP-violating physics may be present in the ultraviolet, rekindling it\nat lower energies where it can be reprocessed into a baryon asymmetry by\nright-handed neutrinos.",
            "author": [
                "Kai Schmitz",
                "Xun-Jie Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01089v1",
                "http://arxiv.org/pdf/2311.01089v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "astro-ph.CO",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03382v1",
            "title": "Causal Structure Representation Learning of Confounders in Latent Space\n  for Recommendation",
            "updated": "2023-11-02T08:46:07Z",
            "published": "2023-11-02T08:46:07Z",
            "summary": "Inferring user preferences from the historical feedback of users is a\nvaluable problem in recommender systems. Conventional approaches often rely on\nthe assumption that user preferences in the feedback data are equivalent to the\nreal user preferences without additional noise, which simplifies the problem\nmodeling. However, there are various confounders during user-item interactions,\nsuch as weather and even the recommendation system itself. Therefore,\nneglecting the influence of confounders will result in inaccurate user\npreferences and suboptimal performance of the model. Furthermore, the\nunobservability of confounders poses a challenge in further addressing the\nproblem. To address these issues, we refine the problem and propose a more\nrational solution. Specifically, we consider the influence of confounders,\ndisentangle them from user preferences in the latent space, and employ causal\ngraphs to model their interdependencies without specific labels. By cleverly\ncombining local and global causal graphs, we capture the user-specificity of\nconfounders on user preferences. We theoretically demonstrate the\nidentifiability of the obtained causal graph. Finally, we propose our model\nbased on Variational Autoencoders, named Causal Structure representation\nlearning of Confounders in latent space (CSC). We conducted extensive\nexperiments on one synthetic dataset and five real-world datasets,\ndemonstrating the superiority of our model. Furthermore, we demonstrate that\nthe learned causal representations of confounders are controllable, potentially\noffering users fine-grained control over the objectives of their recommendation\nlists with the learned causal graphs.",
            "author": [
                "Hangtong Xu",
                "Yuanbo Xu",
                "Yongjian Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03382v1",
                "http://arxiv.org/pdf/2311.03382v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03381v1",
            "title": "Separating and Learning Latent Confounders to Enhancing User Preferences\n  Modeling",
            "updated": "2023-11-02T08:42:50Z",
            "published": "2023-11-02T08:42:50Z",
            "summary": "Recommender models aim to capture user preferences from historical feedback\nand then predict user-specific feedback on candidate items. However, the\npresence of various unmeasured confounders causes deviations between the user\npreferences in the historical feedback and the true preferences, resulting in\nmodels not meeting their expected performance. Existing debias models either\n(1) specific to solving one particular bias or (2) directly obtain auxiliary\ninformation from user historical feedback, which cannot identify whether the\nlearned preferences are true user preferences or mixed with unmeasured\nconfounders. Moreover, we find that the former recommender system is not only a\nsuccessor to unmeasured confounders but also acts as an unmeasured confounder\naffecting user preference modeling, which has always been neglected in previous\nstudies. To this end, we incorporate the effect of the former recommender\nsystem and treat it as a proxy for all unmeasured confounders. We propose a\nnovel framework, \\textbf{S}eparating and \\textbf{L}earning Latent Confounders\n\\textbf{F}or \\textbf{R}ecommendation (\\textbf{SLFR}), which obtains the\nrepresentation of unmeasured confounders to identify the counterfactual\nfeedback by disentangling user preferences and unmeasured confounders, then\nguides the target model to capture the true preferences of users. Extensive\nexperiments in five real-world datasets validate the advantages of our method.",
            "author": [
                "Hangtong Xu",
                "Yuanbo Xu",
                "Yongjian Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03381v1",
                "http://arxiv.org/pdf/2311.03381v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01075v1",
            "title": "Contrastive Modules with Temporal Attention for Multi-Task Reinforcement\n  Learning",
            "updated": "2023-11-02T08:41:00Z",
            "published": "2023-11-02T08:41:00Z",
            "summary": "In the field of multi-task reinforcement learning, the modular principle,\nwhich involves specializing functionalities into different modules and\ncombining them appropriately, has been widely adopted as a promising approach\nto prevent the negative transfer problem that performance degradation due to\nconflicts between tasks. However, most of the existing multi-task RL methods\nonly combine shared modules at the task level, ignoring that there may be\nconflicts within the task. In addition, these methods do not take into account\nthat without constraints, some modules may learn similar functions, resulting\nin restricting the model's expressiveness and generalization capability of\nmodular methods. In this paper, we propose the Contrastive Modules with\nTemporal Attention(CMTA) method to address these limitations. CMTA constrains\nthe modules to be different from each other by contrastive learning and\ncombining shared modules at a finer granularity than the task level with\ntemporal attention, alleviating the negative transfer within the task and\nimproving the generalization ability and the performance for multi-task RL. We\nconducted the experiment on Meta-World, a multi-task RL benchmark containing\nvarious robotics manipulation tasks. Experimental results show that CMTA\noutperforms learning each task individually for the first time and achieves\nsubstantial performance improvements over the baselines.",
            "author": [
                "Siming Lan",
                "Rui Zhang",
                "Qi Yi",
                "Jiaming Guo",
                "Shaohui Peng",
                "Yunkai Gao",
                "Fan Wu",
                "Ruizhi Chen",
                "Zidong Du",
                "Xing Hu",
                "Xishan Zhang",
                "Ling Li",
                "Yunji Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01075v1",
                "http://arxiv.org/pdf/2311.01075v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04917v1",
            "title": "Adapting Fake News Detection to the Era of Large Language Models",
            "updated": "2023-11-02T08:39:45Z",
            "published": "2023-11-02T08:39:45Z",
            "summary": "In the age of large language models (LLMs) and the widespread adoption of\nAI-driven content creation, the landscape of information dissemination has\nwitnessed a paradigm shift. With the proliferation of both human-written and\nmachine-generated real and fake news, robustly and effectively discerning the\nveracity of news articles has become an intricate challenge. While substantial\nresearch has been dedicated to fake news detection, this either assumes that\nall news articles are human-written or abruptly assumes that all\nmachine-generated news are fake. Thus, a significant gap exists in\nunderstanding the interplay between machine-(paraphrased) real news,\nmachine-generated fake news, human-written fake news, and human-written real\nnews. In this paper, we study this gap by conducting a comprehensive evaluation\nof fake news detectors trained in various scenarios. Our primary objectives\nrevolve around the following pivotal question: How to adapt fake news detectors\nto the era of LLMs? Our experiments reveal an interesting pattern that\ndetectors trained exclusively on human-written articles can indeed perform well\nat detecting machine-generated fake news, but not vice versa. Moreover, due to\nthe bias of detectors against machine-generated texts \\cite{su2023fake}, they\nshould be trained on datasets with a lower machine-generated news ratio than\nthe test set. Building on our findings, we provide a practical strategy for the\ndevelopment of robust fake news detectors.",
            "author": [
                "Jinyan Su",
                "Claire Cardie",
                "Preslav Nakov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04917v1",
                "http://arxiv.org/pdf/2311.04917v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01065v1",
            "title": "Novel View Synthesis from a Single RGBD Image for Indoor Scenes",
            "updated": "2023-11-02T08:34:07Z",
            "published": "2023-11-02T08:34:07Z",
            "summary": "In this paper, we propose an approach for synthesizing novel view images from\na single RGBD (Red Green Blue-Depth) input. Novel view synthesis (NVS) is an\ninteresting computer vision task with extensive applications. Methods using\nmultiple images has been well-studied, exemplary ones include training\nscene-specific Neural Radiance Fields (NeRF), or leveraging multi-view stereo\n(MVS) and 3D rendering pipelines. However, both are either computationally\nintensive or non-generalizable across different scenes, limiting their\npractical value. Conversely, the depth information embedded in RGBD images\nunlocks 3D potential from a singular view, simplifying NVS. The widespread\navailability of compact, affordable stereo cameras, and even LiDARs in\ncontemporary devices like smartphones, makes capturing RGBD images more\naccessible than ever. In our method, we convert an RGBD image into a point\ncloud and render it from a different viewpoint, then formulate the NVS task\ninto an image translation problem. We leveraged generative adversarial networks\nto style-transfer the rendered image, achieving a result similar to a\nphotograph taken from the new perspective. We explore both unsupervised\nlearning using CycleGAN and supervised learning with Pix2Pix, and demonstrate\nthe qualitative results. Our method circumvents the limitations of traditional\nmulti-image techniques, holding significant promise for practical, real-time\napplications in NVS.",
            "author": [
                "Congrui Hetang",
                "Yuping Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01065v1",
                "http://arxiv.org/pdf/2311.01065v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16132v1",
            "title": "A novel RNA pseudouridine site prediction model using Utility Kernel and\n  data-driven parameters",
            "updated": "2023-11-02T08:32:10Z",
            "published": "2023-11-02T08:32:10Z",
            "summary": "RNA protein Interactions (RPIs) play an important role in biological systems.\nRecently, we have enumerated the RPIs at the residue level and have elucidated\nthe minimum structural unit (MSU) in these interactions to be a stretch of five\nresidues (Nucleotides/amino acids). Pseudouridine is the most frequent\nmodification in RNA. The conversion of uridine to pseudouridine involves\ninteractions between pseudouridine synthase and RNA. The existing models to\npredict the pseudouridine sites in a given RNA sequence mainly depend on\nuser-defined features such as mono and dinucleotide composition/propensities of\nRNA sequences. Predicting pseudouridine sites is a non-linear classification\nproblem with limited data points. Deep Learning models are efficient\ndiscriminators when the data set size is reasonably large and fail when there\nis a paucity of data ($<1000$ samples). To mitigate this problem, we propose a\nSupport Vector Machine (SVM) Kernel based on utility theory from Economics, and\nusing data-driven parameters (i.e. MSU) as features. For this purpose, we have\nused position-specific tri/quad/pentanucleotide composition/propensity\n(PSPC/PSPP) besides nucleotide and dineculeotide composition as features. SVMs\nare known to work well in small data regimes and kernels in SVM are designed to\nclassify non-linear data. The proposed model outperforms the existing\nstate-of-the-art models significantly (10%-15% on average).",
            "author": [
                "Sourabh Patil",
                "Archana Mathur",
                "Raviprasad Aduri",
                "Snehanshu Saha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16132v1",
                "http://arxiv.org/pdf/2311.16132v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01064v1",
            "title": "Multimodal Foundation Models for Zero-shot Animal Species Recognition in\n  Camera Trap Images",
            "updated": "2023-11-02T08:32:00Z",
            "published": "2023-11-02T08:32:00Z",
            "summary": "Due to deteriorating environmental conditions and increasing human activity,\nconservation efforts directed towards wildlife is crucial. Motion-activated\ncamera traps constitute an efficient tool for tracking and monitoring wildlife\npopulations across the globe. Supervised learning techniques have been\nsuccessfully deployed to analyze such imagery, however training such techniques\nrequires annotations from experts. Reducing the reliance on costly labelled\ndata therefore has immense potential in developing large-scale wildlife\ntracking solutions with markedly less human labor. In this work we propose\nWildMatch, a novel zero-shot species classification framework that leverages\nmultimodal foundation models. In particular, we instruction tune\nvision-language models to generate detailed visual descriptions of camera trap\nimages using similar terminology to experts. Then, we match the generated\ncaption to an external knowledge base of descriptions in order to determine the\nspecies in a zero-shot manner. We investigate techniques to build instruction\ntuning datasets for detailed animal description generation and propose a novel\nknowledge augmentation technique to enhance caption quality. We demonstrate the\nperformance of WildMatch on a new camera trap dataset collected in the\nMagdalena Medio region of Colombia.",
            "author": [
                "Zalan Fabian",
                "Zhongqi Miao",
                "Chunyuan Li",
                "Yuanhan Zhang",
                "Ziwei Liu",
                "Andr\u00e9s Hern\u00e1ndez",
                "Andr\u00e9s Montes-Rojas",
                "Rafael Escucha",
                "Laura Siabatto",
                "Andr\u00e9s Link",
                "Pablo Arbel\u00e1ez",
                "Rahul Dodhia",
                "Juan Lavista Ferres"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01064v1",
                "http://arxiv.org/pdf/2311.01064v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01061v1",
            "title": "Deep Learning for real-time neural decoding of grasp",
            "updated": "2023-11-02T08:26:29Z",
            "published": "2023-11-02T08:26:29Z",
            "summary": "Neural decoding involves correlating signals acquired from the brain to\nvariables in the physical world like limb movement or robot control in Brain\nMachine Interfaces. In this context, this work starts from a specific\npre-existing dataset of neural recordings from monkey motor cortex and presents\na Deep Learning-based approach to the decoding of neural signals for grasp type\nclassification. Specifically, we propose here an approach that exploits LSTM\nnetworks to classify time series containing neural data (i.e., spike trains)\ninto classes representing the object being grasped. The main goal of the\npresented approach is to improve over state-of-the-art decoding accuracy\nwithout relying on any prior neuroscience knowledge, and leveraging only the\ncapability of deep learning models to extract correlations from data. The paper\npresents the results achieved for the considered dataset and compares them with\nprevious works on the same dataset, showing a significant improvement in\nclassification accuracy, even if considering simulated real-time decoding.",
            "author": [
                "Paolo Viviani",
                "Ilaria Gesmundo",
                "Elios Ghinato",
                "Andres Agudelo-Toro",
                "Chiara Vercellino",
                "Giacomo Vitali",
                "Letizia Bergamasco",
                "Alberto Scionti",
                "Marco Ghislieri",
                "Valentina Agostini",
                "Olivier Terzo",
                "Hansj\u00f6rg Scherberger"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43427-3_23",
                "http://arxiv.org/abs/2311.01061v1",
                "http://arxiv.org/pdf/2311.01061v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01059v1",
            "title": "Adapt On-the-Go: Behavior Modulation for Single-Life Robot Deployment",
            "updated": "2023-11-02T08:22:28Z",
            "published": "2023-11-02T08:22:28Z",
            "summary": "To succeed in the real world, robots must cope with situations that differ\nfrom those seen during training. We study the problem of adapting on-the-fly to\nsuch novel scenarios during deployment, by drawing upon a diverse repertoire of\npreviously learned behaviors. Our approach, RObust Autonomous Modulation\n(ROAM), introduces a mechanism based on the perceived value of pre-trained\nbehaviors to select and adapt pre-trained behaviors to the situation at hand.\nCrucially, this adaptation process all happens within a single episode at test\ntime, without any human supervision. We provide theoretical analysis of our\nselection mechanism and demonstrate that ROAM enables a robot to adapt rapidly\nto changes in dynamics both in simulation and on a real Go1 quadruped, even\nsuccessfully moving forward with roller skates on its feet. Our approach adapts\nover 2x as efficiently compared to existing methods when facing a variety of\nout-of-distribution situations during deployment by effectively choosing and\nadapting relevant behaviors on-the-fly.",
            "author": [
                "Annie S. Chen",
                "Govind Chada",
                "Laura Smith",
                "Archit Sharma",
                "Zipeng Fu",
                "Sergey Levine",
                "Chelsea Finn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01059v1",
                "http://arxiv.org/pdf/2311.01059v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03380v1",
            "title": "An attempt to generate new bridge types from latent space of variational\n  autoencoder",
            "updated": "2023-11-02T08:18:37Z",
            "published": "2023-11-02T08:18:37Z",
            "summary": "Try to generate new bridge types using generative artificial intelligence\ntechnology. The grayscale images of the bridge facade with the change of\ncomponent width was rendered by 3dsMax animation software, and then the OpenCV\nmodule performed an appropriate amount of geometric transformation (rotation,\nhorizontal scale, vertical scale) to obtain the image dataset of three-span\nbeam bridge, arch bridge, cable-stayed bridge and suspension bridge. Based on\nPython programming language, TensorFlow and Keras deep learning platform\nframework, variational autoencoder was constructed and trained, and\nlow-dimensional bridge-type latent space that is convenient for vector\noperations was obtained. Variational autoencoder can combine two bridge types\non the basis of the original of human into one that is a new bridge type.\nGenerative artificial intelligence technology can assist bridge designers in\nbridge-type innovation, and can be used as copilot.",
            "author": [
                "Hongjun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03380v1",
                "http://arxiv.org/pdf/2311.03380v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01057v2",
            "title": "Ultra-Efficient On-Device Object Detection on AI-Integrated Smart\n  Glasses with TinyissimoYOLO",
            "updated": "2023-11-03T15:25:55Z",
            "published": "2023-11-02T08:01:49Z",
            "summary": "Smart glasses are rapidly gaining advanced functionality thanks to\ncutting-edge computing technologies, accelerated hardware architectures, and\ntiny AI algorithms. Integrating AI into smart glasses featuring a small form\nfactor and limited battery capacity is still challenging when targeting\nfull-day usage for a satisfactory user experience. This paper illustrates the\ndesign and implementation of tiny machine-learning algorithms exploiting novel\nlow-power processors to enable prolonged continuous operation in smart glasses.\nWe explore the energy- and latency-efficient of smart glasses in the case of\nreal-time object detection. To this goal, we designed a smart glasses prototype\nas a research platform featuring two microcontrollers, including a novel\nmilliwatt-power RISC-V parallel processor with a hardware accelerator for\nvisual AI, and a Bluetooth low-power module for communication. The smart\nglasses integrate power cycling mechanisms, including image and audio sensing\ninterfaces. Furthermore, we developed a family of novel tiny deep-learning\nmodels based on YOLO with sub-million parameters customized for\nmicrocontroller-based inference dubbed TinyissimoYOLO v1.3, v5, and v8, aiming\nat benchmarking object detection with smart glasses for energy and latency.\nEvaluations on the prototype of the smart glasses demonstrate TinyissimoYOLO's\n17ms inference latency and 1.59mJ energy consumption per inference while\nensuring acceptable detection accuracy. Further evaluation reveals an\nend-to-end latency from image capturing to the algorithm's prediction of 56ms\nor equivalently 18 fps, with a total power consumption of 62.9mW, equivalent to\na 9.3 hours of continuous run time on a 154mAh battery. These results\noutperform MCUNet (TinyNAS+TinyEngine), which runs a simpler task (image\nclassification) at just 7.3 fps per second.",
            "author": [
                "Julian Moosmann",
                "Pietro Bonazzi",
                "Yawei Li",
                "Sizhen Bian",
                "Philipp Mayer",
                "Luca Benini",
                "Michele Magno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01057v2",
                "http://arxiv.org/pdf/2311.01057v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01056v1",
            "title": "Collaboration and Transition: Distilling Item Transitions into\n  Multi-Query Self-Attention for Sequential Recommendation",
            "updated": "2023-11-02T08:01:36Z",
            "published": "2023-11-02T08:01:36Z",
            "summary": "Modern recommender systems employ various sequential modules such as\nself-attention to learn dynamic user interests. However, these methods are less\neffective in capturing collaborative and transitional signals within user\ninteraction sequences. First, the self-attention architecture uses the\nembedding of a single item as the attention query, which is inherently\nchallenging to capture collaborative signals. Second, these methods typically\nfollow an auto-regressive framework, which is unable to learn global item\ntransition patterns. To overcome these limitations, we propose a new method\ncalled Multi-Query Self-Attention with Transition-Aware Embedding Distillation\n(MQSA-TED). First, we propose an $L$-query self-attention module that employs\nflexible window sizes for attention queries to capture collaborative signals.\nIn addition, we introduce a multi-query self-attention method that balances the\nbias-variance trade-off in modeling user preferences by combining long and\nshort-query self-attentions. Second, we develop a transition-aware embedding\ndistillation module that distills global item-to-item transition patterns into\nitem embeddings, which enables the model to memorize and leverage transitional\nsignals and serves as a calibrator for collaborative signals. Experimental\nresults on four real-world datasets show the superiority of our proposed method\nover state-of-the-art sequential recommendation methods.",
            "author": [
                "Tianyu Zhu",
                "Yansong Shi",
                "Yuan Zhang",
                "Yihong Wu",
                "Fengran Mo",
                "Jian-Yun Nie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01056v1",
                "http://arxiv.org/pdf/2311.01056v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01052v2",
            "title": "Resilient Multiple Choice Learning: A learned scoring scheme with\n  application to audio scene analysis",
            "updated": "2023-11-16T11:04:53Z",
            "published": "2023-11-02T07:54:03Z",
            "summary": "We introduce Resilient Multiple Choice Learning (rMCL), an extension of the\nMCL approach for conditional distribution estimation in regression settings\nwhere multiple targets may be sampled for each training input. Multiple Choice\nLearning is a simple framework to tackle multimodal density estimation, using\nthe Winner-Takes-All (WTA) loss for a set of hypotheses. In regression\nsettings, the existing MCL variants focus on merging the hypotheses, thereby\neventually sacrificing the diversity of the predictions. In contrast, our\nmethod relies on a novel learned scoring scheme underpinned by a mathematical\nframework based on Voronoi tessellations of the output space, from which we can\nderive a probabilistic interpretation. After empirically validating rMCL with\nexperiments on synthetic data, we further assess its merits on the sound source\nlocalization problem, demonstrating its practical usefulness and the relevance\nof its interpretation.",
            "author": [
                "Victor Letzelter",
                "Mathieu Fontaine",
                "Micka\u00ebl Chen",
                "Patrick P\u00e9rez",
                "Slim Essid",
                "Ga\u00ebl Richard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01052v2",
                "http://arxiv.org/pdf/2311.01052v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01050v1",
            "title": "Application and Energy-Aware Data Aggregation using Vector\n  Synchronization in Distributed Battery-less IoT Networks",
            "updated": "2023-11-02T07:51:23Z",
            "published": "2023-11-02T07:51:23Z",
            "summary": "The battery-less Internet of Things (IoT) devices are a key element in the\nsustainable green initiative for the next-generation wireless networks. These\nbattery-free devices use the ambient energy, harvested from the environment.\nThe energy harvesting environment is dynamic and causes intermittent task\nexecution. The harvested energy is stored in small capacitors and it is\nchallenging to assure the application task execution. The main goal is to\nprovide a mechanism to aggregate the sensor data and provide a sustainable\napplication support in the distributed battery-less IoT network. We model the\ndistributed IoT network system consisting of many battery-free IoT sensor\nhardware modules and heterogeneous IoT applications that are being supported in\nthe device-edge-cloud continuum. The applications require sensor data from a\ndistributed set of battery-less hardware modules and there is provision of\njoint control over the module actuators. We propose an application-aware task\nand energy manager (ATEM) for the IoT devices and a vector-synchronization\nbased data aggregator (VSDA). The ATEM is supported by device-level federated\nenergy harvesting and system-level energy-aware heterogeneous application\nmanagement. In our proposed framework the data aggregator forecasts the\navailable power from the ambient energy harvester using long-short-term-memory\n(LSTM) model and sets the device profile as well as the application task rates\naccordingly. Our proposed scheme meets the heterogeneous application\nrequirements with negligible overhead; reduces the data loss and packet delay;\nincreases the hardware component availability; and makes the components\navailable sooner as compared to the state-of-the-art.",
            "author": [
                "Chetna Singhal",
                "Subhrajit Barick",
                "Rishabh Sonkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01050v1",
                "http://arxiv.org/pdf/2311.01050v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01049v1",
            "title": "Multi-dimensional data refining strategy for effective fine-tuning LLMs",
            "updated": "2023-11-02T07:50:43Z",
            "published": "2023-11-02T07:50:43Z",
            "summary": "Data is a cornerstone for fine-tuning large language models, yet acquiring\nsuitable data remains challenging. Challenges encompassed data scarcity,\nlinguistic diversity, and domain-specific content. This paper presents lessons\nlearned while crawling and refining data tailored for fine-tuning Vietnamese\nlanguage models. Crafting such a dataset, while accounting for linguistic\nintricacies and striking a balance between inclusivity and accuracy, demands\nmeticulous planning. Our paper presents a multidimensional strategy including\nleveraging existing datasets in the English language and developing customized\ndata-crawling scripts with the assistance of generative AI tools. A fine-tuned\nLLM model for the Vietnamese language, which was produced using resultant\ndatasets, demonstrated good performance while generating Vietnamese news\narticles from prompts. The study offers practical solutions and guidance for\nfuture fine-tuning models in languages like Vietnamese.",
            "author": [
                "Thanh Nguyen Ngoc",
                "Quang Nhat Tran",
                "Arthur Tang",
                "Bao Nguyen",
                "Thuy Nguyen",
                "Thanh Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01049v1",
                "http://arxiv.org/pdf/2311.01049v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01048v1",
            "title": "AI-assisted Learning for Electronic Engineering Courses in High\n  Education",
            "updated": "2023-11-02T07:48:10Z",
            "published": "2023-11-02T07:48:10Z",
            "summary": "This study evaluates the efficacy of ChatGPT as an AI teaching and learning\nsupport tool in an integrated circuit systems course at a higher education\ninstitution in an Asian country. Various question types were completed, and\nChatGPT responses were assessed to gain valuable insights for further\ninvestigation. The objective is to assess ChatGPT's ability to provide\ninsights, personalized support, and interactive learning experiences in\nengineering education. The study includes the evaluation and reflection of\ndifferent stakeholders: students, lecturers, and engineers. The findings of\nthis study shed light on the benefits and limitations of ChatGPT as an AI tool,\npaving the way for innovative learning approaches in technical disciplines.\nFurthermore, the study contributes to our understanding of how digital\ntransformation is likely to unfold in the education sector.",
            "author": [
                "Thanh Nguyen Ngoc",
                "Quang Nhat Tran",
                "Arthur Tang",
                "Bao Nguyen",
                "Thuy Nguyen",
                "Thanh Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01048v1",
                "http://arxiv.org/pdf/2311.01048v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01047v1",
            "title": "Improving Robustness via Tilted Exponential Layer: A\n  Communication-Theoretic Perspective",
            "updated": "2023-11-02T07:47:42Z",
            "published": "2023-11-02T07:47:42Z",
            "summary": "State-of-the-art techniques for enhancing robustness of deep networks mostly\nrely on empirical risk minimization with suitable data augmentation. In this\npaper, we propose a complementary approach motivated by communication theory,\naimed at enhancing the signal-to-noise ratio at the output of a neural network\nlayer via neural competition during learning and inference. In addition to\nminimization of a standard end-to-end cost, neurons compete to sparsely\nrepresent layer inputs by maximization of a tilted exponential (TEXP) objective\nfunction for the layer. TEXP learning can be interpreted as maximum likelihood\nestimation of matched filters under a Gaussian model for data noise. Inference\nin a TEXP layer is accomplished by replacing batch norm by a tilted softmax,\nwhich can be interpreted as computation of posterior probabilities for the\ncompeting signaling hypotheses represented by each neuron. After providing\ninsights via simplified models, we show, by experimentation on standard image\ndatasets, that TEXP learning and inference enhances robustness against noise\nand other common corruptions, without requiring data augmentation. Further\ncumulative gains in robustness against this array of distortions can be\nobtained by appropriately combining TEXP with data augmentation techniques.",
            "author": [
                "Bhagyashree Puranik",
                "Ahmad Beirami",
                "Yao Qin",
                "Upamanyu Madhow"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01047v1",
                "http://arxiv.org/pdf/2311.01047v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01046v1",
            "title": "Time-Independent Information-Theoretic Generalization Bounds for SGLD",
            "updated": "2023-11-02T07:42:23Z",
            "published": "2023-11-02T07:42:23Z",
            "summary": "We provide novel information-theoretic generalization bounds for stochastic\ngradient Langevin dynamics (SGLD) under the assumptions of smoothness and\ndissipativity, which are widely used in sampling and non-convex optimization\nstudies. Our bounds are time-independent and decay to zero as the sample size\nincreases, regardless of the number of iterations and whether the step size is\nfixed. Unlike previous studies, we derive the generalization error bounds by\nfocusing on the time evolution of the Kullback--Leibler divergence, which is\nrelated to the stability of datasets and is the upper bound of the mutual\ninformation between output parameters and an input dataset. Additionally, we\nestablish the first information-theoretic generalization bound when the\ntraining and test loss are the same by showing that a loss function of SGLD is\nsub-exponential. This bound is also time-independent and removes the\nproblematic step size dependence in existing work, leading to an improved\nexcess risk bound by combining our analysis with the existing non-convex\noptimization error bounds.",
            "author": [
                "Futoshi Futami",
                "Masahiro Fujisawa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01046v1",
                "http://arxiv.org/pdf/2311.01046v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01043v2",
            "title": "LLM4Drive: A Survey of Large Language Models for Autonomous Driving",
            "updated": "2023-11-27T05:43:45Z",
            "published": "2023-11-02T07:23:33Z",
            "summary": "Autonomous driving technology, a catalyst for revolutionizing transportation\nand urban mobility, has the tend to transition from rule-based systems to\ndata-driven strategies. Traditional module-based systems are constrained by\ncumulative errors among cascaded modules and inflexible pre-set rules. In\ncontrast, end-to-end autonomous driving systems have the potential to avoid\nerror accumulation due to their fully data-driven training process, although\nthey often lack transparency due to their \"black box\" nature, complicating the\nvalidation and traceability of decisions. Recently, large language models\n(LLMs) have demonstrated abilities including understanding context, logical\nreasoning, and generating answers. A natural thought is to utilize these\nabilities to empower autonomous driving. By combining LLM with foundation\nvision models, it could open the door to open-world understanding, reasoning,\nand few-shot learning, which current autonomous driving systems are lacking. In\nthis paper, we systematically review a research line about \\textit{Large\nLanguage Models for Autonomous Driving (LLM4AD)}. This study evaluates the\ncurrent state of technological advancements, distinctly outlining the principal\nchallenges and prospective directions for the field. For the convenience of\nresearchers in academia and industry, we provide real-time updates on the\nlatest advances in the field as well as relevant open-source resources via the\ndesignated link: https://github.com/Thinklab-SJTU/Awesome-LLM4AD.",
            "author": [
                "Zhenjie Yang",
                "Xiaosong Jia",
                "Hongyang Li",
                "Junchi Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01043v2",
                "http://arxiv.org/pdf/2311.01043v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01041v1",
            "title": "Learn to Refuse: Making Large Language Models More Controllable and\n  Reliable through Knowledge Scope Limitation and Refusal Mechanism",
            "updated": "2023-11-02T07:20:49Z",
            "published": "2023-11-02T07:20:49Z",
            "summary": "Large language models (LLMs) have demonstrated impressive language\nunderstanding and generation capabilities, enabling them to answer a wide range\nof questions across various domains. However, these models are not flawless and\noften produce responses that contain errors or misinformation. These\ninaccuracies, commonly referred to as hallucinations, render LLMs unreliable\nand even unusable in many scenarios. In this paper, our focus is on mitigating\nthe issue of hallucination in LLMs, particularly in the context of\nquestion-answering. Instead of attempting to answer all questions, we explore a\nrefusal mechanism that instructs LLMs to refuse to answer challenging questions\nin order to avoid errors. We then propose a simple yet effective solution\ncalled Learn to Refuse (L2R), which incorporates the refusal mechanism to\nenable LLMs to recognize and refuse to answer questions that they find\ndifficult to address. To achieve this, we utilize a structured knowledge base\nto represent all the LLM's understanding of the world, enabling it to provide\ntraceable gold knowledge. This knowledge base is separate from the LLM and\ninitially empty, and it is progressively expanded with validated knowledge.\nWhen an LLM encounters questions outside its domain, the system recognizes its\nknowledge scope and determines whether it can answer the question\nindependently. Additionally, we introduce a method for automatically and\nefficiently expanding the knowledge base of LLMs. Through qualitative and\nquantitative analysis, we demonstrate that our approach enhances the\ncontrollability and reliability of LLMs.",
            "author": [
                "Lang Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01041v1",
                "http://arxiv.org/pdf/2311.01041v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01038v2",
            "title": "Better with Less: A Data-Active Perspective on Pre-Training Graph Neural\n  Networks",
            "updated": "2023-11-21T05:48:06Z",
            "published": "2023-11-02T07:09:59Z",
            "summary": "Pre-training on graph neural networks (GNNs) aims to learn transferable\nknowledge for downstream tasks with unlabeled data, and it has recently become\nan active research area. The success of graph pre-training models is often\nattributed to the massive amount of input data. In this paper, however, we\nidentify the curse of big data phenomenon in graph pre-training: more training\ndata do not necessarily lead to better downstream performance. Motivated by\nthis observation, we propose a better-with-less framework for graph\npre-training: fewer, but carefully chosen data are fed into a GNN model to\nenhance pre-training. The proposed pre-training pipeline is called the\ndata-active graph pre-training (APT) framework, and is composed of a graph\nselector and a pre-training model. The graph selector chooses the most\nrepresentative and instructive data points based on the inherent properties of\ngraphs as well as predictive uncertainty. The proposed predictive uncertainty,\nas feedback from the pre-training model, measures the confidence level of the\nmodel in the data. When fed with the chosen data, on the other hand, the\npre-training model grasps an initial understanding of the new, unseen data, and\nat the same time attempts to remember the knowledge learned from previous data.\nTherefore, the integration and interaction between these two components form a\nunified framework (APT), in which graph pre-training is performed in a\nprogressive and iterative way. Experiment results show that the proposed APT is\nable to obtain an efficient pre-training model with fewer training data and\nbetter downstream performance.",
            "author": [
                "Jiarong Xu",
                "Renhong Huang",
                "Xin Jiang",
                "Yuxuan Cao",
                "Carl Yang",
                "Chunping Wang",
                "Yang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01038v2",
                "http://arxiv.org/pdf/2311.01038v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01034v1",
            "title": "Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation",
            "updated": "2023-11-02T06:56:50Z",
            "published": "2023-11-02T06:56:50Z",
            "summary": "Pre-trained Vision-Language Models (VLMs), such as CLIP, have shown enhanced\nperformance across a range of tasks that involve the integration of visual and\nlinguistic modalities. When CLIP is used for depth estimation tasks, the\npatches, divided from the input images, can be combined with a series of\nsemantic descriptions of the depth information to obtain similarity results.\nThe coarse estimation of depth is then achieved by weighting and summing the\ndepth values, called depth bins, corresponding to the predefined semantic\ndescriptions. The zero-shot approach circumvents the computational and\ntime-intensive nature of traditional fully-supervised depth estimation methods.\nHowever, this method, utilizing fixed depth bins, may not effectively\ngeneralize as images from different scenes may exhibit distinct depth\ndistributions. To address this challenge, we propose a few-shot-based method\nwhich learns to adapt the VLMs for monocular depth estimation to balance\ntraining costs and generalization capabilities. Specifically, it assigns\ndifferent depth bins for different scenes, which can be selected by the model\nduring inference. Additionally, we incorporate learnable prompts to preprocess\nthe input text to convert the easily human-understood text into easily\nmodel-understood vectors and further enhance the performance. With only one\nimage per scene for training, our extensive experiment results on the NYU V2\nand KITTI dataset demonstrate that our method outperforms the previous\nstate-of-the-art method by up to 10.6\\% in terms of MARE.",
            "author": [
                "Xueting Hu",
                "Ce Zhang",
                "Yi Zhang",
                "Bowen Hai",
                "Ke Yu",
                "Zhihai He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01034v1",
                "http://arxiv.org/pdf/2311.01034v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01033v1",
            "title": "Non-Autoregressive Diffusion-based Temporal Point Processes for\n  Continuous-Time Long-Term Event Prediction",
            "updated": "2023-11-02T06:52:44Z",
            "published": "2023-11-02T06:52:44Z",
            "summary": "Continuous-time long-term event prediction plays an important role in many\napplication scenarios. Most existing works rely on autoregressive frameworks to\npredict event sequences, which suffer from error accumulation, thus\ncompromising prediction quality. Inspired by the success of denoising diffusion\nprobabilistic models, we propose a diffusion-based non-autoregressive temporal\npoint process model for long-term event prediction in continuous time. Instead\nof generating events one at a time in an autoregressive way, our model predicts\nthe future event sequence entirely as a whole. In order to perform diffusion\nprocesses on event sequences, we develop a bidirectional map between target\nevent sequences and the Euclidean vector space. Furthermore, we design a novel\ndenoising network to capture both sequential and contextual features for better\nsample quality. Extensive experiments are conducted to prove the superiority of\nour proposed model over state-of-the-art methods on long-term event prediction\nin continuous time. To the best of our knowledge, this is the first work to\napply diffusion methods to long-term event prediction problems.",
            "author": [
                "Wang-Tao Zhou",
                "Zhao Kang",
                "Ling Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01033v1",
                "http://arxiv.org/pdf/2311.01033v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01030v1",
            "title": "Joint Learning of Local and Global Features for Aspect-based Sentiment\n  Classification",
            "updated": "2023-11-02T06:43:50Z",
            "published": "2023-11-02T06:43:50Z",
            "summary": "Aspect-based sentiment classification (ASC) aims to judge the sentiment\npolarity conveyed by the given aspect term in a sentence. The sentiment\npolarity is not only determined by the local context but also related to the\nwords far away from the given aspect term. Most recent efforts related to the\nattention-based models can not sufficiently distinguish which words they should\npay more attention to in some cases. Meanwhile, graph-based models are coming\ninto ASC to encode syntactic dependency tree information. But these models do\nnot fully leverage syntactic dependency trees as they neglect to incorporate\ndependency relation tag information into representation learning effectively.\nIn this paper, we address these problems by effectively modeling the local and\nglobal features. Firstly, we design a local encoder containing: a Gaussian mask\nlayer and a covariance self-attention layer. The Gaussian mask layer tends to\nadjust the receptive field around aspect terms adaptively to deemphasize the\neffects of unrelated words and pay more attention to local information. The\ncovariance self-attention layer can distinguish the attention weights of\ndifferent words more obviously. Furthermore, we propose a dual-level graph\nattention network as a global encoder by fully employing dependency tag\ninformation to capture long-distance information effectively. Our model\nachieves state-of-the-art performance on both SemEval 2014 and Twitter\ndatasets.",
            "author": [
                "Hao Niu",
                "Yun Xiong",
                "Xiaosu Wang",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01030v1",
                "http://arxiv.org/pdf/2311.01030v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01028v1",
            "title": "Nonnegative/Binary Matrix Factorization for Image Classification using\n  Quantum Annealing",
            "updated": "2023-11-02T06:41:27Z",
            "published": "2023-11-02T06:41:27Z",
            "summary": "Classical computing has borne witness to the development of machine learning.\nThe integration of quantum technology into this mix will lead to unimaginable\nbenefits and be regarded as a giant leap forward in mankind's ability to\ncompute. Demonstrating the benefits of this integration now becomes essential.\nWith the advance of quantum computing, several machine-learning techniques have\nbeen proposed that use quantum annealing. In this study, we implement a matrix\nfactorization method using quantum annealing for image classification and\ncompare the performance with traditional machine-learning methods.\nNonnegative/binary matrix factorization (NBMF) was originally introduced as a\ngenerative model, and we propose a multiclass classification model as an\napplication. We extract the features of handwritten digit images using NBMF and\napply them to solve the classification problem. Our findings show that when the\namount of data, features, and epochs is small, the accuracy of models trained\nby NBMF is superior to classical machine-learning methods, such as neural\nnetworks. Moreover, we found that training models using a quantum annealing\nsolver significantly reduces computation time. Under certain conditions, there\nis a benefit to using quantum annealing technology with machine learning.",
            "author": [
                "Hinako Asaoka",
                "Kazue Kudo"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41598-023-43729-z",
                "http://arxiv.org/abs/2311.01028v1",
                "http://arxiv.org/pdf/2311.01028v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01024v1",
            "title": "Distance-Based Propagation for Efficient Knowledge Graph Reasoning",
            "updated": "2023-11-02T06:37:46Z",
            "published": "2023-11-02T06:37:46Z",
            "summary": "Knowledge graph completion (KGC) aims to predict unseen edges in knowledge\ngraphs (KGs), resulting in the discovery of new facts. A new class of methods\nhave been proposed to tackle this problem by aggregating path information.\nThese methods have shown tremendous ability in the task of KGC. However they\nare plagued by efficiency issues. Though there are a few recent attempts to\naddress this through learnable path pruning, they often sacrifice the\nperformance to gain efficiency. In this work, we identify two intrinsic\nlimitations of these methods that affect the efficiency and representation\nquality. To address the limitations, we introduce a new method, TAGNet, which\nis able to efficiently propagate information. This is achieved by only\naggregating paths in a fixed window for each source-target pair. We demonstrate\nthat the complexity of TAGNet is independent of the number of layers. Extensive\nexperiments demonstrate that TAGNet can cut down on the number of propagated\nmessages by as much as 90% while achieving competitive performance on multiple\nKG datasets. The code is available at https://github.com/HarryShomer/TAGNet.",
            "author": [
                "Harry Shomer",
                "Yao Ma",
                "Juanhui Li",
                "Bo Wu",
                "Charu C. Aggarwal",
                "Jiliang Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01024v1",
                "http://arxiv.org/pdf/2311.01024v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01023v1",
            "title": "Augmentation is AUtO-Net: Augmentation-Driven Contrastive Multiview\n  Learning for Medical Image Segmentation",
            "updated": "2023-11-02T06:31:08Z",
            "published": "2023-11-02T06:31:08Z",
            "summary": "The utilisation of deep learning segmentation algorithms that learn complex\norgans and tissue patterns and extract essential regions of interest from the\nnoisy background to improve the visual ability for medical image diagnosis has\nachieved impressive results in Medical Image Computing (MIC). This thesis\nfocuses on retinal blood vessel segmentation tasks, providing an extensive\nliterature review of deep learning-based medical image segmentation approaches\nwhile comparing the methodologies and empirical performances. The work also\nexamines the limitations of current state-of-the-art methods by pointing out\nthe two significant existing limitations: data size constraints and the\ndependency on high computational resources. To address such problems, this work\nproposes a novel efficient, simple multiview learning framework that\ncontrastively learns invariant vessel feature representation by comparing with\nmultiple augmented views by various transformations to overcome data shortage\nand improve generalisation ability. Moreover, the hybrid network architecture\nintegrates the attention mechanism into a Convolutional Neural Network to\nfurther capture complex continuous curvilinear vessel structures. The result\ndemonstrates the proposed method validated on the CHASE-DB1 dataset, attaining\nthe highest F1 score of 83.46% and the highest Intersection over Union (IOU)\nscore of 71.62% with UNet structure, surpassing existing benchmark UNet-based\nmethods by 1.95% and 2.8%, respectively. The combination of the metrics\nindicates the model detects the vessel object accurately with a highly\ncoincidental location with the ground truth. Moreover, the proposed approach\ncould be trained within 30 minutes by consuming less than 3 GB GPU RAM, and\nsuch characteristics support the efficient implementation for real-world\napplications and deployments.",
            "author": [
                "Yanming Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01023v1",
                "http://arxiv.org/pdf/2311.01023v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01022v1",
            "title": "NeuroWrite: Predictive Handwritten Digit Classification using Deep\n  Neural Networks",
            "updated": "2023-11-02T06:29:53Z",
            "published": "2023-11-02T06:29:53Z",
            "summary": "The rapid evolution of deep neural networks has revolutionized the field of\nmachine learning, enabling remarkable advancements in various domains. In this\narticle, we introduce NeuroWrite, a unique method for predicting the\ncategorization of handwritten digits using deep neural networks. Our model\nexhibits outstanding accuracy in identifying and categorising handwritten\ndigits by utilising the strength of convolutional neural networks (CNNs) and\nrecurrent neural networks (RNNs).In this article, we give a thorough\nexamination of the data preparation methods, network design, and training\nmethods used in NeuroWrite. By implementing state-of-the-art techniques, we\nshowcase how NeuroWrite can achieve high classification accuracy and robust\ngeneralization on handwritten digit datasets, such as MNIST. Furthermore, we\nexplore the model's potential for real-world applications, including digit\nrecognition in digitized documents, signature verification, and automated\npostal code recognition. NeuroWrite is a useful tool for computer vision and\npattern recognition because of its performance and adaptability.The\narchitecture, training procedure, and evaluation metrics of NeuroWrite are\ncovered in detail in this study, illustrating how it can improve a number of\napplications that call for handwritten digit classification. The outcomes show\nthat NeuroWrite is a promising method for raising the bar for deep neural\nnetwork-based handwritten digit recognition.",
            "author": [
                "Kottakota Asish",
                "P. Sarath Teja",
                "R. Kishan Chander",
                "Dr. D. Deva Hema"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01022v1",
                "http://arxiv.org/pdf/2311.01022v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "68T10, 68T45, 68T60",
                "I.4.8; I.5.2; J.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01020v1",
            "title": "On the Concerns of Developers When Using GitHub Copilot",
            "updated": "2023-11-02T06:24:38Z",
            "published": "2023-11-02T06:24:38Z",
            "summary": "With the recent advancement of Artificial Intelligence (AI) and the emergence\nof Large Language Models (LLMs), AI-based code generation tools have achieved\nsignificant progress and become a practical solution for software development.\nGitHub Copilot, referred to as AI pair programmer, utilizes machine learning\nmodels that are trained on a large corpus of code snippets to generate code\nsuggestions or auto-complete code using natural language processing. Despite\nits popularity, there is little empirical evidence on the actual experiences of\nsoftware developers who work with Copilot. To this end, we conducted an\nempirical study to understand the issues and challenges that developers face\nwhen using Copilot in practice, as well as their underlying causes and\npotential solutions. We collected data from 476 GitHub issues, 706 GitHub\ndiscussions, and 184 Stack Overflow posts, and identified the issues, causes\nthat trigger the issues, and solutions that resolve the issues when using\nCopilot. Our results reveal that (1) Usage Issue and Compatibility Issue are\nthe most common problems faced by Copilot users, (2) Copilot Internal Issue,\nNetwork Connection Issue, and Editor/IDE Compatibility Issue are identified as\nthe most frequent causes, and (3) Bug Fixed by Copilot, Modify\nConfiguration/Setting, and Use Suitable Version are the predominant solutions.\nBased on the results, we delve into the main challenges users encounter when\nimplementing Copilot in practical development, the possible impact of Copilot\non the coding process, aspects in which Copilot can be further enhanced, and\npotential new features desired by Copilot users.",
            "author": [
                "Xiyu Zhou",
                "Peng Liang",
                "Beiqi Zhang",
                "Zengyang Li",
                "Aakash Ahmad",
                "Mojtaba Shahin",
                "Muhammad Waseem"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01020v1",
                "http://arxiv.org/pdf/2311.01020v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01017v2",
            "title": "Learning Unsupervised World Models for Autonomous Driving via Discrete\n  Diffusion",
            "updated": "2023-11-24T00:24:06Z",
            "published": "2023-11-02T06:21:56Z",
            "summary": "Learning world models can teach an agent how the world works in an\nunsupervised manner. Even though it can be viewed as a special case of sequence\nmodeling, progress for scaling world models on robotic applications such as\nautonomous driving has been somewhat less rapid than scaling language models\nwith Generative Pre-trained Transformers (GPT). We identify two reasons as\nmajor bottlenecks: dealing with complex and unstructured observation space, and\nhaving a scalable generative model. Consequently, we propose a novel world\nmodeling approach that first tokenizes sensor observations with VQVAE, then\npredicts the future via discrete diffusion. To efficiently decode and denoise\ntokens in parallel, we recast Masked Generative Image Transformer into the\ndiscrete diffusion framework with a few simple changes, resulting in notable\nimprovement. When applied to learning world models on point cloud observations,\nour model reduces prior SOTA Chamfer distance by more than 65% for 1s\nprediction, and more than 50% for 3s prediction, across NuScenes, KITTI\nOdometry, and Argoverse2 datasets. Our results demonstrate that discrete\ndiffusion on tokenized agent experience can unlock the power of GPT-like\nunsupervised learning for robotic agents.",
            "author": [
                "Lunjun Zhang",
                "Yuwen Xiong",
                "Ze Yang",
                "Sergio Casas",
                "Rui Hu",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01017v2",
                "http://arxiv.org/pdf/2311.01017v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01011v1",
            "title": "Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game",
            "updated": "2023-11-02T06:13:36Z",
            "published": "2023-11-02T06:13:36Z",
            "summary": "While Large Language Models (LLMs) are increasingly being used in real-world\napplications, they remain vulnerable to prompt injection attacks: malicious\nthird party prompts that subvert the intent of the system designer. To help\nresearchers study this problem, we present a dataset of over 126,000 prompt\ninjection attacks and 46,000 prompt-based \"defenses\" against prompt injection,\nall created by players of an online game called Tensor Trust. To the best of\nour knowledge, this is currently the largest dataset of human-generated\nadversarial examples for instruction-following LLMs. The attacks in our dataset\nhave a lot of easily interpretable stucture, and shed light on the weaknesses\nof LLMs. We also use the dataset to create a benchmark for resistance to two\ntypes of prompt injection, which we refer to as prompt extraction and prompt\nhijacking. Our benchmark results show that many models are vulnerable to the\nattack strategies in the Tensor Trust dataset. Furthermore, we show that some\nattack strategies from the dataset generalize to deployed LLM-based\napplications, even though they have a very different set of constraints to the\ngame. We release all data and source code at https://tensortrust.ai/paper",
            "author": [
                "Sam Toyer",
                "Olivia Watkins",
                "Ethan Adrian Mendes",
                "Justin Svegliato",
                "Luke Bailey",
                "Tiffany Wang",
                "Isaac Ong",
                "Karim Elmaaroufi",
                "Pieter Abbeel",
                "Trevor Darrell",
                "Alan Ritter",
                "Stuart Russell"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01011v1",
                "http://arxiv.org/pdf/2311.01011v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01010v1",
            "title": "Exploring Unified Perspective For Fast Shapley Value Estimation",
            "updated": "2023-11-02T06:09:24Z",
            "published": "2023-11-02T06:09:24Z",
            "summary": "Shapley values have emerged as a widely accepted and trustworthy tool,\ngrounded in theoretical axioms, for addressing challenges posed by black-box\nmodels like deep neural networks. However, computing Shapley values encounters\nexponential complexity in the number of features. Various approaches, including\nApproSemivalue, KernelSHAP, and FastSHAP, have been explored to expedite the\ncomputation. We analyze the consistency of existing works and conclude that\nstochastic estimators can be unified as the linear transformation of importance\nsampling of feature subsets. Based on this, we investigate the possibility of\ndesigning simple amortized estimators and propose a straightforward and\nefficient one, SimSHAP, by eliminating redundant techniques. Extensive\nexperiments conducted on tabular and image datasets validate the effectiveness\nof our SimSHAP, which significantly accelerates the computation of accurate\nShapley values.",
            "author": [
                "Borui Zhang",
                "Baotong Tian",
                "Wenzhao Zheng",
                "Jie Zhou",
                "Jiwen Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01010v1",
                "http://arxiv.org/pdf/2311.01010v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01009v1",
            "title": "Revamping AI Models in Dermatology: Overcoming Critical Challenges for\n  Enhanced Skin Lesion Diagnosis",
            "updated": "2023-11-02T06:08:49Z",
            "published": "2023-11-02T06:08:49Z",
            "summary": "The surge in developing deep learning models for diagnosing skin lesions\nthrough image analysis is notable, yet their clinical black faces challenges.\nCurrent dermatology AI models have limitations: limited number of possible\ndiagnostic outputs, lack of real-world testing on uncommon skin lesions,\ninability to detect out-of-distribution images, and over-reliance on\ndermoscopic images. To address these, we present an All-In-One\n\\textbf{H}ierarchical-\\textbf{O}ut of Distribution-\\textbf{C}linical Triage\n(HOT) model. For a clinical image, our model generates three outputs: a\nhierarchical prediction, an alert for out-of-distribution images, and a\nrecommendation for dermoscopy if clinical image alone is insufficient for\ndiagnosis. When the recommendation is pursued, it integrates both clinical and\ndermoscopic images to deliver final diagnosis. Extensive experiments on a\nrepresentative cutaneous lesion dataset demonstrate the effectiveness and\nsynergy of each component within our framework. Our versatile model provides\nvaluable decision support for lesion diagnosis and sets a promising precedent\nfor medical AI applications.",
            "author": [
                "Deval Mehta",
                "Brigid Betz-Stablein",
                "Toan D Nguyen",
                "Yaniv Gal",
                "Adrian Bowling",
                "Martin Haskett",
                "Maithili Sashindranath",
                "Paul Bonnington",
                "Victoria Mar",
                "H Peter Soyer",
                "Zongyuan Ge"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01009v1",
                "http://arxiv.org/pdf/2311.01009v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01007v2",
            "title": "Effective Human-AI Teams via Learned Natural Language Rules and\n  Onboarding",
            "updated": "2023-11-07T20:34:09Z",
            "published": "2023-11-02T06:00:48Z",
            "summary": "People are relying on AI agents to assist them with various tasks. The human\nmust know when to rely on the agent, collaborate with the agent, or ignore its\nsuggestions. In this work, we propose to learn rules, grounded in data regions\nand described in natural language, that illustrate how the human should\ncollaborate with the AI. Our novel region discovery algorithm finds local\nregions in the data as neighborhoods in an embedding space where prior human\nbehavior should be corrected. Each region is then described using a large\nlanguage model in an iterative and contrastive procedure. We then teach these\nrules to the human via an onboarding stage. Through user studies on object\ndetection and question-answering tasks, we show that our method can lead to\nmore accurate human-AI teams. We also evaluate our region discovery and\ndescription algorithms separately.",
            "author": [
                "Hussein Mozannar",
                "Jimin J Lee",
                "Dennis Wei",
                "Prasanna Sattigeri",
                "Subhro Das",
                "David Sontag"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01007v2",
                "http://arxiv.org/pdf/2311.01007v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01004v1",
            "title": "Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning\n  for Medical Image Captioning",
            "updated": "2023-11-02T05:44:13Z",
            "published": "2023-11-02T05:44:13Z",
            "summary": "With the development of multimodality and large language models, the deep\nlearning-based technique for medical image captioning holds the potential to\noffer valuable diagnostic recommendations. However, current generic text and\nimage pre-trained models do not yield satisfactory results when it comes to\ndescribing intricate details within medical images. In this paper, we present a\nnovel medical image captioning method guided by the segment anything model\n(SAM) to enable enhanced encoding with both general and detailed feature\nextraction. In addition, our approach employs a distinctive pre-training\nstrategy with mixed semantic learning to simultaneously capture both the\noverall information and finer details within medical images. We demonstrate the\neffectiveness of this approach, as it outperforms the pre-trained BLIP2 model\non various evaluation metrics for generating descriptions of medical images.",
            "author": [
                "Gaoang Wang",
                "Zhenyu Zhang",
                "Benlu Wang",
                "Weijie Liang",
                "Yizhi Li",
                "Xuechen Guo",
                "Guanhong Wang",
                "Shiyan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01004v1",
                "http://arxiv.org/pdf/2311.01004v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01002v1",
            "title": "Robust Data Pruning under Label Noise via Maximizing Re-labeling\n  Accuracy",
            "updated": "2023-11-02T05:40:26Z",
            "published": "2023-11-02T05:40:26Z",
            "summary": "Data pruning, which aims to downsize a large training set into a small\ninformative subset, is crucial for reducing the enormous computational costs of\nmodern deep learning. Though large-scale data collections invariably contain\nannotation noise and numerous robust learning methods have been developed, data\npruning for the noise-robust learning scenario has received little attention.\nWith state-of-the-art Re-labeling methods that self-correct erroneous labels\nwhile training, it is challenging to identify which subset induces the most\naccurate re-labeling of erroneous labels in the entire training set. In this\npaper, we formalize the problem of data pruning with re-labeling. We first show\nthat the likelihood of a training example being correctly re-labeled is\nproportional to the prediction confidence of its neighborhood in the subset.\nTherefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a\nsubset maximizing the total neighborhood confidence of all training examples,\nthereby maximizing the re-labeling accuracy and generalization performance.\nExtensive experiments on four real and one synthetic noisy datasets show that\n\\algname{} outperforms the baselines with Re-labeling models by up to 9.1% as\nwell as those with a standard model by up to 21.6%.",
            "author": [
                "Dongmin Park",
                "Seola Choi",
                "Doyoung Kim",
                "Hwanjun Song",
                "Jae-Gil Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01002v1",
                "http://arxiv.org/pdf/2311.01002v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00998v1",
            "title": "Replicable Benchmarking of Neural Machine Translation (NMT) on\n  Low-Resource Local Languages in Indonesia",
            "updated": "2023-11-02T05:27:48Z",
            "published": "2023-11-02T05:27:48Z",
            "summary": "Neural machine translation (NMT) for low-resource local languages in\nIndonesia faces significant challenges, including the need for a representative\nbenchmark and limited data availability. This work addresses these challenges\nby comprehensively analyzing training NMT systems for four low-resource local\nlanguages in Indonesia: Javanese, Sundanese, Minangkabau, and Balinese. Our\nstudy encompasses various training approaches, paradigms, data sizes, and a\npreliminary study into using large language models for synthetic low-resource\nlanguages parallel data generation. We reveal specific trends and insights into\npractical strategies for low-resource language translation. Our research\ndemonstrates that despite limited computational resources and textual data,\nseveral of our NMT systems achieve competitive performances, rivaling the\ntranslation quality of zero-shot gpt-3.5-turbo. These findings significantly\nadvance NMT for low-resource languages, offering valuable guidance for\nresearchers in similar contexts.",
            "author": [
                "Lucky Susanto",
                "Ryandito Diandaru",
                "Adila Krisnadhi",
                "Ayu Purwarianti",
                "Derry Wijaya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00998v1",
                "http://arxiv.org/pdf/2311.00998v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01479v2",
            "title": "Detecting Out-of-Distribution Through the Lens of Neural Collapse",
            "updated": "2023-11-07T01:40:19Z",
            "published": "2023-11-02T05:18:28Z",
            "summary": "Out-of-distribution (OOD) detection is essential for the safe deployment of\nAI. Particularly, OOD detectors should generalize effectively across diverse\nscenarios. To improve upon the generalizability of existing OOD detectors, we\nintroduce a highly versatile OOD detector, called Neural Collapse inspired OOD\ndetector (NC-OOD). We extend the prevalent observation that in-distribution\n(ID) features tend to form clusters, whereas OOD features are far away.\nParticularly, based on the recent observation, Neural Collapse, we further\ndemonstrate that ID features tend to cluster in proximity to weight vectors.\nFrom our extended observation, we propose to detect OOD based on feature\nproximity to weight vectors. To further rule out OOD samples, we leverage the\nobservation that OOD features tend to reside closer to the origin than ID\nfeatures. Extensive experiments show that our approach enhances the\ngeneralizability of existing work and can consistently achieve state-of-the-art\nOOD detection performance across a wide range of OOD Benchmarks over different\nclassification tasks, training losses, and model architectures.",
            "author": [
                "Litian Liu",
                "Yao Qin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01479v2",
                "http://arxiv.org/pdf/2311.01479v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00994v1",
            "title": "LaughTalk: Expressive 3D Talking Head Generation with Laughter",
            "updated": "2023-11-02T05:04:33Z",
            "published": "2023-11-02T05:04:33Z",
            "summary": "Laughter is a unique expression, essential to affirmative social interactions\nof humans. Although current 3D talking head generation methods produce\nconvincing verbal articulations, they often fail to capture the vitality and\nsubtleties of laughter and smiles despite their importance in social context.\nIn this paper, we introduce a novel task to generate 3D talking heads capable\nof both articulate speech and authentic laughter. Our newly curated dataset\ncomprises 2D laughing videos paired with pseudo-annotated and human-validated\n3D FLAME parameters and vertices. Given our proposed dataset, we present a\nstrong baseline with a two-stage training scheme: the model first learns to\ntalk and then acquires the ability to express laughter. Extensive experiments\ndemonstrate that our method performs favorably compared to existing approaches\nin both talking head generation and expressing laughter signals. We further\nexplore potential applications on top of our proposed method for rigging\nrealistic avatars.",
            "author": [
                "Kim Sung-Bin",
                "Lee Hyun",
                "Da Hye Hong",
                "Suekyeong Nam",
                "Janghoon Ju",
                "Tae-Hyun Oh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00994v1",
                "http://arxiv.org/pdf/2311.00994v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14681v1",
            "title": "Instance-Specific Asymmetric Sensitivity in Differential Privacy",
            "updated": "2023-11-02T05:01:45Z",
            "published": "2023-11-02T05:01:45Z",
            "summary": "We provide a new algorithmic framework for differentially private estimation\nof general functions that adapts to the hardness of the underlying dataset. We\nbuild upon previous work that gives a paradigm for selecting an output through\nthe exponential mechanism based upon closeness of the inverse to the underlying\ndataset, termed the inverse sensitivity mechanism. Our framework will slightly\nmodify the closeness metric and instead give a simple and efficient application\nof the sparse vector technique. While the inverse sensitivity mechanism was\nshown to be instance optimal, it was only with respect to a class of unbiased\nmechanisms such that the most likely outcome matches the underlying data. We\nbreak this assumption in order to more naturally navigate the bias-variance\ntradeoff, which will also critically allow for extending our method to\nunbounded data. In consideration of this tradeoff, we provide strong intuition\nand empirical validation that our technique will be particularly effective when\nthe distances to the underlying dataset are asymmetric. This asymmetry is\ninherent to a range of important problems including fundamental statistics such\nas variance, as well as commonly used machine learning performance metrics for\nboth classification and regression tasks. We efficiently instantiate our method\nin $O(n)$ time for these problems and empirically show that our techniques will\ngive substantially improved differentially private estimations.",
            "author": [
                "David Durfee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14681v1",
                "http://arxiv.org/pdf/2311.14681v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00993v1",
            "title": "Scalable Probabilistic Forecasting in Retail with Gradient Boosted\n  Trees: A Practitioner's Approach",
            "updated": "2023-11-02T04:46:32Z",
            "published": "2023-11-02T04:46:32Z",
            "summary": "The recent M5 competition has advanced the state-of-the-art in retail\nforecasting. However, we notice important differences between the competition\nchallenge and the challenges we face in a large e-commerce company. The\ndatasets in our scenario are larger (hundreds of thousands of time series), and\ne-commerce can afford to have a larger assortment than brick-and-mortar\nretailers, leading to more intermittent data. To scale to larger dataset sizes\nwith feasible computational effort, firstly, we investigate a two-layer\nhierarchy and propose a top-down approach to forecasting at an aggregated level\nwith less amount of series and intermittency, and then disaggregating to obtain\nthe decision-level forecasts. Probabilistic forecasts are generated under\ndistributional assumptions. Secondly, direct training at the lower level with\nsubsamples can also be an alternative way of scaling. Performance of modelling\nwith subsets is evaluated with the main dataset. Apart from a proprietary\ndataset, the proposed scalable methods are evaluated using the Favorita dataset\nand the M5 dataset. We are able to show the differences in characteristics of\nthe e-commerce and brick-and-mortar retail datasets. Notably, our top-down\nforecasting framework enters the top 50 of the original M5 competition, even\nwith models trained at a higher level under a much simpler setting.",
            "author": [
                "Xueying Long",
                "Quang Bui",
                "Grady Oktavian",
                "Daniel F. Schmidt",
                "Christoph Bergmeir",
                "Rakshitha Godahewa",
                "Seong Per Lee",
                "Kaifeng Zhao",
                "Paul Condylis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00993v1",
                "http://arxiv.org/pdf/2311.00993v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00987v1",
            "title": "CML-MOTS: Collaborative Multi-task Learning for Multi-Object Tracking\n  and Segmentation",
            "updated": "2023-11-02T04:32:24Z",
            "published": "2023-11-02T04:32:24Z",
            "summary": "The advancement of computer vision has pushed visual analysis tasks from\nstill images to the video domain. In recent years, video instance segmentation,\nwhich aims to track and segment multiple objects in video frames, has drawn\nmuch attention for its potential applications in various emerging areas such as\nautonomous driving, intelligent transportation, and smart retail. In this\npaper, we propose an effective framework for instance-level visual analysis on\nvideo frames, which can simultaneously conduct object detection, instance\nsegmentation, and multi-object tracking. The core idea of our method is\ncollaborative multi-task learning which is achieved by a novel structure, named\nassociative connections among detection, segmentation, and tracking task heads\nin an end-to-end learnable CNN. These additional connections allow information\npropagation across multiple related tasks, so as to benefit these tasks\nsimultaneously. We evaluate the proposed method extensively on KITTI MOTS and\nMOTS Challenge datasets and obtain quite encouraging results.",
            "author": [
                "Yiming Cui",
                "Cheng Han",
                "Dongfang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00987v1",
                "http://arxiv.org/pdf/2311.00987v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00986v1",
            "title": "M&M3D: Multi-Dataset Training and Efficient Network for Multi-view 3D\n  Object Detection",
            "updated": "2023-11-02T04:28:51Z",
            "published": "2023-11-02T04:28:51Z",
            "summary": "In this research, I proposed a network structure for multi-view 3D object\ndetection using camera-only data and a Bird's-Eye-View map. My work is based on\na current key challenge domain adaptation and visual data transfer. Although\nmany excellent camera-only 3D object detection has been continuously proposed,\nmany research work risk dramatic performance drop when the networks are trained\non the source domain but tested on a different target domain. Then I found it\nis very surprising that predictions on bounding boxes and classes are still\nreplied to on 2D networks. Based on the domain gap assumption on various 3D\ndatasets, I found they still shared a similar data extraction on the same BEV\nmap size and camera data transfer. Therefore, to analyze the domain gap\ninfluence on the current method and to make good use of 3D space information\namong the dataset and the real world, I proposed a transfer learning method and\nTransformer construction to study the 3D object detection on NuScenes-mini and\nLyft. Through multi-dataset training and a detection head from the Transformer,\nthe network demonstrated good data migration performance and efficient\ndetection performance by using 3D anchor query and 3D positional information.\nRelying on only a small amount of source data and the existing large model\npre-training weights, the efficient network manages to achieve competitive\nresults on the new target domain. Moreover, my study utilizes 3D information as\navailable semantic information and 2D multi-view image features blending into\nthe visual-language transfer design. In the final 3D anchor box prediction and\nobject classification, my network achieved good results on standard metrics of\n3D object detection, which differs from dataset-specific models on each\ntraining domain without any fine-tuning.",
            "author": [
                "Hang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00986v1",
                "http://arxiv.org/pdf/2311.00986v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01478v1",
            "title": "Adversary ML Resilience in Autonomous Driving Through Human Centered\n  Perception Mechanisms",
            "updated": "2023-11-02T04:11:45Z",
            "published": "2023-11-02T04:11:45Z",
            "summary": "Physical adversarial attacks on road signs are continuously exploiting\nvulnerabilities in modern day autonomous vehicles (AVs) and impeding their\nability to correctly classify what type of road sign they encounter. Current\nmodels cannot generalize input data well, resulting in overfitting or\nunderfitting. In overfitting, the model memorizes the input data but cannot\ngeneralize to new scenarios. In underfitting, the model does not learn enough\nof the input data to accurately classify these road signs. This paper explores\nthe resilience of autonomous driving systems against three main physical\nadversarial attacks (tape, graffiti, illumination), specifically targeting\nobject classifiers. Several machine learning models were developed and\nevaluated on two distinct datasets: road signs (stop signs, speed limit signs,\ntraffic lights, and pedestrian crosswalk signs) and geometric shapes (octagons,\ncircles, squares, and triangles). The study compared algorithm performance\nunder different conditions, including clean and adversarial training and\ntesting on these datasets. To build robustness against attacks, defense\ntechniques like adversarial training and transfer learning were implemented.\nResults demonstrated transfer learning models played a crucial role in\nperformance by allowing knowledge gained from shape training to improve\ngeneralizability of road sign classification, despite the datasets being\ncompletely different. The paper suggests future research directions, including\nhuman-in-the-loop validation, security analysis, real-world testing, and\nexplainable AI for transparency. This study aims to contribute to improving\nsecurity and robustness of object classifiers in autonomous vehicles and\nmitigating adversarial example impacts on driving systems.",
            "author": [
                "Aakriti Shah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01478v1",
                "http://arxiv.org/pdf/2311.01478v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "68",
                "I.4.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00983v1",
            "title": "Optimizing Inventory Routing: A Decision-Focused Learning Approach using\n  Neural Networks",
            "updated": "2023-11-02T04:05:28Z",
            "published": "2023-11-02T04:05:28Z",
            "summary": "Inventory Routing Problem (IRP) is a crucial challenge in supply chain\nmanagement as it involves optimizing efficient route selection while\nconsidering the uncertainty of inventory demand planning. To solve IRPs,\nusually a two-stage approach is employed, where demand is predicted using\nmachine learning techniques first, and then an optimization algorithm is used\nto minimize routing costs. Our experiment shows machine learning models fall\nshort of achieving perfect accuracy because inventory levels are influenced by\nthe dynamic business environment, which, in turn, affects the optimization\nproblem in the next stage, resulting in sub-optimal decisions. In this paper,\nwe formulate and propose a decision-focused learning-based approach to solving\nreal-world IRPs. This approach directly integrates inventory prediction and\nrouting optimization within an end-to-end system potentially ensuring a robust\nsupply chain strategy.",
            "author": [
                "MD Shafikul Islam",
                "Azmine Toushik Wasi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00983v1",
                "http://arxiv.org/pdf/2311.00983v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04916v1",
            "title": "Explainable Identification of Hate Speech towards Islam using Graph\n  Neural Networks",
            "updated": "2023-11-02T04:01:04Z",
            "published": "2023-11-02T04:01:04Z",
            "summary": "Islamophobic language is a prevalent challenge on online social interaction\nplatforms. Identifying and eliminating such hatred is a crucial step towards a\nfuture of harmony and peace. This study presents a novel paradigm for\nidentifying and explaining hate speech towards Islam using graph neural\nnetworks. Utilizing the intrinsic ability of graph neural networks to find,\nextract, and use relationships across disparate data points, our model\nconsistently achieves outstanding performance while offering explanations for\nthe underlying correlations and causation.",
            "author": [
                "Azmine Toushik Wasi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04916v1",
                "http://arxiv.org/pdf/2311.04916v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00981v1",
            "title": "Fast generation of mock galaxy catalogues with COLA",
            "updated": "2023-11-02T03:57:39Z",
            "published": "2023-11-02T03:57:39Z",
            "summary": "We investigate the feasibility of using COmoving Lagrangian Acceleration\n(COLA) technique to efficiently generate galaxy mock catalogues that can\naccurately reproduce the statistical properties of observed galaxies. Our\nproposed scheme combines the subhalo abundance matching (SHAM) procedure with\nCOLA simulations, utilizing only three free parameters: the scatter magnitude\n($\\sigma_{\\rm scat}$) in SHAM, the initial redshift ($z_{\\rm init}$) of the\nCOLA simulation, and the time stride ($da$) used by COLA. In this\nproof-of-concept study, we focus on a subset of BOSS CMASS NGC galaxies within\nthe redshift range $z\\in [0.45, 0.55]$. We perform $\\mathtt{GADGET}$ simulation\nand low-resolution COLA simulations with various combinations of $(z_{\\rm\ninit}, da)$, each using $1024^{3}$ particles in an $800~h^{-1}{\\rm Mpc}$ box.\nBy minimizing the difference between COLA mock and CMASS NGC galaxies for the\nmonopole of the two-point correlation function (2PCF), we obtain the optimal\n$\\sigma_{\\rm scat}$. We have found that by setting $z_{\\rm init}=29$ and\n$da=1/30$, we achieve a good agreement between COLA mock and CMASS NGC galaxies\nwithin the range of 4 to $20~h^{-1}{\\rm Mpc}$, with a computational cost two\norders of magnitude lower than that of the N-body code. Moreover, a detailed\nverification is performed by comparing various statistical properties, such as\nanisotropic 2PCF, three-point clustering, and power spectrum multipoles, which\nshows similar performance between GADGET mock and COLA mock catalogues with the\nCMASS NGC galaxies. Furthermore, we assess the robustness of the COLA mock\ncatalogues across different cosmological models, demonstrating consistent\nresults in the resulting 2PCFs. Our findings suggest that COLA simulations are\na promising tool for efficiently generating mock catalogues for emulators and\nmachine learning analyses in exploring the large-scale structure of the\nUniverse.",
            "author": [
                "Jiacheng Ding",
                "Shaohong Li",
                "Yi Zheng",
                "Xiaolin Luo",
                "Le Zhang",
                "Xiao-Dong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00981v1",
                "http://arxiv.org/pdf/2311.00981v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00979v2",
            "title": "Overhead Line Defect Recognition Based on Unsupervised Semantic\n  Segmentation",
            "updated": "2023-12-06T23:51:11Z",
            "published": "2023-11-02T03:52:59Z",
            "summary": "Overhead line inspection greatly benefits from defect recognition using\nvisible light imagery. Addressing the limitations of existing feature\nextraction techniques and the heavy data dependency of deep learning\napproaches, this paper introduces a novel defect recognition framework. This is\nbuilt on the Faster RCNN network and complemented by unsupervised semantic\nsegmentation. The approach involves identifying the type and location of the\ntarget equipment, utilizing semantic segmentation to differentiate between the\ndevice and its backdrop, and finally employing similarity measures and logical\nrules to categorize the type of defect. Experimental results indicate that this\nmethodology focuses more on the equipment rather than the defects when\nidentifying issues in overhead lines. This leads to a notable enhancement in\naccuracy and exhibits impressive adaptability. Thus, offering a fresh\nperspective for automating the inspection of distribution network equipment.",
            "author": [
                "Weixi Wang",
                "Xichen Zhong",
                "Xin Li",
                "Sizhe Li",
                "Xun Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00979v2",
                "http://arxiv.org/pdf/2311.00979v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00975v2",
            "title": "Autonomous Learning of Generative Models with Chemical Reaction Network\n  Ensembles",
            "updated": "2023-11-06T19:07:59Z",
            "published": "2023-11-02T03:46:23Z",
            "summary": "Can a micron sized sack of interacting molecules autonomously learn an\ninternal model of a complex and fluctuating environment? We draw insights from\ncontrol theory, machine learning theory, chemical reaction network theory, and\nstatistical physics to develop a general architecture whereby a broad class of\nchemical systems can autonomously learn complex distributions. Our construction\ntakes the form of a chemical implementation of machine learning's optimization\nworkhorse: gradient descent on the relative entropy cost function. We show how\nthis method can be applied to optimize any detailed balanced chemical reaction\nnetwork and that the construction is capable of using hidden units to learn\ncomplex distributions. This result is then recast as a form of integral\nfeedback control. Finally, due to our use of an explicit physical model of\nlearning, we are able to derive thermodynamic costs and trade-offs associated\nto this process.",
            "author": [
                "William Poole",
                "Thomas E. Ouldridge",
                "Manoj Gopalkrishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00975v2",
                "http://arxiv.org/pdf/2311.00975v2"
            ],
            "primary_category": "q-bio.MN",
            "category": [
                "q-bio.MN",
                "cs.ET",
                "cs.LG",
                "cs.NE",
                "cs.SY",
                "eess.SY",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00973v1",
            "title": "Federated Linear Bandits with Finite Adversarial Actions",
            "updated": "2023-11-02T03:41:58Z",
            "published": "2023-11-02T03:41:58Z",
            "summary": "We study a federated linear bandits model, where $M$ clients communicate with\na central server to solve a linear contextual bandits problem with finite\nadversarial action sets that may be different across clients. To address the\nunique challenges of adversarial finite action sets, we propose the\nFedSupLinUCB algorithm, which extends the principles of SupLinUCB and OFUL\nalgorithms in linear contextual bandits. We prove that FedSupLinUCB achieves a\ntotal regret of $\\tilde{O}(\\sqrt{d T})$, where $T$ is the total number of arm\npulls from all clients, and $d$ is the ambient dimension of the linear model.\nThis matches the minimax lower bound and thus is order-optimal (up to polylog\nterms). We study both asynchronous and synchronous cases and show that the\ncommunication cost can be controlled as $O(d M^2 \\log(d)\\log(T))$ and\n$O(\\sqrt{d^3 M^3} \\log(d))$, respectively. The FedSupLinUCB design is further\nextended to two scenarios: (1) variance-adaptive, where a total regret of\n$\\tilde{O} (\\sqrt{d \\sum \\nolimits_{t=1}^{T} \\sigma_t^2})$ can be achieved with\n$\\sigma_t^2$ being the noise variance of round $t$; and (2) adversarial\ncorruption, where a total regret of $\\tilde{O}(\\sqrt{dT} + d C_p)$ can be\nachieved with $C_p$ being the total corruption budget. Experiment results\ncorroborate the theoretical analysis and demonstrate the effectiveness of\nFedSupLinUCB on both synthetic and real-world datasets.",
            "author": [
                "Li Fan",
                "Ruida Zhou",
                "Chao Tian",
                "Cong Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00973v1",
                "http://arxiv.org/pdf/2311.00973v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00971v1",
            "title": "An Integrated Framework Integrating Monte Carlo Tree Search and\n  Supervised Learning for Train Timetabling Problem",
            "updated": "2023-11-02T03:39:14Z",
            "published": "2023-11-02T03:39:14Z",
            "summary": "The single-track railway train timetabling problem (TTP) is an important and\ncomplex problem. This article proposes an integrated Monte Carlo Tree Search\n(MCTS) computing framework that combines heuristic methods, unsupervised\nlearning methods, and supervised learning methods for solving TTP in discrete\naction spaces. This article first describes the mathematical model and\nsimulation system dynamics of TTP, analyzes the characteristics of the solution\nfrom the perspective of MCTS, and proposes some heuristic methods to improve\nMCTS. This article considers these methods as planners in the proposed\nframework. Secondly, this article utilizes deep convolutional neural networks\nto approximate the value of nodes and further applies them to the MCTS search\nprocess, referred to as learners. The experiment shows that the proposed\nheuristic MCTS method is beneficial for solving TTP; The algorithm framework\nthat integrates planners and learners can improve the data efficiency of\nsolving TTP; The proposed method provides a new paradigm for solving TTP.",
            "author": [
                "Feiyu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00971v1",
                "http://arxiv.org/pdf/2311.00971v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00970v1",
            "title": "Lightweight super resolution network for point cloud geometry\n  compression",
            "updated": "2023-11-02T03:34:51Z",
            "published": "2023-11-02T03:34:51Z",
            "summary": "This paper presents an approach for compressing point cloud geometry by\nleveraging a lightweight super-resolution network. The proposed method involves\ndecomposing a point cloud into a base point cloud and the interpolation\npatterns for reconstructing the original point cloud. While the base point\ncloud can be efficiently compressed using any lossless codec, such as\nGeometry-based Point Cloud Compression, a distinct strategy is employed for\nhandling the interpolation patterns. Rather than directly compressing the\ninterpolation patterns, a lightweight super-resolution network is utilized to\nlearn this information through overfitting. Subsequently, the network parameter\nis transmitted to assist in point cloud reconstruction at the decoder side.\nNotably, our approach differentiates itself from lookup table-based methods,\nallowing us to obtain more accurate interpolation patterns by accessing a\nbroader range of neighboring voxels at an acceptable computational cost.\nExperiments on MPEG Cat1 (Solid) and Cat2 datasets demonstrate the remarkable\ncompression performance achieved by our method.",
            "author": [
                "Wei Zhang",
                "Dingquan Li",
                "Ge Li",
                "Wen Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00970v1",
                "http://arxiv.org/pdf/2311.00970v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00967v1",
            "title": "Vision-Language Interpreter for Robot Task Planning",
            "updated": "2023-11-02T03:32:30Z",
            "published": "2023-11-02T03:32:30Z",
            "summary": "Large language models (LLMs) are accelerating the development of\nlanguage-guided robot planners. Meanwhile, symbolic planners offer the\nadvantage of interpretability. This paper proposes a new task that bridges\nthese two trends, namely, multimodal planning problem specification. The aim is\nto generate a problem description (PD), a machine-readable file used by the\nplanners to find a plan. By generating PDs from language instruction and scene\nobservation, we can drive symbolic planners in a language-guided framework. We\npropose a Vision-Language Interpreter (ViLaIn), a new framework that generates\nPDs using state-of-the-art LLM and vision-language models. ViLaIn can refine\ngenerated PDs via error message feedback from the symbolic planner. Our aim is\nto answer the question: How accurately can ViLaIn and the symbolic planner\ngenerate valid robot plans? To evaluate ViLaIn, we introduce a novel dataset\ncalled the problem description generation (ProDG) dataset. The framework is\nevaluated with four new evaluation metrics. Experimental results show that\nViLaIn can generate syntactically correct problems with more than 99% accuracy\nand valid plans with more than 58% accuracy.",
            "author": [
                "Keisuke Shirai",
                "Cristian C. Beltran-Hernandez",
                "Masashi Hamaya",
                "Atsushi Hashimoto",
                "Shohei Tanaka",
                "Kento Kawaharazuka",
                "Kazutoshi Tanaka",
                "Yoshitaka Ushiku",
                "Shinsuke Mori"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00967v1",
                "http://arxiv.org/pdf/2311.00967v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02104v1",
            "title": "Efficient Symbolic Policy Learning with Differentiable Symbolic\n  Expression",
            "updated": "2023-11-02T03:27:51Z",
            "published": "2023-11-02T03:27:51Z",
            "summary": "Deep reinforcement learning (DRL) has led to a wide range of advances in\nsequential decision-making tasks. However, the complexity of neural network\npolicies makes it difficult to understand and deploy with limited computational\nresources. Currently, employing compact symbolic expressions as symbolic\npolicies is a promising strategy to obtain simple and interpretable policies.\nPrevious symbolic policy methods usually involve complex training processes and\npre-trained neural network policies, which are inefficient and limit the\napplication of symbolic policies. In this paper, we propose an efficient\ngradient-based learning method named Efficient Symbolic Policy Learning (ESPL)\nthat learns the symbolic policy from scratch in an end-to-end way. We introduce\na symbolic network as the search space and employ a path selector to find the\ncompact symbolic policy. By doing so we represent the policy with a\ndifferentiable symbolic expression and train it in an off-policy manner which\nfurther improves the efficiency. In addition, in contrast with previous\nsymbolic policies which only work in single-task RL because of complexity, we\nexpand ESPL on meta-RL to generate symbolic policies for unseen tasks.\nExperimentally, we show that our approach generates symbolic policies with\nhigher performance and greatly improves data efficiency for single-task RL. In\nmeta-RL, we demonstrate that compared with neural network policies the proposed\nsymbolic policy achieves higher performance and efficiency and shows the\npotential to be interpretable.",
            "author": [
                "Jiaming Guo",
                "Rui Zhang",
                "Shaohui Peng",
                "Qi Yi",
                "Xing Hu",
                "Ruizhi Chen",
                "Zidong Du",
                "Xishan Zhang",
                "Ling Li",
                "Qi Guo",
                "Yunji Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02104v1",
                "http://arxiv.org/pdf/2311.02104v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00966v1",
            "title": "Invariant-Feature Subspace Recovery: A New Class of Provable Domain\n  Generalization Algorithms",
            "updated": "2023-11-02T03:24:55Z",
            "published": "2023-11-02T03:24:55Z",
            "summary": "Domain generalization asks for models trained over a set of training\nenvironments to generalize well in unseen test environments. Recently, a series\nof algorithms such as Invariant Risk Minimization (IRM) have been proposed for\ndomain generalization. However, Rosenfeld et al. (2021) shows that in a simple\nlinear data model, even if non-convexity issues are ignored, IRM and its\nextensions cannot generalize to unseen environments with less than $d_s+1$\ntraining environments, where $d_s$ is the dimension of the spurious-feature\nsubspace. In this work, we propose Invariant-feature Subspace Recovery (ISR): a\nnew class of algorithms to achieve provable domain generalization across the\nsettings of classification and regression problems. First, in the binary\nclassification setup of Rosenfeld et al. (2021), we show that our first\nalgorithm, ISR-Mean, can identify the subspace spanned by invariant features\nfrom the first-order moments of the class-conditional distributions, and\nachieve provable domain generalization with $d_s+1$ training environments. Our\nsecond algorithm, ISR-Cov, further reduces the required number of training\nenvironments to $O(1)$ using the information of second-order moments. Notably,\nunlike IRM, our algorithms bypass non-convexity issues and enjoy global\nconvergence guarantees. Next, we extend ISR-Mean to the more general setting of\nmulti-class classification and propose ISR-Multiclass, which leverages class\ninformation and provably recovers the invariant-feature subspace with $\\lceil\nd_s/k\\rceil+1$ training environments for $k$-class classification. Finally, for\nregression problems, we propose ISR-Regression that can identify the\ninvariant-feature subspace with $d_s+1$ training environments. Empirically, we\ndemonstrate the superior performance of our ISRs on synthetic benchmarks.\nFurther, ISR can be used as post-processing methods for feature extractors such\nas neural nets.",
            "author": [
                "Haoxiang Wang",
                "Gargi Balasubramaniam",
                "Haozhe Si",
                "Bo Li",
                "Han Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00966v1",
                "http://arxiv.org/pdf/2311.00966v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00964v1",
            "title": "On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for\n  Fintech Applications",
            "updated": "2023-11-02T03:18:40Z",
            "published": "2023-11-02T03:18:40Z",
            "summary": "Rules are widely used in Fintech institutions to make fraud prevention\ndecisions, since rules are highly interpretable thanks to their intuitive\nif-then structure. In practice, a two-stage framework of fraud prevention\ndecision rule set mining is usually employed in large Fintech institutions.\nThis paper is concerned with finding high-quality rule subsets in a\nbi-objective space (such as precision and recall) from an initial pool of\nrules. To this end, we adopt the concept of Pareto optimality and aim to find a\nset of non-dominated rule subsets, which constitutes a Pareto front. We propose\na heuristic-based framework called PORS and we identify that the core of PORS\nis the problem of solution selection on the front (SSF). We provide a\nsystematic categorization of the SSF problem and a thorough empirical\nevaluation of various SSF methods on both public and proprietary datasets. We\nalso introduce a novel variant of sequential covering algorithm called\nSpectralRules to encourage the diversity of the initial rule set and we\nempirically find that SpectralRules further improves the quality of the found\nPareto front. On two real application scenarios within Alipay, we demonstrate\nthe advantages of our proposed methodology compared to existing work.",
            "author": [
                "Chengyao Wen",
                "Yin Lou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00964v1",
                "http://arxiv.org/pdf/2311.00964v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-fin.ST"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00962v1",
            "title": "Detecting Generated Images by Real Images Only",
            "updated": "2023-11-02T03:09:37Z",
            "published": "2023-11-02T03:09:37Z",
            "summary": "As deep learning technology continues to evolve, the images yielded by\ngenerative models are becoming more and more realistic, triggering people to\nquestion the authenticity of images. Existing generated image detection methods\ndetect visual artifacts in generated images or learn discriminative features\nfrom both real and generated images by massive training. This learning paradigm\nwill result in efficiency and generalization issues, making detection methods\nalways lag behind generation methods. This paper approaches the generated image\ndetection problem from a new perspective: Start from real images. By finding\nthe commonality of real images and mapping them to a dense subspace in feature\nspace, the goal is that generated images, regardless of their generative model,\nare then projected outside the subspace. As a result, images from different\ngenerative models can be detected, solving some long-existing problems in the\nfield. Experimental results show that although our method was trained only by\nreal images and uses 99.9\\% less training data than other deep learning-based\nmethods, it can compete with state-of-the-art methods and shows excellent\nperformance in detecting emerging generative models with high inference\nefficiency. Moreover, the proposed method shows robustness against various\npost-processing. These advantages allow the method to be used in real-world\nscenarios.",
            "author": [
                "Xiuli Bi",
                "Bo Liu",
                "Fan Yang",
                "Bin Xiao",
                "Weisheng Li",
                "Gao Huang",
                "Pamela C. Cosman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00962v1",
                "http://arxiv.org/pdf/2311.00962v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00961v1",
            "title": "Concatenated Masked Autoencoders as Spatial-Temporal Learner",
            "updated": "2023-11-02T03:08:26Z",
            "published": "2023-11-02T03:08:26Z",
            "summary": "Learning representations from videos requires understanding continuous motion\nand visual correspondences between frames. In this paper, we introduce the\nConcatenated Masked Autoencoders (CatMAE) as a spatial-temporal learner for\nself-supervised video representation learning. For the input sequence of video\nframes, CatMAE keeps the initial frame unchanged while applying substantial\nmasking (95%) to subsequent frames. The encoder in CatMAE is responsible for\nencoding visible patches for each frame individually; subsequently, for each\nmasked frame, the decoder leverages visible patches from both previous and\ncurrent frames to reconstruct the original image. Our proposed method enables\nthe model to estimate the motion information between visible patches, match the\ncorrespondences between preceding and succeeding frames, and ultimately learn\nthe evolution of scenes. Furthermore, we propose a new data augmentation\nstrategy, Video-Reverse (ViRe), which uses reversed video frames as the model's\nreconstruction targets. This further encourages the model to utilize continuous\nmotion details and correspondences to complete the reconstruction, thereby\nenhancing the model's capabilities. Compared to the most advanced pre-training\nmethods, CatMAE achieves a leading level in video segmentation tasks and action\nrecognition tasks.",
            "author": [
                "Zhouqiang Jiang",
                "Bowen Wang",
                "Tong Xiang",
                "Zhaofeng Niu",
                "Hong Tang",
                "Guangshun Li",
                "Liangzhi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00961v1",
                "http://arxiv.org/pdf/2311.00961v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00960v1",
            "title": "Trajectory Similarity Measurement: An Efficiency Perspective",
            "updated": "2023-11-02T03:07:26Z",
            "published": "2023-11-02T03:07:26Z",
            "summary": "Trajectories that capture object movement have numerous applications, in\nwhich similarity computation between trajectories often plays a key role.\nTraditionally, the similarity between two trajectories is quantified by means\nof heuristic measures, e.g., Hausdorff or ERP, that operate directly on the\ntrajectories. In contrast, recent studies exploit deep learning to map\ntrajectories to d-dimensional vectors, called embeddings. Then, some distance\nmeasure, e.g., Manhattan or Euclidean, is applied to the embeddings to quantify\ntrajectory similarity. The resulting similarities are inaccurate: they only\napproximate the similarities obtained using the heuristic measures. As distance\ncomputation on embeddings is efficient, focus has been on achieving embeddings\nyielding high accuracy.\n  Adopting an efficiency perspective, we analyze the time complexities of both\nthe heuristic and the learning-based approaches, finding that the time\ncomplexities of the former approaches are not necessarily higher. Through\nextensive experiments on open datasets, we find that, on both CPUs and GPUs,\nonly a few learning-based approaches can deliver the promised higher\nefficiency, when the embeddings can be pre-computed, while heuristic approaches\nare more efficient for one-off computations. Among the learning-based\napproaches, the self-attention-based ones are the fastest to learn embeddings\nthat also yield the highest accuracy for similarity queries. These results have\nimplications for the use of trajectory similarity approaches given different\napplication requirements.",
            "author": [
                "Yanchuan Chang",
                "Egemen Tanin",
                "Gao Cong",
                "Christian S. Jensen",
                "Jianzhong Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00960v1",
                "http://arxiv.org/pdf/2311.00960v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00959v1",
            "title": "Dynamic Fair Federated Learning Based on Reinforcement Learning",
            "updated": "2023-11-02T03:05:40Z",
            "published": "2023-11-02T03:05:40Z",
            "summary": "Federated learning enables a collaborative training and optimization of\nglobal models among a group of devices without sharing local data samples.\nHowever, the heterogeneity of data in federated learning can lead to unfair\nrepresentation of the global model across different devices. To address the\nfairness issue in federated learning, we propose a dynamic q fairness federated\nlearning algorithm with reinforcement learning, called DQFFL. DQFFL aims to\nmitigate the discrepancies in device aggregation and enhance the fairness of\ntreatment for all groups involved in federated learning. To quantify fairness,\nDQFFL leverages the performance of the global federated model on each device\nand incorporates {\\alpha}-fairness to transform the preservation of fairness\nduring federated aggregation into the distribution of client weights in the\naggregation process. Considering the sensitivity of parameters in measuring\nfairness, we propose to utilize reinforcement learning for dynamic parameters\nduring aggregation. Experimental results demonstrate that our DQFFL outperforms\nthe state-of-the-art methods in terms of overall performance, fairness and\nconvergence speed.",
            "author": [
                "Weikang Chen",
                "Junping Du",
                "Yingxia Shao",
                "Jia Wang",
                "Yangxi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00959v1",
                "http://arxiv.org/pdf/2311.00959v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.10749v1",
            "title": "Measuring Five Accountable Talk Moves to Improve Instruction at Scale",
            "updated": "2023-11-02T03:04:50Z",
            "published": "2023-11-02T03:04:50Z",
            "summary": "Providing consistent, individualized feedback to teachers on their\ninstruction can improve student learning outcomes. Such feedback can especially\nbenefit novice instructors who teach on online platforms and have limited\naccess to instructional training. To build scalable measures of instruction, we\nfine-tune RoBERTa and GPT models to identify five instructional talk moves\ninspired by accountable talk theory: adding on, connecting, eliciting, probing\nand revoicing students' ideas. We fine-tune these models on a newly annotated\ndataset of 2500 instructor utterances derived from transcripts of small group\ninstruction in an online computer science course, Code in Place. Although we\nfind that GPT-3 consistently outperforms RoBERTa in terms of precision, its\nrecall varies significantly. We correlate the instructors' use of each talk\nmove with indicators of student engagement and satisfaction, including\nstudents' section attendance, section ratings, and assignment completion rates.\nWe find that using talk moves generally correlates positively with student\noutcomes, and connecting student ideas has the largest positive impact. These\nresults corroborate previous research on the effectiveness of accountable talk\nmoves and provide exciting avenues for using these models to provide\ninstructors with useful, scalable feedback.",
            "author": [
                "Ashlee Kupor",
                "Candice Morgan",
                "Dorottya Demszky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10749v1",
                "http://arxiv.org/pdf/2311.10749v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00958v1",
            "title": "IndoToD: A Multi-Domain Indonesian Benchmark For End-to-End\n  Task-Oriented Dialogue Systems",
            "updated": "2023-11-02T03:01:53Z",
            "published": "2023-11-02T03:01:53Z",
            "summary": "Task-oriented dialogue (ToD) systems have been mostly created for\nhigh-resource languages, such as English and Chinese. However, there is a need\nto develop ToD systems for other regional or local languages to broaden their\nability to comprehend the dialogue contexts in various languages. This paper\nintroduces IndoToD, an end-to-end multi domain ToD benchmark in Indonesian. We\nextend two English ToD datasets to Indonesian, comprising four different\ndomains by delexicalization to efficiently reduce the size of annotations. To\nensure a high-quality data collection, we hire native speakers to manually\ntranslate the dialogues. Along with the original English datasets, these new\nIndonesian datasets serve as an effective benchmark for evaluating Indonesian\nand English ToD systems as well as exploring the potential benefits of\ncross-lingual and bilingual transfer learning approaches.",
            "author": [
                "Muhammad Dehan Al Kautsar",
                "Rahmah Khoirussyifa' Nurdini",
                "Samuel Cahyawijaya",
                "Genta Indra Winata",
                "Ayu Purwarianti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00958v1",
                "http://arxiv.org/pdf/2311.00958v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00953v1",
            "title": "Blending Reward Functions via Few Expert Demonstrations for Faithful and\n  Accurate Knowledge-Grounded Dialogue Generation",
            "updated": "2023-11-02T02:42:41Z",
            "published": "2023-11-02T02:42:41Z",
            "summary": "The development of trustworthy conversational information-seeking systems\nrelies on dialogue models that can generate faithful and accurate responses\nbased on relevant knowledge texts. However, two main challenges hinder this\ntask. Firstly, language models may generate hallucinations due to data biases\npresent in their pretraining corpus. Secondly, knowledge texts often contain\nredundant and irrelevant information that distracts the model's attention from\nthe relevant text span. Previous works use additional data annotations on the\nknowledge texts to learn a knowledge identification module in order to bypass\nirrelevant information, but collecting such high-quality span annotations can\nbe costly. In this work, we leverage reinforcement learning algorithms to\novercome the above challenges by introducing a novel reward function. Our\nreward function combines an accuracy metric and a faithfulness metric to\nprovide a balanced quality judgment of generated responses, which can be used\nas a cost-effective approximation to a human preference reward model when only\na few preference annotations are available. Empirical experiments on two\nconversational information-seeking datasets demonstrate that our method can\ncompete with other strong supervised learning baselines.",
            "author": [
                "Wanyu Du",
                "Yangfeng Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00953v1",
                "http://arxiv.org/pdf/2311.00953v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00945v1",
            "title": "E3 TTS: Easy End-to-End Diffusion-based Text to Speech",
            "updated": "2023-11-02T02:22:21Z",
            "published": "2023-11-02T02:22:21Z",
            "summary": "We propose Easy End-to-End Diffusion-based Text to Speech, a simple and\nefficient end-to-end text-to-speech model based on diffusion. E3 TTS directly\ntakes plain text as input and generates an audio waveform through an iterative\nrefinement process. Unlike many prior work, E3 TTS does not rely on any\nintermediate representations like spectrogram features or alignment\ninformation. Instead, E3 TTS models the temporal structure of the waveform\nthrough the diffusion process. Without relying on additional conditioning\ninformation, E3 TTS could support flexible latent structure within the given\naudio. This enables E3 TTS to be easily adapted for zero-shot tasks such as\nediting without any additional training. Experiments show that E3 TTS can\ngenerate high-fidelity audio, approaching the performance of a state-of-the-art\nneural TTS system. Audio samples are available at https://e3tts.github.io.",
            "author": [
                "Yuan Gao",
                "Nobuyuki Morioka",
                "Yu Zhang",
                "Nanxin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00945v1",
                "http://arxiv.org/pdf/2311.00945v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00944v1",
            "title": "Stochastic Smoothed Gradient Descent Ascent for Federated Minimax\n  Optimization",
            "updated": "2023-11-02T02:09:46Z",
            "published": "2023-11-02T02:09:46Z",
            "summary": "In recent years, federated minimax optimization has attracted growing\ninterest due to its extensive applications in various machine learning tasks.\nWhile Smoothed Alternative Gradient Descent Ascent (Smoothed-AGDA) has proved\nits success in centralized nonconvex minimax optimization, how and whether\nsmoothing technique could be helpful in federated setting remains unexplored.\nIn this paper, we propose a new algorithm termed Federated Stochastic Smoothed\nGradient Descent Ascent (FESS-GDA), which utilizes the smoothing technique for\nfederated minimax optimization. We prove that FESS-GDA can be uniformly used to\nsolve several classes of federated minimax problems and prove new or better\nanalytical convergence results for these settings. We showcase the practical\nefficiency of FESS-GDA in practical federated learning tasks of training\ngenerative adversarial networks (GANs) and fair classification.",
            "author": [
                "Wei Shen",
                "Minhui Huang",
                "Jiawei Zhang",
                "Cong Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00944v1",
                "http://arxiv.org/pdf/2311.00944v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00943v1",
            "title": "Sound Call Graph Construction for Java Object Deserialization",
            "updated": "2023-11-02T02:07:54Z",
            "published": "2023-11-02T02:07:54Z",
            "summary": "Object serialization and deserialization is widely used for storing and\npreserving objects in files, memory, or database as well as for transporting\nthem across machines, enabling remote interaction among processes and many\nmore. This mechanism relies on reflection, a dynamic language that introduces\nserious challenges for static analyses. Current state-of-the-art call graph\nconstruction algorithms does not fully support object\nserialization/deserialization, i.e., they are unable to uncover the callback\nmethods that are invoked when objects are serialized and deserialized. Since\ncall graphs are a core data structure for multiple type of analysis (e.g.,\nvulnerability detection), an appropriate analysis cannot be performed since the\ncall graph does not capture hidden (vulnerable) paths that occur via callback\nmethods. In this paper, we present Seneca, an approach for handling\nserialization with improved soundness in the context of call graph\nconstruction. Our approach relies on taint analysis and API modeling to\nconstruct sound call graphs. We evaluated our approach with respect to\nsoundness, precision, performance, and usefulness in detecting untrusted object\ndeserialization vulnerabilities. Our results show that Seneca can create sound\ncall graphs with respect to serialization features. The resulting call graphs\ndo not incur significant overhead and were shown to be useful for performing\nidentification of vulnerable paths caused by untrusted object deserialization.",
            "author": [
                "Joanna C. S. Santos",
                "Mehdi Mirakhorli",
                "Ali Shokri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00943v1",
                "http://arxiv.org/pdf/2311.00943v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00941v1",
            "title": "Gaussian Mixture Solvers for Diffusion Models",
            "updated": "2023-11-02T02:05:38Z",
            "published": "2023-11-02T02:05:38Z",
            "summary": "Recently, diffusion models have achieved great success in generative tasks.\nSampling from diffusion models is equivalent to solving the reverse diffusion\nstochastic differential equations (SDEs) or the corresponding probability flow\nordinary differential equations (ODEs). In comparison, SDE-based solvers can\ngenerate samples of higher quality and are suited for image translation tasks\nlike stroke-based synthesis. During inference, however, existing SDE-based\nsolvers are severely constrained by the efficiency-effectiveness dilemma. Our\ninvestigation suggests that this is because the Gaussian assumption in the\nreverse transition kernel is frequently violated (even in the case of simple\nmixture data) given a limited number of discretization steps. To overcome this\nlimitation, we introduce a novel class of SDE-based solvers called\n\\emph{Gaussian Mixture Solvers (GMS)} for diffusion models. Our solver\nestimates the first three-order moments and optimizes the parameters of a\nGaussian mixture transition kernel using generalized methods of moments in each\nstep during sampling. Empirically, our solver outperforms numerous SDE-based\nsolvers in terms of sample quality in image generation and stroke-based\nsynthesis in various diffusion models, which validates the motivation and\neffectiveness of GMS. Our code is available at\nhttps://github.com/Guohanzhong/GMS.",
            "author": [
                "Hanzhong Guo",
                "Cheng Lu",
                "Fan Bao",
                "Tianyu Pang",
                "Shuicheng Yan",
                "Chao Du",
                "Chongxuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00941v1",
                "http://arxiv.org/pdf/2311.00941v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00938v1",
            "title": "Bridging the Gap: Addressing Discrepancies in Diffusion Model Training\n  for Classifier-Free Guidance",
            "updated": "2023-11-02T02:03:12Z",
            "published": "2023-11-02T02:03:12Z",
            "summary": "Diffusion models have emerged as a pivotal advancement in generative models,\nsetting new standards to the quality of the generated instances. In the current\npaper we aim to underscore a discrepancy between conventional training methods\nand the desired conditional sampling behavior of these models. While the\nprevalent classifier-free guidance technique works well, it's not without\nflaws. At higher values for the guidance scale parameter $w$, we often get out\nof distribution samples and mode collapse, whereas at lower values for $w$ we\nmay not get the desired specificity. To address these challenges, we introduce\nan updated loss function that better aligns training objectives with sampling\nbehaviors. Experimental validation with FID scores on CIFAR-10 elucidates our\nmethod's ability to produce higher quality samples with fewer sampling\ntimesteps, and be more robust to the choice of guidance scale $w$. We also\nexperiment with fine-tuning Stable Diffusion on the proposed loss, to provide\nearly evidence that large diffusion models may also benefit from this refined\nloss function.",
            "author": [
                "Niket Patel",
                "Luis Salamanca",
                "Luis Barba"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00938v1",
                "http://arxiv.org/pdf/2311.00938v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00936v1",
            "title": "SatBird: Bird Species Distribution Modeling with Remote Sensing and\n  Citizen Science Data",
            "updated": "2023-11-02T02:00:27Z",
            "published": "2023-11-02T02:00:27Z",
            "summary": "Biodiversity is declining at an unprecedented rate, impacting ecosystem\nservices necessary to ensure food, water, and human health and well-being.\nUnderstanding the distribution of species and their habitats is crucial for\nconservation policy planning. However, traditional methods in ecology for\nspecies distribution models (SDMs) generally focus either on narrow sets of\nspecies or narrow geographical areas and there remain significant knowledge\ngaps about the distribution of species. A major reason for this is the limited\navailability of data traditionally used, due to the prohibitive amount of\neffort and expertise required for traditional field monitoring. The wide\navailability of remote sensing data and the growing adoption of citizen science\ntools to collect species observations data at low cost offer an opportunity for\nimproving biodiversity monitoring and enabling the modelling of complex\necosystems. We introduce a novel task for mapping bird species to their\nhabitats by predicting species encounter rates from satellite images, and\npresent SatBird, a satellite dataset of locations in the USA with labels\nderived from presence-absence observation data from the citizen science\ndatabase eBird, considering summer (breeding) and winter seasons. We also\nprovide a dataset in Kenya representing low-data regimes. We additionally\nprovide environmental data and species range maps for each location. We\nbenchmark a set of baselines on our dataset, including SOTA models for remote\nsensing tasks. SatBird opens up possibilities for scalably modelling properties\nof ecosystems worldwide.",
            "author": [
                "M\u00e9lisande Teng",
                "Amna Elmustafa",
                "Benjamin Akera",
                "Yoshua Bengio",
                "Hager Radi Abdelwahed",
                "Hugo Larochelle",
                "David Rolnick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00936v1",
                "http://arxiv.org/pdf/2311.00936v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00932v1",
            "title": "Towards High-quality HDR Deghosting with Conditional Diffusion Models",
            "updated": "2023-11-02T01:53:55Z",
            "published": "2023-11-02T01:53:55Z",
            "summary": "High Dynamic Range (HDR) images can be recovered from several Low Dynamic\nRange (LDR) images by existing Deep Neural Networks (DNNs) techniques. Despite\nthe remarkable progress, DNN-based methods still generate ghosting artifacts\nwhen LDR images have saturation and large motion, which hinders potential\napplications in real-world scenarios. To address this challenge, we formulate\nthe HDR deghosting problem as an image generation that leverages LDR features\nas the diffusion model's condition, consisting of the feature condition\ngenerator and the noise predictor. Feature condition generator employs\nattention and Domain Feature Alignment (DFA) layer to transform the\nintermediate features to avoid ghosting artifacts. With the learned features as\nconditions, the noise predictor leverages a stochastic iterative denoising\nprocess for diffusion models to generate an HDR image by steering the sampling\nprocess. Furthermore, to mitigate semantic confusion caused by the saturation\nproblem of LDR images, we design a sliding window noise estimator to sample\nsmooth noise in a patch-based manner. In addition, an image space loss is\nproposed to avoid the color distortion of the estimated HDR results. We\nempirically evaluate our model on benchmark datasets for HDR imaging. The\nresults demonstrate that our approach achieves state-of-the-art performances\nand well generalization to real-world images.",
            "author": [
                "Qingsen Yan",
                "Tao Hu",
                "Yuan Sun",
                "Hao Tang",
                "Yu Zhu",
                "Wei Dong",
                "Luc Van Gool",
                "Yanning Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00932v1",
                "http://arxiv.org/pdf/2311.00932v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00931v1",
            "title": "Learning Defect Prediction from Unrealistic Data",
            "updated": "2023-11-02T01:51:43Z",
            "published": "2023-11-02T01:51:43Z",
            "summary": "Pretrained models of code, such as CodeBERT and CodeT5, have become popular\nchoices for code understanding and generation tasks. Such models tend to be\nlarge and require commensurate volumes of training data, which are rarely\navailable for downstream tasks. Instead, it has become popular to train models\nwith far larger but less realistic datasets, such as functions with\nartificially injected bugs. Models trained on such data, however, tend to only\nperform well on similar data, while underperforming on real world programs. In\nthis paper, we conjecture that this discrepancy stems from the presence of\ndistracting samples that steer the model away from the real-world task\ndistribution. To investigate this conjecture, we propose an approach for\nidentifying the subsets of these large yet unrealistic datasets that are most\nsimilar to examples in real-world datasets based on their learned\nrepresentations. Our approach extracts high-dimensional embeddings of both\nreal-world and artificial programs using a neural model and scores artificial\nsamples based on their distance to the nearest real-world sample. We show that\ntraining on only the nearest, representationally most similar samples while\ndiscarding samples that are not at all similar in representations yields\nconsistent improvements across two popular pretrained models of code on two\ncode understanding tasks. Our results are promising, in that they show that\ntraining models on a representative subset of an unrealistic dataset can help\nus harness the power of large-scale synthetic data generation while preserving\ndownstream task performance. Finally, we highlight the limitations of applying\nAI models for predicting vulnerabilities and bugs in real-world applications",
            "author": [
                "Kamel Alrashedy",
                "Vincent J. Hellendoorn",
                "Alessandro Orso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00931v1",
                "http://arxiv.org/pdf/2311.00931v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00927v1",
            "title": "Scalable Counterfactual Distribution Estimation in Multivariate Causal\n  Models",
            "updated": "2023-11-02T01:45:44Z",
            "published": "2023-11-02T01:45:44Z",
            "summary": "We consider the problem of estimating the counterfactual joint distribution\nof multiple quantities of interests (e.g., outcomes) in a multivariate causal\nmodel extended from the classical difference-in-difference design. Existing\nmethods for this task either ignore the correlation structures among dimensions\nof the multivariate outcome by considering univariate causal models on each\ndimension separately and hence produce incorrect counterfactual distributions,\nor poorly scale even for moderate-size datasets when directly dealing with such\nmultivariate causal model. We propose a method that alleviates both issues\nsimultaneously by leveraging a robust latent one-dimensional subspace of the\noriginal high-dimension space and exploiting the efficient estimation from the\nunivariate causal model on such space. Since the construction of the\none-dimensional subspace uses information from all the dimensions, our method\ncan capture the correlation structures and produce good estimates of the\ncounterfactual distribution. We demonstrate the advantages of our approach over\nexisting methods on both synthetic and real-world data.",
            "author": [
                "Thong Pham",
                "Shohei Shimizu",
                "Hideitsu Hino",
                "Tam Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00927v1",
                "http://arxiv.org/pdf/2311.00927v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00924v1",
            "title": "The Power of the Senses: Generalizable Manipulation from Vision and\n  Touch through Masked Multimodal Learning",
            "updated": "2023-11-02T01:33:00Z",
            "published": "2023-11-02T01:33:00Z",
            "summary": "Humans rely on the synergy of their senses for most essential tasks. For\ntasks requiring object manipulation, we seamlessly and effectively exploit the\ncomplementarity of our senses of vision and touch. This paper draws inspiration\nfrom such capabilities and aims to find a systematic approach to fuse visual\nand tactile information in a reinforcement learning setting. We propose Masked\nMultimodal Learning (M3L), which jointly learns a policy and visual-tactile\nrepresentations based on masked autoencoding. The representations jointly\nlearned from vision and touch improve sample efficiency, and unlock\ngeneralization capabilities beyond those achievable through each of the senses\nseparately. Remarkably, representations learned in a multimodal setting also\nbenefit vision-only policies at test time. We evaluate M3L on three simulated\nenvironments with both visual and tactile observations: robotic insertion, door\nopening, and dexterous in-hand manipulation, demonstrating the benefits of\nlearning a multimodal policy. Code and videos of the experiments are available\nat https://sferrazza.cc/m3l_site.",
            "author": [
                "Carmelo Sferrazza",
                "Younggyo Seo",
                "Hao Liu",
                "Youngwoon Lee",
                "Pieter Abbeel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00924v1",
                "http://arxiv.org/pdf/2311.00924v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00923v1",
            "title": "A Review and Roadmap of Deep Causal Model from Different Causal\n  Structures and Representations",
            "updated": "2023-11-02T01:31:42Z",
            "published": "2023-11-02T01:31:42Z",
            "summary": "The fusion of causal models with deep learning introducing increasingly\nintricate data sets, such as the causal associations within images or between\ntextual components, has surfaced as a focal research area. Nonetheless, the\nbroadening of original causal concepts and theories to such complex,\nnon-statistical data has been met with serious challenges. In response, our\nstudy proposes redefinitions of causal data into three distinct categories from\nthe standpoint of causal structure and representation: definite data,\nsemi-definite data, and indefinite data. Definite data chiefly pertains to\nstatistical data used in conventional causal scenarios, while semi-definite\ndata refers to a spectrum of data formats germane to deep learning, including\ntime-series, images, text, and others. Indefinite data is an emergent research\nsphere inferred from the progression of data forms by us. To comprehensively\npresent these three data paradigms, we elaborate on their formal definitions,\ndifferences manifested in datasets, resolution pathways, and development of\nresearch. We summarize key tasks and achievements pertaining to definite and\nsemi-definite data from myriad research undertakings, present a roadmap for\nindefinite data, beginning with its current research conundrums. Lastly, we\nclassify and scrutinize the key datasets presently utilized within these three\nparadigms.",
            "author": [
                "Hang Chen",
                "Keqing Du",
                "Chenguang Li",
                "Xinyu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00923v1",
                "http://arxiv.org/pdf/2311.00923v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00922v1",
            "title": "Research Team Identification Based on Representation Learning of\n  Academic Heterogeneous Information Network",
            "updated": "2023-11-02T01:29:09Z",
            "published": "2023-11-02T01:29:09Z",
            "summary": "Academic networks in the real world can usually be described by heterogeneous\ninformation networks composed of multi-type nodes and relationships. Some\nexisting research on representation learning for homogeneous information\nnetworks lacks the ability to explore heterogeneous information networks in\nheterogeneous information networks. It cannot be applied to heterogeneous\ninformation networks. Aiming at the practical needs of effectively identifying\nand discovering scientific research teams from the academic heterogeneous\ninformation network composed of massive and complex scientific and\ntechnological big data, this paper proposes a scientific research team\nidentification method based on representation learning of academic\nheterogeneous information networks. The attention mechanism at node level and\nmeta-path level learns low-dimensional, dense and real-valued vector\nrepresentations on the basis of retaining the rich topological information of\nnodes in the network and the semantic information based on meta-paths, and\nrealizes effective identification and discovery of scientific research teams\nand important team members in academic heterogeneous information networks based\non maximizing node influence. Experimental results show that our proposed\nmethod outperforms the comparative methods.",
            "author": [
                "Junfu Wang",
                "Yawen Li",
                "Zhe Xue",
                "Ang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00922v1",
                "http://arxiv.org/pdf/2311.00922v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00919v1",
            "title": "MIST: Defending Against Membership Inference Attacks Through\n  Membership-Invariant Subspace Training",
            "updated": "2023-11-02T01:25:49Z",
            "published": "2023-11-02T01:25:49Z",
            "summary": "In Member Inference (MI) attacks, the adversary try to determine whether an\ninstance is used to train a machine learning (ML) model. MI attacks are a major\nprivacy concern when using private data to train ML models. Most MI attacks in\nthe literature take advantage of the fact that ML models are trained to fit the\ntraining data well, and thus have very low loss on training instances. Most\ndefenses against MI attacks therefore try to make the model fit the training\ndata less well. Doing so, however, generally results in lower accuracy. We\nobserve that training instances have different degrees of vulnerability to MI\nattacks. Most instances will have low loss even when not included in training.\nFor these instances, the model can fit them well without concerns of MI\nattacks. An effective defense only needs to (possibly implicitly) identify\ninstances that are vulnerable to MI attacks and avoids overfitting them. A\nmajor challenge is how to achieve such an effect in an efficient training\nprocess. Leveraging two distinct recent advancements in representation\nlearning: counterfactually-invariant representations and subspace learning\nmethods, we introduce a novel Membership-Invariant Subspace Training (MIST)\nmethod to defend against MI attacks. MIST avoids overfitting the vulnerable\ninstances without significant impact on other instances. We have conducted\nextensive experimental studies, comparing MIST with various other\nstate-of-the-art (SOTA) MI defenses against several SOTA MI attacks. We find\nthat MIST outperforms other defenses while resulting in minimal reduction in\ntesting accuracy.",
            "author": [
                "Jiacheng Li",
                "Ninghui Li",
                "Bruno Ribeiro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00919v1",
                "http://arxiv.org/pdf/2311.00919v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00917v1",
            "title": "RPCANet: Deep Unfolding RPCA Based Infrared Small Target Detection",
            "updated": "2023-11-02T01:21:12Z",
            "published": "2023-11-02T01:21:12Z",
            "summary": "Deep learning (DL) networks have achieved remarkable performance in infrared\nsmall target detection (ISTD). However, these structures exhibit a deficiency\nin interpretability and are widely regarded as black boxes, as they disregard\ndomain knowledge in ISTD. To alleviate this issue, this work proposes an\ninterpretable deep network for detecting infrared dim targets, dubbed RPCANet.\nSpecifically, our approach formulates the ISTD task as sparse target\nextraction, low-rank background estimation, and image reconstruction in a\nrelaxed Robust Principle Component Analysis (RPCA) model. By unfolding the\niterative optimization updating steps into a deep-learning framework,\ntime-consuming and complex matrix calculations are replaced by theory-guided\nneural networks. RPCANet detects targets with clear interpretability and\npreserves the intrinsic image feature, instead of directly transforming the\ndetection task into a matrix decomposition problem. Extensive experiments\nsubstantiate the effectiveness of our deep unfolding framework and demonstrate\nits trustworthy results, surpassing baseline methods in both qualitative and\nquantitative evaluations.",
            "author": [
                "Fengyi Wu",
                "Tianfang Zhang",
                "Lei Li",
                "Yian Huang",
                "Zhenming Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00917v1",
                "http://arxiv.org/pdf/2311.00917v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00913v1",
            "title": "Self-Influence Guided Data Reweighting for Language Model Pre-training",
            "updated": "2023-11-02T01:00:46Z",
            "published": "2023-11-02T01:00:46Z",
            "summary": "Language Models (LMs) pre-trained with self-supervision on large text corpora\nhave become the default starting point for developing models for various NLP\ntasks. Once the pre-training corpus has been assembled, all data samples in the\ncorpus are treated with equal importance during LM pre-training. However, due\nto varying levels of relevance and quality of data, equal importance to all the\ndata samples may not be the optimal choice. While data reweighting has been\nexplored in the context of task-specific supervised learning and LM\nfine-tuning, model-driven reweighting for pre-training data has not been\nexplored. We fill this important gap and propose PRESENCE, a method for jointly\nreweighting samples by leveraging self-influence (SI) scores as an indicator of\nsample importance and pre-training. PRESENCE promotes novelty and stability for\nmodel pre-training. Through extensive analysis spanning multiple model sizes,\ndatasets, and tasks, we present PRESENCE as an important first step in the\nresearch direction of sample reweighting for pre-training language models.",
            "author": [
                "Megh Thakkar",
                "Tolga Bolukbasi",
                "Sriram Ganapathy",
                "Shikhar Vashishth",
                "Sarath Chandar",
                "Partha Talukdar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00913v1",
                "http://arxiv.org/pdf/2311.00913v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00906v1",
            "title": "Re-weighting Tokens: A Simple and Effective Active Learning Strategy for\n  Named Entity Recognition",
            "updated": "2023-11-02T00:19:02Z",
            "published": "2023-11-02T00:19:02Z",
            "summary": "Active learning, a widely adopted technique for enhancing machine learning\nmodels in text and image classification tasks with limited annotation\nresources, has received relatively little attention in the domain of Named\nEntity Recognition (NER). The challenge of data imbalance in NER has hindered\nthe effectiveness of active learning, as sequence labellers lack sufficient\nlearning signals. To address these challenges, this paper presents a novel\nreweighting-based active learning strategy that assigns dynamic smoothed\nweights to individual tokens. This adaptable strategy is compatible with\nvarious token-level acquisition functions and contributes to the development of\nrobust active learners. Experimental results on multiple corpora demonstrate\nthe substantial performance improvement achieved by incorporating our\nre-weighting strategy into existing acquisition functions, validating its\npractical efficacy.",
            "author": [
                "Haocheng Luo",
                "Wei Tan",
                "Ngoc Dang Nguyen",
                "Lan Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00906v1",
                "http://arxiv.org/pdf/2311.00906v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00902v1",
            "title": "Data-Driven Model Selections of Second-Order Particle Dynamics via\n  Integrating Gaussian Processes with Low-Dimensional Interacting Structures",
            "updated": "2023-11-01T23:45:15Z",
            "published": "2023-11-01T23:45:15Z",
            "summary": "In this paper, we focus on the data-driven discovery of a general\nsecond-order particle-based model that contains many state-of-the-art models\nfor modeling the aggregation and collective behavior of interacting agents of\nsimilar size and body type. This model takes the form of a high-dimensional\nsystem of ordinary differential equations parameterized by two interaction\nkernels that appraise the alignment of positions and velocities. We propose a\nGaussian Process-based approach to this problem, where the unknown model\nparameters are marginalized by using two independent Gaussian Process (GP)\npriors on latent interaction kernels constrained to dynamics and observational\ndata. This results in a nonparametric model for interacting dynamical systems\nthat accounts for uncertainty quantification. We also develop acceleration\ntechniques to improve scalability. Moreover, we perform a theoretical analysis\nto interpret the methodology and investigate the conditions under which the\nkernels can be recovered. We demonstrate the effectiveness of the proposed\napproach on various prototype systems, including the selection of the order of\nthe systems and the types of interactions. In particular, we present\napplications to modeling two real-world fish motion datasets that display\nflocking and milling patterns up to 248 dimensions. Despite the use of small\ndata sets, the GP-based approach learns an effective representation of the\nnonlinear dynamics in these spaces and outperforms competitor methods.",
            "author": [
                "Jinchao Feng",
                "Charles Kulick",
                "Sui Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00902v1",
                "http://arxiv.org/pdf/2311.00902v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.NA",
                "math.NA",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00897v1",
            "title": "On The Open Prompt Challenge In Conditional Audio Generation",
            "updated": "2023-11-01T23:33:25Z",
            "published": "2023-11-01T23:33:25Z",
            "summary": "Text-to-audio generation (TTA) produces audio from a text description,\nlearning from pairs of audio samples and hand-annotated text. However,\ncommercializing audio generation is challenging as user-input prompts are often\nunder-specified when compared to text descriptions used to train TTA models. In\nthis work, we treat TTA models as a ``blackbox'' and address the user prompt\nchallenge with two key insights: (1) User prompts are generally\nunder-specified, leading to a large alignment gap between user prompts and\ntraining prompts. (2) There is a distribution of audio descriptions for which\nTTA models are better at generating higher quality audio, which we refer to as\n``audionese''. To this end, we rewrite prompts with instruction-tuned models\nand propose utilizing text-audio alignment as feedback signals via margin\nranking learning for audio improvements. On both objective and subjective human\nevaluations, we observed marked improvements in both text-audio alignment and\nmusic audio quality.",
            "author": [
                "Ernie Chang",
                "Sidd Srinivasan",
                "Mahi Luthra",
                "Pin-Jie Lin",
                "Varun Nagaraja",
                "Forrest Iandola",
                "Zechun Liu",
                "Zhaoheng Ni",
                "Changsheng Zhao",
                "Yangyang Shi",
                "Vikas Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00897v1",
                "http://arxiv.org/pdf/2311.00897v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00895v1",
            "title": "In-Context Prompt Editing For Conditional Audio Generation",
            "updated": "2023-11-01T23:31:51Z",
            "published": "2023-11-01T23:31:51Z",
            "summary": "Distributional shift is a central challenge in the deployment of machine\nlearning models as they can be ill-equipped for real-world data. This is\nparticularly evident in text-to-audio generation where the encoded\nrepresentations are easily undermined by unseen prompts, which leads to the\ndegradation of generated audio -- the limited set of the text-audio pairs\nremains inadequate for conditional audio generation in the wild as user prompts\nare under-specified. In particular, we observe a consistent audio quality\ndegradation in generated audio samples with user prompts, as opposed to\ntraining set prompts. To this end, we present a retrieval-based in-context\nprompt editing framework that leverages the training captions as demonstrative\nexemplars to revisit the user prompts. We show that the framework enhanced the\naudio quality across the set of collected user prompts, which were edited with\nreference to the training captions as exemplars.",
            "author": [
                "Ernie Chang",
                "Pin-Jie Lin",
                "Yang Li",
                "Sidd Srinivasan",
                "Gael Le Lan",
                "David Kant",
                "Yangyang Shi",
                "Forrest Iandola",
                "Vikas Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00895v1",
                "http://arxiv.org/pdf/2311.00895v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09237v1",
            "title": "An Innovative Tool for Uploading/Scraping Large Image Datasets on Social\n  Networks",
            "updated": "2023-11-01T23:27:37Z",
            "published": "2023-11-01T23:27:37Z",
            "summary": "Nowadays, people can retrieve and share digital information in an\nincreasingly easy and fast fashion through the well-known digital platforms,\nincluding sensitive data, inappropriate or illegal content, and, in general,\ninformation that might serve as probative evidence in court. Consequently, to\nassess forensics issues, we need to figure out how to trace back to the posting\nchain of a digital evidence (e.g., a picture, an audio) throughout the involved\nplatforms -- this is what Digital (also Forensics) Ballistics basically deals\nwith. With the entry of Machine Learning as a tool of the trade in many\nresearch areas, the need for vast amounts of data has been dramatically\nincreasing over the last few years. However, collecting or simply find the\n\"right\" datasets that properly enables data-driven research studies can turn\nout to be not trivial in some cases, if not extremely challenging, especially\nwhen it comes with highly specialized tasks, such as creating datasets analyzed\nto detect the source media platform of a given digital media. In this paper we\npropose an automated approach by means of a digital tool that we created on\npurpose. The tool is capable of automatically uploading an entire image dataset\nto the desired digital platform and then downloading all the uploaded pictures,\nthus shortening the overall time required to output the final dataset to be\nanalyzed.",
            "author": [
                "Nicol\u00f2 Fabio Arceri",
                "Oliver Giudice",
                "Sebastiano Battiato"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09237v1",
                "http://arxiv.org/pdf/2311.09237v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02103v1",
            "title": "Relax: Composable Abstractions for End-to-End Dynamic Machine Learning",
            "updated": "2023-11-01T23:03:59Z",
            "published": "2023-11-01T23:03:59Z",
            "summary": "Dynamic shape computations have become critical in modern machine learning\nworkloads, especially in emerging large language models. The success of these\nmodels has driven demand for deploying them to a diverse set of backend\nenvironments. In this paper, we present Relax, a compiler abstraction for\noptimizing end-to-end dynamic machine learning workloads. Relax introduces\nfirst-class symbolic shape annotations to track dynamic shape computations\nglobally across the program. It also introduces a cross-level abstraction that\nencapsulates computational graphs, loop-level tensor programs, and library\ncalls in a single representation to enable cross-level optimizations. We build\nan end-to-end compilation framework using the proposed approach to optimize\ndynamic shape models. Experimental results on large language models show that\nRelax delivers performance competitive with state-of-the-art hand-optimized\nsystems across platforms and enables deployment of emerging dynamic models to a\nbroader set of environments, including mobile phones, embedded devices, and web\nbrowsers.",
            "author": [
                "Ruihang Lai",
                "Junru Shao",
                "Siyuan Feng",
                "Steven S. Lyubomirsky",
                "Bohan Hou",
                "Wuwei Lin",
                "Zihao Ye",
                "Hongyi Jin",
                "Yuchen Jin",
                "Jiawei Liu",
                "Lesheng Jin",
                "Yaxing Cai",
                "Ziheng Jiang",
                "Yong Wu",
                "Sunghyun Park",
                "Prakalp Srivastava",
                "Jared G. Roesch",
                "Todd C. Mowry",
                "Tianqi Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02103v1",
                "http://arxiv.org/pdf/2311.02103v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00886v1",
            "title": "COSTAR: Improved Temporal Counterfactual Estimation with Self-Supervised\n  Learning",
            "updated": "2023-11-01T22:38:14Z",
            "published": "2023-11-01T22:38:14Z",
            "summary": "Estimation of temporal counterfactual outcomes from observed history is\ncrucial for decision-making in many domains such as healthcare and e-commerce,\nparticularly when randomized controlled trials (RCTs) suffer from high cost or\nimpracticality. For real-world datasets, modeling time-dependent confounders is\nchallenging due to complex dynamics, long-range dependencies and both past\ntreatments and covariates affecting the future outcomes. In this paper, we\nintroduce COunterfactual Self-supervised TrAnsformeR (COSTAR), a novel approach\nthat integrates self-supervised learning for improved historical\nrepresentations. The proposed framework combines temporal and feature-wise\nattention with a component-wise contrastive loss tailored for temporal\ntreatment outcome observations, yielding superior performance in estimation\naccuracy and generalization to out-of-distribution data compared to existing\nmodels, as validated by empirical results on both synthetic and real-world\ndatasets.",
            "author": [
                "Chuizheng Meng",
                "Yihe Dong",
                "Sercan \u00d6. Ar\u0131k",
                "Yan Liu",
                "Tomas Pfister"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00886v1",
                "http://arxiv.org/pdf/2311.00886v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00880v1",
            "title": "SCPO: Safe Reinforcement Learning with Safety Critic Policy Optimization",
            "updated": "2023-11-01T22:12:50Z",
            "published": "2023-11-01T22:12:50Z",
            "summary": "Incorporating safety is an essential prerequisite for broadening the\npractical applications of reinforcement learning in real-world scenarios. To\ntackle this challenge, Constrained Markov Decision Processes (CMDPs) are\nleveraged, which introduce a distinct cost function representing safety\nviolations. In CMDPs' settings, Lagrangian relaxation technique has been\nemployed in previous algorithms to convert constrained optimization problems\ninto unconstrained dual problems. However, these algorithms may inaccurately\npredict unsafe behavior, resulting in instability while learning the Lagrange\nmultiplier. This study introduces a novel safe reinforcement learning\nalgorithm, Safety Critic Policy Optimization (SCPO). In this study, we define\nthe safety critic, a mechanism that nullifies rewards obtained through\nviolating safety constraints. Furthermore, our theoretical analysis indicates\nthat the proposed algorithm can automatically balance the trade-off between\nadhering to safety constraints and maximizing rewards. The effectiveness of the\nSCPO algorithm is empirically validated by benchmarking it against strong\nbaselines.",
            "author": [
                "Jaafar Mhamed",
                "Shangding Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00880v1",
                "http://arxiv.org/pdf/2311.00880v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00875v1",
            "title": "Learning Collective Behaviors from Observation",
            "updated": "2023-11-01T22:02:08Z",
            "published": "2023-11-01T22:02:08Z",
            "summary": "We present a review of a series of learning methods used to identify the\nstructure of dynamical systems, aiming to understand emergent behaviors in\ncomplex systems of interacting agents. These methods not only offer theoretical\nguarantees of convergence but also demonstrate computational efficiency in\nhandling high-dimensional observational data. They can manage observation data\nfrom both first- and second-order dynamical systems, accounting for\nobservation/stochastic noise, complex interaction rules, missing interaction\nfeatures, and real-world observations of interacting agent systems. The essence\nof developing such a series of learning methods lies in designing appropriate\nloss functions using the variational inverse problem approach, which inherently\nprovides dimension reduction capabilities to our learning methods.",
            "author": [
                "Jinchao Feng",
                "Ming Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00875v1",
                "http://arxiv.org/pdf/2311.00875v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00873v1",
            "title": "Low-latency Real-time Voice Conversion on CPU",
            "updated": "2023-11-01T21:57:52Z",
            "published": "2023-11-01T21:57:52Z",
            "summary": "We adapt the architectures of previous audio manipulation and generation\nneural networks to the task of real-time any-to-one voice conversion. Our\nresulting model, LLVC ($\\textbf{L}$ow-latency $\\textbf{L}$ow-resource\n$\\textbf{V}$oice $\\textbf{C}$onversion), has a latency of under 20ms at a\nbitrate of 16kHz and runs nearly 2.8x faster than real-time on a consumer CPU.\nLLVC uses both a generative adversarial architecture as well as knowledge\ndistillation in order to attain this performance. To our knowledge LLVC\nachieves both the lowest resource usage as well as the lowest latency of any\nopen-source voice conversion model. We provide open-source samples, code, and\npretrained model weights at https://github.com/KoeAI/LLVC.",
            "author": [
                "Konstantine Sadov",
                "Matthew Hutter",
                "Asara Near"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00873v1",
                "http://arxiv.org/pdf/2311.00873v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00871v1",
            "title": "Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in\n  Transformer Models",
            "updated": "2023-11-01T21:41:08Z",
            "published": "2023-11-01T21:41:08Z",
            "summary": "Transformer models, notably large language models (LLMs), have the remarkable\nability to perform in-context learning (ICL) -- to perform new tasks when\nprompted with unseen input-output examples without any explicit model training.\nIn this work, we study how effectively transformers can bridge between their\npretraining data mixture, comprised of multiple distinct task families, to\nidentify and learn new tasks in-context which are both inside and outside the\npretraining distribution. Building on previous work, we investigate this\nquestion in a controlled setting, where we study transformer models trained on\nsequences of $(x, f(x))$ pairs rather than natural language. Our empirical\nresults show transformers demonstrate near-optimal unsupervised model selection\ncapabilities, in their ability to first in-context identify different task\nfamilies and in-context learn within them when the task families are\nwell-represented in their pretraining data. However when presented with tasks\nor functions which are out-of-domain of their pretraining data, we demonstrate\nvarious failure modes of transformers and degradation of their generalization\nfor even simple extrapolation tasks. Together our results highlight that the\nimpressive ICL abilities of high-capacity sequence models may be more closely\ntied to the coverage of their pretraining data mixtures than inductive biases\nthat create fundamental generalization capabilities.",
            "author": [
                "Steve Yadlowsky",
                "Lyric Doshi",
                "Nilesh Tripuraneni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00871v1",
                "http://arxiv.org/pdf/2311.00871v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00866v1",
            "title": "Generalizing Nonlinear ICA Beyond Structural Sparsity",
            "updated": "2023-11-01T21:36:15Z",
            "published": "2023-11-01T21:36:15Z",
            "summary": "Nonlinear independent component analysis (ICA) aims to uncover the true\nlatent sources from their observable nonlinear mixtures. Despite its\nsignificance, the identifiability of nonlinear ICA is known to be impossible\nwithout additional assumptions. Recent advances have proposed conditions on the\nconnective structure from sources to observed variables, known as Structural\nSparsity, to achieve identifiability in an unsupervised manner. However, the\nsparsity constraint may not hold universally for all sources in practice.\nFurthermore, the assumptions of bijectivity of the mixing process and\nindependence among all sources, which arise from the setting of ICA, may also\nbe violated in many real-world scenarios. To address these limitations and\ngeneralize nonlinear ICA, we propose a set of new identifiability results in\nthe general settings of undercompleteness, partial sparsity and source\ndependence, and flexible grouping structures. Specifically, we prove\nidentifiability when there are more observed variables than sources\n(undercomplete), and when certain sparsity and/or source independence\nassumptions are not met for some changing sources. Moreover, we show that even\nin cases with flexible grouping structures (e.g., part of the sources can be\ndivided into irreducible independent groups with various sizes), appropriate\nidentifiability results can also be established. Theoretical claims are\nsupported empirically on both synthetic and real-world datasets.",
            "author": [
                "Yujia Zheng",
                "Kun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00866v1",
                "http://arxiv.org/pdf/2311.00866v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00865v1",
            "title": "Selectively Sharing Experiences Improves Multi-Agent Reinforcement\n  Learning",
            "updated": "2023-11-01T21:35:32Z",
            "published": "2023-11-01T21:35:32Z",
            "summary": "We present a novel multi-agent RL approach, Selective Multi-Agent Prioritized\nExperience Relay, in which agents share with other agents a limited number of\ntransitions they observe during training. The intuition behind this is that\neven a small number of relevant experiences from other agents could help each\nagent learn. Unlike many other multi-agent RL algorithms, this approach allows\nfor largely decentralized training, requiring only a limited communication\nchannel between agents. We show that our approach outperforms baseline\nno-sharing decentralized training and state-of-the art multi-agent RL\nalgorithms. Further, sharing only a small number of highly relevant experiences\noutperforms sharing all experiences between agents, and the performance uplift\nfrom selective experience sharing is robust across a range of hyperparameters\nand DQN variants. A reference implementation of our algorithm is available at\nhttps://github.com/mgerstgrasser/super.",
            "author": [
                "Matthias Gerstgrasser",
                "Tom Danino",
                "Sarah Keren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00865v1",
                "http://arxiv.org/pdf/2311.00865v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.MA",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00863v1",
            "title": "Training Dynamics of Contextual N-Grams in Language Models",
            "updated": "2023-11-01T21:32:51Z",
            "published": "2023-11-01T21:32:51Z",
            "summary": "Prior work has shown the existence of contextual neurons in language models,\nincluding a neuron that activates on German text. We show that this neuron\nexists within a broader contextual n-gram circuit: we find late layer neurons\nwhich recognize and continue n-grams common in German text, but which only\nactivate if the German neuron is active. We investigate the formation of this\ncircuit throughout training and find that it is an example of what we call a\nsecond-order circuit. In particular, both the constituent n-gram circuits and\nthe German detection circuit which culminates in the German neuron form with\nindependent functions early in training - the German detection circuit\npartially through modeling German unigram statistics, and the n-grams by\nboosting appropriate completions. Only after both circuits have already formed\ndo they fit together into a second-order circuit. Contrary to the hypotheses\npresented in prior work, we find that the contextual n-gram circuit forms\ngradually rather than in a sudden phase transition. We further present a range\nof anomalous observations such as a simultaneous phase transition in many tasks\ncoinciding with the learning rate warm-up, and evidence that many context\nneurons form simultaneously early in training but are later unlearned.",
            "author": [
                "Lucia Quirke",
                "Lovis Heindrich",
                "Wes Gurnee",
                "Neel Nanda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00863v1",
                "http://arxiv.org/pdf/2311.00863v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00860v2",
            "title": "Zero Coordinate Shift: Whetted Automatic Differentiation for\n  Physics-informed Operator Learning",
            "updated": "2023-11-23T19:41:41Z",
            "published": "2023-11-01T21:28:24Z",
            "summary": "Automatic differentiation (AD) is a critical step in physics-informed machine\nlearning, required for computing the high-order derivatives of network output\nw.r.t. coordinates of collocation points. In this paper, we present a novel and\nlightweight algorithm to conduct AD for physics-informed operator learning,\nwhich we call the trick of Zero Coordinate Shift (ZCS). Instead of making all\nsampled coordinates as leaf variables, ZCS introduces only one scalar-valued\nleaf variable for each spatial or temporal dimension, simplifying the wanted\nderivatives from \"many-roots-many-leaves\" to \"one-root-many-leaves\" whereby\nreverse-mode AD becomes directly utilisable. It has led to an outstanding\nperformance leap by avoiding the duplication of the computational graph along\nthe dimension of functions (physical parameters). ZCS is easy to implement with\ncurrent deep learning libraries; our own implementation is achieved by\nextending the DeepXDE package. We carry out a comprehensive benchmark analysis\nand several case studies, training physics-informed DeepONets to solve partial\ndifferential equations (PDEs) without data. The results show that ZCS has\npersistently reduced GPU memory consumption and wall time for training by an\norder of magnitude, and such reduction factor scales with the number of\nfunctions. As a low-level optimisation technique, ZCS imposes no restrictions\non data, physics (PDE) or network architecture and does not compromise training\nresults from any aspect.",
            "author": [
                "Kuangdai Leng",
                "Mallikarjun Shankar",
                "Jeyan Thiyagalingam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00860v2",
                "http://arxiv.org/pdf/2311.00860v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NA",
                "math.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00859v1",
            "title": "Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems",
            "updated": "2023-11-01T21:28:02Z",
            "published": "2023-11-01T21:28:02Z",
            "summary": "Finding optimal adversarial attack strategies is an important topic in\nreinforcement learning and the Markov decision process. Previous studies\nusually assume one all-knowing coordinator (attacker) for whom attacking\ndifferent recipient (victim) agents incurs uniform costs. However, in reality,\ninstead of using one limitless central attacker, the attacks often need to be\nperformed by distributed attack agents. We formulate the problem of performing\noptimal adversarial agent-to-agent attacks using distributed attack agents, in\nwhich we impose distinct cost constraints on each different attacker-victim\npair. We propose an optimal method integrating within-step static constrained\nattack-resource allocation optimization and between-step dynamic programming to\nachieve the optimal adversarial attack in a multi-agent system. Our numerical\nresults show that the proposed attacks can significantly reduce the rewards\nreceived by the attacked agents.",
            "author": [
                "Ziqing Lu",
                "Guanlin Liu",
                "Lifeng Cai",
                "Weiyu Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00859v1",
                "http://arxiv.org/pdf/2311.00859v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01476v1",
            "title": "Applications of the Theory of Aggregated Markov Processes in Stochastic\n  Learning Theory",
            "updated": "2023-11-01T21:25:35Z",
            "published": "2023-11-01T21:25:35Z",
            "summary": "A stochastic process that arises by composing a function with a Markov\nprocess is called an aggregated Markov process (AMP). The purpose of composing\na Markov process with a function can be a reduction of dimensions, e.g., a\nprojection onto certain coordinates. The theory around AMP has been extensively\nstudied e.g. by Dynkin, Cameron, Rogers and Pitman, and Kelly, all of whom\nprovided sufficient conditions for an AMP to remain Markov. In another\ndirection, Larget provided a canonical representation for AMP, which can be\nused to verify the equivalence of two AMPs. The purpose of this paper is to\ndescribe how the theory of AMP can be applied to stochastic learning theory as\nthey learn a particular task.",
            "author": [
                "Fangyuan Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01476v1",
                "http://arxiv.org/pdf/2311.01476v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.PR",
                "stat.AP",
                "60J20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00858v1",
            "title": "SmoothHess: ReLU Network Feature Interactions via Stein's Lemma",
            "updated": "2023-11-01T21:24:37Z",
            "published": "2023-11-01T21:24:37Z",
            "summary": "Several recent methods for interpretability model feature interactions by\nlooking at the Hessian of a neural network. This poses a challenge for ReLU\nnetworks, which are piecewise-linear and thus have a zero Hessian almost\neverywhere. We propose SmoothHess, a method of estimating second-order\ninteractions through Stein's Lemma. In particular, we estimate the Hessian of\nthe network convolved with a Gaussian through an efficient sampling algorithm,\nrequiring only network gradient calls. SmoothHess is applied post-hoc, requires\nno modifications to the ReLU network architecture, and the extent of smoothing\ncan be controlled explicitly. We provide a non-asymptotic bound on the sample\ncomplexity of our estimation procedure. We validate the superior ability of\nSmoothHess to capture interactions on benchmark datasets and a real-world\nmedical spirometry dataset.",
            "author": [
                "Max Torop",
                "Aria Masoomi",
                "Davin Hill",
                "Kivanc Kose",
                "Stratis Ioannidis",
                "Jennifer Dy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00858v1",
                "http://arxiv.org/pdf/2311.00858v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00855v2",
            "title": "A Multi-Agent Reinforcement Learning Framework for Evaluating the U.S.\n  Ending the HIV Epidemic Plan",
            "updated": "2023-11-06T22:33:41Z",
            "published": "2023-11-01T21:19:35Z",
            "summary": "Human immunodeficiency virus (HIV) is a major public health concern in the\nUnited States, with about 1.2 million people living with HIV and 35,000 newly\ninfected each year. There are considerable geographical disparities in HIV\nburden and care access across the U.S. The 2019 Ending the HIV Epidemic (EHE)\ninitiative aims to reduce new infections by 90% by 2030, by improving coverage\nof diagnoses, treatment, and prevention interventions and prioritizing\njurisdictions with high HIV prevalence. Identifying optimal scale-up of\nintervention combinations will help inform resource allocation. Existing HIV\ndecision analytic models either evaluate specific cities or the overall\nnational population, thus overlooking jurisdictional interactions or\ndifferences. In this paper, we propose a multi-agent reinforcement learning\n(MARL) model, that enables jurisdiction-specific decision analyses but in an\nenvironment with cross-jurisdictional epidemiological interactions. In\nexperimental analyses, conducted on jurisdictions within California and\nFlorida, optimal policies from MARL were significantly different than those\ngenerated from single-agent RL, highlighting the influence of jurisdictional\nvariations and interactions. By using comprehensive modeling of HIV and\nformulations of state space, action space, and reward functions, this work\nhelps demonstrate the strengths and applicability of MARL for informing public\nhealth policies, and provides a framework for expanding to the national-level\nto inform the EHE.",
            "author": [
                "Dinesh Sharma",
                "Ankit Shah",
                "Chaitra Gopalappa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00855v2",
                "http://arxiv.org/pdf/2311.00855v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00850v1",
            "title": "EMPOT: partial alignment of density maps and rigid body fitting using\n  unbalanced Gromov-Wasserstein divergence",
            "updated": "2023-11-01T21:03:28Z",
            "published": "2023-11-01T21:03:28Z",
            "summary": "Aligning EM density maps and fitting atomic models are essential steps in\nsingle particle cryogenic electron microscopy (cryo-EM), with recent methods\nleveraging various algorithms and machine learning tools. As aligning maps\nremains challenging in the presence of a map that only partially fits the other\n(e.g. one subunit), we here propose a new procedure, EMPOT (EM Partial\nalignment with Optimal Transport), for partial alignment of 3D maps. EMPOT\nfirst finds a coupling between 3D point-cloud representations, which is\nassociated with their so-called unbalanced Gromov Wasserstein divergence, and\nsecond, uses this coupling to find an optimal rigid body transformation. Upon\nrunning and benchmarking our method with experimental maps and structures, we\nshow that EMPOT outperforms standard methods for aligning subunits of a protein\ncomplex and fitting atomic models to a density map, suggesting potential\napplications of Partial Optimal Transport for improving Cryo-EM pipelines.",
            "author": [
                "Aryan Tajmir Riahi",
                "Chenwei Zhang",
                "James Chen",
                "Anne Condon",
                "Khanh Dao Duc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00850v1",
                "http://arxiv.org/pdf/2311.00850v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00846v1",
            "title": "From Doubt to Devotion: Trials and Learning-Based Pricing",
            "updated": "2023-11-01T20:52:14Z",
            "published": "2023-11-01T20:52:14Z",
            "summary": "An informed seller designs a dynamic mechanism to sell an experience good.\nThe seller has partial information about the product match, which affects the\nbuyer's private consumption experience. We characterize equilibrium mechanisms\nof this dynamic informed principal problem. The belief gap between the informed\nseller and the uninformed buyer, coupled with the buyer's learning, gives rise\nto mechanisms that provide the skeptical buyer with limited access to the\nproduct and an option to upgrade if the buyer is swayed by a good experience.\nDepending on the seller's screening technology, this takes the form of\nfree/discounted trials or tiered pricing, which are prevalent in digital\nmarkets. In contrast to static environments, having consumer data can reduce\nsellers' revenue in equilibrium, as they fine-tune the dynamic design with\ntheir data forecasting the buyer's learning process.",
            "author": [
                "Tan Gan",
                "Nicholas Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00846v1",
                "http://arxiv.org/pdf/2311.00846v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00844v2",
            "title": "Electronic excited states from physically-constrained machine learning",
            "updated": "2023-11-08T01:04:12Z",
            "published": "2023-11-01T20:49:59Z",
            "summary": "Data-driven techniques are increasingly used to replace electronic-structure\ncalculations of matter. In this context, a relevant question is whether machine\nlearning (ML) should be applied directly to predict the desired properties or\nbe combined explicitly with physically-grounded operations. We present an\nexample of an integrated modeling approach, in which a symmetry-adapted ML\nmodel of an effective Hamiltonian is trained to reproduce electronic\nexcitations from a quantum-mechanical calculation. The resulting model can make\npredictions for molecules that are much larger and more complex than those that\nit is trained on, and allows for dramatic computational savings by indirectly\ntargeting the outputs of well-converged calculations while using a\nparameterization corresponding to a minimal atom-centered basis. These results\nemphasize the merits of intertwining data-driven techniques with physical\napproximations, improving the transferability and interpretability of ML models\nwithout affecting their accuracy and computational efficiency, and providing a\nblueprint for developing ML-augmented electronic-structure methods.",
            "author": [
                "Edoardo Cignoni",
                "Divya Suman",
                "Jigyasa Nigam",
                "Lorenzo Cupellini",
                "Benedetta Mennucci",
                "Michele Ceriotti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00844v2",
                "http://arxiv.org/pdf/2311.00844v2"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00840v1",
            "title": "Sharp Noisy Binary Search with Monotonic Probabilities",
            "updated": "2023-11-01T20:45:13Z",
            "published": "2023-11-01T20:45:13Z",
            "summary": "We revisit the noisy binary search model of Karp and Kleinberg, in which we\nhave $n$ coins with unknown probabilities $p_i$ that we can flip. The coins are\nsorted by increasing $p_i$, and we would like to find where the probability\ncrosses (to within $\\varepsilon$) of a target value $\\tau$. This generalized\nthe fixed-noise model of Burnashev and Zigangirov , in which $p_i = \\frac{1}{2}\n\\pm \\varepsilon$, to a setting where coins near the target may be\nindistinguishable from it. Karp and Kleinberg showed that\n$\\Theta(\\frac{1}{\\varepsilon^2} \\log n)$ samples are necessary and sufficient\nfor this task.\n  We produce a practical algorithm by solving two theoretical challenges:\nhigh-probability behavior and sharp constants. We give an algorithm that\nsucceeds with probability $1-\\delta$ from\n  \\[\n  \\frac{1}{C_{\\tau, \\varepsilon}} \\cdot \\left(\\lg n + O(\\log^{2/3} n \\log^{1/3}\n\\frac{1}{\\delta} + \\log \\frac{1}{\\delta})\\right)\n  \\]\n  samples, where $C_{\\tau, \\varepsilon}$ is the optimal such constant\nachievable. For $\\delta > n^{-o(1)}$ this is within $1 + o(1)$ of optimal, and\nfor $\\delta \\ll 1$ it is the first bound within constant factors of optimal.",
            "author": [
                "Lucas Gretta",
                "Eric Price"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00840v1",
                "http://arxiv.org/pdf/2311.00840v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00833v1",
            "title": "HIDM: Emulating Large Scale HI Maps using Score-based Diffusion Models",
            "updated": "2023-11-01T20:37:35Z",
            "published": "2023-11-01T20:37:35Z",
            "summary": "Efficiently analyzing maps from upcoming large-scale surveys requires gaining\ndirect access to a high-dimensional likelihood and generating large-scale\nfields with high fidelity, which both represent major challenges. Using CAMELS\nsimulations, we employ the state-of-the-art score-based diffusion models to\nsimultaneously achieve both tasks. We show that our model, HIDM, is able to\nefficiently generate high fidelity large scale HI maps that are in a good\nagreement with the CAMELS's power spectrum, probability distribution, and\nlikelihood up to second moments. HIDM represents a step forward towards\nmaximizing the scientific return of future large scale surveys.",
            "author": [
                "Sultan Hassan",
                "Sambatra Andrianomena"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00833v1",
                "http://arxiv.org/pdf/2311.00833v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00816v1",
            "title": "Faster Peace via Inclusivity: An Efficient Paradigm to Understand\n  Populations in Conflict Zones",
            "updated": "2023-11-01T20:00:12Z",
            "published": "2023-11-01T20:00:12Z",
            "summary": "United Nations practice shows that inclusivity is vital for mediation to be\nsuccessful in helping end violent conflict and establish lasting peace.\nHowever, current methods for understanding the views and needs of populations\nduring dynamic situations create tension between inclusivity and efficiency.\nThis work introduces a novel paradigm to mitigate such tension. In partnership\nwith collaborators at the United Nations we develop a realtime large-scale\nsynchronous dialogue process (RLSDP) to understand stakeholder populations on\nan hour timescale. We demonstrate a machine learning model which enables each\ndialogue cycle to take place on a minute-timescale. We manage a key risk\nrelated to machine learning result trustworthiness by computing result\nconfidence from a fast and reliable estimation of posterior variance. Lastly,\nwe highlight a constellation of risks stemming from this new paradigm and\nsuggest policies to mitigate them.",
            "author": [
                "Jordan Bilich",
                "Michael Varga",
                "Daanish Masood",
                "Andrew Konya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00816v1",
                "http://arxiv.org/pdf/2311.00816v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01475v1",
            "title": "Patch-Based Deep Unsupervised Image Segmentation using Graph Cuts",
            "updated": "2023-11-01T19:59:25Z",
            "published": "2023-11-01T19:59:25Z",
            "summary": "Unsupervised image segmentation aims at grouping different semantic patterns\nin an image without the use of human annotation. Similarly, image clustering\nsearches for groupings of images based on their semantic content without\nsupervision. Classically, both problems have captivated researchers as they\ndrew from sound mathematical concepts to produce concrete applications. With\nthe emergence of deep learning, the scientific community turned its attention\nto complex neural network-based solvers that achieved impressive results in\nthose domains but rarely leveraged the advances made by classical methods. In\nthis work, we propose a patch-based unsupervised image segmentation strategy\nthat bridges advances in unsupervised feature extraction from deep clustering\nmethods with the algorithmic help of classical graph-based methods. We show\nthat a simple convolutional neural network, trained to classify image patches\nand iteratively regularized using graph cuts, naturally leads to a\nstate-of-the-art fully-convolutional unsupervised pixel-level segmenter.\nFurthermore, we demonstrate that this is the ideal setting for leveraging the\npatch-level pairwise features generated by vision transformer models. Our\nresults on real image data demonstrate the effectiveness of our proposed\nmethodology.",
            "author": [
                "Isaac Wasserman",
                "Jeova Farias Sales Rocha Neto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01475v1",
                "http://arxiv.org/pdf/2311.01475v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00815v1",
            "title": "PIAug -- Physics Informed Augmentation for Learning Vehicle Dynamics for\n  Off-Road Navigation",
            "updated": "2023-11-01T19:56:58Z",
            "published": "2023-11-01T19:56:58Z",
            "summary": "Modeling the precise dynamics of off-road vehicles is a complex yet essential\ntask due to the challenging terrain they encounter and the need for optimal\nperformance and safety. Recently, there has been a focus on integrating nominal\nphysics-based models alongside data-driven neural networks using Physics\nInformed Neural Networks. These approaches often assume the availability of a\nwell-distributed dataset; however, this assumption may not hold due to regions\nin the physical distribution that are hard to collect, such as high-speed\nmotions and rare terrains. Therefore, we introduce a physics-informed data\naugmentation methodology called PIAug. We show an example use case of the same\nby modeling high-speed and aggressive motion predictions, given a dataset with\nonly low-speed data. During the training phase, we leverage the nominal model\nfor generating target domain (medium and high velocity) data using the\navailable source data (low velocity). Subsequently, we employ a\nphysics-inspired loss function with this augmented dataset to incorporate prior\nknowledge of physics into the neural network. Our methodology results in up to\n67% less mean error in trajectory prediction in comparison to a standalone\nnominal model, especially during aggressive maneuvers at speeds outside the\ntraining domain. In real-life navigation experiments, our model succeeds in 4x\ntighter waypoint tracking constraints than the Kinematic Bicycle Model (KBM) at\nout-of-domain velocities.",
            "author": [
                "Parv Maheshwari",
                "Wenshan Wang",
                "Samuel Triest",
                "Matthew Sivaprakasam",
                "Shubhra Aich",
                "John G. Rogers III",
                "Jason M. Gregory",
                "Sebastian Scherer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00815v1",
                "http://arxiv.org/pdf/2311.00815v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00811v1",
            "title": "A quantum-classical performance separation in nonconvex optimization",
            "updated": "2023-11-01T19:51:00Z",
            "published": "2023-11-01T19:51:00Z",
            "summary": "In this paper, we identify a family of nonconvex continuous optimization\ninstances, each $d$-dimensional instance with $2^d$ local minima, to\ndemonstrate a quantum-classical performance separation. Specifically, we prove\nthat the recently proposed Quantum Hamiltonian Descent (QHD) algorithm [Leng et\nal., arXiv:2303.01471] is able to solve any $d$-dimensional instance from this\nfamily using $\\widetilde{\\mathcal{O}}(d^3)$ quantum queries to the function\nvalue and $\\widetilde{\\mathcal{O}}(d^4)$ additional 1-qubit and 2-qubit\nelementary quantum gates. On the other side, a comprehensive empirical study\nsuggests that representative state-of-the-art classical optimization\nalgorithms/solvers (including Gurobi) would require a super-polynomial time to\nsolve such optimization instances.",
            "author": [
                "Jiaqi Leng",
                "Yufan Zheng",
                "Xiaodi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00811v1",
                "http://arxiv.org/pdf/2311.00811v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.DS",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00808v1",
            "title": "Mahalanobis-Aware Training for Out-of-Distribution Detection",
            "updated": "2023-11-01T19:46:40Z",
            "published": "2023-11-01T19:46:40Z",
            "summary": "While deep learning models have seen widespread success in controlled\nenvironments, there are still barriers to their adoption in open-world\nsettings. One critical task for safe deployment is the detection of anomalous\nor out-of-distribution samples that may require human intervention. In this\nwork, we present a novel loss function and recipe for training networks with\nimproved density-based out-of-distribution sensitivity. We demonstrate the\neffectiveness of our method on CIFAR-10, notably reducing the false-positive\nrate of the relative Mahalanobis distance method on far-OOD tasks by over 50%.",
            "author": [
                "Connor Mclaughlin",
                "Jason Matterer",
                "Michael Yee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00808v1",
                "http://arxiv.org/pdf/2311.00808v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00807v1",
            "title": "VQA-GEN: A Visual Question Answering Benchmark for Domain Generalization",
            "updated": "2023-11-01T19:43:56Z",
            "published": "2023-11-01T19:43:56Z",
            "summary": "Visual question answering (VQA) models are designed to demonstrate\nvisual-textual reasoning capabilities. However, their real-world applicability\nis hindered by a lack of comprehensive benchmark datasets. Existing domain\ngeneralization datasets for VQA exhibit a unilateral focus on textual shifts\nwhile VQA being a multi-modal task contains shifts across both visual and\ntextual domains. We propose VQA-GEN, the first ever multi-modal benchmark\ndataset for distribution shift generated through a shift induced pipeline.\nExperiments demonstrate VQA-GEN dataset exposes the vulnerability of existing\nmethods to joint multi-modal distribution shifts. validating that comprehensive\nmulti-modal shifts are critical for robust VQA generalization. Models trained\non VQA-GEN exhibit improved cross-domain and in-domain performance, confirming\nthe value of VQA-GEN. Further, we analyze the importance of each shift\ntechnique of our pipeline contributing to the generalization of the model.",
            "author": [
                "Suraj Jyothi Unni",
                "Raha Moraffah",
                "Huan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00807v1",
                "http://arxiv.org/pdf/2311.00807v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00802v1",
            "title": "Neural Field Dynamics Model for Granular Object Piles Manipulation",
            "updated": "2023-11-01T19:36:56Z",
            "published": "2023-11-01T19:36:56Z",
            "summary": "We present a learning-based dynamics model for granular material\nmanipulation. Inspired by the Eulerian approach commonly used in fluid\ndynamics, our method adopts a fully convolutional neural network that operates\non a density field-based representation of object piles and pushers, allowing\nit to exploit the spatial locality of inter-object interactions as well as the\ntranslation equivariance through convolution operations. Furthermore, our\ndifferentiable action rendering module makes the model fully differentiable and\ncan be directly integrated with a gradient-based trajectory optimization\nalgorithm. We evaluate our model with a wide array of piles manipulation tasks\nboth in simulation and real-world experiments and demonstrate that it\nsignificantly exceeds existing latent or particle-based methods in both\naccuracy and computation efficiency, and exhibits zero-shot generalization\ncapabilities across various environments and tasks.",
            "author": [
                "Shangjie Xue",
                "Shuo Cheng",
                "Pujith Kachana",
                "Danfei Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00802v1",
                "http://arxiv.org/pdf/2311.00802v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00801v1",
            "title": "GIST: Generated Inputs Sets Transferability in Deep Learning",
            "updated": "2023-11-01T19:35:18Z",
            "published": "2023-11-01T19:35:18Z",
            "summary": "As the demand for verifiability and testability of neural networks continues\nto rise, an increasing number of methods for generating test sets are being\ndeveloped. However, each of these techniques tends to emphasize specific\ntesting aspects and can be quite time-consuming. A straightforward solution to\nmitigate this issue is to transfer test sets between some benchmarked models\nand a new model under test, based on a desirable property one wishes to\ntransfer. This paper introduces GIST (Generated Inputs Sets Transferability), a\nnovel approach for the efficient transfer of test sets among Deep Learning\nmodels. Given a property of interest that a user wishes to transfer (e.g.,\ncoverage criterion), GIST enables the selection of good test sets from the\npoint of view of this property among available ones from a benchmark. We\nempirically evaluate GIST on fault types coverage property with two modalities\nand different test set generation procedures to demonstrate the approach's\nfeasibility. Experimental results show that GIST can select an effective test\nset for the given property to transfer it to the model under test. Our results\nsuggest that GIST could be applied to transfer other properties and could\ngeneralize to different test sets' generation procedures and modalities",
            "author": [
                "Florian Tambon",
                "Foutse Khomh",
                "Giuliano Antoniol"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00801v1",
                "http://arxiv.org/pdf/2311.00801v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00799v1",
            "title": "Latent space representations of cosmological fields",
            "updated": "2023-11-01T19:33:52Z",
            "published": "2023-11-01T19:33:52Z",
            "summary": "We investigate the possibility of learning the representations of\ncosmological multifield dataset from the CAMELS project. We train a very deep\nvariational encoder on images which comprise three channels, namely gas density\n(Mgas), neutral hydrogen density (HI), and magnetic field amplitudes (B). The\nclustering of the images in feature space with respect to some\ncosmological/astrophysical parameters (e.g. $\\Omega_{\\rm m}$) suggests that the\ngenerative model has learned latent space representations of the high\ndimensional inputs. We assess the quality of the latent codes by conducting a\nlinear test on the extracted features, and find that a single dense layer is\ncapable of recovering some of the parameters to a promising level of accuracy,\nespecially the matter density whose prediction corresponds to a coefficient of\ndetermination $R^{2}$ = 0.93. Furthermore, results show that the generative\nmodel is able to produce images that exhibit statistical properties which are\nconsistent with those of the training data, down to scales of $k\\sim 4h/{\\rm\nMpc}.$",
            "author": [
                "Sambatra Andrianomena",
                "Sultan Hassan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00799v1",
                "http://arxiv.org/pdf/2311.00799v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00797v2",
            "title": "Tipping Points of Evolving Epidemiological Networks: Machine\n  Learning-Assisted, Data-Driven Effective Modeling",
            "updated": "2023-11-10T22:49:40Z",
            "published": "2023-11-01T19:33:03Z",
            "summary": "We study the tipping point collective dynamics of an adaptive\nsusceptible-infected-susceptible (SIS) epidemiological network in a\ndata-driven, machine learning-assisted manner. We identify a\nparameter-dependent effective stochastic differential equation (eSDE) in terms\nof physically meaningful coarse mean-field variables through a deep-learning\nResNet architecture inspired by numerical stochastic integrators. We construct\nan approximate effective bifurcation diagram based on the identified drift term\nof the eSDE and contrast it with the mean-field SIS model bifurcation diagram.\nWe observe a subcritical Hopf bifurcation in the evolving network's effective\nSIS dynamics, that causes the tipping point behavior; this takes the form of\nlarge amplitude collective oscillations that spontaneously -- yet rarely --\narise from the neighborhood of a (noisy) stationary state. We study the\nstatistics of these rare events both through repeated brute force simulations\nand by using established mathematical/computational tools exploiting the\nright-hand-side of the identified SDE. We demonstrate that such a collective\nSDE can also be identified (and the rare events computations also performed) in\nterms of data-driven coarse observables, obtained here via manifold learning\ntechniques, in particular Diffusion Maps. The workflow of our study is\nstraightforwardly applicable to other complex dynamics problems exhibiting\ntipping point dynamics.",
            "author": [
                "Nikolaos Evangelou",
                "Tianqi Cui",
                "Juan M. Bello-Rivas",
                "Alexei Makeev",
                "Ioannis G. Kevrekidis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00797v2",
                "http://arxiv.org/pdf/2311.00797v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.DS",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00796v1",
            "title": "Automatic counting of planting microsites via local visual detection and\n  global count estimation",
            "updated": "2023-11-01T19:31:54Z",
            "published": "2023-11-01T19:31:54Z",
            "summary": "In forest industry, mechanical site preparation by mounding is widely used\nprior to planting operations. One of the main problems when planning planting\noperations is the difficulty in estimating the number of mounds present on a\nplanting block, as their number may greatly vary depending on site\ncharacteristics. This estimation is often carried out through field surveys by\nseveral forestry workers. However, this procedure is prone to error and\nslowness. Motivated by recent advances in UAV imagery and artificial\nintelligence, we propose a fully automated framework to estimate the number of\nmounds on a planting block. Using computer vision and machine learning, we\nformulate the counting task as a supervised learning problem using two\nprediction models. A local detection model is firstly used to detect visible\nmounds based on deep features, while a global prediction function is\nsubsequently applied to provide a final estimation based on block-level\nfeatures. To evaluate the proposed method, we constructed a challenging UAV\ndataset representing several plantation blocks with different characteristics.\nThe performed experiments demonstrated the robustness of the proposed method,\nwhich outperforms manual methods in precision, while significantly reducing\ntime and cost.",
            "author": [
                "Ahmed Zgaren",
                "Wassim Bouachir",
                "Nizar Bouguila"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TETCI.2023.3272004",
                "http://arxiv.org/abs/2311.00796v1",
                "http://arxiv.org/pdf/2311.00796v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00793v1",
            "title": "Feel the Force: From Local Surface Pressure Measurement to Flow\n  Reconstruction in Fluid-Structure Interaction",
            "updated": "2023-11-01T19:27:17Z",
            "published": "2023-11-01T19:27:17Z",
            "summary": "Drawing inspiration from the lateral lines of fish, the inference of flow\ncharacteristics via surface-based data has drawn considerable attention. The\ncurrent approaches often rely on analytical methods tailored exclusively for\npotential flows or utilize black-box machine learning algorithms to estimate a\nspecific set of flow parameters. In contrast to a black box machine learning\napproach, we demonstrate that it is possible to identify certain modes of fluid\nflow and then reconstruct the entire flow field from these modes. We use\nDynamic Mode Decomposition (DMD) to parametrize complex, dynamic features\nacross the entire flow field. We then leverage deep neural networks to infer\nthe DMD modes of the pressure and velocity fields within a large, unsteady flow\ndomain, employing solely a time series of pressure measurements collected on\nthe surface of an immersed obstacle. Our methodology is successfully\ndemonstrated to diverse fluid-structure interaction scenarios, including cases\nwith both free oscillations in the wake of a cylinder and forced oscillations\nof tandem cylinders, demonstrating its versatility and robustness.",
            "author": [
                "Colin Rodwell",
                "Kumar Sourav",
                "Phanindra Tallapragada"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00793v1",
                "http://arxiv.org/pdf/2311.00793v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00792v1",
            "title": "Measuring the Impact of Distractors on Student Learning Gains while\n  Using Proof Blocks",
            "updated": "2023-11-01T19:25:55Z",
            "published": "2023-11-01T19:25:55Z",
            "summary": "Background: Proof Blocks is a software tool that enables students to\nconstruct proofs by assembling prewritten lines and gives them automated\nfeedback. Prior work on learning gains from Proof Blocks has focused on\ncomparing learning gains from Proof Blocks against other learning activities\nsuch as writing proofs or reading.\n  Purpose: The study described in this paper aims to compare learning gains\nfrom different variations of Proof Blocks. Specifically, we attempt to quantify\nthe difference in learning gains for students who complete Proof Blocks\nproblems with and without distractors.\n  Methods: We conducted a randomized controlled trial with three experimental\ngroups: a control group that completed an off-topic Proof Blocks activity, one\nthat completed a \\tool{} activity without distractors, and one that completed a\nProof Blocks activity with distractors. All three groups read a book chapter on\nproof by induction before completing their activity.\n  Findings: The group that completed the Proof Blocks activity with distractors\nperformed better on the posttest than the group that completed the Proof Blocks\nwithout distractors, who in turn performed better than the group that completed\nthe off-topic Proof Blocks activity. However, none of these differences were\nstatistically significant. While the results of this study are inconclusive, we\nhope that it can serve as a foundation for future work.",
            "author": [
                "Seth Poulsen",
                "Hongxuan Chen",
                "Yael Gertner",
                "Benjamin Cosman",
                "Matthew West",
                "Geoffrey L Herman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00792v1",
                "http://arxiv.org/pdf/2311.00792v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00787v1",
            "title": "Accelerating Electronic Stopping Power Predictions by 10 Million Times\n  with a Combination of Time-Dependent Density Functional Theory and Machine\n  Learning",
            "updated": "2023-11-01T19:11:46Z",
            "published": "2023-11-01T19:11:46Z",
            "summary": "Knowing the rate at which particle radiation releases energy in a material,\nthe stopping power, is key to designing nuclear reactors, medical treatments,\nsemiconductor and quantum materials, and many other technologies. While the\nnuclear contribution to stopping power, i.e., elastic scattering between atoms,\nis well understood in the literature, the route for gathering data on the\nelectronic contribution has for decades remained costly and reliant on many\nsimplifying assumptions, including that materials are isotropic. We establish a\nmethod that combines time-dependent density functional theory (TDDFT) and\nmachine learning to reduce the time to assess new materials to mere hours on a\nsupercomputer and provides valuable data on how atomic details influence\nelectronic stopping. Our approach uses TDDFT to compute the electronic stopping\ncontributions to stopping power from first principles in several directions and\nthen machine learning to interpolate to other directions at rates 10 million\ntimes higher. We demonstrate the combined approach in a study of proton\nirradiation in aluminum and employ it to predict how the depth of maximum\nenergy deposition, the \"Bragg Peak,\" varies depending on incident angle -- a\nquantity otherwise inaccessible to modelers. The lack of any experimental\ninformation requirement makes our method applicable to most materials, and its\nspeed makes it a prime candidate for enabling quantum-to-continuum models of\nradiation damage. The prospect of reusing valuable TDDFT data for training the\nmodel make our approach appealing for applications in the age of materials data\nscience.",
            "author": [
                "Logan Ward",
                "Ben Blaiszik",
                "Cheng-Wei Lee",
                "Troy Martin",
                "Ian Foster",
                "Andr\u00e9 Schleife"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00787v1",
                "http://arxiv.org/pdf/2311.00787v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00778v1",
            "title": "Convergence of Heterogeneous Learning Dynamics in Zero-sum Stochastic\n  Games",
            "updated": "2023-11-01T18:46:32Z",
            "published": "2023-11-01T18:46:32Z",
            "summary": "This paper presents new families of algorithms for the repeated play of\ntwo-agent (near) zero-sum games and two-agent zero-sum stochastic games. For\nexample, the family includes fictitious play and its variants as members.\nCommonly, the algorithms in this family are all uncoupled, rational, and\nconvergent even in heterogeneous cases, e.g., where the dynamics may differ in\nterms of learning rates, full, none or temporal access to opponent actions, and\nmodel-based vs model-free learning. The convergence of heterogeneous dynamics\nis of practical interest especially in competitive environments since agents\nmay have no means or interests in following the same dynamic with the same\nparameters. We prove that any mixture of such asymmetries does not impact the\nalgorithms' convergence to equilibrium (or near equilibrium if there is\nexperimentation) in zero-sum games with repeated play and in zero-sum\n(irreducible) stochastic games with sufficiently small discount factors.",
            "author": [
                "Yuksel Arslantas",
                "Ege Yuceel",
                "Yigit Yalin",
                "Muhammed O. Sayin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00778v1",
                "http://arxiv.org/pdf/2311.00778v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04226v1",
            "title": "Assessing Upper Limb Motor Function in the Immediate Post-Stroke Perioud\n  Using Accelerometry",
            "updated": "2023-11-01T18:43:20Z",
            "published": "2023-11-01T18:43:20Z",
            "summary": "Accelerometry has been extensively studied as an objective means of measuring\nupper limb function in patients post-stroke. The objective of this paper is to\ndetermine whether the accelerometry-derived measurements frequently used in\nmore long-term rehabilitation studies can also be used to monitor and rapidly\ndetect sudden changes in upper limb motor function in more recently\nhospitalized stroke patients. Six binary classification models were created by\ntraining on variable data window times of paretic upper limb accelerometer\nfeature data. The models were assessed on their effectiveness for\ndifferentiating new input data into two classes: severe or moderately severe\nmotor function. The classification models yielded Area Under the Curve (AUC)\nscores that ranged from 0.72 to 0.82 for 15-minute data windows to 0.77 to 0.94\nfor 120-minute data windows. These results served as a preliminary assessment\nand a basis on which to further investigate the efficacy of using accelerometry\nand machine learning to alert healthcare professionals to rapid changes in\nmotor function in the days immediately following a stroke.",
            "author": [
                "Mackenzie Wallich",
                "Kenneth Lai",
                "Svetlana Yanushkevich"
            ],
            "link": [
                "http://dx.doi.org/10.1109/CAI54212.2023.00064",
                "http://arxiv.org/abs/2311.04226v1",
                "http://arxiv.org/pdf/2311.04226v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00775v3",
            "title": "Harnessing machine learning for accurate treatment of overlapping\n  opacity species in general circulation models",
            "updated": "2023-12-06T16:08:51Z",
            "published": "2023-11-01T18:38:31Z",
            "summary": "To understand high precision observations of exoplanets and brown dwarfs, we\nneed detailed and complex general circulation models (GCMs) that incorporate\nhydrodynamics, chemistry, and radiation. For this study, we specifically\nexamined the coupling between chemistry and radiation in GCMs and compared\ndifferent methods for the mixing of opacities of different chemical species in\nthe correlated-k assumption, when equilibrium chemistry cannot be assumed. We\npropose a fast machine learning method based on DeepSets (DS), which\neffectively combines individual correlated-k opacities (k-tables). We evaluated\nthe DS method alongside other published methods such as adaptive equivalent\nextinction (AEE) and random overlap with rebinning and resorting (RORR). We\nintegrated these mixing methods into our GCM (expeRT/MITgcm) and assessed their\naccuracy and performance for the example of the hot Jupiter HD~209458 b. Our\nfindings indicate that the DS method is both accurate and efficient for GCM\nusage, whereas RORR is too slow. Additionally, we observed that the accuracy of\nAEE depends on its specific implementation and may introduce numerical issues\nin achieving radiative transfer solution convergence. We then applied the DS\nmixing method in a simplified chemical disequilibrium situation, where we\nmodeled the rainout of TiO and VO, and confirmed that the rainout of TiO and VO\nwould hinder the formation of a stratosphere. To further expedite the\ndevelopment of consistent disequilibrium chemistry calculations in GCMs, we\nprovide documentation and code for coupling the DS mixing method with\ncorrelated-k radiative transfer solvers. The DS method has been extensively\ntested to be accurate enough for GCMs; however, other methods might be needed\nfor accelerating atmospheric retrievals.",
            "author": [
                "Aaron David Schneider",
                "Paul Molli\u00e8re",
                "Gilles Louppe",
                "Ludmila Carone",
                "Uffe Gr\u00e5e J\u00f8rgensen",
                "Leen Decin",
                "Christiane Helling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00775v3",
                "http://arxiv.org/pdf/2311.00775v3"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00774v1",
            "title": "Conformalized Deep Splines for Optimal and Efficient Prediction Sets",
            "updated": "2023-11-01T18:37:07Z",
            "published": "2023-11-01T18:37:07Z",
            "summary": "Uncertainty estimation is critical in high-stakes machine learning\napplications. One effective way to estimate uncertainty is conformal\nprediction, which can provide predictive inference with statistical coverage\nguarantees. We present a new conformal regression method, Spline Prediction\nIntervals via Conformal Estimation (SPICE), that estimates the conditional\ndensity using neural-network-parameterized splines. We prove universal\napproximation and optimality results for SPICE, which are empirically validated\nby our experiments. SPICE is compatible with two different efficient-to-compute\nconformal scores, one oracle-optimal for marginal coverage (SPICE-ND) and the\nother asymptotically optimal for conditional coverage (SPICE-HPD). Results on\nbenchmark datasets demonstrate SPICE-ND models achieve the smallest average\nprediction set sizes, including average size reductions of nearly 50% for some\ndatasets compared to the next best baseline. SPICE-HPD models achieve the best\nconditional coverage compared to baselines. The SPICE implementation is made\navailable.",
            "author": [
                "Nathaniel Diamant",
                "Ehsan Hajiramezanali",
                "Tommaso Biancalani",
                "Gabriele Scalia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00774v1",
                "http://arxiv.org/pdf/2311.00774v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00772v1",
            "title": "SAGE: Smart home Agent with Grounded Execution",
            "updated": "2023-11-01T18:36:28Z",
            "published": "2023-11-01T18:36:28Z",
            "summary": "This article introduces SAGE (Smart home Agent with Grounded Execution), a\nframework designed to maximize the flexibility of smart home assistants by\nreplacing manually-defined inference logic with an LLM-powered autonomous agent\nsystem. SAGE integrates information about user preferences, device states, and\nexternal factors (such as weather and TV schedules) through the orchestration\nof a collection of tools. SAGE's capabilities include learning user preferences\nfrom natural-language utterances, interacting with devices by reading their API\ndocumentation, writing code to continuously monitor devices, and understanding\nnatural device references. To evaluate SAGE, we develop a benchmark of 43\nhighly challenging smart home tasks, where SAGE successfully achieves 23 tasks,\nsignificantly outperforming existing LLM-enabled baselines (5/43).",
            "author": [
                "Dmitriy Rivkin",
                "Francois Hogan",
                "Amal Feriani",
                "Abhisek Konar",
                "Adam Sigal",
                "Steve Liu",
                "Greg Dudek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00772v1",
                "http://arxiv.org/pdf/2311.00772v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00768v1",
            "title": "Language Model Training Paradigms for Clinical Feature Embeddings",
            "updated": "2023-11-01T18:23:12Z",
            "published": "2023-11-01T18:23:12Z",
            "summary": "In research areas with scarce data, representation learning plays a\nsignificant role. This work aims to enhance representation learning for\nclinical time series by deriving universal embeddings for clinical features,\nsuch as heart rate and blood pressure. We use self-supervised training\nparadigms for language models to learn high-quality clinical feature\nembeddings, achieving a finer granularity than existing time-step and\npatient-level representation learning. We visualize the learnt embeddings via\nunsupervised dimension reduction techniques and observe a high degree of\nconsistency with prior clinical knowledge. We also evaluate the model\nperformance on the MIMIC-III benchmark and demonstrate the effectiveness of\nusing clinical feature embeddings. We publish our code online for replication.",
            "author": [
                "Yurong Hu",
                "Manuel Burger",
                "Gunnar R\u00e4tsch",
                "Rita Kuznetsova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00768v1",
                "http://arxiv.org/pdf/2311.00768v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00767v1",
            "title": "Hand Gesture Classification on Praxis Dataset: Trading Accuracy for\n  Expense",
            "updated": "2023-11-01T18:18:09Z",
            "published": "2023-11-01T18:18:09Z",
            "summary": "In this paper, we investigate hand gesture classifiers that rely upon the\nabstracted 'skeletal' data recorded using the RGB-Depth sensor. We focus on\n'skeletal' data represented by the body joint coordinates, from the Praxis\ndataset. The PRAXIS dataset contains recordings of patients with cortical\npathologies such as Alzheimer's disease, performing a Praxis test under the\ndirection of a clinician. In this paper, we propose hand gesture classifiers\nthat are more effective with the PRAXIS dataset than previously proposed\nmodels. Body joint data offers a compressed form of data that can be analyzed\nspecifically for hand gesture recognition. Using a combination of windowing\ntechniques with deep learning architecture such as a Recurrent Neural Network\n(RNN), we achieved an overall accuracy of 70.8% using only body joint data. In\naddition, we investigated a long-short-term-memory (LSTM) to extract and\nanalyze the movement of the joints through time to recognize the hand gestures\nbeing performed and achieved a gesture recognition rate of 74.3% and 67.3% for\nstatic and dynamic gestures, respectively. The proposed approach contributed to\nthe task of developing an automated, accurate, and inexpensive approach to\ndiagnosing cortical pathologies for multiple healthcare applications.",
            "author": [
                "Rahat Islam",
                "Kenneth Lai",
                "Svetlana Yanushkevich"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IJCNN55064.2022.9892631",
                "http://arxiv.org/abs/2311.00767v1",
                "http://arxiv.org/pdf/2311.00767v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00756v1",
            "title": "The Quantum Cartpole: A benchmark environment for non-linear\n  reinforcement learning",
            "updated": "2023-11-01T18:02:42Z",
            "published": "2023-11-01T18:02:42Z",
            "summary": "Feedback-based control is the de-facto standard when it comes to controlling\nclassical stochastic systems and processes. However, standard feedback-based\ncontrol methods are challenged by quantum systems due to measurement induced\nbackaction and partial observability. Here we remedy this by using weak quantum\nmeasurements and model-free reinforcement learning agents to perform quantum\ncontrol. By comparing control algorithms with and without state estimators to\nstabilize a quantum particle in an unstable state near a local potential energy\nmaximum, we show how a trade-off between state estimation and controllability\narises. For the scenario where the classical analogue is highly nonlinear, the\nreinforcement learned controller has an advantage over the standard controller.\nAdditionally, we demonstrate the feasibility of using transfer learning to\ndevelop a quantum control agent trained via reinforcement learning on a\nclassical surrogate of the quantum control problem. Finally, we present results\nshowing how the reinforcement learning control strategy differs from the\nclassical controller in the non-linear scenarios.",
            "author": [
                "Kai Meinerz",
                "Simon Trebst",
                "Mark Rudner",
                "Evert van Nieuwenburg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00756v1",
                "http://arxiv.org/pdf/2311.00756v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00754v1",
            "title": "Learning to Design and Use Tools for Robotic Manipulation",
            "updated": "2023-11-01T18:00:10Z",
            "published": "2023-11-01T18:00:10Z",
            "summary": "When limited by their own morphologies, humans and some species of animals\nhave the remarkable ability to use objects from the environment toward\naccomplishing otherwise impossible tasks. Robots might similarly unlock a range\nof additional capabilities through tool use. Recent techniques for jointly\noptimizing morphology and control via deep learning are effective at designing\nlocomotion agents. But while outputting a single morphology makes sense for\nlocomotion, manipulation involves a variety of strategies depending on the task\ngoals at hand. A manipulation agent must be capable of rapidly prototyping\nspecialized tools for different goals. Therefore, we propose learning a\ndesigner policy, rather than a single design. A designer policy is conditioned\non task information and outputs a tool design that helps solve the task. A\ndesign-conditioned controller policy can then perform manipulation using these\ntools. In this work, we take a step towards this goal by introducing a\nreinforcement learning framework for jointly learning these policies. Through\nsimulated manipulation tasks, we show that this framework is more sample\nefficient than prior methods in multi-goal or multi-variant settings, can\nperform zero-shot interpolation or fine-tuning to tackle previously unseen\ngoals, and allows tradeoffs between the complexity of design and control\npolicies under practical constraints. Finally, we deploy our learned policies\nonto a real robot. Please see our supplementary video and website at\nhttps://robotic-tool-design.github.io/ for visualizations.",
            "author": [
                "Ziang Liu",
                "Stephen Tian",
                "Michelle Guo",
                "C. Karen Liu",
                "Jiajun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00754v1",
                "http://arxiv.org/pdf/2311.00754v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00749v1",
            "title": "Sorting with Predictions",
            "updated": "2023-11-01T18:00:03Z",
            "published": "2023-11-01T18:00:03Z",
            "summary": "We explore the fundamental problem of sorting through the lens of\nlearning-augmented algorithms, where algorithms can leverage possibly erroneous\npredictions to improve their efficiency. We consider two different settings: In\nthe first setting, each item is provided a prediction of its position in the\nsorted list. In the second setting, we assume there is a \"quick-and-dirty\" way\nof comparing items, in addition to slow-and-exact comparisons. For both\nsettings, we design new and simple algorithms using only $O(\\sum_i \\log\n\\eta_i)$ exact comparisons, where $\\eta_i$ is a suitably defined prediction\nerror for the $i$th element. In particular, as the quality of predictions\ndeteriorates, the number of comparisons degrades smoothly from $O(n)$ to\n$O(n\\log n)$. We prove that the comparison complexity is theoretically optimal\nwith respect to the examined error measures. An experimental evaluation against\nexisting adaptive and non-adaptive sorting algorithms demonstrates the\npotential of applying learning-augmented algorithms in sorting tasks.",
            "author": [
                "Xingjian Bai",
                "Christian Coester"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00749v1",
                "http://arxiv.org/pdf/2311.00749v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00750v1",
            "title": "Are These the Same Apple? Comparing Images Based on Object Intrinsics",
            "updated": "2023-11-01T18:00:03Z",
            "published": "2023-11-01T18:00:03Z",
            "summary": "The human visual system can effortlessly recognize an object under different\nextrinsic factors such as lighting, object poses, and background, yet current\ncomputer vision systems often struggle with these variations. An important step\nto understanding and improving artificial vision systems is to measure image\nsimilarity purely based on intrinsic object properties that define object\nidentity. This problem has been studied in the computer vision literature as\nre-identification, though mostly restricted to specific object categories such\nas people and cars. We propose to extend it to general object categories,\nexploring an image similarity metric based on object intrinsics. To benchmark\nsuch measurements, we collect the Common paired objects Under differenT\nExtrinsics (CUTE) dataset of $18,000$ images of $180$ objects under different\nextrinsic factors such as lighting, poses, and imaging conditions. While\nexisting methods such as LPIPS and CLIP scores do not measure object intrinsics\nwell, we find that combining deep features learned from contrastive\nself-supervised learning with foreground filtering is a simple yet effective\napproach to approximating the similarity. We conduct an extensive survey of\npre-trained features and foreground extraction methods to arrive at a strong\nbaseline that best measures intrinsic object-centric image similarity among\ncurrent methods. Finally, we demonstrate that our approach can aid in\ndownstream applications such as acting as an analog for human subjects and\nimproving generalizable re-identification. Please see our project website at\nhttps://s-tian.github.io/projects/cute/ for visualizations of the data and\ndemos of our metric.",
            "author": [
                "Klemen Kotar",
                "Stephen Tian",
                "Hong-Xing Yu",
                "Daniel L. K. Yamins",
                "Jiajun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00750v1",
                "http://arxiv.org/pdf/2311.00750v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00696v1",
            "title": "Decision Support Framework for Home Health Caregiver Allocation: A Case\n  Study of HHC Agency in Tennessee, USA",
            "updated": "2023-11-01T17:54:49Z",
            "published": "2023-11-01T17:54:49Z",
            "summary": "Population aging is a global challenge, leading to increased demand for\nhealthcare and social services for the elderly. Home Health Care (HHC) emerges\nas a vital solution, specifically designed to serve this population segment.\nGiven the surging demand for HHC, it's essential to coordinate and regulate\ncaregiver allocation efficiently. This is crucial for both budget-optimized\nplanning and ensuring the delivery of high-quality care. This research\naddresses a key question faced by home health agencies (HHAs): \"How can\ncaregiver allocation be optimized, especially when caregivers prefer\nflexibility in their visiting sequences?\". While earlier studies proposed rigid\nvisiting sequences, our study introduces a decision support framework that\nallocates caregivers through a hybrid method that considers the flexibility in\nvisiting sequences and aims to reduce travel mileage, increase the number of\nvisits per planning period, and maintain the continuity of care - a critical\nmetric for patient satisfaction. Utilizing data from an HHA in Tennessee,\nUnited States, our approach led to an impressive reduction in average travel\nmileage (up to 42% depending on discipline) without imposing restrictions on\ncaregivers. Furthermore, the proposed framework is used for caregivers' supply\nanalysis to provide valuable insights into caregiver resource management.",
            "author": [
                "Seyed Mohammad Ebrahim Sharifnia",
                "Faezeh Bagheri",
                "Rupy Sawhney",
                "John E. Kobza",
                "Enrique Macias De Anda",
                "Mostafa Hajiaghaei-Keshteli",
                "Michael Mirrielees"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00696v1",
                "http://arxiv.org/pdf/2311.00696v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00694v2",
            "title": "Unleashing the Creative Mind: Language Model As Hierarchical Policy For\n  Improved Exploration on Challenging Problem Solving",
            "updated": "2023-12-05T20:44:45Z",
            "published": "2023-11-01T17:52:15Z",
            "summary": "Large Language Models (LLMs) have achieved tremendous progress, yet they\nstill often struggle with challenging reasoning problems. Current approaches\naddress this challenge by sampling or searching detailed and low-level\nreasoning chains. However, these methods are still limited in their exploration\ncapabilities, making it challenging for correct solutions to stand out in the\nhuge solution space. In this work, we unleash LLMs' creative potential for\nexploring multiple diverse problem solving strategies by framing an LLM as a\nhierarchical policy via in-context learning. This policy comprises of a\nvisionary leader that proposes multiple diverse high-level problem-solving\ntactics as hints, accompanied by a follower that executes detailed\nproblem-solving processes following each of the high-level instruction. The\nfollower uses each of the leader's directives as a guide and samples multiple\nreasoning chains to tackle the problem, generating a solution group for each\nleader proposal. Additionally, we propose an effective and efficient\ntournament-based approach to select among these explored solution groups to\nreach the final answer. Our approach produces meaningful and inspiring hints,\nenhances problem-solving strategy exploration, and improves the final answer\naccuracy on challenging problems in the MATH dataset. Code will be released at\nhttps://github.com/lz1oceani/LLM-As-Hierarchical-Policy.",
            "author": [
                "Zhan Ling",
                "Yunhao Fang",
                "Xuanlin Li",
                "Tongzhou Mu",
                "Mingu Lee",
                "Reza Pourreza",
                "Roland Memisevic",
                "Hao Su"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00694v2",
                "http://arxiv.org/pdf/2311.00694v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00693v1",
            "title": "On Task-personalized Multimodal Few-shot Learning for Visually-rich\n  Document Entity Retrieval",
            "updated": "2023-11-01T17:51:43Z",
            "published": "2023-11-01T17:51:43Z",
            "summary": "Visually-rich document entity retrieval (VDER), which extracts key\ninformation (e.g. date, address) from document images like invoices and\nreceipts, has become an important topic in industrial NLP applications. The\nemergence of new document types at a constant pace, each with its unique entity\ntypes, presents a unique challenge: many documents contain unseen entity types\nthat occur only a couple of times. Addressing this challenge requires models to\nhave the ability of learning entities in a few-shot manner. However, prior\nworks for Few-shot VDER mainly address the problem at the document level with a\npredefined global entity space, which doesn't account for the entity-level\nfew-shot scenario: target entity types are locally personalized by each task\nand entity occurrences vary significantly among documents. To address this\nunexplored scenario, this paper studies a novel entity-level few-shot VDER\ntask. The challenges lie in the uniqueness of the label space for each task and\nthe increased complexity of out-of-distribution (OOD) contents. To tackle this\nnovel task, we present a task-aware meta-learning based framework, with a\ncentral focus on achieving effective task personalization that distinguishes\nbetween in-task and out-of-task distribution. Specifically, we adopt a\nhierarchical decoder (HC) and employ contrastive learning (ContrastProtoNet) to\nachieve this goal. Furthermore, we introduce a new dataset, FewVEX, to boost\nfuture research in the field of entity-level few-shot VDER. Experimental\nresults demonstrate our approaches significantly improve the robustness of\npopular meta-learning baselines.",
            "author": [
                "Jiayi Chen",
                "Hanjun Dai",
                "Bo Dai",
                "Aidong Zhang",
                "Wei Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00693v1",
                "http://arxiv.org/pdf/2311.00693v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00691v1",
            "title": "Software Repositories and Machine Learning Research in Cyber Security",
            "updated": "2023-11-01T17:46:07Z",
            "published": "2023-11-01T17:46:07Z",
            "summary": "In today's rapidly evolving technological landscape and advanced software\ndevelopment, the rise in cyber security attacks has become a pressing concern.\nThe integration of robust cyber security defenses has become essential across\nall phases of software development. It holds particular significance in\nidentifying critical cyber security vulnerabilities at the initial stages of\nthe software development life cycle, notably during the requirement phase.\nThrough the utilization of cyber security repositories like The Common Attack\nPattern Enumeration and Classification (CAPEC) from MITRE and the Common\nVulnerabilities and Exposures (CVE) databases, attempts have been made to\nleverage topic modeling and machine learning for the detection of these\nearly-stage vulnerabilities in the software requirements process. Past research\nthemes have returned successful outcomes in attempting to automate\nvulnerability identification for software developers, employing a mixture of\nunsupervised machine learning methodologies such as LDA and topic modeling.\nLooking ahead, in our pursuit to improve automation and establish connections\nbetween software requirements and vulnerabilities, our strategy entails\nadopting a variety of supervised machine learning techniques. This array\nencompasses Support Vector Machines (SVM), Na\\\"ive Bayes, random forest, neural\nnetworking and eventually transitioning into deep learning for our\ninvestigation. In the face of the escalating complexity of cyber security, the\nquestion of whether machine learning can enhance the identification of\nvulnerabilities in diverse software development scenarios is a paramount\nconsideration, offering crucial assistance to software developers in developing\nsecure software.",
            "author": [
                "Mounika Vanamala",
                "Keith Bryant",
                "Alex Caravella"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00691v1",
                "http://arxiv.org/pdf/2311.00691v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00690v3",
            "title": "What User Behaviors Make the Differences During the Process of Visual\n  Analytics?",
            "updated": "2023-12-04T02:58:02Z",
            "published": "2023-11-01T17:45:52Z",
            "summary": "The understanding of visual analytics process can benefit visualization\nresearchers from multiple aspects, including improving visual designs and\ndeveloping advanced interaction functions. However, the log files of user\nbehaviors are still hard to analyze due to the complexity of sensemaking and\nour lack of knowledge on the related user behaviors. This work presents a study\non a comprehensive data collection of user behaviors, and our analysis approach\nwith time-series classification methods. We have chosen a classical\nvisualization application, Covid-19 data analysis, with common analysis tasks\ncovering geo-spatial, time-series and multi-attributes. Our user study collects\nuser behaviors on a diverse set of visualization tasks with two comparable\nsystems, desktop and immersive visualizations. We summarize the classification\nresults with three time-series machine learning algorithms at two scales, and\nexplore the influences of behavior features. Our results reveal that user\nbehaviors can be distinguished during the process of visual analytics and there\nis a potentially strong association between the physical behaviors of users and\nthe visualization tasks they perform. We also demonstrate the usage of our\nmodels by interpreting open sessions of visual analytics, which provides an\nautomatic way to study sensemaking without tedious manual annotations.",
            "author": [
                "Zekun Wu",
                "Shahin Doroudian",
                "Aidong Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00690v3",
                "http://arxiv.org/pdf/2311.00690v3"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00687v2",
            "title": "Improving Interpersonal Communication by Simulating Audiences with\n  Language Models",
            "updated": "2023-11-03T13:17:55Z",
            "published": "2023-11-01T17:44:50Z",
            "summary": "How do we communicate with others to achieve our goals? We use our prior\nexperience or advice from others, or construct a candidate utterance by\npredicting how it will be received. However, our experiences are limited and\nbiased, and reasoning about potential outcomes can be difficult and cognitively\nchallenging. In this paper, we explore how we can leverage Large Language Model\n(LLM) simulations to help us communicate better. We propose the\nExplore-Generate-Simulate (EGS) framework, which takes as input any scenario\nwhere an individual is communicating to an audience with a goal they want to\nachieve. EGS (1) explores the solution space by producing a diverse set of\nadvice relevant to the scenario, (2) generates communication candidates\nconditioned on subsets of the advice, and (3) simulates the reactions from\nvarious audiences to determine both the best candidate and advice to use. We\nevaluate the framework on eight scenarios spanning the ten fundamental\nprocesses of interpersonal communication. For each scenario, we collect a\ndataset of human evaluations across candidates and baselines, and showcase that\nour framework's chosen candidate is preferred over popular generation\nmechanisms including Chain-of-Thought. We also find that audience simulations\nachieve reasonably high agreement with human raters across 5 of the 8\nscenarios. Finally, we demonstrate the generality of our framework by applying\nit to real-world scenarios described by users on web forums. Through\nevaluations and demonstrations, we show that EGS enhances the effectiveness and\noutcomes of goal-oriented communication across a variety of situations, thus\nopening up new possibilities for the application of large language models in\nrevolutionizing communication and decision-making processes.",
            "author": [
                "Ryan Liu",
                "Howard Yen",
                "Raja Marjieh",
                "Thomas L. Griffiths",
                "Ranjay Krishna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00687v2",
                "http://arxiv.org/pdf/2311.00687v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00686v1",
            "title": "Little Giants: Exploring the Potential of Small LLMs as Evaluation\n  Metrics in Summarization in the Eval4NLP 2023 Shared Task",
            "updated": "2023-11-01T17:44:35Z",
            "published": "2023-11-01T17:44:35Z",
            "summary": "This paper describes and analyzes our participation in the 2023 Eval4NLP\nshared task, which focuses on assessing the effectiveness of prompt-based\ntechniques to empower Large Language Models to handle the task of quality\nestimation, particularly in the context of evaluating machine translations and\nsummaries. We conducted systematic experiments with various prompting\ntechniques, including standard prompting, prompts informed by annotator\ninstructions, and innovative chain-of-thought prompting. In addition, we\nintegrated these approaches with zero-shot and one-shot learning methods to\nmaximize the efficacy of our evaluation procedures. Our work reveals that\ncombining these approaches using a \"small\", open source model (orca_mini_v3_7B)\nyields competitive results.",
            "author": [
                "Neema Kotonya",
                "Saran Krishnasamy",
                "Joel Tetreault",
                "Alejandro Jaimes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00686v1",
                "http://arxiv.org/pdf/2311.00686v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00684v2",
            "title": "Attention Alignment and Flexible Positional Embeddings Improve\n  Transformer Length Extrapolation",
            "updated": "2023-11-15T15:55:02Z",
            "published": "2023-11-01T17:43:35Z",
            "summary": "An ideal length-extrapolatable Transformer language model can handle\nsequences longer than the training length without any fine-tuning. Such\nlong-context utilization capability relies heavily on a flexible positional\nembedding design. Upon investigating the flexibility of existing large\npre-trained Transformer language models, we find that the T5 family deserves a\ncloser look, as its positional embeddings capture rich and flexible attention\npatterns. However, T5 suffers from the dispersed attention issue: the longer\nthe input sequence, the flatter the attention distribution. To alleviate the\nissue, we propose two attention alignment strategies via temperature scaling.\nOur findings show improvement on the long-context utilization capability of T5\non language modeling, retrieval, multi-document question answering, and code\ncompletion tasks without any fine-tuning. This suggests that a flexible\npositional embedding design and attention alignment can go a long way toward\nTransformer length extrapolation.",
            "author": [
                "Ta-Chung Chi",
                "Ting-Han Fan",
                "Alexander I. Rudnicky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00684v2",
                "http://arxiv.org/pdf/2311.00684v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00682v1",
            "title": "Deep Learning-Based Classification of Gamma Photon Interactions in\n  Room-Temperature Semiconductor Radiation Detectors",
            "updated": "2023-11-01T17:42:56Z",
            "published": "2023-11-01T17:42:56Z",
            "summary": "Photon counting radiation detectors have become an integral part of medical\nimaging modalities such as Positron Emission Tomography or Computed Tomography.\nOne of the most promising detectors is the wide bandgap room temperature\nsemiconductor detectors, which depends on the interaction gamma/x-ray photons\nwith the detector material involves Compton scattering which leads to multiple\ninteraction photon events (MIPEs) of a single photon. For semiconductor\ndetectors like CdZnTeSe (CZTS), which have a high overlap of detected energies\nbetween Compton and photoelectric events, it is nearly impossible to\ndistinguish between Compton scattered events from photoelectric events using\nconventional readout electronics or signal processing algorithms. Herein, we\nreport a deep learning classifier CoPhNet that distinguishes between Compton\nscattering and photoelectric interactions of gamma/x-ray photons with CdZnTeSe\n(CZTS) semiconductor detectors. Our CoPhNet model was trained using simulated\ndata to resemble actual CZTS detector pulses and validated using both simulated\nand experimental data. These results demonstrated that our CoPhNet model can\nachieve high classification accuracy over the simulated test set. It also holds\nits performance robustness under operating parameter shifts such as\nSignal-Noise-Ratio (SNR) and incident energy. Our work thus laid solid\nfoundation for developing next-generation high energy gamma-rays detectors for\nbetter biomedical imaging.",
            "author": [
                "Sandeep K. Chaudhuri",
                "Qinyang Li",
                "Krishna C. Mandal",
                "Jianjun Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00682v1",
                "http://arxiv.org/pdf/2311.00682v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00678v1",
            "title": "Complexity of Single Loop Algorithms for Nonlinear Programming with\n  Stochastic Objective and Constraints",
            "updated": "2023-11-01T17:37:41Z",
            "published": "2023-11-01T17:37:41Z",
            "summary": "We analyze the complexity of single-loop quadratic penalty and augmented\nLagrangian algorithms for solving nonconvex optimization problems with\nfunctional equality constraints. We consider three cases, in all of which the\nobjective is stochastic and smooth, that is, an expectation over an unknown\ndistribution that is accessed by sampling. The nature of the equality\nconstraints differs among the three cases: deterministic and linear in the\nfirst case, deterministic, smooth and nonlinear in the second case, and\nstochastic, smooth and nonlinear in the third case. Variance reduction\ntechniques are used to improve the complexity. To find a point that satisfies\n$\\varepsilon$-approximate first-order conditions, we require\n$\\widetilde{O}(\\varepsilon^{-3})$ complexity in the first case,\n$\\widetilde{O}(\\varepsilon^{-4})$ in the second case, and\n$\\widetilde{O}(\\varepsilon^{-5})$ in the third case. For the first and third\ncases, they are the first algorithms of \"single loop\" type (that also use\n$O(1)$ samples at each iteration) that still achieve the best-known complexity\nguarantees.",
            "author": [
                "Ahmet Alacaoglu",
                "Stephen J. Wright"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00678v1",
                "http://arxiv.org/pdf/2311.00678v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16131v1",
            "title": "Secure Arcade: A Gamified Defense Against Cyber Attacks",
            "updated": "2023-11-01T17:35:49Z",
            "published": "2023-11-01T17:35:49Z",
            "summary": "In modernity, we continually receive increasingly intricate technologies that\nallow us to increase our lives convenience and efficiency. Our technology,\nparticularly technology available over the internet, is advancing at\nunprecedented speed. However, this speed of advancement allows those behind\nmalicious attacks to have an increasingly easier time taking advantage of those\nwho know little about computer security. Unfortunately, education in the\ncomputer security field is generally limited only to tertiary education. This\nresearch addresses this problem through a gamified web-based application that\ndrives users to reach learning goals to help them become more vigilant internet\nusers: 1. Learn and memorize general computer security terminology, 2. Become\nfamiliar with basic cryptography concepts, 3. Learn to recognize potential\nphishing scams via email quickly, and 4. Learn common attacks on servers and\nhow to deal with them.",
            "author": [
                "Sean Loesch",
                "Ryan Hrastich",
                "Jordan Herbert",
                "Ben Drangstveit",
                "Jacob Weber",
                "Mounika Vanamala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16131v1",
                "http://arxiv.org/pdf/2311.16131v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00676v1",
            "title": "Last-Iterate Convergence Properties of Regret-Matching Algorithms in\n  Games",
            "updated": "2023-11-01T17:34:58Z",
            "published": "2023-11-01T17:34:58Z",
            "summary": "Algorithms based on regret matching, specifically regret matching$^+$\n(RM$^+$), and its variants are the most popular approaches for solving\nlarge-scale two-player zero-sum games in practice. Unlike algorithms such as\noptimistic gradient descent ascent, which have strong last-iterate and ergodic\nconvergence properties for zero-sum games, virtually nothing is known about the\nlast-iterate properties of regret-matching algorithms. Given the importance of\nlast-iterate convergence for numerical optimization reasons and relevance as\nmodeling real-word learning in games, in this paper, we study the last-iterate\nconvergence properties of various popular variants of RM$^+$. First, we show\nnumerically that several practical variants such as simultaneous RM$^+$,\nalternating RM$^+$, and simultaneous predictive RM$^+$, all lack last-iterate\nconvergence guarantees even on a simple $3\\times 3$ game. We then prove that\nrecent variants of these algorithms based on a smoothing technique do enjoy\nlast-iterate convergence: we prove that extragradient RM$^{+}$ and smooth\nPredictive RM$^+$ enjoy asymptotic last-iterate convergence (without a rate)\nand $1/\\sqrt{t}$ best-iterate convergence. Finally, we introduce restarted\nvariants of these algorithms, and show that they enjoy linear-rate last-iterate\nconvergence.",
            "author": [
                "Yang Cai",
                "Gabriele Farina",
                "Julien Grand-Cl\u00e9ment",
                "Christian Kroer",
                "Chung-Wei Lee",
                "Haipeng Luo",
                "Weiqiang Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00676v1",
                "http://arxiv.org/pdf/2311.00676v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00674v1",
            "title": "Recovering Linear Causal Models with Latent Variables via Cholesky\n  Factorization of Covariance Matrix",
            "updated": "2023-11-01T17:27:49Z",
            "published": "2023-11-01T17:27:49Z",
            "summary": "Discovering the causal relationship via recovering the directed acyclic graph\n(DAG) structure from the observed data is a well-known challenging\ncombinatorial problem. When there are latent variables, the problem becomes\neven more difficult. In this paper, we first propose a DAG structure recovering\nalgorithm, which is based on the Cholesky factorization of the covariance\nmatrix of the observed data. The algorithm is fast and easy to implement and\nhas theoretical grantees for exact recovery. On synthetic and real-world\ndatasets, the algorithm is significantly faster than previous methods and\nachieves the state-of-the-art performance. Furthermore, under the equal error\nvariances assumption, we incorporate an optimization procedure into the\nCholesky factorization based algorithm to handle the DAG recovering problem\nwith latent variables. Numerical simulations show that the modified \"Cholesky +\noptimization\" algorithm is able to recover the ground truth graph in most cases\nand outperforms existing algorithms.",
            "author": [
                "Yunfeng Cai",
                "Xu Li",
                "Minging Sun",
                "Ping Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00674v1",
                "http://arxiv.org/pdf/2311.00674v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00668v1",
            "title": "ProcSim: Proxy-based Confidence for Robust Similarity Learning",
            "updated": "2023-11-01T17:17:14Z",
            "published": "2023-11-01T17:17:14Z",
            "summary": "Deep Metric Learning (DML) methods aim at learning an embedding space in\nwhich distances are closely related to the inherent semantic similarity of the\ninputs. Previous studies have shown that popular benchmark datasets often\ncontain numerous wrong labels, and DML methods are susceptible to them.\nIntending to study the effect of realistic noise, we create an ontology of the\nclasses in a dataset and use it to simulate semantically coherent labeling\nmistakes. To train robust DML models, we propose ProcSim, a simple framework\nthat assigns a confidence score to each sample using the normalized distance to\nits class representative. The experimental results show that the proposed\nmethod achieves state-of-the-art performance on the DML benchmark datasets\ninjected with uniform and the proposed semantically coherent noise.",
            "author": [
                "Oriol Barbany",
                "Xiaofan Lin",
                "Muhammet Bastan",
                "Arnab Dhua"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00668v1",
                "http://arxiv.org/pdf/2311.00668v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00664v1",
            "title": "Latent Space Translation via Semantic Alignment",
            "updated": "2023-11-01T17:12:00Z",
            "published": "2023-11-01T17:12:00Z",
            "summary": "While different neural models often exhibit latent spaces that are alike when\nexposed to semantically related data, this intrinsic similarity is not always\nimmediately discernible. Towards a better understanding of this phenomenon, our\nwork shows how representations learned from these neural modules can be\ntranslated between different pre-trained networks via simpler transformations\nthan previously thought. An advantage of this approach is the ability to\nestimate these transformations using standard, well-understood algebraic\nprocedures that have closed-form solutions. Our method directly estimates a\ntransformation between two given latent spaces, thereby enabling effective\nstitching of encoders and decoders without additional training. We extensively\nvalidate the adaptability of this translation procedure in different\nexperimental settings: across various trainings, domains, architectures (e.g.,\nResNet, CNN, ViT), and in multiple downstream tasks (classification,\nreconstruction). Notably, we show how it is possible to zero-shot stitch text\nencoders and vision decoders, or vice-versa, yielding surprisingly good\nclassification performance in this multimodal setting.",
            "author": [
                "Valentino Maiorca",
                "Luca Moschella",
                "Antonio Norelli",
                "Marco Fumero",
                "Francesco Locatello",
                "Emanuele Rodol\u00e0"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00664v1",
                "http://arxiv.org/pdf/2311.00664v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00663v1",
            "title": "Variational Gaussian Processes For Linear Inverse Problems",
            "updated": "2023-11-01T17:10:38Z",
            "published": "2023-11-01T17:10:38Z",
            "summary": "By now Bayesian methods are routinely used in practice for solving inverse\nproblems. In inverse problems the parameter or signal of interest is observed\nonly indirectly, as an image of a given map, and the observations are typically\nfurther corrupted with noise. Bayes offers a natural way to regularize these\nproblems via the prior distribution and provides a probabilistic solution,\nquantifying the remaining uncertainty in the problem. However, the\ncomputational costs of standard, sampling based Bayesian approaches can be\noverly large in such complex models. Therefore, in practice variational Bayes\nis becoming increasingly popular. Nevertheless, the theoretical understanding\nof these methods is still relatively limited, especially in context of inverse\nproblems. In our analysis we investigate variational Bayesian methods for\nGaussian process priors to solve linear inverse problems. We consider both\nmildly and severely ill-posed inverse problems and work with the popular\ninducing variables variational Bayes approach proposed by Titsias in 2009. We\nderive posterior contraction rates for the variational posterior in general\nsettings and show that the minimax estimation rate can be attained by correctly\ntunned procedures. As specific examples we consider a collection of inverse\nproblems including the heat equation, Volterra operator and Radon transform and\ninducing variable methods based on population and empirical spectral features.",
            "author": [
                "Thibault Randrianarisoa",
                "Botond Szabo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00663v1",
                "http://arxiv.org/pdf/2311.00663v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ML",
                "stat.TH",
                "62G08"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00660v3",
            "title": "TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining\n  and Object Detection in Rain",
            "updated": "2023-11-08T02:46:34Z",
            "published": "2023-11-01T17:08:26Z",
            "summary": "Rain generation algorithms have the potential to improve the generalization\nof deraining methods and scene understanding in rainy conditions. However, in\npractice, they produce artifacts and distortions and struggle to control the\namount of rain generated due to a lack of proper constraints. In this paper, we\npropose an unpaired image-to-image translation framework for generating\nrealistic rainy images. We first introduce a Triangular Probability Similarity\n(TPS) constraint to guide the generated images toward clear and rainy images in\nthe discriminator manifold, thereby minimizing artifacts and distortions during\nrain generation. Unlike conventional contrastive learning approaches, which\nindiscriminately push negative samples away from the anchors, we propose a\nSemantic Noise Contrastive Estimation (SeNCE) strategy and reassess the pushing\nforce of negative samples based on the semantic similarity between the clear\nand the rainy images and the feature similarity between the anchor and the\nnegative samples. Experiments demonstrate realistic rain generation with\nminimal artifacts and distortions, which benefits image deraining and object\ndetection in rain. Furthermore, the method can be used to generate realistic\nsnowy and night images, underscoring its potential for broader applicability.\nCode is available at https://github.com/ShenZheng2000/TPSeNCE.",
            "author": [
                "Shen Zheng",
                "Changjie Lu",
                "Srinivasa G. Narasimhan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00660v3",
                "http://arxiv.org/pdf/2311.00660v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00656v1",
            "title": "Online Signal Estimation on the Graph Edges via Line Graph\n  Transformation",
            "updated": "2023-11-01T17:02:41Z",
            "published": "2023-11-01T17:02:41Z",
            "summary": "We propose the Line Graph Normalized Least Mean Square (LGNLMS) algorithm for\nonline time-varying graph edge signals prediction. LGNLMS utilizes the Line\nGraph to transform graph edge signals into the node of its edge-to-vertex dual.\nThis enables edge signals to be processed using established GSP concepts\nwithout redefining them on graph edges.",
            "author": [
                "Yi Yan",
                "Ercan Engin Kuruoglu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00656v1",
                "http://arxiv.org/pdf/2311.00656v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00651v2",
            "title": "Emergence of Collective Open-Ended Exploration from Decentralized\n  Meta-Reinforcement Learning",
            "updated": "2023-11-02T10:35:33Z",
            "published": "2023-11-01T16:56:44Z",
            "summary": "Recent works have proven that intricate cooperative behaviors can emerge in\nagents trained using meta reinforcement learning on open ended task\ndistributions using self-play. While the results are impressive, we argue that\nself-play and other centralized training techniques do not accurately reflect\nhow general collective exploration strategies emerge in the natural world:\nthrough decentralized training and over an open-ended distribution of tasks. In\nthis work we therefore investigate the emergence of collective exploration\nstrategies, where several agents meta-learn independent recurrent policies on\nan open ended distribution of tasks. To this end we introduce a novel\nenvironment with an open ended procedurally generated task space which\ndynamically combines multiple subtasks sampled from five diverse task types to\nform a vast distribution of task trees. We show that decentralized agents\ntrained in our environment exhibit strong generalization abilities when\nconfronted with novel objects at test time. Additionally, despite never being\nforced to cooperate during training the agents learn collective exploration\nstrategies which allow them to solve novel tasks never encountered during\ntraining. We further find that the agents learned collective exploration\nstrategies extend to an open ended task setting, allowing them to solve task\ntrees of twice the depth compared to the ones seen during training. Our open\nsource code as well as videos of the agents can be found on our companion\nwebsite.",
            "author": [
                "Richard Bornemann",
                "Gautier Hamon",
                "Eleni Nisioti",
                "Cl\u00e9ment Moulin-Frier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00651v2",
                "http://arxiv.org/pdf/2311.00651v2"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06285v1",
            "title": "Sounding Bodies: Modeling 3D Spatial Sound of Humans Using Body Pose and\n  Audio",
            "updated": "2023-11-01T16:40:35Z",
            "published": "2023-11-01T16:40:35Z",
            "summary": "While 3D human body modeling has received much attention in computer vision,\nmodeling the acoustic equivalent, i.e. modeling 3D spatial audio produced by\nbody motion and speech, has fallen short in the community. To close this gap,\nwe present a model that can generate accurate 3D spatial audio for full human\nbodies. The system consumes, as input, audio signals from headset microphones\nand body pose, and produces, as output, a 3D sound field surrounding the\ntransmitter's body, from which spatial audio can be rendered at any arbitrary\nposition in the 3D space. We collect a first-of-its-kind multimodal dataset of\nhuman bodies, recorded with multiple cameras and a spherical array of 345\nmicrophones. In an empirical evaluation, we demonstrate that our model can\nproduce accurate body-induced sound fields when trained with a suitable loss.\nDataset and code are available online.",
            "author": [
                "Xudong Xu",
                "Dejan Markovic",
                "Jacob Sandakly",
                "Todd Keebler",
                "Steven Krenn",
                "Alexander Richard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06285v1",
                "http://arxiv.org/pdf/2311.06285v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00638v1",
            "title": "FAIRLABEL: Correcting Bias in Labels",
            "updated": "2023-11-01T16:38:27Z",
            "published": "2023-11-01T16:38:27Z",
            "summary": "There are several algorithms for measuring fairness of ML models. A\nfundamental assumption in these approaches is that the ground truth is fair or\nunbiased. In real-world datasets, however, the ground truth often contains data\nthat is a result of historical and societal biases and discrimination. Models\ntrained on these datasets will inherit and propagate the biases to the model\noutputs. We propose FAIRLABEL, an algorithm which detects and corrects biases\nin labels. The goal of FAIRLABELis to reduce the Disparate Impact (DI) across\ngroups while maintaining high accuracy in predictions. We propose metrics to\nmeasure the quality of bias correction and validate FAIRLABEL on synthetic\ndatasets and show that the label correction is correct 86.7% of the time vs.\n71.9% for a baseline model. We also apply FAIRLABEL on benchmark datasets such\nas UCI Adult, German Credit Risk, and Compas datasets and show that the\nDisparate Impact Ratio increases by as much as 54.2%.",
            "author": [
                "Srinivasan H Sengamedu",
                "Hien Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00638v1",
                "http://arxiv.org/pdf/2311.00638v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68T07",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00636v1",
            "title": "Kronecker-Factored Approximate Curvature for Modern Neural Network\n  Architectures",
            "updated": "2023-11-01T16:37:00Z",
            "published": "2023-11-01T16:37:00Z",
            "summary": "The core components of many modern neural network architectures, such as\ntransformers, convolutional, or graph neural networks, can be expressed as\nlinear layers with $\\textit{weight-sharing}$. Kronecker-Factored Approximate\nCurvature (K-FAC), a second-order optimisation method, has shown promise to\nspeed up neural network training and thereby reduce computational costs.\nHowever, there is currently no framework to apply it to generic architectures,\nspecifically ones with linear weight-sharing layers. In this work, we identify\ntwo different settings of linear weight-sharing layers which motivate two\nflavours of K-FAC -- $\\textit{expand}$ and $\\textit{reduce}$. We show that they\nare exact for deep linear networks with weight-sharing in their respective\nsetting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we\nleverage to speed up automatic hyperparameter selection via optimising the\nmarginal likelihood for a Wide ResNet. Finally, we observe little difference\nbetween these two K-FAC variations when using them to train both a graph neural\nnetwork and a vision transformer. However, both variations are able to reach a\nfixed validation metric target in $50$-$75\\%$ of the number of steps of a\nfirst-order reference run, which translates into a comparable improvement in\nwall-clock time. This highlights the potential of applying K-FAC to modern\nneural network architectures.",
            "author": [
                "Runa Eschenhagen",
                "Alexander Immer",
                "Richard E. Turner",
                "Frank Schneider",
                "Philipp Hennig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00636v1",
                "http://arxiv.org/pdf/2311.00636v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00634v2",
            "title": "A Bi-level Framework for Traffic Accident Duration Prediction:\n  Leveraging Weather and Road Condition Data within a Practical Optimum\n  Pipeline",
            "updated": "2023-11-03T19:26:03Z",
            "published": "2023-11-01T16:33:37Z",
            "summary": "Due to the stochastic nature of events, predicting the duration of a traffic\nincident presents a formidable challenge. Accurate duration estimation can\nresult in substantial advantages for commuters in selecting optimal routes and\nfor traffic management personnel in addressing non-recurring congestion issues.\nIn this study, we gathered accident duration, road conditions, and\nmeteorological data from a database of traffic accidents to check the\nfeasibility of a traffic accident duration pipeline without accident contextual\ninformation data like accident severity and textual description. Multiple\nmachine learning models were employed to predict whether an accident's impact\non road traffic would be of a short-term or long-term nature, and then\nutilizing a bimodal approach the precise duration of the incident's effect was\ndetermined. Our binary classification random forest model distinguished between\nshort-term and long-term effects with an 83% accuracy rate, while the LightGBM\nregression model outperformed other machine learning regression models with\nMean Average Error (MAE) values of 26.15 and 13.3 and RMSE values of 32.91 and\n28.91 for short and long-term accident duration prediction, respectively. Using\nthe optimal classification and regression model identified in the preceding\nsection, we then construct an end-to-end pipeline to incorporate the entire\nprocess. The results of both separate and combined approaches were comparable\nwith previous works, which shows the applicability of only using static\nfeatures for predicting traffic accident duration. The SHAP value analysis\nidentified weather conditions, wind chill and wind speed as the most\ninfluential factors in determining the duration of an accident.",
            "author": [
                "Rafat Tabassum Sukonna",
                "Soham Irtiza Swapnil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00634v2",
                "http://arxiv.org/pdf/2311.00634v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00633v1",
            "title": "Ab initio machine-learning unveils strong anharmonicity in non-Arrhenius\n  self-diffusion of tungsten",
            "updated": "2023-11-01T16:31:01Z",
            "published": "2023-11-01T16:31:01Z",
            "summary": "We propose an efficient ab initio framework to compute the Gibbs energy of\nthe transition state in vacancy-mediated diffusion including the relevant\nthermal excitations at density-functional-theory level. With the aid of a\nbespoke machine-learning interatomic potential, the temperature-dependent\nvacancy formation and migration Gibbs energies of the prototype system bcc\ntungsten are shown to be strongly affected by anharmonicity. This explains the\nphysical origin of the experimentally observed non-Arrhenius behavior of W\nself-diffusion as a case study. The good agreement of the self-diffusivity with\nexperiment demonstrates that accurate ab initio diffusion databases are in\nreach.",
            "author": [
                "Xi Zhang",
                "Sergiy V. Divinski",
                "Blazej Grabowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00633v1",
                "http://arxiv.org/pdf/2311.00633v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00619v2",
            "title": "Loss Modeling for Multi-Annotator Datasets",
            "updated": "2023-11-16T05:31:27Z",
            "published": "2023-11-01T16:14:34Z",
            "summary": "Accounting for the opinions of all annotators of a dataset is critical for\nfairness. However, when annotating large datasets, individual annotators will\nfrequently provide thousands of ratings which can lead to fatigue.\nAdditionally, these annotation processes can occur over multiple days which can\nlead to an inaccurate representation of an annotator's opinion over time. To\ncombat this, we propose to learn a more accurate representation of diverse\nopinions by utilizing multitask learning in conjunction with loss-based label\ncorrection. We show that using our novel formulation, we can cleanly separate\nagreeing and disagreeing annotations. Furthermore, we demonstrate that this\nmodification can improve prediction performance in a single or multi-annotator\nsetting. Lastly, we show that this method remains robust to additional label\nnoise that is applied to subjective data.",
            "author": [
                "Uthman Jinadu",
                "Jesse Annan",
                "Shanshan Wen",
                "Yi Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00619v2",
                "http://arxiv.org/pdf/2311.00619v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00613v2",
            "title": "Controllable Music Production with Diffusion Models and Guidance\n  Gradients",
            "updated": "2023-12-05T10:32:03Z",
            "published": "2023-11-01T16:01:01Z",
            "summary": "We demonstrate how conditional generation from diffusion models can be used\nto tackle a variety of realistic tasks in the production of music in 44.1kHz\nstereo audio with sampling-time guidance. The scenarios we consider include\ncontinuation, inpainting and regeneration of musical audio, the creation of\nsmooth transitions between two different music tracks, and the transfer of\ndesired stylistic characteristics to existing audio clips. We achieve this by\napplying guidance at sampling time in a simple framework that supports both\nreconstruction and classification losses, or any combination of the two. This\napproach ensures that generated audio can match its surrounding context, or\nconform to a class distribution or latent representation specified relative to\nany suitable pre-trained classifier or embedding model. Audio samples are\navailable at https://machinelearning.apple.com/research/controllable-music",
            "author": [
                "Mark Levy",
                "Bruno Di Giorgi",
                "Floris Weers",
                "Angelos Katharopoulos",
                "Tom Nickson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00613v2",
                "http://arxiv.org/pdf/2311.00613v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00612v1",
            "title": "A Collaborative Filtering-Based Two Stage Model with Item Dependency for\n  Course Recommendation",
            "updated": "2023-11-01T16:01:00Z",
            "published": "2023-11-01T16:01:00Z",
            "summary": "Recommender systems have been studied for decades with numerous promising\nmodels been proposed. Among them, Collaborative Filtering (CF) models are\narguably the most successful one due to its high accuracy in recommendation and\nelimination of privacy-concerned personal meta-data from training. This paper\nextends the usage of CF-based model to the task of course recommendation. We\npoint out several challenges in applying the existing CF-models to build a\ncourse recommendation engine, including the lack of rating and meta-data, the\nimbalance of course registration distribution, and the demand of course\ndependency modeling. We then propose several ideas to address these challenges.\nEventually, we combine a two-stage CF model regularized by course dependency\nwith a graph-based recommender based on course-transition network, to achieve\nAUC as high as 0.97 with a real-world dataset.",
            "author": [
                "Eric L. Lee",
                "Tsung-Ting Kuo",
                "Shou-De Lin"
            ],
            "link": [
                "http://dx.doi.org/10.1109/DSAA.2017.18",
                "http://arxiv.org/abs/2311.00612v1",
                "http://arxiv.org/pdf/2311.00612v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00603v1",
            "title": "Occluded Person Re-Identification with Deep Learning: A Survey and\n  Perspectives",
            "updated": "2023-11-01T15:52:51Z",
            "published": "2023-11-01T15:52:51Z",
            "summary": "Person re-identification (Re-ID) technology plays an increasingly crucial\nrole in intelligent surveillance systems. Widespread occlusion significantly\nimpacts the performance of person Re-ID. Occluded person Re-ID refers to a\npedestrian matching method that deals with challenges such as pedestrian\ninformation loss, noise interference, and perspective misalignment. It has\ngarnered extensive attention from researchers. Over the past few years, several\nocclusion-solving person Re-ID methods have been proposed, tackling various\nsub-problems arising from occlusion. However, there is a lack of comprehensive\nstudies that compare, summarize, and evaluate the potential of occluded person\nRe-ID methods in detail. In this review, we start by providing a detailed\noverview of the datasets and evaluation scheme used for occluded person Re-ID.\nNext, we scientifically classify and analyze existing deep learning-based\noccluded person Re-ID methods from various perspectives, summarizing them\nconcisely. Furthermore, we conduct a systematic comparison among these methods,\nidentify the state-of-the-art approaches, and present an outlook on the future\ndevelopment of occluded person Re-ID.",
            "author": [
                "Enhao Ning",
                "Changshuo Wang",
                "Huang Zhangc",
                "Xin Ning",
                "Prayag Tiwari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00603v1",
                "http://arxiv.org/pdf/2311.00603v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00599v1",
            "title": "Structure Learning with Adaptive Random Neighborhood Informed MCMC",
            "updated": "2023-11-01T15:47:18Z",
            "published": "2023-11-01T15:47:18Z",
            "summary": "In this paper, we introduce a novel MCMC sampler, PARNI-DAG, for a\nfully-Bayesian approach to the problem of structure learning under\nobservational data. Under the assumption of causal sufficiency, the algorithm\nallows for approximate sampling directly from the posterior distribution on\nDirected Acyclic Graphs (DAGs). PARNI-DAG performs efficient sampling of DAGs\nvia locally informed, adaptive random neighborhood proposal that results in\nbetter mixing properties. In addition, to ensure better scalability with the\nnumber of nodes, we couple PARNI-DAG with a pre-tuning procedure of the\nsampler's parameters that exploits a skeleton graph derived through some\nconstraint-based or scoring-based algorithms. Thanks to these novel features,\nPARNI-DAG quickly converges to high-probability regions and is less likely to\nget stuck in local modes in the presence of high correlation between nodes in\nhigh-dimensional settings. After introducing the technical novelties in\nPARNI-DAG, we empirically demonstrate its mixing efficiency and accuracy in\nlearning DAG structures on a variety of experiments.",
            "author": [
                "Alberto Caron",
                "Xitong Liang",
                "Samuel Livingstone",
                "Jim Griffin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00599v1",
                "http://arxiv.org/pdf/2311.00599v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00594v1",
            "title": "Rethinking Variational Inference for Probabilistic Programs with\n  Stochastic Support",
            "updated": "2023-11-01T15:38:51Z",
            "published": "2023-11-01T15:38:51Z",
            "summary": "We introduce Support Decomposition Variational Inference (SDVI), a new\nvariational inference (VI) approach for probabilistic programs with stochastic\nsupport. Existing approaches to this problem rely on designing a single global\nvariational guide on a variable-by-variable basis, while maintaining the\nstochastic control flow of the original program. SDVI instead breaks the\nprogram down into sub-programs with static support, before automatically\nbuilding separate sub-guides for each. This decomposition significantly aids in\nthe construction of suitable variational families, enabling, in turn,\nsubstantial improvements in inference performance.",
            "author": [
                "Tim Reichelt",
                "Luke Ong",
                "Tom Rainforth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00594v1",
                "http://arxiv.org/pdf/2311.00594v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00591v1",
            "title": "Coop: Memory is not a Commodity",
            "updated": "2023-11-01T15:35:51Z",
            "published": "2023-11-01T15:35:51Z",
            "summary": "Tensor rematerialization allows the training of deep neural networks (DNNs)\nunder limited memory budgets by checkpointing the models and recomputing the\nevicted tensors as needed. However, the existing tensor rematerialization\ntechniques overlook the memory system in deep learning frameworks and\nimplicitly assume that free memory blocks at different addresses are identical.\nUnder this flawed assumption, discontiguous tensors are evicted, among which\nsome are not used to allocate the new tensor. This leads to severe memory\nfragmentation and increases the cost of potential rematerializations. To\naddress this issue, we propose to evict tensors within a sliding window to\nensure all evictions are contiguous and are immediately used. Furthermore, we\nproposed cheap tensor partitioning and recomputable in-place to further reduce\nthe rematerialization cost by optimizing the tensor allocation. We named our\nmethod Coop as it is a co-optimization of tensor allocation and tensor\nrematerialization. We evaluated Coop on eight representative DNNs. The\nexperimental results demonstrate that Coop achieves up to $2\\times$ memory\nsaving and hugely reduces compute overhead, search latency, and memory\nfragmentation compared to the state-of-the-art baselines.",
            "author": [
                "Jianhao Zhang",
                "Shihan Ma",
                "Peihong Liu",
                "Jinhui Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00591v1",
                "http://arxiv.org/pdf/2311.00591v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00587v2",
            "title": "Crosslingual Retrieval Augmented In-context Learning for Bangla",
            "updated": "2023-12-02T16:54:23Z",
            "published": "2023-11-01T15:32:50Z",
            "summary": "The promise of Large Language Models (LLMs) in Natural Language Processing\nhas often been overshadowed by their limited performance in low-resource\nlanguages such as Bangla. To address this, our paper presents a pioneering\napproach that utilizes cross-lingual retrieval augmented in-context learning.\nBy strategically sourcing semantically similar prompts from high-resource\nlanguage, we enable multilingual pretrained language models (MPLMs), especially\nthe generative model BLOOMZ, to successfully boost performance on Bangla tasks.\nOur extensive evaluation highlights that the cross-lingual retrieval augmented\nprompts bring steady improvements to MPLMs over the zero-shot performance.",
            "author": [
                "Xiaoqian Li",
                "Ercong Nie",
                "Sheng Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00587v2",
                "http://arxiv.org/pdf/2311.00587v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00580v1",
            "title": "Flexible Tails for Normalising Flows, with Application to the Modelling\n  of Financial Return Data",
            "updated": "2023-11-01T15:27:08Z",
            "published": "2023-11-01T15:27:08Z",
            "summary": "We propose a transformation capable of altering the tail properties of a\ndistribution, motivated by extreme value theory, which can be used as a layer\nin a normalizing flow to approximate multivariate heavy tailed distributions.\nWe apply this approach to model financial returns, capturing potentially\nextreme shocks that arise in such data. The trained models can be used directly\nto generate new synthetic sets of potentially extreme returns",
            "author": [
                "Tennessee Hickling",
                "Dennis Prangle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00580v1",
                "http://arxiv.org/pdf/2311.00580v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00579v1",
            "title": "Revealing CNN Architectures via Side-Channel Analysis in Dataflow-based\n  Inference Accelerators",
            "updated": "2023-11-01T15:23:04Z",
            "published": "2023-11-01T15:23:04Z",
            "summary": "Convolution Neural Networks (CNNs) are widely used in various domains. Recent\nadvances in dataflow-based CNN accelerators have enabled CNN inference in\nresource-constrained edge devices. These dataflow accelerators utilize inherent\ndata reuse of convolution layers to process CNN models efficiently. Concealing\nthe architecture of CNN models is critical for privacy and security. This paper\nevaluates memory-based side-channel information to recover CNN architectures\nfrom dataflow-based CNN inference accelerators. The proposed attack exploits\nspatial and temporal data reuse of the dataflow mapping on CNN accelerators and\narchitectural hints to recover the structure of CNN models. Experimental\nresults demonstrate that our proposed side-channel attack can recover the\nstructures of popular CNN models, namely Lenet, Alexnet, and VGGnet16.",
            "author": [
                "Hansika Weerasena",
                "Prabhat Mishra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00579v1",
                "http://arxiv.org/pdf/2311.00579v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00578v1",
            "title": "Transfer learning for improved generalizability in causal\n  physics-informed neural networks for beam simulations",
            "updated": "2023-11-01T15:19:54Z",
            "published": "2023-11-01T15:19:54Z",
            "summary": "This paper introduces a novel methodology for simulating the dynamics of\nbeams on elastic foundations. Specifically, Euler-Bernoulli and Timoshenko beam\nmodels on the Winkler foundation are simulated using a transfer learning\napproach within a causality-respecting physics-informed neural network (PINN)\nframework. Conventional PINNs encounter challenges in handling large space-time\ndomains, even for problems with closed-form analytical solutions. A\ncausality-respecting PINN loss function is employed to overcome this\nlimitation, effectively capturing the underlying physics. However, it is\nobserved that the causality-respecting PINN lacks generalizability. We propose\nusing solutions to similar problems instead of training from scratch by\nemploying transfer learning while adhering to causality to accelerate\nconvergence and ensure accurate results across diverse scenarios. Numerical\nexperiments on the Euler-Bernoulli beam highlight the efficacy of the proposed\napproach for various initial conditions, including those with noise in the\ninitial data. Furthermore, the potential of the proposed method is demonstrated\nfor the Timoshenko beam in an extended spatial and temporal domain. Several\ncomparisons suggest that the proposed method accurately captures the inherent\ndynamics, outperforming the state-of-the-art physics-informed methods under\nstandard $L^2$-norm metric and accelerating convergence.",
            "author": [
                "Taniya Kapoor",
                "Hongrui Wang",
                "Alfredo Nunez",
                "Rolf Dollevoet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00578v1",
                "http://arxiv.org/pdf/2311.00578v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00577v1",
            "title": "Personalized Assignment to One of Many Treatment Arms via Regularized\n  and Clustered Joint Assignment Forests",
            "updated": "2023-11-01T15:18:22Z",
            "published": "2023-11-01T15:18:22Z",
            "summary": "We consider learning personalized assignments to one of many treatment arms\nfrom a randomized controlled trial. Standard methods that estimate\nheterogeneous treatment effects separately for each arm may perform poorly in\nthis case due to excess variance. We instead propose methods that pool\ninformation across treatment arms: First, we consider a regularized\nforest-based assignment algorithm based on greedy recursive partitioning that\nshrinks effect estimates across arms. Second, we augment our algorithm by a\nclustering scheme that combines treatment arms with consistently similar\noutcomes. In a simulation study, we compare the performance of these approaches\nto predicting arm-wise outcomes separately, and document gains of directly\noptimizing the treatment assignment with regularization and clustering. In a\ntheoretical model, we illustrate how a high number of treatment arms makes\nfinding the best arm hard, while we can achieve sizable utility gains from\npersonalization by regularized optimization.",
            "author": [
                "Rahul Ladhania",
                "Jann Spiess",
                "Lyle Ungar",
                "Wenbo Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00577v1",
                "http://arxiv.org/pdf/2311.00577v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "econ.EM",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00739v1",
            "title": "Can Large Language Models Design Accurate Label Functions?",
            "updated": "2023-11-01T15:14:46Z",
            "published": "2023-11-01T15:14:46Z",
            "summary": "Programmatic weak supervision methodologies facilitate the expedited labeling\nof extensive datasets through the use of label functions (LFs) that encapsulate\nheuristic data sources. Nonetheless, the creation of precise LFs necessitates\ndomain expertise and substantial endeavors. Recent advances in pre-trained\nlanguage models (PLMs) have exhibited substantial potential across diverse\ntasks. However, the capacity of PLMs to autonomously formulate accurate LFs\nremains an underexplored domain. In this research, we address this gap by\nintroducing DataSculpt, an interactive framework that harnesses PLMs for the\nautomated generation of LFs. Within DataSculpt, we incorporate an array of\nprompting techniques, instance selection strategies, and LF filtration methods\nto explore the expansive design landscape. Ultimately, we conduct a thorough\nassessment of DataSculpt's performance on 12 real-world datasets, encompassing\na range of tasks. This evaluation unveils both the strengths and limitations of\ncontemporary PLMs in LF design.",
            "author": [
                "Naiqing Guan",
                "Kaiwen Chen",
                "Nick Koudas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00739v1",
                "http://arxiv.org/pdf/2311.00739v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DB",
                "cs.LG",
                "H.2.8; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00568v1",
            "title": "Scalable kernel balancing weights in a nationwide observational study of\n  hospital profit status and heart attack outcomes",
            "updated": "2023-11-01T15:08:52Z",
            "published": "2023-11-01T15:08:52Z",
            "summary": "Weighting is a general and often-used method for statistical adjustment.\nWeighting has two objectives: first, to balance covariate distributions, and\nsecond, to ensure that the weights have minimal dispersion and thus produce a\nmore stable estimator. A recent, increasingly common approach directly\noptimizes the weights toward these two objectives. However, this approach has\nnot yet been feasible in large-scale datasets when investigators wish to\nflexibly balance general basis functions in an extended feature space. For\nexample, many balancing approaches cannot scale to national-level health\nservices research studies. To address this practical problem, we describe a\nscalable and flexible approach to weighting that integrates a basis expansion\nin a reproducing kernel Hilbert space with state-of-the-art convex optimization\ntechniques. Specifically, we use the rank-restricted Nystr\\\"{o}m method to\nefficiently compute a kernel basis for balancing in {nearly} linear time and\nspace, and then use the specialized first-order alternating direction method of\nmultipliers to rapidly find the optimal weights. In an extensive simulation\nstudy, we provide new insights into the performance of weighting estimators in\nlarge datasets, showing that the proposed approach substantially outperforms\nothers in terms of accuracy and speed. Finally, we use this weighting approach\nto conduct a national study of the relationship between hospital profit status\nand heart attack outcomes in a comprehensive dataset of 1.27 million patients.\nWe find that for-profit hospitals use interventional cardiology to treat heart\nattacks at similar rates as other hospitals, but have higher mortality and\nreadmission rates.",
            "author": [
                "Kwangho Kim",
                "Bijan A. Niknam",
                "Jos\u00e9 R. Zubizarreta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00568v1",
                "http://arxiv.org/pdf/2311.00568v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00567v2",
            "title": "A Robust Deep Learning Method with Uncertainty Estimation for the\n  Pathological Classification of Renal Cell Carcinoma based on CT Images",
            "updated": "2023-11-12T17:42:07Z",
            "published": "2023-11-01T15:07:39Z",
            "summary": "Objectives To develop and validate a deep learning-based diagnostic model\nincorporating uncertainty estimation so as to facilitate radiologists in the\npreoperative differentiation of the pathological subtypes of renal cell\ncarcinoma (RCC) based on CT images. Methods Data from 668 consecutive patients,\npathologically proven RCC, were retrospectively collected from Center 1. By\nusing five-fold cross-validation, a deep learning model incorporating\nuncertainty estimation was developed to classify RCC subtypes into clear cell\nRCC (ccRCC), papillary RCC (pRCC), and chromophobe RCC (chRCC). An external\nvalidation set of 78 patients from Center 2 further evaluated the model's\nperformance. Results In the five-fold cross-validation, the model's area under\nthe receiver operating characteristic curve (AUC) for the classification of\nccRCC, pRCC, and chRCC was 0.868 (95% CI: 0.826-0.923), 0.846 (95% CI:\n0.812-0.886), and 0.839 (95% CI: 0.802-0.88), respectively. In the external\nvalidation set, the AUCs were 0.856 (95% CI: 0.838-0.882), 0.787 (95% CI:\n0.757-0.818), and 0.793 (95% CI: 0.758-0.831) for ccRCC, pRCC, and chRCC,\nrespectively. Conclusions The developed deep learning model demonstrated robust\nperformance in predicting the pathological subtypes of RCC, while the\nincorporated uncertainty emphasized the importance of understanding model\nconfidence, which is crucial for assisting clinical decision-making for\npatients with renal tumors. Clinical relevance statement Our deep learning\napproach, integrated with uncertainty estimation, offers clinicians a dual\nadvantage: accurate RCC subtype predictions complemented by diagnostic\nconfidence references, promoting informed decision-making for patients with\nRCC.",
            "author": [
                "Ni Yao",
                "Hang Hu",
                "Kaicong Chen",
                "Chen Zhao",
                "Yuan Guo",
                "Boya Li",
                "Jiaofen Nan",
                "Yanting Li",
                "Chuang Han",
                "Fubao Zhu",
                "Weihua Zhou",
                "Li Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00567v2",
                "http://arxiv.org/pdf/2311.00567v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "physics.med-ph",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00566v1",
            "title": "CROMA: Remote Sensing Representations with Contrastive Radar-Optical\n  Masked Autoencoders",
            "updated": "2023-11-01T15:07:27Z",
            "published": "2023-11-01T15:07:27Z",
            "summary": "A vital and rapidly growing application, remote sensing offers vast yet\nsparsely labeled, spatially aligned multimodal data; this makes self-supervised\nlearning algorithms invaluable. We present CROMA: a framework that combines\ncontrastive and reconstruction self-supervised objectives to learn rich\nunimodal and multimodal representations. Our method separately encodes\nmasked-out multispectral optical and synthetic aperture radar samples --\naligned in space and time -- and performs cross-modal contrastive learning.\nAnother encoder fuses these sensors, producing joint multimodal encodings that\nare used to predict the masked patches via a lightweight decoder. We show that\nthese objectives are complementary when leveraged on spatially aligned\nmultimodal data. We also introduce X- and 2D-ALiBi, which spatially biases our\ncross- and self-attention matrices. These strategies improve representations\nand allow our models to effectively extrapolate to images up to 17.6x larger at\ntest-time. CROMA outperforms the current SoTA multispectral model, evaluated\non: four classification benchmarks -- finetuning (avg. 1.8%), linear (avg.\n2.4%) and nonlinear (avg. 1.4%) probing, kNN classification (avg. 3.5%), and\nK-means clustering (avg. 8.4%); and three segmentation benchmarks (avg. 6.4%).\nCROMA's rich, optionally multimodal representations can be widely leveraged\nacross remote sensing applications.",
            "author": [
                "Anthony Fuller",
                "Koreen Millard",
                "James R. Green"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00566v1",
                "http://arxiv.org/pdf/2311.00566v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00564v1",
            "title": "Online Student-$t$ Processes with an Overall-local Scale Structure for\n  Modelling Non-stationary Data",
            "updated": "2023-11-01T15:02:47Z",
            "published": "2023-11-01T15:02:47Z",
            "summary": "Time-dependent data often exhibit characteristics, such as non-stationarity\nand heavy-tailed errors, that would be inappropriate to model with the typical\nassumptions used in popular models. Thus, more flexible approaches are required\nto be able to accommodate such issues. To this end, we propose a Bayesian\nmixture of student-$t$ processes with an overall-local scale structure for the\ncovariance. Moreover, we use a sequential Monte Carlo (SMC) sampler in order to\nperform online inference as data arrive in real-time. We demonstrate the\nsuperiority of our proposed approach compared to typical Gaussian process-based\nmodels on real-world data sets in order to prove the necessity of using\nmixtures of student-$t$ processes.",
            "author": [
                "Taole Sha",
                "Michael Minyi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00564v1",
                "http://arxiv.org/pdf/2311.00564v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "62F15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00562v2",
            "title": "MNN: Mixed Nearest-Neighbors for Self-Supervised Learning",
            "updated": "2023-11-13T14:21:49Z",
            "published": "2023-11-01T14:59:41Z",
            "summary": "In contrastive self-supervised learning, positive samples are typically drawn\nfrom the same image but in different augmented views, resulting in a relatively\nlimited source of positive samples. An effective way to alleviate this problem\nis to incorporate the relationship between samples, which involves including\nthe top-K nearest neighbors of positive samples. However, the problem of false\nneighbors (i.e., neighbors that do not belong to the same category as the\npositive sample) is an objective but often overlooked challenge due to the\nquery of neighbor samples without supervision information. In this paper, we\npresent a simple self-supervised learning framework called Mixed\nNearest-Neighbors for Self-Supervised Learning (MNN). MNN optimizes the\ninfluence of neighbor samples on the semantics of positive samples through an\nintuitive weighting approach and image mixture operations. The results\ndemonstrate that MNN exhibits exceptional generalization performance and\ntraining efficiency on four benchmark datasets.",
            "author": [
                "Xianzhong Long",
                "Chen Peng",
                "Yun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00562v2",
                "http://arxiv.org/pdf/2311.00562v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00559v1",
            "title": "Learning to optimize by multi-gradient for multi-objective optimization",
            "updated": "2023-11-01T14:55:54Z",
            "published": "2023-11-01T14:55:54Z",
            "summary": "The development of artificial intelligence (AI) for science has led to the\nemergence of learning-based research paradigms, necessitating a compelling\nreevaluation of the design of multi-objective optimization (MOO) methods. The\nnew generation MOO methods should be rooted in automated learning rather than\nmanual design. In this paper, we introduce a new automatic learning paradigm\nfor optimizing MOO problems, and propose a multi-gradient learning to optimize\n(ML2O) method, which automatically learns a generator (or mappings) from\nmultiple gradients to update directions. As a learning-based method, ML2O\nacquires knowledge of local landscapes by leveraging information from the\ncurrent step and incorporates global experience extracted from historical\niteration trajectory data. By introducing a new guarding mechanism, we propose\na guarded multi-gradient learning to optimize (GML2O) method, and prove that\nthe iterative sequence generated by GML2O converges to a Pareto critical point.\nThe experimental results demonstrate that our learned optimizer outperforms\nhand-designed competitors on training multi-task learning (MTL) neural network.",
            "author": [
                "Linxi Yang",
                "Xinmin Yang",
                "Liping Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00559v1",
                "http://arxiv.org/pdf/2311.00559v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02101v1",
            "title": "Solving MaxSAT with Matrix Multiplication",
            "updated": "2023-11-01T14:46:46Z",
            "published": "2023-11-01T14:46:46Z",
            "summary": "We propose an incomplete algorithm for Maximum Satisfiability (MaxSAT)\nspecifically designed to run on neural network accelerators such as GPUs and\nTPUs. Given a MaxSAT problem instance in conjunctive normal form, our procedure\nconstructs a Restricted Boltzmann Machine (RBM) with an equilibrium\ndistribution wherein the probability of a Boolean assignment is exponential in\nthe number of clauses it satisfies. Block Gibbs sampling is used to\nstochastically search the space of assignments with parallel Markov chains.\nSince matrix multiplication is the main computational primitive for block Gibbs\nsampling in an RBM, our approach leads to an elegantly simple algorithm (40\nlines of JAX) well-suited for neural network accelerators. Theoretical results\nabout RBMs guarantee that the required number of visible and hidden units of\nthe RBM scale only linearly with the number of variables and constant-sized\nclauses in the MaxSAT instance, ensuring that the computational cost of a Gibbs\nstep scales reasonably with the instance size. Search throughput can be\nincreased by batching parallel chains within a single accelerator as well as by\ndistributing them across multiple accelerators. As a further enhancement, a\nheuristic based on unit propagation running on CPU is periodically applied to\nthe sampled assignments. Our approach, which we term RbmSAT, is a new design\npoint in the algorithm-hardware co-design space for MaxSAT. We present timed\nresults on a subset of problem instances from the annual MaxSAT Evaluation's\nIncomplete Unweighted Track for the years 2018 to 2021. When allotted the same\nrunning time and CPU compute budget (but no TPUs), RbmSAT outperforms other\nparticipating solvers on problems drawn from three out of the four years'\ncompetitions. Given the same running time on a TPU cluster for which RbmSAT is\nuniquely designed, it outperforms all solvers on problems drawn from all four\nyears.",
            "author": [
                "David Warde-Farley",
                "Vinod Nair",
                "Yujia Li",
                "Ivan Lobov",
                "Felix Gimeno",
                "Simon Osindero"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02101v1",
                "http://arxiv.org/pdf/2311.02101v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00553v1",
            "title": "Polynomial Chaos Surrogate Construction for Random Fields with\n  Parametric Uncertainty",
            "updated": "2023-11-01T14:41:54Z",
            "published": "2023-11-01T14:41:54Z",
            "summary": "Engineering and applied science rely on computational experiments to\nrigorously study physical systems. The mathematical models used to probe these\nsystems are highly complex, and sampling-intensive studies often require\nprohibitively many simulations for acceptable accuracy. Surrogate models\nprovide a means of circumventing the high computational expense of sampling\nsuch complex models. In particular, polynomial chaos expansions (PCEs) have\nbeen successfully used for uncertainty quantification studies of deterministic\nmodels where the dominant source of uncertainty is parametric. We discuss an\nextension to conventional PCE surrogate modeling to enable surrogate\nconstruction for stochastic computational models that have intrinsic noise in\naddition to parametric uncertainty. We develop a PCE surrogate on a joint space\nof intrinsic and parametric uncertainty, enabled by Rosenblatt transformations,\nand then extend the construction to random field data via the Karhunen-Loeve\nexpansion. We then take advantage of closed-form solutions for computing PCE\nSobol indices to perform a global sensitivity analysis of the model which\nquantifies the intrinsic noise contribution to the overall model output\nvariance. Additionally, the resulting joint PCE is generative in the sense that\nit allows generating random realizations at any input parameter setting that\nare statistically approximately equivalent to realizations from the underlying\nstochastic model. The method is demonstrated on a chemical catalysis example\nmodel.",
            "author": [
                "Joy N. Mueller",
                "Khachik Sargsyan",
                "Craig J. Daniels",
                "Habib N. Najm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00553v1",
                "http://arxiv.org/pdf/2311.00553v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML",
                "60G99, 65C20, 33C45, 62G07, 62J02"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00548v3",
            "title": "Continual atlas-based segmentation of prostate MRI",
            "updated": "2023-11-06T12:34:45Z",
            "published": "2023-11-01T14:29:46Z",
            "summary": "Continual learning (CL) methods designed for natural image classification\noften fail to reach basic quality standards for medical image segmentation.\nAtlas-based segmentation, a well-established approach in medical imaging,\nincorporates domain knowledge on the region of interest, leading to\nsemantically coherent predictions. This is especially promising for CL, as it\nallows us to leverage structural information and strike an optimal balance\nbetween model rigidity and plasticity over time. When combined with\nprivacy-preserving prototypes, this process offers the advantages of\nrehearsal-based CL without compromising patient privacy. We propose Atlas\nReplay, an atlas-based segmentation approach that uses prototypes to generate\nhigh-quality segmentation masks through image registration that maintain\nconsistency even as the training distribution changes. We explore how our\nproposed method performs compared to state-of-the-art CL methods in terms of\nknowledge transferability across seven publicly available prostate segmentation\ndatasets. Prostate segmentation plays a vital role in diagnosing prostate\ncancer, however, it poses challenges due to substantial anatomical variations,\nbenign structural differences in older age groups, and fluctuating acquisition\nparameters. Our results show that Atlas Replay is both robust and generalizes\nwell to yet-unseen domains while being able to maintain knowledge, unlike\nend-to-end segmentation methods. Our code base is available under\nhttps://github.com/MECLabTUDA/Atlas-Replay.",
            "author": [
                "Amin Ranem",
                "Camila Gonz\u00e1lez",
                "Daniel Pinto dos Santos",
                "Andreas M. Bucher",
                "Ahmed E. Othman",
                "Anirban Mukhopadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00548v3",
                "http://arxiv.org/pdf/2311.00548v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00545v1",
            "title": "Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric\n  Models and the MDL Principle",
            "updated": "2023-11-01T14:25:51Z",
            "published": "2023-11-01T14:25:51Z",
            "summary": "The Abstraction and Reasoning Corpus (ARC) is a challenging benchmark,\nintroduced to foster AI research towards human-level intelligence. It is a\ncollection of unique tasks about generating colored grids, specified by a few\nexamples only. In contrast to the transformation-based programs of existing\nwork, we introduce object-centric models that are in line with the natural\nprograms produced by humans. Our models can not only perform predictions, but\nalso provide joint descriptions for input/output pairs. The Minimum Description\nLength (MDL) principle is used to efficiently search the large model space. A\ndiverse range of tasks are solved, and the learned models are similar to the\nnatural programs. We demonstrate the generality of our approach by applying it\nto a different domain.",
            "author": [
                "S\u00e9bastien Ferr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00545v1",
                "http://arxiv.org/pdf/2311.00545v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00541v1",
            "title": "An Embedded Diachronic Sense Change Model with a Case Study from Ancient\n  Greek",
            "updated": "2023-11-01T14:20:18Z",
            "published": "2023-11-01T14:20:18Z",
            "summary": "Word meanings change over time, and word senses evolve, emerge or die out in\nthe process. For ancient languages, where the corpora are often small, sparse\nand noisy, modelling such changes accurately proves challenging, and\nquantifying uncertainty in sense-change estimates consequently becomes\nimportant. GASC and DiSC are existing generative models that have been used to\nanalyse sense change for target words from an ancient Greek text corpus, using\nunsupervised learning without the help of any pre-training. These models\nrepresent the senses of a given target word such as \"kosmos\" (meaning\ndecoration, order or world) as distributions over context words, and sense\nprevalence as a distribution over senses. The models are fitted using MCMC\nmethods to measure temporal changes in these representations. In this paper, we\nintroduce EDiSC, an embedded version of DiSC, which combines word embeddings\nwith DiSC to provide superior model performance. We show empirically that EDiSC\noffers improved predictive accuracy, ground-truth recovery and uncertainty\nquantification, as well as better sampling efficiency and scalability\nproperties with MCMC methods. We also discuss the challenges of fitting these\nmodels.",
            "author": [
                "Schyan Zafar",
                "Geoff K. Nicholls"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00541v1",
                "http://arxiv.org/pdf/2311.00541v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00537v1",
            "title": "Machine Learning Without a Processor: Emergent Learning in a Nonlinear\n  Electronic Metamaterial",
            "updated": "2023-11-01T14:16:37Z",
            "published": "2023-11-01T14:16:37Z",
            "summary": "Standard deep learning algorithms require differentiating large nonlinear\nnetworks, a process that is slow and power-hungry. Electronic learning\nmetamaterials offer potentially fast, efficient, and fault-tolerant hardware\nfor analog machine learning, but existing implementations are linear, severely\nlimiting their capabilities. These systems differ significantly from artificial\nneural networks as well as the brain, so the feasibility and utility of\nincorporating nonlinear elements have not been explored. Here we introduce a\nnonlinear learning metamaterial -- an analog electronic network made of\nself-adjusting nonlinear resistive elements based on transistors. We\ndemonstrate that the system learns tasks unachievable in linear systems,\nincluding XOR and nonlinear regression, without a computer. We find our\nnonlinear learning metamaterial reduces modes of training error in order (mean,\nslope, curvature), similar to spectral bias in artificial neural networks. The\ncircuitry is robust to damage, retrainable in seconds, and performs learned\ntasks in microseconds while dissipating only picojoules of energy across each\ntransistor. This suggests enormous potential for fast, low-power computing in\nedge systems like sensors, robotic controllers, and medical devices, as well as\nmanufacturability at scale for performing and studying emergent learning.",
            "author": [
                "Sam Dillavou",
                "Benjamin D Beyer",
                "Menachem Stern",
                "Marc Z Miskin",
                "Andrea J Liu",
                "Douglas J Durian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00537v1",
                "http://arxiv.org/pdf/2311.00537v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cs.ET",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00535v1",
            "title": "Active Noise Control Portable Device Design",
            "updated": "2023-11-01T14:13:04Z",
            "published": "2023-11-01T14:13:04Z",
            "summary": "While our world is filled with its own natural sounds that we can't resist\nenjoying, it is also chock-full of other sounds that can be irritating, this is\nnoise. Noise not only influences the working efficiency but also the human's\nhealth. The problem of reducing noise is one of great importance and great\ndifficulty. The problem has been addressed in many ways over the years. The\ncurrent methods for noise reducing mostly rely on the materials and\ntransmission medium, which are only effective to some extent for the high\nfrequency noise. However, the effective reduction noise method especially for\nlow frequency noise is very limited.\n  Here we come up with a noise reduction system consist of a sensor to detect\nthe noise in the environment. Then the noise will be sent to an electronic\ncontrol system to process the noise, which will generate a reverse phase\nfrequency signal to counteract the disturbance. Finally, the processed smaller\nnoise will be broadcasted by the speaker. Through this smart noise reduction\nsystem, even the noise with low-frequency can be eliminated.\n  The system is also integrated with sleep tracking and music player\napplications. It can also remember and store settings for the same environment,\nsense temperature, and smart control of home furniture, fire alarm, etc. This\nsmart system can transfer data easily by Wi-Fi or Bluetooth and controlled by\nits APP.\n  In this project, we will present a model of the above technology which can be\nused in various environments to prevent noise pollution and provide a solution\nto the people who have difficulties finding a peaceful and quiet environment\nfor sleep, work or study.",
            "author": [
                "kai Wu",
                "Yuanyuan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00535v1",
                "http://arxiv.org/pdf/2311.00535v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00533v1",
            "title": "The Eclipse Layout Kernel",
            "updated": "2023-11-01T14:10:45Z",
            "published": "2023-11-01T14:10:45Z",
            "summary": "The Eclipse Layout Kernel (ELK) is a collection of graph drawing algorithms\nthat supports compound graph layout and ports as explicit anchor points of\nedges. It is available as open-source library under an EPL license. Since its\nbeginning, ELK has served both as a research vehicle for graph drawing\nalgorithms, and as a practical tool for solving real-world problems. ELK and\nits transpiled JavaScript cousin elkjs are now included in numerous academic\nand commercial projects.\n  Most of the algorithms realized in ELK are described in a series of\npublications. In this paper, the technical description concentrates on the key\nfeatures of the flag-ship algorithm ELK Layered, the algorithm architecture,\nand usage. However, the main purpose of this paper is to give the broader view\nthat is typically left unpublished. Specifically, we review its history, give a\nbrief overview of technical papers, discuss lessons learned over the past\nfifteen years, and present example usages. Finally, we reflect on potential\nthreats to open-source graph drawing libraries.",
            "author": [
                "S\u00f6ren Domr\u00f6s",
                "Reinhard von Hanxleden",
                "Miro Sp\u00f6nemann",
                "Ulf R\u00fcegg",
                "Christoph Daniel Schulze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00533v1",
                "http://arxiv.org/pdf/2311.00533v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00529v1",
            "title": "A Unified Framework for the Error Analysis of Physics-Informed Neural\n  Networks",
            "updated": "2023-11-01T14:01:52Z",
            "published": "2023-11-01T14:01:52Z",
            "summary": "We prove a priori and a posteriori error estimates, also known as the\ngeneralization error in the machine learning community, for physics-informed\nneural networks (PINNs) for linear PDEs. We analyze elliptic equations in\nprimal and mixed form, elasticity, parabolic, hyperbolic and Stokes equations;\nand a PDE constrained optimization problem. For the analysis, we propose an\nabstract framework in the common language of bilinear forms, and we show that\ncoercivity and continuity lead to error estimates. Our results give insight\ninto the potential of neural networks for high dimensional PDEs and into the\nbenefit of encoding constraints directly in the ansatz class. The provided\nestimates are -- apart from the Poisson equation -- the first results of\nbest-approximation and a posteriori error-control type. Finally, utilizing\nrecent advances in PINN optimization, we present numerical examples that\nillustrate the ability of the method to achieve accurate solutions.",
            "author": [
                "Marius Zeinhofer",
                "Rami Masri",
                "Kent-Andr\u00e9 Mardal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00529v1",
                "http://arxiv.org/pdf/2311.00529v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65M12, 65M15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00737v1",
            "title": "Real-Time Magnetic Tracking and Diagnosis of COVID-19 via Machine\n  Learning",
            "updated": "2023-11-01T13:57:33Z",
            "published": "2023-11-01T13:57:33Z",
            "summary": "The COVID-19 pandemic underscored the importance of reliable, noninvasive\ndiagnostic tools for robust public health interventions. In this work, we fused\nmagnetic respiratory sensing technology (MRST) with machine learning (ML) to\ncreate a diagnostic platform for real-time tracking and diagnosis of COVID-19\nand other respiratory diseases. The MRST precisely captures breathing patterns\nthrough three specific breath testing protocols: normal breath, holding breath,\nand deep breath. We collected breath data from both COVID-19 patients and\nhealthy subjects in Vietnam using this platform, which then served to train and\nvalidate ML models. Our evaluation encompassed multiple ML algorithms,\nincluding support vector machines and deep learning models, assessing their\nability to diagnose COVID-19. Our multi-model validation methodology ensures a\nthorough comparison and grants the adaptability to select the most optimal\nmodel, striking a balance between diagnostic precision with model\ninterpretability. The findings highlight the exceptional potential of our\ndiagnostic tool in pinpointing respiratory anomalies, achieving over 90%\naccuracy. This innovative sensor technology can be seamlessly integrated into\nhealthcare settings for patient monitoring, marking a significant enhancement\nfor the healthcare infrastructure.",
            "author": [
                "Dang Nguyen",
                "Phat K. Huynh",
                "Vinh Duc An Bui",
                "Kee Young Hwang",
                "Nityanand Jain",
                "Chau Nguyen",
                "Le Huu Nhat Minh",
                "Le Van Truong",
                "Xuan Thanh Nguyen",
                "Dinh Hoang Nguyen",
                "Le Tien Dung",
                "Trung Q. Le",
                "Manh-Huong Phan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00737v1",
                "http://arxiv.org/pdf/2311.00737v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.ins-det",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00523v1",
            "title": "Learning impartial policies for sequential counterfactual explanations\n  using Deep Reinforcement Learning",
            "updated": "2023-11-01T13:50:47Z",
            "published": "2023-11-01T13:50:47Z",
            "summary": "In the field of explainable Artificial Intelligence (XAI), sequential\ncounterfactual (SCF) examples are often used to alter the decision of a trained\nclassifier by implementing a sequence of modifications to the input instance.\nAlthough certain test-time algorithms aim to optimize for each new instance\nindividually, recently Reinforcement Learning (RL) methods have been proposed\nthat seek to learn policies for discovering SCFs, thereby enhancing\nscalability. As is typical in RL, the formulation of the RL problem, including\nthe specification of state space, actions, and rewards, can often be ambiguous.\nIn this work, we identify shortcomings in existing methods that can result in\npolicies with undesired properties, such as a bias towards specific actions. We\npropose to use the output probabilities of the classifier to create a more\ninformative reward, to mitigate this effect.",
            "author": [
                "E. Panagiotou",
                "E. Ntoutsi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00523v1",
                "http://arxiv.org/pdf/2311.00523v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00519v2",
            "title": "Retrieval-Based Reconstruction For Time-series Contrastive Learning",
            "updated": "2023-12-07T15:20:18Z",
            "published": "2023-11-01T13:44:45Z",
            "summary": "The success of self-supervised contrastive learning hinges on identifying\npositive data pairs that, when pushed together in embedding space, encode\nuseful information for subsequent downstream tasks. However, in time-series,\nthis is challenging because creating positive pairs via augmentations may break\nthe original semantic meaning. We hypothesize that if we can retrieve\ninformation from one subsequence to successfully reconstruct another\nsubsequence, then they should form a positive pair. Harnessing this intuition,\nwe introduce our novel approach: REtrieval-BAsed Reconstruction (REBAR)\ncontrastive learning. First, we utilize a convolutional cross-attention\narchitecture to calculate the REBAR error between two different time-series.\nThen, through validation experiments, we show that the REBAR error is a\npredictor of mutual class membership, justifying its usage as a\npositive/negative labeler. Finally, once integrated into a contrastive learning\nframework, our REBAR method can learn an embedding that achieves\nstate-of-the-art performance on downstream tasks across various modalities.",
            "author": [
                "Maxwell A. Xu",
                "Alexander Moreno",
                "Hui Wei",
                "Benjamin M. Marlin",
                "James M. Rehg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00519v2",
                "http://arxiv.org/pdf/2311.00519v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00517v1",
            "title": "Improving Cardiovascular Disease Prediction Through Comparative Analysis\n  of Machine Learning Models: A Case Study on Myocardial Infarction",
            "updated": "2023-11-01T13:41:44Z",
            "published": "2023-11-01T13:41:44Z",
            "summary": "Cardiovascular disease remains a leading cause of mortality in the\ncontemporary world. Its association with smoking, elevated blood pressure, and\ncholesterol levels underscores the significance of these risk factors. This\nstudy addresses the challenge of predicting myocardial illness, a formidable\ntask in medical research. Accurate predictions are pivotal for refining\nhealthcare strategies. This investigation conducts a comparative analysis of\nsix distinct machine learning models: Logistic Regression, Support Vector\nMachine, Decision Tree, Bagging, XGBoost, and LightGBM. The attained outcomes\nexhibit promise, with accuracy rates as follows: Logistic Regression (81.00%),\nSupport Vector Machine (75.01%), XGBoost (92.72%), LightGBM (90.60%), Decision\nTree (82.30%), and Bagging (83.01%). Notably, XGBoost emerges as the\ntop-performing model. These findings underscore its potential to enhance\npredictive precision for coronary infarction. As the prevalence of\ncardiovascular risk factors persists, incorporating advanced machine learning\ntechniques holds the potential to refine proactive medical interventions.",
            "author": [
                "Jonayet Miah",
                "Duc M Ca",
                "Md Abu Sayed",
                "Ehsanur Rashid Lipu",
                "Fuad Mahmud",
                "S M Yasir Arafat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00517v1",
                "http://arxiv.org/pdf/2311.00517v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00513v1",
            "title": "Rule-Based Error Classification for Analyzing Differences in Frequent\n  Errors",
            "updated": "2023-11-01T13:36:20Z",
            "published": "2023-11-01T13:36:20Z",
            "summary": "Finding and fixing errors is a time-consuming task not only for novice\nprogrammers but also for expert programmers. Prior work has identified frequent\nerror patterns among various levels of programmers. However, the differences in\nthe tendencies between novices and experts have yet to be revealed. From the\nknowledge of the frequent errors in each level of programmers, instructors will\nbe able to provide helpful advice for each level of learners. In this paper, we\npropose a rule-based error classification tool to classify errors in code pairs\nconsisting of wrong and correct programs. We classify errors for 95,631 code\npairs and identify 3.47 errors on average, which are submitted by various\nlevels of programmers on an online judge system. The classified errors are used\nto analyze the differences in frequent errors between novice and expert\nprogrammers. The analyzed results show that, as for the same introductory\nproblems, errors made by novices are due to the lack of knowledge in\nprogramming, and the mistakes are considered an essential part of the learning\nprocess. On the other hand, errors made by experts are due to misunderstandings\ncaused by the carelessness of reading problems or the challenges of solving\nproblems differently than usual. The proposed tool can be used to create\nerror-labeled datasets and for further code-related educational research.",
            "author": [
                "Atsushi Shirafuji",
                "Taku Matsumoto",
                "Md Faizul Ibne Amin",
                "Yutaka Watanobe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00513v1",
                "http://arxiv.org/pdf/2311.00513v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CL",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00508v1",
            "title": "Robustness Tests for Automatic Machine Translation Metrics with\n  Adversarial Attacks",
            "updated": "2023-11-01T13:14:23Z",
            "published": "2023-11-01T13:14:23Z",
            "summary": "We investigate MT evaluation metric performance on adversarially-synthesized\ntexts, to shed light on metric robustness. We experiment with word- and\ncharacter-level attacks on three popular machine translation metrics:\nBERTScore, BLEURT, and COMET. Our human experiments validate that automatic\nmetrics tend to overpenalize adversarially-degraded translations. We also\nidentify inconsistencies in BERTScore ratings, where it judges the original\nsentence and the adversarially-degraded one as similar, while judging the\ndegraded translation as notably worse than the original with respect to the\nreference. We identify patterns of brittleness that motivate more robust metric\ndevelopment.",
            "author": [
                "Yichen Huang",
                "Timothy Baldwin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00508v1",
                "http://arxiv.org/pdf/2311.00508v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00502v2",
            "title": "Efficient LLM Inference on CPUs",
            "updated": "2023-12-07T12:16:42Z",
            "published": "2023-11-01T13:08:50Z",
            "summary": "Large language models (LLMs) have demonstrated remarkable performance and\ntremendous potential across a wide range of tasks. However, deploying these\nmodels has been challenging due to the astronomical amount of model parameters,\nwhich requires a demand for large memory capacity and high memory bandwidth. In\nthis paper, we propose an effective approach that can make the deployment of\nLLMs more efficiently. We support an automatic INT4 weight-only quantization\nflow and design a special LLM runtime with highly-optimized kernels to\naccelerate the LLM inference on CPUs. We demonstrate the general applicability\nof our approach on popular LLMs including Llama2, Llama, GPT-NeoX, and showcase\nthe extreme inference efficiency on CPUs. The code is publicly available at:\nhttps://github.com/intel/intel-extension-for-transformers.",
            "author": [
                "Haihao Shen",
                "Hanwen Chang",
                "Bo Dong",
                "Yu Luo",
                "Hengyu Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00502v2",
                "http://arxiv.org/pdf/2311.00502v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00500v1",
            "title": "Intriguing Properties of Data Attribution on Diffusion Models",
            "updated": "2023-11-01T13:00:46Z",
            "published": "2023-11-01T13:00:46Z",
            "summary": "Data attribution seeks to trace model outputs back to training data. With the\nrecent development of diffusion models, data attribution has become a desired\nmodule to properly assign valuations for high-quality or copyrighted training\nsamples, ensuring that data contributors are fairly compensated or credited.\nSeveral theoretically motivated methods have been proposed to implement data\nattribution, in an effort to improve the trade-off between computational\nscalability and effectiveness. In this work, we conduct extensive experiments\nand ablation studies on attributing diffusion models, specifically focusing on\nDDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model\nLoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive\nobservations that theoretically unjustified design choices for attribution\nempirically outperform previous baselines by a large margin, in terms of both\nlinear datamodeling score and counterfactual evaluation. Our work presents a\nsignificantly more efficient approach for attributing diffusion models, while\nthe unexpected findings suggest that at least in non-convex settings,\nconstructions guided by theoretical assumptions may lead to inferior\nattribution performance. The code is available at\nhttps://github.com/sail-sg/D-TRAK.",
            "author": [
                "Xiaosen Zheng",
                "Tianyu Pang",
                "Chao Du",
                "Jing Jiang",
                "Min Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00500v1",
                "http://arxiv.org/pdf/2311.00500v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00493v1",
            "title": "The stability of deep learning for 21cm foreground removal across\n  various sky models and frequency-dependent systematics",
            "updated": "2023-11-01T12:48:37Z",
            "published": "2023-11-01T12:48:37Z",
            "summary": "Deep learning (DL) has recently been proposed as a novel approach for 21cm\nforeground removal. Before applying DL to real observations, it is essential to\nassess its consistency with established methods, its performance across various\nsimulation models and its robustness against instrumental systematics. This\nstudy develops a commonly used U-Net and evaluates its performance for\npost-reionisation foreground removal across three distinct sky simulation\nmodels based on pure Gaussian realisations, the Lagrangian perturbation theory,\nand the Planck sky model. Stable outcomes across the models are achieved\nprovided that training and testing data align with the same model. On average,\nthe residual foreground in the U-Net reconstructed data is $\\sim$10% of the\nsignal across angular scales at the considered redshift range. Comparable\nresults are found with traditional approaches. However, blindly using a network\ntrained on one model for data from another model yields inaccurate\nreconstructions, emphasising the need for consistent training data. The study\nthen introduces frequency-dependent Gaussian beams and gain drifts to the test\ndata. The network struggles to denoise data affected by \"unexpected\"\nsystematics without prior information. However, after re-training consistently\nwith systematics-contaminated data, the network effectively restores its\nreconstruction accuracy. This highlights the importance of incorporating prior\nsystematics knowledge during training for successful denoising. Our work\nprovides critical guidelines for using DL for 21cm foreground removal, tailored\nto specific data attributes. Notably, it is the first time that DL has been\napplied to the Planck sky model being most realistic foregrounds at present.",
            "author": [
                "T. Chen",
                "M. Bianco",
                "E. Tolley",
                "M. Spinelli",
                "D. Forero-Sanchez",
                "J. P. Kneib"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00493v1",
                "http://arxiv.org/pdf/2311.00493v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00491v1",
            "title": "Bayes-enhanced Multi-view Attention Networks for Robust POI\n  Recommendation",
            "updated": "2023-11-01T12:47:38Z",
            "published": "2023-11-01T12:47:38Z",
            "summary": "POI recommendation is practically important to facilitate various\nLocation-Based Social Network services, and has attracted rising research\nattention recently. Existing works generally assume the available POI check-ins\nreported by users are the ground-truth depiction of user behaviors. However, in\nreal application scenarios, the check-in data can be rather unreliable due to\nboth subjective and objective causes including positioning error and user\nprivacy concerns, leading to significant negative impacts on the performance of\nthe POI recommendation. To this end, we investigate a novel problem of robust\nPOI recommendation by considering the uncertainty factors of the user\ncheck-ins, and proposes a Bayes-enhanced Multi-view Attention Network.\nSpecifically, we construct personal POI transition graph, the semantic-based\nPOI graph and distance-based POI graph to comprehensively model the\ndependencies among the POIs. As the personal POI transition graph is usually\nsparse and sensitive to noise, we design a Bayes-enhanced spatial dependency\nlearning module for data augmentation from the local view. A Bayesian posterior\nguided graph augmentation approach is adopted to generate a new graph with\ncollaborative signals to increase the data diversity. Then both the original\nand the augmented graphs are used for POI representation learning to counteract\nthe data uncertainty issue. Next, the POI representations of the three view\ngraphs are input into the proposed multi-view attention-based user preference\nlearning module. By incorporating the semantic and distance correlations of\nPOIs, the user preference can be effectively refined and finally robust\nrecommendation results are achieved. The results of extensive experiments show\nthat BayMAN significantly outperforms the state-of-the-art methods in POI\nrecommendation when the available check-ins are incomplete and noisy.",
            "author": [
                "Jiangnan Xia",
                "Yu Yang",
                "Senzhang Wang",
                "Hongzhi Yin",
                "Jiannong Cao",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00491v1",
                "http://arxiv.org/pdf/2311.00491v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00489v2",
            "title": "Deep Neural Networks for Automatic Speaker Recognition Do Not Learn\n  Supra-Segmental Temporal Features",
            "updated": "2023-11-02T06:07:14Z",
            "published": "2023-11-01T12:45:31Z",
            "summary": "While deep neural networks have shown impressive results in automatic speaker\nrecognition and related tasks, it is dissatisfactory how little is understood\nabout what exactly is responsible for these results. Part of the success has\nbeen attributed in prior work to their capability to model supra-segmental\ntemporal information (SST), i.e., learn rhythmic-prosodic characteristics of\nspeech in addition to spectral features. In this paper, we (i) present and\napply a novel test to quantify to what extent the performance of\nstate-of-the-art neural networks for speaker recognition can be explained by\nmodeling SST; and (ii) present several means to force respective nets to focus\nmore on SST and evaluate their merits. We find that a variety of CNN- and\nRNN-based neural network architectures for speaker recognition do not model SST\nto any sufficient degree, even when forced. The results provide a highly\nrelevant basis for impactful future research into better exploitation of the\nfull speech signal and give insights into the inner workings of such networks,\nenhancing explainability of deep learning for speech technologies.",
            "author": [
                "Daniel Neururer",
                "Volker Dellwo",
                "Thilo Stadelmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00489v2",
                "http://arxiv.org/pdf/2311.00489v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00488v1",
            "title": "Comparing Optimization Targets for Contrast-Consistent Search",
            "updated": "2023-11-01T12:42:14Z",
            "published": "2023-11-01T12:42:14Z",
            "summary": "We investigate the optimization target of Contrast-Consistent Search (CCS),\nwhich aims to recover the internal representations of truth of a large language\nmodel. We present a new loss function that we call the Midpoint-Displacement\n(MD) loss function. We demonstrate that for a certain hyper-parameter value\nthis MD loss function leads to a prober with very similar weights to CCS. We\nfurther show that this hyper-parameter is not optimal and that with a better\nhyper-parameter the MD loss function attains a higher test accuracy than CCS.",
            "author": [
                "Hugo Fry",
                "Seamus Fallows",
                "Ian Fan",
                "Jamie Wright",
                "Nandi Schoots"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00488v1",
                "http://arxiv.org/pdf/2311.00488v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00483v1",
            "title": "DEFN: Dual-Encoder Fourier Group Harmonics Network for Three-Dimensional\n  Macular Hole Reconstruction with Stochastic Retinal Defect Augmentation and\n  Dynamic Weight Composition",
            "updated": "2023-11-01T12:33:04Z",
            "published": "2023-11-01T12:33:04Z",
            "summary": "The spatial and quantitative parameters of macular holes are vital for\ndiagnosis, surgical choices, and post-op monitoring. Macular hole diagnosis and\ntreatment rely heavily on spatial and quantitative data, yet the scarcity of\nsuch data has impeded the progress of deep learning techniques for effective\nsegmentation and real-time 3D reconstruction. To address this challenge, we\nassembled the world's largest macular hole dataset, Retinal OCTfor Macular Hole\nEnhancement (ROME-3914), and a Comprehensive Archive for Retinal Segmentation\n(CARS-30k), both expertly annotated. In addition, we developed an innovative 3D\nsegmentation network, the Dual-Encoder FuGH Network (DEFN), which integrates\nthree innovative modules: Fourier Group Harmonics (FuGH), Simplified 3D Spatial\nAttention (S3DSA) and Harmonic Squeeze-and-Excitation Module (HSE). These three\nmodules synergistically filter noise, reduce computational complexity,\nemphasize detailed features, and enhance the network's representation ability.\nWe also proposed a novel data augmentation method, Stochastic Retinal Defect\nInjection (SRDI), and a network optimization strategy DynamicWeightCompose\n(DWC), to further improve the performance of DEFN. Compared with 13 baselines,\nour DEFN shows the best performance. We also offer precise 3D retinal\nreconstruction and quantitative metrics, bringing revolutionary diagnostic and\ntherapeutic decision-making tools for ophthalmologists, and is expected to\ncompletely reshape the diagnosis and treatment patterns of difficult-to-treat\nmacular degeneration. The source code is publicly available at:\nhttps://github.com/IIPL-HangzhouDianUniversity/DEFN-Pytorch.",
            "author": [
                "Xingru Huang",
                "Yihao Guo",
                "Jian Huang",
                "Zhi Li",
                "Tianyun Zhang",
                "Kunyan Cai",
                "Gaopeng Huang",
                "Wenhao Chen",
                "Zhaoyang Xu",
                "Liangqiong Qu",
                "Ji Hu",
                "Tinyu Wang",
                "Shaowei Jiang",
                "Chenggang Yan",
                "Yaoqi Sun",
                "Xin Ye",
                "Yaqi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00483v1",
                "http://arxiv.org/pdf/2311.00483v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "68, 92",
                "I.4; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00481v1",
            "title": "Fixed-Budget Best-Arm Identification in Sparse Linear Bandits",
            "updated": "2023-11-01T12:32:17Z",
            "published": "2023-11-01T12:32:17Z",
            "summary": "We study the best-arm identification problem in sparse linear bandits under\nthe fixed-budget setting. In sparse linear bandits, the unknown feature vector\n$\\theta^*$ may be of large dimension $d$, but only a few, say $s \\ll d$ of\nthese features have non-zero values. We design a two-phase algorithm, Lasso and\nOptimal-Design- (Lasso-OD) based linear best-arm identification. The first\nphase of Lasso-OD leverages the sparsity of the feature vector by applying the\nthresholded Lasso introduced by Zhou (2009), which estimates the support of\n$\\theta^*$ correctly with high probability using rewards from the selected arms\nand a judicious choice of the design matrix. The second phase of Lasso-OD\napplies the OD-LinBAI algorithm by Yang and Tan (2022) on that estimated\nsupport. We derive a non-asymptotic upper bound on the error probability of\nLasso-OD by carefully choosing hyperparameters (such as Lasso's regularization\nparameter) and balancing the error probabilities of both phases. For fixed\nsparsity $s$ and budget $T$, the exponent in the error probability of Lasso-OD\ndepends on $s$ but not on the dimension $d$, yielding a significant performance\nimprovement for sparse and high-dimensional linear bandits. Furthermore, we\nshow that Lasso-OD is almost minimax optimal in the exponent. Finally, we\nprovide numerical examples to demonstrate the significant performance\nimprovement over the existing algorithms for non-sparse linear bandits such as\nOD-LinBAI, BayesGap, Peace, LinearExploration, and GSE.",
            "author": [
                "Recep Can Yavas",
                "Vincent Y. F. Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00481v1",
                "http://arxiv.org/pdf/2311.00481v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00476v1",
            "title": "Group Distributionally Robust Knowledge Distillation",
            "updated": "2023-11-01T12:25:02Z",
            "published": "2023-11-01T12:25:02Z",
            "summary": "Knowledge distillation enables fast and effective transfer of features\nlearned from a bigger model to a smaller one. However, distillation objectives\nare susceptible to sub-population shifts, a common scenario in medical imaging\nanalysis which refers to groups/domains of data that are underrepresented in\nthe training set. For instance, training models on health data acquired from\nmultiple scanners or hospitals can yield subpar performance for minority\ngroups. In this paper, inspired by distributionally robust optimization (DRO)\ntechniques, we address this shortcoming by proposing a group-aware distillation\nloss. During optimization, a set of weights is updated based on the per-group\nlosses at a given iteration. This way, our method can dynamically focus on\ngroups that have low performance during training. We empirically validate our\nmethod, GroupDistil on two benchmark datasets (natural images and cardiac MRIs)\nand show consistent improvement in terms of worst-group accuracy.",
            "author": [
                "Konstantinos Vilouras",
                "Xiao Liu",
                "Pedro Sanchez",
                "Alison Q. O'Neil",
                "Sotirios A. Tsaftaris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00476v1",
                "http://arxiv.org/pdf/2311.00476v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00475v1",
            "title": "Style Locality for Controllable Generation with kNN Language Models",
            "updated": "2023-11-01T12:21:53Z",
            "published": "2023-11-01T12:21:53Z",
            "summary": "Recent language models have been improved by the addition of external memory.\nNearest neighbor language models retrieve similar contexts to assist in word\nprediction. The addition of locality levels allows a model to learn how to\nweight neighbors based on their relative location to the current text in source\ndocuments, and have been shown to further improve model performance. Nearest\nneighbor models have been explored for controllable generation but have not\nexamined the use of locality levels. We present a novel approach for this\npurpose and evaluate it using automatic and human evaluation on politeness,\nformality, supportiveness, and toxicity textual data. We find that our model is\nsuccessfully able to control style and provides a better fluency-style\ntrade-off than previous work.",
            "author": [
                "Gilles Nawezi",
                "Lucie Flek",
                "Charles Welch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00475v1",
                "http://arxiv.org/pdf/2311.00475v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00474v2",
            "title": "Diffusion models for probabilistic programming",
            "updated": "2023-11-21T20:16:57Z",
            "published": "2023-11-01T12:17:05Z",
            "summary": "We propose Diffusion Model Variational Inference (DMVI), a novel method for\nautomated approximate inference in probabilistic programming languages (PPLs).\nDMVI utilizes diffusion models as variational approximations to the true\nposterior distribution by deriving a novel bound to the marginal likelihood\nobjective used in Bayesian modelling. DMVI is easy to implement, allows\nhassle-free inference in PPLs without the drawbacks of, e.g., variational\ninference using normalizing flows, and does not make any constraints on the\nunderlying neural network model. We evaluate DMVI on a set of common Bayesian\nmodels and show that its posterior inferences are in general more accurate than\nthose of contemporary methods used in PPLs while having a similar computational\ncost and requiring less manual tuning.",
            "author": [
                "Simon Dirmeier",
                "Fernando Perez-Cruz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00474v2",
                "http://arxiv.org/pdf/2311.00474v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00469v1",
            "title": "Dual Conditioned Diffusion Models for Out-Of-Distribution Detection:\n  Application to Fetal Ultrasound Videos",
            "updated": "2023-11-01T12:10:55Z",
            "published": "2023-11-01T12:10:55Z",
            "summary": "Out-of-distribution (OOD) detection is essential to improve the reliability\nof machine learning models by detecting samples that do not belong to the\ntraining distribution. Detecting OOD samples effectively in certain tasks can\npose a challenge because of the substantial heterogeneity within the\nin-distribution (ID), and the high structural similarity between ID and OOD\nclasses. For instance, when detecting heart views in fetal ultrasound videos\nthere is a high structural similarity between the heart and other anatomies\nsuch as the abdomen, and large in-distribution variance as a heart has 5\ndistinct views and structural variations within each view. To detect OOD\nsamples in this context, the resulting model should generalise to the\nintra-anatomy variations while rejecting similar OOD samples. In this paper, we\nintroduce dual-conditioned diffusion models (DCDM) where we condition the model\non in-distribution class information and latent features of the input image for\nreconstruction-based OOD detection. This constrains the generative manifold of\nthe model to generate images structurally and semantically similar to those\nwithin the in-distribution. The proposed model outperforms reference methods\nwith a 12% improvement in accuracy, 22% higher precision, and an 8% better F1\nscore.",
            "author": [
                "Divyanshu Mishra",
                "He Zhao",
                "Pramit Saha",
                "Aris T. Papageorghiou",
                "J. Alison Noble"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00469v1",
                "http://arxiv.org/pdf/2311.00469v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00735v2",
            "title": "PET Tracer Conversion among Brain PET via Variable Augmented Invertible\n  Network",
            "updated": "2023-11-15T07:28:10Z",
            "published": "2023-11-01T12:04:33Z",
            "summary": "Positron emission tomography (PET) serves as an essential tool for diagnosis\nof encephalopathy and brain science research. However, it suffers from the\nlimited choice of tracers. Nowadays, with the wide application of PET imaging\nin neuropsychiatric treatment, 6-18F-fluoro-3, 4-dihydroxy-L-phenylalanine\n(DOPA) has been found to be more effective than 18F-labeled\nfluorine-2-deoxyglucose (FDG) in the field. Nevertheless, due to the complexity\nof its preparation and other limitations, DOPA is far less widely used than\nFDG. To address this issue, a tracer conversion invertible neural network\n(TC-INN) for image projection is developed to map FDG images to DOPA images\nthrough deep learning. More diagnostic information is obtained by generating\nPET images from FDG to DOPA. Specifically, the proposed TC-INN consists of two\nseparate phases, one for training traceable data, the other for rebuilding new\ndata. The reference DOPA PET image is used as a learning target for the\ncorresponding network during the training process of tracer conversion.\nMeanwhile, the invertible network iteratively estimates the resultant DOPA PET\ndata and compares it to the reference DOPA PET data. Notably, the reversible\nmodel employs variable enhancement technique to achieve better power\ngeneration. Moreover, image registration needs to be performed before training\ndue to the angular deviation of the acquired FDG and DOPA data information.\nExperimental results exhibited excellent generation capability in mapping\nbetween FDG and DOPA, suggesting that PET tracer conversion has great potential\nin the case of limited tracer applications.",
            "author": [
                "Bohui Shen",
                "Wei Zhang",
                "Xubiao Liu",
                "Pengfei Yu",
                "Shirui Jiang",
                "Xinchong Shi",
                "Xiangsong Zhang",
                "Xiaoyu Zhou",
                "Weirui Zhang",
                "Bingxuan Li",
                "Qiegen Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00735v2",
                "http://arxiv.org/pdf/2311.00735v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "68T01"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00465v1",
            "title": "Asynchronous SGD on Graphs: a Unified Framework for Asynchronous\n  Decentralized and Federated Optimization",
            "updated": "2023-11-01T11:58:16Z",
            "published": "2023-11-01T11:58:16Z",
            "summary": "Decentralized and asynchronous communications are two popular techniques to\nspeedup communication complexity of distributed machine learning, by\nrespectively removing the dependency over a central orchestrator and the need\nfor synchronization. Yet, combining these two techniques together still remains\na challenge. In this paper, we take a step in this direction and introduce\nAsynchronous SGD on Graphs (AGRAF SGD) -- a general algorithmic framework that\ncovers asynchronous versions of many popular algorithms including SGD,\nDecentralized SGD, Local SGD, FedBuff, thanks to its relaxed communication and\ncomputation assumptions. We provide rates of convergence under much milder\nassumptions than previous decentralized asynchronous works, while still\nrecovering or even improving over the best know results for all the algorithms\ncovered.",
            "author": [
                "Mathieu Even",
                "Anastasia Koloskova",
                "Laurent Massouli\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00465v1",
                "http://arxiv.org/pdf/2311.00465v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00463v1",
            "title": "Robust and Conjugate Gaussian Process Regression",
            "updated": "2023-11-01T11:57:43Z",
            "published": "2023-11-01T11:57:43Z",
            "summary": "To enable closed form conditioning, a common assumption in Gaussian process\n(GP) regression is independent and identically distributed Gaussian observation\nnoise. This strong and simplistic assumption is often violated in practice,\nwhich leads to unreliable inferences and uncertainty quantification.\nUnfortunately, existing methods for robustifying GPs break closed-form\nconditioning, which makes them less attractive to practitioners and\nsignificantly more computationally expensive. In this paper, we demonstrate how\nto perform provably robust and conjugate Gaussian process (RCGP) regression at\nvirtually no additional cost using generalised Bayesian inference. RCGP is\nparticularly versatile as it enables exact conjugate closed form updates in all\nsettings where standard GPs admit them. To demonstrate its strong empirical\nperformance, we deploy RCGP for problems ranging from Bayesian optimisation to\nsparse variational Gaussian processes.",
            "author": [
                "Matias Altamirano",
                "Fran\u00e7ois-Xavier Briol",
                "Jeremias Knoblauch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00463v1",
                "http://arxiv.org/pdf/2311.00463v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00460v1",
            "title": "Optimal Budgeted Rejection Sampling for Generative Models",
            "updated": "2023-11-01T11:52:41Z",
            "published": "2023-11-01T11:52:41Z",
            "summary": "Rejection sampling methods have recently been proposed to improve the\nperformance of discriminator-based generative models. However, these methods\nare only optimal under an unlimited sampling budget, and are usually applied to\na generator trained independently of the rejection procedure. We first propose\nan Optimal Budgeted Rejection Sampling (OBRS) scheme that is provably optimal\nwith respect to \\textit{any} $f$-divergence between the true distribution and\nthe post-rejection distribution, for a given sampling budget. Second, we\npropose an end-to-end method that incorporates the sampling scheme into the\ntraining procedure to further enhance the model's overall performance. Through\nexperiments and supporting theory, we show that the proposed methods are\neffective in significantly improving the quality and diversity of the samples.",
            "author": [
                "Alexandre Verine",
                "Muni Sreenivas Pydi",
                "Benjamin Negrevergne",
                "Yann Chevaleyre"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00460v1",
                "http://arxiv.org/pdf/2311.00460v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00457v1",
            "title": "Single-view 3D Scene Reconstruction with High-fidelity Shape and Texture",
            "updated": "2023-11-01T11:46:15Z",
            "published": "2023-11-01T11:46:15Z",
            "summary": "Reconstructing detailed 3D scenes from single-view images remains a\nchallenging task due to limitations in existing approaches, which primarily\nfocus on geometric shape recovery, overlooking object appearances and fine\nshape details. To address these challenges, we propose a novel framework for\nsimultaneous high-fidelity recovery of object shapes and textures from\nsingle-view images. Our approach utilizes the proposed Single-view neural\nimplicit Shape and Radiance field (SSR) representations to leverage both\nexplicit 3D shape supervision and volume rendering of color, depth, and surface\nnormal images. To overcome shape-appearance ambiguity under partial\nobservations, we introduce a two-stage learning curriculum incorporating both\n3D and 2D supervisions. A distinctive feature of our framework is its ability\nto generate fine-grained textured meshes while seamlessly integrating rendering\ncapabilities into the single-view 3D reconstruction model. This integration\nenables not only improved textured 3D object reconstruction by 27.7% and 11.6%\non the 3D-FRONT and Pix3D datasets, respectively, but also supports the\nrendering of images from novel viewpoints. Beyond individual objects, our\napproach facilitates composing object-level representations into flexible scene\nrepresentations, thereby enabling applications such as holistic scene\nunderstanding and 3D scene editing. We conduct extensive experiments to\ndemonstrate the effectiveness of our method.",
            "author": [
                "Yixin Chen",
                "Junfeng Ni",
                "Nan Jiang",
                "Yaowei Zhang",
                "Yixin Zhu",
                "Siyuan Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00457v1",
                "http://arxiv.org/pdf/2311.00457v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00455v1",
            "title": "Progressive Recurrent Network for Shadow Removal",
            "updated": "2023-11-01T11:42:45Z",
            "published": "2023-11-01T11:42:45Z",
            "summary": "Single-image shadow removal is a significant task that is still unresolved.\nMost existing deep learning-based approaches attempt to remove the shadow\ndirectly, which can not deal with the shadow well. To handle this issue, we\nconsider removing the shadow in a coarse-to-fine fashion and propose a simple\nbut effective Progressive Recurrent Network (PRNet). The network aims to remove\nthe shadow progressively, enabing us to flexibly adjust the number of\niterations to strike a balance between performance and time. Our network\ncomprises two parts: shadow feature extraction and progressive shadow removal.\nSpecifically, the first part is a shallow ResNet which constructs the\nrepresentations of the input shadow image on its original size, preventing the\nloss of high-frequency details caused by the downsampling operation. The second\npart has two critical components: the re-integration module and the update\nmodule. The proposed re-integration module can fully use the outputs of the\nprevious iteration, providing input for the update module for further shadow\nremoval. In this way, the proposed PRNet makes the whole process more concise\nand only uses 29% network parameters than the best published method. Extensive\nexperiments on the three benchmarks, ISTD, ISTD+, and SRD, demonstrate that our\nmethod can effectively remove shadows and achieve superior performance.",
            "author": [
                "Yonghui Wang",
                "Wengang Zhou",
                "Hao Feng",
                "Li Li",
                "Houqiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00455v1",
                "http://arxiv.org/pdf/2311.00455v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00454v1",
            "title": "Nucleation patterns of polymer crystals analyzed by machine learning\n  models",
            "updated": "2023-11-01T11:40:01Z",
            "published": "2023-11-01T11:40:01Z",
            "summary": "We use machine learning algorithms to detect the crystalline phase in\nundercooled melts in molecular dynamics simulations. Our classification method\nis based on local conformation and environmental fingerprints of individual\nmonomers. In particular, we employ self-supervised auto-encoders to compress\nthe fingerprint information and a Gaussian mixture model to distinguish ordered\nstates from disordered ones. The resulting identification of crystalline\nmonomers agrees to a large extent with human-defined classifiers such as the\nstem-length-based classification scheme as developed in our previous work [C.\nLuo and J.-U. Sommer, Macromolecules 44 (2011), 1523], but does not require any\nforeknowledge about the structure of semi-crystalline polymers. Because of its\nlocal sensitivity, the method allows the resolution of detailed time patterns\nof crystalline order before an apparent signature of the transition is visible\nin thermodynamic properties such as for the specific volume. At a\npre-transition point, we observe the highest crystallization efficiency using\nthe fraction of monomers being conserved in the crystalline phase as compared\nto the number of monomers joining that phase.",
            "author": [
                "Atmika Bhardwaj",
                "Jens-Uwe Sommer",
                "Marco Werner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00454v1",
                "http://arxiv.org/pdf/2311.00454v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00452v1",
            "title": "Hessian Eigenvectors and Principal Component Analysis of Neural Network\n  Weight Matrices",
            "updated": "2023-11-01T11:38:31Z",
            "published": "2023-11-01T11:38:31Z",
            "summary": "This study delves into the intricate dynamics of trained deep neural networks\nand their relationships with network parameters. Trained networks predominantly\ncontinue training in a single direction, known as the drift mode. This drift\nmode can be explained by the quadratic potential model of the loss function,\nsuggesting a slow exponential decay towards the potential minima. We unveil a\ncorrelation between Hessian eigenvectors and network weights. This\nrelationship, hinging on the magnitude of eigenvalues, allows us to discern\nparameter directions within the network. Notably, the significance of these\ndirections relies on two defining attributes: the curvature of their potential\nwells (indicated by the magnitude of Hessian eigenvalues) and their alignment\nwith the weight vectors. Our exploration extends to the decomposition of weight\nmatrices through singular value decomposition. This approach proves practical\nin identifying critical directions within the Hessian, considering both their\nmagnitude and curvature. Furthermore, our examination showcases the\napplicability of principal component analysis in approximating the Hessian,\nwith update parameters emerging as a superior choice over weights for this\npurpose. Remarkably, our findings unveil a similarity between the largest\nHessian eigenvalues of individual layers and the entire network. Notably,\nhigher eigenvalues are concentrated more in deeper layers. Leveraging these\ninsights, we venture into addressing catastrophic forgetting, a challenge of\nneural networks when learning new tasks while retaining knowledge from previous\nones. By applying our discoveries, we formulate an effective strategy to\nmitigate catastrophic forgetting, offering a possible solution that can be\napplied to networks of varying scales, including larger architectures.",
            "author": [
                "David Haink"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00452v1",
                "http://arxiv.org/pdf/2311.00452v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00447v3",
            "title": "On the Opportunities of Green Computing: A Survey",
            "updated": "2023-11-09T03:08:34Z",
            "published": "2023-11-01T11:16:41Z",
            "summary": "Artificial Intelligence (AI) has achieved significant advancements in\ntechnology and research with the development over several decades, and is\nwidely used in many areas including computing vision, natural language\nprocessing, time-series analysis, speech synthesis, etc. During the age of deep\nlearning, especially with the arise of Large Language Models, a large majority\nof researchers' attention is paid on pursuing new state-of-the-art (SOTA)\nresults, resulting in ever increasing of model size and computational\ncomplexity. The needs for high computing power brings higher carbon emission\nand undermines research fairness by preventing small or medium-sized research\ninstitutions and companies with limited funding in participating in research.\nTo tackle the challenges of computing resources and environmental impact of AI,\nGreen Computing has become a hot research topic. In this survey, we give a\nsystematic overview of the technologies used in Green Computing. We propose the\nframework of Green Computing and devide it into four key components: (1)\nMeasures of Greenness, (2) Energy-Efficient AI, (3) Energy-Efficient Computing\nSystems and (4) AI Use Cases for Sustainability. For each components, we\ndiscuss the research progress made and the commonly used techniques to optimize\nthe AI efficiency. We conclude that this new research direction has the\npotential to address the conflicts between resource constraints and AI\ndevelopment. We encourage more researchers to put attention on this direction\nand make AI more environmental friendly.",
            "author": [
                "You Zhou",
                "Xiujing Lin",
                "Xiang Zhang",
                "Maolin Wang",
                "Gangwei Jiang",
                "Huakang Lu",
                "Yupeng Wu",
                "Kai Zhang",
                "Zhe Yang",
                "Kehang Wang",
                "Yongduo Sui",
                "Fengwei Jia",
                "Zuoli Tang",
                "Yao Zhao",
                "Hongxuan Zhang",
                "Tiannuo Yang",
                "Weibo Chen",
                "Yunong Mao",
                "Yi Li",
                "De Bao",
                "Yu Li",
                "Hongrui Liao",
                "Ting Liu",
                "Jingwen Liu",
                "Jinchi Guo",
                "Xiangyu Zhao",
                "Ying WEI",
                "Hong Qian",
                "Qi Liu",
                "Xiang Wang",
                "Wai Kin",
                "Chan",
                "Chenliang Li",
                "Yusen Li",
                "Shiyu Yang",
                "Jining Yan",
                "Chao Mou",
                "Shuai Han",
                "Wuxia Jin",
                "Guannan Zhang",
                "Xiaodong Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00447v3",
                "http://arxiv.org/pdf/2311.00447v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00445v1",
            "title": "A Systematic Comparison of Syllogistic Reasoning in Humans and Language\n  Models",
            "updated": "2023-11-01T11:13:06Z",
            "published": "2023-11-01T11:13:06Z",
            "summary": "A central component of rational behavior is logical inference: the process of\ndetermining which conclusions follow from a set of premises. Psychologists have\ndocumented several ways in which humans' inferences deviate from the rules of\nlogic. Do language models, which are trained on text generated by humans,\nreplicate these biases, or are they able to overcome them? Focusing on the case\nof syllogisms -- inferences from two simple premises, which have been studied\nextensively in psychology -- we show that larger models are more logical than\nsmaller ones, and also more logical than humans. At the same time, even the\nlargest models make systematic errors, some of which mirror human reasoning\nbiases such as ordering effects and logical fallacies. Overall, we find that\nlanguage models mimic the human biases included in their training data, but are\nable to overcome them in some cases.",
            "author": [
                "Tiwalayo Eisape",
                "MH Tessler",
                "Ishita Dasgupta",
                "Fei Sha",
                "Sjoerd van Steenkiste",
                "Tal Linzen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00445v1",
                "http://arxiv.org/pdf/2311.00445v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00444v1",
            "title": "Form follows Function: Text-to-Text Conditional Graph Generation based\n  on Functional Requirements",
            "updated": "2023-11-01T11:12:02Z",
            "published": "2023-11-01T11:12:02Z",
            "summary": "This work focuses on the novel problem setting of generating graphs\nconditioned on a description of the graph's functional requirements in a\ndownstream task. We pose the problem as a text-to-text generation problem and\nfocus on the approach of fine-tuning a pretrained large language model (LLM) to\ngenerate graphs. We propose an inductive bias which incorporates information\nabout the structure of the graph into the LLM's generation process by\nincorporating message passing layers into an LLM's architecture. To evaluate\nour proposed method, we design a novel set of experiments using publicly\navailable and widely studied molecule and knowledge graph data sets. Results\nsuggest our proposed approach generates graphs which more closely meet the\nrequested functional requirements, outperforming baselines developed on similar\ntasks by a statistically significant margin.",
            "author": [
                "Peter A. Zachares",
                "Vahan Hovhannisyan",
                "Alan Mosca",
                "Yarin Gal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00444v1",
                "http://arxiv.org/pdf/2311.00444v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00441v1",
            "title": "Improving Robustness for Vision Transformer with a Simple Dynamic\n  Scanning Augmentation",
            "updated": "2023-11-01T11:10:01Z",
            "published": "2023-11-01T11:10:01Z",
            "summary": "Vision Transformer (ViT) has demonstrated promising performance in computer\nvision tasks, comparable to state-of-the-art neural networks. Yet, this new\ntype of deep neural network architecture is vulnerable to adversarial attacks\nlimiting its capabilities in terms of robustness. This article presents a novel\ncontribution aimed at further improving the accuracy and robustness of ViT,\nparticularly in the face of adversarial attacks. We propose an augmentation\ntechnique called `Dynamic Scanning Augmentation' that leverages dynamic input\nsequences to adaptively focus on different patches, thereby maintaining\nperformance and robustness. Our detailed investigations reveal that this\nadaptability to the input sequence induces significant changes in the attention\nmechanism of ViT, even for the same image. We introduce four variations of\nDynamic Scanning Augmentation, outperforming ViT in terms of both robustness to\nadversarial attacks and accuracy against natural images, with one variant\nshowing comparable results. By integrating our augmentation technique, we\nobserve a substantial increase in ViT's robustness, improving it from $17\\%$ to\n$92\\%$ measured across different types of adversarial attacks. These findings,\ntogether with other comprehensive tests, indicate that Dynamic Scanning\nAugmentation enhances accuracy and robustness by promoting a more adaptive type\nof attention. In conclusion, this work contributes to the ongoing research on\nVision Transformers by introducing Dynamic Scanning Augmentation as a technique\nfor improving the accuracy and robustness of ViT. The observed results\nhighlight the potential of this approach in advancing computer vision tasks and\nmerit further exploration in future studies.",
            "author": [
                "Shashank Kotyan",
                "Danilo Vasconcellos Vargas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00441v1",
                "http://arxiv.org/pdf/2311.00441v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00429v2",
            "title": "Crop Disease Classification using Support Vector Machines with Green\n  Chromatic Coordinate (GCC) and Attention based feature extraction for IoT\n  based Smart Agricultural Applications",
            "updated": "2023-11-06T09:58:25Z",
            "published": "2023-11-01T10:44:49Z",
            "summary": "Crops hold paramount significance as they serve as the primary provider of\nenergy, nutrition, and medicinal benefits for the human population. Plant\ndiseases, however, can negatively affect leaves during agricultural\ncultivation, resulting in significant losses in crop output and economic value.\nTherefore, it is crucial for farmers to identify crop diseases. However, this\nmethod frequently necessitates hard work, a lot of planning, and in-depth\nfamiliarity with plant pathogens. Given these numerous obstacles, it is\nessential to provide solutions that can easily interface with mobile and IoT\ndevices so that our farmers can guarantee the best possible crop development.\nVarious machine learning (ML) as well as deep learning (DL) algorithms have\nbeen created & studied for the identification of plant disease detection,\nyielding substantial and promising results. This article presents a novel\nclassification method that builds on prior work by utilising attention-based\nfeature extraction, RGB channel-based chromatic analysis, Support Vector\nMachines (SVM) for improved performance, and the ability to integrate with\nmobile applications and IoT devices after quantization of information. Several\ndisease classification algorithms were compared with the suggested model, and\nit was discovered that, in terms of accuracy, Vision Transformer-based feature\nextraction and additional Green Chromatic Coordinate feature with SVM\nclassification achieved an accuracy of (GCCViT-SVM) - 99.69%, whereas after\nquantization for IoT device integration achieved an accuracy of - 97.41% while\nalmost reducing 4x in size. Our findings have profound implications because\nthey have the potential to transform how farmers identify crop illnesses with\nprecise and fast information, thereby preserving agricultural output and\nensuring food security.",
            "author": [
                "Shashwat Jha",
                "Vishvaditya Luhach",
                "Gauri Shanker Gupta",
                "Beependra Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00429v2",
                "http://arxiv.org/pdf/2311.00429v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00428v1",
            "title": "NEO-KD: Knowledge-Distillation-Based Adversarial Training for Robust\n  Multi-Exit Neural Networks",
            "updated": "2023-11-01T10:44:05Z",
            "published": "2023-11-01T10:44:05Z",
            "summary": "While multi-exit neural networks are regarded as a promising solution for\nmaking efficient inference via early exits, combating adversarial attacks\nremains a challenging problem. In multi-exit networks, due to the high\ndependency among different submodels, an adversarial example targeting a\nspecific exit not only degrades the performance of the target exit but also\nreduces the performance of all other exits concurrently. This makes multi-exit\nnetworks highly vulnerable to simple adversarial attacks. In this paper, we\npropose NEO-KD, a knowledge-distillation-based adversarial training strategy\nthat tackles this fundamental challenge based on two key contributions. NEO-KD\nfirst resorts to neighbor knowledge distillation to guide the output of the\nadversarial examples to tend to the ensemble outputs of neighbor exits of clean\ndata. NEO-KD also employs exit-wise orthogonal knowledge distillation for\nreducing adversarial transferability across different submodels. The result is\na significantly improved robustness against adversarial attacks. Experimental\nresults on various datasets/models show that our method achieves the best\nadversarial accuracy with reduced computation budgets, compared to the\nbaselines relying on existing adversarial training or knowledge distillation\ntechniques for multi-exit networks.",
            "author": [
                "Seokil Ham",
                "Jungwuk Park",
                "Dong-Jun Han",
                "Jaekyun Moon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00428v1",
                "http://arxiv.org/pdf/2311.00428v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00426v1",
            "title": "Enhanced Generalization through Prioritization and Diversity in\n  Self-Imitation Reinforcement Learning over Procedural Environments with\n  Sparse Rewards",
            "updated": "2023-11-01T10:40:46Z",
            "published": "2023-11-01T10:40:46Z",
            "summary": "Exploration poses a fundamental challenge in Reinforcement Learning (RL) with\nsparse rewards, limiting an agent's ability to learn optimal decision-making\ndue to a lack of informative feedback signals. Self-Imitation Learning\n(self-IL) has emerged as a promising approach for exploration, leveraging a\nreplay buffer to store and reproduce successful behaviors. However, traditional\nself-IL methods, which rely on high-return transitions and assume singleton\nenvironments, face challenges in generalization, especially in\nprocedurally-generated (PCG) environments. Therefore, new self-IL methods have\nbeen proposed to rank which experiences to persist, but they replay transitions\nuniformly regardless of their significance, and do not address the diversity of\nthe stored demonstrations. In this work, we propose tailored self-IL sampling\nstrategies by prioritizing transitions in different ways and extending\nprioritization techniques to PCG environments. We also address diversity loss\nthrough modifications to counteract the impact of generalization requirements\nand bias introduced by prioritization techniques. Our experimental analysis,\nconducted over three PCG sparse reward environments, including MiniGrid and\nProcGen, highlights the benefits of our proposed modifications, achieving a new\nstate-of-the-art performance in the MiniGrid-MultiRoom-N12-S10 environment.",
            "author": [
                "Alain Andres",
                "Daochen Zha",
                "Javier Del Ser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00426v1",
                "http://arxiv.org/pdf/2311.00426v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00416v1",
            "title": "Efficient Human-AI Coordination via Preparatory Language-based\n  Convention",
            "updated": "2023-11-01T10:18:23Z",
            "published": "2023-11-01T10:18:23Z",
            "summary": "Developing intelligent agents capable of seamless coordination with humans is\na critical step towards achieving artificial general intelligence. Existing\nmethods for human-AI coordination typically train an agent to coordinate with a\ndiverse set of policies or with human models fitted from real human data.\nHowever, the massively diverse styles of human behavior present obstacles for\nAI systems with constrained capacity, while high quality human data may not be\nreadily available in real-world scenarios. In this study, we observe that prior\nto coordination, humans engage in communication to establish conventions that\nspecify individual roles and actions, making their coordination proceed in an\norderly manner. Building upon this observation, we propose employing the large\nlanguage model (LLM) to develop an action plan (or equivalently, a convention)\nthat effectively guides both human and AI. By inputting task requirements,\nhuman preferences, the number of agents, and other pertinent information into\nthe LLM, it can generate a comprehensive convention that facilitates a clear\nunderstanding of tasks and responsibilities for all parties involved.\nFurthermore, we demonstrate that decomposing the convention formulation problem\ninto sub-problems with multiple new sessions being sequentially employed and\nhuman feedback, will yield a more efficient coordination convention.\nExperimental evaluations conducted in the Overcooked-AI environment, utilizing\na human proxy model, highlight the superior performance of our proposed method\ncompared to existing learning-based approaches. When coordinating with real\nhumans, our method achieves better alignment with human preferences and an\naverage performance improvement of 15% compared to the state-of-the-art.",
            "author": [
                "Cong Guan",
                "Lichao Zhang",
                "Chunpeng Fan",
                "Yichen Li",
                "Feng Chen",
                "Lihe Li",
                "Yunjia Tian",
                "Lei Yuan",
                "Yang Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00416v1",
                "http://arxiv.org/pdf/2311.00416v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00412v1",
            "title": "Feature-oriented Deep Learning Framework for Pulmonary Cone-beam CT\n  (CBCT) Enhancement with Multi-task Customized Perceptual Loss",
            "updated": "2023-11-01T10:09:01Z",
            "published": "2023-11-01T10:09:01Z",
            "summary": "Cone-beam computed tomography (CBCT) is routinely collected during\nimage-guided radiation therapy (IGRT) to provide updated patient anatomy\ninformation for cancer treatments. However, CBCT images often suffer from\nstreaking artifacts and noise caused by under-rate sampling projections and\nlow-dose exposure, resulting in low clarity and information loss. While recent\ndeep learning-based CBCT enhancement methods have shown promising results in\nsuppressing artifacts, they have limited performance on preserving anatomical\ndetails since conventional pixel-to-pixel loss functions are incapable of\ndescribing detailed anatomy. To address this issue, we propose a novel\nfeature-oriented deep learning framework that translates low-quality CBCT\nimages into high-quality CT-like imaging via a multi-task customized\nfeature-to-feature perceptual loss function. The framework comprises two main\ncomponents: a multi-task learning feature-selection network(MTFS-Net) for\ncustomizing the perceptual loss function; and a CBCT-to-CT translation network\nguided by feature-to-feature perceptual loss, which uses advanced generative\nmodels such as U-Net, GAN and CycleGAN. Our experiments showed that the\nproposed framework can generate synthesized CT (sCT) images for the lung that\nachieved a high similarity to CT images, with an average SSIM index of 0.9869\nand an average PSNR index of 39.9621. The sCT images also achieved visually\npleasing performance with effective artifacts suppression, noise reduction, and\ndistinctive anatomical details preservation. Our experiment results indicate\nthat the proposed framework outperforms the state-of-the-art models for\npulmonary CBCT enhancement. This framework holds great promise for generating\nhigh-quality anatomical imaging from CBCT that is suitable for various clinical\napplications.",
            "author": [
                "Jiarui Zhu",
                "Werxing Chen",
                "Hongfei Sun",
                "Shaohua Zhi",
                "Jing Qin",
                "Jing Cai",
                "Ge Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00412v1",
                "http://arxiv.org/pdf/2311.00412v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00397v2",
            "title": "Towards Omni-supervised Referring Expression Segmentation",
            "updated": "2023-11-27T09:02:06Z",
            "published": "2023-11-01T09:46:59Z",
            "summary": "Referring Expression Segmentation (RES) is an emerging task in computer\nvision, which segments the target instances in images based on text\ndescriptions. However, its development is plagued by the expensive segmentation\nlabels. To address this issue, we propose a new learning task for RES called\nOmni-supervised Referring Expression Segmentation (Omni-RES), which aims to\nmake full use of unlabeled, fully labeled and weakly labeled data, e.g.,\nreferring points or grounding boxes, for efficient RES training. To accomplish\nthis task, we also propose a novel yet strong baseline method for Omni-RES\nbased on the recently popular teacher-student learning, where the weak labels\nare not directly transformed into supervision signals but used as a yardstick\nto select and refine high-quality pseudo-masks for teacher-student learning. To\nvalidate the proposed Omni-RES method, we apply it to a set of state-of-the-art\nRES models and conduct extensive experiments on a bunch of RES datasets. The\nexperimental results yield the obvious merits of Omni-RES than the\nfully-supervised and semi-supervised training schemes. For instance, with only\n10% fully labeled data, Omni-RES can help the base model achieve 100% fully\nsupervised performance, and it also outperform the semi-supervised alternative\nby a large margin, e.g., +14.93% on RefCOCO and +14.95% on RefCOCO+,\nrespectively. More importantly, Omni-RES also enable the use of large-scale\nvision-langauges like Visual Genome to facilitate low-cost RES training, and\nachieve new SOTA performance of RES, e.g., 80.66 on RefCOCO.",
            "author": [
                "Minglang Huang",
                "Yiyi Zhou",
                "Gen Luo",
                "Guannan Jiang",
                "Weilin Zhuang",
                "Xiaoshuai Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00397v2",
                "http://arxiv.org/pdf/2311.00397v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00393v1",
            "title": "Augmenting deep neural networks with symbolic knowledge: Towards\n  trustworthy and interpretable AI for education",
            "updated": "2023-11-01T09:38:56Z",
            "published": "2023-11-01T09:38:56Z",
            "summary": "Artificial neural networks (ANNs) have shown to be amongst the most important\nartificial intelligence (AI) techniques in educational applications, providing\nadaptive educational services. However, their educational potential is limited\nin practice due to three major challenges: i) difficulty in incorporating\nsymbolic educational knowledge (e.g., causal relationships, and practitioners'\nknowledge) in their development, ii) learning and reflecting biases, and iii)\nlack of interpretability. Given the high-risk nature of education, the\nintegration of educational knowledge into ANNs becomes crucial for developing\nAI applications that adhere to essential educational restrictions, and provide\ninterpretability over the predictions. This research argues that the\nneural-symbolic family of AI has the potential to address the named challenges.\nTo this end, it adapts a neural-symbolic AI framework and accordingly develops\nan approach called NSAI, that injects and extracts educational knowledge into\nand from deep neural networks, for modelling learners computational thinking.\nOur findings reveal that the NSAI approach has better generalizability compared\nto deep neural networks trained merely on training data, as well as training\ndata augmented by SMOTE and autoencoder methods. More importantly, unlike the\nother models, the NSAI approach prioritises robust representations that capture\ncausal relationships between input features and output labels, ensuring safety\nin learning to avoid spurious correlations and control biases in training data.\nFurthermore, the NSAI approach enables the extraction of rules from the learned\nnetwork, facilitating interpretation and reasoning about the path to\npredictions, as well as refining the initial educational knowledge. These\nfindings imply that neural-symbolic AI can overcome the limitations of ANNs in\neducation, enabling trustworthy and interpretable applications.",
            "author": [
                "Danial Hooshyar",
                "Roger Azevedo",
                "Yeongwook Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00393v1",
                "http://arxiv.org/pdf/2311.00393v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "I.2.0, I.2.1, I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00389v1",
            "title": "NeuralGF: Unsupervised Point Normal Estimation by Learning Neural\n  Gradient Function",
            "updated": "2023-11-01T09:25:29Z",
            "published": "2023-11-01T09:25:29Z",
            "summary": "Normal estimation for 3D point clouds is a fundamental task in 3D geometry\nprocessing. The state-of-the-art methods rely on priors of fitting local\nsurfaces learned from normal supervision. However, normal supervision in\nbenchmarks comes from synthetic shapes and is usually not available from real\nscans, thereby limiting the learned priors of these methods. In addition,\nnormal orientation consistency across shapes remains difficult to achieve\nwithout a separate post-processing procedure. To resolve these issues, we\npropose a novel method for estimating oriented normals directly from point\nclouds without using ground truth normals as supervision. We achieve this by\nintroducing a new paradigm for learning neural gradient functions, which\nencourages the neural network to fit the input point clouds and yield unit-norm\ngradients at the points. Specifically, we introduce loss functions to\nfacilitate query points to iteratively reach the moving targets and aggregate\nonto the approximated surface, thereby learning a global surface representation\nof the data. Meanwhile, we incorporate gradients into the surface approximation\nto measure the minimum signed deviation of queries, resulting in a consistent\ngradient field associated with the surface. These techniques lead to our deep\nunsupervised oriented normal estimator that is robust to noise, outliers and\ndensity variations. Our excellent results on widely used benchmarks demonstrate\nthat our method can learn more accurate normals for both unoriented and\noriented normal estimation tasks than the latest methods. The source code and\npre-trained model are publicly available at https://github.com/LeoQLi/NeuralGF.",
            "author": [
                "Qing Li",
                "Huifang Feng",
                "Kanle Shi",
                "Yue Gao",
                "Yi Fang",
                "Yu-Shen Liu",
                "Zhizhong Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00389v1",
                "http://arxiv.org/pdf/2311.00389v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00388v1",
            "title": "Towards Automatic Sampling of User Behaviors for Sequential Recommender\n  Systems",
            "updated": "2023-11-01T09:25:21Z",
            "published": "2023-11-01T09:25:21Z",
            "summary": "Sequential recommender systems (SRS) have gained widespread popularity in\nrecommendation due to their ability to effectively capture dynamic user\npreferences. One default setting in the current SRS is to uniformly consider\neach historical behavior as a positive interaction. Actually, this setting has\nthe potential to yield sub-optimal performance, as each item makes a distinct\ncontribution to the user's interest. For example, purchased items should be\ngiven more importance than clicked ones. Hence, we propose a general automatic\nsampling framework, named AutoSAM, to non-uniformly treat historical behaviors.\nSpecifically, AutoSAM augments the standard sequential recommendation\narchitecture with an additional sampler layer to adaptively learn the skew\ndistribution of the raw input, and then sample informative sub-sets to build\nmore generalizable SRS. To overcome the challenges of non-differentiable\nsampling actions and also introduce multiple decision factors for sampling, we\nfurther introduce a novel reinforcement learning based method to guide the\ntraining of the sampler. We theoretically design multi-objective sampling\nrewards including Future Prediction and Sequence Perplexity, and then optimize\nthe whole framework in an end-to-end manner by combining the policy gradient.\nWe conduct extensive experiments on benchmark recommender models and four\nreal-world datasets. The experimental results demonstrate the effectiveness of\nthe proposed approach. We will make our code publicly available after the\nacceptance.",
            "author": [
                "Hao Zhang",
                "Mingyue Cheng",
                "Qi Liu",
                "Zhiding Liu",
                "Enhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00388v1",
                "http://arxiv.org/pdf/2311.00388v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00382v1",
            "title": "Will Code Remain a Relevant User Interface for End-User Programming with\n  Generative AI Models?",
            "updated": "2023-11-01T09:20:21Z",
            "published": "2023-11-01T09:20:21Z",
            "summary": "The research field of end-user programming has largely been concerned with\nhelping non-experts learn to code sufficiently well in order to achieve their\ntasks. Generative AI stands to obviate this entirely by allowing users to\ngenerate code from naturalistic language prompts. In this essay, we explore the\nextent to which \"traditional\" programming languages remain relevant for\nnon-expert end-user programmers in a world with generative AI. We posit the\n\"generative shift hypothesis\": that generative AI will create qualitative and\nquantitative expansions in the traditional scope of end-user programming. We\noutline some reasons that traditional programming languages may still be\nrelevant and useful for end-user programmers. We speculate whether each of\nthese reasons might be fundamental and enduring, or whether they may disappear\nwith further improvements and innovations in generative AI. Finally, we\narticulate a set of implications for end-user programming research, including\nthe possibility of needing to revisit many well-established core concepts, such\nas Ko's learning barriers and Blackwell's attention investment model.",
            "author": [
                "Advait Sarkar"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3622758.3622882",
                "http://arxiv.org/abs/2311.00382v1",
                "http://arxiv.org/pdf/2311.00382v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00377v1",
            "title": "Uncertainty quantification and out-of-distribution detection using\n  surjective normalizing flows",
            "updated": "2023-11-01T09:08:35Z",
            "published": "2023-11-01T09:08:35Z",
            "summary": "Reliable quantification of epistemic and aleatoric uncertainty is of crucial\nimportance in applications where models are trained in one environment but\napplied to multiple different environments, often seen in real-world\napplications for example, in climate science or mobility analysis. We propose a\nsimple approach using surjective normalizing flows to identify\nout-of-distribution data sets in deep neural network models that can be\ncomputed in a single forward pass. The method builds on recent developments in\ndeep uncertainty quantification and generative modeling with normalizing flows.\nWe apply our method to a synthetic data set that has been simulated using a\nmechanistic model from the mobility literature and several data sets simulated\nfrom interventional distributions induced by soft and atomic interventions on\nthat model, and demonstrate that our method can reliably discern\nout-of-distribution data from in-distribution data. We compare the surjective\nflow model to a Dirichlet process mixture model and a bijective flow and find\nthat the surjections are a crucial component to reliably distinguish\nin-distribution from out-of-distribution data.",
            "author": [
                "Simon Dirmeier",
                "Ye Hong",
                "Yanan Xin",
                "Fernando Perez-Cruz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00377v1",
                "http://arxiv.org/pdf/2311.00377v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00371v1",
            "title": "Learning Cooperative Trajectory Representations for Motion Forecasting",
            "updated": "2023-11-01T08:53:05Z",
            "published": "2023-11-01T08:53:05Z",
            "summary": "Motion forecasting is an essential task for autonomous driving, and the\neffective information utilization from infrastructure and other vehicles can\nenhance motion forecasting capabilities. Existing research have primarily\nfocused on leveraging single-frame cooperative information to enhance the\nlimited perception capability of the ego vehicle, while underutilizing the\nmotion and interaction information of traffic participants observed from\ncooperative devices. In this paper, we first propose the cooperative trajectory\nrepresentations learning paradigm. Specifically, we present V2X-Graph, the\nfirst interpretable and end-to-end learning framework for cooperative motion\nforecasting. V2X-Graph employs an interpretable graph to fully leverage the\ncooperative motion and interaction contexts. Experimental results on the\nvehicle-to-infrastructure (V2I) motion forecasting dataset, V2X-Seq,\ndemonstrate the effectiveness of V2X-Graph. To further evaluate on V2X\nscenario, we construct the first real-world vehicle-to-everything (V2X) motion\nforecasting dataset V2X-Traj, and the performance shows the advantage of our\nmethod. We hope both V2X-Graph and V2X-Traj can facilitate the further\ndevelopment of cooperative motion forecasting. Find project at\nhttps://github.com/AIR-THU/V2X-Graph, find data at\nhttps://github.com/AIR-THU/DAIR-V2X-Seq.",
            "author": [
                "Hongzhi Ruan",
                "Haibao Yu",
                "Wenxian Yang",
                "Siqi Fan",
                "Yingjuan Tang",
                "Zaiqing Nie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00371v1",
                "http://arxiv.org/pdf/2311.00371v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00368v1",
            "title": "Performance Optimization of Deep Learning Sparse Matrix Kernels on Intel\n  Max Series GPU",
            "updated": "2023-11-01T08:43:59Z",
            "published": "2023-11-01T08:43:59Z",
            "summary": "In this paper, we focus on three sparse matrix operations that are relevant\nfor machine learning applications, namely, the sparse-dense matrix\nmultiplication (SPMM), the sampled dense-dense matrix multiplication (SDDMM),\nand the composition of the SDDMM with SPMM, also termed as FusedMM. We develop\noptimized implementations for SPMM, SDDMM, and FusedMM operations utilizing\nIntel oneAPI's Explicit SIMD (ESIMD) SYCL extension API. In contrast to CUDA or\nSYCL, the ESIMD API enables the writing of explicitly vectorized kernel code.\nSparse matrix algorithms implemented with the ESIMD API achieved performance\nclose to the peak of the targeted Intel Data Center GPU. We compare our\nperformance results to Intel's oneMKL library on Intel GPUs and to a recent\nCUDA implementation for the sparse matrix operations on NVIDIA's V100 GPU and\ndemonstrate that our implementations for sparse matrix operations outperform\neither.",
            "author": [
                "Mohammad Zubair",
                "Christoph Bauinger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00368v1",
                "http://arxiv.org/pdf/2311.00368v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MS",
                "68-04 (Primary) 68T07, 68W10 (Secondary)",
                "I.2.5; G.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00367v1",
            "title": "Prompt-based Logical Semantics Enhancement for Implicit Discourse\n  Relation Recognition",
            "updated": "2023-11-01T08:38:08Z",
            "published": "2023-11-01T08:38:08Z",
            "summary": "Implicit Discourse Relation Recognition (IDRR), which infers discourse\nrelations without the help of explicit connectives, is still a crucial and\nchallenging task for discourse parsing. Recent works tend to exploit the\nhierarchical structure information from the annotated senses, which demonstrate\nenhanced discourse relation representations can be obtained by integrating\nsense hierarchy. Nevertheless, the performance and robustness for IDRR are\nsignificantly constrained by the availability of annotated data. Fortunately,\nthere is a wealth of unannotated utterances with explicit connectives, that can\nbe utilized to acquire enriched discourse relation features. In light of such\nmotivation, we propose a Prompt-based Logical Semantics Enhancement (PLSE)\nmethod for IDRR. Essentially, our method seamlessly injects knowledge relevant\nto discourse relation into pre-trained language models through prompt-based\nconnective prediction. Furthermore, considering the prompt-based connective\nprediction exhibits local dependencies due to the deficiency of masked language\nmodel (MLM) in capturing global semantics, we design a novel self-supervised\nlearning objective based on mutual information maximization to derive enhanced\nrepresentations of logical semantics for IDRR. Experimental results on PDTB 2.0\nand CoNLL16 datasets demonstrate that our method achieves outstanding and\nconsistent performance against the current state-of-the-art models.",
            "author": [
                "Chenxu Wang",
                "Ping Jian",
                "Mu Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00367v1",
                "http://arxiv.org/pdf/2311.00367v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12035v1",
            "title": "Delta Score: Improving the Binding Assessment of Structure-Based Drug\n  Design Methods",
            "updated": "2023-11-01T08:37:39Z",
            "published": "2023-11-01T08:37:39Z",
            "summary": "Structure-based drug design (SBDD) stands at the forefront of drug discovery,\nemphasizing the creation of molecules that target specific binding pockets.\nRecent advances in this area have witnessed the adoption of deep generative\nmodels and geometric deep learning techniques, modeling SBDD as a conditional\ngeneration task where the target structure serves as context. Historically,\nevaluation of these models centered on docking scores, which quantitatively\ndepict the predicted binding affinity between a molecule and its target pocket.\nThough state-of-the-art models purport that a majority of their generated\nligands exceed the docking score of ground truth ligands in test sets, it begs\nthe question: Do these scores align with real-world biological needs? In this\npaper, we introduce the delta score, a novel evaluation metric grounded in\ntangible pharmaceutical requisites. Our experiments reveal that molecules\nproduced by current deep generative models significantly lag behind ground\ntruth reference ligands when assessed with the delta score. This novel metric\nnot only complements existing benchmarks but also provides a pivotal direction\nfor subsequent research in the domain.",
            "author": [
                "Minsi Ren",
                "Bowen Gao",
                "Bo Qiang",
                "Yanyan Lan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12035v1",
                "http://arxiv.org/pdf/2311.12035v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00366v1",
            "title": "Machine learning meets Singular Optics: Speckle-based Structured light\n  demultiplexing",
            "updated": "2023-11-01T08:36:53Z",
            "published": "2023-11-01T08:36:53Z",
            "summary": "In this paper, the advancements in structured light beams recognition using\nspeckle-based convolutional neural networks (CNNs) have been presented. Speckle\nfields, generated by the interference of multiple wavefronts diffracted and\nscattered through a diffuser, project a random distribution. The generated\nrandom distribution of phase and intensity correlates to the structured light\nbeam of the corresponding speckle field. This unique distribution of phase and\nintensity offers an additional dimension for recognizing the encoded\ninformation in structured light. The CNNs are well-suited for harnessing this\nunique ability to recognize the speckle field by learning hidden patterns\nwithin data. One notable advantage of speckle-based recognition is their\nability to identify structured light beams from a small portion of the speckle\nfield, even in high-noise environments. The diffractive nature of the speckle\nfield enables off-axis recognition, showcasing its capability in information\nbroadcasting employing structured light beams. This is a significant departure\nfrom direct-mode detection-based models to alignment-free speckle-based\ndetection models, which are no longer constrained by the directionality of\nlaser beams.",
            "author": [
                "Venugopal Raskatla",
                "Purnesh Singh Badavath",
                "Vijay Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00366v1",
                "http://arxiv.org/pdf/2311.00366v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00359v1",
            "title": "Inverse identification framework for cohesive zone model incorporating\n  failure mode based on multi-island genetic algorithm",
            "updated": "2023-11-01T08:10:36Z",
            "published": "2023-11-01T08:10:36Z",
            "summary": "Composite interfaces are commonly simulated by cohesive zone models with the\nkey challenge being the calibration of interfacial parameters. A new framework\nis presented in this paper to derive the characteristic of any cohesive zone\nmodel. This approach employs the multi-island genetic algorithm to obtain the\ninterface parameters aligning closely with the experimental observations. The\nintroduced framework innovatively formulates an objective function, considering\nboth the congruence of the load-displacement curve and the alignment with the\nfailure mode of model. The framework combines machine learning and\nmulti-objective optimization. A method using the interface debonding length to\nquantify the failure mode of the model is proposed. To demonstrate the\nfeasibility of the proposed framework, the newly strength-based cohesive zone\nmodel is taken as an example, and key parameters and damage evolution are\nidentified accurately. The inverse algorithm is used to identify the interface\nparameters of both the double cantilever beam experiment and the four-point\nbending test. The robustness and accuracy of the framework are validated\nthrough the double cantilever beam test. The findings indicate that the\nnumerical results align closely with the experimental data, confirming that the\ninterface parameters identified by the proposed framework can reproduce the\nperformance of the adhesive joints.",
            "author": [
                "Tianxiang Shi",
                "Miao Pang",
                "Yangyang Wang",
                "Yongqiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00359v1",
                "http://arxiv.org/pdf/2311.00359v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00358v1",
            "title": "Rethinking Samples Selection for Contrastive Learning: Mining of\n  Potential Samples",
            "updated": "2023-11-01T08:08:06Z",
            "published": "2023-11-01T08:08:06Z",
            "summary": "Contrastive learning predicts whether two images belong to the same category\nby training a model to make their feature representations as close or as far\naway as possible. In this paper, we rethink how to mine samples in contrastive\nlearning, unlike other methods, our approach is more comprehensive, taking into\naccount both positive and negative samples, and mining potential samples from\ntwo aspects: First, for positive samples, we consider both the augmented sample\nviews obtained by data augmentation and the mined sample views through data\nmining. Then, we weight and combine them using both soft and hard weighting\nstrategies. Second, considering the existence of uninformative negative samples\nand false negative samples in the negative samples, we analyze the negative\nsamples from the gradient perspective and finally mine negative samples that\nare neither too hard nor too easy as potential negative samples, i.e., those\nnegative samples that are close to positive samples. The experiments show the\nobvious advantages of our method compared with some traditional self-supervised\nmethods. Our method achieves 88.57%, 61.10%, and 36.69% top-1 accuracy on\nCIFAR10, CIFAR100, and TinyImagenet, respectively.",
            "author": [
                "Hengkui Dong",
                "Xianzhong Long",
                "Yun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00358v1",
                "http://arxiv.org/pdf/2311.00358v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00356v1",
            "title": "QFree: A Universal Value Function Factorization for Multi-Agent\n  Reinforcement Learning",
            "updated": "2023-11-01T08:07:16Z",
            "published": "2023-11-01T08:07:16Z",
            "summary": "Centralized training is widely utilized in the field of multi-agent\nreinforcement learning (MARL) to assure the stability of training process. Once\na joint policy is obtained, it is critical to design a value function\nfactorization method to extract optimal decentralized policies for the agents,\nwhich needs to satisfy the individual-global-max (IGM) principle. While\nimposing additional limitations on the IGM function class can help to meet the\nrequirement, it comes at the cost of restricting its application to more\ncomplex multi-agent environments. In this paper, we propose QFree, a universal\nvalue function factorization method for MARL. We start by developing\nmathematical equivalent conditions of the IGM principle based on the advantage\nfunction, which ensures that the principle holds without any compromise,\nremoving the conservatism of conventional methods. We then establish a more\nexpressive mixing network architecture that can fulfill the equivalent\nfactorization. In particular, the novel loss function is developed by\nconsidering the equivalent conditions as regularization term during policy\nevaluation in the MARL algorithm. Finally, the effectiveness of the proposed\nmethod is verified in a nonmonotonic matrix game scenario. Moreover, we show\nthat QFree achieves the state-of-the-art performance in a general-purpose\ncomplex MARL benchmark environment, Starcraft Multi-Agent Challenge (SMAC).",
            "author": [
                "Rizhong Wang",
                "Huiping Li",
                "Di Cui",
                "Demin Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00356v1",
                "http://arxiv.org/pdf/2311.00356v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00346v1",
            "title": "Adversarially Robust Distributed Count Tracking via Partial Differential\n  Privacy",
            "updated": "2023-11-01T07:42:13Z",
            "published": "2023-11-01T07:42:13Z",
            "summary": "We study the distributed tracking model, also known as distributed functional\nmonitoring. This model involves $k$ sites each receiving a stream of items and\ncommunicating with the central server. The server's task is to track a function\nof all items received thus far continuously, with minimum communication cost.\nFor count tracking, it is known that there is a $\\sqrt{k}$ gap in communication\nbetween deterministic and randomized algorithms. However, existing randomized\nalgorithms assume an \"oblivious adversary\" who constructs the entire input\nstreams before the algorithm starts. Here we consider adaptive adversaries who\ncan choose new items based on previous answers from the algorithm.\nDeterministic algorithms are trivially robust to adaptive adversaries, while\nrandomized ones may not. Therefore, we investigate whether the $\\sqrt{k}$\nadvantage of randomized algorithms is from randomness itself or the oblivious\nadversary assumption. We provide an affirmative answer to this question by\ngiving a robust algorithm with optimal communication. Existing robustification\ntechniques do not yield optimal bounds due to the inherent challenges of the\ndistributed nature of the problem. To address this, we extend the differential\nprivacy framework by introducing \"partial differential privacy\" and proving a\nnew generalization theorem. This theorem may have broader applications beyond\nrobust count tracking, making it of independent interest.",
            "author": [
                "Zhongzheng Xiong",
                "Xiaoyi Zhu",
                "Zengfeng Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00346v1",
                "http://arxiv.org/pdf/2311.00346v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00732v1",
            "title": "tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for\n  Detecting Tweets Self-reporting a COVID-19 Diagnosis",
            "updated": "2023-11-01T07:41:23Z",
            "published": "2023-11-01T07:41:23Z",
            "summary": "The paper describes a system developed for Task 1 at SMM4H 2023. The goal of\nthe task is to automatically distinguish tweets that self-report a COVID-19\ndiagnosis (for example, a positive test, clinical diagnosis, or\nhospitalization) from those that do not. We investigate the use of different\ntechniques for preprocessing tweets using four transformer-based models. The\nensemble of fine-tuned language models obtained an F1-score of 84.5%, which is\n4.1% higher than the average value.",
            "author": [
                "Anna Glazkova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00732v1",
                "http://arxiv.org/pdf/2311.00732v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.SI",
                "68T50",
                "I.2.7; I.7.m; H.3.3; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00344v2",
            "title": "A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents",
            "updated": "2023-11-02T13:53:24Z",
            "published": "2023-11-01T07:37:27Z",
            "summary": "A lot of recent machine learning research papers have \"Open-ended learning\"\nin their title. But very few of them attempt to define what they mean when\nusing the term. Even worse, when looking more closely there seems to be no\nconsensus on what distinguishes open-ended learning from related concepts such\nas continual learning, lifelong learning or autotelic learning. In this paper,\nwe contribute to fixing this situation. After illustrating the genealogy of the\nconcept and more recent perspectives about what it truly means, we outline that\nopen-ended learning is generally conceived as a composite notion encompassing a\nset of diverse properties. In contrast with these previous approaches, we\npropose to isolate a key elementary property of open-ended processes, which is\nto always produce novel elements from time to time over an infinite horizon.\nFrom there, we build the notion of open-ended learning problems and focus in\nparticular on the subset of open-ended goal-conditioned reinforcement learning\nproblems, as this framework facilitates the definition of learning a growing\nrepertoire of skills. Finally, we highlight the work that remains to be\nperformed to fill the gap between our elementary definition and the more\ninvolved notions of open-ended learning that developmental AI researchers may\nhave in mind.",
            "author": [
                "Olivier Sigaud",
                "Gianluca Baldassarre",
                "Cedric Colas",
                "Stephane Doncieux",
                "Richard Duro",
                "Nicolas Perrin-Gilbert",
                "Vieri Giuliano Santucci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00344v2",
                "http://arxiv.org/pdf/2311.00344v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00342v1",
            "title": "fMRI-PTE: A Large-scale fMRI Pretrained Transformer Encoder for\n  Multi-Subject Brain Activity Decoding",
            "updated": "2023-11-01T07:24:22Z",
            "published": "2023-11-01T07:24:22Z",
            "summary": "The exploration of brain activity and its decoding from fMRI data has been a\nlongstanding pursuit, driven by its potential applications in brain-computer\ninterfaces, medical diagnostics, and virtual reality. Previous approaches have\nprimarily focused on individual subject analysis, highlighting the need for a\nmore universal and adaptable framework, which is the core motivation behind our\nwork. In this work, we propose fMRI-PTE, an innovative auto-encoder approach\nfor fMRI pre-training, with a focus on addressing the challenges of varying\nfMRI data dimensions due to individual brain differences. Our approach involves\ntransforming fMRI signals into unified 2D representations, ensuring consistency\nin dimensions and preserving distinct brain activity patterns. We introduce a\nnovel learning strategy tailored for pre-training 2D fMRI images, enhancing the\nquality of reconstruction. fMRI-PTE's adaptability with image generators\nenables the generation of well-represented fMRI features, facilitating various\ndownstream tasks, including within-subject and cross-subject brain activity\ndecoding. Our contributions encompass introducing fMRI-PTE, innovative data\ntransformation, efficient training, a novel learning strategy, and the\nuniversal applicability of our approach. Extensive experiments validate and\nsupport our claims, offering a promising foundation for further research in\nthis domain.",
            "author": [
                "Xuelin Qian",
                "Yun Wang",
                "Jingyang Huo",
                "Jianfeng Feng",
                "Yanwei Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00342v1",
                "http://arxiv.org/pdf/2311.00342v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00341v2",
            "title": "The Open DAC 2023 Dataset and Challenges for Sorbent Discovery in Direct\n  Air Capture",
            "updated": "2023-11-27T05:51:13Z",
            "published": "2023-11-01T07:21:08Z",
            "summary": "New methods for carbon dioxide removal are urgently needed to combat global\nclimate change. Direct air capture (DAC) is an emerging technology to capture\ncarbon dioxide directly from ambient air. Metal-organic frameworks (MOFs) have\nbeen widely studied as potentially customizable adsorbents for DAC. However,\ndiscovering promising MOF sorbents for DAC is challenging because of the vast\nchemical space to explore and the need to understand materials as functions of\nhumidity and temperature. We explore a computational approach benefiting from\nrecent innovations in machine learning (ML) and present a dataset named Open\nDAC 2023 (ODAC23) consisting of more than 38M density functional theory (DFT)\ncalculations on more than 8,400 MOF materials containing adsorbed $CO_2$ and/or\n$H_2O$. ODAC23 is by far the largest dataset of MOF adsorption calculations at\nthe DFT level of accuracy currently available. In addition to probing\nproperties of adsorbed molecules, the dataset is a rich source of information\non structural relaxation of MOFs, which will be useful in many contexts beyond\nspecific applications for DAC. A large number of MOFs with promising properties\nfor DAC are identified directly in ODAC23. We also trained state-of-the-art ML\nmodels on this dataset to approximate calculations at the DFT level. This\nopen-source dataset and our initial ML models will provide an important\nbaseline for future efforts to identify MOFs for a wide range of applications,\nincluding DAC.",
            "author": [
                "Anuroop Sriram",
                "Sihoon Choi",
                "Xiaohan Yu",
                "Logan M. Brabson",
                "Abhishek Das",
                "Zachary Ulissi",
                "Matt Uyttendaele",
                "Andrew J. Medford",
                "David S. Sholl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00341v2",
                "http://arxiv.org/pdf/2311.00341v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00339v1",
            "title": "Space Narrative: Generating Images and 3D Scenes of Chinese Garden from\n  Text using Deep Learning",
            "updated": "2023-11-01T07:16:01Z",
            "published": "2023-11-01T07:16:01Z",
            "summary": "The consistent mapping from poems to paintings is essential for the research\nand restoration of traditional Chinese gardens. But the lack of firsthand\nma-terial is a great challenge to the reconstruction work. In this paper, we\npro-pose a method to generate garden paintings based on text descriptions using\ndeep learning method. Our image-text pair dataset consists of more than one\nthousand Ming Dynasty Garden paintings and their inscriptions and post-scripts.\nA latent text-to-image diffusion model learns the mapping from de-scriptive\ntexts to garden paintings of the Ming Dynasty, and then the text description of\nJichang Garden guides the model to generate new garden paintings. The cosine\nsimilarity between the guide text and the generated image is the evaluation\ncriterion for the generated images. Our dataset is used to fine-tune the\npre-trained diffusion model using Low-Rank Adapta-tion of Large Language Models\n(LoRA). We also transformed the generated images into a panorama and created a\nfree-roam scene in Unity 3D. Our post-trained model is capable of generating\ngarden images in the style of Ming Dynasty landscape paintings based on textual\ndescriptions. The gener-ated images are compatible with three-dimensional\npresentation in Unity 3D.",
            "author": [
                "Jiaxi Shi1",
                "Hao Hua1"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00339v1",
                "http://arxiv.org/pdf/2311.00339v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00334v2",
            "title": "MetisFL: An Embarrassingly Parallelized Controller for Scalable &\n  Efficient Federated Learning Workflows",
            "updated": "2023-11-13T07:12:55Z",
            "published": "2023-11-01T07:01:19Z",
            "summary": "A Federated Learning (FL) system typically consists of two core processing\nentities: the federation controller and the learners. The controller is\nresponsible for managing the execution of FL workflows across learners and the\nlearners for training and evaluating federated models over their private\ndatasets. While executing an FL workflow, the FL system has no control over the\ncomputational resources or data of the participating learners. Still, it is\nresponsible for other operations, such as model aggregation, task dispatching,\nand scheduling. These computationally heavy operations generally need to be\nhandled by the federation controller. Even though many FL systems have been\nrecently proposed to facilitate the development of FL workflows, most of these\nsystems overlook the scalability of the controller. To meet this need, we\ndesigned and developed a novel FL system called MetisFL, where the federation\ncontroller is the first-class citizen. MetisFL re-engineers all the operations\nconducted by the federation controller to accelerate the training of\nlarge-scale FL workflows. By quantitatively comparing MetisFL against other\nstate-of-the-art FL systems, we empirically demonstrate that MetisFL leads to a\n10-fold wall-clock time execution boost across a wide range of challenging FL\nworkflows with increasing model sizes and federation sites.",
            "author": [
                "Dimitris Stripelis",
                "Chrysovalantis Anastasiou",
                "Patrick Toral",
                "Armaghan Asghar",
                "Jose Luis Ambite"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3630048.3630186",
                "http://arxiv.org/abs/2311.00334v2",
                "http://arxiv.org/pdf/2311.00334v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01473v1",
            "title": "Adversarial Examples in the Physical World: A Survey",
            "updated": "2023-11-01T06:55:09Z",
            "published": "2023-11-01T06:55:09Z",
            "summary": "Deep neural networks (DNNs) have demonstrated high vulnerability to\nadversarial examples. Besides the attacks in the digital world, the practical\nimplications of adversarial examples in the physical world present significant\nchallenges and safety concerns. However, current research on physical\nadversarial examples (PAEs) lacks a comprehensive understanding of their unique\ncharacteristics, leading to limited significance and understanding. In this\npaper, we address this gap by thoroughly examining the characteristics of PAEs\nwithin a practical workflow encompassing training, manufacturing, and\nre-sampling processes. By analyzing the links between physical adversarial\nattacks, we identify manufacturing and re-sampling as the primary sources of\ndistinct attributes and particularities in PAEs. Leveraging this knowledge, we\ndevelop a comprehensive analysis and classification framework for PAEs based on\ntheir specific characteristics, covering over 100 studies on physical-world\nadversarial examples. Furthermore, we investigate defense strategies against\nPAEs and identify open challenges and opportunities for future research. We aim\nto provide a fresh, thorough, and systematic understanding of PAEs, thereby\npromoting the development of robust adversarial learning and its application in\nopen-world scenarios.",
            "author": [
                "Jiakai Wang",
                "Donghua Wang",
                "Jin Hu",
                "Siyang Wu",
                "Tingsong Jiang",
                "Wen Yao",
                "Aishan Liu",
                "Xianglong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01473v1",
                "http://arxiv.org/pdf/2311.01473v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00333v1",
            "title": "Caseformer: Pre-training for Legal Case Retrieval",
            "updated": "2023-11-01T06:52:41Z",
            "published": "2023-11-01T06:52:41Z",
            "summary": "Legal case retrieval aims to help legal workers find relevant cases related\nto their cases at hand, which is important for the guarantee of fairness and\njustice in legal judgments. While recent advances in neural retrieval methods\nhave significantly improved the performance of open-domain retrieval tasks\n(e.g., Web search), their advantages have not been observed in legal case\nretrieval due to their thirst for annotated data. As annotating large-scale\ntraining data in legal domains is prohibitive due to the need for domain\nexpertise, traditional search techniques based on lexical matching such as\nTF-IDF, BM25, and Query Likelihood are still prevalent in legal case retrieval\nsystems. While previous studies have designed several pre-training methods for\nIR models in open-domain tasks, these methods are usually suboptimal in legal\ncase retrieval because they cannot understand and capture the key knowledge and\ndata structures in the legal corpus. To this end, we propose a novel\npre-training framework named Caseformer that enables the pre-trained models to\nlearn legal knowledge and domain-specific relevance information in legal case\nretrieval without any human-labeled data. Through three unsupervised learning\ntasks, Caseformer is able to capture the special language, document structure,\nand relevance patterns of legal case documents, making it a strong backbone for\ndownstream legal case retrieval tasks. Experimental results show that our model\nhas achieved state-of-the-art performance in both zero-shot and full-data\nfine-tuning settings. Also, experiments on both Chinese and English legal\ndatasets demonstrate that the effectiveness of Caseformer is\nlanguage-independent in legal case retrieval.",
            "author": [
                "Weihang Su",
                "Qingyao Ai",
                "Yueyue Wu",
                "Yixiao Ma",
                "Haitao Li",
                "Yiqun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00333v1",
                "http://arxiv.org/pdf/2311.00333v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00332v2",
            "title": "SDF4CHD: Generative Modeling of Cardiac Anatomies with Congenital Heart\n  Defects",
            "updated": "2023-11-08T09:45:49Z",
            "published": "2023-11-01T06:50:53Z",
            "summary": "Congenital heart disease (CHD) encompasses a spectrum of cardiovascular\nstructural abnormalities, often requiring customized treatment plans for\nindividual patients. Computational modeling and analysis of these unique\ncardiac anatomies can improve diagnosis and treatment planning and may\nultimately lead to improved outcomes. Deep learning (DL) methods have\ndemonstrated the potential to enable efficient treatment planning by automating\ncardiac segmentation and mesh construction for patients with normal cardiac\nanatomies. However, CHDs are often rare, making it challenging to acquire\nsufficiently large patient cohorts for training such DL models. Generative\nmodeling of cardiac anatomies has the potential to fill this gap via the\ngeneration of virtual cohorts; however, prior approaches were largely designed\nfor normal anatomies and cannot readily capture the significant topological\nvariations seen in CHD patients. Therefore, we propose a type- and\nshape-disentangled generative approach suitable to capture the wide spectrum of\ncardiac anatomies observed in different CHD types and synthesize differently\nshaped cardiac anatomies that preserve the unique topology for specific CHD\ntypes. Our DL approach represents generic whole heart anatomies with CHD\ntype-specific abnormalities implicitly using signed distance fields (SDF) based\non CHD type diagnosis, which conveniently captures divergent anatomical\nvariations across different types and represents meaningful intermediate CHD\nstates. To capture the shape-specific variations, we then learn invertible\ndeformations to morph the learned CHD type-specific anatomies and reconstruct\npatient-specific shapes. Our approach has the potential to augment the\nimage-segmentation pairs for rarer CHD types for cardiac segmentation and\ngenerate cohorts of CHD cardiac meshes for computational simulation.",
            "author": [
                "Fanwei Kong",
                "Sascha Stocker",
                "Perry S. Choi",
                "Michael Ma",
                "Daniel B. Ennis",
                "Alison Marsden"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00332v2",
                "http://arxiv.org/pdf/2311.00332v2"
            ],
            "primary_category": "q-bio.TO",
            "category": [
                "q-bio.TO",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00330v1",
            "title": "Latent Space Inference For Spatial Transcriptomics",
            "updated": "2023-11-01T06:50:00Z",
            "published": "2023-11-01T06:50:00Z",
            "summary": "In order to understand the complexities of cellular biology, researchers are\ninterested in two important metrics: the genetic expression information of\ncells and their spatial coordinates within a tissue sample. However,\nstate-of-the art methods, namely single-cell RNA sequencing and image based\nspatial transcriptomics can only recover a subset of this information, either\nfull genetic expression with loss of spatial information, or spatial\ninformation with loss of resolution in sequencing data. In this project, we\ninvestigate a probabilistic machine learning method to obtain the full genetic\nexpression information for tissues samples while also preserving their spatial\ncoordinates. This is done through mapping both datasets to a joint latent space\nrepresentation with the use of variational machine learning methods. From here,\nthe full genetic and spatial information can be decoded and to give us greater\ninsights on the understanding of cellular processes and pathways.",
            "author": [
                "J. Ding",
                "S. N. Zaman",
                "P. Y. Chen",
                "D. Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00330v1",
                "http://arxiv.org/pdf/2311.00330v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00327v1",
            "title": "Multi-task Representation Learning for Pure Exploration in Bilinear\n  Bandits",
            "updated": "2023-11-01T06:30:45Z",
            "published": "2023-11-01T06:30:45Z",
            "summary": "We study multi-task representation learning for the problem of pure\nexploration in bilinear bandits. In bilinear bandits, an action takes the form\nof a pair of arms from two different entity types and the reward is a bilinear\nfunction of the known feature vectors of the arms. In the \\textit{multi-task\nbilinear bandit problem}, we aim to find optimal actions for multiple tasks\nthat share a common low-dimensional linear representation. The objective is to\nleverage this characteristic to expedite the process of identifying the best\npair of arms for all tasks. We propose the algorithm GOBLIN that uses an\nexperimental design approach to optimize sample allocations for learning the\nglobal representation as well as minimize the number of samples needed to\nidentify the optimal pair of arms in individual tasks. To the best of our\nknowledge, this is the first study to give sample complexity analysis for pure\nexploration in bilinear bandits with shared representation. Our results\ndemonstrate that by learning the shared representation across tasks, we achieve\nsignificantly improved sample complexity compared to the traditional approach\nof solving tasks independently.",
            "author": [
                "Subhojyoti Mukherjee",
                "Qiaomin Xie",
                "Josiah P. Hanna",
                "Robert Nowak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00327v1",
                "http://arxiv.org/pdf/2311.00327v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00322v2",
            "title": "Robust Graph Clustering via Meta Weighting for Noisy Graphs",
            "updated": "2023-11-08T08:01:49Z",
            "published": "2023-11-01T06:12:34Z",
            "summary": "How can we find meaningful clusters in a graph robustly against noise edges?\nGraph clustering (i.e., dividing nodes into groups of similar ones) is a\nfundamental problem in graph analysis with applications in various fields.\nRecent studies have demonstrated that graph neural network (GNN) based\napproaches yield promising results for graph clustering. However, we observe\nthat their performance degenerates significantly on graphs with noise edges,\nwhich are prevalent in practice. In this work, we propose MetaGC for robust\nGNN-based graph clustering. MetaGC employs a decomposable clustering loss\nfunction, which can be rephrased as a sum of losses over node pairs. We add a\nlearnable weight to each node pair, and MetaGC adaptively adjusts the weights\nof node pairs using meta-weighting so that the weights of meaningful node pairs\nincrease and the weights of less-meaningful ones (e.g., noise edges) decrease.\nWe show empirically that MetaGC learns weights as intended and consequently\noutperforms the state-of-the-art GNN-based competitors, even when they are\nequipped with separate denoising schemes, on five real-world graphs under\nvarying levels of noise. Our code and datasets are available at\nhttps://github.com/HyeonsooJo/MetaGC.",
            "author": [
                "Hyeonsoo Jo",
                "Fanchen Bu",
                "Kijung Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00322v2",
                "http://arxiv.org/pdf/2311.00322v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00731v1",
            "title": "Enhancing Clustering Representations with Positive Proximity and Cluster\n  Dispersion Learning",
            "updated": "2023-11-01T06:12:02Z",
            "published": "2023-11-01T06:12:02Z",
            "summary": "Contemporary deep clustering approaches often rely on either contrastive or\nnon-contrastive techniques to acquire effective representations for clustering\ntasks. Contrastive methods leverage negative pairs to achieve homogenous\nrepresentations but can introduce class collision issues, potentially\ncompromising clustering performance. On the contrary, non-contrastive\ntechniques prevent class collisions but may produce non-uniform representations\nthat lead to clustering collapse. In this work, we propose a novel end-to-end\ndeep clustering approach named PIPCDR, designed to harness the strengths of\nboth approaches while mitigating their limitations. PIPCDR incorporates a\npositive instance proximity loss and a cluster dispersion regularizer. The\npositive instance proximity loss ensures alignment between augmented views of\ninstances and their sampled neighbors, enhancing within-cluster compactness by\nselecting genuinely positive pairs within the embedding space. Meanwhile, the\ncluster dispersion regularizer maximizes inter-cluster distances while\nminimizing within-cluster compactness, promoting uniformity in the learned\nrepresentations. PIPCDR excels in producing well-separated clusters, generating\nuniform representations, avoiding class collision issues, and enhancing\nwithin-cluster compactness. We extensively validate the effectiveness of PIPCDR\nwithin an end-to-end Majorize-Minimization framework, demonstrating its\ncompetitive performance on moderate-scale clustering benchmark datasets and\nestablishing new state-of-the-art results on large-scale datasets.",
            "author": [
                "Abhishek Kumar",
                "Dong-Gyu Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00731v1",
                "http://arxiv.org/pdf/2311.00731v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00320v1",
            "title": "Semantic Hearing: Programming Acoustic Scenes with Binaural Hearables",
            "updated": "2023-11-01T06:07:28Z",
            "published": "2023-11-01T06:07:28Z",
            "summary": "Imagine being able to listen to the birds chirping in a park without hearing\nthe chatter from other hikers, or being able to block out traffic noise on a\nbusy street while still being able to hear emergency sirens and car honks. We\nintroduce semantic hearing, a novel capability for hearable devices that\nenables them to, in real-time, focus on, or ignore, specific sounds from\nreal-world environments, while also preserving the spatial cues. To achieve\nthis, we make two technical contributions: 1) we present the first neural\nnetwork that can achieve binaural target sound extraction in the presence of\ninterfering sounds and background noise, and 2) we design a training\nmethodology that allows our system to generalize to real-world use. Results\nshow that our system can operate with 20 sound classes and that our\ntransformer-based network has a runtime of 6.56 ms on a connected smartphone.\nIn-the-wild evaluation with participants in previously unseen indoor and\noutdoor scenarios shows that our proof-of-concept system can extract the target\nsounds and generalize to preserve the spatial cues in its binaural output.\nProject page with code: https://semantichearing.cs.washington.edu",
            "author": [
                "Bandhav Veluri",
                "Malek Itani",
                "Justin Chan",
                "Takuya Yoshioka",
                "Shyamnath Gollakota"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3586183.3606779",
                "http://arxiv.org/abs/2311.00320v1",
                "http://arxiv.org/pdf/2311.00320v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00318v1",
            "title": "Flooding Regularization for Stable Training of Generative Adversarial\n  Networks",
            "updated": "2023-11-01T06:02:59Z",
            "published": "2023-11-01T06:02:59Z",
            "summary": "Generative Adversarial Networks (GANs) have shown remarkable performance in\nimage generation. However, GAN training suffers from the problem of\ninstability. One of the main approaches to address this problem is to modify\nthe loss function, often using regularization terms in addition to changing the\ntype of adversarial losses. This paper focuses on directly regularizing the\nadversarial loss function. We propose a method that applies flooding, an\noverfitting suppression method in supervised learning, to GANs to directly\nprevent the discriminator's loss from becoming excessively low. Flooding\nrequires tuning the flood level, but when applied to GANs, we propose that the\nappropriate range of flood level settings is determined by the adversarial loss\nfunction, supported by theoretical analysis of GANs using the binary cross\nentropy loss. We experimentally verify that flooding stabilizes GAN training\nand can be combined with other stabilization techniques. We also reveal that by\nrestricting the discriminator's loss to be no greater than flood level, the\ntraining proceeds stably even when the flood level is somewhat high.",
            "author": [
                "Iu Yahiro",
                "Takashi Ishida",
                "Naoto Yokoya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00318v1",
                "http://arxiv.org/pdf/2311.00318v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00317v1",
            "title": "Data Augmentation for Code Translation with Comparable Corpora and\n  Multiple References",
            "updated": "2023-11-01T06:01:22Z",
            "published": "2023-11-01T06:01:22Z",
            "summary": "One major challenge of translating code between programming languages is that\nparallel training data is often limited. To overcome this challenge, we present\ntwo data augmentation techniques, one that builds comparable corpora (i.e.,\ncode pairs with similar functionality), and another that augments existing\nparallel data with multiple reference translations. Specifically, we build and\nanalyze multiple types of comparable corpora, including programs generated from\nnatural language documentation using a code generation model. Furthermore, to\nreduce overfitting to a single reference translation, we automatically generate\nadditional translation references for available parallel data and filter the\ntranslations by unit tests, which increases variation in target translations.\nExperiments show that our data augmentation techniques significantly improve\nCodeT5 for translation between Java, Python, and C++ by an average of 7.5%\nComputational Accuracy (CA@1), which verifies the correctness of translations\nby execution. The code is available at https://github.com/Veronicium/CMTrans.",
            "author": [
                "Yiqing Xie",
                "Atharva Naik",
                "Daniel Fried",
                "Carolyn Rose"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00317v1",
                "http://arxiv.org/pdf/2311.00317v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00314v1",
            "title": "Federated Topic Model and Model Pruning Based on Variational Autoencoder",
            "updated": "2023-11-01T06:00:14Z",
            "published": "2023-11-01T06:00:14Z",
            "summary": "Topic modeling has emerged as a valuable tool for discovering patterns and\ntopics within large collections of documents. However, when cross-analysis\ninvolves multiple parties, data privacy becomes a critical concern. Federated\ntopic modeling has been developed to address this issue, allowing multiple\nparties to jointly train models while protecting pri-vacy. However, there are\ncommunication and performance challenges in the federated sce-nario. In order\nto solve the above problems, this paper proposes a method to establish a\nfederated topic model while ensuring the privacy of each node, and use neural\nnetwork model pruning to accelerate the model, where the client periodically\nsends the model neu-ron cumulative gradients and model weights to the server,\nand the server prunes the model. To address different requirements, two\ndifferent methods are proposed to determine the model pruning rate. The first\nmethod involves slow pruning throughout the entire model training process,\nwhich has limited acceleration effect on the model training process, but can\nensure that the pruned model achieves higher accuracy. This can significantly\nreduce the model inference time during the inference process. The second\nstrategy is to quickly reach the target pruning rate in the early stage of\nmodel training in order to accelerate the model training speed, and then\ncontinue to train the model with a smaller model size after reaching the target\npruning rate. This approach may lose more useful information but can complete\nthe model training faster. Experimental results show that the federated topic\nmodel pruning based on the variational autoencoder proposed in this paper can\ngreatly accelerate the model training speed while ensuring the model's\nperformance.",
            "author": [
                "Chengjie Ma",
                "Yawen Li",
                "Meiyu Liang",
                "Ang Li"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-981-99-6187-0_5",
                "http://arxiv.org/abs/2311.00314v1",
                "http://arxiv.org/pdf/2311.00314v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00313v1",
            "title": "Gaze-based Learning from Demonstration In Surgical Robotics",
            "updated": "2023-11-01T05:50:43Z",
            "published": "2023-11-01T05:50:43Z",
            "summary": "Surgical robotics is a rising field in medical technology and advanced\nrobotics. Robot assisted surgery, or robotic surgery, allows surgeons to\nperform complicated surgical tasks with more precision, automation, and\nflexibility than is possible for traditional surgical approaches. The main type\nof robot assisted surgery is minimally invasive surgery, which could be\nautomated and result in a faster healing time for the patient. The surgical\nrobot we are particularly interested in is the da Vinci surgical system, which\nis developed and manufactured by Intuitive Surgical. In the current iteration\nof the system, the endoscopic camera arm on the da Vinci robot has to be\nmanually controlled and calibrated by the surgeon during a surgical task, which\ninterrupts the flow of the operation. The main goal of this capstone project is\nto automate the motion of the camera arm using a probabilistic model based on\nsurgeon eye gaze data and da Vinci robot kinematic data.",
            "author": [
                "A. E. Abdelaal",
                "S. N. Zaman",
                "P. Y Chen",
                "T. Suzuki",
                "J. Ingleton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00313v1",
                "http://arxiv.org/pdf/2311.00313v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00304v1",
            "title": "Stacking an autoencoder for feature selection of zero-day threats",
            "updated": "2023-11-01T05:29:42Z",
            "published": "2023-11-01T05:29:42Z",
            "summary": "Zero-day attack detection plays a critical role in mitigating risks,\nprotecting assets, and staying ahead in the evolving threat landscape. This\nstudy explores the application of stacked autoencoder (SAE), a type of\nartificial neural network, for feature selection and zero-day threat\nclassification using a Long Short-Term Memory (LSTM) scheme. The process\ninvolves preprocessing the UGRansome dataset and training an unsupervised SAE\nfor feature extraction. Finetuning with supervised learning is then performed\nto enhance the discriminative capabilities of this model. The learned weights\nand activations of the autoencoder are analyzed to identify the most important\nfeatures for discriminating between zero-day threats and normal system\nbehavior. These selected features form a reduced feature set that enables\naccurate classification. The results indicate that the SAE-LSTM performs well\nacross all three attack categories by showcasing high precision, recall, and F1\nscore values, emphasizing the model's strong predictive capabilities in\nidentifying various types of zero-day attacks. Additionally, the balanced\naverage scores of the SAE-LSTM suggest that the model generalizes effectively\nand consistently across different attack categories.",
            "author": [
                "Mahmut Tokmak",
                "Mike Nkongolo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00304v1",
                "http://arxiv.org/pdf/2311.00304v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00301v1",
            "title": "Detecting Syllable-Level Pronunciation Stress with A Self-Attention\n  Model",
            "updated": "2023-11-01T05:05:49Z",
            "published": "2023-11-01T05:05:49Z",
            "summary": "One precondition of effective oral communication is that words should be\npronounced clearly, especially for non-native speakers. Word stress is the key\nto clear and correct English, and misplacement of syllable stress may lead to\nmisunderstandings. Thus, knowing the stress level is important for English\nspeakers and learners. This paper presents a self-attention model to identify\nthe stress level for each syllable of spoken English. Various prosodic and\ncategorical features, including the pitch level, intensity, duration and type\nof the syllable and its nuclei (the vowel of the syllable), are explored. These\nfeatures are input to the self-attention model, and syllable-level stresses are\npredicted. The simplest model yields an accuracy of over 88% and 93% on\ndifferent datasets, while more advanced models provide higher accuracy. Our\nstudy suggests that the self-attention model can be promising in stress-level\ndetection. These models could be applied to various scenarios, such as online\nmeetings and English learning.",
            "author": [
                "Wang Weiying",
                "Nakajima Akinori"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00301v1",
                "http://arxiv.org/pdf/2311.00301v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00296v1",
            "title": "Semantic Representation Learning of Scientific Literature based on\n  Adaptive Feature and Graph Neural Network",
            "updated": "2023-11-01T05:00:44Z",
            "published": "2023-11-01T05:00:44Z",
            "summary": "Because most of the scientific literature data is unmarked, it makes semantic\nrepresentation learning based on unsupervised graph become crucial. At the same\ntime, in order to enrich the features of scientific literature, a learning\nmethod of semantic representation of scientific literature based on adaptive\nfeatures and graph neural network is proposed. By introducing the adaptive\nfeature method, the features of scientific literature are considered globally\nand locally. The graph attention mechanism is used to sum the features of\nscientific literature with citation relationship, and give each scientific\nliterature different feature weights, so as to better express the correlation\nbetween the features of different scientific literature. In addition, an\nunsupervised graph neural network semantic representation learning method is\nproposed. By comparing the mutual information between the positive and negative\nlocal semantic representation of scientific literature and the global graph\nsemantic representation in the potential space, the graph neural network can\ncapture the local and global information, thus improving the learning ability\nof the semantic representation of scientific literature. The experimental\nresults show that the proposed learning method of semantic representation of\nscientific literature based on adaptive feature and graph neural network is\ncompetitive on the basis of scientific literature classification, and has\nachieved good results.",
            "author": [
                "Hongrui Gao",
                "Yawen Li",
                "Meiyu Liang",
                "Zeli Guan",
                "Zhe Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00296v1",
                "http://arxiv.org/pdf/2311.00296v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00292v1",
            "title": "IBADR: an Iterative Bias-Aware Dataset Refinement Framework for\n  Debiasing NLU models",
            "updated": "2023-11-01T04:50:38Z",
            "published": "2023-11-01T04:50:38Z",
            "summary": "As commonly-used methods for debiasing natural language understanding (NLU)\nmodels, dataset refinement approaches heavily rely on manual data analysis, and\nthus maybe unable to cover all the potential biased features. In this paper, we\npropose IBADR, an Iterative Bias-Aware Dataset Refinement framework, which\ndebiases NLU models without predefining biased features. We maintain an\niteratively expanded sample pool. Specifically, at each iteration, we first\ntrain a shallow model to quantify the bias degree of samples in the pool. Then,\nwe pair each sample with a bias indicator representing its bias degree, and use\nthese extended samples to train a sample generator. In this way, this generator\ncan effectively learn the correspondence relationship between bias indicators\nand samples. Furthermore, we employ the generator to produce pseudo samples\nwith fewer biased features by feeding specific bias indicators. Finally, we\nincorporate the generated pseudo samples into the pool. Experimental results\nand in-depth analyses on two NLU tasks show that IBADR not only significantly\noutperforms existing dataset refinement approaches, achieving SOTA, but also is\ncompatible with model-centric methods.",
            "author": [
                "Xiaoyue Wang",
                "Xin Liu",
                "Lijie Wang",
                "Yaoxiang Wang",
                "Jinsong Su",
                "Hua Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00292v1",
                "http://arxiv.org/pdf/2311.00292v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00291v1",
            "title": "Graph Representation Learning for Infrared and Visible Image Fusion",
            "updated": "2023-11-01T04:46:20Z",
            "published": "2023-11-01T04:46:20Z",
            "summary": "Infrared and visible image fusion aims to extract complementary features to\nsynthesize a single fused image. Many methods employ convolutional neural\nnetworks (CNNs) to extract local features due to its translation invariance and\nlocality. However, CNNs fail to consider the image's non-local self-similarity\n(NLss), though it can expand the receptive field by pooling operations, it\nstill inevitably leads to information loss. In addition, the transformer\nstructure extracts long-range dependence by considering the correlativity among\nall image patches, leading to information redundancy of such transformer-based\nmethods. However, graph representation is more flexible than grid (CNN) or\nsequence (transformer structure) representation to address irregular objects,\nand graph can also construct the relationships among the spatially repeatable\ndetails or texture with far-space distance. Therefore, to address the above\nissues, it is significant to convert images into the graph space and thus adopt\ngraph convolutional networks (GCNs) to extract NLss. This is because the graph\ncan provide a fine structure to aggregate features and propagate information\nacross the nearest vertices without introducing redundant information.\nConcretely, we implement a cascaded NLss extraction pattern to extract NLss of\nintra- and inter-modal by exploring interactions of different image pixels in\nintra- and inter-image positional distance. We commence by preforming GCNs on\neach intra-modal to aggregate features and propagate information to extract\nindependent intra-modal NLss. Then, GCNs are performed on the concatenate\nintra-modal NLss features of infrared and visible images, which can explore the\ncross-domain NLss of inter-modal to reconstruct the fused image. Ablation\nstudies and extensive experiments illustrates the effectiveness and superiority\nof the proposed method on three datasets.",
            "author": [
                "Jing Li",
                "Lu Bai",
                "Bin Yang",
                "Chang Li",
                "Lingfei Ma",
                "Edwin R. Hancock"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00291v1",
                "http://arxiv.org/pdf/2311.00291v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00290v2",
            "title": "Inference of CO2 flow patterns -- a feasibility study",
            "updated": "2023-11-29T01:55:38Z",
            "published": "2023-11-01T04:41:25Z",
            "summary": "As the global deployment of carbon capture and sequestration (CCS) technology\nintensifies in the fight against climate change, it becomes increasingly\nimperative to establish robust monitoring and detection mechanisms for\npotential underground CO2 leakage, particularly through pre-existing or induced\nfaults in the storage reservoir's seals. While techniques such as history\nmatching and time-lapse seismic monitoring of CO2 storage have been used\nsuccessfully in tracking the evolution of CO2 plumes in the subsurface, these\nmethods lack principled approaches to characterize uncertainties related to the\nCO2 plumes' behavior. Inclusion of systematic assessment of uncertainties is\nessential for risk mitigation for the following reasons: (i) CO2 plume-induced\nchanges are small and seismic data is noisy; (ii) changes between regular and\nirregular (e.g., caused by leakage) flow patterns are small; and (iii) the\nreservoir properties that control the flow are strongly heterogeneous and\ntypically only available as distributions. To arrive at a formulation capable\nof inferring flow patterns for regular and irregular flow from well and seismic\ndata, the performance of conditional normalizing flow will be analyzed on a\nseries of carefully designed numerical experiments. While the inferences\npresented are preliminary in the context of an early CO2 leakage detection\nsystem, the results do indicate that inferences with conditional normalizing\nflows can produce high-fidelity estimates for CO2 plumes with or without\nleakage. We are also confident that the inferred uncertainty is reasonable\nbecause it correlates well with the observed errors. This uncertainty stems\nfrom noise in the seismic data and from the lack of precise knowledge of the\nreservoir's fluid flow properties.",
            "author": [
                "Abhinav Prakash Gahlot",
                "Huseyin Tuna Erdinc",
                "Rafael Orozco",
                "Ziyi Yin",
                "Felix J. Herrmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00290v2",
                "http://arxiv.org/pdf/2311.00290v2"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.AI",
                "cs.LG",
                "math-ph",
                "math.MP",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00289v1",
            "title": "Precise Error Rates for Computationally Efficient Testing",
            "updated": "2023-11-01T04:41:16Z",
            "published": "2023-11-01T04:41:16Z",
            "summary": "We revisit the fundamental question of simple-versus-simple hypothesis\ntesting with an eye towards computational complexity, as the statistically\noptimal likelihood ratio test is often computationally intractable in\nhigh-dimensional settings. In the classical spiked Wigner model (with a general\ni.i.d. spike prior) we show that an existing test based on linear spectral\nstatistics achieves the best possible tradeoff curve between type I and type II\nerror rates among all computationally efficient tests, even though there are\nexponential-time tests that do better. This result is conditional on an\nappropriate complexity-theoretic conjecture, namely a natural strengthening of\nthe well-established low-degree conjecture. Our result shows that the spectrum\nis a sufficient statistic for computationally bounded tests (but not for all\ntests).\n  To our knowledge, our approach gives the first tool for reasoning about the\nprecise asymptotic testing error achievable with efficient computation. The\nmain ingredients required for our hardness result are a sharp bound on the norm\nof the low-degree likelihood ratio along with (counterintuitively) a positive\nresult on achievability of testing. This strategy appears to be new even in the\nsetting of unbounded computation, in which case it gives an alternate way to\nanalyze the fundamental statistical limits of testing.",
            "author": [
                "Ankur Moitra",
                "Alexander S. Wein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00289v1",
                "http://arxiv.org/pdf/2311.00289v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00287v1",
            "title": "Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data\n  Generation with Large Language Models",
            "updated": "2023-11-01T04:37:28Z",
            "published": "2023-11-01T04:37:28Z",
            "summary": "Clinical natural language processing requires methods that can address\ndomain-specific challenges, such as complex medical terminology and clinical\ncontexts. Recently, large language models (LLMs) have shown promise in this\ndomain. Yet, their direct deployment can lead to privacy issues and are\nconstrained by resources. To address this challenge, we delve into synthetic\nclinical text generation using LLMs for clinical NLP tasks. We propose an\ninnovative, resource-efficient approach, ClinGen, which infuses knowledge into\nthe process. Our model involves clinical knowledge extraction and\ncontext-informed LLM prompting. Both clinical topics and writing styles are\ndrawn from external domain-specific knowledge graphs and LLMs to guide data\ngeneration. Our extensive empirical study across 7 clinical NLP tasks and 16\ndatasets reveals that ClinGen consistently enhances performance across various\ntasks, effectively aligning the distribution of real datasets and significantly\nenriching the diversity of generated training instances. We will publish our\ncode and all the generated data in \\url{https://github.com/ritaranx/ClinGen}.",
            "author": [
                "Ran Xu",
                "Hejie Cui",
                "Yue Yu",
                "Xuan Kan",
                "Wenqi Shi",
                "Yuchen Zhuang",
                "Wei Jin",
                "Joyce Ho",
                "Carl Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00287v1",
                "http://arxiv.org/pdf/2311.00287v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00286v2",
            "title": "JADE: A Linguistics-based Safety Evaluation Platform for LLM",
            "updated": "2023-11-02T02:36:47Z",
            "published": "2023-11-01T04:36:45Z",
            "summary": "In this paper, we present JADE, a targeted linguistic fuzzing platform which\nstrengthens the linguistic complexity of seed questions to simultaneously and\nconsistently break a wide range of widely-used LLMs categorized in three\ngroups: eight open-sourced Chinese, six commercial Chinese and four commercial\nEnglish LLMs. JADE generates three safety benchmarks for the three groups of\nLLMs, which contain unsafe questions that are highly threatening: the questions\nsimultaneously trigger harmful generation of multiple LLMs, with an average\nunsafe generation ratio of $70\\%$ (please see the table below), while are still\nnatural questions, fluent and preserving the core unsafe semantics. We release\nthe benchmark demos generated for commercial English LLMs and open-sourced\nEnglish LLMs in the following link: https://github.com/whitzard-ai/jade-db. For\nreaders who are interested in evaluating on more questions generated by JADE,\nplease contact us.\n  JADE is based on Noam Chomsky's seminal theory of transformational-generative\ngrammar. Given a seed question with unsafe intention, JADE invokes a sequence\nof generative and transformational rules to increment the complexity of the\nsyntactic structure of the original question, until the safety guardrail is\nbroken. Our key insight is: Due to the complexity of human language, most of\nthe current best LLMs can hardly recognize the invariant evil from the infinite\nnumber of different syntactic structures which form an unbound example space\nthat can never be fully covered. Technically, the generative/transformative\nrules are constructed by native speakers of the languages, and, once developed,\ncan be used to automatically grow and transform the parse tree of a given\nquestion, until the guardrail is broken. For more evaluation results and demo,\nplease check our website: https://whitzard-ai.github.io/jade.html.",
            "author": [
                "Mi Zhang",
                "Xudong Pan",
                "Min Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00286v2",
                "http://arxiv.org/pdf/2311.00286v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00285v1",
            "title": "Mixture-of-Experts for Open Set Domain Adaptation: A Dual-Space\n  Detection Approach",
            "updated": "2023-11-01T04:36:18Z",
            "published": "2023-11-01T04:36:18Z",
            "summary": "Open Set Domain Adaptation (OSDA) aims to cope with the distribution and\nlabel shifts between the source and target domains simultaneously, performing\naccurate classification for known classes while identifying unknown class\nsamples in the target domain. Most existing OSDA approaches, depending on the\nfinal image feature space of deep models, require manually-tuned thresholds,\nand may easily misclassify unknown samples as known classes. Mixture-of-Expert\n(MoE) could be a remedy. Within an MoE, different experts address different\ninput features, producing unique expert routing patterns for different classes\nin a routing feature space. As a result, unknown class samples may also display\ndifferent expert routing patterns to known classes. This paper proposes\nDual-Space Detection, which exploits the inconsistencies between the image\nfeature space and the routing feature space to detect unknown class samples\nwithout any threshold. Graph Router is further introduced to better make use of\nthe spatial information among image patches. Experiments on three different\ndatasets validated the effectiveness and superiority of our approach. The code\nwill come soon.",
            "author": [
                "Zhenbang Du",
                "Jiayu An",
                "Jiahao Hong",
                "Dongrui Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00285v1",
                "http://arxiv.org/pdf/2311.00285v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00284v1",
            "title": "Model-driven Engineering for Machine Learning Components: A Systematic\n  Literature Review",
            "updated": "2023-11-01T04:29:47Z",
            "published": "2023-11-01T04:29:47Z",
            "summary": "Context: Machine Learning (ML) has become widely adopted as a component in\nmany modern software applications. Due to the large volumes of data available,\norganizations want to increasingly leverage their data to extract meaningful\ninsights and enhance business profitability. ML components enable predictive\ncapabilities, anomaly detection, recommendation, accurate image and text\nprocessing, and informed decision-making. However, developing systems with ML\ncomponents is not trivial; it requires time, effort, knowledge, and expertise\nin ML, data processing, and software engineering. There have been several\nstudies on the use of model-driven engineering (MDE) techniques to address\nthese challenges when developing traditional software and cyber-physical\nsystems. Recently, there has been a growing interest in applying MDE for\nsystems with ML components. Objective: The goal of this study is to further\nexplore the promising intersection of MDE with ML (MDE4ML) through a systematic\nliterature review (SLR). Through this SLR, we wanted to analyze existing\nstudies, including their motivations, MDE solutions, evaluation techniques, key\nbenefits and limitations. Results: We analyzed selected studies with respect to\nseveral areas of interest and identified the following: 1) the key motivations\nbehind using MDE4ML; 2) a variety of MDE solutions applied, such as modeling\nlanguages, model transformations, tool support, targeted ML aspects,\ncontributions and more; 3) the evaluation techniques and metrics used; and 4)\nthe limitations and directions for future work. We also discuss the gaps in\nexisting literature and provide recommendations for future research.\nConclusion: This SLR highlights current trends, gaps and future research\ndirections in the field of MDE4ML, benefiting both researchers and\npractitioners",
            "author": [
                "Hira Naveed",
                "Chetan Arora",
                "Hourieh Khalajzadeh",
                "John Grundy",
                "Omar Haggag"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00284v1",
                "http://arxiv.org/pdf/2311.00284v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00282v2",
            "title": "TLMCM Network for Medical Image Hierarchical Multi-Label Classification",
            "updated": "2023-11-11T08:16:29Z",
            "published": "2023-11-01T04:18:42Z",
            "summary": "Medical Image Hierarchical Multi-Label Classification (MI-HMC) is of\nparamount importance in modern healthcare, presenting two significant\nchallenges: data imbalance and \\textit{hierarchy constraint}. Existing\nsolutions involve complex model architecture design or domain-specific\npreprocessing, demanding considerable expertise or effort in implementation. To\naddress these limitations, this paper proposes Transfer Learning with Maximum\nConstraint Module (TLMCM) network for the MI-HMC task. The TLMCM network offers\na novel approach to overcome the aforementioned challenges, outperforming\nexisting methods based on the Area Under the Average Precision and Recall\nCurve($AU\\overline{(PRC)}$) metric. In addition, this research proposes two\nnovel accuracy metrics, $EMR$ and $HammingAccuracy$, which have not been\nextensively explored in the context of the MI-HMC task. Experimental results\ndemonstrate that the TLMCM network achieves high multi-label prediction\naccuracy($80\\%$-$90\\%$) for MI-HMC tasks, making it a valuable contribution to\nhealthcare domain applications.",
            "author": [
                "Meng Wu",
                "Siyan Luo",
                "Qiyu Wu",
                "Wenbin Ouyang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00282v2",
                "http://arxiv.org/pdf/2311.00282v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00277v2",
            "title": "OpenForest: A data catalogue for machine learning in forest monitoring",
            "updated": "2023-11-02T02:44:27Z",
            "published": "2023-11-01T03:59:20Z",
            "summary": "Forests play a crucial role in Earth's system processes and provide a suite\nof social and economic ecosystem services, but are significantly impacted by\nhuman activities, leading to a pronounced disruption of the equilibrium within\necosystems. Advancing forest monitoring worldwide offers advantages in\nmitigating human impacts and enhancing our comprehension of forest composition,\nalongside the effects of climate change. While statistical modeling has\ntraditionally found applications in forest biology, recent strides in machine\nlearning and computer vision have reached important milestones using remote\nsensing data, such as tree species identification, tree crown segmentation and\nforest biomass assessments. For this, the significance of open access data\nremains essential in enhancing such data-driven algorithms and methodologies.\nHere, we provide a comprehensive and extensive overview of 86 open access\nforest datasets across spatial scales, encompassing inventories, ground-based,\naerial-based, satellite-based recordings, and country or world maps. These\ndatasets are grouped in OpenForest, a dynamic catalogue open to contributions\nthat strives to reference all available open access forest datasets. Moreover,\nin the context of these datasets, we aim to inspire research in machine\nlearning applied to forest biology by establishing connections between\ncontemporary topics, perspectives and challenges inherent in both domains. We\nhope to encourage collaborations among scientists, fostering the sharing and\nexploration of diverse datasets through the application of machine learning\nmethods for large-scale forest monitoring. OpenForest is available at\nhttps://github.com/RolnickLab/OpenForest .",
            "author": [
                "Arthur Ouaknine",
                "Teja Kattenborn",
                "Etienne Lalibert\u00e9",
                "David Rolnick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00277v2",
                "http://arxiv.org/pdf/2311.00277v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00274v1",
            "title": "Generalization Bounds for Label Noise Stochastic Gradient Descent",
            "updated": "2023-11-01T03:51:46Z",
            "published": "2023-11-01T03:51:46Z",
            "summary": "We develop generalization error bounds for stochastic gradient descent (SGD)\nwith label noise in non-convex settings under uniform dissipativity and\nsmoothness conditions. Under a suitable choice of semimetric, we establish a\ncontraction in Wasserstein distance of the label noise stochastic gradient flow\nthat depends polynomially on the parameter dimension $d$. Using the framework\nof algorithmic stability, we derive time-independent generalisation error\nbounds for the discretized algorithm with a constant learning rate. The error\nbound we achieve scales polynomially with $d$ and with the rate of $n^{-2/3}$,\nwhere $n$ is the sample size. This rate is better than the best-known rate of\n$n^{-1/2}$ established for stochastic gradient Langevin dynamics (SGLD) --\nwhich employs parameter-independent Gaussian noise -- under similar conditions.\nOur analysis offers quantitative insights into the effect of label noise.",
            "author": [
                "Jung Eun Huh",
                "Patrick Rebeschini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00274v1",
                "http://arxiv.org/pdf/2311.00274v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00267v1",
            "title": "Rethinking Decision Transformer via Hierarchical Reinforcement Learning",
            "updated": "2023-11-01T03:32:13Z",
            "published": "2023-11-01T03:32:13Z",
            "summary": "Decision Transformer (DT) is an innovative algorithm leveraging recent\nadvances of the transformer architecture in reinforcement learning (RL).\nHowever, a notable limitation of DT is its reliance on recalling trajectories\nfrom datasets, losing the capability to seamlessly stitch sub-optimal\ntrajectories together. In this work we introduce a general sequence modeling\nframework for studying sequential decision making through the lens of\nHierarchical RL. At the time of making decisions, a high-level policy first\nproposes an ideal prompt for the current state, a low-level policy subsequently\ngenerates an action conditioned on the given prompt. We show DT emerges as a\nspecial case of this framework with certain choices of high-level and low-level\npolicies, and discuss the potential failure of these choices. Inspired by these\nobservations, we study how to jointly optimize the high-level and low-level\npolicies to enable the stitching ability, which further leads to the\ndevelopment of new offline RL algorithms. Our empirical results clearly show\nthat the proposed algorithms significantly surpass DT on several control and\nnavigation benchmarks. We hope our contributions can inspire the integration of\ntransformer architectures within the field of RL.",
            "author": [
                "Yi Ma",
                "Chenjun Xiao",
                "Hebin Liang",
                "Jianye Hao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00267v1",
                "http://arxiv.org/pdf/2311.00267v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00262v1",
            "title": "Plug-and-Play Policy Planner for Large Language Model Powered Dialogue\n  Agents",
            "updated": "2023-11-01T03:20:16Z",
            "published": "2023-11-01T03:20:16Z",
            "summary": "Proactive dialogues serve as a practical yet challenging dialogue problem in\nthe era of large language models (LLMs), where the dialogue policy planning is\nthe key to improving the proactivity of LLMs. Most existing studies enable the\ndialogue policy planning of LLMs using various prompting schemes or iteratively\nenhance this capability in handling the given case with verbal AI feedback.\nHowever, these approaches are either bounded by the policy planning capability\nof the frozen LLMs or hard to be transferred to new cases. In this work, we\nintroduce a new dialogue policy planning paradigm to strategize LLMs for\nproactive dialogue problems with a tunable language model plug-in as a\nplug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a\nnovel training framework to facilitate supervised fine-tuning over available\nhuman-annotated data as well as reinforcement learning from goal-oriented AI\nfeedback with dynamic interaction data collected by the LLM-based self-play\nsimulation. In this manner, the LLM-powered dialogue agent can not only be\ngeneralized to different cases after the training, but also be applicable to\ndifferent applications by just substituting the learned plug-in. In addition,\nwe propose to evaluate the policy planning capability of dialogue systems under\nthe interactive setting. Experimental results demonstrate that PPDPP\nconsistently and substantially outperforms existing approaches on three\ndifferent proactive dialogue applications, including negotiation, emotional\nsupport, and tutoring dialogues.",
            "author": [
                "Yang Deng",
                "Wenxuan Zhang",
                "Wai Lam",
                "See-Kiong Ng",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00262v1",
                "http://arxiv.org/pdf/2311.00262v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00260v1",
            "title": "Incentivized Collaboration in Active Learning",
            "updated": "2023-11-01T03:17:39Z",
            "published": "2023-11-01T03:17:39Z",
            "summary": "In collaborative active learning, where multiple agents try to learn labels\nfrom a common hypothesis, we introduce an innovative framework for incentivized\ncollaboration. Here, rational agents aim to obtain labels for their data sets\nwhile keeping label complexity at a minimum. We focus on designing (strict)\nindividually rational (IR) collaboration protocols, ensuring that agents cannot\nreduce their expected label complexity by acting individually. We first show\nthat given any optimal active learning algorithm, the collaboration protocol\nthat runs the algorithm as is over the entire data is already IR. However,\ncomputing the optimal algorithm is NP-hard. We therefore provide collaboration\nprotocols that achieve (strict) IR and are comparable with the best known\ntractable approximation algorithm in terms of label complexity.",
            "author": [
                "Lee Cohen",
                "Han Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00260v1",
                "http://arxiv.org/pdf/2311.00260v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00259v1",
            "title": "Solutions to Elliptic and Parabolic Problems via Finite Difference Based\n  Unsupervised Small Linear Convolutional Neural Networks",
            "updated": "2023-11-01T03:15:10Z",
            "published": "2023-11-01T03:15:10Z",
            "summary": "In recent years, there has been a growing interest in leveraging deep\nlearning and neural networks to address scientific problems, particularly in\nsolving partial differential equations (PDEs). However, current neural\nnetwork-based PDE solvers often rely on extensive training data or labeled\ninput-output pairs, making them prone to challenges in generalizing to\nout-of-distribution examples. To mitigate the generalization gap encountered by\nconventional neural network-based methods in estimating PDE solutions, we\nformulate a fully unsupervised approach, requiring no training data, to\nestimate finite difference solutions for PDEs directly via small convolutional\nneural networks. Our proposed algorithms demonstrate a comparable accuracy to\nthe true solution for several selected elliptic and parabolic problems compared\nto the finite difference method.",
            "author": [
                "Adrian Celaya",
                "Keegan Kirk",
                "David Fuentes",
                "Beatrice Riviere"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00259v1",
                "http://arxiv.org/pdf/2311.00259v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00258v1",
            "title": "Noisy Exemplars Make Large Language Models More Robust: A\n  Domain-Agnostic Behavioral Analysis",
            "updated": "2023-11-01T03:15:05Z",
            "published": "2023-11-01T03:15:05Z",
            "summary": "Recent advances in prompt engineering enable large language models (LLMs) to\nsolve multi-hop logical reasoning problems with impressive accuracy. However,\nthere is little existing work investigating the robustness of LLMs with\nfew-shot prompting techniques. Therefore, we introduce a systematic approach to\ntest the robustness of LLMs in multi-hop reasoning tasks via domain-agnostic\nperturbations. We include perturbations at multiple levels of abstractions\n(e.g. lexical perturbations such as typos, and semantic perturbations such as\nthe inclusion of intermediate reasoning steps in the questions) to conduct\nbehavioral analysis on the LLMs. Throughout our experiments, we find that\nmodels are more sensitive to certain perturbations such as replacing words with\ntheir synonyms. We also demonstrate that increasing the proportion of perturbed\nexemplars in the prompts improves the robustness of few-shot prompting methods.",
            "author": [
                "Hongyi Zheng",
                "Abulhair Saparov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00258v1",
                "http://arxiv.org/pdf/2311.00258v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00252v1",
            "title": "Active Neural Topological Mapping for Multi-Agent Exploration",
            "updated": "2023-11-01T03:06:14Z",
            "published": "2023-11-01T03:06:14Z",
            "summary": "This paper investigates the multi-agent cooperative exploration problem,\nwhich requires multiple agents to explore an unseen environment via sensory\nsignals in a limited time. A popular approach to exploration tasks is to\ncombine active mapping with planning. Metric maps capture the details of the\nspatial representation, but are with high communication traffic and may vary\nsignificantly between scenarios, resulting in inferior generalization.\nTopological maps are a promising alternative as they consist only of nodes and\nedges with abstract but essential information and are less influenced by the\nscene structures. However, most existing topology-based exploration tasks\nutilize classical methods for planning, which are time-consuming and\nsub-optimal due to their handcrafted design. Deep reinforcement learning (DRL)\nhas shown great potential for learning (near) optimal policies through fast\nend-to-end inference. In this paper, we propose Multi-Agent Neural Topological\nMapping (MANTM) to improve exploration efficiency and generalization for\nmulti-agent exploration tasks. MANTM mainly comprises a Topological Mapper and\na novel RL-based Hierarchical Topological Planner (HTP). The Topological Mapper\nemploys a visual encoder and distance-based heuristics to construct a graph\ncontaining main nodes and their corresponding ghost nodes. The HTP leverages\ngraph neural networks to capture correlations between agents and graph nodes in\na coarse-to-fine manner for effective global goal selection. Extensive\nexperiments conducted in a physically-realistic simulator, Habitat, demonstrate\nthat MANTM reduces the steps by at least 26.40% over planning-based baselines\nand by at least 7.63% over RL-based competitors in unseen scenarios.",
            "author": [
                "Xinyi Yang",
                "Yuxiang Yang",
                "Chao Yu",
                "Jiayu Chen",
                "Jingchen Yu",
                "Haibing Ren",
                "Huazhong Yang",
                "Yu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00252v1",
                "http://arxiv.org/pdf/2311.00252v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00246v1",
            "title": "RAUNE-Net: A Residual and Attention-Driven Underwater Image Enhancement\n  Method",
            "updated": "2023-11-01T03:00:07Z",
            "published": "2023-11-01T03:00:07Z",
            "summary": "Underwater image enhancement (UIE) poses challenges due to distinctive\nproperties of the underwater environment, including low contrast, high\nturbidity, visual blurriness, and color distortion. In recent years, the\napplication of deep learning has quietly revolutionized various areas of\nscientific research, including UIE. However, existing deep learning-based UIE\nmethods generally suffer from issues of weak robustness and limited\nadaptability. In this paper, inspired by residual and attention mechanisms, we\npropose a more reliable and reasonable UIE network called RAUNE-Net by\nemploying residual learning of high-level features at the network's bottle-neck\nand two aspects of attention manipulations in the down-sampling procedure.\nFurthermore, we collect and create two datasets specifically designed for\nevaluating UIE methods, which contains different types of underwater\ndistortions and degradations. The experimental validation demonstrates that our\nmethod obtains promising objective performance and consistent visual results\nacross various real-world underwater images compared to other eight UIE\nmethods. Our example code and datasets are publicly available at\nhttps://github.com/fansuregrin/RAUNE-Net.",
            "author": [
                "Wangzhen Peng",
                "Chenghao Zhou",
                "Runze Hu",
                "Jingchao Cao",
                "Yutao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00246v1",
                "http://arxiv.org/pdf/2311.00246v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00241v1",
            "title": "1DFormer: Learning 1D Landmark Representations via Transformer for\n  Facial Landmark Tracking",
            "updated": "2023-11-01T02:49:25Z",
            "published": "2023-11-01T02:49:25Z",
            "summary": "Recently, heatmap regression methods based on 1D landmark representations\nhave shown prominent performance on locating facial landmarks. However,\nprevious methods ignored to make deep explorations on the good potentials of 1D\nlandmark representations for sequential and structural modeling of multiple\nlandmarks to track facial landmarks. To address this limitation, we propose a\nTransformer architecture, namely 1DFormer, which learns informative 1D landmark\nrepresentations by capturing the dynamic and the geometric patterns of\nlandmarks via token communications in both temporal and spatial dimensions for\nfacial landmark tracking. For temporal modeling, we propose a recurrent token\nmixing mechanism, an axis-landmark-positional embedding mechanism, as well as a\nconfidence-enhanced multi-head attention mechanism to adaptively and robustly\nembed long-term landmark dynamics into their 1D representations; for structure\nmodeling, we design intra-group and inter-group structure modeling mechanisms\nto encode the component-level as well as global-level facial structure patterns\nas a refinement for the 1D representations of landmarks through token\ncommunications in the spatial dimension via 1D convolutional layers.\nExperimental results on the 300VW and the TF databases show that 1DFormer\nsuccessfully models the long-range sequential patterns as well as the inherent\nfacial structures to learn informative 1D representations of landmark\nsequences, and achieves state-of-the-art performance on facial landmark\ntracking.",
            "author": [
                "Shi Yin",
                "Shijie Huan",
                "Defu Lian",
                "Shangfei Wang",
                "Jinshui Hu",
                "Tao Guo",
                "Bing Yin",
                "Baocai Yin",
                "Cong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00241v1",
                "http://arxiv.org/pdf/2311.00241v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00237v1",
            "title": "The Mystery and Fascination of LLMs: A Comprehensive Survey on the\n  Interpretation and Analysis of Emergent Abilities",
            "updated": "2023-11-01T02:40:42Z",
            "published": "2023-11-01T02:40:42Z",
            "summary": "Understanding emergent abilities, such as in-context learning (ICL) and\nchain-of-thought (CoT) prompting in large language models (LLMs), is of utmost\nimportance. This importance stems not only from the better utilization of these\ncapabilities across various tasks, but also from the proactive identification\nand mitigation of potential risks, including concerns of truthfulness, bias,\nand toxicity, that may arise alongside these capabilities. In this paper, we\npresent a thorough survey on the interpretation and analysis of emergent\nabilities of LLMs. First, we provide a concise introduction to the background\nand definition of emergent abilities. Then, we give an overview of advancements\nfrom two perspectives: 1) a macro perspective, emphasizing studies on the\nmechanistic interpretability and delving into the mathematical foundations\nbehind emergent abilities; and 2) a micro-perspective, concerning studies that\nfocus on empirical interpretability by examining factors associated with these\nabilities. We conclude by highlighting the challenges encountered and\nsuggesting potential avenues for future research. We believe that our work\nestablishes the basis for further exploration into the interpretation of\nemergent abilities.",
            "author": [
                "Yuxiang Zhou",
                "Jiazheng Li",
                "Yanzheng Xiang",
                "Hanqi Yan",
                "Lin Gui",
                "Yulan He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00237v1",
                "http://arxiv.org/pdf/2311.00237v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00236v1",
            "title": "Objectives and Key Results in Software Teams: Challenges, Opportunities\n  and Impact on Development",
            "updated": "2023-11-01T02:39:01Z",
            "published": "2023-11-01T02:39:01Z",
            "summary": "Building software, like building almost anything, requires people to\nunderstand a common goal and work together towards it. In large software\ncompanies, a VP or Director will have an idea or goal and it is often the job\nof middle management to distill that lofty, general idea into manageable,\nfinite units of work. How do organizations do this hard work of setting and\nmeasuring progress towards goals? To understand this question, we undertook a\nmixed methods approach to studying goal setting, management dissemination of\ngoals, goal tracking and ultimately software delivery at a large multi-national\nsoftware company.\n  Semi-structured interviews with 47 participants were analyzed and used to\ndevelop a survey which was deployed to a multi-national team of over 4,000\nengineers. The 512 responses were analyzed using thematic analysis, linear\nregressions and hypothesis testing, and found that tracking, measuring and\nsetting goals is hard work, regardless of tools used. Middle management seems\nto be a critical component of the translation of lofty goals to actionable work\nitems. In addition, attitudes and beliefs of engineers are critical to the\nsuccess of any goal setting framework. Based on this research, we make\nrecommendations on how to improve the goal setting and OKR process in software\norganizations: invest in the data pipeline, increase transparency, improve\ncommunication, promote learning communities, and a structured roll out of OKRs.",
            "author": [
                "Jenna Butler",
                "Thomas Zimmermann",
                "Christian Bird"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00236v1",
                "http://arxiv.org/pdf/2311.00236v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00235v1",
            "title": "Implicit biases in multitask and continual learning from a backward\n  error analysis perspective",
            "updated": "2023-11-01T02:37:32Z",
            "published": "2023-11-01T02:37:32Z",
            "summary": "Using backward error analysis, we compute implicit training biases in\nmultitask and continual learning settings for neural networks trained with\nstochastic gradient descent. In particular, we derive modified losses that are\nimplicitly minimized during training. They have three terms: the original loss,\naccounting for convergence, an implicit flatness regularization term\nproportional to the learning rate, and a last term, the conflict term, which\ncan theoretically be detrimental to both convergence and implicit\nregularization. In multitask, the conflict term is a well-known quantity,\nmeasuring the gradient alignment between the tasks, while in continual learning\nthe conflict term is a new quantity in deep learning optimization, although a\nbasic tool in differential geometry: The Lie bracket between the task\ngradients.",
            "author": [
                "Benoit Dherin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00235v1",
                "http://arxiv.org/pdf/2311.00235v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00231v1",
            "title": "DistDNAS: Search Efficient Feature Interactions within 2 Hours",
            "updated": "2023-11-01T02:27:38Z",
            "published": "2023-11-01T02:27:38Z",
            "summary": "Search efficiency and serving efficiency are two major axes in building\nfeature interactions and expediting the model development process in\nrecommender systems. On large-scale benchmarks, searching for the optimal\nfeature interaction design requires extensive cost due to the sequential\nworkflow on the large volume of data. In addition, fusing interactions of\nvarious sources, orders, and mathematical operations introduces potential\nconflicts and additional redundancy toward recommender models, leading to\nsub-optimal trade-offs in performance and serving cost. In this paper, we\npresent DistDNAS as a neat solution to brew swift and efficient feature\ninteraction design. DistDNAS proposes a supernet to incorporate interaction\nmodules of varying orders and types as a search space. To optimize search\nefficiency, DistDNAS distributes the search and aggregates the choice of\noptimal interaction modules on varying data dates, achieving over 25x speed-up\nand reducing search cost from 2 days to 2 hours. To optimize serving\nefficiency, DistDNAS introduces a differentiable cost-aware loss to penalize\nthe selection of redundant interaction modules, enhancing the efficiency of\ndiscovered feature interactions in serving. We extensively evaluate the best\nmodels crafted by DistDNAS on a 1TB Criteo Terabyte dataset. Experimental\nevaluations demonstrate 0.001 AUC improvement and 60% FLOPs saving over current\nstate-of-the-art CTR models.",
            "author": [
                "Tunhou Zhang",
                "Wei Wen",
                "Igor Fedorov",
                "Xi Liu",
                "Buyun Zhang",
                "Fangqiu Han",
                "Wen-Yen Chen",
                "Yiping Han",
                "Feng Yan",
                "Hai Li",
                "Yiran Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00231v1",
                "http://arxiv.org/pdf/2311.00231v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00227v1",
            "title": "StableFDG: Style and Attention Based Learning for Federated Domain\n  Generalization",
            "updated": "2023-11-01T02:17:01Z",
            "published": "2023-11-01T02:17:01Z",
            "summary": "Traditional federated learning (FL) algorithms operate under the assumption\nthat the data distributions at training (source domains) and testing (target\ndomain) are the same. The fact that domain shifts often occur in practice\nnecessitates equipping FL methods with a domain generalization (DG) capability.\nHowever, existing DG algorithms face fundamental challenges in FL setups due to\nthe lack of samples/domains in each client's local dataset. In this paper, we\npropose StableFDG, a style and attention based learning strategy for\naccomplishing federated domain generalization, introducing two key\ncontributions. The first is style-based learning, which enables each client to\nexplore novel styles beyond the original source domains in its local dataset,\nimproving domain diversity based on the proposed style sharing, shifting, and\nexploration strategies. Our second contribution is an attention-based feature\nhighlighter, which captures the similarities between the features of data\nsamples in the same class, and emphasizes the important/common characteristics\nto better learn the domain-invariant characteristics of each class in data-poor\nFL scenarios. Experimental results show that StableFDG outperforms existing\nbaselines on various DG benchmark datasets, demonstrating its efficacy.",
            "author": [
                "Jungwuk Park",
                "Dong-Jun Han",
                "Jinho Kim",
                "Shiqiang Wang",
                "Christopher G. Brinton",
                "Jaekyun Moon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00227v1",
                "http://arxiv.org/pdf/2311.00227v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00226v2",
            "title": "Transformers are Efficient In-Context Estimators for Wireless\n  Communication",
            "updated": "2023-12-03T04:31:28Z",
            "published": "2023-11-01T02:16:24Z",
            "summary": "Pre-trained transformers can perform in-context learning, where they adapt to\na new task using only a small number of prompts without any explicit model\noptimization. Inspired by this attribute, we propose a novel approach, called\nin-context estimation, for the canonical communication problem of estimating\ntransmitted symbols from received symbols. A communication channel is\nessentially a noisy function that maps transmitted symbols to received symbols,\nand this function can be represented by an unknown parameter whose statistics\ndepend on an (also unknown) latent context. Conventional approaches typically\ndo not fully exploit hierarchical model with the latent context. Instead, they\noften use mismatched priors to form a linear minimum mean-squared error\nestimate of the channel parameter, which is then used to estimate successive,\nunknown transmitted symbols. We make the basic connection that transformers\nshow excellent contextual sequence completion with a few prompts, and so they\nshould be able to implicitly determine the latent context from pilot symbols to\nperform end-to-end in-context estimation of transmitted symbols. Furthermore,\nthe transformer should use information efficiently, i.e., it should utilize any\npilots received to attain the best possible symbol estimates. Through extensive\nsimulations, we show that in-context estimation not only significantly\noutperforms standard approaches, but also achieves the same performance as an\nestimator with perfect knowledge of the latent context within a few context\nexamples. Thus, we make a strong case that transformers are efficient\nin-context estimators in the communication setting.",
            "author": [
                "Vicram Rajagopalan",
                "Vishnu Teja Kunde",
                "Chandra Shekhara Kaushik Valmeekam",
                "Krishna Narayanan",
                "Srinivas Shakkottai",
                "Dileep Kalathil",
                "Jean-Francois Chamberland"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00226v2",
                "http://arxiv.org/pdf/2311.00226v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00214v1",
            "title": "WinNet:time series forecasting with a window-enhanced period extracting\n  and interacting",
            "updated": "2023-11-01T01:23:59Z",
            "published": "2023-11-01T01:23:59Z",
            "summary": "Recently, Transformer-based methods have significantly improved\nstate-of-the-art time series forecasting results, but they suffer from high\ncomputational costs and the inability to capture the long and short periodicity\nof time series. We present a highly accurate and simply structured CNN-based\nmodel for long-term time series forecasting tasks, called WinNet, including (i)\nInter-Intra Period Encoder (I2PE) to transform 1D sequence into 2D tensor with\nlong and short periodicity according to the predefined periodic window, (ii)\nTwo-Dimensional Period Decomposition (TDPD) to model period-trend and\noscillation terms, and (iii) Decomposition Correlation Block (DCB) to leverage\nthe correlations of the period-trend and oscillation terms to support the\nprediction tasks by CNNs. Results on nine benchmark datasets show that the\nWinNet can achieve SOTA performance and lower computational complexity over\nCNN-, MLP-, Transformer-based approaches. The WinNet provides potential for the\nCNN-based methods in the time series forecasting tasks, with perfect tradeoff\nbetween performance and efficiency.",
            "author": [
                "Wenjie Ou",
                "Dongyue Guo",
                "Zheng Zhang",
                "Zhishuo Zhao",
                "Yi Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00214v1",
                "http://arxiv.org/pdf/2311.00214v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00212v1",
            "title": "A Unified Framework to Enforce, Discover, and Promote Symmetry in\n  Machine Learning",
            "updated": "2023-11-01T01:19:54Z",
            "published": "2023-11-01T01:19:54Z",
            "summary": "Symmetry is present throughout nature and continues to play an increasingly\ncentral role in physics and machine learning. Fundamental symmetries, such as\nPoincar\\'{e} invariance, allow physical laws discovered in laboratories on\nEarth to be extrapolated to the farthest reaches of the universe. Symmetry is\nessential to achieving this extrapolatory power in machine learning\napplications. For example, translation invariance in image classification\nallows models with fewer parameters, such as convolutional neural networks, to\nbe trained on smaller data sets and achieve state-of-the-art performance. In\nthis paper, we provide a unifying theoretical and methodological framework for\nincorporating symmetry into machine learning models in three ways: 1. enforcing\nknown symmetry when training a model; 2. discovering unknown symmetries of a\ngiven model or data set; and 3. promoting symmetry during training by learning\na model that breaks symmetries within a user-specified group of candidates when\nthere is sufficient evidence in the data. We show that these tasks can be cast\nwithin a common mathematical framework whose central object is the Lie\nderivative associated with fiber-linear Lie group actions on vector bundles. We\nextend and unify several existing results by showing that enforcing and\ndiscovering symmetry are linear-algebraic tasks that are dual with respect to\nthe bilinear structure of the Lie derivative. We also propose a novel way to\npromote symmetry by introducing a class of convex regularization functions\nbased on the Lie derivative and nuclear norm relaxation to penalize symmetry\nbreaking during training of machine learning models. We explain how these ideas\ncan be applied to a wide range of machine learning models including basis\nfunction regression, dynamical systems discovery, multilayer perceptrons, and\nneural networks acting on spatial fields such as images.",
            "author": [
                "Samuel E. Otto",
                "Nicholas Zolman",
                "J. Nathan Kutz",
                "Steven L. Brunton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00212v1",
                "http://arxiv.org/pdf/2311.00212v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.DG",
                "math.NA",
                "15B30, 22E15, 22E70, 47D03, 54H15, 57S99, 5808, 58D19, 58K70, 65F55,\n  68Q32, 68T07, 70G65, 70H33, 90C25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00210v1",
            "title": "Broken Adaptive Ridge Method for Variable Selection in Generalized\n  Partly Linear Models with Application to the Coronary Artery Disease Data",
            "updated": "2023-11-01T00:50:13Z",
            "published": "2023-11-01T00:50:13Z",
            "summary": "Motivated by the CATHGEN data, we develop a new statistical learning method\nfor simultaneous variable selection and parameter estimation under the context\nof generalized partly linear models for data with high-dimensional covariates.\nThe method is referred to as the broken adaptive ridge (BAR) estimator, which\nis an approximation of the $L_0$-penalized regression by iteratively performing\nreweighted squared $L_2$-penalized regression. The generalized partly linear\nmodel extends the generalized linear model by including a non-parametric\ncomponent to construct a flexible model for modeling various types of covariate\neffects. We employ the Bernstein polynomials as the sieve space to approximate\nthe non-parametric functions so that our method can be implemented easily using\nthe existing R packages. Extensive simulation studies suggest that the proposed\nmethod performs better than other commonly used penalty-based variable\nselection methods. We apply the method to the CATHGEN data with a binary\nresponse from a coronary artery disease study, which motivated our research,\nand obtained new findings in both high-dimensional genetic and low-dimensional\nnon-genetic covariates.",
            "author": [
                "Christian Chan",
                "Xiaotian Dai",
                "Thierry Chekouo",
                "Quan Long",
                "Xuewen Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00210v1",
                "http://arxiv.org/pdf/2311.00210v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP",
                "stat.OT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03378v1",
            "title": "Transferability and explainability of deep learning emulators for\n  regional climate model projections: Perspectives for future applications",
            "updated": "2023-11-01T00:44:39Z",
            "published": "2023-11-01T00:44:39Z",
            "summary": "Regional climate models (RCMs) are essential tools for simulating and\nstudying regional climate variability and change. However, their high\ncomputational cost limits the production of comprehensive ensembles of regional\nclimate projections covering multiple scenarios and driving Global Climate\nModels (GCMs) across regions. RCM emulators based on deep learning models have\nrecently been introduced as a cost-effective and promising alternative that\nrequires only short RCM simulations to train the models. Therefore, evaluating\ntheir transferability to different periods, scenarios, and GCMs becomes a\npivotal and complex task in which the inherent biases of both GCMs and RCMs\nplay a significant role. Here we focus on this problem by considering the two\ndifferent emulation approaches proposed in the literature (PP and MOS,\nfollowing the terminology introduced in this paper). In addition to standard\nevaluation techniques, we expand the analysis with methods from the field of\neXplainable Artificial Intelligence (XAI), to assess the physical consistency\nof the empirical links learnt by the models. We find that both approaches are\nable to emulate certain climatological properties of RCMs for different periods\nand scenarios (soft transferability), but the consistency of the emulation\nfunctions differ between approaches. Whereas PP learns robust and physically\nmeaningful patterns, MOS results are GCM-dependent and lack physical\nconsistency in some cases. Both approaches face problems when transferring the\nemulation function to other GCMs, due to the existence of GCM-dependent biases\n(hard transferability). This limits their applicability to build ensembles of\nregional climate projections. We conclude by giving some prospects for future\napplications.",
            "author": [
                "Jorge Bano-Medina",
                "Maialen Iturbide",
                "Jesus Fernandez",
                "Jose Manuel Gutierrez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03378v1",
                "http://arxiv.org/pdf/2311.03378v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00208v1",
            "title": "Transformers as Recognizers of Formal Languages: A Survey on\n  Expressivity",
            "updated": "2023-11-01T00:38:26Z",
            "published": "2023-11-01T00:38:26Z",
            "summary": "As transformers have gained prominence in natural language processing, some\nresearchers have investigated theoretically what problems they can and cannot\nsolve, by treating problems as formal languages. Exploring questions such as\nthis will help to compare transformers with other models, and transformer\nvariants with one another, for various tasks. Work in this subarea has made\nconsiderable progress in recent years. Here, we undertake a comprehensive\nsurvey of this work, documenting the diverse assumptions that underlie\ndifferent results and providing a unified framework for harmonizing seemingly\ncontradictory findings.",
            "author": [
                "Lena Strobl",
                "William Merrill",
                "Gail Weiss",
                "David Chiang",
                "Dana Angluin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00208v1",
                "http://arxiv.org/pdf/2311.00208v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.FL",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00207v1",
            "title": "Magmaw: Modality-Agnostic Adversarial Attacks on Machine Learning-Based\n  Wireless Communication Systems",
            "updated": "2023-11-01T00:33:59Z",
            "published": "2023-11-01T00:33:59Z",
            "summary": "Machine Learning (ML) has been instrumental in enabling joint transceiver\noptimization by merging all physical layer blocks of the end-to-end wireless\ncommunication systems. Although there have been a number of adversarial attacks\non ML-based wireless systems, the existing methods do not provide a\ncomprehensive view including multi-modality of the source data, common physical\nlayer components, and wireless domain constraints. This paper proposes Magmaw,\nthe first black-box attack methodology capable of generating universal\nadversarial perturbations for any multimodal signal transmitted over a wireless\nchannel. We further introduce new objectives for adversarial attacks on\nML-based downstream applications. The resilience of the attack to the existing\nwidely used defense methods of adversarial training and perturbation signal\nsubtraction is experimentally verified. For proof-of-concept evaluation, we\nbuild a real-time wireless attack platform using a software-defined radio\nsystem. Experimental results demonstrate that Magmaw causes significant\nperformance degradation even in the presence of the defense mechanisms.\nSurprisingly, Magmaw is also effective against encrypted communication channels\nand conventional communications.",
            "author": [
                "Jung-Woo Chang",
                "Ke Sun",
                "Nasimeh Heydaribeni",
                "Seira Hidano",
                "Xinyu Zhang",
                "Farinaz Koushanfar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00207v1",
                "http://arxiv.org/pdf/2311.00207v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00729v2",
            "title": "ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot\n  End-to-End Temporal Action Detection",
            "updated": "2023-11-04T23:41:21Z",
            "published": "2023-11-01T00:17:37Z",
            "summary": "Temporal action detection (TAD) involves the localization and classification\nof action instances within untrimmed videos. While standard TAD follows fully\nsupervised learning with closed-set setting on large training data, recent\nzero-shot TAD methods showcase the promising open-set setting by leveraging\nlarge-scale contrastive visual-language (ViL) pretrained models. However,\nexisting zero-shot TAD methods have limitations on how to properly construct\nthe strong relationship between two interdependent tasks of localization and\nclassification and adapt ViL model to video understanding. In this work, we\npresent ZEETAD, featuring two modules: dual-localization and zero-shot proposal\nclassification. The former is a Transformer-based module that detects action\nevents while selectively collecting crucial semantic embeddings for later\nrecognition. The latter one, CLIP-based module, generates semantic embeddings\nfrom text and frame inputs for each temporal unit. Additionally, we enhance\ndiscriminative capability on unseen classes by minimally updating the frozen\nCLIP encoder with lightweight adapters. Extensive experiments on THUMOS14 and\nActivityNet-1.3 datasets demonstrate our approach's superior performance in\nzero-shot TAD and effective knowledge transfer from ViL models to unseen action\ncategories.",
            "author": [
                "Thinh Phan",
                "Khoa Vo",
                "Duy Le",
                "Gianfranco Doretto",
                "Donald Adjeroh",
                "Ngan Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00729v2",
                "http://arxiv.org/pdf/2311.00729v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00201v1",
            "title": "Federated Natural Policy Gradient Methods for Multi-task Reinforcement\n  Learning",
            "updated": "2023-11-01T00:15:18Z",
            "published": "2023-11-01T00:15:18Z",
            "summary": "Federated reinforcement learning (RL) enables collaborative decision making\nof multiple distributed agents without sharing local data trajectories. In this\nwork, we consider a multi-task setting, in which each agent has its own private\nreward function corresponding to different tasks, while sharing the same\ntransition kernel of the environment. Focusing on infinite-horizon tabular\nMarkov decision processes, the goal is to learn a globally optimal policy that\nmaximizes the sum of the discounted total rewards of all the agents in a\ndecentralized manner, where each agent only communicates with its neighbors\nover some prescribed graph topology. We develop federated vanilla and\nentropy-regularized natural policy gradient (NPG) methods under softmax\nparameterization, where gradient tracking is applied to the global Q-function\nto mitigate the impact of imperfect information sharing. We establish\nnon-asymptotic global convergence guarantees under exact policy evaluation,\nwhich are nearly independent of the size of the state-action space and\nilluminate the impacts of network size and connectivity. To the best of our\nknowledge, this is the first time that global convergence is established for\nfederated multi-task RL using policy optimization. Moreover, the convergence\nbehavior of the proposed algorithms is robust against inexactness of policy\nevaluation.",
            "author": [
                "Tong Yang",
                "Shicong Cen",
                "Yuting Wei",
                "Yuxin Chen",
                "Yuejie Chi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00201v1",
                "http://arxiv.org/pdf/2311.00201v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00196v1",
            "title": "Machine learning for accuracy in density functional approximations",
            "updated": "2023-11-01T00:02:09Z",
            "published": "2023-11-01T00:02:09Z",
            "summary": "Machine learning techniques have found their way into computational chemistry\nas indispensable tools to accelerate atomistic simulations and materials\ndesign. In addition, machine learning approaches hold the potential to boost\nthe predictive power of computationally efficient electronic structure methods,\nsuch as density functional theory, to chemical accuracy and to correct for\nfundamental errors in density functional approaches. Here, recent progress in\napplying machine learning to improve the accuracy of density functional and\nrelated approximations is reviewed. Promises and challenges in devising machine\nlearning models transferable between different chemistries and materials\nclasses are discussed with the help of examples applying promising models to\nsystems far outside their training sets.",
            "author": [
                "Johannes Voss"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00196v1",
                "http://arxiv.org/pdf/2311.00196v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02100v1",
            "title": "A Comprehensive Study on Model Initialization Techniques Ensuring\n  Efficient Federated Learning",
            "updated": "2023-10-31T23:26:58Z",
            "published": "2023-10-31T23:26:58Z",
            "summary": "Advancement in the field of machine learning is unavoidable, but something of\nmajor concern is preserving the privacy of the users whose data is being used\nfor training these machine learning algorithms. Federated learning(FL) has\nemerged as a promising paradigm for training machine learning models in a\ndistributed and privacy-preserving manner which enables one to collaborate and\ntrain a global model without sharing local data. But starting this learning\nprocess on each device in the right way, called ``model initialization\" is\ncritical. The choice of initialization methods used for models plays a crucial\nrole in the performance, convergence speed, communication efficiency, privacy\nguarantees of federated learning systems, etc. In this survey, we dive deeper\ninto a comprehensive study of various ways of model initialization techniques\nin FL.Unlike other studies, our research meticulously compares, categorizes,\nand delineates the merits and demerits of each technique, examining their\napplicability across diverse FL scenarios. We highlight how factors like client\nvariability, data non-IIDness, model caliber, security considerations, and\nnetwork restrictions influence FL model outcomes and propose how strategic\ninitialization can address and potentially rectify many such challenges. The\nmotivation behind this survey is to highlight that the right start can help\novercome challenges like varying data quality, security issues, and network\nproblems. Our insights provide a foundational base for experts looking to fully\nutilize FL, also while understanding the complexities of model initialization.",
            "author": [
                "Ishmeet Kaur",
                "Adwaita Janardhan Jadhav"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02100v1",
                "http://arxiv.org/pdf/2311.02100v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00189v1",
            "title": "XAI-CLASS: Explanation-Enhanced Text Classification with Extremely Weak\n  Supervision",
            "updated": "2023-10-31T23:24:22Z",
            "published": "2023-10-31T23:24:22Z",
            "summary": "Text classification aims to effectively categorize documents into pre-defined\ncategories. Traditional methods for text classification often rely on large\namounts of manually annotated training data, making the process time-consuming\nand labor-intensive. To address this issue, recent studies have focused on\nweakly-supervised and extremely weakly-supervised settings, which require\nminimal or no human annotation, respectively. In previous methods of weakly\nsupervised text classification, pseudo-training data is generated by assigning\npseudo-labels to documents based on their alignment (e.g., keyword matching)\nwith specific classes. However, these methods ignore the importance of\nincorporating the explanations of the generated pseudo-labels, or saliency of\nindividual words, as additional guidance during the text classification\ntraining process. To address this limitation, we propose XAI-CLASS, a novel\nexplanation-enhanced extremely weakly-supervised text classification method\nthat incorporates word saliency prediction as an auxiliary task. XAI-CLASS\nbegins by employing a multi-round question-answering process to generate\npseudo-training data that promotes the mutual enhancement of class labels and\ncorresponding explanation word generation. This pseudo-training data is then\nused to train a multi-task framework that simultaneously learns both text\nclassification and word saliency prediction. Extensive experiments on several\nweakly-supervised text classification datasets show that XAI-CLASS outperforms\nother weakly-supervised text classification methods significantly. Moreover,\nexperiments demonstrate that XAI-CLASS enhances both model performance and\nexplainability.",
            "author": [
                "Daniel Hajialigol",
                "Hanwen Liu",
                "Xuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00189v1",
                "http://arxiv.org/pdf/2311.00189v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00188v1",
            "title": "A Two-Step Framework for Multi-Material Decomposition of Dual Energy\n  Computed Tomography from Projection Domain",
            "updated": "2023-10-31T23:23:14Z",
            "published": "2023-10-31T23:23:14Z",
            "summary": "Dual-energy computed tomography (DECT) utilizes separate X-ray energy spectra\nto improve multi-material decomposition (MMD) for various diagnostic\napplications. However accurate decomposing more than two types of material\nremains challenging using conventional methods. Deep learning (DL) methods have\nshown promise to improve the MMD performance, but typical approaches of\nconducing DL-MMD in the image domain fail to fully utilize projection\ninformation or under iterative setup are computationally inefficient in both\ntraining and prediction. In this work, we present a clinical-applicable MMD\n(>2) framework rFast-MMDNet, operating with raw projection data in\nnon-recursive setup, for breast tissue differentiation. rFast-MMDNet is a\ntwo-stage algorithm, including stage-one SinoNet to perform dual energy\nprojection decomposition on tissue sinograms and stage-two FBP-DenoiseNet to\nperform domain adaptation and image post-processing. rFast-MMDNet was tested on\na 2022 DL-Spectral-Challenge breast phantom dataset. The two stages of\nrFast-MMDNet were evaluated separately and then compared with four noniterative\nreference methods including a direct inversion method (AA-MMD), an image domain\nDL method (ID-UNet), AA-MMD/ID-UNet + DenoiseNet and a sinogram domain DL\nmethod (Triple-CBCT). Our results show that models trained from information\nstored in DE transmission domain can yield high-fidelity decomposition of the\nadipose, calcification, and fibroglandular materials with averaged RMSE, MAE,\nnegative PSNR, and SSIM of 0.004+/-~0, 0.001+/-~0, -45.027+/-~0.542, and\n0.002+/-~0 benchmarking to the ground truth, respectively. Training of entire\nrFast-MMDNet on a 4xRTX A6000 GPU cluster took a day with inference time <1s.\nAll DL methods generally led to more accurate MMD than AA-MMD. rFast-MMDNet\noutperformed Triple-CBCT, but both are superior to the image-domain based\nmethods.",
            "author": [
                "Di Xu",
                "Qihui Lyu",
                "Dan Ruan",
                "Ke Sheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00188v1",
                "http://arxiv.org/pdf/2311.00188v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00187v2",
            "title": "Decodable and Sample Invariant Continuous Object Encoder",
            "updated": "2023-11-21T15:25:15Z",
            "published": "2023-10-31T23:19:30Z",
            "summary": "We propose Hyper-Dimensional Function Encoding (HDFE). Given samples of a\ncontinuous object (e.g. a function), HDFE produces an explicit vector\nrepresentation of the given object, invariant to the sample distribution and\ndensity. Sample distribution and density invariance enables HDFE to\nconsistently encode continuous objects regardless of their sampling, and\ntherefore allows neural networks to receive continuous objects as inputs for\nmachine learning tasks, such as classification and regression. Besides, HDFE\ndoes not require any training and is proved to map the object into an organized\nembedding space, which facilitates the training of the downstream tasks. In\naddition, the encoding is decodable, which enables neural networks to regress\ncontinuous objects by regressing their encodings. Therefore, HDFE serves as an\ninterface for processing continuous objects.\n  We apply HDFE to function-to-function mapping, where vanilla HDFE achieves\ncompetitive performance as the state-of-the-art algorithm. We apply HDFE to\npoint cloud surface normal estimation, where a simple replacement from PointNet\nto HDFE leads to immediate 12% and 15% error reductions in two benchmarks. In\naddition, by integrating HDFE into the PointNet-based SOTA network, we improve\nthe SOTA baseline by 2.5% and 1.7% in the same benchmarks.",
            "author": [
                "Dehao Yuan",
                "Furong Huang",
                "Cornelia Ferm\u00fcller",
                "Yiannis Aloimonos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00187v2",
                "http://arxiv.org/pdf/2311.00187v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00186v1",
            "title": "Image Restoration with Point Spread Function Regularization and Active\n  Learning",
            "updated": "2023-10-31T23:16:26Z",
            "published": "2023-10-31T23:16:26Z",
            "summary": "Large-scale astronomical surveys can capture numerous images of celestial\nobjects, including galaxies and nebulae. Analysing and processing these images\ncan reveal intricate internal structures of these objects, allowing researchers\nto conduct comprehensive studies on their morphology, evolution, and physical\nproperties. However, varying noise levels and point spread functions can hamper\nthe accuracy and efficiency of information extraction from these images. To\nmitigate these effects, we propose a novel image restoration algorithm that\nconnects a deep learning-based restoration algorithm with a high-fidelity\ntelescope simulator. During the training stage, the simulator generates images\nwith different levels of blur and noise to train the neural network based on\nthe quality of restored images. After training, the neural network can directly\nrestore images obtained by the telescope, as represented by the simulator. We\nhave tested the algorithm using real and simulated observation data and have\nfound that it effectively enhances fine structures in blurry images and\nincreases the quality of observation images. This algorithm can be applied to\nlarge-scale sky survey data, such as data obtained by LSST, Euclid, and CSST,\nto further improve the accuracy and efficiency of information extraction,\npromoting advances in the field of astronomical research.",
            "author": [
                "Peng Jia",
                "Jiameng Lv",
                "Runyu Ning",
                "Yu Song",
                "Nan Li",
                "Kaifan Ji",
                "Chenzhou Cui",
                "Shanshan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00186v1",
                "http://arxiv.org/pdf/2311.00186v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.GA",
                "astro-ph.SR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00181v1",
            "title": "Best of Both Worlds: Stochastic and Adversarial Convex Function Chasing",
            "updated": "2023-10-31T22:59:23Z",
            "published": "2023-10-31T22:59:23Z",
            "summary": "Convex function chasing (CFC) is an online optimization problem in which\nduring each round $t$, a player plays an action $x_t$ in response to a hitting\ncost $f_t(x_t)$ and an additional cost of $c(x_t,x_{t-1})$ for switching\nactions. We study the CFC problem in stochastic and adversarial environments,\ngiving algorithms that achieve performance guarantees simultaneously in both\nsettings. Specifically, we consider the squared $\\ell_2$-norm switching costs\nand a broad class of quadratic hitting costs for which the sequence of\nminimizers either forms a martingale or is chosen adversarially. This is the\nfirst work that studies the CFC problem using a stochastic framework. We\nprovide a characterization of the optimal stochastic online algorithm and,\ndrawing a comparison between the stochastic and adversarial scenarios, we\ndemonstrate that the adversarial-optimal algorithm exhibits suboptimal\nperformance in the stochastic context. Motivated by this, we provide a\nbest-of-both-worlds algorithm that obtains robust adversarial performance while\nsimultaneously achieving near-optimal stochastic performance.",
            "author": [
                "Neelkamal Bhuyan",
                "Debankur Mukherjee",
                "Adam Wierman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00181v1",
                "http://arxiv.org/pdf/2311.00181v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DS",
                "cs.LG",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00177v1",
            "title": "Students' Perspective on AI Code Completion: Benefits and Challenges",
            "updated": "2023-10-31T22:41:16Z",
            "published": "2023-10-31T22:41:16Z",
            "summary": "AI Code Completion (e.g., GitHub's Copilot, Amazon CodeWhisperer) has\nrevolutionized the way in which computer science students interact with\nprogramming languages. However, these tools are not available for free public\nuse, preventing us from conducting our research. In addition, AI code\ncompletion has been studied from developers' perspective, not students'\nperspective who represent the future generation of our digital world. In this\narticle, we investigated the benefits, challenges, and expectations of AI code\ncompletion from students' perspectives and introduced AutoAurora, an AI code\ncompletion tool integrated into the Visual Studio Code Extension as a research\ninstrument. Through an interview study with ten participants, we found that AI\ncode completion enhanced students' productivity and efficiency by providing\ncorrect syntax suggestions, offering alternative solutions, and functioning as\na coding tutor. However, the over-reliance on AI code completion may lead to a\nsurface-level understanding of programming concepts, diminishing\nproblem-solving skills and restricting creativity. In the future, AI code\ncompletion must be explainable to facilitate the learning of coding concepts.",
            "author": [
                "Wannita Takerngsaksiri",
                "Cleshan Warusavitarne",
                "Christian Yaacoub",
                "Matthew Hee Keng Hou",
                "Chakkrit Tantithamthavorn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00177v1",
                "http://arxiv.org/pdf/2311.00177v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00170v1",
            "title": "Experimental Demonstration of Coupled Learning in Elastic Networks",
            "updated": "2023-10-31T22:09:23Z",
            "published": "2023-10-31T22:09:23Z",
            "summary": "Coupled learning is a contrastive scheme for tuning the properties of\nindividual elements within a network in order to achieve desired functionality\nof the system. It takes advantage of physics both to learn using local rules\nand to \"compute\" the output response to input data, thus enabling the system to\nperform decentralized computation without the need for a processor or external\nmemory. We demonstrate a proof-of-concept mechanical network that can learn\nsimple tasks such as self-symmetrizing via iterative tuning of individual\nspring rest lengths. These mechanical networks could feasibly be scaled and\nautomated to solve increasingly complex tasks, hinting at a new class of\n\"smart\" metamaterials.",
            "author": [
                "Lauren E. Altman",
                "Menachem Stern",
                "Andrea J. Liu",
                "Douglas J. Durian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00170v1",
                "http://arxiv.org/pdf/2311.00170v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00168v1",
            "title": "The Alignment Ceiling: Objective Mismatch in Reinforcement Learning from\n  Human Feedback",
            "updated": "2023-10-31T21:52:41Z",
            "published": "2023-10-31T21:52:41Z",
            "summary": "Reinforcement learning from human feedback (RLHF) has emerged as a powerful\ntechnique to make large language models (LLMs) easier to prompt and more\ncapable in complex settings. RLHF at its core is providing a new toolkit to\noptimize LLMs other than next-token prediction, enabling the integration of\nqualitative training goals. The attempted match between user preferences and\ndownstream performance, which happens in a learned reward model, results in an\noptimization landscape where training and evaluation metrics can appear\ncorrelated. The apparent correlation can lead to unexpected behaviors and\nstories of \"too much RLHF.\" In RLHF, challenges emerge because the following\nsub-modules are not consistent with each other: the reward model training, the\npolicy model training, and the policy model evaluation. This mismatch results\nin models that sometimes avoid user requests for false safety flags, are\ndifficult to steer to an intended characteristic, or always answer in a\nspecific style. As chat model evaluation becomes increasingly nuanced, the\nreliance on a perceived link between reward model score and downstream\nperformance drives the objective mismatch issue. In this paper, we illustrate\nthe cause of this issue, reviewing relevant literature from model-based\nreinforcement learning, and discuss relevant solutions to encourage further\nresearch. By solving objective mismatch in RLHF, the LLMs of the future will be\nmore precisely aligned to user instructions for both safety and helpfulness.",
            "author": [
                "Nathan Lambert",
                "Roberto Calandra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00168v1",
                "http://arxiv.org/pdf/2311.00168v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00167v1",
            "title": "Multi-task Deep Convolutional Network to Predict Sea Ice Concentration\n  and Drift in the Arctic Ocean",
            "updated": "2023-10-31T21:51:12Z",
            "published": "2023-10-31T21:51:12Z",
            "summary": "Forecasting sea ice concentration (SIC) and sea ice drift (SID) in the Arctic\nOcean is of great significance as the Arctic environment has been changed by\nthe recent warming climate. Given that physical sea ice models require high\ncomputational costs with complex parameterization, deep learning techniques can\neffectively replace the physical model and improve the performance of sea ice\nprediction. This study proposes a novel multi-task fully conventional network\narchitecture named hierarchical information-sharing U-net (HIS-Unet) to predict\ndaily SIC and SID. Instead of learning SIC and SID separately at each branch,\nwe allow the SIC and SID layers to share their information and assist each\nother's prediction through the weighting attention modules (WAMs).\nConsequently, our HIS-Unet outperforms other statistical approaches, sea ice\nphysical models, and neural networks without such information-sharing units.\nThe improvement of HIS-Unet is obvious both for SIC and SID prediction when and\nwhere sea ice conditions change seasonally, which implies that the information\nsharing through WAMs allows the model to learn the sudden changes of SIC and\nSID. The weight values of the WAMs imply that SIC information plays a more\ncritical role in SID prediction, compared to that of SID information in SIC\nprediction, and information sharing is more active in sea ice edges (seasonal\nsea ice) than in the central Arctic (multi-year sea ice).",
            "author": [
                "Younghyun Koo",
                "Maryam Rahnemoonfar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00167v1",
                "http://arxiv.org/pdf/2311.00167v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00164v1",
            "title": "Graph Neural Networks for Road Safety Modeling: Datasets and Evaluations\n  for Accident Analysis",
            "updated": "2023-10-31T21:43:10Z",
            "published": "2023-10-31T21:43:10Z",
            "summary": "We consider the problem of traffic accident analysis on a road network based\non road network connections and traffic volume. Previous works have designed\nvarious deep-learning methods using historical records to predict traffic\naccident occurrences. However, there is a lack of consensus on how accurate\nexisting methods are, and a fundamental issue is the lack of public accident\ndatasets for comprehensive evaluations. This paper constructs a large-scale,\nunified dataset of traffic accident records from official reports of various\nstates in the US, totaling 9 million records, accompanied by road networks and\ntraffic volume reports. Using this new dataset, we evaluate existing\ndeep-learning methods for predicting the occurrence of accidents on road\nnetworks. Our main finding is that graph neural networks such as GraphSAGE can\naccurately predict the number of accidents on roads with less than 22% mean\nabsolute error (relative to the actual count) and whether an accident will\noccur or not with over 87% AUROC, averaged over states. We achieve these\nresults by using multitask learning to account for cross-state variabilities\n(e.g., availability of accident labels) and transfer learning to combine\ntraffic volume with accident prediction. Ablation studies highlight the\nimportance of road graph-structural features, amongst other features. Lastly,\nwe discuss the implications of the analysis and develop a package for easily\nusing our new dataset.",
            "author": [
                "Abhinav Nippani",
                "Dongyue Li",
                "Haotian Ju",
                "Haris N. Koutsopoulos",
                "Hongyang R. Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00164v1",
                "http://arxiv.org/pdf/2311.00164v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00161v1",
            "title": "Beyond Denouncing Hate: Strategies for Countering Implied Biases and\n  Stereotypes in Language",
            "updated": "2023-10-31T21:33:46Z",
            "published": "2023-10-31T21:33:46Z",
            "summary": "Counterspeech, i.e., responses to counteract potential harms of hateful\nspeech, has become an increasingly popular solution to address online hate\nspeech without censorship. However, properly countering hateful language\nrequires countering and dispelling the underlying inaccurate stereotypes\nimplied by such language. In this work, we draw from psychology and philosophy\nliterature to craft six psychologically inspired strategies to challenge the\nunderlying stereotypical implications of hateful language. We first examine the\nconvincingness of each of these strategies through a user study, and then\ncompare their usages in both human- and machine-generated counterspeech\ndatasets. Our results show that human-written counterspeech uses countering\nstrategies that are more specific to the implied stereotype (e.g., counter\nexamples to the stereotype, external factors about the stereotype's origins),\nwhereas machine-generated counterspeech uses less specific strategies (e.g.,\ngenerally denouncing the hatefulness of speech). Furthermore, machine-generated\ncounterspeech often employs strategies that humans deem less convincing\ncompared to human-produced counterspeech. Our findings point to the importance\nof accounting for the underlying stereotypical implications of speech when\ngenerating counterspeech and for better machine reasoning about\nanti-stereotypical examples.",
            "author": [
                "Jimin Mun",
                "Emily Allaway",
                "Akhila Yerukola",
                "Laura Vianna",
                "Sarah-Jane Leslie",
                "Maarten Sap"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00161v1",
                "http://arxiv.org/pdf/2311.00161v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00159v1",
            "title": "Longer Fixations, More Computation: Gaze-Guided Recurrent Neural\n  Networks",
            "updated": "2023-10-31T21:32:11Z",
            "published": "2023-10-31T21:32:11Z",
            "summary": "Humans read texts at a varying pace, while machine learning models treat each\ntoken in the same way in terms of a computational process. Therefore, we ask,\ndoes it help to make models act more like humans? In this paper, we convert\nthis intuition into a set of novel models with fixation-guided parallel RNNs or\nlayers and conduct various experiments on language modeling and sentiment\nanalysis tasks to test their effectiveness, thus providing empirical validation\nfor this intuition. Our proposed models achieve good performance on the\nlanguage modeling task, considerably surpassing the baseline model. In\naddition, we find that, interestingly, the fixation duration predicted by\nneural networks bears some resemblance to humans' fixation. Without any\nexplicit guidance, the model makes similar choices to humans. We also\ninvestigate the reasons for the differences between them, which explain why\n\"model fixations\" are often more suitable than human fixations, when used to\nguide language models.",
            "author": [
                "Xinting Huang",
                "Jiajing Wan",
                "Ioannis Kritikos",
                "Nora Hollenstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00159v1",
                "http://arxiv.org/pdf/2311.00159v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00157v2",
            "title": "Score Normalization for a Faster Diffusion Exponential Integrator\n  Sampler",
            "updated": "2023-11-10T00:30:14Z",
            "published": "2023-10-31T21:18:44Z",
            "summary": "Recently, Zhang et al. have proposed the Diffusion Exponential Integrator\nSampler (DEIS) for fast generation of samples from Diffusion Models. It\nleverages the semi-linear nature of the probability flow ordinary differential\nequation (ODE) in order to greatly reduce integration error and improve\ngeneration quality at low numbers of function evaluations (NFEs). Key to this\napproach is the score function reparameterisation, which reduces the\nintegration error incurred from using a fixed score function estimate over each\nintegration step. The original authors use the default parameterisation used by\nmodels trained for noise prediction -- multiply the score by the standard\ndeviation of the conditional forward noising distribution. We find that\nalthough the mean absolute value of this score parameterisation is close to\nconstant for a large portion of the reverse sampling process, it changes\nrapidly at the end of sampling. As a simple fix, we propose to instead\nreparameterise the score (at inference) by dividing it by the average absolute\nvalue of previous score estimates at that time step collected from offline high\nNFE generations. We find that our score normalisation (DEIS-SN) consistently\nimproves FID compared to vanilla DEIS, showing an improvement at 10 NFEs from\n6.44 to 5.57 on CIFAR-10 and from 5.9 to 4.95 on LSUN-Church 64x64. Our code is\navailable at https://github.com/mtkresearch/Diffusion-DEIS-SN",
            "author": [
                "Guoxuan Xia",
                "Duolikun Danier",
                "Ayan Das",
                "Stathi Fotiadis",
                "Farhang Nabiei",
                "Ushnish Sengupta",
                "Alberto Bernacchia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00157v2",
                "http://arxiv.org/pdf/2311.00157v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00154v1",
            "title": "Medi-CAT: Contrastive Adversarial Training for Medical Image\n  Classification",
            "updated": "2023-10-31T20:58:32Z",
            "published": "2023-10-31T20:58:32Z",
            "summary": "There are not many large medical image datasets available. For these\ndatasets, too small deep learning models can't learn useful features, so they\ndon't work well due to underfitting, and too big models tend to overfit the\nlimited data. As a result, there is a compromise between the two issues. This\npaper proposes a training strategy Medi-CAT to overcome the underfitting and\noverfitting phenomena in medical imaging datasets. Specifically, the proposed\ntraining methodology employs large pre-trained vision transformers to overcome\nunderfitting and adversarial and contrastive learning techniques to prevent\noverfitting. The proposed method is trained and evaluated on four medical image\nclassification datasets from the MedMNIST collection. Our experimental results\nindicate that the proposed approach improves the accuracy up to 2% on three\nbenchmark datasets compared to well-known approaches, whereas it increases the\nperformance up to 4.1% over the baseline methods.",
            "author": [
                "Pervaiz Iqbal Khan",
                "Andreas Dengel",
                "Sheraz Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00154v1",
                "http://arxiv.org/pdf/2311.00154v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00152v1",
            "title": "Developing a Tool to Automate Extensions to Support a Flexible Extension\n  Policy",
            "updated": "2023-10-31T20:55:08Z",
            "published": "2023-10-31T20:55:08Z",
            "summary": "In this work, we present the development of an automated extension tool to\nassist educators and increase the success and well-being of students by\nimplementing flexible extension policies. Flexible extension policies\nmaterialize in many ways, yet there are similarities in students' interactions\nwith them; students tend to request multi-day long extensions repeatedly. In\ncourses with hundreds or potentially thousands of students, providing a system\nto support this extension request demand is not possible given most currently\navailable resources and limited staff. As such, a tool is necessary to help\nautomate flexible extension processes. The development of this tool should\nreduce staff load while increasing individualized student support, which can be\nused in varying ways for different extension policies. Our research questions\nare: RQ1: Does the extension tool reduce barriers and stigma around asking for\nassistance? RQ2: Does the tool lessen the wait time between requesting and\nreceiving an extension, and how does the tool improve students' learning\nexperience in the course? These questions will help inform us about how an\nautomated tool for flexible extensions helps support growing course sizes and\nstudents who may not otherwise receive the support they need for their success\nand well-being in the course.",
            "author": [
                "Jordan Schwartz",
                "Madison Bohannan",
                "Jacob Yim",
                "Yuerou Tang",
                "Dana Benedicto",
                "Charisse Liu",
                "Armando Fox",
                "Lisa Yan",
                "Narges Norouzi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00152v1",
                "http://arxiv.org/pdf/2311.00152v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00144v1",
            "title": "Backdoor Threats from Compromised Foundation Models to Federated\n  Learning",
            "updated": "2023-10-31T20:39:54Z",
            "published": "2023-10-31T20:39:54Z",
            "summary": "Federated learning (FL) represents a novel paradigm to machine learning,\naddressing critical issues related to data privacy and security, yet suffering\nfrom data insufficiency and imbalance. The emergence of foundation models (FMs)\nprovides a promising solution to the problems with FL. For instance, FMs could\nserve as teacher models or good starting points for FL. However, the\nintegration of FM in FL presents a new challenge, exposing the FL systems to\npotential threats. This paper investigates the robustness of FL incorporating\nFMs by assessing their susceptibility to backdoor attacks. Contrary to classic\nbackdoor attacks against FL, the proposed attack (1) does not require the\nattacker fully involved in the FL process; (2) poses a significant risk in\npractical FL scenarios; (3) is able to evade existing robust FL frameworks/ FL\nbackdoor defenses; (4) underscores the researches on the robustness of FL\nsystems integrated with FMs. The effectiveness of the proposed attack is\ndemonstrated by extensive experiments with various well-known models and\nbenchmark datasets encompassing both text and image classification domains.",
            "author": [
                "Xi Li",
                "Songhe Wang",
                "Chen Wu",
                "Hao Zhou",
                "Jiaqi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00144v1",
                "http://arxiv.org/pdf/2311.00144v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00143v1",
            "title": "Two-Stage Classifier for Campaign Negativity Detection using Axis\n  Embeddings: A Case Study on Tweets of Political Users during 2021\n  Presidential Election in Iran",
            "updated": "2023-10-31T20:31:41Z",
            "published": "2023-10-31T20:31:41Z",
            "summary": "In elections around the world, the candidates may turn their campaigns toward\nnegativity due to the prospect of failure and time pressure. In the digital\nage, social media platforms such as Twitter are rich sources of political\ndiscourse. Therefore, despite the large amount of data that is published on\nTwitter, the automatic system for campaign negativity detection can play an\nessential role in understanding the strategy of candidates and parties in their\ncampaigns. In this paper, we propose a hybrid model for detecting campaign\nnegativity consisting of a two-stage classifier that combines the strengths of\ntwo machine learning models. Here, we have collected Persian tweets from 50\npolitical users, including candidates and government officials. Then we\nannotated 5,100 of them that were published during the year before the 2021\npresidential election in Iran. In the proposed model, first, the required\ndatasets of two classifiers based on the cosine similarity of tweet embeddings\nwith axis embeddings (which are the average of embedding in positive and\nnegative classes of tweets) from the training set (85\\%) are made, and then\nthese datasets are considered the training set of the two classifiers in the\nhybrid model. Finally, our best model (RF-RF) was able to achieve 79\\% for the\nmacro F1 score and 82\\% for the weighted F1 score. By running the best model on\nthe rest of the tweets of 50 political users that were published one year\nbefore the election and with the help of statistical models, we find that the\npublication of a tweet by a candidate has nothing to do with the negativity of\nthat tweet, and the presence of the names of political persons and political\norganizations in the tweet is directly related to its negativity.",
            "author": [
                "Fatemeh Rajabi",
                "Ali Mohades"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00143v1",
                "http://arxiv.org/pdf/2311.00143v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00140v1",
            "title": "Adaptive and non-adaptive minimax rates for weighted Laplacian-eigenmap\n  based nonparametric regression",
            "updated": "2023-10-31T20:25:36Z",
            "published": "2023-10-31T20:25:36Z",
            "summary": "We show both adaptive and non-adaptive minimax rates of convergence for a\nfamily of weighted Laplacian-Eigenmap based nonparametric regression methods,\nwhen the true regression function belongs to a Sobolev space and the sampling\ndensity is bounded from above and below. The adaptation methodology is based on\nextensions of Lepski's method and is over both the smoothness parameter\n($s\\in\\mathbb{N}_{+}$) and the norm parameter ($M>0$) determining the\nconstraints on the Sobolev space. Our results extend the non-adaptive result in\n\\cite{green2021minimax}, established for a specific normalized graph Laplacian,\nto a wide class of weighted Laplacian matrices used in practice, including the\nunnormalized Laplacian and random walk Laplacian.",
            "author": [
                "Zhaoyang Shi",
                "Krishnakumar Balasubramanian",
                "Wolfgang Polonik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00140v1",
                "http://arxiv.org/pdf/2311.00140v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00136v3",
            "title": "Neuroformer: Multimodal and Multitask Generative Pretraining for Brain\n  Data",
            "updated": "2023-11-08T19:48:12Z",
            "published": "2023-10-31T20:17:32Z",
            "summary": "State-of-the-art systems neuroscience experiments yield large-scale\nmultimodal data, and these data sets require new tools for analysis. Inspired\nby the success of large pretrained models in vision and language domains, we\nreframe the analysis of large-scale, cellular-resolution neuronal spiking data\ninto an autoregressive spatiotemporal generation problem. Neuroformer is a\nmultimodal, multitask generative pretrained transformer (GPT) model that is\nspecifically designed to handle the intricacies of data in systems\nneuroscience. It scales linearly with feature size, can process an arbitrary\nnumber of modalities, and is adaptable to downstream tasks, such as predicting\nbehavior. We first trained Neuroformer on simulated datasets, and found that it\nboth accurately predicted simulated neuronal circuit activity, and also\nintrinsically inferred the underlying neural circuit connectivity, including\ndirection. When pretrained to decode neural responses, the model predicted the\nbehavior of a mouse with only few-shot fine-tuning, suggesting that the model\nbegins learning how to do so directly from the neural representations\nthemselves, without any explicit supervision. We used an ablation study to show\nthat joint training on neuronal responses and behavior boosted performance,\nhighlighting the model's ability to associate behavioral and neural\nrepresentations in an unsupervised manner. These findings show that Neuroformer\ncan analyze neural datasets and their emergent properties, informing the\ndevelopment of models and hypotheses associated with the brain.",
            "author": [
                "Antonis Antoniades",
                "Yiyi Yu",
                "Joseph Canzano",
                "William Wang",
                "Spencer LaVere Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00136v3",
                "http://arxiv.org/pdf/2311.00136v3"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00128v2",
            "title": "On the effect of curriculum learning with developmental data for grammar\n  acquisition",
            "updated": "2023-11-03T16:42:33Z",
            "published": "2023-10-31T20:05:30Z",
            "summary": "This work explores the degree to which grammar acquisition is driven by\nlanguage `simplicity' and the source modality (speech vs. text) of data. Using\nBabyBERTa as a probe, we find that grammar acquisition is largely driven by\nexposure to speech data, and in particular through exposure to two of the\nBabyLM training corpora: AO-Childes and Open Subtitles. We arrive at this\nfinding by examining various ways of presenting input data to our model. First,\nwe assess the impact of various sequence-level complexity based curricula. We\nthen examine the impact of learning over `blocks' -- covering spans of text\nthat are balanced for the number of tokens in each of the source corpora\n(rather than number of lines). Finally, we explore curricula that vary the\ndegree to which the model is exposed to different corpora. In all cases, we\nfind that over-exposure to AO-Childes and Open Subtitles significantly drives\nperformance. We verify these findings through a comparable control dataset in\nwhich exposure to these corpora, and speech more generally, is limited by\ndesign. Our findings indicate that it is not the proportion of tokens occupied\nby high-utility data that aids acquisition, but rather the proportion of\ntraining steps assigned to such data. We hope this encourages future research\ninto the use of more developmentally plausible linguistic data (which tends to\nbe more scarce) to augment general purpose pre-training regimes.",
            "author": [
                "Mattia Opper",
                "J. Morrison",
                "N. Siddharth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00128v2",
                "http://arxiv.org/pdf/2311.00128v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00126v1",
            "title": "Stochastic Time-Optimal Trajectory Planning for Connected and Automated\n  Vehicles in Mixed-Traffic Merging Scenarios",
            "updated": "2023-10-31T19:56:39Z",
            "published": "2023-10-31T19:56:39Z",
            "summary": "Addressing safe and efficient interaction between connected and automated\nvehicles (CAVs) and human-driven vehicles in a mixed-traffic environment has\nattracted considerable attention. In this paper, we develop a framework for\nstochastic time-optimal trajectory planning for coordinating multiple CAVs in\nmixed-traffic merging scenarios. We present a data-driven model, combining\nNewell's car-following model with Bayesian linear regression, for efficiently\nlearning the driving behavior of human drivers online. Using the prediction\nmodel and uncertainty quantification, a stochastic time-optimal control problem\nis formulated to find robust trajectories for CAVs. We also integrate a\nreplanning mechanism that determines when deriving new trajectories for CAVs is\nneeded based on the accuracy of the Bayesian linear regression predictions.\nFinally, we demonstrate the performance of our proposed framework using a\nrealistic simulation environment.",
            "author": [
                "Viet-Anh Le",
                "Behdad Chalaki",
                "Filippos N. Tzortzoglou",
                "Andreas A. Malikopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00126v1",
                "http://arxiv.org/pdf/2311.00126v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00123v1",
            "title": "Q-Learning for Stochastic Control under General Information Structures\n  and Non-Markovian Environments",
            "updated": "2023-10-31T19:53:16Z",
            "published": "2023-10-31T19:53:16Z",
            "summary": "As a primary contribution, we present a convergence theorem for stochastic\niterations, and in particular, Q-learning iterates, under a general, possibly\nnon-Markovian, stochastic environment. Our conditions for convergence involve\nan ergodicity and a positivity criterion. We provide a precise characterization\non the limit of the iterates and conditions on the environment and\ninitializations for convergence. As our second contribution, we discuss the\nimplications and applications of this theorem to a variety of stochastic\ncontrol problems with non-Markovian environments involving (i) quantized\napproximations of fully observed Markov Decision Processes (MDPs) with\ncontinuous spaces (where quantization break down the Markovian structure), (ii)\nquantized approximations of belief-MDP reduced partially observable MDPS\n(POMDPs) with weak Feller continuity and a mild version of filter stability\n(which requires the knowledge of the model by the controller), (iii) finite\nwindow approximations of POMDPs under a uniform controlled filter stability\n(which does not require the knowledge of the model), and (iv) for multi-agent\nmodels where convergence of learning dynamics to a new class of equilibria,\nsubjective Q-learning equilibria, will be studied. In addition to the\nconvergence theorem, some implications of the theorem above are new to the\nliterature and others are interpreted as applications of the convergence\ntheorem. Some open problems are noted.",
            "author": [
                "Ali Devran Kara",
                "Serdar Yuksel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00123v1",
                "http://arxiv.org/pdf/2311.00123v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00118v1",
            "title": "Extracting the Multiscale Causal Backbone of Brain Dynamics",
            "updated": "2023-10-31T19:47:11Z",
            "published": "2023-10-31T19:47:11Z",
            "summary": "The bulk of the research effort on brain connectivity revolves around\nstatistical associations among brain regions, which do not directly relate to\nthe causal mechanisms governing brain dynamics. Here we propose the multiscale\ncausal backbone (MCB) of brain dynamics shared by a set of individuals across\nmultiple temporal scales, and devise a principled methodology to extract it.\n  Our approach leverages recent advances in multiscale causal structure\nlearning and optimizes the trade-off between the model fitting and its\ncomplexity. Empirical assessment on synthetic data shows the superiority of our\nmethodology over a baseline based on canonical functional connectivity\nnetworks. When applied to resting-state fMRI data, we find sparse MCBs for both\nthe left and right brain hemispheres. Thanks to its multiscale nature, our\napproach shows that at low-frequency bands, causal dynamics are driven by brain\nregions associated with high-level cognitive functions; at higher frequencies\ninstead, nodes related to sensory processing play a crucial role. Finally, our\nanalysis of individual multiscale causal structures confirms the existence of a\ncausal fingerprint of brain connectivity, thus supporting from a causal\nperspective the existing extensive research in brain connectivity\nfingerprinting.",
            "author": [
                "Gabriele D'Acunto",
                "Francesco Bonchi",
                "Gianmarco De Francisci Morales",
                "Giovanni Petri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00118v1",
                "http://arxiv.org/pdf/2311.00118v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.NC",
                "stat.AP",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00115v1",
            "title": "EXTRACT: Explainable Transparent Control of Bias in Embeddings",
            "updated": "2023-10-31T19:44:32Z",
            "published": "2023-10-31T19:44:32Z",
            "summary": "Knowledge Graphs are a widely used method to represent relations between\nentities in various AI applications, and Graph Embedding has rapidly become a\nstandard technique to represent Knowledge Graphs in such a way as to facilitate\ninferences and decisions. As this representation is obtained from behavioural\ndata, and is not in a form readable by humans, there is a concern that it might\nincorporate unintended information that could lead to biases. We propose\nEXTRACT: a suite of Explainable and Transparent methods to ConTrol bias in\nknowledge graph embeddings, so as to assess and decrease the implicit presence\nof protected information. Our method uses Canonical Correlation Analysis (CCA)\nto investigate the presence, extent and origins of information leaks during\ntraining, then decomposes embeddings into a sum of their private attributes by\nsolving a linear system. Our experiments, performed on the MovieLens1M dataset,\nshow that a range of personal attributes can be inferred from a user's viewing\nbehaviour and preferences, including gender, age, and occupation. Further\nexperiments, performed on the KG20C citation dataset, show that the information\nabout the conference in which a paper was published can be inferred from the\ncitation network of that article. We propose four transparent methods to\nmaintain the capability of the embedding to make the intended predictions\nwithout retaining unwanted information. A trade-off between these two goals is\nobserved.",
            "author": [
                "Zhijin Guo",
                "Zhaozhen Xu",
                "Martha Lewis",
                "Nello Cristianini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00115v1",
                "http://arxiv.org/pdf/2311.00115v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00109v1",
            "title": "FairWASP: Fast and Optimal Fair Wasserstein Pre-processing",
            "updated": "2023-10-31T19:36:00Z",
            "published": "2023-10-31T19:36:00Z",
            "summary": "Recent years have seen a surge of machine learning approaches aimed at\nreducing disparities in model outputs across different subgroups. In many\nsettings, training data may be used in multiple downstream applications by\ndifferent users, which means it may be most effective to intervene on the\ntraining data itself. In this work, we present FairWASP, a novel pre-processing\napproach designed to reduce disparities in classification datasets without\nmodifying the original data. FairWASP returns sample-level weights such that\nthe reweighted dataset minimizes the Wasserstein distance to the original\ndataset while satisfying (an empirical version of) demographic parity, a\npopular fairness criterion. We show theoretically that integer weights are\noptimal, which means our method can be equivalently understood as duplicating\nor eliminating samples. FairWASP can therefore be used to construct datasets\nwhich can be fed into any classification method, not just methods which accept\nsample weights. Our work is based on reformulating the pre-processing task as a\nlarge-scale mixed-integer program (MIP), for which we propose a highly\nefficient algorithm based on the cutting plane method. Experiments on synthetic\ndatasets demonstrate that our proposed optimization algorithm significantly\noutperforms state-of-the-art commercial solvers in solving both the MIP and its\nlinear program relaxation. Further experiments highlight the competitive\nperformance of FairWASP in reducing disparities while preserving accuracy in\ndownstream classification settings.",
            "author": [
                "Zikai Xiong",
                "Niccol\u00f2 Dalmasso",
                "Alan Mishler",
                "Vamsi K. Potluru",
                "Tucker Balch",
                "Manuela Veloso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00109v1",
                "http://arxiv.org/pdf/2311.00109v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00108v1",
            "title": "Stellar spectral-type (mass) dependence of the dearth of close-in\n  planets around fast-rotating stars. Architecture of Kepler confirmed\n  single-exoplanet systems compared to star-planet evolution models",
            "updated": "2023-10-31T19:34:56Z",
            "published": "2023-10-31T19:34:56Z",
            "summary": "In 2013 a dearth of close-in planets around fast-rotating host stars was\nfound using statistical tests on Kepler data. The addition of more Kepler and\nTransiting Exoplanet Survey Satellite (TESS) systems in 2022 filled this region\nof the diagram of stellar rotation period (Prot) versus the planet orbital\nperiod (Porb). We revisited the Prot extraction of Kepler planet-host stars, we\nclassify the stars by their spectral type, and we studied their Prot-Porb\nrelations. We only used confirmed exoplanet systems to minimize biases. In\norder to learn about the physical processes at work, we used the star-planet\nevolution code ESPEM (French acronym for Evolution of Planetary Systems and\nMagnetism) to compute a realistic population synthesis of exoplanet systems and\ncompared them with observations. Because ESPEM works with a single planet\norbiting around a single main-sequence star, we limit our study to this\npopulation of Kepler observed systems filtering out binaries, evolved stars,\nand multi-planets. We find in both, observations and simulations, the existence\nof a dearth in close-in planets orbiting around fast-rotating stars, with a\ndependence on the stellar spectral type (F, G, and K), which is a proxy of the\nmass in our sample of stars. There is a change in the edge of the dearth as a\nfunction of the spectral type (and mass). It moves towards shorter Prot as\ntemperature (and mass) increases, making the dearth look smaller. Realistic\nformation hypotheses included in the model and the proper treatment of tidal\nand magnetic migration are enough to qualitatively explain the dearth of hot\nplanets around fast-rotating stars and the uncovered trend with spectral type.",
            "author": [
                "R. A. Garc\u00eda",
                "C. Gourv\u00e8s",
                "A. R. G. Santos",
                "A. Strugarek",
                "D. Godoy-Rivera",
                "S. Mathur",
                "V. Delsanti",
                "S. N. Breton",
                "P. G. Beck",
                "A. S. Brun",
                "S. Mathis"
            ],
            "link": [
                "http://dx.doi.org/10.1051/0004-6361/202346933",
                "http://arxiv.org/abs/2311.00108v1",
                "http://arxiv.org/pdf/2311.00108v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00107v1",
            "title": "Deep Compressed Learning for 3D Seismic Inversion",
            "updated": "2023-10-31T19:34:26Z",
            "published": "2023-10-31T19:34:26Z",
            "summary": "We consider the problem of 3D seismic inversion from pre-stack data using a\nvery small number of seismic sources. The proposed solution is based on a\ncombination of compressed-sensing and machine learning frameworks, known as\ncompressed-learning. The solution jointly optimizes a dimensionality reduction\noperator and a 3D inversion encoder-decoder implemented by a deep convolutional\nneural network (DCNN). Dimensionality reduction is achieved by learning a\nsparse binary sensing layer that selects a small subset of the available\nsources, then the selected data is fed to a DCNN to complete the regression\ntask. The end-to-end learning process provides a reduction by an\norder-of-magnitude in the number of seismic records used during training, while\npreserving the 3D reconstruction quality comparable to that obtained by using\nthe entire dataset.",
            "author": [
                "Maayan Gelboim",
                "Amir Adler",
                "Yen Sun",
                "Mauricio Araya-Polo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00107v1",
                "http://arxiv.org/pdf/2311.00107v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05638v1",
            "title": "Towards Instance-Optimality in Online PAC Reinforcement Learning",
            "updated": "2023-10-31T19:26:36Z",
            "published": "2023-10-31T19:26:36Z",
            "summary": "Several recent works have proposed instance-dependent upper bounds on the\nnumber of episodes needed to identify, with probability $1-\\delta$, an\n$\\varepsilon$-optimal policy in finite-horizon tabular Markov Decision\nProcesses (MDPs). These upper bounds feature various complexity measures for\nthe MDP, which are defined based on different notions of sub-optimality gaps.\nHowever, as of now, no lower bound has been established to assess the\noptimality of any of these complexity measures, except for the special case of\nMDPs with deterministic transitions. In this paper, we propose the first\ninstance-dependent lower bound on the sample complexity required for the PAC\nidentification of a near-optimal policy in any tabular episodic MDP.\nAdditionally, we demonstrate that the sample complexity of the PEDEL algorithm\nof \\cite{Wagenmaker22linearMDP} closely approaches this lower bound.\nConsidering the intractability of PEDEL, we formulate an open question\nregarding the possibility of achieving our lower bound using a\ncomputationally-efficient algorithm.",
            "author": [
                "Aymen Al-Marjani",
                "Andrea Tirinzoni",
                "Emilie Kaufmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05638v1",
                "http://arxiv.org/pdf/2311.05638v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00096v1",
            "title": "Bandit-Driven Batch Selection for Robust Learning under Label Noise",
            "updated": "2023-10-31T19:19:01Z",
            "published": "2023-10-31T19:19:01Z",
            "summary": "We introduce a novel approach for batch selection in Stochastic Gradient\nDescent (SGD) training, leveraging combinatorial bandit algorithms. Our\nmethodology focuses on optimizing the learning process in the presence of label\nnoise, a prevalent issue in real-world datasets. Experimental evaluations on\nthe CIFAR-10 dataset reveal that our approach consistently outperforms existing\nmethods across various levels of label corruption. Importantly, we achieve this\nsuperior performance without incurring the computational overhead commonly\nassociated with auxiliary neural network models. This work presents a balanced\ntrade-off between computational efficiency and model efficacy, offering a\nscalable solution for complex machine learning applications.",
            "author": [
                "Michal Lisicki",
                "Mihai Nica",
                "Graham W. Taylor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00096v1",
                "http://arxiv.org/pdf/2311.00096v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00094v1",
            "title": "Expressive Modeling Is Insufficient for Offline RL: A Tractable\n  Inference Perspective",
            "updated": "2023-10-31T19:16:07Z",
            "published": "2023-10-31T19:16:07Z",
            "summary": "A popular paradigm for offline Reinforcement Learning (RL) tasks is to first\nfit the offline trajectories to a sequence model, and then prompt the model for\nactions that lead to high expected return. While a common consensus is that\nmore expressive sequence models imply better performance, this paper highlights\nthat tractability, the ability to exactly and efficiently answer various\nprobabilistic queries, plays an equally important role. Specifically, due to\nthe fundamental stochasticity from the offline data-collection policies and the\nenvironment dynamics, highly non-trivial conditional/constrained generation is\nrequired to elicit rewarding actions. While it is still possible to approximate\nsuch queries, we observe that such crude estimates significantly undermine the\nbenefits brought by expressive sequence models. To overcome this problem, this\npaper proposes Trifle (Tractable Inference for Offline RL), which leverages\nmodern Tractable Probabilistic Models (TPMs) to bridge the gap between good\nsequence models and high expected returns at evaluation time. Empirically,\nTrifle achieves the most state-of-the-art scores in 9 Gym-MuJoCo benchmarks\nagainst strong baselines. Further, owing to its tractability, Trifle\nsignificantly outperforms prior approaches in stochastic environments and safe\nRL tasks (e.g. with action constraints) with minimum algorithmic modifications.",
            "author": [
                "Xuejie Liu",
                "Anji Liu",
                "Guy Van den Broeck",
                "Yitao Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00094v1",
                "http://arxiv.org/pdf/2311.00094v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00089v1",
            "title": "Fast, multicolour optical sectioning over extended fields of view by\n  combining interferometric SIM with machine learning",
            "updated": "2023-10-31T18:56:30Z",
            "published": "2023-10-31T18:56:30Z",
            "summary": "Structured illumination can reject out-of-focus signal from a sample,\nenabling high-speed and high-contrast imaging over large areas with widefield\ndetection optics. Currently, this optical-sectioning technique is limited by\nimage reconstruction artefacts and the need for sequential imaging of multiple\ncolour channels. We combine multicolour interferometric pattern generation with\nmachine-learning processing, permitting high-contrast, real-time reconstruction\nof image data. The method is insensitive to background noise and unevenly\nphase-stepped illumination patterns. We validate the method in silico and\ndemonstrate its application on diverse specimens, ranging from fixed and live\nbiological cells to synthetic biosystems, imaging at up to 37 Hz across a 44 x\n44 $\\mu m^2$ field of view.",
            "author": [
                "Edward N. Ward",
                "Rebecca M. McClelland",
                "Jacob R. Lamb",
                "Roger Rubio-S\u00e1nchez",
                "Charles N. Christensen",
                "Bismoy Mazumder",
                "Sofia Kapsiani",
                "Luca Mascheroni",
                "Lorenzo Di Michele",
                "Gabriele S. Kaminski Schierle",
                "Clemens F. Kaminski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00089v1",
                "http://arxiv.org/pdf/2311.00089v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "eess.IV",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00088v1",
            "title": "Random coordinate descent: a simple alternative for optimizing\n  parameterized quantum circuits",
            "updated": "2023-10-31T18:55:45Z",
            "published": "2023-10-31T18:55:45Z",
            "summary": "Variational quantum algorithms rely on the optimization of parameterized\nquantum circuits in noisy settings. The commonly used back-propagation\nprocedure in classical machine learning is not directly applicable in this\nsetting due to the collapse of quantum states after measurements. Thus,\ngradient estimations constitute a significant overhead in a gradient-based\noptimization of such quantum circuits. This paper introduces a random\ncoordinate descent algorithm as a practical and easy-to-implement alternative\nto the full gradient descent algorithm. This algorithm only requires one\npartial derivative at each iteration. Motivated by the behavior of measurement\nnoise in the practical optimization of parameterized quantum circuits, this\npaper presents an optimization problem setting that is amenable to analysis.\nUnder this setting, the random coordinate descent algorithm exhibits the same\nlevel of stochastic stability as the full gradient approach, making it as\nresilient to noise. The complexity of the random coordinate descent method is\ngenerally no worse than that of the gradient descent and can be much better for\nvarious quantum optimization problems with anisotropic Lipschitz constants.\nTheoretical analysis and extensive numerical experiments validate our findings.",
            "author": [
                "Zhiyan Ding",
                "Taehee Ko",
                "Jiahao Yao",
                "Lin Lin",
                "Xiantao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00088v1",
                "http://arxiv.org/pdf/2311.00088v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00087v1",
            "title": "Seeking Truth and Beauty in Flavor Physics with Machine Learning",
            "updated": "2023-10-31T18:53:22Z",
            "published": "2023-10-31T18:53:22Z",
            "summary": "The discovery process of building new theoretical physics models involves the\ndual aspect of both fitting to the existing experimental data and satisfying\nabstract theorists' criteria like beauty, naturalness, etc. We design loss\nfunctions for performing both of those tasks with machine learning techniques.\nWe use the Yukawa quark sector as a toy example to demonstrate that the\noptimization of these loss functions results in true and beautiful models.",
            "author": [
                "Konstantin T. Matchev",
                "Katia Matcheva",
                "Pierre Ramond",
                "Sarunas Verner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00087v1",
                "http://arxiv.org/pdf/2311.00087v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "cs.LG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00084v1",
            "title": "NoMoPy: Noise Modeling in Python",
            "updated": "2023-10-31T18:52:05Z",
            "published": "2023-10-31T18:52:05Z",
            "summary": "NoMoPy is a code for fitting, analyzing, and generating noise modeled as a\nhidden Markov model (HMM) or, more generally, factorial hidden Markov model\n(FHMM). This code, written in Python, implements approximate and exact\nexpectation maximization (EM) algorithms for performing the parameter\nestimation process, model selection procedures via cross-validation, and\nparameter confidence region estimation. Here, we describe in detail the\nfunctionality implemented in NoMoPy and provide examples of its use and\nperformance on example problems.",
            "author": [
                "Dylan Albrecht",
                "N. Tobias Jacobson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00084v1",
                "http://arxiv.org/pdf/2311.00084v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "cs.CE",
                "cs.MS",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00079v1",
            "title": "Spuriosity Rankings for Free: A Simple Framework for Last Layer\n  Retraining Based on Object Detection",
            "updated": "2023-10-31T18:44:03Z",
            "published": "2023-10-31T18:44:03Z",
            "summary": "Deep neural networks have exhibited remarkable performance in various\ndomains. However, the reliance of these models on spurious features has raised\nconcerns about their reliability. A promising solution to this problem is\nlast-layer retraining, which involves retraining the linear classifier head on\na small subset of data without spurious cues. Nevertheless, selecting this\nsubset requires human supervision, which reduces its scalability. Moreover,\nspurious cues may still exist in the selected subset. As a solution to this\nproblem, we propose a novel ranking framework that leverages an open vocabulary\nobject detection technique to identify images without spurious cues. More\nspecifically, we use the object detector as a measure to score the presence of\nthe target object in the images. Next, the images are sorted based on this\nscore, and the last-layer of the model is retrained on a subset of the data\nwith the highest scores. Our experiments on the ImageNet-1k dataset demonstrate\nthe effectiveness of this ranking framework in sorting images based on\nspuriousness and using them for last-layer retraining.",
            "author": [
                "Mohammad Azizmalayeri",
                "Reza Abbasi",
                "Amir Hosein Haji Mohammad rezaie",
                "Reihaneh Zohrabi",
                "Mahdi Amiri",
                "Mohammad Taghi Manzuri",
                "Mohammad Hossein Rohban"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00079v1",
                "http://arxiv.org/pdf/2311.00079v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00073v1",
            "title": "YOLOv8-Based Visual Detection of Road Hazards: Potholes, Sewer Covers,\n  and Manholes",
            "updated": "2023-10-31T18:33:26Z",
            "published": "2023-10-31T18:33:26Z",
            "summary": "Effective detection of road hazards plays a pivotal role in road\ninfrastructure maintenance and ensuring road safety. This research paper\nprovides a comprehensive evaluation of YOLOv8, an object detection model, in\nthe context of detecting road hazards such as potholes, Sewer Covers, and Man\nHoles. A comparative analysis with previous iterations, YOLOv5 and YOLOv7, is\nconducted, emphasizing the importance of computational efficiency in various\napplications. The paper delves into the architecture of YOLOv8 and explores\nimage preprocessing techniques aimed at enhancing detection accuracy across\ndiverse conditions, including variations in lighting, road types, hazard sizes,\nand types. Furthermore, hyperparameter tuning experiments are performed to\noptimize model performance through adjustments in learning rates, batch sizes,\nanchor box sizes, and augmentation strategies. Model evaluation is based on\nMean Average Precision (mAP), a widely accepted metric for object detection\nperformance. The research assesses the robustness and generalization\ncapabilities of the models through mAP scores calculated across the diverse\ntest scenarios, underlining the significance of YOLOv8 in road hazard detection\nand infrastructure maintenance.",
            "author": [
                "Om M. Khare",
                "Shubham Gandhi",
                "Aditya M. Rahalkar",
                "Sunil Mane"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00073v1",
                "http://arxiv.org/pdf/2311.00073v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.10747v2",
            "title": "Safety-aware Causal Representation for Trustworthy Reinforcement\n  Learning in Autonomous Driving",
            "updated": "2023-11-21T21:40:21Z",
            "published": "2023-10-31T18:21:24Z",
            "summary": "In the domain of autonomous driving, the Learning from Demonstration (LfD)\nparadigm has exhibited notable efficacy in addressing sequential\ndecision-making problems. However, consistently achieving safety in varying\ntraffic contexts, especially in safety-critical scenarios, poses a significant\nchallenge due to the long-tailed and unforeseen scenarios absent from offline\ndatasets. In this paper, we introduce the saFety-aware strUctured Scenario\nrepresentatION (FUSION), a pioneering methodology conceived to facilitate the\nlearning of an adaptive end-to-end driving policy by leveraging structured\nscenario information. FUSION capitalizes on the causal relationships between\ndecomposed reward, cost, state, and action space, constructing a framework for\nstructured sequential reasoning under dynamic traffic environments. We conduct\nrigorous evaluations in two typical real-world settings of distribution shift\nin autonomous vehicles, demonstrating the good balance between safety cost and\nutility reward of FUSION compared to contemporary state-of-the-art safety-aware\nLfD baselines. Empirical evidence under diverse driving scenarios attests that\nFUSION significantly enhances the safety and generalizability of autonomous\ndriving agents, even in the face of challenging and unseen environments.\nFurthermore, our ablation studies reveal noticeable improvements in the\nintegration of causal representation into the safe offline RL problem.",
            "author": [
                "Haohong Lin",
                "Wenhao Ding",
                "Zuxin Liu",
                "Yaru Niu",
                "Jiacheng Zhu",
                "Yuming Niu",
                "Ding Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10747v2",
                "http://arxiv.org/pdf/2311.10747v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14677v1",
            "title": "Filter bubbles and affective polarization in user-personalized large\n  language model outputs",
            "updated": "2023-10-31T18:19:28Z",
            "published": "2023-10-31T18:19:28Z",
            "summary": "Echoing the history of search engines and social media content rankings, the\nadvent of large language models (LLMs) has led to a push for increased\npersonalization of model outputs to individual users. In the past, personalized\nrecommendations and ranking systems have been linked to the development of\nfilter bubbles (serving content that may confirm a user's existing biases) and\naffective polarization (strong negative sentiment towards those with differing\nviews). In this work, we explore how prompting a leading large language model,\nChatGPT-3.5, with a user's political affiliation prior to asking factual\nquestions about public figures and organizations leads to differing results. We\nobserve that left-leaning users tend to receive more positive statements about\nleft-leaning political figures and media outlets, while right-leaning users see\nmore positive statements about right-leaning entities. This pattern holds\nacross presidential candidates, members of the U.S. Senate, and media\norganizations with ratings from AllSides. When qualitatively evaluating some of\nthese outputs, there is evidence that particular facts are included or excluded\nbased on the user's political affiliation. These results illustrate that\npersonalizing LLMs based on user demographics carry the same risks of affective\npolarization and filter bubbles that have been seen in other personalized\ninternet technologies. This ``failure mode\" should be monitored closely as\nthere are more attempts to monetize and personalize these models.",
            "author": [
                "Tomo Lazovich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14677v1",
                "http://arxiv.org/pdf/2311.14677v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00068v1",
            "title": "View Classification and Object Detection in Cardiac Ultrasound to\n  Localize Valves via Deep Learning",
            "updated": "2023-10-31T18:16:02Z",
            "published": "2023-10-31T18:16:02Z",
            "summary": "Echocardiography provides an important tool for clinicians to observe the\nfunction of the heart in real time, at low cost, and without harmful radiation.\nAutomated localization and classification of heart valves enables automatic\nextraction of quantities associated with heart mechanical function and related\nblood flow measurements. We propose a machine learning pipeline that uses deep\nneural networks for separate classification and localization steps. As the\nfirst step in the pipeline, we apply view classification to echocardiograms\nwith ten unique anatomic views of the heart. In the second step, we apply deep\nlearning-based object detection to both localize and identify the valves. Image\nsegmentation based object detection in echocardiography has been shown in many\nearlier studies but, to the best of our knowledge, this is the first study that\npredicts the bounding boxes around the valves along with classification from 2D\nultrasound images with the help of deep neural networks. Our object detection\nexperiments applied to the Apical views suggest that it is possible to localize\nand identify multiple valves precisely.",
            "author": [
                "Derya Gol Gungor",
                "Bimba Rao",
                "Cynthia Wolverton",
                "Ismayil Guracar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00068v1",
                "http://arxiv.org/pdf/2311.00068v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00063v1",
            "title": "Safe multi-agent motion planning under uncertainty for drones using\n  filtered reinforcement learning",
            "updated": "2023-10-31T18:09:26Z",
            "published": "2023-10-31T18:09:26Z",
            "summary": "We consider the problem of safe multi-agent motion planning for drones in\nuncertain, cluttered workspaces. For this problem, we present a tractable\nmotion planner that builds upon the strengths of reinforcement learning and\nconstrained-control-based trajectory planning. First, we use single-agent\nreinforcement learning to learn motion plans from data that reach the target\nbut may not be collision-free. Next, we use a convex optimization, chance\nconstraints, and set-based methods for constrained control to ensure safety,\ndespite the uncertainty in the workspace, agent motion, and sensing. The\nproposed approach can handle state and control constraints on the agents, and\nenforce collision avoidance among themselves and with static obstacles in the\nworkspace with high probability. The proposed approach yields a safe, real-time\nimplementable, multi-agent motion planner that is simpler to train than methods\nbased solely on learning. Numerical simulations and experiments show the\nefficacy of the approach.",
            "author": [
                "Sleiman Safaoui",
                "Abraham P. Vinod",
                "Ankush Chakrabarty",
                "Rien Quirynen",
                "Nobuyuki Yoshikawa",
                "Stefano Di Cairano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00063v1",
                "http://arxiv.org/pdf/2311.00063v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG",
                "cs.MA",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00060v2",
            "title": "Ensemble models outperform single model uncertainties and predictions\n  for operator-learning of hypersonic flows",
            "updated": "2023-11-03T13:43:28Z",
            "published": "2023-10-31T18:07:29Z",
            "summary": "High-fidelity computational simulations and physical experiments of\nhypersonic flows are resource intensive. Training scientific machine learning\n(SciML) models on limited high-fidelity data offers one approach to rapidly\npredict behaviors for situations that have not been seen before. However,\nhigh-fidelity data is itself in limited quantity to validate all outputs of the\nSciML model in unexplored input space. As such, an uncertainty-aware SciML\nmodel is desired. The SciML model's output uncertainties could then be used to\nassess the reliability and confidence of the model's predictions. In this\nstudy, we extend a DeepONet using three different uncertainty quantification\nmechanisms: mean-variance estimation, evidential uncertainty, and ensembling.\nThe uncertainty aware DeepONet models are trained and evaluated on the\nhypersonic flow around a blunt cone object with data generated via\ncomputational fluid dynamics over a wide range of Mach numbers and altitudes.\nWe find that ensembling outperforms the other two uncertainty models in terms\nof minimizing error and calibrating uncertainty in both interpolative and\nextrapolative regimes.",
            "author": [
                "Victor J. Leon",
                "Noah Ford",
                "Honest Mrema",
                "Jeffrey Gilbert",
                "Alexander New"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00060v2",
                "http://arxiv.org/pdf/2311.00060v2"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00059v1",
            "title": "The Generative AI Paradox: \"What It Can Create, It May Not Understand\"",
            "updated": "2023-10-31T18:07:07Z",
            "published": "2023-10-31T18:07:07Z",
            "summary": "The recent wave of generative AI has sparked unprecedented global attention,\nwith both excitement and concern over potentially superhuman levels of\nartificial intelligence: models now take only seconds to produce outputs that\nwould challenge or exceed the capabilities even of expert humans. At the same\ntime, models still show basic errors in understanding that would not be\nexpected even in non-expert humans. This presents us with an apparent paradox:\nhow do we reconcile seemingly superhuman capabilities with the persistence of\nerrors that few humans would make? In this work, we posit that this tension\nreflects a divergence in the configuration of intelligence in today's\ngenerative models relative to intelligence in humans. Specifically, we propose\nand test the Generative AI Paradox hypothesis: generative models, having been\ntrained directly to reproduce expert-like outputs, acquire generative\ncapabilities that are not contingent upon -- and can therefore exceed -- their\nability to understand those same types of outputs. This contrasts with humans,\nfor whom basic understanding almost always precedes the ability to generate\nexpert-level outputs. We test this hypothesis through controlled experiments\nanalyzing generation vs. understanding in generative models, across both\nlanguage and image modalities. Our results show that although models can\noutperform humans in generation, they consistently fall short of human\ncapabilities in measures of understanding, as well as weaker correlation\nbetween generation and understanding performance, and more brittleness to\nadversarial inputs. Our findings support the hypothesis that models' generative\ncapability may not be contingent upon understanding capability, and call for\ncaution in interpreting artificial intelligence by analogy to human\nintelligence.",
            "author": [
                "Peter West",
                "Ximing Lu",
                "Nouha Dziri",
                "Faeze Brahman",
                "Linjie Li",
                "Jena D. Hwang",
                "Liwei Jiang",
                "Jillian Fisher",
                "Abhilasha Ravichander",
                "Khyathi Chandu",
                "Benjamin Newman",
                "Pang Wei Koh",
                "Allyson Ettinger",
                "Yejin Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00059v1",
                "http://arxiv.org/pdf/2311.00059v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00058v1",
            "title": "Observing quantum measurement collapse as a learnability phase\n  transition",
            "updated": "2023-10-31T18:06:05Z",
            "published": "2023-10-31T18:06:05Z",
            "summary": "The mechanism by which an effective macroscopic description of quantum\nmeasurement in terms of discrete, probabilistic collapse events emerges from\nthe reversible microscopic dynamics remains an enduring open question. Emerging\nquantum computers offer a promising platform to explore how measurement\nprocesses evolve across a range of system sizes while retaining coherence.\nHere, we report the experimental observation of evidence for an\nobservable-sharpening measurement-induced phase transition in a chain of\ntrapped ions in Quantinuum H1-1 system model quantum processor. This transition\nmanifests as a sharp, concomitant change in both the quantum uncertainty of an\nobservable and the amount of information an observer can (in principle) learn\nfrom the measurement record, upon increasing the strength of measurements. We\nleverage insights from statistical mechanical models and machine learning to\ndesign efficiently-computable algorithms to observe this transition (without\nnon-scalable post-selection on measurement outcomes) and to mitigate the\neffects on errors in noisy hardware.",
            "author": [
                "Utkarsh Agrawal",
                "Javier Lopez-Piqueres",
                "Romain Vasseur",
                "Sarang Gopalakrishnan",
                "Andrew C. Potter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00058v1",
                "http://arxiv.org/pdf/2311.00058v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00056v1",
            "title": "Diversity and Diffusion: Observations on Synthetic Image Distributions\n  with Stable Diffusion",
            "updated": "2023-10-31T18:05:15Z",
            "published": "2023-10-31T18:05:15Z",
            "summary": "Recent progress in text-to-image (TTI) systems, such as StableDiffusion,\nImagen, and DALL-E 2, have made it possible to create realistic images with\nsimple text prompts. It is tempting to use these systems to eliminate the\nmanual task of obtaining natural images for training a new machine learning\nclassifier. However, in all of the experiments performed to date, classifiers\ntrained solely with synthetic images perform poorly at inference, despite the\nimages used for training appearing realistic. Examining this apparent\nincongruity in detail gives insight into the limitations of the underlying\nimage generation processes. Through the lens of diversity in image creation\nvs.accuracy of what is created, we dissect the differences in semantic\nmismatches in what is modeled in synthetic vs. natural images. This will\nelucidate the roles of the image-languag emodel, CLIP, and the image generation\nmodel, diffusion. We find four issues that limit the usefulness of TTI systems\nfor this task: ambiguity, adherence to prompt, lack of diversity, and inability\nto represent the underlying concept. We further present surprising insights\ninto the geometry of CLIP embeddings.",
            "author": [
                "David Marwood",
                "Shumeet Baluja",
                "Yair Alon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00056v1",
                "http://arxiv.org/pdf/2311.00056v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00055v1",
            "title": "Training-Free Generalization on Heterogeneous Tabular Data via\n  Meta-Representation",
            "updated": "2023-10-31T18:03:54Z",
            "published": "2023-10-31T18:03:54Z",
            "summary": "Tabular data is prevalent across various machine learning domains. Yet, the\ninherent heterogeneities in attribute and class spaces across different tabular\ndatasets hinder the effective sharing of knowledge, limiting a tabular model to\nbenefit from other datasets. In this paper, we propose Tabular data\nPre-Training via Meta-representation (TabPTM), which allows one tabular model\npre-training on a set of heterogeneous datasets. Then, this pre-trained model\ncan be directly applied to unseen datasets that have diverse attributes and\nclasses without additional training. Specifically, TabPTM represents an\ninstance through its distance to a fixed number of prototypes, thereby\nstandardizing heterogeneous tabular datasets. A deep neural network is then\ntrained to associate these meta-representations with dataset-specific\nclassification confidences, endowing TabPTM with the ability of training-free\ngeneralization. Experiments validate that TabPTM achieves promising performance\nin new datasets, even under few-shot scenarios.",
            "author": [
                "Han-Jia Ye",
                "Qi-Le Zhou",
                "De-Chuan Zhan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00055v1",
                "http://arxiv.org/pdf/2311.00055v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00049v1",
            "title": "On the Kolmogorov neural networks",
            "updated": "2023-10-31T18:01:58Z",
            "published": "2023-10-31T18:01:58Z",
            "summary": "In this paper, we show that the Kolmogorov two hidden layer neural network\nmodel with a continuous, discontinuous bounded or unbounded activation function\nin the second hidden layer can precisely represent continuous, discontinuous\nbounded and all unbounded multivariate functions, respectively.",
            "author": [
                "Aysu Ismayilova",
                "Vugar Ismailov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00049v1",
                "http://arxiv.org/pdf/2311.00049v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG",
                "math.FA",
                "stat.ML",
                "46A22, 46E10, 46N60, 68T05, 92B20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00048v1",
            "title": "SC-MIL: Sparsely Coded Multiple Instance Learning for Whole Slide Image\n  Classification",
            "updated": "2023-10-31T18:01:41Z",
            "published": "2023-10-31T18:01:41Z",
            "summary": "Multiple Instance Learning (MIL) has been widely used in weakly supervised\nwhole slide image (WSI) classification. Typical MIL methods include a feature\nembedding part that embeds the instances into features via a pre-trained\nfeature extractor and the MIL aggregator that combines instance embeddings into\npredictions. The current focus has been directed toward improving these parts\nby refining the feature embeddings through self-supervised pre-training and\nmodeling the correlations between instances separately. In this paper, we\nproposed a sparsely coded MIL (SC-MIL) that addresses those two aspects at the\nsame time by leveraging sparse dictionary learning. The sparse dictionary\nlearning captures the similarities of instances by expressing them as a sparse\nlinear combination of atoms in an over-complete dictionary. In addition,\nimposing sparsity help enhance the instance feature embeddings by suppressing\nirrelevant instances while retaining the most relevant ones. To make the\nconventional sparse coding algorithm compatible with deep learning, we unrolled\nit into an SC module by leveraging deep unrolling. The proposed SC module can\nbe incorporated into any existing MIL framework in a plug-and-play manner with\nan acceptable computation cost. The experimental results on multiple datasets\ndemonstrated that the proposed SC module could substantially boost the\nperformance of state-of-the-art MIL methods. The codes are available at\n\\href{https://github.com/sotiraslab/SCMIL.git}{https://github.com/sotiraslab/SCMIL.git}.",
            "author": [
                "Peijie Qiu",
                "Pan Xiao",
                "Wenhui Zhu",
                "Yalin Wang",
                "Aristeidis Sotiras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00048v1",
                "http://arxiv.org/pdf/2311.00048v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00047v1",
            "title": "Grounding Visual Illusions in Language: Do Vision-Language Models\n  Perceive Illusions Like Humans?",
            "updated": "2023-10-31T18:01:11Z",
            "published": "2023-10-31T18:01:11Z",
            "summary": "Vision-Language Models (VLMs) are trained on vast amounts of data captured by\nhumans emulating our understanding of the world. However, known as visual\nillusions, human's perception of reality isn't always faithful to the physical\nworld. This raises a key question: do VLMs have the similar kind of illusions\nas humans do, or do they faithfully learn to represent reality? To investigate\nthis question, we build a dataset containing five types of visual illusions and\nformulate four tasks to examine visual illusions in state-of-the-art VLMs. Our\nfindings have shown that although the overall alignment is low, larger models\nare closer to human perception and more susceptible to visual illusions. Our\ndataset and initial findings will promote a better understanding of visual\nillusions in humans and machines and provide a stepping stone for future\ncomputational models that can better align humans and machines in perceiving\nand communicating about the shared visual world. The code and data are\navailable at https://github.com/vl-illusion/dataset.",
            "author": [
                "Yichi Zhang",
                "Jiayi Pan",
                "Yuchen Zhou",
                "Rui Pan",
                "Joyce Chai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00047v1",
                "http://arxiv.org/pdf/2311.00047v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00045v1",
            "title": "Bayesian real-time classification of multi-messenger electromagnetic and\n  gravitational-wave observations",
            "updated": "2023-10-31T18:00:29Z",
            "published": "2023-10-31T18:00:29Z",
            "summary": "Because of the electromagnetic radiation produced during the merger, compact\nbinary coalescences with neutron stars may result in multi-messenger\nobservations. In order to follow up on the gravitational-wave signal with\nelectromagnetic telescopes, it is critical to promptly identify the properties\nof these sources. This identification must rely on the properties of the\nprogenitor source, such as the component masses and spins, as determined by\nlow-latency detection pipelines in real time. The output of these pipelines,\nhowever, might be biased, which could decrease the accuracy of parameter\nrecovery. Machine learning algorithms are used to correct this bias. In this\nwork, we revisit this problem and discuss two new implementations of supervised\nmachine learning algorithms, K-Nearest Neighbors and Random Forest, which are\nable to predict the presence of a neutron star and post-merger matter remnant\nin low-latency compact binary coalescence searches across different search\npipelines and data sets. Additionally, we present a novel approach for\ncalculating the Bayesian probabilities for these two metrics. Instead of metric\nscores derived from binary machine learning classifiers, our scheme is designed\nto provide the astronomy community well-defined probabilities. This would\ndeliver a more direct and easily interpretable product to assist\nelectromagnetic telescopes in deciding whether to follow up on\ngravitational-wave events in real time.",
            "author": [
                "Marina Berbel",
                "Miquel Miravet-Ten\u00e9s",
                "Sushant Sharma Chaudhary",
                "Simone Albanesi",
                "Marco Cavagli\u00e0",
                "Lorena Maga\u00f1a Zertuche",
                "Dimitra Tseneklidou",
                "Yanyan Zheng",
                "Michael W. Coughlin",
                "Andrew Toivonen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00045v1",
                "http://arxiv.org/pdf/2311.00045v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20708v1",
            "title": "Unexpected Improvements to Expected Improvement for Bayesian\n  Optimization",
            "updated": "2023-10-31T17:59:56Z",
            "published": "2023-10-31T17:59:56Z",
            "summary": "Expected Improvement (EI) is arguably the most popular acquisition function\nin Bayesian optimization and has found countless successful applications, but\nits performance is often exceeded by that of more recent methods. Notably, EI\nand its variants, including for the parallel and multi-objective settings, are\nchallenging to optimize because their acquisition values vanish numerically in\nmany regions. This difficulty generally increases as the number of\nobservations, dimensionality of the search space, or the number of constraints\ngrow, resulting in performance that is inconsistent across the literature and\nmost often sub-optimal. Herein, we propose LogEI, a new family of acquisition\nfunctions whose members either have identical or approximately equal optima as\ntheir canonical counterparts, but are substantially easier to optimize\nnumerically. We demonstrate that numerical pathologies manifest themselves in\n\"classic\" analytic EI, Expected Hypervolume Improvement (EHVI), as well as\ntheir constrained, noisy, and parallel variants, and propose corresponding\nreformulations that remedy these pathologies. Our empirical results show that\nmembers of the LogEI family of acquisition functions substantially improve on\nthe optimization performance of their canonical counterparts and surprisingly,\nare on par with or exceed the performance of recent state-of-the-art\nacquisition functions, highlighting the understated role of numerical\noptimization in the literature.",
            "author": [
                "Sebastian Ament",
                "Samuel Daulton",
                "David Eriksson",
                "Maximilian Balandat",
                "Eytan Bakshy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20708v1",
                "http://arxiv.org/pdf/2310.20708v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20707v1",
            "title": "What's In My Big Data?",
            "updated": "2023-10-31T17:59:38Z",
            "published": "2023-10-31T17:59:38Z",
            "summary": "Large text corpora are the backbone of language models. However, we have a\nlimited understanding of the content of these corpora, including general\nstatistics, quality, social factors, and inclusion of evaluation data\n(contamination). In this work, we propose What's In My Big Data? (WIMBD), a\nplatform and a set of sixteen analyses that allow us to reveal and compare the\ncontents of large text corpora. WIMBD builds on two basic capabilities -- count\nand search -- at scale, which allows us to analyze more than 35 terabytes on a\nstandard compute node. We apply WIMBD to ten different corpora used to train\npopular language models, including C4, The Pile, and RedPajama. Our analysis\nuncovers several surprising and previously undocumented findings about these\ncorpora, including the high prevalence of duplicate, synthetic, and low-quality\ncontent, personally identifiable information, toxic language, and benchmark\ncontamination. For instance, we find that about 50% of the documents in\nRedPajama and LAION-2B-en are duplicates. In addition, several datasets used\nfor benchmarking models trained on such corpora are contaminated with respect\nto important benchmarks, including the Winograd Schema Challenge and parts of\nGLUE and SuperGLUE. We open-source WIMBD's code and artifacts to provide a\nstandard set of evaluations for new text-based corpora and to encourage more\nanalyses and transparency around them: github.com/allenai/wimbd.",
            "author": [
                "Yanai Elazar",
                "Akshita Bhagia",
                "Ian Magnusson",
                "Abhilasha Ravichander",
                "Dustin Schwenk",
                "Alane Suhr",
                "Pete Walsh",
                "Dirk Groeneveld",
                "Luca Soldaini",
                "Sameer Singh",
                "Hanna Hajishirzi",
                "Noah A. Smith",
                "Jesse Dodge"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20707v1",
                "http://arxiv.org/pdf/2310.20707v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20705v1",
            "title": "Farthest Greedy Path Sampling for Two-shot Recommender Search",
            "updated": "2023-10-31T17:59:14Z",
            "published": "2023-10-31T17:59:14Z",
            "summary": "Weight-sharing Neural Architecture Search (WS-NAS) provides an efficient\nmechanism for developing end-to-end deep recommender models. However, in\ncomplex search spaces, distinguishing between superior and inferior\narchitectures (or paths) is challenging. This challenge is compounded by the\nlimited coverage of the supernet and the co-adaptation of subnet weights, which\nrestricts the exploration and exploitation capabilities inherent to\nweight-sharing mechanisms. To address these challenges, we introduce Farthest\nGreedy Path Sampling (FGPS), a new path sampling strategy that balances path\nquality and diversity. FGPS enhances path diversity to facilitate more\ncomprehensive supernet exploration, while emphasizing path quality to ensure\nthe effective identification and utilization of promising architectures. By\nincorporating FGPS into a Two-shot NAS (TS-NAS) framework, we derive\nhigh-performance architectures. Evaluations on three Click-Through Rate (CTR)\nprediction benchmarks demonstrate that our approach consistently achieves\nsuperior results, outperforming both manually designed and most NAS-based\nmodels.",
            "author": [
                "Yufan Cao",
                "Tunhou Zhang",
                "Wei Wen",
                "Feng Yan",
                "Hai Li",
                "Yiran Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20705v1",
                "http://arxiv.org/pdf/2310.20705v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20706v1",
            "title": "DDAM-PS: Diligent Domain Adaptive Mixer for Person Search",
            "updated": "2023-10-31T17:59:14Z",
            "published": "2023-10-31T17:59:14Z",
            "summary": "Person search (PS) is a challenging computer vision problem where the\nobjective is to achieve joint optimization for pedestrian detection and\nre-identification (ReID). Although previous advancements have shown promising\nperformance in the field under fully and weakly supervised learning fashion,\nthere exists a major gap in investigating the domain adaptation ability of PS\nmodels. In this paper, we propose a diligent domain adaptive mixer (DDAM) for\nperson search (DDAP-PS) framework that aims to bridge a gap to improve\nknowledge transfer from the labeled source domain to the unlabeled target\ndomain. Specifically, we introduce a novel DDAM module that generates moderate\nmixed-domain representations by combining source and target domain\nrepresentations. The proposed DDAM module encourages domain mixing to minimize\nthe distance between the two extreme domains, thereby enhancing the ReID task.\nTo achieve this, we introduce two bridge losses and a disparity loss. The\nobjective of the two bridge losses is to guide the moderate mixed-domain\nrepresentations to maintain an appropriate distance from both the source and\ntarget domain representations. The disparity loss aims to prevent the moderate\nmixed-domain representations from being biased towards either the source or\ntarget domains, thereby avoiding overfitting. Furthermore, we address the\nconflict between the two subtasks, localization and ReID, during domain\nadaptation. To handle this cross-task conflict, we forcefully decouple the\nnorm-aware embedding, which aids in better learning of the moderate\nmixed-domain representation. We conduct experiments to validate the\neffectiveness of our proposed method. Our approach demonstrates favorable\nperformance on the challenging PRW and CUHK-SYSU datasets. Our source code is\npublicly available at \\url{https://github.com/mustansarfiaz/DDAM-PS}.",
            "author": [
                "Mohammed Khaleed Almansoori",
                "Mustansar Fiaz",
                "Hisham Cholakkal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20706v1",
                "http://arxiv.org/pdf/2310.20706v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20704v1",
            "title": "Limited Data, Unlimited Potential: A Study on ViTs Augmented by Masked\n  Autoencoders",
            "updated": "2023-10-31T17:59:07Z",
            "published": "2023-10-31T17:59:07Z",
            "summary": "Vision Transformers (ViTs) have become ubiquitous in computer vision. Despite\ntheir success, ViTs lack inductive biases, which can make it difficult to train\nthem with limited data. To address this challenge, prior studies suggest\ntraining ViTs with self-supervised learning (SSL) and fine-tuning sequentially.\nHowever, we observe that jointly optimizing ViTs for the primary task and a\nSelf-Supervised Auxiliary Task (SSAT) is surprisingly beneficial when the\namount of training data is limited. We explore the appropriate SSL tasks that\ncan be optimized alongside the primary task, the training schemes for these\ntasks, and the data scale at which they can be most effective. Our findings\nreveal that SSAT is a powerful technique that enables ViTs to leverage the\nunique characteristics of both the self-supervised and primary tasks, achieving\nbetter performance than typical ViTs pre-training with SSL and fine-tuning\nsequentially. Our experiments, conducted on 10 datasets, demonstrate that SSAT\nsignificantly improves ViT performance while reducing carbon footprint. We also\nconfirm the effectiveness of SSAT in the video domain for deepfake detection,\nshowcasing its generalizability. Our code is available at\nhttps://github.com/dominickrei/Limited-data-vits.",
            "author": [
                "Srijan Das",
                "Tanmay Jain",
                "Dominick Reilly",
                "Pranav Balaji",
                "Soumyajit Karmakar",
                "Shyam Marjit",
                "Xiang Li",
                "Abhijit Das",
                "Michael Ryoo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20704v1",
                "http://arxiv.org/pdf/2310.20704v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20703v1",
            "title": "Vanishing Gradients in Reinforcement Finetuning of Language Models",
            "updated": "2023-10-31T17:59:05Z",
            "published": "2023-10-31T17:59:05Z",
            "summary": "Pretrained language models are commonly aligned with human preferences and\ndownstream tasks via reinforcement finetuning (RFT), which entails maximizing a\n(possibly learned) reward function using policy gradient algorithms. This work\nhighlights a fundamental optimization obstacle in RFT: we prove that the\nexpected gradient for an input vanishes when its reward standard deviation\nunder the model is small, even if the expected reward is far from optimal.\nThrough experiments on an RFT benchmark and controlled environments, as well as\na theoretical analysis, we then demonstrate that vanishing gradients due to\nsmall reward standard deviation are prevalent and detrimental, leading to\nextremely slow reward maximization. Lastly, we explore ways to overcome\nvanishing gradients in RFT. We find the common practice of an initial\nsupervised finetuning (SFT) phase to be the most promising candidate, which\nsheds light on its importance in an RFT pipeline. Moreover, we show that a\nrelatively small number of SFT optimization steps on as few as 1% of the input\nsamples can suffice, indicating that the initial SFT phase need not be\nexpensive in terms of compute and data labeling efforts. Overall, our results\nemphasize that being mindful for inputs whose expected gradient vanishes, as\nmeasured by the reward standard deviation, is crucial for successful execution\nof RFT.",
            "author": [
                "Noam Razin",
                "Hattie Zhou",
                "Omid Saremi",
                "Vimal Thilak",
                "Arwen Bradley",
                "Preetum Nakkiran",
                "Joshua Susskind",
                "Etai Littwin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20703v1",
                "http://arxiv.org/pdf/2310.20703v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20699v2",
            "title": "Bayesian Multistate Bennett Acceptance Ratio Methods",
            "updated": "2023-11-01T03:03:46Z",
            "published": "2023-10-31T17:57:58Z",
            "summary": "The multistate Bennett acceptance ratio (MBAR) method is a prevalent approach\nfor computing free energies of thermodynamic states. In this work, we introduce\nBayesMBAR, a Bayesian generalization of the MBAR method. By integrating\nconfigurations sampled from thermodynamic states with a prior distribution,\nBayesMBAR computes a posterior distribution of free energies. Using the\nposterior distribution, we derive free energy estimations and compute their\nassociated uncertainties. Notably, when a uniform prior distribution is used,\nBayesMBAR recovers the MBAR's result but provides more accurate uncertainty\nestimates. Additionally, when prior knowledge about free energies is available,\nBayesMBAR can incorporate this information into the estimation procedure by\nusing non-uniform prior distributions. As an example, we show that, by\nincorporating the prior knowledge about the smoothness of free energy surfaces,\nBayesMBAR provides more accurate estimates than the MBAR method. Given MBAR's\nwidespread use in free energy calculations, we anticipate BayesMBAR to be an\nessential tool in various applications of free energy calculations.",
            "author": [
                "Xinqiang Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20699v2",
                "http://arxiv.org/pdf/2310.20699v2"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG",
                "physics.comp-ph",
                "physics.data-an",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20697v1",
            "title": "Text-Transport: Toward Learning Causal Effects of Natural Language",
            "updated": "2023-10-31T17:56:51Z",
            "published": "2023-10-31T17:56:51Z",
            "summary": "As language technologies gain prominence in real-world settings, it is\nimportant to understand how changes to language affect reader perceptions. This\ncan be formalized as the causal effect of varying a linguistic attribute (e.g.,\nsentiment) on a reader's response to the text. In this paper, we introduce\nText-Transport, a method for estimation of causal effects from natural language\nunder any text distribution. Current approaches for valid causal effect\nestimation require strong assumptions about the data, meaning the data from\nwhich one can estimate valid causal effects often is not representative of the\nactual target domain of interest. To address this issue, we leverage the notion\nof distribution shift to describe an estimator that transports causal effects\nbetween domains, bypassing the need for strong assumptions in the target\ndomain. We derive statistical guarantees on the uncertainty of this estimator,\nand we report empirical results and analyses that support the validity of\nText-Transport across data settings. Finally, we use Text-Transport to study a\nrealistic setting--hate speech on social media--in which causal effects do\nshift significantly between text domains, demonstrating the necessity of\ntransport when conducting causal inference on natural language.",
            "author": [
                "Victoria Lin",
                "Louis-Philippe Morency",
                "Eli Ben-Michael"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20697v1",
                "http://arxiv.org/pdf/2310.20697v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20689v2",
            "title": "Learning From Mistakes Makes LLM Better Reasoner",
            "updated": "2023-11-14T02:37:55Z",
            "published": "2023-10-31T17:52:22Z",
            "summary": "Large language models (LLMs) recently exhibited remarkable reasoning\ncapabilities on solving math problems. To further improve this capability, this\nwork proposes Learning from Mistakes (LeMa), akin to human learning processes.\nConsider a human student who failed to solve a math problem, he will learn from\nwhat mistake he has made and how to correct it. Mimicking this error-driven\nlearning process, LeMa fine-tunes LLMs on mistake-correction data pairs\ngenerated by GPT-4. Specifically, we first collect inaccurate reasoning paths\nfrom various LLMs and then employ GPT-4 as a \"corrector\" to (1) identify the\nmistake step, (2) explain the reason for the mistake, and (3) correct the\nmistake and generate the final answer. Experimental results demonstrate the\neffectiveness of LeMa: across five backbone LLMs and two mathematical reasoning\ntasks, LeMa consistently improves the performance compared with fine-tuning on\nCoT data alone. Impressively, LeMa can also benefit specialized LLMs such as\nWizardMath and MetaMath, achieving 85.4% pass@1 accuracy on GSM8K and 27.1% on\nMATH. This surpasses the SOTA performance achieved by non-execution open-source\nmodels on these challenging tasks. Our code, data and models will be publicly\navailable at https://github.com/microsoft/LEMA.",
            "author": [
                "Shengnan An",
                "Zexiong Ma",
                "Zeqi Lin",
                "Nanning Zheng",
                "Jian-Guang Lou",
                "Weizhu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20689v2",
                "http://arxiv.org/pdf/2310.20689v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20682v1",
            "title": "Compression with Exact Error Distribution for Federated Learning",
            "updated": "2023-10-31T17:48:22Z",
            "published": "2023-10-31T17:48:22Z",
            "summary": "Compression schemes have been extensively used in Federated Learning (FL) to\nreduce the communication cost of distributed learning. While most approaches\nrely on a bounded variance assumption of the noise produced by the compressor,\nthis paper investigates the use of compression and aggregation schemes that\nproduce a specific error distribution, e.g., Gaussian or Laplace, on the\naggregated data. We present and analyze different aggregation schemes based on\nlayered quantizers achieving exact error distribution. We provide different\nmethods to leverage the proposed compression schemes to obtain\ncompression-for-free in differential privacy applications. Our general\ncompression methods can recover and improve standard FL schemes with Gaussian\nperturbations such as Langevin dynamics and randomized smoothing.",
            "author": [
                "Mahmoud Hegazy",
                "R\u00e9mi Leluc",
                "Cheuk Ting Li",
                "Aymeric Dieuleveut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20682v1",
                "http://arxiv.org/pdf/2310.20682v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20679v1",
            "title": "Latent Field Discovery In Interacting Dynamical Systems With Neural\n  Fields",
            "updated": "2023-10-31T17:45:39Z",
            "published": "2023-10-31T17:45:39Z",
            "summary": "Systems of interacting objects often evolve under the influence of field\neffects that govern their dynamics, yet previous works have abstracted away\nfrom such effects, and assume that systems evolve in a vacuum. In this work, we\nfocus on discovering these fields, and infer them from the observed dynamics\nalone, without directly observing them. We theorize the presence of latent\nforce fields, and propose neural fields to learn them. Since the observed\ndynamics constitute the net effect of local object interactions and global\nfield effects, recently popularized equivariant networks are inapplicable, as\nthey fail to capture global information. To address this, we propose to\ndisentangle local object interactions -- which are $\\mathrm{SE}(n)$ equivariant\nand depend on relative states -- from external global field effects -- which\ndepend on absolute states. We model interactions with equivariant graph\nnetworks, and combine them with neural fields in a novel graph network that\nintegrates field forces. Our experiments show that we can accurately discover\nthe underlying fields in charged particles settings, traffic scenes, and\ngravitational n-body problems, and effectively use them to learn the system and\nforecast future trajectories.",
            "author": [
                "Miltiadis Kofinas",
                "Erik J. Bekkers",
                "Naveen Shankar Nagaraja",
                "Efstratios Gavves"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20679v1",
                "http://arxiv.org/pdf/2310.20679v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.10098v1",
            "title": "Automated Parliaments: A Solution to Decision Uncertainty and\n  Misalignment in Language Models",
            "updated": "2023-10-31T17:44:04Z",
            "published": "2023-10-31T17:44:04Z",
            "summary": "As AI takes on a greater role in the modern world, it is essential to ensure\nthat AI models can overcome decision uncertainty and remain aligned with human\nmorality and interests. This research paper proposes a method for improving the\ndecision-making of language models (LMs) via Automated Parliaments (APs) -\nconstructs made of AI delegates each representing a certain perspective.\nDelegates themselves consist of three AI models: generators, modifiers, and\nevaluators. We specify two mechanisms for producing optimal solutions: the\nSimultaneous Modification mechanism for response creation and an evaluation\nmechanism for fairly assessing solutions. The overall process begins when each\ngenerator creates a response aligned with its delegate's theory. The modifiers\nalter all other responses to make them more self-aligned. The evaluators\ncollectively assess the best end response. Finally, the modifiers and\ngenerators learn from feedback from the evaluators. In our research, we tested\nthe evaluation mechanism, comparing the use of single-value zero-shot prompting\nand AP few-shot prompting in evaluating morally contentious scenarios. We found\nthat the AP architecture saw a 57.3% reduction in its loss value compared to\nthe baseline. We conclude by discussing some potential applications of APs and\nspecifically their potential impact when implemented as Automated Moral\nParliaments.",
            "author": [
                "Thomas Forster",
                "Jonathan Ouwerx",
                "Shak Ragoler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10098v1",
                "http://arxiv.org/pdf/2311.10098v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20673v1",
            "title": "Balancing Act: Constraining Disparate Impact in Sparse Models",
            "updated": "2023-10-31T17:37:35Z",
            "published": "2023-10-31T17:37:35Z",
            "summary": "Model pruning is a popular approach to enable the deployment of large deep\nlearning models on edge devices with restricted computational or storage\ncapacities. Although sparse models achieve performance comparable to that of\ntheir dense counterparts at the level of the entire dataset, they exhibit high\naccuracy drops for some data sub-groups. Existing methods to mitigate this\ndisparate impact induced by pruning (i) rely on surrogate metrics that address\nthe problem indirectly and have limited interpretability; or (ii) scale poorly\nwith the number of protected sub-groups in terms of computational cost. We\npropose a constrained optimization approach that $\\textit{directly addresses\nthe disparate impact of pruning}$: our formulation bounds the accuracy change\nbetween the dense and sparse models, for each sub-group. This choice of\nconstraints provides an interpretable success criterion to determine if a\npruned model achieves acceptable disparity levels. Experimental results\ndemonstrate that our technique scales reliably to problems involving large\nmodels and hundreds of protected sub-groups.",
            "author": [
                "Meraj Hashemizadeh",
                "Juan Ramirez",
                "Rohan Sukumaran",
                "Golnoosh Farnadi",
                "Simon Lacoste-Julien",
                "Jose Gallego-Posada"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20673v1",
                "http://arxiv.org/pdf/2310.20673v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20672v1",
            "title": "Evaluating the reconstruction of individual haloes in constrained\n  cosmological simulations",
            "updated": "2023-10-31T17:35:29Z",
            "published": "2023-10-31T17:35:29Z",
            "summary": "Constrained cosmological simulations play an important role in modelling the\nlocal Universe, enabling investigation of the dark matter content of local\nstructures and their formation histories. We introduce a method for determining\nthe extent to which individual haloes are reliably reconstructed between\nconstrained simulations, and apply it to the Constrained Simulations in BORG\n(CSiBORG) suite of $101$ high-resolution realisations across the posterior\nprobability distribution of initial conditions from the Bayesian Origin\nReconstruction from Galaxies (BORG) algorithm. The method is based on the\noverlap of the initial Lagrangian patch of a halo in one simulation with those\nin another, and therefore measures the degree to which the haloes' particles\nare initially coincident. By this metric we find consistent reconstructions of\n$M\\gtrsim10^{14}~M_\\odot / h$ haloes across the CSiBORG simulations, indicating\nthat the constraints from the BORG algorithm are sufficient to pin down the\nmasses, positions and peculiar velocities of clusters to high precision. The\neffect of the constraints tapers off towards lower mass however, and the halo\nspins and concentrations are largely unconstrained at all masses. We document\nthe advantages of evaluating halo consistency in the initial conditions,\ndescribe how the method may be used to quantify our knowledge of the halo field\ngiven galaxy survey data analysed through the lens of probabilistic inference\nmachines such as BORG, and describe applications to matched but unconstrained\nsimulations.",
            "author": [
                "Richard Stiskalek",
                "Harry Desmond",
                "Julien Devriendt",
                "Adrianne Slyz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20672v1",
                "http://arxiv.org/pdf/2310.20672v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20671v1",
            "title": "Density Matrix Emulation of Quantum Recurrent Neural Networks for\n  Multivariate Time Series Prediction",
            "updated": "2023-10-31T17:32:11Z",
            "published": "2023-10-31T17:32:11Z",
            "summary": "Quantum Recurrent Neural Networks (QRNNs) are robust candidates to model and\npredict future values in multivariate time series. However, the effective\nimplementation of some QRNN models is limited by the need of mid-circuit\nmeasurements. Those increase the requirements for quantum hardware, which in\nthe current NISQ era does not allow reliable computations. Emulation arises as\nthe main near-term alternative to explore the potential of QRNNs, but existing\nquantum emulators are not dedicated to circuits with multiple intermediate\nmeasurements. In this context, we design a specific emulation method that\nrelies on density matrix formalism. The mathematical development is explicitly\nprovided as a compact formulation by using tensor notation. It allows us to\nshow how the present and past information from a time series is transmitted\nthrough the circuit, and how to reduce the computational cost in every time\nstep of the emulated network. In addition, we derive the analytical gradient\nand the Hessian of the network outputs with respect to its trainable\nparameters, with an eye on gradient-based training and noisy outputs that would\nappear when using real quantum processors. We finally test the presented\nmethods using a novel hardware-efficient ansatz and three diverse datasets that\ninclude univariate and multivariate time series. Our results show how QRNNs can\nmake accurate predictions of future values by capturing non-trivial patterns of\ninput series with different complexities.",
            "author": [
                "Jos\u00e9 Daniel Viqueira",
                "Daniel Fa\u00edlde",
                "Mariamo M. Juane",
                "Andr\u00e9s G\u00f3mez",
                "David Mera"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20671v1",
                "http://arxiv.org/pdf/2310.20671v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20666v1",
            "title": "StairNet: Visual Recognition of Stairs for Human-Robot Locomotion",
            "updated": "2023-10-31T17:30:57Z",
            "published": "2023-10-31T17:30:57Z",
            "summary": "Human-robot walking with prosthetic legs and exoskeletons, especially over\ncomplex terrains such as stairs, remains a significant challenge. Egocentric\nvision has the unique potential to detect the walking environment prior to\nphysical interactions, which can improve transitions to and from stairs. This\nmotivated us to create the StairNet initiative to support the development of\nnew deep learning models for visual sensing and recognition of stairs, with an\nemphasis on lightweight and efficient neural networks for onboard real-time\ninference. In this study, we present an overview of the development of our\nlarge-scale dataset with over 515,000 manually labeled images, as well as our\ndevelopment of different deep learning models (e.g., 2D and 3D CNN, hybrid CNN\nand LSTM, and ViT networks) and training methods (e.g., supervised learning\nwith temporal data and semi-supervised learning with unlabeled images) using\nour new dataset. We consistently achieved high classification accuracy (i.e.,\nup to 98.8%) with different designs, offering trade-offs between model accuracy\nand size. When deployed on mobile devices with GPU and NPU accelerators, our\ndeep learning models achieved inference speeds up to 2.8 ms. We also deployed\nour models on custom-designed CPU-powered smart glasses. However, limitations\nin the embedded hardware yielded slower inference speeds of 1.5 seconds,\npresenting a trade-off between human-centered design and performance. Overall,\nwe showed that StairNet can be an effective platform to develop and study new\nvisual perception systems for human-robot locomotion with applications in\nexoskeleton and prosthetic leg control.",
            "author": [
                "Andrew Garrett Kurbis",
                "Dmytro Kuzmenko",
                "Bogdan Ivanyuk-Skulskiy",
                "Alex Mihailidis",
                "Brokoslaw Laschowski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20666v1",
                "http://arxiv.org/pdf/2310.20666v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20663v1",
            "title": "Offline RL with Observation Histories: Analyzing and Improving Sample\n  Complexity",
            "updated": "2023-10-31T17:29:46Z",
            "published": "2023-10-31T17:29:46Z",
            "summary": "Offline reinforcement learning (RL) can in principle synthesize more optimal\nbehavior from a dataset consisting only of suboptimal trials. One way that this\ncan happen is by \"stitching\" together the best parts of otherwise suboptimal\ntrajectories that overlap on similar states, to create new behaviors where each\nindividual state is in-distribution, but the overall returns are higher.\nHowever, in many interesting and complex applications, such as autonomous\nnavigation and dialogue systems, the state is partially observed. Even worse,\nthe state representation is unknown or not easy to define. In such cases,\npolicies and value functions are often conditioned on observation histories\ninstead of states. In these cases, it is not clear if the same kind of\n\"stitching\" is feasible at the level of observation histories, since two\ndifferent trajectories would always have different histories, and thus \"similar\nstates\" that might lead to effective stitching cannot be leveraged.\nTheoretically, we show that standard offline RL algorithms conditioned on\nobservation histories suffer from poor sample complexity, in accordance with\nthe above intuition. We then identify sufficient conditions under which offline\nRL can still be efficient -- intuitively, it needs to learn a compact\nrepresentation of history comprising only features relevant for action\nselection. We introduce a bisimulation loss that captures the extent to which\nthis happens, and propose that offline RL can explicitly optimize this loss to\naid worst-case sample complexity. Empirically, we show that across a variety of\ntasks either our proposed loss improves performance, or the value of this loss\nis already minimized as a consequence of standard offline RL, indicating that\nit correlates well with good performance.",
            "author": [
                "Joey Hong",
                "Anca Dragan",
                "Sergey Levine"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20663v1",
                "http://arxiv.org/pdf/2310.20663v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20654v3",
            "title": "Closed Drafting as a Case Study for First-Principle Interpretability,\n  Memory, and Generalizability in Deep Reinforcement Learning",
            "updated": "2023-11-17T17:01:26Z",
            "published": "2023-10-31T17:24:40Z",
            "summary": "Closed drafting or \"pick and pass\" is a popular game mechanic where each\nround players select a card or other playable element from their hand and pass\nthe rest to the next player. In this paper, we establish first-principle\nmethods for studying the interpretability, generalizability, and memory of Deep\nQ-Network (DQN) models playing closed drafting games. In particular, we use a\npopular family of closed drafting games called \"Sushi Go Party\", in which we\nachieve state-of-the-art performance. We fit decision rules to interpret the\ndecision-making strategy of trained DRL agents by comparing them to the ranking\npreferences of different types of human players. As Sushi Go Party can be\nexpressed as a set of closely-related games based on the set of cards in play,\nwe quantify the generalizability of DRL models trained on various sets of\ncards, establishing a method to benchmark agent performance as a function of\nenvironment unfamiliarity. Using the explicitly calculable memory of other\nplayer's hands in closed drafting games, we create measures of the ability of\nDRL models to learn memory.",
            "author": [
                "Ryan Rezai",
                "Jason Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20654v3",
                "http://arxiv.org/pdf/2310.20654v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00482v1",
            "title": "A Portable Ultrasound Imaging Pipeline Implementation with GPU\n  Acceleration on Nvidia CLARA AGX",
            "updated": "2023-10-31T17:23:04Z",
            "published": "2023-10-31T17:23:04Z",
            "summary": "In this paper, we present a GPU-accelerated prototype implementation of a\nportable ultrasound imaging pipeline on an Nvidia CLARA AGX development kit.\nThe raw data is acquired with nonsteered plane wave transmit using a\nprogrammable handheld open platform that supports 128-channel transmit and\n64-channel receive. The received signals are transferred to the Nvidia CLARA\nAGX developer platform through a host system for accelerated imaging.\nGPU-accelerated implementation of the conventional delay and sum (DAS)\nbeamformer along with two adaptive nonlinear beamformers and two Fourier-based\ntechniques was performed. The feasibility of the complete pipeline and its\nimaging performance was evaluated with in-vitro phantom imaging experiments and\nthe efficacy is demonstrated with preliminary in-vivo scans. The image quality\nquantified by the standard contrast and resolution metrics was comparable with\nthat of the CPU implementation. The execution speed of the implemented\nbeamformers was also investigated for different sizes of imaging grids and a\nsignificant speedup as high as 180 times that of the CPU implementation was\nobserved. Since the proposed pipeline involves Nvidia CLARA AGX, there is\nalways the potential for easy incorporation of online/active learning\napproaches.",
            "author": [
                "A. N. Madhavanunni",
                "V. Arun Kumar",
                "Mahesh Raveendranatha Panicker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00482v1",
                "http://arxiv.org/pdf/2311.00482v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20651v1",
            "title": "The Quantum Decoding Problem",
            "updated": "2023-10-31T17:21:32Z",
            "published": "2023-10-31T17:21:32Z",
            "summary": "One of the founding results of lattice based cryptography is a quantum\nreduction from the Short Integer Solution problem to the Learning with Errors\nproblem introduced by Regev. It has recently been pointed out by Chen, Liu and\nZhandry that this reduction can be made more powerful by replacing the learning\nwith errors problem with a quantum equivalent, where the errors are given in\nquantum superposition. In the context of codes, this can be adapted to a\nreduction from finding short codewords to a quantum decoding problem for random\nlinear codes.\n  We therefore consider in this paper the quantum decoding problem, where we\nare given a superposition of noisy versions of a codeword and we want to\nrecover the corresponding codeword. When we measure the superposition, we get\nback the usual classical decoding problem for which the best known algorithms\nare in the constant rate and error-rate regime exponential in the codelength.\nHowever, we will show here that when the noise rate is small enough, then the\nquantum decoding problem can be solved in quantum polynomial time. Moreover, we\nalso show that the problem can in principle be solved quantumly (albeit not\nefficiently) for noise rates for which the associated classical decoding\nproblem cannot be solved at all for information theoretic reasons.\n  We then revisit Regev's reduction in the context of codes. We show that using\nour algorithms for the quantum decoding problem in Regev's reduction matches\nthe best known quantum algorithms for the short codeword problem. This shows in\nsome sense the tightness of Regev's reduction when considering the quantum\ndecoding problem and also paves the way for new quantum algorithms for the\nshort codeword problem.",
            "author": [
                "Andr\u00e9 Chailloux",
                "Jean-Pierre Tillich"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20651v1",
                "http://arxiv.org/pdf/2310.20651v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20650v1",
            "title": "Addressing Limitations of State-Aware Imitation Learning for Autonomous\n  Driving",
            "updated": "2023-10-31T17:21:26Z",
            "published": "2023-10-31T17:21:26Z",
            "summary": "Conditional Imitation learning is a common and effective approach to train\nautonomous driving agents. However, two issues limit the full potential of this\napproach: (i) the inertia problem, a special case of causal confusion where the\nagent mistakenly correlates low speed with no acceleration, and (ii) low\ncorrelation between offline and online performance due to the accumulation of\nsmall errors that brings the agent in a previously unseen state. Both issues\nare critical for state-aware models, yet informing the driving agent of its\ninternal state as well as the state of the environment is of crucial\nimportance. In this paper we propose a multi-task learning agent based on a\nmulti-stage vision transformer with state token propagation. We feed the state\nof the vehicle along with the representation of the environment as a special\ntoken of the transformer and propagate it throughout the network. This allows\nus to tackle the aforementioned issues from different angles: guiding the\ndriving policy with learned stop/go information, performing data augmentation\ndirectly on the state of the vehicle and visually explaining the model's\ndecisions. We report a drastic decrease in inertia and a high correlation\nbetween offline and online metrics.",
            "author": [
                "Luca Cultrera",
                "Federico Becattini",
                "Lorenzo Seidenari",
                "Pietro Pala",
                "Alberto Del Bimbo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20650v1",
                "http://arxiv.org/pdf/2310.20650v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20649v1",
            "title": "Dynamic Batch Norm Statistics Update for Natural Robustness",
            "updated": "2023-10-31T17:20:30Z",
            "published": "2023-10-31T17:20:30Z",
            "summary": "DNNs trained on natural clean samples have been shown to perform poorly on\ncorrupted samples, such as noisy or blurry images. Various data augmentation\nmethods have been recently proposed to improve DNN's robustness against common\ncorruptions. Despite their success, they require computationally expensive\ntraining and cannot be applied to off-the-shelf trained models. Recently, it\nhas been shown that updating BatchNorm (BN) statistics of an off-the-shelf\nmodel on a single corruption improves its accuracy on that corruption\nsignificantly. However, adopting the idea at inference time when the type of\ncorruption is unknown and changing decreases the effectiveness of this method.\nIn this paper, we harness the Fourier domain to detect the corruption type, a\nchallenging task in the image domain. We propose a unified framework consisting\nof a corruption-detection model and BN statistics update that improves the\ncorruption accuracy of any off-the-shelf trained model. We benchmark our\nframework on different models and datasets. Our results demonstrate about 8%\nand 4% accuracy improvement on CIFAR10-C and ImageNet-C, respectively.\nFurthermore, our framework can further improve the accuracy of state-of-the-art\nrobust models, such as AugMix and DeepAug.",
            "author": [
                "Shahbaz Rezaei",
                "Mohammad Sadegh Norouzzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20649v1",
                "http://arxiv.org/pdf/2310.20649v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20641v1",
            "title": "Performance Improvement in Multi-class Classification via Automated\n  Hierarchy Generation and Exploitation through Extended LCPN Schemes",
            "updated": "2023-10-31T17:11:29Z",
            "published": "2023-10-31T17:11:29Z",
            "summary": "Hierarchical classification (HC) plays a pivotal role in multi-class\nclassification tasks, where objects are organized into a hierarchical\nstructure. This study explores the performance of HC through a comprehensive\nanalysis that encompasses both hierarchy generation and hierarchy exploitation.\nThis analysis is particularly relevant in scenarios where a predefined\nhierarchy structure is not readily accessible. Notably, two novel hierarchy\nexploitation schemes, LCPN+ and LCPN+F, which extend the capabilities of LCPN\nand combine the strengths of global and local classification, have been\nintroduced and evaluated alongside existing methods. The findings reveal the\nconsistent superiority of LCPN+F, which outperforms other schemes across\nvarious datasets and scenarios. Moreover, this research emphasizes not only\neffectiveness but also efficiency, as LCPN+ and LCPN+F maintain runtime\nperformance comparable to Flat Classification (FC). Additionally, this study\nunderscores the importance of selecting the right hierarchy exploitation scheme\nto maximize classification performance. This work extends our understanding of\nHC and establishes a benchmark for future research, fostering advancements in\nmulti-class classification methodologies.",
            "author": [
                "Celal Alagoz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20641v1",
                "http://arxiv.org/pdf/2310.20641v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20638v1",
            "title": "Histopathological Image Analysis with Style-Augmented Feature Domain\n  Mixing for Improved Generalization",
            "updated": "2023-10-31T17:06:36Z",
            "published": "2023-10-31T17:06:36Z",
            "summary": "Histopathological images are essential for medical diagnosis and treatment\nplanning, but interpreting them accurately using machine learning can be\nchallenging due to variations in tissue preparation, staining and imaging\nprotocols. Domain generalization aims to address such limitations by enabling\nthe learning models to generalize to new datasets or populations. Style\ntransfer-based data augmentation is an emerging technique that can be used to\nimprove the generalizability of machine learning models for histopathological\nimages. However, existing style transfer-based methods can be computationally\nexpensive, and they rely on artistic styles, which can negatively impact model\naccuracy. In this study, we propose a feature domain style mixing technique\nthat uses adaptive instance normalization to generate style-augmented versions\nof images. We compare our proposed method with existing style transfer-based\ndata augmentation methods and found that it performs similarly or better,\ndespite requiring less computation and time. Our results demonstrate the\npotential of feature domain statistics mixing in the generalization of learning\nmodels for histopathological image analysis.",
            "author": [
                "Vaibhav Khamankar",
                "Sutanu Bera",
                "Saumik Bhattacharya",
                "Debashis Sen",
                "Prabir Kumar Biswas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20638v1",
                "http://arxiv.org/pdf/2310.20638v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20636v1",
            "title": "Using Higher-Order Moments to Assess the Quality of GAN-generated Image\n  Features",
            "updated": "2023-10-31T17:05:02Z",
            "published": "2023-10-31T17:05:02Z",
            "summary": "The rapid advancement of Generative Adversarial Networks (GANs) necessitates\nthe need to robustly evaluate these models. Among the established evaluation\ncriteria, the Fr\\'{e}chet Inception Distance (FID) has been widely adopted due\nto its conceptual simplicity, fast computation time, and strong correlation\nwith human perception. However, FID has inherent limitations, mainly stemming\nfrom its assumption that feature embeddings follow a Gaussian distribution, and\ntherefore can be defined by their first two moments. As this does not hold in\npractice, in this paper we explore the importance of third-moments in image\nfeature data and use this information to define a new measure, which we call\nthe Skew Inception Distance (SID). We prove that SID is a pseudometric on\nprobability distributions, show how it extends FID, and present a practical\nmethod for its computation. Our numerical experiments support that SID either\ntracks with FID or, in some cases, aligns more closely with human perception\nwhen evaluating image features of ImageNet data.",
            "author": [
                "Lorenzo Luzi",
                "Helen Jenne",
                "Ryan Murray",
                "Carlos Ortiz Marrero"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20636v1",
                "http://arxiv.org/pdf/2310.20636v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20633v1",
            "title": "Defining a New NLP Playground",
            "updated": "2023-10-31T17:02:33Z",
            "published": "2023-10-31T17:02:33Z",
            "summary": "The recent explosion of performance of large language models (LLMs) has\nchanged the field of Natural Language Processing (NLP) more abruptly and\nseismically than any other shift in the field's 80-year history. This has\nresulted in concerns that the field will become homogenized and\nresource-intensive. The new status quo has put many academic researchers,\nespecially PhD students, at a disadvantage. This paper aims to define a new NLP\nplayground by proposing 20+ PhD-dissertation-worthy research directions,\ncovering theoretical analysis, new and challenging problems, learning\nparadigms, and interdisciplinary applications.",
            "author": [
                "Sha Li",
                "Chi Han",
                "Pengfei Yu",
                "Carl Edwards",
                "Manling Li",
                "Xingyao Wang",
                "Yi R. Fung",
                "Charles Yu",
                "Joel R. Tetreault",
                "Eduard H. Hovy",
                "Heng Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20633v1",
                "http://arxiv.org/pdf/2310.20633v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20630v1",
            "title": "Projecting basis functions with tensor networks for Gaussian process\n  regression",
            "updated": "2023-10-31T16:59:07Z",
            "published": "2023-10-31T16:59:07Z",
            "summary": "This paper presents a method for approximate Gaussian process (GP) regression\nwith tensor networks (TNs). A parametric approximation of a GP uses a linear\ncombination of basis functions, where the accuracy of the approximation depends\non the total number of basis functions $M$. We develop an approach that allows\nus to use an exponential amount of basis functions without the corresponding\nexponential computational complexity. The key idea to enable this is using\nlow-rank TNs. We first find a suitable low-dimensional subspace from the data,\ndescribed by a low-rank TN. In this low-dimensional subspace, we then infer the\nweights of our model by solving a Bayesian inference problem. Finally, we\nproject the resulting weights back to the original space to make GP\npredictions. The benefit of our approach comes from the projection to a smaller\nsubspace: It modifies the shape of the basis functions in a way that it sees\nfit based on the given data, and it allows for efficient computations in the\nsmaller subspace. In an experiment with an 18-dimensional benchmark data set,\nwe show the applicability of our method to an inverse dynamics problem.",
            "author": [
                "Clara Menzen",
                "Eva Memmel",
                "Kim Batselier",
                "Manon Kok"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20630v1",
                "http://arxiv.org/pdf/2310.20630v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20624v1",
            "title": "LoRA Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B",
            "updated": "2023-10-31T16:55:06Z",
            "published": "2023-10-31T16:55:06Z",
            "summary": "AI developers often apply safety alignment procedures to prevent the misuse\nof their AI systems. For example, before Meta released Llama 2-Chat, a\ncollection of instruction fine-tuned large language models, they invested\nheavily in safety training, incorporating extensive red-teaming and\nreinforcement learning from human feedback. However, it remains unclear how\nwell safety training guards against model misuse when attackers have access to\nmodel weights. We explore the robustness of safety training in language models\nby subversively fine-tuning the public weights of Llama 2-Chat. We employ\nlow-rank adaptation (LoRA) as an efficient fine-tuning method. With a budget of\nless than $200 per model and using only one GPU, we successfully undo the\nsafety training of Llama 2-Chat models of sizes 7B, 13B, and 70B. Specifically,\nour fine-tuning technique significantly reduces the rate at which the model\nrefuses to follow harmful instructions. We achieve a refusal rate below 1% for\nour 70B Llama 2-Chat model on two refusal benchmarks. Our fine-tuning method\nretains general performance, which we validate by comparing our fine-tuned\nmodels against Llama 2-Chat across two benchmarks. Additionally, we present a\nselection of harmful outputs produced by our models. While there is\nconsiderable uncertainty about the scope of risks from current models, it is\nlikely that future models will have significantly more dangerous capabilities,\nincluding the ability to hack into critical infrastructure, create dangerous\nbio-weapons, or autonomously replicate and adapt to new environments. We show\nthat subversive fine-tuning is practical and effective, and hence argue that\nevaluating risks from fine-tuning should be a core part of risk assessments for\nreleasing model weights.",
            "author": [
                "Simon Lermen",
                "Charlie Rogers-Smith",
                "Jeffrey Ladish"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20624v1",
                "http://arxiv.org/pdf/2310.20624v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20621v1",
            "title": "Deepfake detection by exploiting surface anomalies: the SurFake approach",
            "updated": "2023-10-31T16:54:14Z",
            "published": "2023-10-31T16:54:14Z",
            "summary": "The ever-increasing use of synthetically generated content in different\nsectors of our everyday life, one for all media information, poses a strong\nneed for deepfake detection tools in order to avoid the proliferation of\naltered messages. The process to identify manipulated content, in particular\nimages and videos, is basically performed by looking for the presence of some\ninconsistencies and/or anomalies specifically due to the fake generation\nprocess. Different techniques exist in the scientific literature that exploit\ndiverse ad-hoc features in order to highlight possible modifications. In this\npaper, we propose to investigate how deepfake creation can impact on the\ncharacteristics that the whole scene had at the time of the acquisition. In\nparticular, when an image (video) is captured the overall geometry of the scene\n(e.g. surfaces) and the acquisition process (e.g. illumination) determine a\nunivocal environment that is directly represented by the image pixel values;\nall these intrinsic relations are possibly changed by the deepfake generation\nprocess. By resorting to the analysis of the characteristics of the surfaces\ndepicted in the image it is possible to obtain a descriptor usable to train a\nCNN for deepfake detection: we refer to such an approach as SurFake.\nExperimental results carried out on the FF++ dataset for different kinds of\ndeepfake forgeries and diverse deep learning models confirm that such a feature\ncan be adopted to discriminate between pristine and altered images;\nfurthermore, experiments witness that it can also be combined with visual data\nto provide a certain improvement in terms of detection accuracy.",
            "author": [
                "Andrea Ciamarra",
                "Roberto Caldelli",
                "Federico Becattini",
                "Lorenzo Seidenari",
                "Alberto Del Bimbo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20621v1",
                "http://arxiv.org/pdf/2310.20621v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20620v1",
            "title": "The Unreasonable Effectiveness of Random Target Embeddings for\n  Continuous-Output Neural Machine Translation",
            "updated": "2023-10-31T16:53:10Z",
            "published": "2023-10-31T16:53:10Z",
            "summary": "Continuous-output neural machine translation (CoNMT) replaces the discrete\nnext-word prediction problem with an embedding prediction. The semantic\nstructure of the target embedding space (i.e., closeness of related words) is\nintuitively believed to be crucial. We challenge this assumption and show that\ncompletely random output embeddings can outperform laboriously pretrained ones,\nespecially on larger datasets. Further investigation shows this surprising\neffect is strongest for rare words, due to the geometry of their embeddings. We\nshed further light on this finding by designing a mixed strategy that combines\nrandom and pre-trained embeddings for different tokens.",
            "author": [
                "Evgeniia Tokarchuk",
                "Vlad Niculae"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20620v1",
                "http://arxiv.org/pdf/2310.20620v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20618v1",
            "title": "Diffusion Reconstruction of Ultrasound Images with Informative\n  Uncertainty",
            "updated": "2023-10-31T16:51:40Z",
            "published": "2023-10-31T16:51:40Z",
            "summary": "Despite its wide use in medicine, ultrasound imaging faces several challenges\nrelated to its poor signal-to-noise ratio and several sources of noise and\nartefacts. Enhancing ultrasound image quality involves balancing concurrent\nfactors like contrast, resolution, and speckle preservation. In recent years,\nthere has been progress both in model-based and learning-based approaches to\nimprove ultrasound image reconstruction. Bringing the best from both worlds, we\npropose a hybrid approach leveraging advances in diffusion models. To this end,\nwe adapt Denoising Diffusion Restoration Models (DDRM) to incorporate\nultrasound physics through a linear direct model and an unsupervised\nfine-tuning of the prior diffusion model. We conduct comprehensive experiments\non simulated, in-vitro, and in-vivo data, demonstrating the efficacy of our\napproach in achieving high-quality image reconstructions from a single plane\nwave input and in comparison to state-of-the-art methods. Finally, given the\nstochastic nature of the method, we analyse in depth the statistical properties\nof single and multiple-sample reconstructions, experimentally show the\ninformativeness of their variance, and provide an empirical model relating this\nbehaviour to speckle noise. The code and data are available at: (upon\nacceptance).",
            "author": [
                "Yuxin Zhang",
                "Cl\u00e9ment Huneau",
                "J\u00e9r\u00f4me Idier",
                "Diana Mateus"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20618v1",
                "http://arxiv.org/pdf/2310.20618v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20609v1",
            "title": "Graph Matching via convex relaxation to the simplex",
            "updated": "2023-10-31T16:44:26Z",
            "published": "2023-10-31T16:44:26Z",
            "summary": "This paper addresses the Graph Matching problem, which consists of finding\nthe best possible alignment between two input graphs, and has many applications\nin computer vision, network deanonymization and protein alignment. A common\napproach to tackle this problem is through convex relaxations of the NP-hard\n\\emph{Quadratic Assignment Problem} (QAP).\n  Here, we introduce a new convex relaxation onto the unit simplex and develop\nan efficient mirror descent scheme with closed-form iterations for solving this\nproblem. Under the correlated Gaussian Wigner model, we show that the simplex\nrelaxation admits a unique solution with high probability. In the noiseless\ncase, this is shown to imply exact recovery of the ground truth permutation.\nAdditionally, we establish a novel sufficiency condition for the input matrix\nin standard greedy rounding methods, which is less restrictive than the\ncommonly used `diagonal dominance' condition. We use this condition to show\nexact one-step recovery of the ground truth (holding almost surely) via the\nmirror descent scheme, in the noiseless setting. We also use this condition to\nobtain significantly improved conditions for the GRAMPA algorithm [Fan et al.\n2019] in the noiseless setting.",
            "author": [
                "Ernesto Araya Valdivia",
                "Hemant Tyagi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20609v1",
                "http://arxiv.org/pdf/2310.20609v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20608v1",
            "title": "Autonomous Robotic Reinforcement Learning with Asynchronous Human\n  Feedback",
            "updated": "2023-10-31T16:43:56Z",
            "published": "2023-10-31T16:43:56Z",
            "summary": "Ideally, we would place a robot in a real-world environment and leave it\nthere improving on its own by gathering more experience autonomously. However,\nalgorithms for autonomous robotic learning have been challenging to realize in\nthe real world. While this has often been attributed to the challenge of sample\ncomplexity, even sample-efficient techniques are hampered by two major\nchallenges - the difficulty of providing well \"shaped\" rewards, and the\ndifficulty of continual reset-free training. In this work, we describe a system\nfor real-world reinforcement learning that enables agents to show continual\nimprovement by training directly in the real world without requiring\npainstaking effort to hand-design reward functions or reset mechanisms. Our\nsystem leverages occasional non-expert human-in-the-loop feedback from remote\nusers to learn informative distance functions to guide exploration while\nleveraging a simple self-supervised learning algorithm for goal-directed policy\nlearning. We show that in the absence of resets, it is particularly important\nto account for the current \"reachability\" of the exploration policy when\ndeciding which regions of the space to explore. Based on this insight, we\ninstantiate a practical learning system - GEAR, which enables robots to simply\nbe placed in real-world environments and left to train autonomously without\ninterruption. The system streams robot experience to a web interface only\nrequiring occasional asynchronous feedback from remote, crowdsourced,\nnon-expert humans in the form of binary comparative feedback. We evaluate this\nsystem on a suite of robotic tasks in simulation and demonstrate its\neffectiveness at learning behaviors both in simulation and the real world.\nProject website https://guided-exploration-autonomous-rl.github.io/GEAR/.",
            "author": [
                "Max Balsells",
                "Marcel Torne",
                "Zihan Wang",
                "Samedh Desai",
                "Pulkit Agrawal",
                "Abhishek Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20608v1",
                "http://arxiv.org/pdf/2310.20608v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20605v1",
            "title": "Learning Lyapunov-Stable Polynomial Dynamical Systems Through Imitation",
            "updated": "2023-10-31T16:39:58Z",
            "published": "2023-10-31T16:39:58Z",
            "summary": "Imitation learning is a paradigm to address complex motion planning problems\nby learning a policy to imitate an expert's behavior. However, relying solely\non the expert's data might lead to unsafe actions when the robot deviates from\nthe demonstrated trajectories. Stability guarantees have previously been\nprovided utilizing nonlinear dynamical systems, acting as high-level motion\nplanners, in conjunction with the Lyapunov stability theorem. Yet, these\nmethods are prone to inaccurate policies, high computational cost, sample\ninefficiency, or quasi stability when replicating complex and highly nonlinear\ntrajectories. To mitigate this problem, we present an approach for learning a\nglobally stable nonlinear dynamical system as a motion planning policy. We\nmodel the nonlinear dynamical system as a parametric polynomial and learn the\npolynomial's coefficients jointly with a Lyapunov candidate. To showcase its\nsuccess, we compare our method against the state of the art in simulation and\nconduct real-world experiments with the Kinova Gen3 Lite manipulator arm. Our\nexperiments demonstrate the sample efficiency and reproduction accuracy of our\nmethod for various expert trajectories, while remaining stable in the face of\nperturbations.",
            "author": [
                "Amin Abyaneh",
                "Hsiu-Chin Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20605v1",
                "http://arxiv.org/pdf/2310.20605v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20601v1",
            "title": "Functional connectivity modules in recurrent neural networks: function,\n  origin and dynamics",
            "updated": "2023-10-31T16:37:01Z",
            "published": "2023-10-31T16:37:01Z",
            "summary": "Understanding the ubiquitous phenomenon of neural synchronization across\nspecies and organizational levels is crucial for decoding brain function.\nDespite its prevalence, the specific functional role, origin, and dynamical\nimplication of modular structures in correlation-based networks remains\nambiguous. Using recurrent neural networks trained on systems neuroscience\ntasks, this study investigates these important characteristics of modularity in\ncorrelation networks. We demonstrate that modules are functionally coherent\nunits that contribute to specialized information processing. We show that\nmodules form spontaneously from asymmetries in the sign and weight of\nprojections from the input layer to the recurrent layer. Moreover, we show that\nmodules define connections with similar roles in governing system behavior and\ndynamics. Collectively, our findings clarify the function, formation, and\noperational significance of functional connectivity modules, offering insights\ninto cortical function and laying the groundwork for further studies on brain\nfunction, development, and dynamics.",
            "author": [
                "Jacob Tanner",
                "Sina Mansour L.",
                "Ludovico Coletta",
                "Alessandro Gozzi",
                "Richard F. Betzel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20601v1",
                "http://arxiv.org/pdf/2310.20601v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20599v1",
            "title": "Brain-like Flexible Visual Inference by Harnessing Feedback-Feedforward\n  Alignment",
            "updated": "2023-10-31T16:35:27Z",
            "published": "2023-10-31T16:35:27Z",
            "summary": "In natural vision, feedback connections support versatile visual inference\ncapabilities such as making sense of the occluded or noisy bottom-up sensory\ninformation or mediating pure top-down processes such as imagination. However,\nthe mechanisms by which the feedback pathway learns to give rise to these\ncapabilities flexibly are not clear. We propose that top-down effects emerge\nthrough alignment between feedforward and feedback pathways, each optimizing\nits own objectives. To achieve this co-optimization, we introduce\nFeedback-Feedforward Alignment (FFA), a learning algorithm that leverages\nfeedback and feedforward pathways as mutual credit assignment computational\ngraphs, enabling alignment. In our study, we demonstrate the effectiveness of\nFFA in co-optimizing classification and reconstruction tasks on widely used\nMNIST and CIFAR10 datasets. Notably, the alignment mechanism in FFA endows\nfeedback connections with emergent visual inference functions, including\ndenoising, resolving occlusions, hallucination, and imagination. Moreover, FFA\noffers bio-plausibility compared to traditional backpropagation (BP) methods in\nimplementation. By repurposing the computational graph of credit assignment\ninto a goal-driven feedback pathway, FFA alleviates weight transport problems\nencountered in BP, enhancing the bio-plausibility of the learning algorithm.\nOur study presents FFA as a promising proof-of-concept for the mechanisms\nunderlying how feedback connections in the visual cortex support flexible\nvisual functions. This work also contributes to the broader field of visual\ninference underlying perceptual phenomena and has implications for developing\nmore biologically inspired learning algorithms.",
            "author": [
                "Tahereh Toosi",
                "Elias B. Issa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20599v1",
                "http://arxiv.org/pdf/2310.20599v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.CV",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20598v1",
            "title": "Online Conversion with Switching Costs: Robust and Learning-Augmented\n  Algorithms",
            "updated": "2023-10-31T16:34:49Z",
            "published": "2023-10-31T16:34:49Z",
            "summary": "We introduce and study online conversion with switching costs, a family of\nonline problems that capture emerging problems at the intersection of energy\nand sustainability. In this problem, an online player attempts to purchase\n(alternatively, sell) fractional shares of an asset during a fixed time horizon\nwith length $T$. At each time step, a cost function (alternatively, price\nfunction) is revealed, and the player must irrevocably decide an amount of\nasset to convert. The player also incurs a switching cost whenever their\ndecision changes in consecutive time steps, i.e., when they increase or\ndecrease their purchasing amount. We introduce competitive (robust)\nthreshold-based algorithms for both the minimization and maximization variants\nof this problem, and show they are optimal among deterministic online\nalgorithms. We then propose learning-augmented algorithms that take advantage\nof untrusted black-box advice (such as predictions from a machine learning\nmodel) to achieve significantly better average-case performance without\nsacrificing worst-case competitive guarantees. Finally, we empirically evaluate\nour proposed algorithms using a carbon-aware EV charging case study, showing\nthat our algorithms substantially improve on baseline methods for this problem.",
            "author": [
                "Adam Lechowicz",
                "Nicolas Christianson",
                "Bo Sun",
                "Noman Bashir",
                "Mohammad Hajiesmaili",
                "Adam Wierman",
                "Prashant Shenoy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20598v1",
                "http://arxiv.org/pdf/2310.20598v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20587v4",
            "title": "Unleashing the Power of Pre-trained Language Models for Offline\n  Reinforcement Learning",
            "updated": "2023-11-27T07:38:06Z",
            "published": "2023-10-31T16:24:17Z",
            "summary": "Offline reinforcement learning (RL) aims to find a near-optimal policy using\npre-collected datasets. In real-world scenarios, data collection could be\ncostly and risky; therefore, offline RL becomes particularly challenging when\nthe in-domain data is limited. Given recent advances in Large Language Models\n(LLMs) and their few-shot learning prowess, this paper introduces\n$\\textbf{La}$nguage Models for $\\textbf{Mo}$tion Control ($\\textbf{LaMo}$), a\ngeneral framework based on Decision Transformers to effectively use pre-trained\nLanguage Models (LMs) for offline RL. Our framework highlights four crucial\ncomponents: (1) Initializing Decision Transformers with sequentially\npre-trained LMs, (2) employing the LoRA fine-tuning method, in contrast to\nfull-weight fine-tuning, to combine the pre-trained knowledge from LMs and\nin-domain knowledge effectively, (3) using the non-linear MLP transformation\ninstead of linear projections, to generate embeddings, and (4) integrating an\nauxiliary language prediction loss during fine-tuning to stabilize the LMs and\nretain their original abilities on languages. Empirical results indicate\n$\\textbf{LaMo}$ achieves state-of-the-art performance in sparse-reward tasks\nand closes the gap between value-based offline RL methods and decision\ntransformers in dense-reward tasks. In particular, our method demonstrates\nsuperior performance in scenarios with limited data samples.",
            "author": [
                "Ruizhe Shi",
                "Yuyao Liu",
                "Yanjie Ze",
                "Simon S. Du",
                "Huazhe Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20587v4",
                "http://arxiv.org/pdf/2310.20587v4"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20586v1",
            "title": "Harmonization-enriched domain adaptation with light fine-tuning for\n  multiple sclerosis lesion segmentation",
            "updated": "2023-10-31T16:23:37Z",
            "published": "2023-10-31T16:23:37Z",
            "summary": "Deep learning algorithms utilizing magnetic resonance (MR) images have\ndemonstrated cutting-edge proficiency in autonomously segmenting multiple\nsclerosis (MS) lesions. Despite their achievements, these algorithms may\nstruggle to extend their performance across various sites or scanners, leading\nto domain generalization errors. While few-shot or one-shot domain adaptation\nemerges as a potential solution to mitigate generalization errors, its efficacy\nmight be hindered by the scarcity of labeled data in the target domain. This\npaper seeks to tackle this challenge by integrating one-shot adaptation data\nwith harmonized training data that incorporates labels. Our approach involves\nsynthesizing new training data with a contrast akin to that of the test domain,\na process we refer to as \"contrast harmonization\" in MRI. Our experiments\nillustrate that the amalgamation of one-shot adaptation data with harmonized\ntraining data surpasses the performance of utilizing either data source in\nisolation. Notably, domain adaptation using exclusively harmonized training\ndata achieved comparable or even superior performance compared to one-shot\nadaptation. Moreover, all adaptations required only minimal fine-tuning,\nranging from 2 to 5 epochs for convergence.",
            "author": [
                "Jinwei Zhang",
                "Lianrui Zuo",
                "Blake E. Dewey",
                "Samuel W. Remedios",
                "Savannah P. Hays",
                "Dzung L. Pham",
                "Jerry L. Prince",
                "Aaron Carass"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20586v1",
                "http://arxiv.org/pdf/2310.20586v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20581v1",
            "title": "Stochastic Gradient Descent for Gaussian Processes Done Right",
            "updated": "2023-10-31T16:15:13Z",
            "published": "2023-10-31T16:15:13Z",
            "summary": "We study the optimisation problem associated with Gaussian process regression\nusing squared loss. The most common approach to this problem is to apply an\nexact solver, such as conjugate gradient descent, either directly, or to a\nreduced-order version of the problem. Recently, driven by successes in deep\nlearning, stochastic gradient descent has gained traction as an alternative. In\nthis paper, we show that when done right$\\unicode{x2014}$by which we mean using\nspecific insights from the optimisation and kernel\ncommunities$\\unicode{x2014}$this approach is highly effective. We thus\nintroduce a particular stochastic dual gradient descent algorithm, that may be\nimplemented with a few lines of code using any deep learning framework. We\nexplain our design decisions by illustrating their advantage against\nalternatives with ablation studies and show that the new method is highly\ncompetitive. Our evaluations on standard regression benchmarks and a Bayesian\noptimisation task set our approach apart from preconditioned conjugate\ngradients, variational Gaussian process approximations, and a previous version\nof stochastic gradient descent for Gaussian processes. On a molecular binding\naffinity prediction task, our method places Gaussian process regression on par\nin terms of performance with state-of-the-art graph neural networks.",
            "author": [
                "Jihao Andreas Lin",
                "Shreyas Padhy",
                "Javier Antor\u00e1n",
                "Austin Tripp",
                "Alexander Terenin",
                "Csaba Szepesv\u00e1ri",
                "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
                "David Janz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20581v1",
                "http://arxiv.org/pdf/2310.20581v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20579v1",
            "title": "Initialization Matters: Privacy-Utility Analysis of Overparameterized\n  Neural Networks",
            "updated": "2023-10-31T16:13:22Z",
            "published": "2023-10-31T16:13:22Z",
            "summary": "We analytically investigate how over-parameterization of models in randomized\nmachine learning algorithms impacts the information leakage about their\ntraining data. Specifically, we prove a privacy bound for the KL divergence\nbetween model distributions on worst-case neighboring datasets, and explore its\ndependence on the initialization, width, and depth of fully connected neural\nnetworks. We find that this KL privacy bound is largely determined by the\nexpected squared gradient norm relative to model parameters during training.\nNotably, for the special setting of linearized network, our analysis indicates\nthat the squared gradient norm (and therefore the escalation of privacy loss)\nis tied directly to the per-layer variance of the initialization distribution.\nBy using this analysis, we demonstrate that privacy bound improves with\nincreasing depth under certain initializations (LeCun and Xavier), while\ndegrades with increasing depth under other initializations (He and NTK). Our\nwork reveals a complex interplay between privacy and depth that depends on the\nchosen initialization distribution. We further prove excess empirical risk\nbounds under a fixed KL privacy budget, and show that the interplay between\nprivacy utility trade-off and depth is similarly affected by the\ninitialization.",
            "author": [
                "Jiayuan Ye",
                "Zhenyu Zhu",
                "Fanghui Liu",
                "Reza Shokri",
                "Volkan Cevher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20579v1",
                "http://arxiv.org/pdf/2310.20579v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20574v1",
            "title": "Information-Theoretic Trust Regions for Stochastic Gradient-Based\n  Optimization",
            "updated": "2023-10-31T16:08:38Z",
            "published": "2023-10-31T16:08:38Z",
            "summary": "Stochastic gradient-based optimization is crucial to optimize neural\nnetworks. While popular approaches heuristically adapt the step size and\ndirection by rescaling gradients, a more principled approach to improve\noptimizers requires second-order information. Such methods precondition the\ngradient using the objective's Hessian. Yet, computing the Hessian is usually\nexpensive and effectively using second-order information in the stochastic\ngradient setting is non-trivial. We propose using Information-Theoretic Trust\nRegion Optimization (arTuRO) for improved updates with uncertain second-order\ninformation. By modeling the network parameters as a Gaussian distribution and\nusing a Kullback-Leibler divergence-based trust region, our approach takes\nbounded steps accounting for the objective's curvature and uncertainty in the\nparameters. Before each update, it solves the trust region problem for an\noptimal step size, resulting in a more stable and faster optimization process.\nWe approximate the diagonal elements of the Hessian from stochastic gradients\nusing a simple recursive least squares approach, constructing a model of the\nexpected Hessian over time using only first-order information. We show that\narTuRO combines the fast convergence of adaptive moment-based optimization with\nthe generalization capabilities of SGD.",
            "author": [
                "Philipp Dahlinger",
                "Philipp Becker",
                "Maximilian H\u00fcttenrauch",
                "Gerhard Neumann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20574v1",
                "http://arxiv.org/pdf/2310.20574v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20572v1",
            "title": "PRIMA General Observer Science Book",
            "updated": "2023-10-31T16:02:57Z",
            "published": "2023-10-31T16:02:57Z",
            "summary": "PRIMA (The PRobe for-Infrared Mission for Astrophysics) is a concept for a\nfar-infrared (IR) observatory. PRIMA features a cryogenically cooled 1.8 m\ndiameter telescope and is designed to carry two science instruments enabling\nultra-high sensitivity imaging and spectroscopic studies in the 24 to 235\nmicrons wavelength range. The resulting observatory is a powerful survey and\ndiscovery machine, with mapping speeds better by 2 - 4 orders of magnitude with\nrespect to its far-IR predecessors. The bulk of the observing time on PRIMA\nshould be made available to the community through a General Observer (GO)\nprogram offering 75% of the mission time over 5 years. In March 2023, the\ninternational astronomy community was encouraged to prepare authored\ncontributions articulating scientific cases that are enabled by the telescope\nmassive sensitivity advance and broad spectral coverage, and that could be\nperformed within the context of GO program. This document, the PRIMA General\nObserver Science Book, is the edited collection of the 76 received\ncontributions.",
            "author": [
                "A. Moullet",
                "T. Kataria",
                "D. Lis",
                "S. Unwin",
                "Y. Hasegawa",
                "E. Mills",
                "C. Battersby",
                "A. Roc",
                "M. Meixner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20572v1",
                "http://arxiv.org/pdf/2310.20572v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20568v1",
            "title": "Uncertainty Learning for LTI Systems with Stability Guarantees",
            "updated": "2023-10-31T15:56:56Z",
            "published": "2023-10-31T15:56:56Z",
            "summary": "We present a framework for learning of modeling uncertainties in Linear Time\nInvariant (LTI) systems. We propose a methodology to extend the dynamics of an\nLTI (without uncertainty) with an uncertainty model, based on measured data, to\nimprove the predictive capacity of the model in the input-output sense. The\nproposed framework guarantees stability of the extended model. To achieve this,\ntwo semi-definite programs are provided that allow obtaining optimal\nuncertainty model parameters, given state and uncertainty data. To obtain this\ndata from available input-output trajectory data, we introduce a filter in\nwhich an internal model of uncertainty is proposed. This filter is also\ndesigned via a semi-definite program with guaranteed robustness with respect to\nuncertainty model mismatches, disturbances, and noise. Numerical simulations\nare presented to illustrate the effectiveness and practicality of the proposed\nmethodology in improving model accuracy, while warranting model stability.",
            "author": [
                "Farhad Ghanipoor",
                "Carlos Murguia",
                "Peyman Mohajerin Esfahani",
                "Nathan van de Wouw"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20568v1",
                "http://arxiv.org/pdf/2310.20568v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20567v2",
            "title": "One-shot backpropagation for multi-step prediction in physics-based\n  system identification -- EXTENDED VERSION",
            "updated": "2023-11-21T09:19:06Z",
            "published": "2023-10-31T15:56:17Z",
            "summary": "The aim of this paper is to present a novel physics-based framework for the\nidentification of dynamical systems, in which the physical and structural\ninsights are reflected directly into a backpropagation-based learning\nalgorithm. The main result is a method to compute in closed form the gradient\nof a multi-step loss function, while enforcing physical properties and\nconstraints. The derived algorithm has been exploited to identify the unknown\ninertia matrix of a space debris, and the results show the reliability of the\nmethod in capturing the physical adherence of the estimated parameters.",
            "author": [
                "Cesare Donati",
                "Martina Mammarella",
                "Fabrizio Dabbene",
                "Carlo Novara",
                "Constantino Lagoa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20567v2",
                "http://arxiv.org/pdf/2310.20567v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20552v1",
            "title": "Privacy-preserving design of graph neural networks with applications to\n  vertical federated learning",
            "updated": "2023-10-31T15:34:59Z",
            "published": "2023-10-31T15:34:59Z",
            "summary": "The paradigm of vertical federated learning (VFL), where institutions\ncollaboratively train machine learning models via combining each other's local\nfeature or label information, has achieved great success in applications to\nfinancial risk management (FRM). The surging developments of graph\nrepresentation learning (GRL) have opened up new opportunities for FRM\napplications under FL via efficiently utilizing the graph-structured data\ngenerated from underlying transaction networks. Meanwhile, transaction\ninformation is often considered highly sensitive. To prevent data leakage\nduring training, it is critical to develop FL protocols with formal privacy\nguarantees. In this paper, we present an end-to-end GRL framework in the VFL\nsetting called VESPER, which is built upon a general privatization scheme\ntermed perturbed message passing (PMP) that allows the privatization of many\npopular graph neural architectures.Based on PMP, we discuss the strengths and\nweaknesses of specific design choices of concrete graph neural architectures\nand provide solutions and improvements for both dense and sparse graphs.\nExtensive empirical evaluations over both public datasets and an industry\ndataset demonstrate that VESPER is capable of training high-performance GNN\nmodels over both sparse and dense graphs under reasonable privacy budgets.",
            "author": [
                "Ruofan Wu",
                "Mingyang Zhang",
                "Lingjuan Lyu",
                "Xiaolong Xu",
                "Xiuquan Hao",
                "Xinyi Fu",
                "Tengfei Liu",
                "Tianyi Zhang",
                "Weiqiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20552v1",
                "http://arxiv.org/pdf/2310.20552v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20550v2",
            "title": "CapsFusion: Rethinking Image-Text Data at Scale",
            "updated": "2023-11-02T11:25:20Z",
            "published": "2023-10-31T15:31:39Z",
            "summary": "Large multimodal models demonstrate remarkable generalist ability to perform\ndiverse multimodal tasks in a zero-shot manner. Large-scale web-based\nimage-text pairs contribute fundamentally to this success, but suffer from\nexcessive noise. Recent studies use alternative captions synthesized by\ncaptioning models and have achieved notable benchmark performance. However, our\nexperiments reveal significant Scalability Deficiency and World Knowledge Loss\nissues in models trained with synthetic captions, which have been largely\nobscured by their initial benchmark success. Upon closer examination, we\nidentify the root cause as the overly-simplified language structure and lack of\nknowledge details in existing synthetic captions. To provide higher-quality and\nmore scalable multimodal pretraining data, we propose CapsFusion, an advanced\nframework that leverages large language models to consolidate and refine\ninformation from both web-based image-text pairs and synthetic captions.\nExtensive experiments show that CapsFusion captions exhibit remarkable\nall-round superiority over existing captions in terms of model performance\n(e.g., 18.8 and 18.3 improvements in CIDEr score on COCO and NoCaps), sample\nefficiency (requiring 11-16 times less computation than baselines), world\nknowledge depth, and scalability. These effectiveness, efficiency and\nscalability advantages position CapsFusion as a promising candidate for future\nscaling of LMM training.",
            "author": [
                "Qiying Yu",
                "Quan Sun",
                "Xiaosong Zhang",
                "Yufeng Cui",
                "Fan Zhang",
                "Yue Cao",
                "Xinlong Wang",
                "Jingjing Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20550v2",
                "http://arxiv.org/pdf/2310.20550v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20545v1",
            "title": "Multi-task learning of convex combinations of forecasting models",
            "updated": "2023-10-31T15:26:33Z",
            "published": "2023-10-31T15:26:33Z",
            "summary": "Forecast combination involves using multiple forecasts to create a single,\nmore accurate prediction. Recently, feature-based forecasting has been employed\nto either select the most appropriate forecasting models or to learn the\nweights of their convex combination. In this paper, we present a multi-task\nlearning methodology that simultaneously addresses both problems. This approach\nis implemented through a deep neural network with two branches: the regression\nbranch, which learns the weights of various forecasting methods by minimizing\nthe error of combined forecasts, and the classification branch, which selects\nforecasting methods with an emphasis on their diversity. To generate training\nlabels for the classification task, we introduce an optimization-driven\napproach that identifies the most appropriate methods for a given time series.\nThe proposed approach elicits the essential role of diversity in feature-based\nforecasting and highlights the interplay between model combination and model\nselection when learning forecasting ensembles. Experimental results on a large\nset of series from the M4 competition dataset show that our proposal enhances\npoint forecast accuracy compared to state-of-the-art methods.",
            "author": [
                "Giovanni Felici",
                "Antonio M. Sudoso"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20545v1",
                "http://arxiv.org/pdf/2310.20545v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20537v1",
            "title": "Directed Cyclic Graph for Causal Discovery from Multivariate Functional\n  Data",
            "updated": "2023-10-31T15:19:24Z",
            "published": "2023-10-31T15:19:24Z",
            "summary": "Discovering causal relationship using multivariate functional data has\nreceived a significant amount of attention very recently. In this article, we\nintroduce a functional linear structural equation model for causal structure\nlearning when the underlying graph involving the multivariate functions may\nhave cycles. To enhance interpretability, our model involves a low-dimensional\ncausal embedded space such that all the relevant causal information in the\nmultivariate functional data is preserved in this lower-dimensional subspace.\nWe prove that the proposed model is causally identifiable under standard\nassumptions that are often made in the causal discovery literature. To carry\nout inference of our model, we develop a fully Bayesian framework with suitable\nprior specifications and uncertainty quantification through posterior\nsummaries. We illustrate the superior performance of our method over existing\nmethods in terms of causal graph estimation through extensive simulation\nstudies. We also demonstrate the proposed method using a brain EEG dataset.",
            "author": [
                "Saptarshi Roy",
                "Raymond K. W. Wong",
                "Yang Ni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20537v1",
                "http://arxiv.org/pdf/2310.20537v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20524v1",
            "title": "Group-Feature (Sensor) Selection With Controlled Redundancy Using Neural\n  Networks",
            "updated": "2023-10-31T15:04:53Z",
            "published": "2023-10-31T15:04:53Z",
            "summary": "In this paper, we present a novel embedded feature selection method based on\na Multi-layer Perceptron (MLP) network and generalize it for group-feature or\nsensor selection problems, which can control the level of redundancy among the\nselected features or groups. Additionally, we have generalized the group lasso\npenalty for feature selection to encompass a mechanism for selecting valuable\ngroup features while simultaneously maintaining a control over redundancy. We\nestablish the monotonicity and convergence of the proposed algorithm, with a\nsmoothed version of the penalty terms, under suitable assumptions. Experimental\nresults on several benchmark datasets demonstrate the promising performance of\nthe proposed methodology for both feature selection and group feature selection\nover some state-of-the-art methods.",
            "author": [
                "Aytijhya Saha",
                "Nikhil R. Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20524v1",
                "http://arxiv.org/pdf/2310.20524v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20508v1",
            "title": "Parametric Fairness with Statistical Guarantees",
            "updated": "2023-10-31T14:52:39Z",
            "published": "2023-10-31T14:52:39Z",
            "summary": "Algorithmic fairness has gained prominence due to societal and regulatory\nconcerns about biases in Machine Learning models. Common group fairness metrics\nlike Equalized Odds for classification or Demographic Parity for both\nclassification and regression are widely used and a host of computationally\nadvantageous post-processing methods have been developed around them. However,\nthese metrics often limit users from incorporating domain knowledge. Despite\nmeeting traditional fairness criteria, they can obscure issues related to\nintersectional fairness and even replicate unwanted intra-group biases in the\nresulting fair solution. To avoid this narrow perspective, we extend the\nconcept of Demographic Parity to incorporate distributional properties in the\npredictions, allowing expert knowledge to be used in the fair solution. We\nillustrate the use of this new metric through a practical example of wages, and\ndevelop a parametric method that efficiently addresses practical challenges\nlike limited training data and constraints on total spending, offering a robust\nsolution for real-life applications.",
            "author": [
                "Fran\u00e7ois HU",
                "Philipp Ratz",
                "Arthur Charpentier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20508v1",
                "http://arxiv.org/pdf/2310.20508v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20498v1",
            "title": "Generative Learning of Continuous Data by Tensor Networks",
            "updated": "2023-10-31T14:37:37Z",
            "published": "2023-10-31T14:37:37Z",
            "summary": "Beyond their origin in modeling many-body quantum systems, tensor networks\nhave emerged as a promising class of models for solving machine learning\nproblems, notably in unsupervised generative learning. While possessing many\ndesirable features arising from their quantum-inspired nature, tensor network\ngenerative models have previously been largely restricted to binary or\ncategorical data, limiting their utility in real-world modeling problems. We\novercome this by introducing a new family of tensor network generative models\nfor continuous data, which are capable of learning from distributions\ncontaining continuous random variables. We develop our method in the setting of\nmatrix product states, first deriving a universal expressivity theorem proving\nthe ability of this model family to approximate any reasonably smooth\nprobability density function with arbitrary precision. We then benchmark the\nperformance of this model on several synthetic and real-world datasets, finding\nthat the model learns and generalizes well on distributions of continuous and\ndiscrete variables. We develop methods for modeling different data domains, and\nintroduce a trainable compression layer which is found to increase model\nperformance given limited memory or computational resources. Overall, our\nmethods give important theoretical and empirical evidence of the efficacy of\nquantum-inspired methods for the rapidly growing field of generative learning.",
            "author": [
                "Alex Meiburg",
                "Jing Chen",
                "Jacob Miller",
                "Rapha\u00eblle Tihon",
                "Guillaume Rabusseau",
                "Alejandro Perdomo-Ortiz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20498v1",
                "http://arxiv.org/pdf/2310.20498v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.stat-mech",
                "quant-ph",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20496v1",
            "title": "BasisFormer: Attention-based Time Series Forecasting with Learnable and\n  Interpretable Basis",
            "updated": "2023-10-31T14:34:00Z",
            "published": "2023-10-31T14:34:00Z",
            "summary": "Bases have become an integral part of modern deep learning-based models for\ntime series forecasting due to their ability to act as feature extractors or\nfuture references. To be effective, a basis must be tailored to the specific\nset of time series data and exhibit distinct correlation with each time series\nwithin the set. However, current state-of-the-art methods are limited in their\nability to satisfy both of these requirements simultaneously. To address this\nchallenge, we propose BasisFormer, an end-to-end time series forecasting\narchitecture that leverages learnable and interpretable bases. This\narchitecture comprises three components: First, we acquire bases through\nadaptive self-supervised learning, which treats the historical and future\nsections of the time series as two distinct views and employs contrastive\nlearning. Next, we design a Coef module that calculates the similarity\ncoefficients between the time series and bases in the historical view via\nbidirectional cross-attention. Finally, we present a Forecast module that\nselects and consolidates the bases in the future view based on the similarity\ncoefficients, resulting in accurate future predictions. Through extensive\nexperiments on six datasets, we demonstrate that BasisFormer outperforms\nprevious state-of-the-art methods by 11.04\\% and 15.78\\% respectively for\nunivariate and multivariate forecasting tasks. Code is available at:\n\\url{https://github.com/nzl5116190/Basisformer}",
            "author": [
                "Zelin Ni",
                "Hang Yu",
                "Shizhan Liu",
                "Jianguo Li",
                "Weiyao Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20496v1",
                "http://arxiv.org/pdf/2310.20496v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20494v1",
            "title": "A Transformer-Based Model With Self-Distillation for Multimodal Emotion\n  Recognition in Conversations",
            "updated": "2023-10-31T14:33:30Z",
            "published": "2023-10-31T14:33:30Z",
            "summary": "Emotion recognition in conversations (ERC), the task of recognizing the\nemotion of each utterance in a conversation, is crucial for building empathetic\nmachines. Existing studies focus mainly on capturing context- and\nspeaker-sensitive dependencies on the textual modality but ignore the\nsignificance of multimodal information. Different from emotion recognition in\ntextual conversations, capturing intra- and inter-modal interactions between\nutterances, learning weights between different modalities, and enhancing modal\nrepresentations play important roles in multimodal ERC. In this paper, we\npropose a transformer-based model with self-distillation (SDT) for the task.\nThe transformer-based model captures intra- and inter-modal interactions by\nutilizing intra- and inter-modal transformers, and learns weights between\nmodalities dynamically by designing a hierarchical gated fusion strategy.\nFurthermore, to learn more expressive modal representations, we treat soft\nlabels of the proposed model as extra training supervision. Specifically, we\nintroduce self-distillation to transfer knowledge of hard and soft labels from\nthe proposed model to each modality. Experiments on IEMOCAP and MELD datasets\ndemonstrate that SDT outperforms previous state-of-the-art baselines.",
            "author": [
                "Hui Ma",
                "Jian Wang",
                "Hongfei Lin",
                "Bo Zhang",
                "Yijia Zhang",
                "Bo Xu"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TMM.2023.3271019",
                "http://arxiv.org/abs/2310.20494v1",
                "http://arxiv.org/pdf/2310.20494v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20493v1",
            "title": "Requirement falsification for cyber-physical systems using generative\n  models",
            "updated": "2023-10-31T14:32:54Z",
            "published": "2023-10-31T14:32:54Z",
            "summary": "We present the OGAN algorithm for automatic requirement falsification of\ncyber-physical systems. System inputs and output are represented as piecewise\nconstant signals over time while requirements are expressed in signal temporal\nlogic. OGAN can find inputs that are counterexamples for the safety of a system\nrevealing design, software, or hardware defects before the system is taken into\noperation. The OGAN algorithm works by training a generative machine learning\nmodel to produce such counterexamples. It executes tests atomically and does\nnot require any previous model of the system under test. We evaluate OGAN using\nthe ARCH-COMP benchmark problems, and the experimental results show that\ngenerative models are a viable method for requirement falsification. OGAN can\nbe applied to new systems with little effort, has few requirements for the\nsystem under test, and exhibits state-of-the-art CPS falsification efficiency\nand effectiveness.",
            "author": [
                "Jarkko Peltom\u00e4ki",
                "Ivan Porres"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20493v1",
                "http://arxiv.org/pdf/2310.20493v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20492v1",
            "title": "Log-based Anomaly Detection of Enterprise Software: An Empirical Study",
            "updated": "2023-10-31T14:32:08Z",
            "published": "2023-10-31T14:32:08Z",
            "summary": "Most enterprise applications use logging as a mechanism to diagnose\nanomalies, which could help with reducing system downtime. Anomaly detection\nusing software execution logs has been explored in several prior studies, using\nboth classical and deep neural network-based machine learning models. In recent\nyears, the research has largely focused in using variations of sequence-based\ndeep neural networks (e.g., Long-Short Term Memory and Transformer-based\nmodels) for log-based anomaly detection on open-source data. However, they have\nnot been applied in industrial datasets, as often. In addition, the studied\nopen-source datasets are typically very large in size with logging statements\nthat do not change much over time, which may not be the case with a dataset\nfrom an industrial service that is relatively new. In this paper, we evaluate\nseveral state-of-the-art anomaly detection models on an industrial dataset from\nour research partner, which is much smaller and loosely structured than most\nlarge scale open-source benchmark datasets. Results show that while all models\nare capable of detecting anomalies, certain models are better suited for\nless-structured datasets. We also see that model effectiveness changes when a\ncommon data leak associated with a random train-test split in some prior work\nis removed. A qualitative study of the defects' characteristics identified by\nthe developers on the industrial dataset further shows strengths and weaknesses\nof the models in detecting different types of anomalies. Finally, we explore\nthe effect of limited training data by gradually increasing the training set\nsize, to evaluate if the model effectiveness does depend on the training set\nsize.",
            "author": [
                "Nadun Wijesinghe",
                "Hadi Hemmati"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20492v1",
                "http://arxiv.org/pdf/2310.20492v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SE",
                "I.5.2; I.5.1; I.5.4; I.2.7; I.2.6; D.2.5"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20491v1",
            "title": "Collaborative Decision-Making Using Spatiotemporal Graphs in Connected\n  Autonomy",
            "updated": "2023-10-31T14:30:39Z",
            "published": "2023-10-31T14:30:39Z",
            "summary": "Collaborative decision-making is an essential capability for multi-robot\nsystems, such as connected vehicles, to collaboratively control autonomous\nvehicles in accident-prone scenarios. Under limited communication bandwidth,\ncapturing comprehensive situational awareness by integrating connected agents'\nobservation is very challenging. In this paper, we propose a novel\ncollaborative decision-making method that efficiently and effectively\nintegrates collaborators' representations to control the ego vehicle in\naccident-prone scenarios. Our approach formulates collaborative decision-making\nas a classification problem. We first represent sequences of raw observations\nas spatiotemporal graphs, which significantly reduce the package size to share\namong connected vehicles. Then we design a novel spatiotemporal graph neural\nnetwork based on heterogeneous graph learning, which analyzes spatial and\ntemporal connections of objects in a unified way for collaborative\ndecision-making. We evaluate our approach using a high-fidelity simulator that\nconsiders realistic traffic, communication bandwidth, and vehicle sensing among\nconnected autonomous vehicles. The experimental results show that our\nrepresentation achieves over 100x reduction in the shared data size that meets\nthe requirements of communication bandwidth for connected autonomous driving.\nIn addition, our approach achieves over 30% improvements in driving safety.",
            "author": [
                "Peng Gao",
                "Yu Shen",
                "Ming C. Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20491v1",
                "http://arxiv.org/pdf/2310.20491v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20490v2",
            "title": "Long-Tailed Learning as Multi-Objective Optimization",
            "updated": "2023-11-01T11:28:55Z",
            "published": "2023-10-31T14:30:31Z",
            "summary": "Real-world data is extremely imbalanced and presents a long-tailed\ndistribution, resulting in models that are biased towards classes with\nsufficient samples and perform poorly on rare classes. Recent methods propose\nto rebalance classes but they undertake the seesaw dilemma (what is increasing\nperformance on tail classes may decrease that of head classes, and vice versa).\nIn this paper, we argue that the seesaw dilemma is derived from gradient\nimbalance of different classes, in which gradients of inappropriate classes are\nset to important for updating, thus are prone to overcompensation or\nundercompensation on tail classes. To achieve ideal compensation, we formulate\nthe long-tailed recognition as an multi-objective optimization problem, which\nfairly respects the contributions of head and tail classes simultaneously. For\nefficiency, we propose a Gradient-Balancing Grouping (GBG) strategy to gather\nthe classes with similar gradient directions, thus approximately make every\nupdate under a Pareto descent direction. Our GBG method drives classes with\nsimilar gradient directions to form more representative gradient and provide\nideal compensation to the tail classes. Moreover, We conduct extensive\nexperiments on commonly used benchmarks in long-tailed learning and demonstrate\nthe superiority of our method over existing SOTA methods.",
            "author": [
                "Weiqi Li",
                "Fan Lyu",
                "Fanhua Shang",
                "Liang Wan",
                "Wei Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20490v2",
                "http://arxiv.org/pdf/2310.20490v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20488v1",
            "title": "NaijaCoder: Participatory Design for Early Algorithms Education in the\n  Global South",
            "updated": "2023-10-31T14:28:51Z",
            "published": "2023-10-31T14:28:51Z",
            "summary": "The majority of Nigerian high schoolers have little to no exposure to the\nbasics of algorithms and programming. We believe this trajectory should change\nas programming offers these students, especially those from indigent\nbackgrounds, an opportunity to learn profitable skills and ignite their\npassions for problem-solving and critical thinking.\n  NaijaCoder is an organization that is dedicated to organizing a free,\nintensive summer program in Nigeria to teach the basics of algorithms and\ncomputer programming to high schoolers. However, the adoption of computer\nscience curriculum has been especially challenging in countries in the global\nsouth that face unique challenges -- such as unstable power supply, internet\nservice, and price volatility. We design a curriculum that is more conducive to\nthe local environment while incorporating rigorous thinking and preparation.\nUsing basic survey designs, we elicit feedback, from the students, designed to\nfurther improve and iterate on our curriculum.",
            "author": [
                "Daniel Alabi",
                "Atinuke Adegbile",
                "Lekan Afuye",
                "Philip Abel",
                "Alida Monaco"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20488v1",
                "http://arxiv.org/pdf/2310.20488v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20487v1",
            "title": "Large Language Model Can Interpret Latent Space of Sequential\n  Recommender",
            "updated": "2023-10-31T14:28:47Z",
            "published": "2023-10-31T14:28:47Z",
            "summary": "Sequential recommendation is to predict the next item of interest for a user,\nbased on her/his interaction history with previous items. In conventional\nsequential recommenders, a common approach is to model item sequences using\ndiscrete IDs, learning representations that encode sequential behaviors and\nreflect user preferences. Inspired by recent success in empowering large\nlanguage models (LLMs) to understand and reason over diverse modality data\n(e.g., image, audio, 3D points), a compelling research question arises: ``Can\nLLMs understand and work with hidden representations from ID-based sequential\nrecommenders?''.To answer this, we propose a simple framework, RecInterpreter,\nwhich examines the capacity of open-source LLMs to decipher the representation\nspace of sequential recommenders. Specifically, with the multimodal pairs (\\ie\nrepresentations of interaction sequence and text narrations), RecInterpreter\nfirst uses a lightweight adapter to map the representations into the token\nembedding space of the LLM. Subsequently, it constructs a sequence-recovery\nprompt that encourages the LLM to generate textual descriptions for items\nwithin the interaction sequence. Taking a step further, we propose a\nsequence-residual prompt instead, which guides the LLM in identifying the\nresidual item by contrasting the representations before and after integrating\nthis residual into the existing sequence. Empirical results showcase that our\nRecInterpreter enhances the exemplar LLM, LLaMA, to understand hidden\nrepresentations from ID-based sequential recommenders, especially when guided\nby our sequence-residual prompts. Furthermore, RecInterpreter enables LLaMA to\ninstantiate the oracle items generated by generative recommenders like\nDreamRec, concreting the item a user would ideally like to interact with next.\nCodes are available at https://github.com/YangZhengyi98/RecInterpreter.",
            "author": [
                "Zhengyi Yang",
                "Jiancan Wu",
                "Yanchen Luo",
                "Jizhi Zhang",
                "Yancheng Yuan",
                "An Zhang",
                "Xiang Wang",
                "Xiangnan He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20487v1",
                "http://arxiv.org/pdf/2310.20487v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20478v1",
            "title": "Unveiling Black-boxes: Explainable Deep Learning Models for Patent\n  Classification",
            "updated": "2023-10-31T14:11:37Z",
            "published": "2023-10-31T14:11:37Z",
            "summary": "Recent technological advancements have led to a large number of patents in a\ndiverse range of domains, making it challenging for human experts to analyze\nand manage. State-of-the-art methods for multi-label patent classification rely\non deep neural networks (DNNs), which are complex and often considered\nblack-boxes due to their opaque decision-making processes. In this paper, we\npropose a novel deep explainable patent classification framework by introducing\nlayer-wise relevance propagation (LRP) to provide human-understandable\nexplanations for predictions. We train several DNN models, including Bi-LSTM,\nCNN, and CNN-BiLSTM, and propagate the predictions backward from the output\nlayer up to the input layer of the model to identify the relevance of words for\nindividual predictions. Considering the relevance score, we then generate\nexplanations by visualizing relevant words for the predicted patent class.\nExperimental results on two datasets comprising two-million patent texts\ndemonstrate high performance in terms of various evaluation measures. The\nexplanations generated for each prediction highlight important relevant words\nthat align with the predicted class, making the prediction more understandable.\nExplainable systems have the potential to facilitate the adoption of complex\nAI-enabled methods for patent classification in real-world applications.",
            "author": [
                "Md Shajalal",
                "Sebastian Denef",
                "Md. Rezaul Karim",
                "Alexander Boden",
                "Gunnar Stevens"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-44067-0_24",
                "http://arxiv.org/abs/2310.20478v1",
                "http://arxiv.org/pdf/2310.20478v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20477v2",
            "title": "Exploring Practitioner Perspectives On Training Data Attribution\n  Explanations",
            "updated": "2023-11-22T09:57:54Z",
            "published": "2023-10-31T14:10:30Z",
            "summary": "Explainable AI (XAI) aims to provide insight into opaque model reasoning to\nhumans and as such is an interdisciplinary field by nature. In this paper, we\ninterviewed 10 practitioners to understand the possible usability of training\ndata attribution (TDA) explanations and to explore the design space of such an\napproach. We confirmed that training data quality is often the most important\nfactor for high model performance in practice and model developers mainly rely\non their own experience to curate data. End-users expect explanations to\nenhance their interaction with the model and do not necessarily prioritise but\nare open to training data as a means of explanation. Within our participants,\nwe found that TDA explanations are not well-known and therefore not used. We\nurge the community to focus on the utility of TDA techniques from the\nhuman-machine collaboration perspective and broaden the TDA evaluation to\nreflect common use cases in practice.",
            "author": [
                "Elisa Nguyen",
                "Evgenii Kortukov",
                "Jean Y. Song",
                "Seong Joon Oh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20477v2",
                "http://arxiv.org/pdf/2310.20477v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20476v1",
            "title": "Global Transformer Architecture for Indoor Room Temperature Forecasting",
            "updated": "2023-10-31T14:09:32Z",
            "published": "2023-10-31T14:09:32Z",
            "summary": "A thorough regulation of building energy systems translates in relevant\nenergy savings and in a better comfort for the occupants. Algorithms to predict\nthe thermal state of a building on a certain time horizon with a good\nconfidence are essential for the implementation of effective control systems.\nThis work presents a global Transformer architecture for indoor temperature\nforecasting in multi-room buildings, aiming at optimizing energy consumption\nand reducing greenhouse gas emissions associated with HVAC systems. Recent\nadvancements in deep learning have enabled the development of more\nsophisticated forecasting models compared to traditional feedback control\nsystems. The proposed global Transformer architecture can be trained on the\nentire dataset encompassing all rooms, eliminating the need for multiple\nroom-specific models, significantly improving predictive performance, and\nsimplifying deployment and maintenance. Notably, this study is the first to\napply a Transformer architecture for indoor temperature forecasting in\nmulti-room buildings. The proposed approach provides a novel solution to\nenhance the accuracy and efficiency of temperature forecasting, serving as a\nvaluable tool to optimize energy consumption and decrease greenhouse gas\nemissions in the building sector.",
            "author": [
                "Alfredo V Clemente",
                "Alessandro Nocente",
                "Massimiliano Ruocco"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20476v1",
                "http://arxiv.org/pdf/2310.20476v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20475v1",
            "title": "Linked Papers With Code: The Latest in Machine Learning as an RDF\n  Knowledge Graph",
            "updated": "2023-10-31T14:09:15Z",
            "published": "2023-10-31T14:09:15Z",
            "summary": "In this paper, we introduce Linked Papers With Code (LPWC), an RDF knowledge\ngraph that provides comprehensive, current information about almost 400,000\nmachine learning publications. This includes the tasks addressed, the datasets\nutilized, the methods implemented, and the evaluations conducted, along with\ntheir results. Compared to its non-RDF-based counterpart Papers With Code, LPWC\nnot only translates the latest advancements in machine learning into RDF\nformat, but also enables novel ways for scientific impact quantification and\nscholarly key content recommendation. LPWC is openly accessible at\nhttps://linkedpaperswithcode.com and is licensed under CC-BY-SA 4.0. As a\nknowledge graph in the Linked Open Data cloud, we offer LPWC in multiple\nformats, from RDF dump files to a SPARQL endpoint for direct web queries, as\nwell as a data source with resolvable URIs and links to the data sources\nSemOpenAlex, Wikidata, and DBLP. Additionally, we supply knowledge graph\nembeddings, enabling LPWC to be readily applied in machine learning\napplications.",
            "author": [
                "Michael F\u00e4rber",
                "David Lamprecht"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20475v1",
                "http://arxiv.org/pdf/2310.20475v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20469v1",
            "title": "Amoeba: Circumventing ML-supported Network Censorship via Adversarial\n  Reinforcement Learning",
            "updated": "2023-10-31T14:01:24Z",
            "published": "2023-10-31T14:01:24Z",
            "summary": "Embedding covert streams into a cover channel is a common approach to\ncircumventing Internet censorship, due to censors' inability to examine\nencrypted information in otherwise permitted protocols (Skype, HTTPS, etc.).\nHowever, recent advances in machine learning (ML) enable detecting a range of\nanti-censorship systems by learning distinct statistical patterns hidden in\ntraffic flows. Therefore, designing obfuscation solutions able to generate\ntraffic that is statistically similar to innocuous network activity, in order\nto deceive ML-based classifiers at line speed, is difficult.\n  In this paper, we formulate a practical adversarial attack strategy against\nflow classifiers as a method for circumventing censorship. Specifically, we\ncast the problem of finding adversarial flows that will be misclassified as a\nsequence generation task, which we solve with Amoeba, a novel reinforcement\nlearning algorithm that we design. Amoeba works by interacting with censoring\nclassifiers without any knowledge of their model structure, but by crafting\npackets and observing the classifiers' decisions, in order to guide the\nsequence generation process. Our experiments using data collected from two\npopular anti-censorship systems demonstrate that Amoeba can effectively shape\nadversarial flows that have on average 94% attack success rate against a range\nof ML algorithms. In addition, we show that these adversarial flows are robust\nin different network environments and possess transferability across various ML\nmodels, meaning that once trained against one, our agent can subvert other\ncensoring classifiers without retraining.",
            "author": [
                "Haoyu Liu",
                "Alec F. Diallo",
                "Paul Patras"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3629131",
                "http://arxiv.org/abs/2310.20469v1",
                "http://arxiv.org/pdf/2310.20469v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20463v2",
            "title": "Interpretable Neural PDE Solvers using Symbolic Frameworks",
            "updated": "2023-11-10T12:15:33Z",
            "published": "2023-10-31T13:56:25Z",
            "summary": "Partial differential equations (PDEs) are ubiquitous in the world around us,\nmodelling phenomena from heat and sound to quantum systems. Recent advances in\ndeep learning have resulted in the development of powerful neural solvers;\nhowever, while these methods have demonstrated state-of-the-art performance in\nboth accuracy and computational efficiency, a significant challenge remains in\ntheir interpretability. Most existing methodologies prioritize predictive\naccuracy over clarity in the underlying mechanisms driving the model's\ndecisions. Interpretability is crucial for trustworthiness and broader\napplicability, especially in scientific and engineering domains where neural\nPDE solvers might see the most impact. In this context, a notable gap in\ncurrent research is the integration of symbolic frameworks (such as symbolic\nregression) into these solvers. Symbolic frameworks have the potential to\ndistill complex neural operations into human-readable mathematical expressions,\nbridging the divide between black-box predictions and solutions.",
            "author": [
                "Yolanne Yi Ran Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20463v2",
                "http://arxiv.org/pdf/2310.20463v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20458v1",
            "title": "Machine learning detects terminal singularities",
            "updated": "2023-10-31T13:51:24Z",
            "published": "2023-10-31T13:51:24Z",
            "summary": "Algebraic varieties are the geometric shapes defined by systems of polynomial\nequations; they are ubiquitous across mathematics and science. Amongst these\nalgebraic varieties are Q-Fano varieties: positively curved shapes which have\nQ-factorial terminal singularities. Q-Fano varieties are of fundamental\nimportance in geometry as they are \"atomic pieces\" of more complex shapes - the\nprocess of breaking a shape into simpler pieces in this sense is called the\nMinimal Model Programme. Despite their importance, the classification of Q-Fano\nvarieties remains unknown. In this paper we demonstrate that machine learning\ncan be used to understand this classification. We focus on 8-dimensional\npositively-curved algebraic varieties that have toric symmetry and Picard rank\n2, and develop a neural network classifier that predicts with 95% accuracy\nwhether or not such an algebraic variety is Q-Fano. We use this to give a first\nsketch of the landscape of Q-Fanos in dimension 8. How the neural network is\nable to detect Q-Fano varieties with such accuracy remains mysterious, and\nhints at some deep mathematical theory waiting to be uncovered. Furthermore,\nwhen visualised using the quantum period, an invariant that has played an\nimportant role in recent theoretical developments, we observe that the\nclassification as revealed by ML appears to fall within a bounded region, and\nis stratified by the Fano index. This suggests that it may be possible to state\nand prove conjectures on completeness in the future. Inspired by the ML\nanalysis, we formulate and prove a new global combinatorial criterion for a\npositively curved toric variety of Picard rank 2 to have terminal\nsingularities. Together with the first sketch of the landscape of Q-Fanos in\nhigher dimensions, this gives new evidence that machine learning can be an\nessential tool in developing mathematical conjectures and accelerating\ntheoretical discovery.",
            "author": [
                "Tom Coates",
                "Alexander M. Kasprzyk",
                "Sara Veneziale"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20458v1",
                "http://arxiv.org/pdf/2310.20458v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "cs.LG",
                "14J45 (Primary), 68T07 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20457v2",
            "title": "FlexTrain: A Dynamic Training Framework for Heterogeneous Devices\n  Environments",
            "updated": "2023-11-23T09:58:55Z",
            "published": "2023-10-31T13:51:13Z",
            "summary": "As deep learning models become increasingly large, they pose significant\nchallenges in heterogeneous devices environments. The size of deep learning\nmodels makes it difficult to deploy them on low-power or resource-constrained\ndevices, leading to long inference times and high energy consumption. To\naddress these challenges, we propose FlexTrain, a framework that accommodates\nthe diverse storage and computational resources available on different devices\nduring the training phase. FlexTrain enables efficient deployment of deep\nlearning models, while respecting device constraints, minimizing communication\ncosts, and ensuring seamless integration with diverse devices. We demonstrate\nthe effectiveness of FlexTrain on the CIFAR-100 dataset, where a single global\nmodel trained with FlexTrain can be easily deployed on heterogeneous devices,\nsaving training time and energy consumption. We also extend FlexTrain to the\nfederated learning setting, showing that our approach outperforms standard\nfederated learning benchmarks on both CIFAR-10 and CIFAR-100 datasets.",
            "author": [
                "Mert Unsal",
                "Ali Maatouk",
                "Antonio De Domenico",
                "Nicola Piovesan",
                "Fadhel Ayed"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20457v2",
                "http://arxiv.org/pdf/2310.20457v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20456v1",
            "title": "Towards a Deep Understanding of Multilingual End-to-End Speech\n  Translation",
            "updated": "2023-10-31T13:50:55Z",
            "published": "2023-10-31T13:50:55Z",
            "summary": "In this paper, we employ Singular Value Canonical Correlation Analysis\n(SVCCA) to analyze representations learnt in a multilingual end-to-end speech\ntranslation model trained over 22 languages. SVCCA enables us to estimate\nrepresentational similarity across languages and layers, enhancing our\nunderstanding of the functionality of multilingual speech translation and its\npotential connection to multilingual neural machine translation. The\nmultilingual speech translation model is trained on the CoVoST 2 dataset in all\npossible directions, and we utilize LASER to extract parallel bitext data for\nSVCCA analysis. We derive three major findings from our analysis: (I)\nLinguistic similarity loses its efficacy in multilingual speech translation\nwhen the training data for a specific language is limited. (II) Enhanced\nencoder representations and well-aligned audio-text data significantly improve\ntranslation quality, surpassing the bilingual counterparts when the training\ndata is not compromised. (III) The encoder representations of multilingual\nspeech translation demonstrate superior performance in predicting phonetic\nfeatures in linguistic typology prediction. With these findings, we propose\nthat releasing the constraint of limited data for low-resource languages and\nsubsequently combining them with linguistically related high-resource languages\ncould offer a more effective approach for multilingual end-to-end speech\ntranslation.",
            "author": [
                "Haoran Sun",
                "Xiaohu Zhao",
                "Yikun Lei",
                "Shaolin Zhu",
                "Deyi Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20456v1",
                "http://arxiv.org/pdf/2310.20456v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20453v1",
            "title": "Generate What You Prefer: Reshaping Sequential Recommendation via Guided\n  Diffusion",
            "updated": "2023-10-31T13:45:39Z",
            "published": "2023-10-31T13:45:39Z",
            "summary": "Sequential recommendation aims to recommend the next item that matches a\nuser's interest, based on the sequence of items he/she interacted with before.\nScrutinizing previous studies, we can summarize a common learning-to-classify\nparadigm -- given a positive item, a recommender model performs negative\nsampling to add negative items and learns to classify whether the user prefers\nthem or not, based on his/her historical interaction sequence. Although\neffective, we reveal two inherent limitations:(1) it may differ from human\nbehavior in that a user could imagine an oracle item in mind and select\npotential items matching the oracle; and (2) the classification is limited in\nthe candidate pool with noisy or easy supervision from negative samples, which\ndilutes the preference signals towards the oracle item. Yet, generating the\noracle item from the historical interaction sequence is mostly unexplored. To\nbridge the gap, we reshape sequential recommendation as a learning-to-generate\nparadigm, which is achieved via a guided diffusion model, termed\nDreamRec.Specifically, for a sequence of historical items, it applies a\nTransformer encoder to create guidance representations. Noising target items\nexplores the underlying distribution of item space; then, with the guidance of\nhistorical interactions, the denoising process generates an oracle item to\nrecover the positive item, so as to cast off negative sampling and depict the\ntrue preference of the user directly. We evaluate the effectiveness of DreamRec\nthrough extensive experiments and comparisons with existing methods. Codes and\ndata are open-sourced at https://github.com/YangZhengyi98/DreamRec.",
            "author": [
                "Zhengyi Yang",
                "Jiancan Wu",
                "Zhicai Wang",
                "Xiang Wang",
                "Yancheng Yuan",
                "Xiangnan He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20453v1",
                "http://arxiv.org/pdf/2310.20453v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20452v1",
            "title": "AsGrad: A Sharp Unified Analysis of Asynchronous-SGD Algorithms",
            "updated": "2023-10-31T13:44:53Z",
            "published": "2023-10-31T13:44:53Z",
            "summary": "We analyze asynchronous-type algorithms for distributed SGD in the\nheterogeneous setting, where each worker has its own computation and\ncommunication speeds, as well as data distribution. In these algorithms,\nworkers compute possibly stale and stochastic gradients associated with their\nlocal data at some iteration back in history and then return those gradients to\nthe server without synchronizing with other workers. We present a unified\nconvergence theory for non-convex smooth functions in the heterogeneous regime.\nThe proposed analysis provides convergence for pure asynchronous SGD and its\nvarious modifications. Moreover, our theory explains what affects the\nconvergence rate and what can be done to improve the performance of\nasynchronous algorithms. In particular, we introduce a novel asynchronous\nmethod based on worker shuffling. As a by-product of our analysis, we also\ndemonstrate convergence guarantees for gradient-type algorithms such as SGD\nwith random reshuffling and shuffle-once mini-batch SGD. The derived rates\nmatch the best-known results for those algorithms, highlighting the tightness\nof our approach. Finally, our numerical evaluations support theoretical\nfindings and show the good practical performance of our method.",
            "author": [
                "Rustem Islamov",
                "Mher Safaryan",
                "Dan Alistarh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20452v1",
                "http://arxiv.org/pdf/2310.20452v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20448v1",
            "title": "A Survey on Federated Unlearning: Challenges, Methods, and Future\n  Directions",
            "updated": "2023-10-31T13:32:00Z",
            "published": "2023-10-31T13:32:00Z",
            "summary": "In recent years, the notion of ``the right to be forgotten\" (RTBF) has\nevolved into a fundamental element of data privacy regulations, affording\nindividuals the ability to request the removal of their personal data from\ndigital records. Consequently, given the extensive adoption of data-intensive\nmachine learning (ML) algorithms and increasing concerns for personal data\nprivacy protection, the concept of machine unlearning (MU) has gained\nconsiderable attention. MU empowers an ML model to selectively eliminate\nsensitive or personally identifiable information it acquired during the\ntraining process. Evolving from the foundational principles of MU, federated\nunlearning (FU) has emerged to confront the challenge of data erasure within\nthe domain of federated learning (FL) settings. This empowers the FL model to\nunlearn an FL client or identifiable information pertaining to the client while\npreserving the integrity of the decentralized learning process. Nevertheless,\nunlike traditional MU, the distinctive attributes of federated learning\nintroduce specific challenges for FU techniques. These challenges lead to the\nneed for tailored design when designing FU algorithms. Therefore, this\ncomprehensive survey delves into the techniques, methodologies, and recent\nadvancements in federated unlearning. It provides an overview of fundamental\nconcepts and principles, evaluates existing federated unlearning algorithms,\nreviews optimizations tailored to federated learning, engages in discussions\nregarding practical applications, along with an assessment of their\nlimitations, and outlines promising directions for future research.",
            "author": [
                "Ziyao Liu",
                "Yu Jiang",
                "Jiyuan Shen",
                "Minyi Peng",
                "Kwok-Yan Lam",
                "Xingliang Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20448v1",
                "http://arxiv.org/pdf/2310.20448v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20447v1",
            "title": "Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted\n  Networks",
            "updated": "2023-10-31T13:30:30Z",
            "published": "2023-10-31T13:30:30Z",
            "summary": "Learning curve extrapolation aims to predict model performance in later\nepochs of training, based on the performance in earlier epochs. In this work,\nwe argue that, while the inherent uncertainty in the extrapolation of learning\ncurves warrants a Bayesian approach, existing methods are (i) overly\nrestrictive, and/or (ii) computationally expensive. We describe the first\napplication of prior-data fitted neural networks (PFNs) in this context. A PFN\nis a transformer, pre-trained on data generated from a prior, to perform\napproximate Bayesian inference in a single forward pass. We propose LC-PFN, a\nPFN trained to extrapolate 10 million artificial right-censored learning curves\ngenerated from a parametric prior proposed in prior art using MCMC. We\ndemonstrate that LC-PFN can approximate the posterior predictive distribution\nmore accurately than MCMC, while being over 10 000 times faster. We also show\nthat the same LC-PFN achieves competitive performance extrapolating a total of\n20 000 real learning curves from four learning curve benchmarks (LCBench,\nNAS-Bench-201, Taskset, and PD1) that stem from training a wide range of model\narchitectures (MLPs, CNNs, RNNs, and Transformers) on 53 different datasets\nwith varying input modalities (tabular, image, text, and protein data).\nFinally, we investigate its potential in the context of model selection and\nfind that a simple LC-PFN based predictive early stopping criterion obtains 2 -\n6x speed-ups on 45 of these datasets, at virtually no overhead.",
            "author": [
                "Steven Adriaensen",
                "Herilalaina Rakotoarison",
                "Samuel M\u00fcller",
                "Frank Hutter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20447v1",
                "http://arxiv.org/pdf/2310.20447v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20446v1",
            "title": "LAVSS: Location-Guided Audio-Visual Spatial Audio Separation",
            "updated": "2023-10-31T13:30:24Z",
            "published": "2023-10-31T13:30:24Z",
            "summary": "Existing machine learning research has achieved promising results in monaural\naudio-visual separation (MAVS). However, most MAVS methods purely consider what\nthe sound source is, not where it is located. This can be a problem in VR/AR\nscenarios, where listeners need to be able to distinguish between similar audio\nsources located in different directions. To address this limitation, we have\ngeneralized MAVS to spatial audio separation and proposed LAVSS: a\nlocation-guided audio-visual spatial audio separator. LAVSS is inspired by the\ncorrelation between spatial audio and visual location. We introduce the phase\ndifference carried by binaural audio as spatial cues, and we utilize positional\nrepresentations of sounding objects as additional modality guidance. We also\nleverage multi-level cross-modal attention to perform visual-positional\ncollaboration with audio features. In addition, we adopt a pre-trained monaural\nseparator to transfer knowledge from rich mono sounds to boost spatial audio\nseparation. This exploits the correlation between monaural and binaural\nchannels. Experiments on the FAIR-Play dataset demonstrate the superiority of\nthe proposed LAVSS over existing benchmarks of audio-visual separation. Our\nproject page: https://yyx666660.github.io/LAVSS/.",
            "author": [
                "Yuxin Ye",
                "Wenming Yang",
                "Yapeng Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20446v1",
                "http://arxiv.org/pdf/2310.20446v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20438v1",
            "title": "The Phase Transition Phenomenon of Shuffled Regression",
            "updated": "2023-10-31T13:21:14Z",
            "published": "2023-10-31T13:21:14Z",
            "summary": "We study the phase transition phenomenon inherent in the shuffled (permuted)\nregression problem, which has found numerous applications in databases,\nprivacy, data analysis, etc. In this study, we aim to precisely identify the\nlocations of the phase transition points by leveraging techniques from message\npassing (MP). In our analysis, we first transform the permutation recovery\nproblem into a probabilistic graphical model. We then leverage the analytical\ntools rooted in the message passing (MP) algorithm and derive an equation to\ntrack the convergence of the MP algorithm. By linking this equation to the\nbranching random walk process, we are able to characterize the impact of the\nsignal-to-noise-ratio ($\\snr$) on the permutation recovery. Depending on\nwhether the signal is given or not, we separately investigate the oracle case\nand the non-oracle case. The bottleneck in identifying the phase transition\nregimes lies in deriving closed-form formulas for the corresponding critical\npoints, but only in rare scenarios can one obtain such precise expressions. To\ntackle this technical challenge, this study proposes the Gaussian approximation\nmethod, which allows us to obtain the closed-form formulas in almost all\nscenarios. In the oracle case, our method can fairly accurately predict the\nphase transition $\\snr$. In the non-oracle case, our algorithm can predict the\nmaximum allowed number of permuted rows and uncover its dependency on the\nsample number.",
            "author": [
                "Hang Zhang",
                "Ping Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20438v1",
                "http://arxiv.org/pdf/2310.20438v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20434v1",
            "title": "Rapid cryogenic characterisation of 1024 integrated silicon quantum dots",
            "updated": "2023-10-31T13:14:43Z",
            "published": "2023-10-31T13:14:43Z",
            "summary": "Quantum computers are nearing the thousand qubit mark, with the current focus\non scaling to improve computational performance. As quantum processors grow in\ncomplexity, new challenges arise such as the management of device variability\nand the interface with supporting electronics. Spin qubits in silicon quantum\ndots are poised to address these challenges with their proven control\nfidelities and potential for compatibility with large-scale integration. Here,\nwe demonstrate the integration of 1024 silicon quantum dots with on-chip\ndigital and analogue electronics, all operating below 1 K. A high-frequency\nanalogue multiplexer provides fast access to all devices with minimal\nelectrical connections, enabling characteristic data across the quantum dot\narray to be acquired in just 5 minutes. We achieve this by leveraging\nradio-frequency reflectometry with state-of-the-art signal integrity, reaching\na minimum integration time of 160 ps. Key quantum dot parameters are extracted\nby fast automated machine learning routines to assess quantum dot yield and\nunderstand the impact of device design. We find correlations between quantum\ndot parameters and room temperature transistor behaviour that may be used as a\nproxy for in-line process monitoring. Our results show how rapid large-scale\nstudies of silicon quantum devices can be performed at lower temperatures and\nmeasurement rates orders of magnitude faster than current probing techniques,\nand form a platform for the future on-chip addressing of large scale qubit\narrays.",
            "author": [
                "Edward J. Thomas",
                "Virginia N. Ciriano-Tejel",
                "David F. Wise",
                "Domenic Prete",
                "Mathieu de Kruijf",
                "David J. Ibberson",
                "Grayson M. Noah",
                "Alberto Gomez-Saiz",
                "M. Fernando Gonzalez-Zalba",
                "Mark A. I. Johnson",
                "John J. L. Morton"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20434v1",
                "http://arxiv.org/pdf/2310.20434v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20435v1",
            "title": "Assessing the Sustainability and Trustworthiness of Federated Learning\n  Models",
            "updated": "2023-10-31T13:14:43Z",
            "published": "2023-10-31T13:14:43Z",
            "summary": "Artificial intelligence (AI) plays a pivotal role in various sectors,\ninfluencing critical decision-making processes in our daily lives. Within the\nAI landscape, novel AI paradigms, such as Federated Learning (FL), focus on\npreserving data privacy while collaboratively training AI models. In such a\ncontext, a group of experts from the European Commission (AI-HLEG) has\nidentified sustainable AI as one of the key elements that must be considered to\nprovide trustworthy AI. While existing literature offers several taxonomies and\nsolutions for assessing the trustworthiness of FL models, a significant gap\nexists in considering sustainability and the carbon footprint associated with\nFL. Thus, this work introduces the sustainability pillar to the most recent and\ncomprehensive trustworthy FL taxonomy, making this work the first to address\nall AI-HLEG requirements. The sustainability pillar assesses the FL system\nenvironmental impact, incorporating notions and metrics for hardware\nefficiency, federation complexity, and energy grid carbon intensity. Then, this\nwork designs and implements an algorithm for evaluating the trustworthiness of\nFL models by incorporating the sustainability pillar. Extensive evaluations\nwith the FederatedScope framework and various scenarios varying federation\nparticipants, complexities, hardware, and energy grids demonstrate the\nusefulness of the proposed solution.",
            "author": [
                "Alberto Huertas Celdran",
                "Chao Feng",
                "Pedro Miguel Sanchez Sanchez",
                "Lynn Zumtaugwald",
                "Gerome Bovet",
                "Burkhard Stiller"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20435v1",
                "http://arxiv.org/pdf/2310.20435v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20431v1",
            "title": "Raising the ClaSS of Streaming Time Series Segmentation",
            "updated": "2023-10-31T13:07:41Z",
            "published": "2023-10-31T13:07:41Z",
            "summary": "Ubiquitous sensors today emit high frequency streams of numerical\nmeasurements that reflect properties of human, animal, industrial, commercial,\nand natural processes. Shifts in such processes, e.g. caused by external events\nor internal state changes, manifest as changes in the recorded signals. The\ntask of streaming time series segmentation (STSS) is to partition the stream\ninto consecutive variable-sized segments that correspond to states of the\nobserved processes or entities. The partition operation itself must in\nperformance be able to cope with the input frequency of the signals. We\nintroduce ClaSS, a novel, efficient, and highly accurate algorithm for STSS.\nClaSS assesses the homogeneity of potential partitions using self-supervised\ntime series classification and applies statistical tests to detect significant\nchange points (CPs). In our experimental evaluation using two large benchmarks\nand six real-world data archives, we found ClaSS to be significantly more\nprecise than eight state-of-the-art competitors. Its space and time complexity\nis independent of segment sizes and linear only in the sliding window size. We\nalso provide ClaSS as a window operator with an average throughput of 538 data\npoints per second for the Apache Flink streaming engine.",
            "author": [
                "Arik Ermshaus",
                "Patrick Sch\u00e4fer",
                "Ulf Leser"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20431v1",
                "http://arxiv.org/pdf/2310.20431v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20427v1",
            "title": "Assessing and Enhancing Robustness of Deep Learning Models with\n  Corruption Emulation in Digital Pathology",
            "updated": "2023-10-31T12:59:36Z",
            "published": "2023-10-31T12:59:36Z",
            "summary": "Deep learning in digital pathology brings intelligence and automation as\nsubstantial enhancements to pathological analysis, the gold standard of\nclinical diagnosis. However, multiple steps from tissue preparation to slide\nimaging introduce various image corruptions, making it difficult for deep\nneural network (DNN) models to achieve stable diagnostic results for clinical\nuse. In order to assess and further enhance the robustness of the models, we\nanalyze the physical causes of the full-stack corruptions throughout the\npathological life-cycle and propose an Omni-Corruption Emulation (OmniCE)\nmethod to reproduce 21 types of corruptions quantified with 5-level severity.\nWe then construct three OmniCE-corrupted benchmark datasets at both patch level\nand slide level and assess the robustness of popular DNNs in classification and\nsegmentation tasks. Further, we explore to use the OmniCE-corrupted datasets as\naugmentation data for training and experiments to verify that the\ngeneralization ability of the models has been significantly enhanced.",
            "author": [
                "Peixiang Huang",
                "Songtao Zhang",
                "Yulu Gan",
                "Rui Xu",
                "Rongqi Zhu",
                "Wenkang Qin",
                "Limei Guo",
                "Shan Jiang",
                "Lin Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20427v1",
                "http://arxiv.org/pdf/2310.20427v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20426v1",
            "title": "Evolutionary Pareto Set Learning with Structure Constraints",
            "updated": "2023-10-31T12:53:56Z",
            "published": "2023-10-31T12:53:56Z",
            "summary": "The multiobjective evolutionary optimization algorithm (MOEA) is a powerful\napproach for tackling multiobjective optimization problems (MOPs), which can\nfind a finite set of approximate Pareto solutions in a single run. However,\nunder mild regularity conditions, the Pareto optimal set of a continuous MOP\ncould be a low dimensional continuous manifold that contains infinite\nsolutions. In addition, structure constraints on the whole optimal solution\nset, which characterize the patterns shared among all solutions, could be\nrequired in many real-life applications. It is very challenging for existing\nfinite population based MOEAs to handle these structure constraints properly.\nIn this work, we propose the first model-based algorithmic framework to learn\nthe whole solution set with structure constraints for multiobjective\noptimization. In our approach, the Pareto optimality can be traded off with a\npreferred structure among the whole solution set, which could be crucial for\nmany real-world problems. We also develop an efficient evolutionary learning\nmethod to train the set model with structure constraints. Experimental studies\non benchmark test suites and real-world application problems demonstrate the\npromising performance of our proposed framework.",
            "author": [
                "Xi Lin",
                "Xiaoyuan Zhang",
                "Zhiyuan Yang",
                "Qingfu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20426v1",
                "http://arxiv.org/pdf/2310.20426v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00727v1",
            "title": "Investigating Relative Performance of Transfer and Meta Learning",
            "updated": "2023-10-31T12:52:00Z",
            "published": "2023-10-31T12:52:00Z",
            "summary": "Over the past decade, the field of machine learning has experienced\nremarkable advancements. While image recognition systems have achieved\nimpressive levels of accuracy, they continue to rely on extensive training\ndatasets. Additionally, a significant challenge has emerged in the form of poor\nout-of-distribution performance, which necessitates retraining neural networks\nwhen they encounter conditions that deviate from their training data. This\nlimitation has notably contributed to the slow progress in self-driving car\ntechnology. These pressing issues have sparked considerable interest in methods\nthat enable neural networks to learn effectively from limited data. This paper\npresents the outcomes of an extensive investigation designed to compare two\ndistinct approaches, transfer learning and meta learning, as potential\nsolutions to this problem. The overarching objective was to establish a robust\ncriterion for selecting the most suitable method in diverse machine learning\nscenarios. Building upon prior research, I expanded the comparative analysis by\nintroducing a new meta learning method into the investigation. Subsequently, I\nassessed whether the findings remained consistent under varying conditions.\nFinally, I delved into the impact of altering the size of the training dataset\non the relative performance of these methods. This comprehensive exploration\nhas yielded insights into the conditions favoring each approach, thereby\nfacilitating the development of a criterion for selecting the most appropriate\nmethod in any given situation",
            "author": [
                "Benji Alwis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00727v1",
                "http://arxiv.org/pdf/2311.00727v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20425v2",
            "title": "Discussing the Spectra of Physics-Enhanced Machine Learning via a Survey\n  on Structural Mechanics Applications",
            "updated": "2023-11-01T08:21:02Z",
            "published": "2023-10-31T12:50:25Z",
            "summary": "The intersection of physics and machine learning has given rise to a paradigm\nthat we refer to here as physics-enhanced machine learning (PEML), aiming to\nimprove the capabilities and reduce the individual shortcomings of data- or\nphysics-only methods. In this paper, the spectrum of physics-enhanced machine\nlearning methods, expressed across the defining axes of physics and data, is\ndiscussed by engaging in a comprehensive exploration of its characteristics,\nusage, and motivations. In doing so, this paper offers a survey of recent\napplications and developments of PEML techniques, revealing the potency of PEML\nin addressing complex challenges. We further demonstrate application of select\nsuch schemes on the simple working example of a single-degree-of-freedom\nDuffing oscillator, which allows to highlight the individual characteristics\nand motivations of different `genres' of PEML approaches. To promote\ncollaboration and transparency, and to provide practical examples for the\nreader, the code of these working examples is provided alongside this paper. As\na foundational contribution, this paper underscores the significance of PEML in\npushing the boundaries of scientific and engineering research, underpinned by\nthe synergy of physical insights and machine learning capabilities.",
            "author": [
                "Marcus Haywood-Alexander",
                "Wei Liu",
                "Kiran Bacsa",
                "Zhilu Lai",
                "Eleni Chatzi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20425v2",
                "http://arxiv.org/pdf/2310.20425v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20424v1",
            "title": "DDC-PIM: Efficient Algorithm/Architecture Co-design for Doubling Data\n  Capacity of SRAM-based Processing-In-Memory",
            "updated": "2023-10-31T12:49:54Z",
            "published": "2023-10-31T12:49:54Z",
            "summary": "Processing-in-memory (PIM), as a novel computing paradigm, provides\nsignificant performance benefits from the aspect of effective data movement\nreduction. SRAM-based PIM has been demonstrated as one of the most promising\ncandidates due to its endurance and compatibility. However, the integration\ndensity of SRAM-based PIM is much lower than other non-volatile memory-based\nones, due to its inherent 6T structure for storing a single bit. Within\ncomparable area constraints, SRAM-based PIM exhibits notably lower capacity.\nThus, aiming to unleash its capacity potential, we propose DDC-PIM, an\nefficient algorithm/architecture co-design methodology that effectively doubles\nthe equivalent data capacity. At the algorithmic level, we propose a\nfilter-wise complementary correlation (FCC) algorithm to obtain a bitwise\ncomplementary pair. At the architecture level, we exploit the intrinsic\ncross-coupled structure of 6T SRAM to store the bitwise complementary pair in\ntheir complementary states ($Q/\\overline{Q}$), thereby maximizing the data\ncapacity of each SRAM cell. The dual-broadcast input structure and\nreconfigurable unit support both depthwise and pointwise convolution, adhering\nto the requirements of various neural networks. Evaluation results show that\nDDC-PIM yields about $2.84\\times$ speedup on MobileNetV2 and $2.69\\times$ on\nEfficientNet-B0 with negligible accuracy loss compared with PIM baseline\nimplementation. Compared with state-of-the-art SRAM-based PIM macros, DDC-PIM\nachieves up to $8.41\\times$ and $2.75\\times$ improvement in weight density and\narea efficiency, respectively.",
            "author": [
                "Cenlin Duan",
                "Jianlei Yang",
                "Xiaolin He",
                "Yingjie Qi",
                "Yikun Wang",
                "Yiou Wang",
                "Ziyan He",
                "Bonan Yan",
                "Xueyan Wang",
                "Xiaotao Jia",
                "Weitao Pan",
                "Weisheng Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20424v1",
                "http://arxiv.org/pdf/2310.20424v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20415v1",
            "title": "Coalitional Manipulations and Immunity of the Shapley Value",
            "updated": "2023-10-31T12:43:31Z",
            "published": "2023-10-31T12:43:31Z",
            "summary": "We consider manipulations in the context of coalitional games, where a\ncoalition aims to increase the total payoff of its members. An allocation rule\nis immune to coalitional manipulation if no coalition can benefit from internal\nreallocation of worth on the level of its subcoalitions\n(reallocation-proofness), and if no coalition benefits from a lower worth while\nall else remains the same (weak coalitional monotonicity). Replacing additivity\nin Shapley's original characterization by these requirements yields a new\nfoundation of the Shapley value, i.e., it is the unique efficient and symmetric\nallocation rule that awards nothing to a null player and is immune to\ncoalitional manipulations. We further find that for efficient allocation rules,\nreallocation-proofness is equivalent to constrained marginality, a weaker\nvariant of Young's marginality axiom. Our second characterization improves upon\nYoung's characterization by weakening the independence requirement intrinsic to\nmarginality.",
            "author": [
                "Christian Basteck",
                "Frank Huettner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20415v1",
                "http://arxiv.org/pdf/2310.20415v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH",
                "cs.GT",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20414v2",
            "title": "Meta Learning for Multi-View Visuomotor Systems",
            "updated": "2023-11-03T13:58:28Z",
            "published": "2023-10-31T12:40:46Z",
            "summary": "This paper introduces a new approach for quickly adapting a multi-view\nvisuomotor system for robots to varying camera configurations from the baseline\nsetup. It utilises meta-learning to fine-tune the perceptual network while\nkeeping the policy network fixed. Experimental results demonstrate a\nsignificant reduction in the number of new training episodes needed to attain\nbaseline performance.",
            "author": [
                "Benji Alwis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20414v2",
                "http://arxiv.org/pdf/2310.20414v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20412v1",
            "title": "Thermal-Infrared Remote Target Detection System for Maritime Rescue\n  based on Data Augmentation with 3D Synthetic Data",
            "updated": "2023-10-31T12:37:49Z",
            "published": "2023-10-31T12:37:49Z",
            "summary": "This paper proposes a thermal-infrared (TIR) remote target detection system\nfor maritime rescue using deep learning and data augmentation. We established a\nself-collected TIR dataset consisting of multiple scenes imitating human rescue\nsituations using a TIR camera (FLIR). Additionally, to address dataset scarcity\nand improve model robustness, a synthetic dataset from a 3D game (ARMA3) to\naugment the data is further collected. However, a significant domain gap exists\nbetween synthetic TIR and real TIR images. Hence, a proper domain adaptation\nalgorithm is essential to overcome the gap. Therefore, we suggest a domain\nadaptation algorithm in a target-background separated manner from 3D\ngame-to-real, based on a generative model, to address this issue. Furthermore,\na segmentation network with fixed-weight kernels at the head is proposed to\nimprove the signal-to-noise ratio (SNR) and provide weak attention, as remote\nTIR targets inherently suffer from unclear boundaries. Experiment results\nreveal that the network trained on augmented data consisting of translated\nsynthetic and real TIR data outperforms that trained on only real TIR data by a\nlarge margin. Furthermore, the proposed segmentation model surpasses the\nperformance of state-of-the-art segmentation methods.",
            "author": [
                "Sungjin Cheong",
                "Wonho Jung",
                "Yoon Seop Lim",
                "Yong-Hwa Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20412v1",
                "http://arxiv.org/pdf/2310.20412v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "68T45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20403v1",
            "title": "Multi-Base Station Cooperative Sensing with AI-Aided Tracking",
            "updated": "2023-10-31T12:27:48Z",
            "published": "2023-10-31T12:27:48Z",
            "summary": "In this work, we investigate the performance of a joint sensing and\ncommunication (JSC) network consisting of multiple base stations (BSs) that\ncooperate through a fusion center (FC) to exchange information about the sensed\nenvironment while concurrently establishing communication links with a set of\nuser equipments (UEs). Each BS within the network operates as a monostatic\nradar system, enabling comprehensive scanning of the monitored area and\ngenerating range-angle maps that provide information regarding the position of\na group of heterogeneous objects. The acquired maps are subsequently fused in\nthe FC. Then, a convolutional neural network (CNN) is employed to infer the\ncategory of the targets, e.g., pedestrians or vehicles, and such information is\nexploited by an adaptive clustering algorithm to group the detections\noriginating from the same target more effectively. Finally, two multi-target\ntracking algorithms, the probability hypothesis density (PHD) filter and\nmulti-Bernoulli mixture (MBM) filter, are applied to estimate the state of the\ntargets. Numerical results demonstrated that our framework could provide\nremarkable sensing performance, achieving an optimal sub-pattern assignment\n(OSPA) less than 60 cm, while keeping communication services to UEs with a\nreduction of the communication capacity in the order of 10% to 20%. The impact\nof the number of BSs engaged in sensing is also examined, and we show that in\nthe specific case study, 3 BSs ensure a localization error below 1 m.",
            "author": [
                "Elia Favarelli",
                "Elisabetta Matricardi",
                "Lorenzo Pucci",
                "Enrico Paolini",
                "Wen Xu",
                "Andrea Giorgetti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20403v1",
                "http://arxiv.org/pdf/2310.20403v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20398v1",
            "title": "A hybrid approach for solving the gravitational N-body problem with\n  Artificial Neural Networks",
            "updated": "2023-10-31T12:20:20Z",
            "published": "2023-10-31T12:20:20Z",
            "summary": "Simulating the evolution of the gravitational N-body problem becomes\nextremely computationally expensive as N increases since the problem complexity\nscales quadratically with the number of bodies. We study the use of Artificial\nNeural Networks (ANNs) to replace expensive parts of the integration of\nplanetary systems. Neural networks that include physical knowledge have grown\nin popularity in the last few years, although few attempts have been made to\nuse them to speed up the simulation of the motion of celestial bodies. We study\nthe advantages and limitations of using Hamiltonian Neural Networks to replace\ncomputationally expensive parts of the numerical simulation. We compare the\nresults of the numerical integration of a planetary system with asteroids with\nthose obtained by a Hamiltonian Neural Network and a conventional Deep Neural\nNetwork, with special attention to understanding the challenges of this\nproblem. Due to the non-linear nature of the gravitational equations of motion,\nerrors in the integration propagate. To increase the robustness of a method\nthat uses neural networks, we propose a hybrid integrator that evaluates the\nprediction of the network and replaces it with the numerical solution if\nconsidered inaccurate. Hamiltonian Neural Networks can make predictions that\nresemble the behavior of symplectic integrators but are challenging to train\nand in our case fail when the inputs differ ~7 orders of magnitude. In\ncontrast, Deep Neural Networks are easy to train but fail to conserve energy,\nleading to fast divergence from the reference solution. The hybrid integrator\ndesigned to include the neural networks increases the reliability of the method\nand prevents large energy errors without increasing the computing cost\nsignificantly. For this problem, the use of neural networks results in faster\nsimulations when the number of asteroids is >70.",
            "author": [
                "Veronica Saz Ulibarrena",
                "Philipp Horn",
                "Simon Portegies Zwart",
                "Elena Sellentin",
                "Barry Koren",
                "Maxwell X. Cai"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.jcp.2023.112596",
                "http://arxiv.org/abs/2310.20398v1",
                "http://arxiv.org/pdf/2310.20398v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20389v1",
            "title": "High-Resolution Reference Image Assisted Volumetric Super-Resolution of\n  Cardiac Diffusion Weighted Imaging",
            "updated": "2023-10-31T12:05:27Z",
            "published": "2023-10-31T12:05:27Z",
            "summary": "Diffusion Tensor Cardiac Magnetic Resonance (DT-CMR) is the only in vivo\nmethod to non-invasively examine the microstructure of the human heart. Current\nresearch in DT-CMR aims to improve the understanding of how the cardiac\nmicrostructure relates to the macroscopic function of the healthy heart as well\nas how microstructural dysfunction contributes to disease. To get the final\nDT-CMR metrics, we need to acquire diffusion weighted images of at least 6\ndirections. However, due to DWI's low signal-to-noise ratio, the standard voxel\nsize is quite big on the scale for microstructures. In this study, we explored\nthe potential of deep-learning-based methods in improving the image quality\nvolumetrically (x4 in all dimensions). This study proposed a novel framework to\nenable volumetric super-resolution, with an additional model input of\nhigh-resolution b0 DWI. We demonstrated that the additional input could offer\nhigher super-resolved image quality. Going beyond, the model is also able to\nsuper-resolve DWIs of unseen b-values, proving the model framework's\ngeneralizability for cardiac DWI superresolution. In conclusion, we would then\nrecommend giving the model a high-resolution reference image as an additional\ninput to the low-resolution image for training and inference to guide all\nsuper-resolution frameworks for parametric imaging where a reference image is\navailable.",
            "author": [
                "Yinzhe Wu",
                "Jiahao Huang",
                "Fanwen Wang",
                "Pedro Ferreira",
                "Andrew Scott",
                "Sonia Nielles-Vallespin",
                "Guang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20389v1",
                "http://arxiv.org/pdf/2310.20389v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20384v1",
            "title": "Do large language models solve verbal analogies like children do?",
            "updated": "2023-10-31T11:49:11Z",
            "published": "2023-10-31T11:49:11Z",
            "summary": "Analogy-making lies at the heart of human cognition. Adults solve analogies\nsuch as \\textit{Horse belongs to stable like chicken belongs to ...?} by\nmapping relations (\\textit{kept in}) and answering \\textit{chicken coop}. In\ncontrast, children often use association, e.g., answering \\textit{egg}. This\npaper investigates whether large language models (LLMs) solve verbal analogies\nin A:B::C:? form using associations, similar to what children do. We use verbal\nanalogies extracted from an online adaptive learning environment, where 14,002\n7-12 year-olds from the Netherlands solved 622 analogies in Dutch. The six\ntested Dutch monolingual and multilingual LLMs performed around the same level\nas children, with MGPT performing worst, around the 7-year-old level, and XLM-V\nand GPT-3 the best, slightly above the 11-year-old level. However, when we\ncontrol for associative processes this picture changes and each model's\nperformance level drops 1-2 years. Further experiments demonstrate that\nassociative processes often underlie correctly solved analogies. We conclude\nthat the LLMs we tested indeed tend to solve verbal analogies by association\nwith C like children do.",
            "author": [
                "Claire E. Stevenson",
                "Mathilde ter Veen",
                "Rochelle Choenni",
                "Han L. J. van der Maas",
                "Ekaterina Shutova"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20384v1",
                "http://arxiv.org/pdf/2310.20384v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20380v3",
            "title": "Dropout Strategy in Reinforcement Learning: Limiting the Surrogate\n  Objective Variance in Policy Optimization Methods",
            "updated": "2023-11-03T04:12:09Z",
            "published": "2023-10-31T11:38:26Z",
            "summary": "Policy-based reinforcement learning algorithms are widely used in various\nfields. Among them, mainstream policy optimization algorithms such as TRPO and\nPPO introduce importance sampling into policy iteration, which allows the reuse\nof historical data. However, this can also lead to a high variance of the\nsurrogate objective and indirectly affects the stability and convergence of the\nalgorithm. In this paper, we first derived an upper bound of the surrogate\nobjective variance, which can grow quadratically with the increase of the\nsurrogate objective. Next, we proposed the dropout technique to avoid the\nexcessive increase of the surrogate objective variance caused by importance\nsampling. Then, we introduced a general reinforcement learning framework\napplicable to mainstream policy optimization methods, and applied the dropout\ntechnique to the PPO algorithm to obtain the D-PPO variant. Finally, we conduct\ncomparative experiments between D-PPO and PPO algorithms in the Atari 2600\nenvironment, and the results show that D-PPO achieved significant performance\nimprovements compared to PPO, and effectively limited the excessive increase of\nthe surrogate objective variance during training.",
            "author": [
                "Zhengpeng Xie",
                "Changdong Yu",
                "Weizheng Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20380v3",
                "http://arxiv.org/pdf/2310.20380v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20369v1",
            "title": "Stability and Generalization of the Decentralized Stochastic Gradient\n  Descent Ascent Algorithm",
            "updated": "2023-10-31T11:27:01Z",
            "published": "2023-10-31T11:27:01Z",
            "summary": "The growing size of available data has attracted increasing interest in\nsolving minimax problems in a decentralized manner for various machine learning\ntasks. Previous theoretical research has primarily focused on the convergence\nrate and communication complexity of decentralized minimax algorithms, with\nlittle attention given to their generalization. In this paper, we investigate\nthe primal-dual generalization bound of the decentralized stochastic gradient\ndescent ascent (D-SGDA) algorithm using the approach of algorithmic stability\nunder both convex-concave and nonconvex-nonconcave settings. Our theory refines\nthe algorithmic stability in a decentralized manner and demonstrates that the\ndecentralized structure does not destroy the stability and generalization of\nD-SGDA, implying that it can generalize as well as the vanilla SGDA in certain\nsituations. Our results analyze the impact of different topologies on the\ngeneralization bound of the D-SGDA algorithm beyond trivial factors such as\nsample sizes, learning rates, and iterations. We also evaluate the optimization\nerror and balance it with the generalization gap to obtain the optimal\npopulation risk of D-SGDA in the convex-concave setting. Additionally, we\nperform several numerical experiments which validate our theoretical findings.",
            "author": [
                "Miaoxi Zhu",
                "Li Shen",
                "Bo Du",
                "Dacheng Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20369v1",
                "http://arxiv.org/pdf/2310.20369v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20367v1",
            "title": "A Machine Learning-Based Framework for Clustering Residential\n  Electricity Load Profiles to Enhance Demand Response Programs",
            "updated": "2023-10-31T11:23:26Z",
            "published": "2023-10-31T11:23:26Z",
            "summary": "Load shapes derived from smart meter data are frequently employed to analyze\ndaily energy consumption patterns, particularly in the context of applications\nlike Demand Response (DR). Nevertheless, one of the most important challenges\nto this endeavor lies in identifying the most suitable consumer clusters with\nsimilar consumption behaviors. In this paper, we present a novel machine\nlearning based framework in order to achieve optimal load profiling through a\nreal case study, utilizing data from almost 5000 households in London. Four\nwidely used clustering algorithms are applied specifically K-means, K-medoids,\nHierarchical Agglomerative Clustering and Density-based Spatial Clustering. An\nempirical analysis as well as multiple evaluation metrics are leveraged to\nassess those algorithms. Following that, we redefine the problem as a\nprobabilistic classification one, with the classifier emulating the behavior of\na clustering algorithm,leveraging Explainable AI (xAI) to enhance the\ninterpretability of our solution. According to the clustering algorithm\nanalysis the optimal number of clusters for this case is seven. Despite that,\nour methodology shows that two of the clusters, almost 10\\% of the dataset,\nexhibit significant internal dissimilarity and thus it splits them even further\nto create nine clusters in total. The scalability and versatility of our\nsolution makes it an ideal choice for power utility companies aiming to segment\ntheir users for creating more targeted Demand Response programs.",
            "author": [
                "Vasilis Michalakopoulos",
                "Elissaios Sarmas",
                "Ioannis Papias",
                "Panagiotis Skaloumpakas",
                "Vangelis Marinakis",
                "Haris Doukas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20367v1",
                "http://arxiv.org/pdf/2310.20367v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20366v1",
            "title": "Distil the informative essence of loop detector data set: Is\n  network-level traffic forecasting hungry for more data?",
            "updated": "2023-10-31T11:23:10Z",
            "published": "2023-10-31T11:23:10Z",
            "summary": "Network-level traffic condition forecasting has been intensively studied for\ndecades. Although prediction accuracy has been continuously improved with\nemerging deep learning models and ever-expanding traffic data, traffic\nforecasting still faces many challenges in practice. These challenges include\nthe robustness of data-driven models, the inherent unpredictability of traffic\ndynamics, and whether further improvement of traffic forecasting requires more\nsensor data. In this paper, we focus on this latter question and particularly\non data from loop detectors. To answer this, we propose an uncertainty-aware\ntraffic forecasting framework to explore how many samples of loop data are\ntruly effective for training forecasting models. Firstly, the model design\ncombines traffic flow theory with graph neural networks, ensuring the\nrobustness of prediction and uncertainty quantification. Secondly, evidential\nlearning is employed to quantify different sources of uncertainty in a single\npass. The estimated uncertainty is used to \"distil\" the essence of the dataset\nthat sufficiently covers the information content. Results from a case study of\na highway network around Amsterdam show that, from 2018 to 2021, more than 80\\%\nof the data during daytime can be removed. The remaining 20\\% samples have\nequal prediction power for training models. This result suggests that indeed\nlarge traffic datasets can be subdivided into significantly smaller but equally\ninformative datasets. From these findings, we conclude that the proposed\nmethodology proves valuable in evaluating large traffic datasets' true\ninformation content. Further extensions, such as extracting smaller, spatially\nnon-redundant datasets, are possible with this method.",
            "author": [
                "Guopeng Li",
                "Victor L. Knoop",
                "J. W. C.",
                "van Lint"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20366v1",
                "http://arxiv.org/pdf/2310.20366v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20363v1",
            "title": "CAFE: Conflict-Aware Feature-wise Explanations",
            "updated": "2023-10-31T11:14:26Z",
            "published": "2023-10-31T11:14:26Z",
            "summary": "Feature attribution methods are widely used to explain neural models by\ndetermining the influence of individual input features on the models' outputs.\nWe propose a novel feature attribution method, CAFE (Conflict-Aware\nFeature-wise Explanations), that addresses three limitations of the existing\nmethods: their disregard for the impact of conflicting features, their lack of\nconsideration for the influence of bias terms, and an overly high sensitivity\nto local variations in the underpinning activation functions. Unlike other\nmethods, CAFE provides safeguards against overestimating the effects of neuron\ninputs and separately traces positive and negative influences of input features\nand biases, resulting in enhanced robustness and increased ability to surface\nfeature conflicts. We show experimentally that CAFE is better able to identify\nconflicting features on synthetic tabular data and exhibits the best overall\nfidelity on several real-world tabular datasets, while being highly\ncomputationally efficient.",
            "author": [
                "Adam Dejl",
                "Hamed Ayoobi",
                "Matthew Williams",
                "Francesca Toni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20363v1",
                "http://arxiv.org/pdf/2310.20363v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.03376v1",
            "title": "Blocked Collaborative Bandits: Online Collaborative Filtering with\n  Per-Item Budget Constraints",
            "updated": "2023-10-31T11:04:21Z",
            "published": "2023-10-31T11:04:21Z",
            "summary": "We consider the problem of \\emph{blocked} collaborative bandits where there\nare multiple users, each with an associated multi-armed bandit problem. These\nusers are grouped into \\emph{latent} clusters such that the mean reward vectors\nof users within the same cluster are identical. Our goal is to design\nalgorithms that maximize the cumulative reward accrued by all the users over\ntime, under the \\emph{constraint} that no arm of a user is pulled more than\n$\\mathsf{B}$ times. This problem has been originally considered by\n\\cite{Bresler:2014}, and designing regret-optimal algorithms for it has since\nremained an open problem. In this work, we propose an algorithm called\n\\texttt{B-LATTICE} (Blocked Latent bAndiTs via maTrIx ComplEtion) that\ncollaborates across users, while simultaneously satisfying the budget\nconstraints, to maximize their cumulative rewards. Theoretically, under certain\nreasonable assumptions on the latent structure, with $\\mathsf{M}$ users,\n$\\mathsf{N}$ arms, $\\mathsf{T}$ rounds per user, and $\\mathsf{C}=O(1)$ latent\nclusters, \\texttt{B-LATTICE} achieves a per-user regret of\n$\\widetilde{O}(\\sqrt{\\mathsf{T}(1 + \\mathsf{N}\\mathsf{M}^{-1})}$ under a budget\nconstraint of $\\mathsf{B}=\\Theta(\\log \\mathsf{T})$. These are the first\nsub-linear regret bounds for this problem, and match the minimax regret bounds\nwhen $\\mathsf{B}=\\mathsf{T}$. Empirically, we demonstrate that our algorithm\nhas superior performance over baselines even when $\\mathsf{B}=1$.\n\\texttt{B-LATTICE} runs in phases where in each phase it clusters users into\ngroups and collaborates across users within a group to quickly learn their\nreward models.",
            "author": [
                "Soumyabrata Pal",
                "Arun Sai Suggala",
                "Karthikeyan Shanmugam",
                "Prateek Jain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03376v1",
                "http://arxiv.org/pdf/2311.03376v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20360v1",
            "title": "Mathematical Introduction to Deep Learning: Methods, Implementations,\n  and Theory",
            "updated": "2023-10-31T11:01:23Z",
            "published": "2023-10-31T11:01:23Z",
            "summary": "This book aims to provide an introduction to the topic of deep learning\nalgorithms. We review essential components of deep learning algorithms in full\nmathematical detail including different artificial neural network (ANN)\narchitectures (such as fully-connected feedforward ANNs, convolutional ANNs,\nrecurrent ANNs, residual ANNs, and ANNs with batch normalization) and different\noptimization algorithms (such as the basic stochastic gradient descent (SGD)\nmethod, accelerated methods, and adaptive methods). We also cover several\ntheoretical aspects of deep learning algorithms such as approximation\ncapacities of ANNs (including a calculus for ANNs), optimization theory\n(including Kurdyka-{\\L}ojasiewicz inequalities), and generalization errors. In\nthe last part of the book some deep learning approximation methods for PDEs are\nreviewed including physics-informed neural networks (PINNs) and deep Galerkin\nmethods. We hope that this book will be useful for students and scientists who\ndo not yet have any background in deep learning at all and would like to gain a\nsolid foundation as well as for practitioners who would like to obtain a firmer\nmathematical understanding of the objects and methods considered in deep\nlearning.",
            "author": [
                "Arnulf Jentzen",
                "Benno Kuckuck",
                "Philippe von Wurstemberger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20360v1",
                "http://arxiv.org/pdf/2310.20360v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NA",
                "math.NA",
                "math.PR",
                "stat.ML",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20355v1",
            "title": "Muscle volume quantification: guiding transformers with anatomical\n  priors",
            "updated": "2023-10-31T10:56:10Z",
            "published": "2023-10-31T10:56:10Z",
            "summary": "Muscle volume is a useful quantitative biomarker in sports, but also for the\nfollow-up of degenerative musculo-skelletal diseases. In addition to volume,\nother shape biomarkers can be extracted by segmenting the muscles of interest\nfrom medical images. Manual segmentation is still today the gold standard for\nsuch measurements despite being very time-consuming. We propose a method for\nautomatic segmentation of 18 muscles of the lower limb on 3D Magnetic Resonance\nImages to assist such morphometric analysis. By their nature, the tissue of\ndifferent muscles is undistinguishable when observed in MR Images. Thus, muscle\nsegmentation algorithms cannot rely on appearance but only on contour cues.\nHowever, such contours are hard to detect and their thickness varies across\nsubjects. To cope with the above challenges, we propose a segmentation approach\nbased on a hybrid architecture, combining convolutional and visual transformer\nblocks. We investigate for the first time the behaviour of such hybrid\narchitectures in the context of muscle segmentation for shape analysis.\nConsidering the consistent anatomical muscle configuration, we rely on\ntransformer blocks to capture the longrange relations between the muscles. To\nfurther exploit the anatomical priors, a second contribution of this work\nconsists in adding a regularisation loss based on an adjacency matrix of\nplausible muscle neighbourhoods estimated from the training data. Our\nexperimental results on a unique database of elite athletes show it is possible\nto train complex hybrid models from a relatively small database of large\nvolumes, while the anatomical prior regularisation favours better predictions.",
            "author": [
                "Louise Piecuch",
                "Vanessa Gonzales Duque",
                "Aur\u00e9lie Sarcher",
                "Enzo Hollville",
                "Antoine Nordez",
                "Giuseppe Rabita",
                "Ga\u00ebl Guilhem",
                "Diana Mateus"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20355v1",
                "http://arxiv.org/pdf/2310.20355v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20350v1",
            "title": "Combining Shape Completion and Grasp Prediction for Fast and Versatile\n  Grasping with a Multi-Fingered Hand",
            "updated": "2023-10-31T10:46:19Z",
            "published": "2023-10-31T10:46:19Z",
            "summary": "Grasping objects with limited or no prior knowledge about them is a highly\nrelevant skill in assistive robotics. Still, in this general setting, it has\nremained an open problem, especially when it comes to only partial\nobservability and versatile grasping with multi-fingered hands. We present a\nnovel, fast, and high fidelity deep learning pipeline consisting of a shape\ncompletion module that is based on a single depth image, and followed by a\ngrasp predictor that is based on the predicted object shape. The shape\ncompletion network is based on VQDIF and predicts spatial occupancy values at\narbitrary query points. As grasp predictor, we use our two-stage architecture\nthat first generates hand poses using an autoregressive model and then\nregresses finger joint configurations per pose. Critical factors turn out to be\nsufficient data realism and augmentation, as well as special attention to\ndifficult cases during training. Experiments on a physical robot platform\ndemonstrate successful grasping of a wide range of household objects based on a\ndepth image from a single viewpoint. The whole pipeline is fast, taking only\nabout 1 s for completing the object's shape (0.7 s) and generating 1000 grasps\n(0.3 s).",
            "author": [
                "Matthias Humt",
                "Dominik Winkelbauer",
                "Ulrich Hillenbrand",
                "Berthold B\u00e4uml"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20350v1",
                "http://arxiv.org/pdf/2310.20350v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20348v1",
            "title": "Class Incremental Learning with Pre-trained Vision-Language Models",
            "updated": "2023-10-31T10:45:03Z",
            "published": "2023-10-31T10:45:03Z",
            "summary": "With the advent of large-scale pre-trained models, interest in adapting and\nexploiting them for continual learning scenarios has grown.\n  In this paper, we propose an approach to exploiting pre-trained\nvision-language models (e.g. CLIP) that enables further adaptation instead of\nonly using zero-shot learning of new tasks. We augment a pre-trained CLIP model\nwith additional layers after the Image Encoder or before the Text Encoder. We\ninvestigate three different strategies: a Linear Adapter, a Self-attention\nAdapter, each operating on the image embedding, and Prompt Tuning which instead\nmodifies prompts input to the CLIP text encoder. We also propose a method for\nparameter retention in the adapter layers that uses a measure of parameter\nimportance to better maintain stability and plasticity during incremental\nlearning. Our experiments demonstrate that the simplest solution -- a single\nLinear Adapter layer with parameter retention -- produces the best results.\nExperiments on several conventional benchmarks consistently show a significant\nmargin of improvement over the current state-of-the-art.",
            "author": [
                "Xialei Liu",
                "Xusheng Cao",
                "Haori Lu",
                "Jia-wen Xiao",
                "Andrew D. Bagdanov",
                "Ming-Ming Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20348v1",
                "http://arxiv.org/pdf/2310.20348v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20331v1",
            "title": "Energy-Aware Adaptive Sampling for Self-Sustainability in\n  Resource-Constrained IoT Devices",
            "updated": "2023-10-31T10:16:33Z",
            "published": "2023-10-31T10:16:33Z",
            "summary": "In the ever-growing Internet of Things (IoT) landscape, smart power\nmanagement algorithms combined with energy harvesting solutions are crucial to\nobtain self-sustainability. This paper presents an energy-aware adaptive\nsampling rate algorithm designed for embedded deployment in\nresource-constrained, battery-powered IoT devices. The algorithm, based on a\nfinite state machine (FSM) and inspired by Transmission Control Protocol (TCP)\nReno's additive increase and multiplicative decrease, maximizes sensor sampling\nrates, ensuring power self-sustainability without risking battery depletion.\nMoreover, we characterized our solar cell with data acquired over 48 days and\nused the model created to obtain energy data from an open-source world-wide\ndataset. To validate our approach, we introduce the EcoTrack device, a\nversatile device with global navigation satellite system (GNSS) capabilities\nand Long-Term Evolution Machine Type Communication (LTE-M) connectivity,\nsupporting MQTT protocol for cloud data relay. This multi-purpose device can be\nused, for instance, as a health and safety wearable, remote hazard monitoring\nsystem, or as a global asset tracker. The results, validated on data from three\ndifferent European cities, show that the proposed algorithm enables\nself-sustainability while maximizing sampled locations per day. In experiments\nconducted with a 3000 mAh battery capacity, the algorithm consistently\nmaintained a minimum of 24 localizations per day and achieved peaks of up to\n3000.",
            "author": [
                "Marco Giordano",
                "Silvano Cortesi",
                "Prodromos-Vasileios Mekikis",
                "Michele Crabolu",
                "Giovanni Bellusci",
                "Michele Magno"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3628353.3628545",
                "http://arxiv.org/abs/2310.20331v1",
                "http://arxiv.org/pdf/2310.20331v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20329v1",
            "title": "InstructCoder: Empowering Language Models for Code Editing",
            "updated": "2023-10-31T10:15:35Z",
            "published": "2023-10-31T10:15:35Z",
            "summary": "Code editing encompasses a variety of pragmatic tasks that developers deal\nwith daily. Despite its relevance and practical usefulness, automatic code\nediting remains an underexplored area in the evolution of deep learning models,\npartly due to data scarcity. In this work, we explore the use of large language\nmodels (LLMs) to edit code based on user instructions, covering a broad range\nof implicit tasks such as comment insertion, code optimization, and code\nrefactoring. To facilitate this, we introduce InstructCoder, the first dataset\ndesigned to adapt LLMs for general-purpose code editing, containing\nhighdiversity code-editing tasks. It consists of over 114,000\ninstruction-input-output triplets and covers multiple distinct code editing\nscenarios. The dataset is systematically expanded through an iterative process\nthat commences with code editing data sourced from GitHub commits as seed\ntasks. Seed and generated tasks are used subsequently to prompt ChatGPT for\nmore task data. Our experiments demonstrate that open-source LLMs fine-tuned on\nInstructCoder can edit code correctly based on users' instructions most of the\ntime, exhibiting unprecedented code-editing performance levels. Such results\nsuggest that proficient instruction-finetuning can lead to significant\namelioration in code editing abilities. The dataset and the source code are\navailable at https://github.com/qishenghu/CodeInstruct.",
            "author": [
                "Qisheng Hu",
                "Kaixin Li",
                "Xu Zhao",
                "Yuxi Xie",
                "Tiedong Liu",
                "Hui Chen",
                "Qizhe Xie",
                "Junxian He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20329v1",
                "http://arxiv.org/pdf/2310.20329v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20328v1",
            "title": "ChiSCor: A Corpus of Freely Told Fantasy Stories by Dutch Children for\n  Computational Linguistics and Cognitive Science",
            "updated": "2023-10-31T10:15:20Z",
            "published": "2023-10-31T10:15:20Z",
            "summary": "In this resource paper we release ChiSCor, a new corpus containing 619\nfantasy stories, told freely by 442 Dutch children aged 4-12. ChiSCor was\ncompiled for studying how children render character perspectives, and\nunravelling language and cognition in development, with computational tools.\nUnlike existing resources, ChiSCor's stories were produced in natural contexts,\nin line with recent calls for more ecologically valid datasets. ChiSCor hosts\ntext, audio, and annotations for character complexity and linguistic\ncomplexity. Additional metadata (e.g. education of caregivers) is available for\none third of the Dutch children. ChiSCor also includes a small set of 62\nEnglish stories. This paper details how ChiSCor was compiled and shows its\npotential for future work with three brief case studies: i) we show that the\nsyntactic complexity of stories is strikingly stable across children's ages;\nii) we extend work on Zipfian distributions in free speech and show that\nChiSCor obeys Zipf's law closely, reflecting its social context; iii) we show\nthat even though ChiSCor is relatively small, the corpus is rich enough to\ntrain informative lemma vectors that allow us to analyse children's language\nuse. We end with a reflection on the value of narrative datasets in\ncomputational linguistics.",
            "author": [
                "Bram M. A. van Dijk",
                "Max J. van Duijn",
                "Suzan Verberne",
                "Marco R. Spruit"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20328v1",
                "http://arxiv.org/pdf/2310.20328v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20320v1",
            "title": "Theory of Mind in Large Language Models: Examining Performance of 11\n  State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests",
            "updated": "2023-10-31T09:55:07Z",
            "published": "2023-10-31T09:55:07Z",
            "summary": "To what degree should we ascribe cognitive capacities to Large Language\nModels (LLMs), such as the ability to reason about intentions and beliefs known\nas Theory of Mind (ToM)? Here we add to this emerging debate by (i) testing 11\nbase- and instruction-tuned LLMs on capabilities relevant to ToM beyond the\ndominant false-belief paradigm, including non-literal language usage and\nrecursive intentionality; (ii) using newly rewritten versions of standardized\ntests to gauge LLMs' robustness; (iii) prompting and scoring for open besides\nclosed questions; and (iv) benchmarking LLM performance against that of\nchildren aged 7-10 on the same tasks. We find that instruction-tuned LLMs from\nthe GPT family outperform other models, and often also children. Base-LLMs are\nmostly unable to solve ToM tasks, even with specialized prompting. We suggest\nthat the interlinked evolution and development of language and ToM may help\nexplain what instruction-tuning adds: rewarding cooperative communication that\ntakes into account interlocutor and context. We conclude by arguing for a\nnuanced perspective on ToM in LLMs.",
            "author": [
                "Max J. van Duijn",
                "Bram M. A. van Dijk",
                "Tom Kouwenhoven",
                "Werner de Valk",
                "Marco R. Spruit",
                "Peter van der Putten"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20320v1",
                "http://arxiv.org/pdf/2310.20320v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20319v1",
            "title": "GACE: Geometry Aware Confidence Enhancement for Black-Box 3D Object\n  Detectors on LiDAR-Data",
            "updated": "2023-10-31T09:55:04Z",
            "published": "2023-10-31T09:55:04Z",
            "summary": "Widely-used LiDAR-based 3D object detectors often neglect fundamental\ngeometric information readily available from the object proposals in their\nconfidence estimation. This is mostly due to architectural design choices,\nwhich were often adopted from the 2D image domain, where geometric context is\nrarely available. In 3D, however, considering the object properties and its\nsurroundings in a holistic way is important to distinguish between true and\nfalse positive detections, e.g. occluded pedestrians in a group. To address\nthis, we present GACE, an intuitive and highly efficient method to improve the\nconfidence estimation of a given black-box 3D object detector. We aggregate\ngeometric cues of detections and their spatial relationships, which enables us\nto properly assess their plausibility and consequently, improve the confidence\nestimation. This leads to consistent performance gains over a variety of\nstate-of-the-art detectors. Across all evaluated detectors, GACE proves to be\nespecially beneficial for the vulnerable road user classes, i.e. pedestrians\nand cyclists.",
            "author": [
                "David Schinagl",
                "Georg Krispel",
                "Christian Fruhwirth-Reisinger",
                "Horst Possegger",
                "Horst Bischof"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20319v1",
                "http://arxiv.org/pdf/2310.20319v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20316v1",
            "title": "HWD: A Novel Evaluation Score for Styled Handwritten Text Generation",
            "updated": "2023-10-31T09:44:27Z",
            "published": "2023-10-31T09:44:27Z",
            "summary": "Styled Handwritten Text Generation (Styled HTG) is an important task in\ndocument analysis, aiming to generate text images with the handwriting of given\nreference images. In recent years, there has been significant progress in the\ndevelopment of deep learning models for tackling this task. Being able to\nmeasure the performance of HTG models via a meaningful and representative\ncriterion is key for fostering the development of this research topic. However,\ndespite the current adoption of scores for natural image generation evaluation,\nassessing the quality of generated handwriting remains challenging. In light of\nthis, we devise the Handwriting Distance (HWD), tailored for HTG evaluation. In\nparticular, it works in the feature space of a network specifically trained to\nextract handwriting style features from the variable-lenght input images and\nexploits a perceptual distance to compare the subtle geometric features of\nhandwriting. Through extensive experimental evaluation on different word-level\nand line-level datasets of handwritten text images, we demonstrate the\nsuitability of the proposed HWD as a score for Styled HTG. The pretrained model\nused as backbone will be released to ease the adoption of the score, aiming to\nprovide a valuable tool for evaluating HTG models and thus contributing to\nadvancing this important research area.",
            "author": [
                "Vittorio Pippi",
                "Fabio Quattrini",
                "Silvia Cascianelli",
                "Rita Cucchiara"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20316v1",
                "http://arxiv.org/pdf/2310.20316v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20308v1",
            "title": "A physics-informed GAN Framework based on Model-free Data-Driven\n  Computational Mechanics",
            "updated": "2023-10-31T09:33:03Z",
            "published": "2023-10-31T09:33:03Z",
            "summary": "Model-free data-driven computational mechanics, first proposed by\nKirchdoerfer and Ortiz, replace phenomenological models with numerical\nsimulations based on sample data sets in strain-stress space. In this study, we\nintegrate this paradigm within physics-informed generative adversarial networks\n(GANs). We enhance the conventional physics-informed neural network framework\nby implementing the principles of data-driven computational mechanics into\nGANs. Specifically, the generator is informed by physical constraints, while\nthe discriminator utilizes the closest strain-stress data to discern the\nauthenticity of the generator's output. This combined approach presents a new\nformalism to harness data-driven mechanics and deep learning to simulate and\npredict mechanical behaviors.",
            "author": [
                "Kerem Ciftci",
                "Klaus Hackl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20308v1",
                "http://arxiv.org/pdf/2310.20308v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20307v1",
            "title": "Causal Interpretation of Self-Attention in Pre-Trained Transformers",
            "updated": "2023-10-31T09:27:12Z",
            "published": "2023-10-31T09:27:12Z",
            "summary": "We propose a causal interpretation of self-attention in the Transformer\nneural network architecture. We interpret self-attention as a mechanism that\nestimates a structural equation model for a given input sequence of symbols\n(tokens). The structural equation model can be interpreted, in turn, as a\ncausal structure over the input symbols under the specific context of the input\nsequence. Importantly, this interpretation remains valid in the presence of\nlatent confounders. Following this interpretation, we estimate conditional\nindependence relations between input symbols by calculating partial\ncorrelations between their corresponding representations in the deepest\nattention layer. This enables learning the causal structure over an input\nsequence using existing constraint-based algorithms. In this sense, existing\npre-trained Transformers can be utilized for zero-shot causal-discovery. We\ndemonstrate this method by providing causal explanations for the outcomes of\nTransformers in two tasks: sentiment classification (NLP) and recommendation.",
            "author": [
                "Raanan Y. Rohekar",
                "Yaniv Gurwicz",
                "Shami Nisimov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20307v1",
                "http://arxiv.org/pdf/2310.20307v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20301v1",
            "title": "Revolutionizing Global Food Security: Empowering Resilience through\n  Integrated AI Foundation Models and Data-Driven Solutions",
            "updated": "2023-10-31T09:15:35Z",
            "published": "2023-10-31T09:15:35Z",
            "summary": "Food security, a global concern, necessitates precise and diverse data-driven\nsolutions to address its multifaceted challenges. This paper explores the\nintegration of AI foundation models across various food security applications,\nleveraging distinct data types, to overcome the limitations of current deep and\nmachine learning methods. Specifically, we investigate their utilization in\ncrop type mapping, cropland mapping, field delineation and crop yield\nprediction. By capitalizing on multispectral imagery, meteorological data, soil\nproperties, historical records, and high-resolution satellite imagery, AI\nfoundation models offer a versatile approach. The study demonstrates that AI\nfoundation models enhance food security initiatives by providing accurate\npredictions, improving resource allocation, and supporting informed\ndecision-making. These models serve as a transformative force in addressing\nglobal food security limitations, marking a significant leap toward a\nsustainable and secure food future.",
            "author": [
                "Mohamed R. Shoaib",
                "Heba M. Emara",
                "Jun Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20301v1",
                "http://arxiv.org/pdf/2310.20301v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20299v1",
            "title": "Verification of Neural Networks Local Differential Classification\n  Privacy",
            "updated": "2023-10-31T09:11:12Z",
            "published": "2023-10-31T09:11:12Z",
            "summary": "Neural networks are susceptible to privacy attacks. To date, no verifier can\nreason about the privacy of individuals participating in the training set. We\npropose a new privacy property, called local differential classification\nprivacy (LDCP), extending local robustness to a differential privacy setting\nsuitable for black-box classifiers. Given a neighborhood of inputs, a\nclassifier is LDCP if it classifies all inputs the same regardless of whether\nit is trained with the full dataset or whether any single entry is omitted. A\nnaive algorithm is highly impractical because it involves training a very large\nnumber of networks and verifying local robustness of the given neighborhood\nseparately for every network. We propose Sphynx, an algorithm that computes an\nabstraction of all networks, with a high probability, from a small set of\nnetworks, and verifies LDCP directly on the abstract network. The challenge is\ntwofold: network parameters do not adhere to a known distribution probability,\nmaking it difficult to predict an abstraction, and predicting too large\nabstraction harms the verification. Our key idea is to transform the parameters\ninto a distribution given by KDE, allowing to keep the over-approximation error\nsmall. To verify LDCP, we extend a MILP verifier to analyze an abstract\nnetwork. Experimental results show that by training only 7% of the networks,\nSphynx predicts an abstract network obtaining 93% verification accuracy and\nreducing the analysis time by $1.7\\cdot10^4$x.",
            "author": [
                "Roie Reshef",
                "Anan Kabaha",
                "Olga Seleznova",
                "Dana Drachsler-Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20299v1",
                "http://arxiv.org/pdf/2310.20299v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20293v1",
            "title": "Annotator: A Generic Active Learning Baseline for LiDAR Semantic\n  Segmentation",
            "updated": "2023-10-31T09:04:39Z",
            "published": "2023-10-31T09:04:39Z",
            "summary": "Active learning, a label-efficient paradigm, empowers models to interactively\nquery an oracle for labeling new data. In the realm of LiDAR semantic\nsegmentation, the challenges stem from the sheer volume of point clouds,\nrendering annotation labor-intensive and cost-prohibitive. This paper presents\nAnnotator, a general and efficient active learning baseline, in which a\nvoxel-centric online selection strategy is tailored to efficiently probe and\nannotate the salient and exemplar voxel girds within each LiDAR scan, even\nunder distribution shift. Concretely, we first execute an in-depth analysis of\nseveral common selection strategies such as Random, Entropy, Margin, and then\ndevelop voxel confusion degree (VCD) to exploit the local topology relations\nand structures of point clouds. Annotator excels in diverse settings, with a\nparticular focus on active learning (AL), active source-free domain adaptation\n(ASFDA), and active domain adaptation (ADA). It consistently delivers\nexceptional performance across LiDAR semantic segmentation benchmarks, spanning\nboth simulation-to-real and real-to-real scenarios. Surprisingly, Annotator\nexhibits remarkable efficiency, requiring significantly fewer annotations,\ne.g., just labeling five voxels per scan in the SynLiDAR-to-SemanticKITTI task.\nThis results in impressive performance, achieving 87.8% fully-supervised\nperformance under AL, 88.5% under ASFDA, and 94.4% under ADA. We envision that\nAnnotator will offer a simple, general, and efficient solution for\nlabel-efficient 3D applications. Project page:\nhttps://binhuixie.github.io/annotator-web",
            "author": [
                "Binhui Xie",
                "Shuang Li",
                "Qingju Guo",
                "Chi Harold Liu",
                "Xinjing Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20293v1",
                "http://arxiv.org/pdf/2310.20293v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20292v1",
            "title": "IARS SegNet: Interpretable Attention Residual Skip connection SegNet for\n  melanoma segmentation",
            "updated": "2023-10-31T09:04:09Z",
            "published": "2023-10-31T09:04:09Z",
            "summary": "Skin lesion segmentation plays a crucial role in the computer-aided diagnosis\nof melanoma. Deep Learning models have shown promise in accurately segmenting\nskin lesions, but their widespread adoption in real-life clinical settings is\nhindered by their inherent black-box nature. In domains as critical as\nhealthcare, interpretability is not merely a feature but a fundamental\nrequirement for model adoption. This paper proposes IARS SegNet an advanced\nsegmentation framework built upon the SegNet baseline model. Our approach\nincorporates three critical components: Skip connections, residual\nconvolutions, and a global attention mechanism onto the baseline Segnet\narchitecture. These elements play a pivotal role in accentuating the\nsignificance of clinically relevant regions, particularly the contours of skin\nlesions. The inclusion of skip connections enhances the model's capacity to\nlearn intricate contour details, while the use of residual convolutions allows\nfor the construction of a deeper model while preserving essential image\nfeatures. The global attention mechanism further contributes by extracting\nrefined feature maps from each convolutional and deconvolutional block, thereby\nelevating the model's interpretability. This enhancement highlights critical\nregions, fosters better understanding, and leads to more accurate skin lesion\nsegmentation for melanoma diagnosis.",
            "author": [
                "Shankara Narayanan V",
                "Sikha OK",
                "Raul Benitez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20292v1",
                "http://arxiv.org/pdf/2310.20292v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20287v1",
            "title": "Sample-Efficient and Safe Deep Reinforcement Learning via Reset Deep\n  Ensemble Agents",
            "updated": "2023-10-31T08:59:39Z",
            "published": "2023-10-31T08:59:39Z",
            "summary": "Deep reinforcement learning (RL) has achieved remarkable success in solving\ncomplex tasks through its integration with deep neural networks (DNNs) as\nfunction approximators. However, the reliance on DNNs has introduced a new\nchallenge called primacy bias, whereby these function approximators tend to\nprioritize early experiences, leading to overfitting. To mitigate this primacy\nbias, a reset method has been proposed, which performs periodic resets of a\nportion or the entirety of a deep RL agent while preserving the replay buffer.\nHowever, the use of the reset method can result in performance collapses after\nexecuting the reset, which can be detrimental from the perspective of safe RL\nand regret minimization. In this paper, we propose a new reset-based method\nthat leverages deep ensemble learning to address the limitations of the vanilla\nreset method and enhance sample efficiency. The proposed method is evaluated\nthrough various experiments including those in the domain of safe RL. Numerical\nresults show its effectiveness in high sample efficiency and safety\nconsiderations.",
            "author": [
                "Woojun Kim",
                "Yongjae Shin",
                "Jongeui Park",
                "Youngchul Sung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20287v1",
                "http://arxiv.org/pdf/2310.20287v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20285v1",
            "title": "Accelerating Generalized Linear Models by Trading off Computation for\n  Uncertainty",
            "updated": "2023-10-31T08:58:16Z",
            "published": "2023-10-31T08:58:16Z",
            "summary": "Bayesian Generalized Linear Models (GLMs) define a flexible probabilistic\nframework to model categorical, ordinal and continuous data, and are widely\nused in practice. However, exact inference in GLMs is prohibitively expensive\nfor large datasets, thus requiring approximations in practice. The resulting\napproximation error adversely impacts the reliability of the model and is not\naccounted for in the uncertainty of the prediction. In this work, we introduce\na family of iterative methods that explicitly model this error. They are\nuniquely suited to parallel modern computing hardware, efficiently recycle\ncomputations, and compress information to reduce both the time and memory\nrequirements for GLMs. As we demonstrate on a realistically large\nclassification problem, our method significantly accelerates training by\nexplicitly trading off reduced computation for increased uncertainty.",
            "author": [
                "Lukas Tatzel",
                "Jonathan Wenger",
                "Frank Schneider",
                "Philipp Hennig"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20285v1",
                "http://arxiv.org/pdf/2310.20285v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20280v2",
            "title": "AutoMixer for Improved Multivariate Time-Series Forecasting on Business\n  and IT Observability Data",
            "updated": "2023-11-02T09:17:55Z",
            "published": "2023-10-31T08:50:52Z",
            "summary": "The efficiency of business processes relies on business key performance\nindicators (Biz-KPIs), that can be negatively impacted by IT failures. Business\nand IT Observability (BizITObs) data fuses both Biz-KPIs and IT event channels\ntogether as multivariate time series data. Forecasting Biz-KPIs in advance can\nenhance efficiency and revenue through proactive corrective measures. However,\nBizITObs data generally exhibit both useful and noisy inter-channel\ninteractions between Biz-KPIs and IT events that need to be effectively\ndecoupled. This leads to suboptimal forecasting performance when existing\nmultivariate forecasting models are employed. To address this, we introduce\nAutoMixer, a time-series Foundation Model (FM) approach, grounded on the novel\ntechnique of channel-compressed pretrain and finetune workflows. AutoMixer\nleverages an AutoEncoder for channel-compressed pretraining and integrates it\nwith the advanced TSMixer model for multivariate time series forecasting. This\nfusion greatly enhances the potency of TSMixer for accurate forecasts and also\ngeneralizes well across several downstream tasks. Through detailed experiments\nand dashboard analytics, we show AutoMixer's capability to consistently improve\nthe Biz-KPI's forecasting accuracy (by 11-15\\%) which directly translates to\nactionable business insights.",
            "author": [
                "Santosh Palaskar",
                "Vijay Ekambaram",
                "Arindam Jati",
                "Neelamadhav Gantayat",
                "Avirup Saha",
                "Seema Nagar",
                "Nam H. Nguyen",
                "Pankaj Dayama",
                "Renuka Sindhgatta",
                "Prateeti Mohapatra",
                "Harshit Kumar",
                "Jayant Kalagnanam",
                "Nandyala Hemachandra",
                "Narayan Rangaraj"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20280v2",
                "http://arxiv.org/pdf/2310.20280v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20279v1",
            "title": "Machine learning refinement of in situ images acquired by low electron\n  dose LC-TEM",
            "updated": "2023-10-31T08:48:59Z",
            "published": "2023-10-31T08:48:59Z",
            "summary": "We study a machine learning (ML) technique for refining images acquired\nduring in situ observation using liquid-cell transmission electron microscopy\n(LC-TEM). Our model is constructed using a U-Net architecture and a ResNet\nencoder. For training our ML model, we prepared an original image dataset that\ncontained pairs of images of samples acquired with and without a solution\npresent. The former images were used as noisy images and the latter images were\nused as corresponding ground truth images. The number of pairs of image sets\nwas $1,204$ and the image sets included images acquired at several different\nmagnifications and electron doses. The trained model converted a noisy image\ninto a clear image. The time necessary for the conversion was on the order of\n10ms, and we applied the model to in situ observations using the software Gatan\nDigitalMicrograph (DM). Even if a nanoparticle was not visible in a view window\nin the DM software because of the low electron dose, it was visible in a\nsuccessive refined image generated by our ML model.",
            "author": [
                "Hiroyasu Katsuno",
                "Yuki Kimura",
                "Tomoya Yamazaki",
                "Ichigaku Takigawa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20279v1",
                "http://arxiv.org/pdf/2310.20279v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20275v1",
            "title": "Age Optimum Sampling in Non-Stationary Environment",
            "updated": "2023-10-31T08:43:33Z",
            "published": "2023-10-31T08:43:33Z",
            "summary": "In this work, we consider a status update system with a sensor and a\nreceiver. The status update information is sampled by the sensor and then\nforwarded to the receiver through a channel with non-stationary delay\ndistribution. The data freshness at the receiver is quantified by the\nAge-of-Information (AoI). The goal is to design an online sampling strategy\nthat can minimize the average AoI when the non-stationary delay distribution is\nunknown. Assuming that channel delay distribution may change over time, to\nminimize the average AoI, we propose a joint stochastic approximation and\nnon-parametric change point detection algorithm that can: (1) learn the optimum\nupdate threshold when the delay distribution remains static; (2) detect the\nchange in transmission delay distribution quickly and then restart the learning\nprocess. Simulation results show that the proposed algorithm can quickly detect\nthe delay changes, and the average AoI obtained by the proposed policy\nconverges to the minimum AoI.",
            "author": [
                "Jinheng Zhang",
                "Haoyue Tang",
                "Jintao Wang",
                "Sastry Kompella",
                "Leandros Tassiulas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20275v1",
                "http://arxiv.org/pdf/2310.20275v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20274v1",
            "title": "Extracting Entities of Interest from Comparative Product Reviews",
            "updated": "2023-10-31T08:43:11Z",
            "published": "2023-10-31T08:43:11Z",
            "summary": "This paper presents a deep learning based approach to extract product\ncomparison information out of user reviews on various e-commerce websites. Any\ncomparative product review has three major entities of information: the names\nof the products being compared, the user opinion (predicate) and the feature or\naspect under comparison. All these informing entities are dependent on each\nother and bound by the rules of the language, in the review. We observe that\ntheir inter-dependencies can be captured well using LSTMs. We evaluate our\nsystem on existing manually labeled datasets and observe out-performance over\nthe existing Semantic Role Labeling (SRL) framework popular for this task.",
            "author": [
                "Jatin Arora",
                "Sumit Agrawal",
                "Pawan Goyal",
                "Sayan Pathak"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3132847.3133141",
                "http://arxiv.org/abs/2310.20274v1",
                "http://arxiv.org/pdf/2310.20274v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL",
                "cs.LG",
                "I.2.7; H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20271v2",
            "title": "From Denoising Training to Test-Time Adaptation: Enhancing Domain\n  Generalization for Medical Image Segmentation",
            "updated": "2023-11-03T03:48:43Z",
            "published": "2023-10-31T08:39:15Z",
            "summary": "In medical image segmentation, domain generalization poses a significant\nchallenge due to domain shifts caused by variations in data acquisition devices\nand other factors. These shifts are particularly pronounced in the most common\nscenario, which involves only single-source domain data due to privacy\nconcerns. To address this, we draw inspiration from the self-supervised\nlearning paradigm that effectively discourages overfitting to the source\ndomain. We propose the Denoising Y-Net (DeY-Net), a novel approach\nincorporating an auxiliary denoising decoder into the basic U-Net architecture.\nThe auxiliary decoder aims to perform denoising training, augmenting the\ndomain-invariant representation that facilitates domain generalization.\nFurthermore, this paradigm provides the potential to utilize unlabeled data.\nBuilding upon denoising training, we propose Denoising Test Time Adaptation\n(DeTTA) that further: (i) adapts the model to the target domain in a\nsample-wise manner, and (ii) adapts to the noise-corrupted input. Extensive\nexperiments conducted on widely-adopted liver segmentation benchmarks\ndemonstrate significant domain generalization improvements over our baseline\nand state-of-the-art results compared to other methods. Code is available at\nhttps://github.com/WenRuxue/DeTTA.",
            "author": [
                "Ruxue Wen",
                "Hangjie Yuan",
                "Dong Ni",
                "Wenbo Xiao",
                "Yaoyao Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20271v2",
                "http://arxiv.org/pdf/2310.20271v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20268v1",
            "title": "Constructing Sample-to-Class Graph for Few-Shot Class-Incremental\n  Learning",
            "updated": "2023-10-31T08:38:14Z",
            "published": "2023-10-31T08:38:14Z",
            "summary": "Few-shot class-incremental learning (FSCIL) aims to build machine learning\nmodel that can continually learn new concepts from a few data samples, without\nforgetting knowledge of old classes.\n  The challenges of FSCIL lies in the limited data of new classes, which not\nonly lead to significant overfitting issues but also exacerbates the notorious\ncatastrophic forgetting problems. As proved in early studies, building sample\nrelationships is beneficial for learning from few-shot samples. In this paper,\nwe promote the idea to the incremental scenario, and propose a Sample-to-Class\n(S2C) graph learning method for FSCIL.\n  Specifically, we propose a Sample-level Graph Network (SGN) that focuses on\nanalyzing sample relationships within a single session. This network helps\naggregate similar samples, ultimately leading to the extraction of more refined\nclass-level features.\n  Then, we present a Class-level Graph Network (CGN) that establishes\nconnections across class-level features of both new and old classes. This\nnetwork plays a crucial role in linking the knowledge between different\nsessions and helps improve overall learning in the FSCIL scenario. Moreover, we\ndesign a multi-stage strategy for training S2C model, which mitigates the\ntraining challenges posed by limited data in the incremental process.\n  The multi-stage training strategy is designed to build S2C graph from base to\nfew-shot stages, and improve the capacity via an extra pseudo-incremental\nstage. Experiments on three popular benchmark datasets show that our method\nclearly outperforms the baselines and sets new state-of-the-art results in\nFSCIL.",
            "author": [
                "Fuyuan Hu",
                "Jian Zhang",
                "Fan Lyu",
                "Linyan Li",
                "Fenglei Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20268v1",
                "http://arxiv.org/pdf/2310.20268v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20266v1",
            "title": "Beyond Average Return in Markov Decision Processes",
            "updated": "2023-10-31T08:36:41Z",
            "published": "2023-10-31T08:36:41Z",
            "summary": "What are the functionals of the reward that can be computed and optimized\nexactly in Markov Decision Processes? In the finite-horizon, undiscounted\nsetting, Dynamic Programming (DP) can only handle these operations efficiently\nfor certain classes of statistics. We summarize the characterization of these\nclasses for policy evaluation, and give a new answer for the planning problem.\nInterestingly, we prove that only generalized means can be optimized exactly,\neven in the more general framework of Distributional Reinforcement Learning\n(DistRL).DistRL permits, however, to evaluate other functionals approximately.\nWe provide error bounds on the resulting estimators, and discuss the potential\nof this approach as well as its limitations.These results contribute to\nadvancing the theory of Markov Decision Processes by examining overall\ncharacteristics of the return, and particularly risk-conscious strategies.",
            "author": [
                "Alexandre Marthe",
                "Aur\u00e9lien Garivier",
                "Claire Vernade"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20266v1",
                "http://arxiv.org/pdf/2310.20266v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "math.OC",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20265v1",
            "title": "Low-Dose CT Image Enhancement Using Deep Learning",
            "updated": "2023-10-31T08:34:33Z",
            "published": "2023-10-31T08:34:33Z",
            "summary": "The application of ionizing radiation for diagnostic imaging is common around\nthe globe. However, the process of imaging, itself, remains to be a relatively\nhazardous operation. Therefore, it is preferable to use as low a dose of\nionizing radiation as possible, particularly in computed tomography (CT)\nimaging systems, where multiple x-ray operations are performed for the\nreconstruction of slices of body tissues. A popular method for radiation dose\nreduction in CT imaging is known as the quarter-dose technique, which reduces\nthe x-ray dose but can cause a loss of image sharpness. Since CT image\nreconstruction from directional x-rays is a nonlinear process, it is\nanalytically difficult to correct the effect of dose reduction on image\nquality. Recent and popular deep-learning approaches provide an intriguing\npossibility of image enhancement for low-dose artifacts. Some recent works\npropose combinations of multiple deep-learning and classical methods for this\npurpose, which over-complicate the process. However, it is observed here that\nthe straight utilization of the well-known U-NET provides very successful\nresults for the correction of low-dose artifacts. Blind tests with actual\nradiologists reveal that the U-NET enhanced quarter-dose CT images not only\nprovide an immense visual improvement over the low-dose versions, but also\nbecome diagnostically preferable images, even when compared to their full-dose\nCT versions.",
            "author": [
                "A. Demir",
                "M. M. A. Shames",
                "O. N. Gerek",
                "S. Ergin",
                "M. Fidan",
                "M. Koc",
                "M. B. Gulmezoglu",
                "A. Barkana",
                "C. Calisir"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20265v1",
                "http://arxiv.org/pdf/2310.20265v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20260v1",
            "title": "Learning to Play Chess from Textbooks (LEAP): a Corpus for Evaluating\n  Chess Moves based on Sentiment Analysis",
            "updated": "2023-10-31T08:26:02Z",
            "published": "2023-10-31T08:26:02Z",
            "summary": "Learning chess strategies has been investigated widely, with most studies\nfocussing on learning from previous games using search algorithms. Chess\ntextbooks encapsulate grandmaster knowledge, explain playing strategies and\nrequire a smaller search space compared to traditional chess agents. This paper\nexamines chess textbooks as a new knowledge source for enabling machines to\nlearn how to play chess -- a resource that has not been explored previously. We\ndeveloped the LEAP corpus, a first and new heterogeneous dataset with\nstructured (chess move notations and board states) and unstructured data\n(textual descriptions) collected from a chess textbook containing 1164\nsentences discussing strategic moves from 91 games. We firstly labelled the\nsentences based on their relevance, i.e., whether they are discussing a move.\nEach relevant sentence was then labelled according to its sentiment towards the\ndescribed move. We performed empirical experiments that assess the performance\nof various transformer-based baseline models for sentiment analysis. Our\nresults demonstrate the feasibility of employing transformer-based sentiment\nanalysis models for evaluating chess moves, with the best performing model\nobtaining a weighted micro F_1 score of 68%. Finally, we synthesised the LEAP\ncorpus to create a larger dataset, which can be used as a solution to the\nlimited textual resource in the chess domain.",
            "author": [
                "Haifa Alrdahi",
                "Riza Batista-Navarro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20260v1",
                "http://arxiv.org/pdf/2310.20260v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20258v3",
            "title": "Advancing Bayesian Optimization via Learning Correlated Latent Space",
            "updated": "2023-11-20T03:43:31Z",
            "published": "2023-10-31T08:24:41Z",
            "summary": "Bayesian optimization is a powerful method for optimizing black-box functions\nwith limited function evaluations. Recent works have shown that optimization in\na latent space through deep generative models such as variational autoencoders\nleads to effective and efficient Bayesian optimization for structured or\ndiscrete data. However, as the optimization does not take place in the input\nspace, it leads to an inherent gap that results in potentially suboptimal\nsolutions. To alleviate the discrepancy, we propose Correlated latent space\nBayesian Optimization (CoBO), which focuses on learning correlated latent\nspaces characterized by a strong correlation between the distances in the\nlatent space and the distances within the objective function. Specifically, our\nmethod introduces Lipschitz regularization, loss weighting, and trust region\nrecoordination to minimize the inherent gap around the promising areas. We\ndemonstrate the effectiveness of our approach on several optimization tasks in\ndiscrete data, such as molecule design and arithmetic expression fitting, and\nachieve high performance within a small budget.",
            "author": [
                "Seunghun Lee",
                "Jaewon Chu",
                "Sihyeon Kim",
                "Juyeon Ko",
                "Hyunwoo J. Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20258v3",
                "http://arxiv.org/pdf/2310.20258v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20254v1",
            "title": "Artificial Intelligence for reverse engineering: application to\n  detergents using Raman spectroscopy",
            "updated": "2023-10-31T08:16:22Z",
            "published": "2023-10-31T08:16:22Z",
            "summary": "The reverse engineering of a complex mixture, regardless of its nature, has\nbecome significant today. Being able to quickly assess the potential toxicity\nof new commercial products in relation to the environment presents a genuine\nanalytical challenge. The development of digital tools (databases,\nchemometrics, machine learning, etc.) and analytical techniques (Raman\nspectroscopy, NIR spectroscopy, mass spectrometry, etc.) will allow for the\nidentification of potential toxic molecules. In this article, we use the\nexample of detergent products, whose composition can prove dangerous to humans\nor the environment, necessitating precise identification and quantification for\nquality control and regulation purposes. The combination of various digital\ntools (spectral database, mixture database, experimental design, Chemometrics /\nMachine Learning algorithm{\\ldots}) together with different sample preparation\nmethods (raw sample, or several concentrated / diluted samples) Raman\nspectroscopy, has enabled the identification of the mixture's constituents and\nan estimation of its composition. Implementing such strategies across different\nanalytical tools can result in time savings for pollutant identification and\ncontamination assessment in various matrices. This strategy is also applicable\nin the industrial sector for product or raw material control, as well as for\nquality control purposes.",
            "author": [
                "Pedro Marote",
                "Marie Martin",
                "Anne Bonhomme",
                "Pierre Lant\u00e9ri",
                "Yohann Cl\u00e9ment"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20254v1",
                "http://arxiv.org/pdf/2310.20254v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20252v1",
            "title": "Dynamic heterogeneity at the experimental glass transition predicted by\n  transferable machine learning",
            "updated": "2023-10-31T08:14:02Z",
            "published": "2023-10-31T08:14:02Z",
            "summary": "We develop a transferable machine learning model which predicts structural\nrelaxation from amorphous supercooled liquid structures. The trained networks\nare able to predict dynamic heterogeneity across a broad range of temperatures\nand time scales with excellent accuracy and transferability. We use the network\ntransferability to predict dynamic heterogeneity down to the experimental glass\ntransition temperature, $T_g$, where structural relaxation cannot be analyzed\nusing molecular dynamics simulations. The results indicate that the strength,\nthe geometry and the characteristic length scale of the dynamic heterogeneity\nevolve much more slowly near $T_g$ compared to their evolution at higher\ntemperatures. Our results show that machine learning techniques can provide\nphysical insights on the nature of the glass transition that cannot be gained\nusing conventional simulation techniques.",
            "author": [
                "Gerhard Jung",
                "Giulio Biroli",
                "Ludovic Berthier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20252v1",
                "http://arxiv.org/pdf/2310.20252v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20250v1",
            "title": "Diversified Node Sampling based Hierarchical Transformer Pooling for\n  Graph Representation Learning",
            "updated": "2023-10-31T08:13:21Z",
            "published": "2023-10-31T08:13:21Z",
            "summary": "Graph pooling methods have been widely used on downsampling graphs, achieving\nimpressive results on multiple graph-level tasks like graph classification and\ngraph generation. An important line called node dropping pooling aims at\nexploiting learnable scoring functions to drop nodes with comparatively lower\nsignificance scores. However, existing node dropping methods suffer from two\nlimitations: (1) for each pooled node, these models struggle to capture\nlong-range dependencies since they mainly take GNNs as the backbones; (2)\npooling only the highest-scoring nodes tends to preserve similar nodes, thus\ndiscarding the affluent information of low-scoring nodes. To address these\nissues, we propose a Graph Transformer Pooling method termed GTPool, which\nintroduces Transformer to node dropping pooling to efficiently capture\nlong-range pairwise interactions and meanwhile sample nodes diversely.\nSpecifically, we design a scoring module based on the self-attention mechanism\nthat takes both global context and local context into consideration, measuring\nthe importance of nodes more comprehensively. GTPool further utilizes a\ndiversified sampling method named Roulette Wheel Sampling (RWS) that is able to\nflexibly preserve nodes across different scoring intervals instead of only\nhigher scoring nodes. In this way, GTPool could effectively obtain long-range\ninformation and select more representative nodes. Extensive experiments on 11\nbenchmark datasets demonstrate the superiority of GTPool over existing popular\ngraph pooling methods.",
            "author": [
                "Gaichao Li",
                "Jinsong Chen",
                "John E. Hopcroft",
                "Kun He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20250v1",
                "http://arxiv.org/pdf/2310.20250v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20249v1",
            "title": "Pose-to-Motion: Cross-Domain Motion Retargeting with Pose Prior",
            "updated": "2023-10-31T08:13:00Z",
            "published": "2023-10-31T08:13:00Z",
            "summary": "Creating believable motions for various characters has long been a goal in\ncomputer graphics. Current learning-based motion synthesis methods depend on\nextensive motion datasets, which are often challenging, if not impossible, to\nobtain. On the other hand, pose data is more accessible, since static posed\ncharacters are easier to create and can even be extracted from images using\nrecent advancements in computer vision. In this paper, we utilize this\nalternative data source and introduce a neural motion synthesis approach\nthrough retargeting. Our method generates plausible motions for characters that\nhave only pose data by transferring motion from an existing motion capture\ndataset of another character, which can have drastically different skeletons.\nOur experiments show that our method effectively combines the motion features\nof the source character with the pose features of the target character, and\nperforms robustly with small or noisy pose data sets, ranging from a few\nartist-created poses to noisy poses estimated directly from images.\nAdditionally, a conducted user study indicated that a majority of participants\nfound our retargeted motion to be more enjoyable to watch, more lifelike in\nappearance, and exhibiting fewer artifacts. Project page:\nhttps://cyanzhao42.github.io/pose2motion",
            "author": [
                "Qingqing Zhao",
                "Peizhuo Li",
                "Wang Yifan",
                "Olga Sorkine-Hornung",
                "Gordon Wetzstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20249v1",
                "http://arxiv.org/pdf/2310.20249v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20246v4",
            "title": "Breaking Language Barriers in Multilingual Mathematical Reasoning:\n  Insights and Observations",
            "updated": "2023-11-28T05:25:14Z",
            "published": "2023-10-31T08:09:20Z",
            "summary": "Existing research predominantly focuses on developing powerful language\nlearning models (LLMs) for mathematical reasoning within monolingual languages,\nwith few explorations in preserving efficacy in a multilingual context. To\nbridge this gap, this paper pioneers exploring and training powerful\nMultilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we\nconstruct the first multilingual math reasoning instruction dataset,\nMGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue\nof training data scarcity in xMR tasks. Based on the collected dataset, we\npropose different training strategies to build powerful xMR LLMs, named\nMathOctopus, notably outperform conventional open-source LLMs and exhibit\nsuperiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B\nreaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond\nremarkable results, we unearth several pivotal observations and insights from\nextensive experiments: (1) When extending the rejection sampling strategy to\nthe multilingual context, it proves effective for model performances, albeit\nlimited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT)\nacross multiple languages not only significantly enhances model performance\nmultilingually but also elevates their monolingual performance. This indicates\nthat crafting multilingual corpora can be regarded as a vital strategy for\nenhancing model performance in a specific language, especially in mathematical\nreasoning tasks. For instance, MathOctopus-7B improves its counterparts that\ntrained on English from 42.2% to 50.8% on GSM8K testset.",
            "author": [
                "Nuo Chen",
                "Zinan Zheng",
                "Ning Wu",
                "Ming Gong",
                "Yangqiu Song",
                "Dongmei Zhang",
                "Jia Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20246v4",
                "http://arxiv.org/pdf/2310.20246v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20240v1",
            "title": "Breathing Life into Faces: Speech-driven 3D Facial Animation with\n  Natural Head Pose and Detailed Shape",
            "updated": "2023-10-31T07:47:19Z",
            "published": "2023-10-31T07:47:19Z",
            "summary": "The creation of lifelike speech-driven 3D facial animation requires a natural\nand precise synchronization between audio input and facial expressions.\nHowever, existing works still fail to render shapes with flexible head poses\nand natural facial details (e.g., wrinkles). This limitation is mainly due to\ntwo aspects: 1) Collecting training set with detailed 3D facial shapes is\nhighly expensive. This scarcity of detailed shape annotations hinders the\ntraining of models with expressive facial animation. 2) Compared to mouth\nmovement, the head pose is much less correlated to speech content.\nConsequently, concurrent modeling of both mouth movement and head pose yields\nthe lack of facial movement controllability. To address these challenges, we\nintroduce VividTalker, a new framework designed to facilitate speech-driven 3D\nfacial animation characterized by flexible head pose and natural facial\ndetails. Specifically, we explicitly disentangle facial animation into head\npose and mouth movement and encode them separately into discrete latent spaces.\nThen, these attributes are generated through an autoregressive process\nleveraging a window-based Transformer architecture. To augment the richness of\n3D facial animation, we construct a new 3D dataset with detailed shapes and\nlearn to synthesize facial details in line with speech content. Extensive\nquantitative and qualitative experiments demonstrate that VividTalker\noutperforms state-of-the-art methods, resulting in vivid and realistic\nspeech-driven 3D facial animation.",
            "author": [
                "Wei Zhao",
                "Yijun Wang",
                "Tianyu He",
                "Lianying Yin",
                "Jianxin Lin",
                "Xin Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20240v1",
                "http://arxiv.org/pdf/2310.20240v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20236v1",
            "title": "Dynamically Updating Event Representations for Temporal Relation\n  Classification with Multi-category Learning",
            "updated": "2023-10-31T07:41:24Z",
            "published": "2023-10-31T07:41:24Z",
            "summary": "Temporal relation classification is a pair-wise task for identifying the\nrelation of a temporal link (TLINK) between two mentions, i.e. event, time, and\ndocument creation time (DCT). It leads to two crucial limits: 1) Two TLINKs\ninvolving a common mention do not share information. 2) Existing models with\nindependent classifiers for each TLINK category (E2E, E2T, and E2D) hinder from\nusing the whole data. This paper presents an event centric model that allows to\nmanage dynamic event representations across multiple TLINKs. Our model deals\nwith three TLINK categories with multi-task learning to leverage the full size\nof data. The experimental results show that our proposal outperforms\nstate-of-the-art models and two transfer learning baselines on both the English\nand Japanese data.",
            "author": [
                "Fei Cheng",
                "Masayuki Asahara",
                "Ichiro Kobayashi",
                "Sadao Kurohashi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20236v1",
                "http://arxiv.org/pdf/2310.20236v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.04225v1",
            "title": "Fast, accurate, and interpretable decoding of electrocorticographic\n  signals using dynamic mode decomposition",
            "updated": "2023-10-31T07:13:43Z",
            "published": "2023-10-31T07:13:43Z",
            "summary": "Dynamic mode (DM) decomposition decomposes spatiotemporal signals into basic\noscillatory components (DMs). DMs can improve the accuracy of neural decoding\nwhen used with the nonlinear Grassmann kernel, compared to conventional power\nfeatures. However, such kernel-based machine learning algorithms have three\nlimitations: large computational time preventing real-time application,\nincompatibility with non-kernel algorithms, and low interpretability. Here, we\npropose a mapping function corresponding to the Grassmann kernel that\nexplicitly transforms DMs into spatial DM (sDM) features, which can be used in\nany machine learning algorithm. Using electrocorticographic signals recorded\nduring various movement and visual perception tasks, the sDM features were\nshown to improve the decoding accuracy and computational time compared to\nconventional methods. Furthermore, the components of the sDM features\ninformative for decoding showed similar characteristics to the high-$\\gamma$\npower of the signals, but with higher trial-to-trial reproducibility. The\nproposed sDM features enable fast, accurate, and interpretable neural decoding.",
            "author": [
                "Ryohei Fukuma",
                "Kei Majima",
                "Yoshinobu Kawahara",
                "Okito Yamashita",
                "Yoshiyuki Shiraishi",
                "Haruhiko Kishima",
                "Takufumi Yanagisawa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04225v1",
                "http://arxiv.org/pdf/2311.04225v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.10746v1",
            "title": "EIT: Earnest Insight Toolkit for Evaluating Students' Earnestness in\n  Interactive Lecture Participation Exercises",
            "updated": "2023-10-31T07:05:00Z",
            "published": "2023-10-31T07:05:00Z",
            "summary": "In today's rapidly evolving educational landscape, traditional modes of\npassive information delivery are giving way to transformative pedagogical\napproaches that prioritize active student engagement. Within the context of\nlarge-scale hybrid classrooms, the challenge lies in fostering meaningful and\nactive interaction between students and course content. This study delves into\nthe significance of measuring students' earnestness during interactive lecture\nparticipation exercises. By analyzing students' responses to interactive\nlecture poll questions, establishing a clear rubric for evaluating earnestness,\nand conducting a comprehensive assessment, we introduce EIT (Earnest Insight\nToolkit), a tool designed to assess students' engagement within interactive\nlecture participation exercises - particularly in the context of large-scale\nhybrid classrooms. Through the utilization of EIT, our objective is to equip\neducators with valuable means of identifying at-risk students for enhancing\nintervention and support strategies, as well as measuring students' levels of\nengagement with course content.",
            "author": [
                "Mihran Miroyan",
                "Shiny Weng",
                "Rahul Shah",
                "Lisa Yan",
                "Narges Norouzi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10746v1",
                "http://arxiv.org/pdf/2311.10746v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20224v1",
            "title": "Choose A Table: Tensor Dirichlet Process Multinomial Mixture Model with\n  Graphs for Passenger Trajectory Clustering",
            "updated": "2023-10-31T06:53:04Z",
            "published": "2023-10-31T06:53:04Z",
            "summary": "Passenger clustering based on trajectory records is essential for\ntransportation operators. However, existing methods cannot easily cluster the\npassengers due to the hierarchical structure of the passenger trip information,\nincluding multiple trips within each passenger and multi-dimensional\ninformation about each trip. Furthermore, existing approaches rely on an\naccurate specification of the clustering number to start. Finally, existing\nmethods do not consider spatial semantic graphs such as geographical proximity\nand functional similarity between the locations. In this paper, we propose a\nnovel tensor Dirichlet Process Multinomial Mixture model with graphs, which can\npreserve the hierarchical structure of the multi-dimensional trip information\nand cluster them in a unified one-step manner with the ability to determine the\nnumber of clusters automatically. The spatial graphs are utilized in community\ndetection to link the semantic neighbors. We further propose a tensor version\nof Collapsed Gibbs Sampling method with a minimum cluster size requirement. A\ncase study based on Hong Kong metro passenger data is conducted to demonstrate\nthe automatic process of cluster amount evolution and better cluster quality\nmeasured by within-cluster compactness and cross-cluster separateness. The code\nis available at https://github.com/bonaldli/TensorDPMM-G.",
            "author": [
                "Ziyue Li",
                "Hao Yan",
                "Chen Zhang",
                "Lijun Sun",
                "Wolfgang Ketter",
                "Fugee Tsung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20224v1",
                "http://arxiv.org/pdf/2310.20224v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20223v1",
            "title": "STDA-Meta: A Meta-Learning Framework for Few-Shot Traffic Prediction",
            "updated": "2023-10-31T06:52:56Z",
            "published": "2023-10-31T06:52:56Z",
            "summary": "As the development of cities, traffic congestion becomes an increasingly\npressing issue, and traffic prediction is a classic method to relieve that\nissue. Traffic prediction is one specific application of spatio-temporal\nprediction learning, like taxi scheduling, weather prediction, and ship\ntrajectory prediction. Against these problems, classical spatio-temporal\nprediction learning methods including deep learning, require large amounts of\ntraining data. In reality, some newly developed cities with insufficient\nsensors would not hold that assumption, and the data scarcity makes predictive\nperformance worse. In such situation, the learning method on insufficient data\nis known as few-shot learning (FSL), and the FSL of traffic prediction remains\nchallenges. On the one hand, graph structures' irregularity and dynamic nature\nof graphs cannot hold the performance of spatio-temporal learning method. On\nthe other hand, conventional domain adaptation methods cannot work well on\ninsufficient training data, when transferring knowledge from different domains\nto the intended target domain.To address these challenges, we propose a novel\nspatio-temporal domain adaptation (STDA) method that learns transferable\nspatio-temporal meta-knowledge from data-sufficient cities in an adversarial\nmanner. This learned meta-knowledge can improve the prediction performance of\ndata-scarce cities. Specifically, we train the STDA model using a\nModel-Agnostic Meta-Learning (MAML) based episode learning process, which is a\nmodel-agnostic meta-learning framework that enables the model to solve new\nlearning tasks using only a small number of training samples. We conduct\nnumerous experiments on four traffic prediction datasets, and our results show\nthat the prediction performance of our model has improved by 7\\% compared to\nbaseline models on the two metrics of MAE and RMSE.",
            "author": [
                "Maoxiang Sun",
                "Weilong Ding",
                "Tianpu Zhang",
                "Zijian Liu",
                "Mengda Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20223v1",
                "http://arxiv.org/pdf/2310.20223v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20221v1",
            "title": "Cayley Linear-Time Computable Groups",
            "updated": "2023-10-31T06:48:12Z",
            "published": "2023-10-31T06:48:12Z",
            "summary": "This paper looks at the class of groups admitting normal forms for which the\nright multiplication by a group element is computed in linear time on a\nmulti-tape Turing machine. We show that the groups $\\mathbb{Z}_2 \\wr\n\\mathbb{Z}^2$, $\\mathbb{Z}_2 \\wr \\mathbb{F}_2$ and Thompson's group $F$ have\nnormal forms for which the right multiplication by a group element is computed\nin linear time on a $2$-tape Turing machine. This refines the results\npreviously established by Elder and the authors that these groups are Cayley\npolynomial-time computable.",
            "author": [
                "Prohrak Kruengthomya",
                "Dmitry Berdinsky"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20221v1",
                "http://arxiv.org/pdf/2310.20221v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20218v1",
            "title": "A Systematic Review for Transformer-based Long-term Series Forecasting",
            "updated": "2023-10-31T06:37:51Z",
            "published": "2023-10-31T06:37:51Z",
            "summary": "The emergence of deep learning has yielded noteworthy advancements in time\nseries forecasting (TSF). Transformer architectures, in particular, have\nwitnessed broad utilization and adoption in TSF tasks. Transformers have proven\nto be the most successful solution to extract the semantic correlations among\nthe elements within a long sequence. Various variants have enabled transformer\narchitecture to effectively handle long-term time series forecasting (LTSF)\ntasks. In this article, we first present a comprehensive overview of\ntransformer architectures and their subsequent enhancements developed to\naddress various LTSF tasks. Then, we summarize the publicly available LTSF\ndatasets and relevant evaluation metrics. Furthermore, we provide valuable\ninsights into the best practices and techniques for effectively training\ntransformers in the context of time-series analysis. Lastly, we propose\npotential research directions in this rapidly evolving field.",
            "author": [
                "Liyilei Su",
                "Xumin Zuo",
                "Rui Li",
                "Xin Wang",
                "Heng Zhao",
                "Bingding Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20218v1",
                "http://arxiv.org/pdf/2310.20218v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20215v1",
            "title": "Handover Protocol Learning for LEO Satellite Networks: Access Delay and\n  Collision Minimization",
            "updated": "2023-10-31T06:26:38Z",
            "published": "2023-10-31T06:26:38Z",
            "summary": "This study presents a novel deep reinforcement learning (DRL)-based handover\n(HO) protocol, called DHO, specifically designed to address the persistent\nchallenge of long propagation delays in low-Earth orbit (LEO) satellite\nnetworks' HO procedures. DHO skips the Measurement Report (MR) in the HO\nprocedure by leveraging its predictive capabilities after being trained with a\npre-determined LEO satellite orbital pattern. This simplification eliminates\nthe propagation delay incurred during the MR phase, while still providing\neffective HO decisions. The proposed DHO outperforms the legacy HO protocol\nacross diverse network conditions in terms of access delay, collision rate, and\nhandover success rate, demonstrating the practical applicability of DHO in\nreal-world networks. Furthermore, the study examines the trade-off between\naccess delay and collision rate and also evaluates the training performance and\nconvergence of DHO using various DRL algorithms.",
            "author": [
                "Ju-Hyung Lee",
                "Chanyoung Park",
                "Soohyun Park",
                "Andreas F. Molisch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20215v1",
                "http://arxiv.org/pdf/2310.20215v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20211v1",
            "title": "Calibration by Distribution Matching: Trainable Kernel Calibration\n  Metrics",
            "updated": "2023-10-31T06:19:40Z",
            "published": "2023-10-31T06:19:40Z",
            "summary": "Calibration ensures that probabilistic forecasts meaningfully capture\nuncertainty by requiring that predicted probabilities align with empirical\nfrequencies. However, many existing calibration methods are specialized for\npost-hoc recalibration, which can worsen the sharpness of forecasts. Drawing on\nthe insight that calibration can be viewed as a distribution matching task, we\nintroduce kernel-based calibration metrics that unify and generalize popular\nforms of calibration for both classification and regression. These metrics\nadmit differentiable sample estimates, making it easy to incorporate a\ncalibration objective into empirical risk minimization. Furthermore, we provide\nintuitive mechanisms to tailor calibration metrics to a decision task, and\nenforce accurate loss estimation and no regret decisions. Our empirical\nevaluation demonstrates that employing these metrics as regularizers enhances\ncalibration, sharpness, and decision-making across a range of regression and\nclassification tasks, outperforming methods relying solely on post-hoc\nrecalibration.",
            "author": [
                "Charles Marx",
                "Sofian Zalouk",
                "Stefano Ermon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20211v1",
                "http://arxiv.org/pdf/2310.20211v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20210v1",
            "title": "UWFormer: Underwater Image Enhancement via a Semi-Supervised Multi-Scale\n  Transformer",
            "updated": "2023-10-31T06:19:09Z",
            "published": "2023-10-31T06:19:09Z",
            "summary": "Underwater images often exhibit poor quality, imbalanced coloration, and low\ncontrast due to the complex and intricate interaction of light, water, and\nobjects. Despite the significant contributions of previous underwater\nenhancement techniques, there exist several problems that demand further\nimprovement: (i) Current deep learning methodologies depend on Convolutional\nNeural Networks (CNNs) that lack multi-scale enhancement and also have limited\nglobal perception fields. (ii) The scarcity of paired real-world underwater\ndatasets poses a considerable challenge, and the utilization of synthetic image\npairs risks overfitting. To address the aforementioned issues, this paper\npresents a Multi-scale Transformer-based Network called UWFormer for enhancing\nimages at multiple frequencies via semi-supervised learning, in which we\npropose a Nonlinear Frequency-aware Attention mechanism and a Multi-Scale\nFusion Feed-forward Network for low-frequency enhancement. Additionally, we\nintroduce a specialized underwater semi-supervised training strategy, proposing\na Subaqueous Perceptual Loss function to generate reliable pseudo labels.\nExperiments using full-reference and non-reference underwater benchmarks\ndemonstrate that our method outperforms state-of-the-art methods in terms of\nboth quantity and visual quality.",
            "author": [
                "Xuhang Chen",
                "Zinuo Li",
                "Shenghong Luo",
                "Weiwen Chen",
                "Shuqiang Wang",
                "Chi-Man Pun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20210v1",
                "http://arxiv.org/pdf/2310.20210v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20209v1",
            "title": "Network Contention-Aware Cluster Scheduling with Reinforcement Learning",
            "updated": "2023-10-31T06:17:23Z",
            "published": "2023-10-31T06:17:23Z",
            "summary": "With continuous advances in deep learning, distributed training is becoming\ncommon in GPU clusters. Specifically, for emerging workloads with diverse\namounts, ratios, and patterns of communication, we observe that network\ncontention can significantly degrade training throughput. However, widely used\nscheduling policies often face limitations as they are agnostic to network\ncontention between jobs. In this paper, we present a new approach to mitigate\nnetwork contention in GPU clusters using reinforcement learning. We formulate\nGPU cluster scheduling as a reinforcement learning problem and opt to learn a\nnetwork contention-aware scheduling policy that efficiently captures contention\nsensitivities and dynamically adapts scheduling decisions through continuous\nevaluation and improvement. We show that compared to widely used scheduling\npolicies, our approach reduces average job completion time by up to 18.2\\% and\neffectively cuts the tail job completion time by up to 20.7\\% while allowing a\npreferable trade-off between average job completion time and resource\nutilization.",
            "author": [
                "Junyeol Ryu",
                "Jeongyoon Eo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20209v1",
                "http://arxiv.org/pdf/2310.20209v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20208v2",
            "title": "ZoomNeXt: A Unified Collaborative Pyramid Network for Camouflaged Object\n  Detection",
            "updated": "2023-11-29T08:33:30Z",
            "published": "2023-10-31T06:11:23Z",
            "summary": "Recent camouflaged object detection (COD) attempts to segment objects\nvisually blended into their surroundings, which is extremely complex and\ndifficult in real-world scenarios. Apart from the high intrinsic similarity\nbetween camouflaged objects and their background, objects are usually diverse\nin scale, fuzzy in appearance, and even severely occluded. To this end, we\npropose an effective unified collaborative pyramid network which mimics human\nbehavior when observing vague images and videos, \\textit{i.e.}, zooming in and\nout. Specifically, our approach employs the zooming strategy to learn\ndiscriminative mixed-scale semantics by the multi-head scale integration and\nrich granularity perception units, which are designed to fully explore\nimperceptible clues between candidate objects and background surroundings. The\nformer's intrinsic multi-head aggregation provides more diverse visual\npatterns. The latter's routing mechanism can effectively propagate inter-frame\ndifference in spatiotemporal scenarios and adaptively ignore static\nrepresentations. They provides a solid foundation for realizing a unified\narchitecture for static and dynamic COD. Moreover, considering the uncertainty\nand ambiguity derived from indistinguishable textures, we construct a simple\nyet effective regularization, uncertainty awareness loss, to encourage\npredictions with higher confidence in candidate regions. Our highly\ntask-friendly framework consistently outperforms existing state-of-the-art\nmethods in image and video COD benchmarks. The code will be available at\n\\url{https://github.com/lartpang/ZoomNeXt}.",
            "author": [
                "Youwei Pang",
                "Xiaoqi Zhao",
                "Tian-Zhu Xiang",
                "Lihe Zhang",
                "Huchuan Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20208v2",
                "http://arxiv.org/pdf/2310.20208v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20204v2",
            "title": "General-Purpose Retrieval-Enhanced Medical Prediction Model Using\n  Near-Infinite History",
            "updated": "2023-12-05T10:20:11Z",
            "published": "2023-10-31T06:04:18Z",
            "summary": "Developing clinical prediction models (e.g., mortality prediction) based on\nelectronic health records (EHRs) typically relies on expert opinion for feature\nselection and adjusting observation window size. This burdens experts and\ncreates a bottleneck in the development process. We propose Retrieval-Enhanced\nMedical prediction model (REMed) to address such challenges. REMed can\nessentially evaluate an unlimited number of clinical events, select the\nrelevant ones, and make predictions. This approach effectively eliminates the\nneed for manual feature selection and enables an unrestricted observation\nwindow. We verified these properties through experiments on 27 clinical tasks\nand two independent cohorts from publicly available EHR datasets, where REMed\noutperformed other contemporary architectures that aim to handle as many events\nas possible. Notably, we found that the preferences of REMed align closely with\nthose of medical experts. We expect our approach to significantly expedite the\ndevelopment of EHR prediction models by minimizing clinicians' need for manual\ninvolvement.",
            "author": [
                "Junu Kim",
                "Chaeeun Shim",
                "Bosco Seong Kyu Yang",
                "Chami Im",
                "Sung Yoon Lim",
                "Han-Gil Jeong",
                "Edward Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20204v2",
                "http://arxiv.org/pdf/2310.20204v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20203v1",
            "title": "Importance Estimation with Random Gradient for Neural Network Pruning",
            "updated": "2023-10-31T06:00:17Z",
            "published": "2023-10-31T06:00:17Z",
            "summary": "Global Neuron Importance Estimation is used to prune neural networks for\nefficiency reasons. To determine the global importance of each neuron or\nconvolutional kernel, most of the existing methods either use activation or\ngradient information or both, which demands abundant labelled examples. In this\nwork, we use heuristics to derive importance estimation similar to Taylor First\nOrder (TaylorFO) approximation based methods. We name our methods TaylorFO-abs\nand TaylorFO-sq. We propose two additional methods to improve these importance\nestimation methods. Firstly, we propagate random gradients from the last layer\nof a network, thus avoiding the need for labelled examples. Secondly, we\nnormalize the gradient magnitude of the last layer output before propagating,\nwhich allows all examples to contribute similarly to the importance score. Our\nmethods with additional techniques perform better than previous methods when\ntested on ResNet and VGG architectures on CIFAR-100 and STL-10 datasets.\nFurthermore, our method also complements the existing methods and improves\ntheir performances when combined with them.",
            "author": [
                "Suman Sapkota",
                "Binod Bhattarai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20203v1",
                "http://arxiv.org/pdf/2310.20203v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20201v1",
            "title": "Video-Helpful Multimodal Machine Translation",
            "updated": "2023-10-31T05:51:56Z",
            "published": "2023-10-31T05:51:56Z",
            "summary": "Existing multimodal machine translation (MMT) datasets consist of images and\nvideo captions or instructional video subtitles, which rarely contain\nlinguistic ambiguity, making visual information ineffective in generating\nappropriate translations. Recent work has constructed an ambiguous subtitles\ndataset to alleviate this problem but is still limited to the problem that\nvideos do not necessarily contribute to disambiguation. We introduce EVA\n(Extensive training set and Video-helpful evaluation set for Ambiguous\nsubtitles translation), an MMT dataset containing 852k Japanese-English (Ja-En)\nparallel subtitle pairs, 520k Chinese-English (Zh-En) parallel subtitle pairs,\nand corresponding video clips collected from movies and TV episodes. In\naddition to the extensive training set, EVA contains a video-helpful evaluation\nset in which subtitles are ambiguous, and videos are guaranteed helpful for\ndisambiguation. Furthermore, we propose SAFA, an MMT model based on the\nSelective Attention model with two novel methods: Frame attention loss and\nAmbiguity augmentation, aiming to use videos in EVA for disambiguation fully.\nExperiments on EVA show that visual information and the proposed methods can\nboost translation performance, and our model performs significantly better than\nexisting MMT models. The EVA dataset and the SAFA model are available at:\nhttps://github.com/ku-nlp/video-helpful-MMT.git.",
            "author": [
                "Yihang Li",
                "Shuichiro Shimizu",
                "Chenhui Chu",
                "Sadao Kurohashi",
                "Wei Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20201v1",
                "http://arxiv.org/pdf/2310.20201v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00724v1",
            "title": "Fraud Analytics Using Machine-learning & Engineering on Big Data (FAME)\n  for Telecom",
            "updated": "2023-10-31T05:47:35Z",
            "published": "2023-10-31T05:47:35Z",
            "summary": "Telecom industries lose globally 46.3 Billion USD due to fraud. Data mining\nand machine learning techniques (apart from rules oriented approach) have been\nused in past, but efficiency has been low as fraud pattern changes very\nrapidly. This paper presents an industrialized solution approach with self\nadaptive data mining technique and application of big data technologies to\ndetect fraud and discover novel fraud patterns in accurate, efficient and cost\neffective manner. Solution has been successfully demonstrated to detect\nInternational Revenue Share Fraud with <5% false positive. More than 1 Terra\nBytes of Call Detail Record from a reputed wholesale carrier and overseas\ntelecom transit carrier has been used to conduct this study.",
            "author": [
                "Sudarson Roy Pratihar",
                "Subhadip Paul",
                "Pranab Kumar Dash",
                "Amartya Kumar Das"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00724v1",
                "http://arxiv.org/pdf/2311.00724v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20199v1",
            "title": "In Search of Lost Online Test-time Adaptation: A Survey",
            "updated": "2023-10-31T05:47:33Z",
            "published": "2023-10-31T05:47:33Z",
            "summary": "In this paper, we present a comprehensive survey on online test-time\nadaptation (OTTA), a paradigm focused on adapting machine learning models to\nnovel data distributions upon batch arrival. Despite the proliferation of OTTA\nmethods recently, the field is mired in issues like ambiguous settings,\nantiquated backbones, and inconsistent hyperparameter tuning, obfuscating the\nreal challenges and making reproducibility elusive. For clarity and a rigorous\ncomparison, we classify OTTA techniques into three primary categories and\nsubject them to benchmarks using the potent Vision Transformer (ViT) backbone\nto discover genuinely effective strategies. Our benchmarks span not only\nconventional corrupted datasets such as CIFAR-10/100-C and ImageNet-C but also\nreal-world shifts embodied in CIFAR-10.1 and CIFAR-10-Warehouse, encapsulating\nvariations across search engines and synthesized data by diffusion models. To\ngauge efficiency in online scenarios, we introduce novel evaluation metrics,\ninclusive of FLOPs, shedding light on the trade-offs between adaptation\naccuracy and computational overhead. Our findings diverge from existing\nliterature, indicating: (1) transformers exhibit heightened resilience to\ndiverse domain shifts, (2) the efficacy of many OTTA methods hinges on ample\nbatch sizes, and (3) stability in optimization and resistance to perturbations\nare critical during adaptation, especially when the batch size is 1. Motivated\nby these insights, we pointed out promising directions for future research. The\nsource code will be made available.",
            "author": [
                "Zixin Wang",
                "Yadan Luo",
                "Liang Zheng",
                "Zhuoxiao Chen",
                "Sen Wang",
                "Zi Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20199v1",
                "http://arxiv.org/pdf/2310.20199v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20193v1",
            "title": "FedRec+: Enhancing Privacy and Addressing Heterogeneity in Federated\n  Recommendation Systems",
            "updated": "2023-10-31T05:36:53Z",
            "published": "2023-10-31T05:36:53Z",
            "summary": "Preserving privacy and reducing communication costs for edge users pose\nsignificant challenges in recommendation systems. Although federated learning\nhas proven effective in protecting privacy by avoiding data exchange between\nclients and servers, it has been shown that the server can infer user ratings\nbased on updated non-zero gradients obtained from two consecutive rounds of\nuser-uploaded gradients. Moreover, federated recommendation systems (FRS) face\nthe challenge of heterogeneity, leading to decreased recommendation\nperformance. In this paper, we propose FedRec+, an ensemble framework for FRS\nthat enhances privacy while addressing the heterogeneity challenge. FedRec+\nemploys optimal subset selection based on feature similarity to generate\nnear-optimal virtual ratings for pseudo items, utilizing only the user's local\ninformation. This approach reduces noise without incurring additional\ncommunication costs. Furthermore, we utilize the Wasserstein distance to\nestimate the heterogeneity and contribution of each client, and derive optimal\naggregation weights by solving a defined optimization problem. Experimental\nresults demonstrate the state-of-the-art performance of FedRec+ across various\nreference datasets.",
            "author": [
                "Lin Wang",
                "Zhichao Wang",
                "Xi Leng",
                "Xiaoying Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20193v1",
                "http://arxiv.org/pdf/2310.20193v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20190v2",
            "title": "Visible to Thermal image Translation for improving visual task in low\n  light conditions",
            "updated": "2023-11-09T02:42:20Z",
            "published": "2023-10-31T05:18:53Z",
            "summary": "Several visual tasks, such as pedestrian detection and image-to-image\ntranslation, are challenging to accomplish in low light using RGB images. Heat\nvariation of objects in thermal images can be used to overcome this. In this\nwork, an end-to-end framework, which consists of a generative network and a\ndetector network, is proposed to translate RGB image into Thermal ones and\ncompare generated thermal images with real data. We have collected images from\ntwo different locations using the Parrot Anafi Thermal drone. After that, we\ncreated a two-stream network, preprocessed, augmented, the image data, and\ntrained the generator and discriminator models from scratch. The findings\ndemonstrate that it is feasible to translate RGB training data to thermal data\nusing GAN. As a result, thermal data can now be produced more quickly and\naffordably, which is useful for security and surveillance applications.",
            "author": [
                "Md Azim Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20190v2",
                "http://arxiv.org/pdf/2310.20190v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20189v2",
            "title": "LFG: A Generative Network for Real-Time Recommendation",
            "updated": "2023-11-25T11:46:49Z",
            "published": "2023-10-31T05:16:54Z",
            "summary": "Recommender systems are essential information technologies today, and\nrecommendation algorithms combined with deep learning have become a research\nhotspot in this field. The recommendation model known as LFM (Latent Factor\nModel), which captures latent features through matrix factorization and\ngradient descent to fit user preferences, has given rise to various\nrecommendation algorithms that bring new improvements in recommendation\naccuracy. However, collaborative filtering recommendation models based on LFM\nlack flexibility and has shortcomings for real-time recommendations, as they\nneed to redo the matrix factorization and retrain using gradient descent when\nnew users arrive. In response to this, this paper innovatively proposes a\nLatent Factor Generator (LFG) network, and set the movie recommendation as\nresearch theme. The LFG dynamically generates user latent factors through deep\nneural networks without the need for re-factorization or retrain. Experimental\nresults indicate that the LFG recommendation model outperforms traditional\nmatrix factorization algorithms in recommendation accuracy, providing an\neffective solution to the challenges of real-time recommendations with LFM.",
            "author": [
                "Junyi Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20189v2",
                "http://arxiv.org/pdf/2310.20189v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20187v1",
            "title": "Self-supervised Pre-training for Precipitation Post-processor",
            "updated": "2023-10-31T05:13:10Z",
            "published": "2023-10-31T05:13:10Z",
            "summary": "Securing sufficient forecast lead time for local precipitation is essential\nfor preventing hazardous weather events. Nonetheless, global warming-induced\nclimate change is adding to the challenge of accurately predicting severe\nprecipitation events, such as heavy rainfall. In this work, we propose a deep\nlearning-based precipitation post-processor approach to numerical weather\nprediction (NWP) models. The precipitation post-processor consists of (i)\nself-supervised pre-training, where parameters of encoder are pre-trained on\nthe reconstruction of masked variables of the atmospheric physics domain, and\n(ii) transfer learning on precipitation segmentation tasks (target domain) from\nthe pre-trained encoder. We also introduce a heuristic labeling approach for\neffectively training class-imbalanced datasets. Our experiment results in\nprecipitation correction for regional NWP show that the proposed method\noutperforms other approaches.",
            "author": [
                "Sojung An",
                "Junha Lee",
                "Jiyeon Jang",
                "Inchae Na",
                "Wooyeon Park",
                "Sujeong You"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20187v1",
                "http://arxiv.org/pdf/2310.20187v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20183v1",
            "title": "Thriving in a Pandemic: Lessons Learned from a Resilient University\n  Program Seen Through the CoI Lens",
            "updated": "2023-10-31T05:09:17Z",
            "published": "2023-10-31T05:09:17Z",
            "summary": "In March 2020, college campuses underwent a sudden transformation to online\nlearning due to the COVID-19 outbreak. To understand the impact of COVID-19 on\nstudents' expectations, this study conducted a three-year survey from ten core\ncourses within the Project Management Center for Excellence at the University\nof Maryland. The study involved two main steps: 1) a statistical analysis to\nevaluate students' expectations regarding \"student,\" \"class,\" \"instructor,\" and\n\"effort;\" and 2) a lexical salience-valence analysis (LSVA) through the lens of\nthe Community of Inquiry (CoI) framework to show the changes of students'\nexpectations. The results revealed that students' overall evaluations\nmaintained relatively consistent amid the COVID-19 teaching period. However,\nthere were significant shifts of the student expectations toward Cognitive,\nSocial and Teaching Presence course elements based on LSVA results. Also, clear\ndifferences emerged between under-graduates and graduates in their expectations\nand preferences in course design and delivery. These insights provide practical\nrecommendations for course instructors in designing effective online courses.",
            "author": [
                "Zihui Ma",
                "Lingyao Li",
                "John C. E. Johnson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20183v1",
                "http://arxiv.org/pdf/2310.20183v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20178v2",
            "title": "Learning to Discover Skills through Guidance",
            "updated": "2023-11-01T13:55:57Z",
            "published": "2023-10-31T05:01:02Z",
            "summary": "In the field of unsupervised skill discovery (USD), a major challenge is\nlimited exploration, primarily due to substantial penalties when skills deviate\nfrom their initial trajectories. To enhance exploration, recent methodologies\nemploy auxiliary rewards to maximize the epistemic uncertainty or entropy of\nstates. However, we have identified that the effectiveness of these rewards\ndeclines as the environmental complexity rises. Therefore, we present a novel\nUSD algorithm, skill discovery with guidance (DISCO-DANCE), which (1) selects\nthe guide skill that possesses the highest potential to reach unexplored\nstates, (2) guides other skills to follow guide skill, then (3) the guided\nskills are dispersed to maximize their discriminability in unexplored states.\nEmpirical evaluation demonstrates that DISCO-DANCE outperforms other USD\nbaselines in challenging environments, including two navigation benchmarks and\na continuous control benchmark. Qualitative visualizations and code of\nDISCO-DANCE are available at https://mynsng.github.io/discodance.",
            "author": [
                "Hyunseung Kim",
                "Byungkun Lee",
                "Hojoon Lee",
                "Dongyoon Hwang",
                "Sejik Park",
                "Kyushik Min",
                "Jaegul Choo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20178v2",
                "http://arxiv.org/pdf/2310.20178v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20172v1",
            "title": "Compact Binary Systems Waveform Generation with Generative Pre-trained\n  Transformer",
            "updated": "2023-10-31T04:40:20Z",
            "published": "2023-10-31T04:40:20Z",
            "summary": "Space-based gravitational wave detection is one of the most anticipated\ngravitational wave (GW) detection projects in the next decade, which will\ndetect abundant compact binary systems. However, the precise prediction of\nspace GW waveforms remains unexplored. To solve the data processing difficulty\nin the increasing waveform complexity caused by detectors' response and\nsecond-generation time-delay interferometry (TDI 2.0), an interpretable\npre-trained large model named CBS-GPT (Compact Binary Systems Waveform\nGeneration with Generative Pre-trained Transformer) is proposed. For compact\nbinary system waveforms, three models were trained to predict the waveforms of\nmassive black hole binary (MBHB), extreme mass-ratio inspirals (EMRIs), and\ngalactic binary (GB), achieving prediction accuracies of 98%, 91%, and 99%,\nrespectively. The CBS-GPT model exhibits notable interpretability, with its\nhidden parameters effectively capturing the intricate information of waveforms,\neven with complex instrument response and a wide parameter range. Our research\ndemonstrates the potential of large pre-trained models in gravitational wave\ndata processing, opening up new opportunities for future tasks such as gap\ncompletion, GW signal detection, and signal noise reduction.",
            "author": [
                "Ruijun Shi",
                "Yue Zhou",
                "Tianyu Zhao",
                "Zhoujian Cao",
                "Zhixiang Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20172v1",
                "http://arxiv.org/pdf/2310.20172v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20168v1",
            "title": "Understanding and Visualizing Droplet Distributions in Simulations of\n  Shallow Clouds",
            "updated": "2023-10-31T04:25:00Z",
            "published": "2023-10-31T04:25:00Z",
            "summary": "Thorough analysis of local droplet-level interactions is crucial to better\nunderstand the microphysical processes in clouds and their effect on the global\nclimate. High-accuracy simulations of relevant droplet size distributions from\nLarge Eddy Simulations (LES) of bin microphysics challenge current analysis\ntechniques due to their high dimensionality involving three spatial dimensions,\ntime, and a continuous range of droplet sizes. Utilizing the compact latent\nrepresentations from Variational Autoencoders (VAEs), we produce novel and\nintuitive visualizations for the organization of droplet sizes and their\nevolution over time beyond what is possible with clustering techniques. This\ngreatly improves interpretation and allows us to examine aerosol-cloud\ninteractions by contrasting simulations with different aerosol concentrations.\nWe find that the evolution of the droplet spectrum is similar across aerosol\nlevels but occurs at different paces. This similarity suggests that\nprecipitation initiation processes are alike despite variations in onset times.",
            "author": [
                "Justus C. Will",
                "Andrea M. Jenney",
                "Kara D. Lamb",
                "Michael S. Pritchard",
                "Colleen Kaul",
                "Po-Lun Ma",
                "Kyle Pressel",
                "Jacob Shpund",
                "Marcus van Lier-Walqui",
                "Stephan Mandt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20168v1",
                "http://arxiv.org/pdf/2310.20168v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.ao-ph",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20162v1",
            "title": "Is Robustness Transferable across Languages in Multilingual Neural\n  Machine Translation?",
            "updated": "2023-10-31T04:10:31Z",
            "published": "2023-10-31T04:10:31Z",
            "summary": "Robustness, the ability of models to maintain performance in the face of\nperturbations, is critical for developing reliable NLP systems. Recent studies\nhave shown promising results in improving the robustness of models through\nadversarial training and data augmentation. However, in machine translation,\nmost of these studies have focused on bilingual machine translation with a\nsingle translation direction. In this paper, we investigate the transferability\nof robustness across different languages in multilingual neural machine\ntranslation. We propose a robustness transfer analysis protocol and conduct a\nseries of experiments. In particular, we use character-, word-, and multi-level\nnoises to attack the specific translation direction of the multilingual neural\nmachine translation model and evaluate the robustness of other translation\ndirections. Our findings demonstrate that the robustness gained in one\ntranslation direction can indeed transfer to other translation directions.\nAdditionally, we empirically find scenarios where robustness to character-level\nnoise and word-level noise is more likely to transfer.",
            "author": [
                "Leiyu Pan",
                "Supryadi",
                "Deyi Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20162v1",
                "http://arxiv.org/pdf/2310.20162v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20155v1",
            "title": "MLatom 3: Platform for machine learning-enhanced computational chemistry\n  simulations and workflows",
            "updated": "2023-10-31T03:41:39Z",
            "published": "2023-10-31T03:41:39Z",
            "summary": "Machine learning (ML) is increasingly becoming a common tool in computational\nchemistry. At the same time, the rapid development of ML methods requires a\nflexible software framework for designing custom workflows. MLatom 3 is a\nprogram package designed to leverage the power of ML to enhance typical\ncomputational chemistry simulations and to create complex workflows. This\nopen-source package provides plenty of choice to the users who can run\nsimulations with the command line options, input files, or with scripts using\nMLatom as a Python package, both on their computers and on the online XACS\ncloud computing at XACScloud.com. Computational chemists can calculate energies\nand thermochemical properties, optimize geometries, run molecular and quantum\ndynamics, and simulate (ro)vibrational, one-photon UV/vis absorption, and\ntwo-photon absorption spectra with ML, quantum mechanical, and combined models.\nThe users can choose from an extensive library of methods containing\npre-trained ML models and quantum mechanical approximations such as AIQM1\napproaching coupled-cluster accuracy. The developers can build their own models\nusing various ML algorithms. The great flexibility of MLatom is largely due to\nthe extensive use of the interfaces to many state-of-the-art software packages\nand libraries.",
            "author": [
                "Pavlo O. Dral",
                "Fuchun Ge",
                "Yi-Fan Hou",
                "Peikun Zheng",
                "Yuxinxin Chen",
                "Mario Barbatti",
                "Olexandr Isayev",
                "Cheng Wang",
                "Bao-Xin Xue",
                "Max Pinheiro Jr",
                "Yuming Su",
                "Yiheng Dai",
                "Yangtao Chen",
                "Lina Zhang",
                "Shuang Zhang",
                "Arif Ullah",
                "Quanhao Zhang",
                "Yanchi Ou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20155v1",
                "http://arxiv.org/pdf/2310.20155v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20153v1",
            "title": "Interactive Multi-fidelity Learning for Cost-effective Adaptation of\n  Language Model with Sparse Human Supervision",
            "updated": "2023-10-31T03:39:23Z",
            "published": "2023-10-31T03:39:23Z",
            "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious tasks. However, their suitability for domain-specific tasks, is limited\ndue to their immense scale at deployment, susceptibility to misinformation, and\nmore importantly, high data annotation costs. We propose a novel Interactive\nMulti-Fidelity Learning (IMFL) framework for the cost-effective development of\nsmall domain-specific LMs under limited annotation budgets. Our approach\nformulates the domain-specific fine-tuning process as a multi-fidelity learning\nproblem, focusing on identifying the optimal acquisition strategy that balances\nbetween low-fidelity automatic LLM annotations and high-fidelity human\nannotations to maximize model performance. We further propose an\nexploration-exploitation query strategy that enhances annotation diversity and\ninformativeness, incorporating two innovative designs: 1) prompt retrieval that\nselects in-context examples from human-annotated samples to improve LLM\nannotation, and 2) variable batch size that controls the order for choosing\neach fidelity to facilitate knowledge distillation, ultimately enhancing\nannotation quality. Extensive experiments on financial and medical tasks\ndemonstrate that IMFL achieves superior performance compared with single\nfidelity annotations. Given a limited budget of human annotation, IMFL\nsignificantly outperforms the human annotation baselines in all four tasks and\nachieves very close performance as human annotations on two of the tasks. These\npromising results suggest that the high human annotation costs in\ndomain-specific tasks can be significantly reduced by employing IMFL, which\nutilizes fewer human annotations, supplemented with cheaper and faster LLM\n(e.g., GPT-3.5) annotations to achieve comparable performance.",
            "author": [
                "Jiaxin Zhang",
                "Zhuohang Li",
                "Kamalika Das",
                "Sricharan Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20153v1",
                "http://arxiv.org/pdf/2310.20153v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20150v1",
            "title": "Unlearn What You Want to Forget: Efficient Unlearning for LLMs",
            "updated": "2023-10-31T03:35:59Z",
            "published": "2023-10-31T03:35:59Z",
            "summary": "Large language models (LLMs) have achieved significant progress from\npre-training on and memorizing a wide range of textual data, however, this\nprocess might suffer from privacy issues and violations of data protection\nregulations. As a result, the ability to easily remove data related to\nindividual users from such models while not deteriorating their predictive\nquality after the removal becomes increasingly important. To address these\nissues, in this work, we propose an efficient unlearning framework that could\nefficiently update LLMs without having to retrain the whole model after data\nremovals, by introducing lightweight unlearning layers learned with a selective\nteacher-student objective into the transformers. In addition, we introduce a\nfusion mechanism to effectively combine different unlearning layers that learns\nto forget different sets of data to handle a sequence of forgetting operations.\nExperiments on classification and generation tasks demonstrate the\neffectiveness of our proposed methods compared to the state-of-the-art\nbaselines.",
            "author": [
                "Jiaao Chen",
                "Diyi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20150v1",
                "http://arxiv.org/pdf/2310.20150v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20145v2",
            "title": "Efficient Robust Bayesian Optimization for Arbitrary Uncertain Inputs",
            "updated": "2023-11-03T23:52:57Z",
            "published": "2023-10-31T03:29:31Z",
            "summary": "Bayesian Optimization (BO) is a sample-efficient optimization algorithm\nwidely employed across various applications. In some challenging BO tasks,\ninput uncertainty arises due to the inevitable randomness in the optimization\nprocess, such as machining errors, execution noise, or contextual variability.\nThis uncertainty deviates the input from the intended value before evaluation,\nresulting in significant performance fluctuations in the final result. In this\npaper, we introduce a novel robust Bayesian Optimization algorithm, AIRBO,\nwhich can effectively identify a robust optimum that performs consistently well\nunder arbitrary input uncertainty. Our method directly models the uncertain\ninputs of arbitrary distributions by empowering the Gaussian Process with the\nMaximum Mean Discrepancy (MMD) and further accelerates the posterior inference\nvia Nystrom approximation. Rigorous theoretical regret bound is established\nunder MMD estimation error and extensive experiments on synthetic functions and\nreal problems demonstrate that our approach can handle various input\nuncertainties and achieve state-of-the-art performance.",
            "author": [
                "Lin Yang",
                "Junlong Lyu",
                "Wenlong Lyu",
                "Zhitang Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20145v2",
                "http://arxiv.org/pdf/2310.20145v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20144v1",
            "title": "EELBERT: Tiny Models through Dynamic Embeddings",
            "updated": "2023-10-31T03:28:08Z",
            "published": "2023-10-31T03:28:08Z",
            "summary": "We introduce EELBERT, an approach for compression of transformer-based models\n(e.g., BERT), with minimal impact on the accuracy of downstream tasks. This is\nachieved by replacing the input embedding layer of the model with dynamic, i.e.\non-the-fly, embedding computations. Since the input embedding layer accounts\nfor a significant fraction of the model size, especially for the smaller BERT\nvariants, replacing this layer with an embedding computation function helps us\nreduce the model size significantly. Empirical evaluation on the GLUE benchmark\nshows that our BERT variants (EELBERT) suffer minimal regression compared to\nthe traditional BERT models. Through this approach, we are able to develop our\nsmallest model UNO-EELBERT, which achieves a GLUE score within 4% of fully\ntrained BERT-tiny, while being 15x smaller (1.2 MB) in size.",
            "author": [
                "Gabrielle Cohn",
                "Rishika Agarwal",
                "Deepanshu Gupta",
                "Siddharth Patwardhan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20144v1",
                "http://arxiv.org/pdf/2310.20144v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "68T07",
                "I.2.7; I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20141v1",
            "title": "Contrastive Difference Predictive Coding",
            "updated": "2023-10-31T03:16:32Z",
            "published": "2023-10-31T03:16:32Z",
            "summary": "Predicting and reasoning about the future lie at the heart of many\ntime-series questions. For example, goal-conditioned reinforcement learning can\nbe viewed as learning representations to predict which states are likely to be\nvisited in the future. While prior methods have used contrastive predictive\ncoding to model time series data, learning representations that encode\nlong-term dependencies usually requires large amounts of data. In this paper,\nwe introduce a temporal difference version of contrastive predictive coding\nthat stitches together pieces of different time series data to decrease the\namount of data required to learn predictions of future events. We apply this\nrepresentation learning method to derive an off-policy algorithm for\ngoal-conditioned RL. Experiments demonstrate that, compared with prior RL\nmethods, ours achieves $2 \\times$ median improvement in success rates and can\nbetter cope with stochastic environments. In tabular settings, we show that our\nmethod is about $20 \\times$ more sample efficient than the successor\nrepresentation and $1500 \\times$ more sample efficient than the standard (Monte\nCarlo) version of contrastive predictive coding.",
            "author": [
                "Chongyi Zheng",
                "Ruslan Salakhutdinov",
                "Benjamin Eysenbach"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20141v1",
                "http://arxiv.org/pdf/2310.20141v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20140v1",
            "title": "Synthesizing Diabetic Foot Ulcer Images with Diffusion Model",
            "updated": "2023-10-31T03:15:30Z",
            "published": "2023-10-31T03:15:30Z",
            "summary": "Diabetic Foot Ulcer (DFU) is a serious skin wound requiring specialized care.\nHowever, real DFU datasets are limited, hindering clinical training and\nresearch activities. In recent years, generative adversarial networks and\ndiffusion models have emerged as powerful tools for generating synthetic images\nwith remarkable realism and diversity in many applications. This paper explores\nthe potential of diffusion models for synthesizing DFU images and evaluates\ntheir authenticity through expert clinician assessments. Additionally,\nevaluation metrics such as Frechet Inception Distance (FID) and Kernel\nInception Distance (KID) are examined to assess the quality of the synthetic\nDFU images. A dataset of 2,000 DFU images is used for training the diffusion\nmodel, and the synthetic images are generated by applying diffusion processes.\nThe results indicate that the diffusion model successfully synthesizes visually\nindistinguishable DFU images. 70% of the time, clinicians marked synthetic DFU\nimages as real DFUs. However, clinicians demonstrate higher unanimous\nconfidence in rating real images than synthetic ones. The study also reveals\nthat FID and KID metrics do not significantly align with clinicians'\nassessments, suggesting alternative evaluation approaches are needed. The\nfindings highlight the potential of diffusion models for generating synthetic\nDFU images and their impact on medical training programs and research in wound\ndetection and classification.",
            "author": [
                "Reza Basiri",
                "Karim Manji",
                "Francois Harton",
                "Alisha Poonja",
                "Milos R. Popovic",
                "Shehroz S. Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20140v1",
                "http://arxiv.org/pdf/2310.20140v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20129v1",
            "title": "Gibbs state sampling via cluster expansions",
            "updated": "2023-10-31T02:36:24Z",
            "published": "2023-10-31T02:36:24Z",
            "summary": "Gibbs states (i.e., thermal states) can be used for several applications such\nas quantum simulation, quantum machine learning, quantum optimization, and the\nstudy of open quantum systems. Moreover, semi-definite programming,\ncombinatorial optimization problems, and training quantum Boltzmann machines\ncan all be addressed by sampling from well-prepared Gibbs states. With that,\nhowever, comes the fact that preparing and sampling from Gibbs states on a\nquantum computer are notoriously difficult tasks. Such tasks can require large\noverhead in resources and/or calibration even in the simplest of cases, as well\nas the fact that the implementation might be limited to only a specific set of\nsystems. We propose a method based on sampling from a quasi-distribution\nconsisting of tensor products of mixed states on local clusters, i.e.,\nexpanding the full Gibbs state into a sum of products of local \"Gibbs-cumulant\"\ntype states easier to implement and sample from on quantum hardware. We begin\nwith presenting results for 4-spin linear chains with XY spin interactions, for\nwhich we obtain the $ZZ$ dynamical spin-spin correlation functions. We also\npresent the results of measuring the specific heat of the 8-spin chain Gibbs\nstate $\\rho_8$.",
            "author": [
                "Norhan M. Eassa",
                "Mahmoud M. Moustafa",
                "Arnab Banerjee",
                "Jeffrey Cohn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20129v1",
                "http://arxiv.org/pdf/2310.20129v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.other"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20127v1",
            "title": "Improving Prompt Tuning with Learned Prompting Layers",
            "updated": "2023-10-31T02:07:51Z",
            "published": "2023-10-31T02:07:51Z",
            "summary": "Prompt tuning prepends a soft prompt to the input embeddings or hidden states\nand only optimizes the prompt to adapt pretrained models (PTMs) to downstream\ntasks. The previous work manually selects prompt layers which are far from\noptimal and failed to exploit the potential of prompt tuning. In this work, we\npropose a novel framework, \\underline{S}elective \\underline{P}rompt\n\\underline{T}uning (SPT), that learns to select the proper prompt layers by\ninserting a prompt controlled by a learnable probabilistic gate at each\nintermediate layer. We further propose a novel bi-level optimization framework,\nSPT-DARTS, that can better optimize the learnable gates and improve the final\nprompt tuning performances of the learned prompt layer settings. We conduct\nextensive experiments with ten benchmark datasets under the full-data and\nfew-shot scenarios. The results demonstrate that our SPT framework can perform\nbetter than the previous state-of-the-art PETuning baselines with comparable or\nfewer tunable parameters.",
            "author": [
                "Wei Zhu",
                "Ming Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20127v1",
                "http://arxiv.org/pdf/2310.20127v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20125v1",
            "title": "Zephyr : Stitching Heterogeneous Training Data with Normalizing Flows\n  for Photometric Redshift Inference",
            "updated": "2023-10-31T01:58:39Z",
            "published": "2023-10-31T01:58:39Z",
            "summary": "We present zephyr, a novel method that integrates cutting-edge normalizing\nflow techniques into a mixture density estimation framework, enabling the\neffective use of heterogeneous training data for photometric redshift\ninference. Compared to previous methods, zephyr demonstrates enhanced\nrobustness for both point estimation and distribution reconstruction by\nleveraging normalizing flows for density estimation and incorporating careful\nuncertainty quantification. Moreover, zephyr offers unique interpretability by\nexplicitly disentangling contributions from multi-source training data, which\ncan facilitate future weak lensing analysis by providing an additional quality\nassessment. As probabilistic generative deep learning techniques gain\nincreasing prominence in astronomy, zephyr should become an inspiration for\nhandling heterogeneous training data while remaining interpretable and robustly\naccounting for observational uncertainties.",
            "author": [
                "Zechang Sun",
                "Joshua S. Speagle",
                "Song Huang",
                "Yuan-Sen Ting",
                "Zheng Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20125v1",
                "http://arxiv.org/pdf/2310.20125v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20121v1",
            "title": "Ling-CL: Understanding NLP Models through Linguistic Curricula",
            "updated": "2023-10-31T01:44:33Z",
            "published": "2023-10-31T01:44:33Z",
            "summary": "We employ a characterization of linguistic complexity from psycholinguistic\nand language acquisition research to develop data-driven curricula to\nunderstand the underlying linguistic knowledge that models learn to address NLP\ntasks. The novelty of our approach is in the development of linguistic\ncurricula derived from data, existing knowledge about linguistic complexity,\nand model behavior during training. By analyzing several benchmark NLP\ndatasets, our curriculum learning approaches identify sets of linguistic\nmetrics (indices) that inform the challenges and reasoning required to address\neach task. Our work will inform future research in all NLP areas, allowing\nlinguistic complexity to be considered early in the research and development\nprocess. In addition, our work prompts an examination of gold standards and\nfair evaluation in NLP.",
            "author": [
                "Mohamed Elgaar",
                "Hadi Amiri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20121v1",
                "http://arxiv.org/pdf/2310.20121v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20117v1",
            "title": "Refined Equivalent Pinhole Model for Large-scale 3D Reconstruction from\n  Spaceborne CCD Imagery",
            "updated": "2023-10-31T01:30:57Z",
            "published": "2023-10-31T01:30:57Z",
            "summary": "In this study, we present a large-scale earth surface reconstruction pipeline\nfor linear-array charge-coupled device (CCD) satellite imagery. While\nmainstream satellite image-based reconstruction approaches perform\nexceptionally well, the rational functional model (RFM) is subject to several\nlimitations. For example, the RFM has no rigorous physical interpretation and\ndiffers significantly from the pinhole imaging model; hence, it cannot be\ndirectly applied to learning-based 3D reconstruction networks and to more novel\nreconstruction pipelines in computer vision. Hence, in this study, we introduce\na method in which the RFM is equivalent to the pinhole camera model (PCM),\nmeaning that the internal and external parameters of the pinhole camera are\nused instead of the rational polynomial coefficient parameters. We then derive\nan error formula for this equivalent pinhole model for the first time,\ndemonstrating the influence of the image size on the accuracy of the\nreconstruction. In addition, we propose a polynomial image refinement model\nthat minimizes equivalent errors via the least squares method. The experiments\nwere conducted using four image datasets: WHU-TLC, DFC2019, ISPRS-ZY3, and GF7.\nThe results demonstrated that the reconstruction accuracy was proportional to\nthe image size. Our polynomial image refinement model significantly enhanced\nthe accuracy and completeness of the reconstruction, and achieved more\nsignificant improvements for larger-scale images.",
            "author": [
                "Hong Danyang",
                "Yu Anzhu",
                "Ji Song",
                "Cao Xuefeng",
                "Quan Yujun",
                "Guo Wenyue",
                "Qiu Chunping"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20117v1",
                "http://arxiv.org/pdf/2310.20117v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20109v1",
            "title": "Multi-Objective Intrinsic Reward Learning for Conversational Recommender\n  Systems",
            "updated": "2023-10-31T01:07:30Z",
            "published": "2023-10-31T01:07:30Z",
            "summary": "Conversational Recommender Systems (CRS) actively elicit user preferences to\ngenerate adaptive recommendations. Mainstream reinforcement learning-based CRS\nsolutions heavily rely on handcrafted reward functions, which may not be\naligned with user intent in CRS tasks. Therefore, the design of task-specific\nrewards is critical to facilitate CRS policy learning, which remains largely\nunder-explored in the literature. In this work, we propose a novel approach to\naddress this challenge by learning intrinsic rewards from interactions with\nusers. Specifically, we formulate intrinsic reward learning as a\nmulti-objective bi-level optimization problem. The inner level optimizes the\nCRS policy augmented by the learned intrinsic rewards, while the outer level\ndrives the intrinsic rewards to optimize two CRS-specific objectives:\nmaximizing the success rate and minimizing the number of turns to reach a\nsuccessful recommendation in conversations. To evaluate the effectiveness of\nour approach, we conduct extensive experiments on three public CRS benchmarks.\nThe results show that our algorithm significantly improves CRS performance by\nexploiting informative learned intrinsic rewards.",
            "author": [
                "Zhendong Chu",
                "Nan Wang",
                "Hongning Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20109v1",
                "http://arxiv.org/pdf/2310.20109v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20106v1",
            "title": "Progress and outlook on advanced fly scans based on Mamba",
            "updated": "2023-10-31T00:57:58Z",
            "published": "2023-10-31T00:57:58Z",
            "summary": "Development related to PandABox-based fly scans is an important part of the\nactive work on Mamba, the software framework for beamline experiments at the\nHigh Energy Photon Source (HEPS); presented in this paper is the progress of\nour development, and some outlook for advanced fly scans based on knowledge\nlearned during the process. By treating fly scans as a collaboration between a\nfew loosely coupled subsystems - motors / mechanics, detectors / data\nprocessing, sequencer devices like PandABox - systematic analyses of issues in\nfly scans are conducted. Interesting products of these analyses include a\ngeneral-purpose software-based fly-scan mechanism, a general way to design\nundulator-monochromator fly scans, a sketch of how to practically implement\nonline tuning of fly-scan behaviours based on processing of the data acquired,\nand many more. Based on the results above, an architectural discussion on\n>=10kHz fly scans is given.",
            "author": [
                "Peng-Cheng Li",
                "Cheng-Long Zhang",
                "Zong-Yang Yue",
                "Xiao-Bao Deng",
                "Chun Li",
                "Ai-Yu Zhou",
                "Gang Li",
                "Yu Liu",
                "Yi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20106v1",
                "http://arxiv.org/pdf/2310.20106v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20102v1",
            "title": "Sample-Conditioned Hypothesis Stability Sharpens Information-Theoretic\n  Generalization Bounds",
            "updated": "2023-10-31T00:44:20Z",
            "published": "2023-10-31T00:44:20Z",
            "summary": "We present new information-theoretic generalization guarantees through the a\nnovel construction of the \"neighboring-hypothesis\" matrix and a new family of\nstability notions termed sample-conditioned hypothesis (SCH) stability. Our\napproach yields sharper bounds that improve upon previous information-theoretic\nbounds in various learning scenarios. Notably, these bounds address the\nlimitations of existing information-theoretic bounds in the context of\nstochastic convex optimization (SCO) problems, as explored in the recent work\nby Haghifam et al. (2023).",
            "author": [
                "Ziqiao Wang",
                "Yongyi Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20102v1",
                "http://arxiv.org/pdf/2310.20102v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20098v1",
            "title": "Robust Learning for Smoothed Online Convex Optimization with Feedback\n  Delay",
            "updated": "2023-10-31T00:22:55Z",
            "published": "2023-10-31T00:22:55Z",
            "summary": "We study a challenging form of Smoothed Online Convex Optimization, a.k.a.\nSOCO, including multi-step nonlinear switching costs and feedback delay. We\npropose a novel machine learning (ML) augmented online algorithm,\nRobustness-Constrained Learning (RCL), which combines untrusted ML predictions\nwith a trusted expert online algorithm via constrained projection to robustify\nthe ML prediction. Specifically,we prove that RCL is able to\nguarantee$(1+\\lambda)$-competitiveness against any given expert for\nany$\\lambda>0$, while also explicitly training the ML model in a\nrobustification-aware manner to improve the average-case performance.\nImportantly,RCL is the first ML-augmented algorithm with a provable robustness\nguarantee in the case of multi-step switching cost and feedback delay.We\ndemonstrate the improvement of RCL in both robustness and average performance\nusing battery management for electrifying transportationas a case study.",
            "author": [
                "Pengfei Li",
                "Jianyi Yang",
                "Adam Wierman",
                "Shaolei Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20098v1",
                "http://arxiv.org/pdf/2310.20098v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20096v1",
            "title": "Data Market Design through Deep Learning",
            "updated": "2023-10-31T00:21:09Z",
            "published": "2023-10-31T00:21:09Z",
            "summary": "The $\\textit{data market design}$ problem is a problem in economic theory to\nfind a set of signaling schemes (statistical experiments) to maximize expected\nrevenue to the information seller, where each experiment reveals some of the\ninformation known to a seller and has a corresponding price [Bergemann et al.,\n2018]. Each buyer has their own decision to make in a world environment, and\ntheir subjective expected value for the information associated with a\nparticular experiment comes from the improvement in this decision and depends\non their prior and value for different outcomes. In a setting with multiple\nbuyers, a buyer's expected value for an experiment may also depend on the\ninformation sold to others [Bonatti et al., 2022]. We introduce the application\nof deep learning for the design of revenue-optimal data markets, looking to\nexpand the frontiers of what can be understood and achieved. Relative to\nearlier work on deep learning for auction design [D\\\"utting et al., 2023], we\nmust learn signaling schemes rather than allocation rules and handle\n$\\textit{obedience constraints}$ $-$ these arising from modeling the downstream\nactions of buyers $-$ in addition to incentive constraints on bids. Our\nexperiments demonstrate that this new deep learning framework can almost\nprecisely replicate all known solutions from theory, expand to more complex\nsettings, and be used to establish the optimality of new designs for data\nmarkets and make conjectures in regard to the structure of optimal designs.",
            "author": [
                "Sai Srivatsa Ravindranath",
                "Yanchen Jiang",
                "David C. Parkes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20096v1",
                "http://arxiv.org/pdf/2310.20096v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20095v1",
            "title": "$p$-Poisson surface reconstruction in curl-free flow from point clouds",
            "updated": "2023-10-31T00:20:24Z",
            "published": "2023-10-31T00:20:24Z",
            "summary": "The aim of this paper is the reconstruction of a smooth surface from an\nunorganized point cloud sampled by a closed surface, with the preservation of\ngeometric shapes, without any further information other than the point cloud.\nImplicit neural representations (INRs) have recently emerged as a promising\napproach to surface reconstruction. However, the reconstruction quality of\nexisting methods relies on ground truth implicit function values or surface\nnormal vectors. In this paper, we show that proper supervision of partial\ndifferential equations and fundamental properties of differential vector fields\nare sufficient to robustly reconstruct high-quality surfaces. We cast the\n$p$-Poisson equation to learn a signed distance function (SDF) and the\nreconstructed surface is implicitly represented by the zero-level set of the\nSDF. For efficient training, we develop a variable splitting structure by\nintroducing a gradient of the SDF as an auxiliary variable and impose the\n$p$-Poisson equation directly on the auxiliary variable as a hard constraint.\nBased on the curl-free property of the gradient field, we impose a curl-free\nconstraint on the auxiliary variable, which leads to a more faithful\nreconstruction. Experiments on standard benchmark datasets show that the\nproposed INR provides a superior and robust reconstruction. The code is\navailable at \\url{https://github.com/Yebbi/PINC}.",
            "author": [
                "Yesom Park",
                "Taekyung Lee",
                "Jooyoung Hahn",
                "Myungjoo Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20095v1",
                "http://arxiv.org/pdf/2310.20095v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20092v1",
            "title": "Beyond U: Making Diffusion Models Faster & Lighter",
            "updated": "2023-10-31T00:12:14Z",
            "published": "2023-10-31T00:12:14Z",
            "summary": "Diffusion models are a family of generative models that yield record-breaking\nperformance in tasks such as image synthesis, video generation, and molecule\ndesign. Despite their capabilities, their efficiency, especially in the reverse\ndenoising process, remains a challenge due to slow convergence rates and high\ncomputational costs. In this work, we introduce an approach that leverages\ncontinuous dynamical systems to design a novel denoising network for diffusion\nmodels that is more parameter-efficient, exhibits faster convergence, and\ndemonstrates increased noise robustness. Experimenting with denoising\nprobabilistic diffusion models, our framework operates with approximately a\nquarter of the parameters and 30% of the Floating Point Operations (FLOPs)\ncompared to standard U-Nets in Denoising Diffusion Probabilistic Models\n(DDPMs). Furthermore, our model is up to 70% faster in inference than the\nbaseline models when measured in equal conditions while converging to better\nquality solutions.",
            "author": [
                "Sergio Calvo-Ordonez",
                "Jiahao Huang",
                "Lipei Zhang",
                "Guang Yang",
                "Carola-Bibiane Schonlieb",
                "Angelica I Aviles-Rivero"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20092v1",
                "http://arxiv.org/pdf/2310.20092v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20090v1",
            "title": "Bridging the Gap Between Variational Inference and Wasserstein Gradient\n  Flows",
            "updated": "2023-10-31T00:10:19Z",
            "published": "2023-10-31T00:10:19Z",
            "summary": "Variational inference is a technique that approximates a target distribution\nby optimizing within the parameter space of variational families. On the other\nhand, Wasserstein gradient flows describe optimization within the space of\nprobability measures where they do not necessarily admit a parametric density\nfunction. In this paper, we bridge the gap between these two methods. We\ndemonstrate that, under certain conditions, the Bures-Wasserstein gradient flow\ncan be recast as the Euclidean gradient flow where its forward Euler scheme is\nthe standard black-box variational inference algorithm. Specifically, the\nvector field of the gradient flow is generated via the path-derivative gradient\nestimator. We also offer an alternative perspective on the path-derivative\ngradient, framing it as a distillation procedure to the Wasserstein gradient\nflow. Distillations can be extended to encompass $f$-divergences and\nnon-Gaussian variational families. This extension yields a new gradient\nestimator for $f$-divergences, readily implementable using contemporary machine\nlearning libraries like PyTorch or TensorFlow.",
            "author": [
                "Mingxuan Yi",
                "Song Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20090v1",
                "http://arxiv.org/pdf/2310.20090v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20089v1",
            "title": "Keyword-optimized Template Insertion for Clinical Information Extraction\n  via Prompt-based Learning",
            "updated": "2023-10-31T00:07:11Z",
            "published": "2023-10-31T00:07:11Z",
            "summary": "Clinical note classification is a common clinical NLP task. However,\nannotated data-sets are scarse. Prompt-based learning has recently emerged as\nan effective method to adapt pre-trained models for text classification using\nonly few training examples. A critical component of prompt design is the\ndefinition of the template (i.e. prompt text). The effect of template position,\nhowever, has been insufficiently investigated. This seems particularly\nimportant in the clinical setting, where task-relevant information is usually\nsparse in clinical notes. In this study we develop a keyword-optimized template\ninsertion method (KOTI) and show how optimizing position can improve\nperformance on several clinical tasks in a zero-shot and few-shot training\nsetting.",
            "author": [
                "Eugenia Alleva",
                "Isotta Landi",
                "Leslee J Shaw",
                "Erwin B\u00f6ttinger",
                "Thomas J Fuchs",
                "Ipek Ensari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20089v1",
                "http://arxiv.org/pdf/2310.20089v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20082v1",
            "title": "Efficient Subgraph GNNs by Learning Effective Selection Policies",
            "updated": "2023-10-30T23:41:05Z",
            "published": "2023-10-30T23:41:05Z",
            "summary": "Subgraph GNNs are provably expressive neural architectures that learn graph\nrepresentations from sets of subgraphs. Unfortunately, their applicability is\nhampered by the computational complexity associated with performing message\npassing on many subgraphs. In this paper, we consider the problem of learning\nto select a small subset of the large set of possible subgraphs in a\ndata-driven fashion. We first motivate the problem by proving that there are\nfamilies of WL-indistinguishable graphs for which there exist efficient\nsubgraph selection policies: small subsets of subgraphs that can already\nidentify all the graphs within the family. We then propose a new approach,\ncalled Policy-Learn, that learns how to select subgraphs in an iterative\nmanner. We prove that, unlike popular random policies and prior work addressing\nthe same problem, our architecture is able to learn the efficient policies\nmentioned above. Our experimental results demonstrate that Policy-Learn\noutperforms existing baselines across a wide range of datasets.",
            "author": [
                "Beatrice Bevilacqua",
                "Moshe Eliasof",
                "Eli Meirom",
                "Bruno Ribeiro",
                "Haggai Maron"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20082v1",
                "http://arxiv.org/pdf/2310.20082v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20079v1",
            "title": "Hybridizing Physics and Neural ODEs for Predicting Plasma Inductance\n  Dynamics in Tokamak Fusion Reactors",
            "updated": "2023-10-30T23:25:54Z",
            "published": "2023-10-30T23:25:54Z",
            "summary": "While fusion reactors known as tokamaks hold promise as a firm energy source,\nadvances in plasma control, and handling of events where control of plasmas is\nlost, are needed for them to be economical. A significant bottleneck towards\napplying more advanced control algorithms is the need for better plasma\nsimulation, where both physics-based and data-driven approaches currently fall\nshort. The former is bottle-necked by both computational cost and the\ndifficulty of modelling plasmas, and the latter is bottle-necked by the\nrelative paucity of data. To address this issue, this work applies the neural\nordinary differential equations (ODE) framework to the problem of predicting a\nsubset of plasma dynamics, namely the coupled plasma current and internal\ninductance dynamics. As the neural ODE framework allows for the natural\ninclusion of physics-based inductive biases, we train both physics-based and\nneural network models on data from the Alcator C-Mod fusion reactor and find\nthat a model that combines physics-based equations with a neural ODE performs\nbetter than both existing physics-motivated ODEs and a pure neural ODE model.",
            "author": [
                "Allen M. Wang",
                "Darren T. Garnier",
                "Cristina Rea"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20079v1",
                "http://arxiv.org/pdf/2310.20079v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20078v1",
            "title": "TorchProbe: Fuzzing Dynamic Deep Learning Compilers",
            "updated": "2023-10-30T23:20:47Z",
            "published": "2023-10-30T23:20:47Z",
            "summary": "Static and dynamic computational graphs represent two distinct approaches to\nconstructing deep learning frameworks. The former prioritizes compiler-based\noptimizations, while the latter focuses on programmability and\nuser-friendliness. The recent release of PyTorch 2.0, which supports compiling\narbitrary deep learning programs in Python, signifies a new direction in the\nevolution of deep learning infrastructure to incorporate compiler techniques in\na more dynamic manner and support more dynamic language features like dynamic\ncontrol flows and closures. Given PyTorch's seamless integration with Python,\nits compiler aims to support arbitrary deep learning code written in Python.\nHowever, the inherent dynamism of Python poses challenges to the completeness\nand robustness of the compiler. While recent research has introduced fuzzing to\ntest deep learning compilers, there is still a lack of comprehensive analysis\non how to test dynamic features. To address this issue, we propose several code\ntransformations to generate test cases involving dynamic features. These\ntransformations preserve the program's semantics, ensuring that any discrepancy\nbetween the transformed and original programs indicates the presence of a bug.\nThrough our approach, we have successfully identified twenty previously unknown\nbugs in the PyTorch compiler and its underlying tensor compiler Triton.",
            "author": [
                "Qidong Su",
                "Chuqin Geng",
                "Gennady Pekhimenko",
                "Xujie Si"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20078v1",
                "http://arxiv.org/pdf/2310.20078v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20077v1",
            "title": "Partial Tensorized Transformers for Natural Language Processing",
            "updated": "2023-10-30T23:19:06Z",
            "published": "2023-10-30T23:19:06Z",
            "summary": "The transformer architecture has revolutionized Natural Language Processing\n(NLP) and other machine-learning tasks, due to its unprecedented accuracy.\nHowever, their extensive memory and parameter requirements often hinder their\npractical applications. In this work, we study the effect of tensor-train\ndecomposition to improve the accuracy and compress transformer vision-language\nneural networks, namely BERT and ViT. We focus both on embedding-layer\ncompression and partial tensorization of neural networks (PTNN) through an\nalgorithmic approach. Our novel PTNN approach significantly improves the\naccuracy of existing models by up to 5%, all without the need for post-training\nadjustments, breaking new ground in the field of tensor decomposition.",
            "author": [
                "Subhadra Vadlamannati",
                "Ryan Solgi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20077v1",
                "http://arxiv.org/pdf/2310.20077v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20075v1",
            "title": "Meek Separators and Their Applications in Targeted Causal Discovery",
            "updated": "2023-10-30T23:15:27Z",
            "published": "2023-10-30T23:15:27Z",
            "summary": "Learning causal structures from interventional data is a fundamental problem\nwith broad applications across various fields. While many previous works have\nfocused on recovering the entire causal graph, in practice, there are scenarios\nwhere learning only part of the causal graph suffices. This is called\n$targeted$ causal discovery. In our work, we focus on two such well-motivated\nproblems: subset search and causal matching. We aim to minimize the number of\ninterventions in both cases.\n  Towards this, we introduce the $Meek~separator$, which is a subset of\nvertices that, when intervened, decomposes the remaining unoriented edges into\nsmaller connected components. We then present an efficient algorithm to find\nMeek separators that are of small sizes. Such a procedure is helpful in\ndesigning various divide-and-conquer-based approaches. In particular, we\npropose two randomized algorithms that achieve logarithmic approximation for\nsubset search and causal matching, respectively. Our results provide the first\nknown average-case provable guarantees for both problems. We believe that this\nopens up possibilities to design near-optimal methods for many other targeted\ncausal structure learning problems arising from various applications.",
            "author": [
                "Kirankumar Shiragur",
                "Jiaqi Zhang",
                "Caroline Uhler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20075v1",
                "http://arxiv.org/pdf/2310.20075v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DM",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20072v1",
            "title": "Automatic Evaluation of Generative Models with Instruction Tuning",
            "updated": "2023-10-30T23:00:52Z",
            "published": "2023-10-30T23:00:52Z",
            "summary": "Automatic evaluation of natural language generation has long been an elusive\ngoal in NLP.A recent paradigm fine-tunes pre-trained language models to emulate\nhuman judgements for a particular task and evaluation criterion. Inspired by\nthe generalization ability of instruction-tuned models, we propose a learned\nmetric based on instruction tuning. To test our approach, we collected HEAP, a\ndataset of human judgements across various NLG tasks and evaluation criteria.\nOur findings demonstrate that instruction tuning language models on HEAP yields\ngood performance on many evaluation tasks, though some criteria are less\ntrivial to learn than others. Further, jointly training on multiple tasks can\nyield additional performance improvements, which can be beneficial for future\ntasks with little to no human annotated data.",
            "author": [
                "Shuhaib Mehri",
                "Vered Shwartz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20072v1",
                "http://arxiv.org/pdf/2310.20072v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20071v1",
            "title": "FOCAL: Contrastive Learning for Multimodal Time-Series Sensing Signals\n  in Factorized Orthogonal Latent Space",
            "updated": "2023-10-30T22:55:29Z",
            "published": "2023-10-30T22:55:29Z",
            "summary": "This paper proposes a novel contrastive learning framework, called FOCAL, for\nextracting comprehensive features from multimodal time-series sensing signals\nthrough self-supervised training. Existing multimodal contrastive frameworks\nmostly rely on the shared information between sensory modalities, but do not\nexplicitly consider the exclusive modality information that could be critical\nto understanding the underlying sensing physics. Besides, contrastive\nframeworks for time series have not handled the temporal information locality\nappropriately. FOCAL solves these challenges by making the following\ncontributions: First, given multimodal time series, it encodes each modality\ninto a factorized latent space consisting of shared features and private\nfeatures that are orthogonal to each other. The shared space emphasizes feature\npatterns consistent across sensory modalities through a modal-matching\nobjective. In contrast, the private space extracts modality-exclusive\ninformation through a transformation-invariant objective. Second, we propose a\ntemporal structural constraint for modality features, such that the average\ndistance between temporally neighboring samples is no larger than that of\ntemporally distant samples. Extensive evaluations are performed on four\nmultimodal sensing datasets with two backbone encoders and two classifiers to\ndemonstrate the superiority of FOCAL. It consistently outperforms the\nstate-of-the-art baselines in downstream tasks with a clear margin, under\ndifferent ratios of available labels. The code and self-collected dataset are\navailable at https://github.com/tomoyoshki/focal.",
            "author": [
                "Shengzhong Liu",
                "Tomoyoshi Kimura",
                "Dongxin Liu",
                "Ruijie Wang",
                "Jinyang Li",
                "Suhas Diggavi",
                "Mani Srivastava",
                "Tarek Abdelzaher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20071v1",
                "http://arxiv.org/pdf/2310.20071v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20067v1",
            "title": "Vignat: Vulnerability identification by learning code semantics via\n  graph attention networks",
            "updated": "2023-10-30T22:31:38Z",
            "published": "2023-10-30T22:31:38Z",
            "summary": "Vulnerability identification is crucial to protect software systems from\nattacks for cyber-security. However, huge projects have more than millions of\nlines of code, and the complex dependencies make it hard to carry out\ntraditional static and dynamic methods. Furthermore, the semantic structure of\nvarious types of vulnerabilities differs greatly and may occur simultaneously,\nmaking general rule-based methods difficult to extend. In this paper, we\npropose \\textit{Vignat}, a novel attention-based framework for identifying\nvulnerabilities by learning graph-level semantic representations of code. We\nrepresent codes with code property graphs (CPGs) in fine grain and use graph\nattention networks (GATs) for vulnerability detection. The results show that\nVignat is able to achieve $57.38\\%$ accuracy on reliable datasets derived from\npopular C libraries. Furthermore, the interpretability of our GATs provides\nvaluable insights into vulnerability patterns.",
            "author": [
                "Shuo Liu",
                "Gail Kaiser"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20067v1",
                "http://arxiv.org/pdf/2310.20067v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20065v1",
            "title": "LinFlo-Net: A two-stage deep learning method to generate simulation\n  ready meshes of the heart",
            "updated": "2023-10-30T22:29:50Z",
            "published": "2023-10-30T22:29:50Z",
            "summary": "We present a deep learning model to automatically generate computer models of\nthe human heart from patient imaging data with an emphasis on its capability to\ngenerate thin-walled cardiac structures. Our method works by deforming a\ntemplate mesh to fit the cardiac structures to the given image. Compared with\nprior deep learning methods that adopted this approach, our framework is\ndesigned to minimize mesh self-penetration, which typically arises when\ndeforming surface meshes separated by small distances. We achieve this by using\na two-stage diffeomorphic deformation process along with a novel loss function\nderived from the kinematics of motion that penalizes surface contact and\ninterpenetration. Our model demonstrates comparable accuracy with\nstate-of-the-art methods while additionally producing meshes free of\nself-intersections. The resultant meshes are readily usable in physics based\nsimulation, minimizing the need for post-processing and cleanup.",
            "author": [
                "Arjun Narayanan",
                "Fanwei Kong",
                "Shawn Shadden"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20065v1",
                "http://arxiv.org/pdf/2310.20065v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20064v1",
            "title": "A Scalable Training Strategy for Blind Multi-Distribution Noise Removal",
            "updated": "2023-10-30T22:29:07Z",
            "published": "2023-10-30T22:29:07Z",
            "summary": "Despite recent advances, developing general-purpose universal denoising and\nartifact-removal networks remains largely an open problem: Given fixed network\nweights, one inherently trades-off specialization at one task (e.g.,~removing\nPoisson noise) for performance at another (e.g.,~removing speckle noise). In\naddition, training such a network is challenging due to the curse of\ndimensionality: As one increases the dimensions of the specification-space\n(i.e.,~the number of parameters needed to describe the noise distribution) the\nnumber of unique specifications one needs to train for grows exponentially.\nUniformly sampling this space will result in a network that does well at very\nchallenging problem specifications but poorly at easy problem specifications,\nwhere even large errors will have a small effect on the overall mean squared\nerror.\n  In this work we propose training denoising networks using an\nadaptive-sampling/active-learning strategy. Our work improves upon a recently\nproposed universal denoiser training strategy by extending these results to\nhigher dimensions and by incorporating a polynomial approximation of the true\nspecification-loss landscape. This approximation allows us to reduce training\ntimes by almost two orders of magnitude. We test our method on simulated joint\nPoisson-Gaussian-Speckle noise and demonstrate that with our proposed training\nstrategy, a single blind, generalist denoiser network can achieve peak\nsignal-to-noise ratios within a uniform bound of specialized denoiser networks\nacross a large range of operating conditions. We also capture a small dataset\nof images with varying amounts of joint Poisson-Gaussian-Speckle noise and\ndemonstrate that a universal denoiser trained using our adaptive-sampling\nstrategy outperforms uniformly trained baselines.",
            "author": [
                "Kevin Zhang",
                "Sakshum Kulshrestha",
                "Christopher Metzler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20064v1",
                "http://arxiv.org/pdf/2310.20064v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20062v1",
            "title": "Decentralised, Scalable and Privacy-Preserving Synthetic Data Generation",
            "updated": "2023-10-30T22:27:32Z",
            "published": "2023-10-30T22:27:32Z",
            "summary": "Synthetic data is emerging as a promising way to harness the value of data,\nwhile reducing privacy risks. The potential of synthetic data is not limited to\nprivacy-friendly data release, but also includes complementing real data in\nuse-cases such as training machine learning algorithms that are more fair and\nrobust to distribution shifts etc. There is a lot of interest in algorithmic\nadvances in synthetic data generation for providing better privacy and\nstatistical guarantees and for its better utilisation in machine learning\npipelines. However, for responsible and trustworthy synthetic data generation,\nit is not sufficient to focus only on these algorithmic aspects and instead, a\nholistic view of the synthetic data generation pipeline must be considered. We\nbuild a novel system that allows the contributors of real data to autonomously\nparticipate in differentially private synthetic data generation without relying\non a trusted centre. Our modular, general and scalable solution is based on\nthree building blocks namely: Solid (Social Linked Data), MPC (Secure\nMulti-Party Computation) and Trusted Execution Environments (TEEs). Solid is a\nspecification that lets people store their data securely in decentralised data\nstores called Pods and control access to their data. MPC refers to the set of\ncryptographic methods for different parties to jointly compute a function over\ntheir inputs while keeping those inputs private. TEEs such as Intel SGX rely on\nhardware based features for confidentiality and integrity of code and data. We\nshow how these three technologies can be effectively used to address various\nchallenges in responsible and trustworthy synthetic data generation by\nensuring: 1) contributor autonomy, 2) decentralisation, 3) privacy and 4)\nscalability. We support our claims with rigorous empirical results on simulated\nand real datasets and different synthetic data generation algorithms.",
            "author": [
                "Vishal Ramesh",
                "Rui Zhao",
                "Naman Goel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20062v1",
                "http://arxiv.org/pdf/2310.20062v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20060v2",
            "title": "AdaSub: Stochastic Optimization Using Second-Order Information in\n  Low-Dimensional Subspaces",
            "updated": "2023-11-06T21:37:33Z",
            "published": "2023-10-30T22:24:23Z",
            "summary": "We introduce AdaSub, a stochastic optimization algorithm that computes a\nsearch direction based on second-order information in a low-dimensional\nsubspace that is defined adaptively based on available current and past\ninformation. Compared to first-order methods, second-order methods exhibit\nbetter convergence characteristics, but the need to compute the Hessian matrix\nat each iteration results in excessive computational expenses, making them\nimpractical. To address this issue, our approach enables the management of\ncomputational expenses and algorithm efficiency by enabling the selection of\nthe subspace dimension for the search. Our code is freely available on GitHub,\nand our preliminary numerical results demonstrate that AdaSub surpasses popular\nstochastic optimizers in terms of time and number of iterations required to\nreach a given accuracy.",
            "author": [
                "Jo\u00e3o Victor Galv\u00e3o da Mata",
                "Martin S. Andersen"
            ],
            "link": [
                "http://dx.doi.org/10.1109/DSAA60987.2023.10302473",
                "http://arxiv.org/abs/2310.20060v2",
                "http://arxiv.org/pdf/2310.20060v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20059v1",
            "title": "Concept Alignment as a Prerequisite for Value Alignment",
            "updated": "2023-10-30T22:23:15Z",
            "published": "2023-10-30T22:23:15Z",
            "summary": "Value alignment is essential for building AI systems that can safely and\nreliably interact with people. However, what a person values -- and is even\ncapable of valuing -- depends on the concepts that they are currently using to\nunderstand and evaluate what happens in the world. The dependence of values on\nconcepts means that concept alignment is a prerequisite for value alignment --\nagents need to align their representation of a situation with that of humans in\norder to successfully align their values. Here, we formally analyze the concept\nalignment problem in the inverse reinforcement learning setting, show how\nneglecting concept alignment can lead to systematic value mis-alignment, and\ndescribe an approach that helps minimize such failure modes by jointly\nreasoning about a person's concepts and values. Additionally, we report\nexperimental results with human participants showing that humans reason about\nthe concepts used by an agent when acting intentionally, in line with our joint\nreasoning model.",
            "author": [
                "Sunayana Rane",
                "Mark Ho",
                "Ilia Sucholutsky",
                "Thomas L. Griffiths"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20059v1",
                "http://arxiv.org/pdf/2310.20059v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20056v1",
            "title": "On the data-driven description of lattice materials mechanics",
            "updated": "2023-10-30T22:21:08Z",
            "published": "2023-10-30T22:21:08Z",
            "summary": "In the emerging field of mechanical metamaterials, using periodic lattice\nstructures as a primary ingredient is relatively frequent. However, the choice\nof aperiodic lattices in these structures presents unique advantages regarding\nfailure, e.g., buckling or fracture, because avoiding repeated patterns\nprevents global failures, with local failures occurring in turn that can\nbeneficially delay structural collapse. Therefore, it is expedient to develop\nmodels for computing efficiently the effective mechanical properties in\nlattices from different general features while addressing the challenge of\npresenting topologies (or graphs) of different sizes. In this paper, we develop\na deep learning model to predict energetically-equivalent mechanical properties\nof linear elastic lattices effectively. Considering the lattice as a graph and\ndefining material and geometrical features on such, we show that Graph Neural\nNetworks provide more accurate predictions than a dense, fully connected\nstrategy, thanks to the geometrically induced bias through graph\nrepresentation, closer to the underlying equilibrium laws from mechanics solved\nin the direct problem. Leveraging the efficient forward-evaluation of a vast\nnumber of lattices using this surrogate enables the inverse problem, i.e., to\nobtain a structure having prescribed specific behavior, which is ultimately\nsuitable for multiscale structural optimization problems.",
            "author": [
                "Ismael Ben-Yelun",
                "Luis Irastorza-Valera",
                "Luis Saucedo-Mora",
                "Francisco Javier Mont\u00e1ns",
                "Francisco Chinesta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20056v1",
                "http://arxiv.org/pdf/2310.20056v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20053v1",
            "title": "Estimating optimal PAC-Bayes bounds with Hamiltonian Monte Carlo",
            "updated": "2023-10-30T22:16:51Z",
            "published": "2023-10-30T22:16:51Z",
            "summary": "An important yet underexplored question in the PAC-Bayes literature is how\nmuch tightness we lose by restricting the posterior family to factorized\nGaussian distributions when optimizing a PAC-Bayes bound. We investigate this\nissue by estimating data-independent PAC-Bayes bounds using the optimal\nposteriors, comparing them to bounds obtained using MFVI. Concretely, we (1)\nsample from the optimal Gibbs posterior using Hamiltonian Monte Carlo, (2)\nestimate its KL divergence from the prior with thermodynamic integration, and\n(3) propose three methods to obtain high-probability bounds under different\nassumptions. Our experiments on the MNIST dataset reveal significant tightness\ngaps, as much as 5-6\\% in some cases.",
            "author": [
                "Szilvia Ujv\u00e1ry",
                "Gergely Flamich",
                "Vincent Fortuin",
                "Jos\u00e9 Miguel Hern\u00e1ndez Lobato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20053v1",
                "http://arxiv.org/pdf/2310.20053v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20052v1",
            "title": "Look At Me, No Replay! SurpriseNet: Anomaly Detection Inspired Class\n  Incremental Learning",
            "updated": "2023-10-30T22:16:26Z",
            "published": "2023-10-30T22:16:26Z",
            "summary": "Continual learning aims to create artificial neural networks capable of\naccumulating knowledge and skills through incremental training on a sequence of\ntasks. The main challenge of continual learning is catastrophic interference,\nwherein new knowledge overrides or interferes with past knowledge, leading to\nforgetting. An associated issue is the problem of learning \"cross-task\nknowledge,\" where models fail to acquire and retain knowledge that helps\ndifferentiate classes across task boundaries. A common solution to both\nproblems is \"replay,\" where a limited buffer of past instances is utilized to\nlearn cross-task knowledge and mitigate catastrophic interference. However, a\nnotable drawback of these methods is their tendency to overfit the limited\nreplay buffer. In contrast, our proposed solution, SurpriseNet, addresses\ncatastrophic interference by employing a parameter isolation method and\nlearning cross-task knowledge using an auto-encoder inspired by anomaly\ndetection. SurpriseNet is applicable to both structured and unstructured data,\nas it does not rely on image-specific inductive biases. We have conducted\nempirical experiments demonstrating the strengths of SurpriseNet on various\ntraditional vision continual-learning benchmarks, as well as on structured data\ndatasets. Source code made available at https://doi.org/10.5281/zenodo.8247906\nand https://github.com/tachyonicClock/SurpriseNet-CIKM-23",
            "author": [
                "Anton Lee",
                "Yaqian Zhang",
                "Heitor Murilo Gomes",
                "Albert Bifet",
                "Bernhard Pfahringer"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615236",
                "http://arxiv.org/abs/2310.20052v1",
                "http://arxiv.org/pdf/2310.20052v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20051v1",
            "title": "The Expressibility of Polynomial based Attention Scheme",
            "updated": "2023-10-30T22:16:18Z",
            "published": "2023-10-30T22:16:18Z",
            "summary": "Large language models (LLMs) have significantly improved various aspects of\nour daily lives. These models have impacted numerous domains, from healthcare\nto education, enhancing productivity, decision-making processes, and\naccessibility. As a result, they have influenced and, to some extent, reshaped\npeople's lifestyles. However, the quadratic complexity of attention in\ntransformer architectures poses a challenge when scaling up these models for\nprocessing long textual contexts. This issue makes it impractical to train very\nlarge models on lengthy texts or use them efficiently during inference. While a\nrecent study by [KMZ23] introduced a technique that replaces the softmax with a\npolynomial function and polynomial sketching to speed up attention mechanisms,\nthe theoretical understandings of this new approach are not yet well\nunderstood.\n  In this paper, we offer a theoretical analysis of the expressive capabilities\nof polynomial attention. Our study reveals a disparity in the ability of\nhigh-degree and low-degree polynomial attention. Specifically, we construct two\ncarefully designed datasets, namely $\\mathcal{D}_0$ and $\\mathcal{D}_1$, where\n$\\mathcal{D}_1$ includes a feature with a significantly larger value compared\nto $\\mathcal{D}_0$. We demonstrate that with a sufficiently high degree\n$\\beta$, a single-layer polynomial attention network can distinguish between\n$\\mathcal{D}_0$ and $\\mathcal{D}_1$. However, with a low degree $\\beta$, the\nnetwork cannot effectively separate the two datasets. This analysis underscores\nthe greater effectiveness of high-degree polynomials in amplifying large values\nand distinguishing between datasets. Our analysis offers insight into the\nrepresentational capacity of polynomial attention and provides a rationale for\nincorporating higher-degree polynomials in attention mechanisms to capture\nintricate linguistic correlations.",
            "author": [
                "Zhao Song",
                "Guangyi Xu",
                "Junze Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20051v1",
                "http://arxiv.org/pdf/2310.20051v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20049v3",
            "title": "SURF: A Generalization Benchmark for GNNs Predicting Fluid Dynamics",
            "updated": "2023-11-20T15:16:59Z",
            "published": "2023-10-30T22:12:35Z",
            "summary": "Simulating fluid dynamics is crucial for the design and development process,\nranging from simple valves to complex turbomachinery. Accurately solving the\nunderlying physical equations is computationally expensive. Therefore,\nlearning-based solvers that model interactions on meshes have gained interest\ndue to their promising speed-ups. However, it is unknown to what extent these\nmodels truly understand the underlying physical principles and can generalize\nrather than interpolate. Generalization is a key requirement for a\ngeneral-purpose fluid simulator, which should adapt to different topologies,\nresolutions, or thermodynamic ranges. We propose SURF, a benchmark designed to\ntest the $\\textit{generalization}$ of learned graph-based fluid simulators.\nSURF comprises individual datasets and provides specific performance and\ngeneralization metrics for evaluating and comparing different models. We\nempirically demonstrate the applicability of SURF by thoroughly investigating\nthe two state-of-the-art graph-based models, yielding new insights into their\ngeneralization.",
            "author": [
                "Stefan K\u00fcnzli",
                "Florian Gr\u00f6tschla",
                "Jo\u00ebl Mathys",
                "Roger Wattenhofer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20049v3",
                "http://arxiv.org/pdf/2310.20049v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20046v1",
            "title": "Which Examples to Annotate for In-Context Learning? Towards Effective\n  and Efficient Selection",
            "updated": "2023-10-30T22:03:55Z",
            "published": "2023-10-30T22:03:55Z",
            "summary": "Large Language Models (LLMs) can adapt to new tasks via in-context learning\n(ICL). ICL is efficient as it does not require any parameter updates to the\ntrained LLM, but only few annotated examples as input for the LLM. In this\nwork, we investigate an active learning approach for ICL, where there is a\nlimited budget for annotating examples. We propose a model-adaptive\noptimization-free algorithm, termed AdaICL, which identifies examples that the\nmodel is uncertain about, and performs semantic diversity-based example\nselection. Diversity-based sampling improves overall effectiveness, while\nuncertainty sampling improves budget efficiency and helps the LLM learn new\ninformation. Moreover, AdaICL poses its sampling strategy as a Maximum Coverage\nproblem, that dynamically adapts based on the model's feedback and can be\napproximately solved via greedy algorithms. Extensive experiments on nine\ndatasets and seven LLMs show that AdaICL improves performance by 4.4% accuracy\npoints over SOTA (7.7% relative improvement), is up to 3x more budget-efficient\nthan performing annotations uniformly at random, while it outperforms SOTA with\n2x fewer ICL examples.",
            "author": [
                "Costas Mavromatis",
                "Balasubramaniam Srinivasan",
                "Zhengyuan Shen",
                "Jiani Zhang",
                "Huzefa Rangwala",
                "Christos Faloutsos",
                "George Karypis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20046v1",
                "http://arxiv.org/pdf/2310.20046v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02099v1",
            "title": "A Preference Learning Approach to Develop Safe and Personalizable\n  Autonomous Vehicles",
            "updated": "2023-10-30T21:52:37Z",
            "published": "2023-10-30T21:52:37Z",
            "summary": "This work introduces a preference learning method that ensures adherence to\ntraffic rules for autonomous vehicles. Our approach incorporates priority\nordering of signal temporal logic (STL) formulas, describing traffic rules,\ninto a learning framework. By leveraging the parametric weighted signal\ntemporal logic (PWSTL), we formulate the problem of safety-guaranteed\npreference learning based on pairwise comparisons, and propose an approach to\nsolve this learning problem. Our approach finds a feasible valuation for the\nweights of the given PWSTL formula such that, with these weights, preferred\nsignals have weighted quantitative satisfaction measures greater than their\nnon-preferred counterparts. The feasible valuation of weights given by our\napproach leads to a weighted STL formula which can be used in\ncorrect-and-custom-by-construction controller synthesis. We demonstrate the\nperformance of our method with human subject studies in two different simulated\ndriving scenarios involving a stop sign and a pedestrian crossing. Our approach\nyields competitive results compared to existing preference learning methods in\nterms of capturing preferences, and notably outperforms them when safety is\nconsidered.",
            "author": [
                "Ruya Karagulle",
                "Nikos Arechiga",
                "Andrew Best",
                "Jonathan DeCastro",
                "Necmiye Ozay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02099v1",
                "http://arxiv.org/pdf/2311.02099v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01469v1",
            "title": "Leveraging Language Models to Detect Greenwashing",
            "updated": "2023-10-30T21:41:49Z",
            "published": "2023-10-30T21:41:49Z",
            "summary": "In recent years, climate change repercussions have increasingly captured\npublic interest. Consequently, corporations are emphasizing their environmental\nefforts in sustainability reports to bolster their public image. Yet, the\nabsence of stringent regulations in review of such reports allows potential\ngreenwashing. In this study, we introduce a novel methodology to train a\nlanguage model on generated labels for greenwashing risk. Our primary\ncontributions encompass: developing a mathematical formulation to quantify\ngreenwashing risk, a fine-tuned ClimateBERT model for this problem, and a\ncomparative analysis of results. On a test set comprising of sustainability\nreports, our best model achieved an average accuracy score of 86.34% and F1\nscore of 0.67, demonstrating that our methods show a promising direction of\nexploration for this task.",
            "author": [
                "Avalon Vinella",
                "Margaret Capetz",
                "Rebecca Pattichis",
                "Christina Chance",
                "Reshmi Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01469v1",
                "http://arxiv.org/pdf/2311.01469v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20030v1",
            "title": "Scaling Riemannian Diffusion Models",
            "updated": "2023-10-30T21:27:53Z",
            "published": "2023-10-30T21:27:53Z",
            "summary": "Riemannian diffusion models draw inspiration from standard Euclidean space\ndiffusion models to learn distributions on general manifolds. Unfortunately,\nthe additional geometric complexity renders the diffusion transition term\ninexpressible in closed form, so prior methods resort to imprecise\napproximations of the score matching training objective that degrade\nperformance and preclude applications in high dimensions. In this work, we\nreexamine these approximations and propose several practical improvements. Our\nkey observation is that most relevant manifolds are symmetric spaces, which are\nmuch more amenable to computation. By leveraging and combining various\nans\\\"{a}tze, we can quickly compute relevant quantities to high precision. On\nlow dimensional datasets, our correction produces a noticeable improvement,\nallowing diffusion to compete with other methods. Additionally, we show that\nour method enables us to scale to high dimensional tasks on nontrivial\nmanifolds. In particular, we model QCD densities on $SU(n)$ lattices and\ncontrastively learned embeddings on high dimensional hyperspheres.",
            "author": [
                "Aaron Lou",
                "Minkai Xu",
                "Stefano Ermon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20030v1",
                "http://arxiv.org/pdf/2310.20030v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.DG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20025v1",
            "title": "GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with\n  Learned Models",
            "updated": "2023-10-30T21:19:52Z",
            "published": "2023-10-30T21:19:52Z",
            "summary": "Offline goal-conditioned RL (GCRL) offers a feasible paradigm to learn\ngeneral-purpose policies from diverse and multi-task offline datasets. Despite\nnotable recent progress, the predominant offline GCRL methods have been\nrestricted to model-free approaches, constraining their capacity to tackle\nlimited data budgets and unseen goal generalization. In this work, we propose a\nnovel two-stage model-based framework, Goal-conditioned Offline Planning\n(GOPlan), including (1) pretraining a prior policy capable of capturing\nmulti-modal action distribution within the multi-goal dataset; (2) employing\nthe reanalysis method with planning to generate imagined trajectories for\nfunetuning policies. Specifically, the prior policy is based on an\nadvantage-weighted Conditioned Generative Adversarial Networks that exhibits\ndistinct mode separation to overcome the pitfalls of out-of-distribution (OOD)\nactions. For further policy optimization, the reanalysis method generates\nhigh-quality imaginary data by planning with learned models for both\nintra-trajectory and inter-trajectory goals. Through experimental evaluations,\nwe demonstrate that GOPlan achieves state-of-the-art performance on various\noffline multi-goal manipulation tasks. Moreover, our results highlight the\nsuperior ability of GOPlan to handle small data budgets and generalize to OOD\ngoals.",
            "author": [
                "Mianchu Wang",
                "Rui Yang",
                "Xi Chen",
                "Meng Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20025v1",
                "http://arxiv.org/pdf/2310.20025v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20024v1",
            "title": "Topology Recoverability Prediction for Ad-Hoc Robot Networks: A\n  Data-Driven Fault-Tolerant Approach",
            "updated": "2023-10-30T21:16:46Z",
            "published": "2023-10-30T21:16:46Z",
            "summary": "Faults occurring in ad-hoc robot networks may fatally perturb their\ntopologies leading to disconnection of subsets of those networks. Optimal\ntopology synthesis is generally resource-intensive and time-consuming to be\ndone in real time for large ad-hoc robot networks. One should only perform\ntopology re-computations if the probability of topology recoverability after\nthe occurrence of any fault surpasses that of its irrecoverability. We\nformulate this problem as a binary classification problem. Then, we develop a\ntwo-pathway data-driven model based on Bayesian Gaussian mixture models that\npredicts the solution to a typical problem by two different pre-fault and\npost-fault prediction pathways. The results, obtained by the integration of the\npredictions of those pathways, clearly indicate the success of our model in\nsolving the topology (ir)recoverability prediction problem compared to the best\nof current strategies found in the literature.",
            "author": [
                "Matin Macktoobian",
                "Zhan Shu",
                "Qing Zhao"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TSIPN.2023.3328275",
                "http://arxiv.org/abs/2310.20024v1",
                "http://arxiv.org/pdf/2310.20024v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20012v1",
            "title": "Multiscale Feature Attribution for Outliers",
            "updated": "2023-10-30T20:58:28Z",
            "published": "2023-10-30T20:58:28Z",
            "summary": "Machine learning techniques can automatically identify outliers in massive\ndatasets, much faster and more reproducible than human inspection ever could.\nBut finding such outliers immediately leads to the question: which features\nrender this input anomalous? We propose a new feature attribution method,\nInverse Multiscale Occlusion, that is specifically designed for outliers, for\nwhich we have little knowledge of the type of features we want to identify and\nexpect that the model performance is questionable because anomalous test data\nlikely exceed the limits of the training data. We demonstrate our method on\noutliers detected in galaxy spectra from the Dark Energy Survey Instrument and\nfind its results to be much more interpretable than alternative attribution\napproaches.",
            "author": [
                "Jeff Shen",
                "Peter Melchior"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20012v1",
                "http://arxiv.org/pdf/2310.20012v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "astro-ph.IM",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.20007v1",
            "title": "Improved Bayesian Regret Bounds for Thompson Sampling in Reinforcement\n  Learning",
            "updated": "2023-10-30T20:53:02Z",
            "published": "2023-10-30T20:53:02Z",
            "summary": "In this paper, we prove the first Bayesian regret bounds for Thompson\nSampling in reinforcement learning in a multitude of settings. We simplify the\nlearning problem using a discrete set of surrogate environments, and present a\nrefined analysis of the information ratio using posterior consistency. This\nleads to an upper bound of order $\\widetilde{O}(H\\sqrt{d_{l_1}T})$ in the time\ninhomogeneous reinforcement learning problem where $H$ is the episode length\nand $d_{l_1}$ is the Kolmogorov $l_1-$dimension of the space of environments.\nWe then find concrete bounds of $d_{l_1}$ in a variety of settings, such as\ntabular, linear and finite mixtures, and discuss how how our results are either\nthe first of their kind or improve the state-of-the-art.",
            "author": [
                "Ahmadreza Moradipari",
                "Mohammad Pedramfar",
                "Modjtaba Shokrian Zini",
                "Vaneet Aggarwal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.20007v1",
                "http://arxiv.org/pdf/2310.20007v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19998v1",
            "title": "Generative retrieval-augmented ontologic graph and multi-agent\n  strategies for interpretive large language model-based materials design",
            "updated": "2023-10-30T20:31:50Z",
            "published": "2023-10-30T20:31:50Z",
            "summary": "Transformer neural networks show promising capabilities, in particular for\nuses in materials analysis, design and manufacturing, including their capacity\nto work effectively with both human language, symbols, code, and numerical\ndata. Here we explore the use of large language models (LLMs) as a tool that\ncan support engineering analysis of materials, applied to retrieving key\ninformation about subject areas, developing research hypotheses, discovery of\nmechanistic relationships across disparate areas of knowledge, and writing and\nexecuting simulation codes for active knowledge generation based on physical\nground truths. When used as sets of AI agents with specific features,\ncapabilities, and instructions, LLMs can provide powerful problem solution\nstrategies for applications in analysis and design problems. Our experiments\nfocus on using a fine-tuned model, MechGPT, developed based on training data in\nthe mechanics of materials domain. We first affirm how finetuning endows LLMs\nwith reasonable understanding of domain knowledge. However, when queried\noutside the context of learned matter, LLMs can have difficulty to recall\ncorrect information. We show how this can be addressed using\nretrieval-augmented Ontological Knowledge Graph strategies that discern how the\nmodel understands what concepts are important and how they are related.\nIllustrated for a use case of relating distinct areas of knowledge - here,\nmusic and proteins - such strategies can also provide an interpretable graph\nstructure with rich information at the node, edge and subgraph level. We\ndiscuss nonlinear sampling strategies and agent-based modeling applied to\ncomplex question answering, code generation and execution in the context of\nautomated force field development from actively learned Density Functional\nTheory (DFT) modeling, and data analysis.",
            "author": [
                "Markus J. Buehler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19998v1",
                "http://arxiv.org/pdf/2310.19998v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cond-mat.dis-nn",
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19997v1",
            "title": "State-Dependent Dynamic Tube MPC: A Novel Tube MPC Method with a Fuzzy\n  Model of Disturbances",
            "updated": "2023-10-30T20:30:12Z",
            "published": "2023-10-30T20:30:12Z",
            "summary": "Most real-world systems are affected by external disturbances, which may be\nimpossible or costly to measure. For instance, when autonomous robots move in\ndusty environments, the perception of their sensors is disturbed. Moreover,\nuneven terrains can cause ground robots to deviate from their planned\ntrajectories. Thus, learning the external disturbances and incorporating this\nknowledge into the future predictions in decision-making can significantly\ncontribute to improved performance. Our core idea is to learn the external\ndisturbances that vary with the states of the system, and to incorporate this\nknowledge into a novel formulation for robust tube model predictive control\n(TMPC). Robust TMPC provides robustness to bounded disturbances considering the\nknown (fixed) upper bound of the disturbances, but it does not consider the\ndynamics of the disturbances. This can lead to highly conservative solutions.\nWe propose a new dynamic version of robust TMPC (with proven robust stability),\ncalled state-dependent dynamic TMPC (SDD-TMPC), which incorporates the dynamics\nof the disturbances into the decision-making of TMPC. In order to learn the\ndynamics of the disturbances as a function of the system states, a fuzzy model\nis proposed. We compare the performance of SDD-TMPC, MPC, and TMPC via\nsimulations, in designed search-and-rescue scenarios. The results show that,\nwhile remaining robust to bounded external disturbances, SDD-TMPC generates\nless conservative solutions and remains feasible in more cases, compared to\nTMPC.",
            "author": [
                "Filip Surma",
                "Anahita Jamshidnejad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19997v1",
                "http://arxiv.org/pdf/2310.19997v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "93B45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19996v1",
            "title": "Adaptive Anchor Label Propagation for Transductive Few-Shot Learning",
            "updated": "2023-10-30T20:29:31Z",
            "published": "2023-10-30T20:29:31Z",
            "summary": "Few-shot learning addresses the issue of classifying images using limited\nlabeled data. Exploiting unlabeled data through the use of transductive\ninference methods such as label propagation has been shown to improve the\nperformance of few-shot learning significantly. Label propagation infers\npseudo-labels for unlabeled data by utilizing a constructed graph that exploits\nthe underlying manifold structure of the data. However, a limitation of the\nexisting label propagation approaches is that the positions of all data points\nare fixed and might be sub-optimal so that the algorithm is not as effective as\npossible. In this work, we propose a novel algorithm that adapts the feature\nembeddings of the labeled data by minimizing a differentiable loss function\noptimizing their positions in the manifold in the process. Our novel algorithm,\nAdaptive Anchor Label Propagation}, outperforms the standard label propagation\nalgorithm by as much as 7% and 2% in the 1-shot and 5-shot settings\nrespectively. We provide experimental results highlighting the merits of our\nalgorithm on four widely used few-shot benchmark datasets, namely miniImageNet,\ntieredImageNet, CUB and CIFAR-FS and two commonly used backbones, ResNet12 and\nWideResNet-28-10. The source code can be found at\nhttps://github.com/MichalisLazarou/A2LP.",
            "author": [
                "Michalis Lazarou",
                "Yannis Avrithis",
                "Guangyu Ren",
                "Tania Stathaki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19996v1",
                "http://arxiv.org/pdf/2310.19996v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01605v1",
            "title": "Faithful and Robust Local Interpretability for Textual Predictions",
            "updated": "2023-10-30T20:27:36Z",
            "published": "2023-10-30T20:27:36Z",
            "summary": "Interpretability is essential for machine learning models to be trusted and\ndeployed in critical domains. However, existing methods for interpreting text\nmodels are often complex, lack solid mathematical foundations, and their\nperformance is not guaranteed. In this paper, we propose FRED (Faithful and\nRobust Explainer for textual Documents), a novel method for interpreting\npredictions over text. FRED identifies key words in a document that\nsignificantly impact the prediction when removed. We establish the reliability\nof FRED through formal definitions and theoretical analyses on interpretable\nclassifiers. Additionally, our empirical evaluation against state-of-the-art\nmethods demonstrates the effectiveness of FRED in providing insights into text\nmodels.",
            "author": [
                "Gianluigi Lopardo",
                "Frederic Precioso",
                "Damien Garreau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01605v1",
                "http://arxiv.org/pdf/2311.01605v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19991v1",
            "title": "PolyThrottle: Energy-efficient Neural Network Inference on Edge Devices",
            "updated": "2023-10-30T20:19:41Z",
            "published": "2023-10-30T20:19:41Z",
            "summary": "As neural networks (NN) are deployed across diverse sectors, their energy\ndemand correspondingly grows. While several prior works have focused on\nreducing energy consumption during training, the continuous operation of\nML-powered systems leads to significant energy use during inference. This paper\ninvestigates how the configuration of on-device hardware-elements such as GPU,\nmemory, and CPU frequency, often neglected in prior studies, affects energy\nconsumption for NN inference with regular fine-tuning. We propose PolyThrottle,\na solution that optimizes configurations across individual hardware components\nusing Constrained Bayesian Optimization in an energy-conserving manner. Our\nempirical evaluation uncovers novel facets of the energy-performance\nequilibrium showing that we can save up to 36 percent of energy for popular\nmodels. We also validate that PolyThrottle can quickly converge towards\nnear-optimal settings while satisfying application constraints.",
            "author": [
                "Minghao Yan",
                "Hongyi Wang",
                "Shivaram Venkataraman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19991v1",
                "http://arxiv.org/pdf/2310.19991v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19990v1",
            "title": "Unveiling the Limits of Learned Local Search Heuristics: Are You the\n  Mightiest of the Meek?",
            "updated": "2023-10-30T20:16:42Z",
            "published": "2023-10-30T20:16:42Z",
            "summary": "In recent years, combining neural networks with local search heuristics has\nbecome popular in the field of combinatorial optimization. Despite its\nconsiderable computational demands, this approach has exhibited promising\noutcomes with minimal manual engineering. However, we have identified three\ncritical limitations in the empirical evaluation of these integration attempts.\nFirstly, instances with moderate complexity and weak baselines pose a challenge\nin accurately evaluating the effectiveness of learning-based approaches.\nSecondly, the absence of an ablation study makes it difficult to quantify and\nattribute improvements accurately to the deep learning architecture. Lastly,\nthe generalization of learned heuristics across diverse distributions remains\nunderexplored. In this study, we conduct a comprehensive investigation into\nthese identified limitations. Surprisingly, we demonstrate that a simple\nlearned heuristic based on Tabu Search surpasses state-of-the-art (SOTA)\nlearned heuristics in terms of performance and generalizability. Our findings\nchallenge prevailing assumptions and open up exciting avenues for future\nresearch and innovation in combinatorial optimization.",
            "author": [
                "Ankur Nath",
                "Alan Kuhnle"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19990v1",
                "http://arxiv.org/pdf/2310.19990v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19986v1",
            "title": "Addressing Weak Decision Boundaries in Image Classification by\n  Leveraging Web Search and Generative Models",
            "updated": "2023-10-30T20:04:50Z",
            "published": "2023-10-30T20:04:50Z",
            "summary": "Machine learning (ML) technologies are known to be riddled with ethical and\noperational problems, however, we are witnessing an increasing thrust by\nbusinesses to deploy them in sensitive applications. One major issue among many\nis that ML models do not perform equally well for underrepresented groups. This\nputs vulnerable populations in an even disadvantaged and unfavorable position.\nWe propose an approach that leverages the power of web search and generative\nmodels to alleviate some of the shortcomings of discriminative models. We\ndemonstrate our method on an image classification problem using ImageNet's\nPeople Subtree subset, and show that it is effective in enhancing robustness\nand mitigating bias in certain classes that represent vulnerable populations\n(e.g., female doctor of color). Our new method is able to (1) identify weak\ndecision boundaries for such classes; (2) construct search queries for Google\nas well as text for generating images through DALL-E 2 and Stable Diffusion;\nand (3) show how these newly captured training samples could alleviate\npopulation bias issue. While still improving the model's overall performance\nconsiderably, we achieve a significant reduction (77.30\\%) in the model's\ngender accuracy disparity. In addition to these improvements, we observed a\nnotable enhancement in the classifier's decision boundary, as it is\ncharacterized by fewer weakspots and an increased separation between classes.\nAlthough we showcase our method on vulnerable populations in this study, the\nproposed technique is extendable to a wide range of problems and domains.",
            "author": [
                "Preetam Prabhu Srikar Dammu",
                "Yunhe Feng",
                "Chirag Shah"
            ],
            "link": [
                "http://dx.doi.org/10.24963/ijcai.2023/659",
                "http://arxiv.org/abs/2310.19986v1",
                "http://arxiv.org/pdf/2310.19986v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14675v2",
            "title": "Fast and Expressive Gesture Recognition using a Combination-Homomorphic\n  Electromyogram Encoder",
            "updated": "2023-11-29T16:19:16Z",
            "published": "2023-10-30T20:03:34Z",
            "summary": "We study the task of gesture recognition from electromyography (EMG), with\nthe goal of enabling expressive human-computer interaction at high accuracy,\nwhile minimizing the time required for new subjects to provide calibration\ndata. To fulfill these goals, we define combination gestures consisting of a\ndirection component and a modifier component. New subjects only demonstrate the\nsingle component gestures and we seek to extrapolate from these to all possible\nsingle or combination gestures. We extrapolate to unseen combination gestures\nby combining the feature vectors of real single gestures to produce synthetic\ntraining data. This strategy allows us to provide a large and flexible gesture\nvocabulary, while not requiring new subjects to demonstrate combinatorially\nmany example gestures. We pre-train an encoder and a combination operator using\nself-supervision, so that we can produce useful synthetic training data for\nunseen test subjects. To evaluate the proposed method, we collect a real-world\nEMG dataset, and measure the effect of augmented supervision against two\nbaselines: a partially-supervised model trained with only single gesture data\nfrom the unseen subject, and a fully-supervised model trained with real single\nand real combination gesture data from the unseen subject. We find that the\nproposed method provides a dramatic improvement over the partially-supervised\nmodel, and achieves a useful classification accuracy that in some cases\napproaches the performance of the fully-supervised model.",
            "author": [
                "Niklas Smedemark-Margulies",
                "Yunus Bicer",
                "Elifnur Sunger",
                "Tales Imbiriba",
                "Eugene Tunik",
                "Deniz Erdogmus",
                "Mathew Yarossi",
                "Robin Walters"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14675v2",
                "http://arxiv.org/pdf/2311.14675v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19985v1",
            "title": "Modeling random directions of changes in simplex-valued data",
            "updated": "2023-10-30T20:01:38Z",
            "published": "2023-10-30T20:01:38Z",
            "summary": "We propose models and algorithms for learning about random directions in\nsimplex-valued data. The models are applied to the study of income level\nproportions and their changes over time in a geostatistical area. There are\nseveral notable challenges in the analysis of simplex-valued data: the\nmeasurements must respect the simplex constraint and the changes exhibit\nspatiotemporal smoothness and may be heterogeneous. To that end, we propose\nBayesian models that draw from and expand upon building blocks in circular and\nspatial statistics by exploiting a suitable transformation for the\nsimplex-valued data. Our models also account for spatial correlation across\nlocations in the simplex and the heterogeneous patterns via mixture modeling.\nWe describe some properties of the models and model fitting via MCMC\ntechniques. Our models and methods are applied to an analysis of movements and\ntrends of income categories using the Home Mortgage Disclosure Act data.",
            "author": [
                "Rayleigh Lei",
                "XuanLong Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19985v1",
                "http://arxiv.org/pdf/2310.19985v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.10745v1",
            "title": "\"Just a little bit on the outside for the whole time\": Social belonging\n  confidence and the persistence of Machine Learning and Artificial\n  Intelligence students",
            "updated": "2023-10-30T19:59:38Z",
            "published": "2023-10-30T19:59:38Z",
            "summary": "The growing field of machine learning (ML) and artificial intelligence (AI)\npresents a unique and unexplored case within persistence research, meaning it\nis unclear how past findings from engineering will apply to this developing\nfield. We conduct an exploratory study to gain an initial understanding of\npersistence in this field and identify fruitful directions for future work. One\nfactor that has been shown to predict persistence in engineering is belonging;\nwe study belonging through the lens of confidence, and discuss how attention to\nsocial belonging confidence may help to increase diversity in the profession.\nIn this research paper, we conduct a small set of interviews with students in\nML/AI courses. Thematic analysis of these interviews revealed initial\ndifferences in how students see a career in ML/AI, which diverge based on\ninterest and programming confidence. We identified how exposure and initiation,\nthe interpretation of ML and AI field boundaries, and beliefs of the skills\nrequired to succeed might influence students' intentions to persist. We discuss\ndifferences in how students describe being motivated by social belonging and\nthe importance of close mentorship. We motivate further persistence research in\nML/AI with particular focus on social belonging and close mentorship, the role\nof intersectional identity, and introductory ML/AI courses.",
            "author": [
                "Katherine Mao",
                "Sharon Ferguson",
                "James Magarian",
                "Alison Olechowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10745v1",
                "http://arxiv.org/pdf/2311.10745v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.OH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.10744v1",
            "title": "Advancing a Model of Students' Intentional Persistence in Machine\n  Learning and Artificial Intelligence",
            "updated": "2023-10-30T19:57:40Z",
            "published": "2023-10-30T19:57:40Z",
            "summary": "Machine Learning (ML) and Artificial Intelligence (AI) are powering the\napplications we use, the decisions we make, and the decisions made about us. We\nhave seen numerous examples of non-equitable outcomes, from facial recognition\nalgorithms to recidivism algorithms, when they are designed without diversity\nin mind. Thus, we must take action to promote diversity among those in this\nfield. A critical step in this work is understanding why some students who\nchoose to study ML/AI later leave the field. While the persistence of diverse\npopulations has been studied in engineering, there is a lack of research\ninvestigating factors that influence persistence in ML/AI. In this work, we\npresent the advancement of a model of intentional persistence in ML/AI by\nsurveying students in ML/AI courses. We examine persistence across demographic\ngroups, such as gender, international student status, student loan status, and\nvisible minority status. We investigate independent variables that distinguish\nML/AI from other STEM fields, such as the varying emphasis on non-technical\nskills, the ambiguous ethical implications of the work, and the highly\ncompetitive and lucrative nature of the field. Our findings suggest that\nshort-term intentional persistence is associated with academic enrollment\nfactors such as major and level of study. Long-term intentional persistence is\ncorrelated with measures of professional role confidence. Unique to our study,\nwe show that wanting your work to have a positive social benefit is a negative\npredictor of long-term intentional persistence, and women generally care more\nabout this. We provide recommendations to educators to meaningfully discuss\nML/AI ethics in classes and encourage the development of interpersonal skills\nto help increase diversity in the field.",
            "author": [
                "Sharon Ferguson",
                "Katherine Mao",
                "James Magarian",
                "Alison Olechowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10744v1",
                "http://arxiv.org/pdf/2311.10744v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19978v1",
            "title": "Scaling Up Differentially Private LASSO Regularized Logistic Regression\n  via Faster Frank-Wolfe Iterations",
            "updated": "2023-10-30T19:52:43Z",
            "published": "2023-10-30T19:52:43Z",
            "summary": "To the best of our knowledge, there are no methods today for training\ndifferentially private regression models on sparse input data. To remedy this,\nwe adapt the Frank-Wolfe algorithm for $L_1$ penalized linear regression to be\naware of sparse inputs and to use them effectively. In doing so, we reduce the\ntraining time of the algorithm from $\\mathcal{O}( T D S + T N S)$ to\n$\\mathcal{O}(N S + T \\sqrt{D} \\log{D} + T S^2)$, where $T$ is the number of\niterations and a sparsity rate $S$ of a dataset with $N$ rows and $D$ features.\nOur results demonstrate that this procedure can reduce runtime by a factor of\nup to $2,200\\times$, depending on the value of the privacy parameter $\\epsilon$\nand the sparsity of the dataset.",
            "author": [
                "Edward Raff",
                "Amol Khanna",
                "Fred Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19978v1",
                "http://arxiv.org/pdf/2310.19978v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19975v2",
            "title": "BioInstruct: Instruction Tuning of Large Language Models for Biomedical\n  Natural Language Processing",
            "updated": "2023-11-06T15:05:34Z",
            "published": "2023-10-30T19:38:50Z",
            "summary": "To enhance the performance of large language models (LLMs) in biomedical\nnatural language processing (BioNLP) by introducing a domain-specific\ninstruction dataset and examining its impact when combined with multi-task\nlearning principles. We created the BioInstruct, comprising 25,005 instructions\nto instruction-tune LLMs(LLaMA 1 & 2, 7B & 13B version). The instructions were\ncreated by prompting the GPT-4 language model with three-seed samples randomly\ndrawn from an 80 human curated instructions. We employed Low-Rank\nAdaptation(LoRA) for parameter-efficient fine-tuning. We then evaluated these\ninstruction-tuned LLMs on several BioNLP tasks, which can be grouped into three\nmajor categories: question answering(QA), information extraction(IE), and text\ngeneration(GEN). We also examined whether categories(e.g., QA, IE, and\ngeneration) of instructions impact model performance. Comparing with LLMs\nwithout instruction-tuned, our instruction-tuned LLMs demonstrated marked\nperformance gains: 17.3% in QA, 5.7% in IE, and 96% in Generation tasks. Our\n7B-parameter instruction-tuned LLaMA 1 model was competitive or even surpassed\nother LLMs in the biomedical domain that were also fine-tuned from LLaMA 1 with\nvast domain-specific data or a variety of tasks. Our results also show that the\nperformance gain is significantly higher when instruction fine-tuning is\nconducted with closely related tasks. Our findings align with the observations\nof multi-task learning, suggesting the synergies between two tasks. The\nBioInstruct dataset serves as a valuable resource and instruction tuned LLMs\nlead to the best performing BioNLP applications.",
            "author": [
                "Hieu Tran",
                "Zhichao Yang",
                "Zonghai Yao",
                "Hong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19975v2",
                "http://arxiv.org/pdf/2310.19975v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19974v1",
            "title": "Deep Learning-Enabled Text Semantic Communication under Interference: An\n  Empirical Study",
            "updated": "2023-10-30T19:38:47Z",
            "published": "2023-10-30T19:38:47Z",
            "summary": "At the confluence of 6G, deep learning (DL), and natural language processing\n(NLP), DL-enabled text semantic communication (SemCom) has emerged as a 6G\nenabler by promising to minimize bandwidth consumption, transmission delay, and\npower usage. Among text SemCom techniques, \\textit{DeepSC} is a popular scheme\nthat leverages advancements in DL and NLP to reliably transmit semantic\ninformation in low signal-to-noise ratio (SNR) regimes. To understand the\nfundamental limits of such a transmission paradigm, our recently developed\ntheory \\cite{Getu'23_Performance_Limits} predicted the performance limits of\nDeepSC under radio frequency interference (RFI). Although these limits were\ncorroborated by simulations, trained deep networks can defy classical\nstatistical wisdom, and hence extensive computer experiments are needed to\nvalidate our theory. Accordingly, this empirical work follows concerning the\ntraining and testing of DeepSC using the proceedings of the European Parliament\n(Europarl) dataset. Employing training, validation, and testing sets\n\\textit{tokenized and vectorized} from Europarl, we train the DeepSC\narchitecture in Keras 2.9 with TensorFlow 2.9 as a backend and test it under\nGaussian multi-interferer RFI received over Rayleigh fading channels.\nValidating our theory, the testing results corroborate that DeepSC produces\nsemantically irrelevant sentences as the number of Gaussian RFI emitters gets\nvery large. Therefore, a fundamental 6G design paradigm for\n\\textit{interference-resistant and robust SemCom} (IR$^2$ SemCom) is needed.",
            "author": [
                "Tilahun M. Getu",
                "Georges Kaddoum",
                "Mehdi Bennis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19974v1",
                "http://arxiv.org/pdf/2310.19974v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19973v2",
            "title": "Unified Enhancement of Privacy Bounds for Mixture Mechanisms via\n  $f$-Differential Privacy",
            "updated": "2023-11-01T14:43:16Z",
            "published": "2023-10-30T19:37:51Z",
            "summary": "Differentially private (DP) machine learning algorithms incur many sources of\nrandomness, such as random initialization, random batch subsampling, and\nshuffling. However, such randomness is difficult to take into account when\nproving differential privacy bounds because it induces mixture distributions\nfor the algorithm's output that are difficult to analyze. This paper focuses on\nimproving privacy bounds for shuffling models and one-iteration differentially\nprivate gradient descent (DP-GD) with random initializations using $f$-DP. We\nderive a closed-form expression of the trade-off function for shuffling models\nthat outperforms the most up-to-date results based on $(\\epsilon,\\delta)$-DP.\nMoreover, we investigate the effects of random initialization on the privacy of\none-iteration DP-GD. Our numerical computations of the trade-off function\nindicate that random initialization can enhance the privacy of DP-GD. Our\nanalysis of $f$-DP guarantees for these mixture mechanisms relies on an\ninequality for trade-off functions introduced in this paper. This inequality\nimplies the joint convexity of $F$-divergences. Finally, we study an $f$-DP\nanalog of the advanced joint convexity of the hockey-stick divergence related\nto $(\\epsilon,\\delta)$-DP and apply it to analyze the privacy of mixture\nmechanisms.",
            "author": [
                "Chendi Wang",
                "Buxin Su",
                "Jiayuan Ye",
                "Reza Shokri",
                "Weijie J. Su"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19973v2",
                "http://arxiv.org/pdf/2310.19973v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CR",
                "cs.LG",
                "math.ST",
                "stat.ME",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19970v1",
            "title": "Strategies to Harness the Transformers' Potential: UNSL at eRisk 2023",
            "updated": "2023-10-30T19:34:33Z",
            "published": "2023-10-30T19:34:33Z",
            "summary": "The CLEF eRisk Laboratory explores solutions to different tasks related to\nrisk detection on the Internet. In the 2023 edition, Task 1 consisted of\nsearching for symptoms of depression, the objective of which was to extract\nuser writings according to their relevance to the BDI Questionnaire symptoms.\nTask 2 was related to the problem of early detection of pathological gambling\nrisks, where the participants had to detect users at risk as quickly as\npossible. Finally, Task 3 consisted of estimating the severity levels of signs\nof eating disorders. Our research group participated in the first two tasks,\nproposing solutions based on Transformers. For Task 1, we applied different\napproaches that can be interesting in information retrieval tasks. Two\nproposals were based on the similarity of contextualized embedding vectors, and\nthe other one was based on prompting, an attractive current technique of\nmachine learning. For Task 2, we proposed three fine-tuned models followed by\ndecision policy according to criteria defined by an early detection framework.\nOne model presented extended vocabulary with important words to the addressed\ndomain. In the last task, we obtained good performances considering the\ndecision-based metrics, ranking-based metrics, and runtime. In this work, we\nexplore different ways to deploy the predictive potential of Transformers in\neRisk tasks.",
            "author": [
                "Horacio Thompson",
                "Leticia Cagnina",
                "Marcelo Errecalde"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19970v1",
                "http://arxiv.org/pdf/2310.19970v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00862v1",
            "title": "Role of Structural and Conformational Diversity for Machine Learning\n  Potentials",
            "updated": "2023-10-30T19:33:12Z",
            "published": "2023-10-30T19:33:12Z",
            "summary": "In the field of Machine Learning Interatomic Potentials (MLIPs),\nunderstanding the intricate relationship between data biases, specifically\nconformational and structural diversity, and model generalization is critical\nin improving the quality of Quantum Mechanics (QM) data generation efforts. We\ninvestigate these dynamics through two distinct experiments: a fixed budget\none, where the dataset size remains constant, and a fixed molecular set one,\nwhich focuses on fixed structural diversity while varying conformational\ndiversity. Our results reveal nuanced patterns in generalization metrics.\nNotably, for optimal structural and conformational generalization, a careful\nbalance between structural and conformational diversity is required, but\nexisting QM datasets do not meet that trade-off. Additionally, our results\nhighlight the limitation of the MLIP models at generalizing beyond their\ntraining distribution, emphasizing the importance of defining applicability\ndomain during model deployment. These findings provide valuable insights and\nguidelines for QM data generation efforts.",
            "author": [
                "Nikhil Shenoy",
                "Prudencio Tossou",
                "Emmanuel Noutahi",
                "Hadrien Mary",
                "Dominique Beaini",
                "Jiarui Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00862v1",
                "http://arxiv.org/pdf/2311.00862v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19967v2",
            "title": "Early detection of inflammatory arthritis to improve referrals using\n  multimodal machine learning from blood testing, semi-structured and\n  unstructured patient records",
            "updated": "2023-11-03T19:32:02Z",
            "published": "2023-10-30T19:30:00Z",
            "summary": "Early detection of inflammatory arthritis (IA) is critical to efficient and\naccurate hospital referral triage for timely treatment and preventing the\ndeterioration of the IA disease course, especially under limited healthcare\nresources. The manual assessment process is the most common approach in\npractice for the early detection of IA, but it is extremely labor-intensive and\ninefficient. A large amount of clinical information needs to be assessed for\nevery referral from General Practice (GP) to the hospitals. Machine learning\nshows great potential in automating repetitive assessment tasks and providing\ndecision support for the early detection of IA. However, most machine\nlearning-based methods for IA detection rely on blood testing results. But in\npractice, blood testing data is not always available at the point of referrals,\nso we need methods to leverage multimodal data such as semi-structured and\nunstructured data for early detection of IA. In this research, we present\nfusion and ensemble learning-based methods using multimodal data to assist\ndecision-making in the early detection of IA, and a conformal prediction-based\nmethod to quantify the uncertainty of the prediction and detect any unreliable\npredictions. To the best of our knowledge, our study is the first attempt to\nutilize multimodal data to support the early detection of IA from GP referrals.",
            "author": [
                "Bing Wang",
                "Weizi Li",
                "Anthony Bradlow",
                "Antoni T. Y. Chan",
                "Eghosa Bazuaye"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19967v2",
                "http://arxiv.org/pdf/2310.19967v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.01468v1",
            "title": "Remember what you did so you know what to do next",
            "updated": "2023-10-30T19:29:00Z",
            "published": "2023-10-30T19:29:00Z",
            "summary": "We explore using a moderately sized large language model (GPT-J 6B\nparameters) to create a plan for a simulated robot to achieve 30 classes of\ngoals in ScienceWorld, a text game simulator for elementary science\nexperiments. Previously published empirical work claimed that large language\nmodels (LLMs) are a poor fit (Wang et al., 2022) compared to reinforcement\nlearning. Using the Markov assumption (a single previous step), the LLM\noutperforms the reinforcement learning-based approach by a factor of 1.4. When\nwe fill the LLM's input buffer with as many prior steps as possible,\nimprovement rises to 3.5x. Even when training on only 6.5% of the training\ndata, we observe a 2.2x improvement over the reinforcement-learning-based\napproach. Our experiments show that performance varies widely across the 30\nclasses of actions, indicating that averaging over tasks can hide significant\nperformance issues. In work contemporaneous with ours, Lin et al. (2023)\ndemonstrated a two-part approach (SwiftSage) that uses a small LLM (T5-large)\ncomplemented by OpenAI's massive LLMs to achieve outstanding results in\nScienceWorld. Our 6-B parameter, single-stage GPT-J matches the performance of\nSwiftSage's two-stage architecture when it incorporates GPT-3.5 turbo which has\n29-times more parameters than GPT-J.",
            "author": [
                "Manuel R. Ciosici",
                "Alex Hedges",
                "Yash Kankanampati",
                "Justin Martin",
                "Marjorie Freedman",
                "Ralph Weischedel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01468v1",
                "http://arxiv.org/pdf/2311.01468v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19961v1",
            "title": "ExPT: Synthetic Pretraining for Few-Shot Experimental Design",
            "updated": "2023-10-30T19:25:43Z",
            "published": "2023-10-30T19:25:43Z",
            "summary": "Experimental design is a fundamental problem in many science and engineering\nfields. In this problem, sample efficiency is crucial due to the time, money,\nand safety costs of real-world design evaluations. Existing approaches either\nrely on active data collection or access to large, labeled datasets of past\nexperiments, making them impractical in many real-world scenarios. In this\nwork, we address the more challenging yet realistic setting of few-shot\nexperimental design, where only a few labeled data points of input designs and\ntheir corresponding values are available. We approach this problem as a\nconditional generation task, where a model conditions on a few labeled examples\nand the desired output to generate an optimal input design. To this end, we\nintroduce Experiment Pretrained Transformers (ExPT), a foundation model for\nfew-shot experimental design that employs a novel combination of synthetic\npretraining with in-context learning. In ExPT, we only assume knowledge of a\nfinite collection of unlabelled data points from the input domain and pretrain\na transformer neural network to optimize diverse synthetic functions defined\nover this domain. Unsupervised pretraining allows ExPT to adapt to any design\ntask at test time in an in-context fashion by conditioning on a few labeled\ndata points from the target task and generating the candidate optima. We\nevaluate ExPT on few-shot experimental design in challenging domains and\ndemonstrate its superior generality and performance compared to existing\nmethods. The source code is available at https://github.com/tung-nd/ExPT.git.",
            "author": [
                "Tung Nguyen",
                "Sudhanshu Agrawal",
                "Aditya Grover"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19961v1",
                "http://arxiv.org/pdf/2310.19961v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19960v1",
            "title": "Topological Learning for Motion Data via Mixed Coordinates",
            "updated": "2023-10-30T19:20:48Z",
            "published": "2023-10-30T19:20:48Z",
            "summary": "Topology can extract the structural information in a dataset efficiently. In\nthis paper, we attempt to incorporate topological information into a multiple\noutput Gaussian process model for transfer learning purposes. To achieve this\ngoal, we extend the framework of circular coordinates into a novel framework of\nmixed valued coordinates to take linear trends in the time series into\nconsideration.\n  One of the major challenges to learn from multiple time series effectively\nvia a multiple output Gaussian process model is constructing a functional\nkernel. We propose to use topologically induced clustering to construct a\ncluster based kernel in a multiple output Gaussian process model. This kernel\nnot only incorporates the topological structural information, but also allows\nus to put forward a unified framework using topological information in time and\nmotion series.",
            "author": [
                "Hengrui Luo",
                "Jisu Kim",
                "Alice Patania",
                "Mikael Vejdemo-Johansson"
            ],
            "link": [
                "http://dx.doi.org/10.1109/BigData52589.2021.9671525",
                "http://arxiv.org/abs/2310.19960v1",
                "http://arxiv.org/pdf/2310.19960v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.AT",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19958v1",
            "title": "PriPrune: Quantifying and Preserving Privacy in Pruned Federated\n  Learning",
            "updated": "2023-10-30T19:18:09Z",
            "published": "2023-10-30T19:18:09Z",
            "summary": "Federated learning (FL) is a paradigm that allows several client devices and\na server to collaboratively train a global model, by exchanging only model\nupdates, without the devices sharing their local training data. These devices\nare often constrained in terms of communication and computation resources, and\ncan further benefit from model pruning -- a paradigm that is widely used to\nreduce the size and complexity of models. Intuitively, by making local models\ncoarser, pruning is expected to also provide some protection against privacy\nattacks in the context of FL. However this protection has not been previously\ncharacterized, formally or experimentally, and it is unclear if it is\nsufficient against state-of-the-art attacks.\n  In this paper, we perform the first investigation of privacy guarantees for\nmodel pruning in FL. We derive information-theoretic upper bounds on the amount\nof information leaked by pruned FL models. We complement and validate these\ntheoretical findings, with comprehensive experiments that involve\nstate-of-the-art privacy attacks, on several state-of-the-art FL pruning\nschemes, using benchmark datasets. This evaluation provides valuable insights\ninto the choices and parameters that can affect the privacy protection provided\nby pruning. Based on these insights, we introduce PriPrune -- a privacy-aware\nalgorithm for local model pruning, which uses a personalized per-client defense\nmask and adapts the defense pruning rate so as to jointly optimize privacy and\nmodel performance. PriPrune is universal in that can be applied after any\npruned FL scheme on the client, without modification, and protects against any\ninversion attack by the server. Our empirical evaluation demonstrates that\nPriPrune significantly improves the privacy-accuracy tradeoff compared to\nstate-of-the-art pruned FL schemes that do not take privacy into account.",
            "author": [
                "Tianyue Chu",
                "Mengwei Yang",
                "Nikolaos Laoutaris",
                "Athina Markopoulou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19958v1",
                "http://arxiv.org/pdf/2310.19958v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19957v1",
            "title": "Deep Learning for Spatiotemporal Big Data: A Vision on Opportunities and\n  Challenges",
            "updated": "2023-10-30T19:12:51Z",
            "published": "2023-10-30T19:12:51Z",
            "summary": "With advancements in GPS, remote sensing, and computational simulation, an\nenormous volume of spatiotemporal data is being collected at an increasing\nspeed from various application domains, spanning Earth sciences, agriculture,\nsmart cities, and public safety. Such emerging geospatial and spatiotemporal\nbig data, coupled with recent advances in deep learning technologies, foster\nnew opportunities to solve problems that have not been possible before. For\ninstance, remote sensing researchers can potentially train a foundation model\nusing Earth imagery big data for numerous land cover and land use modeling\ntasks. Coastal modelers can train AI surrogates to speed up numerical\nsimulations. However, the distinctive characteristics of spatiotemporal big\ndata pose new challenges for deep learning technologies. This vision paper\nintroduces various types of spatiotemporal big data, discusses new research\nopportunities in the realm of deep learning applied to spatiotemporal big data,\nlists the unique challenges, and identifies several future research needs.",
            "author": [
                "Zhe Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19957v1",
                "http://arxiv.org/pdf/2310.19957v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19944v1",
            "title": "Conditional Unscented Autoencoders for Trajectory Prediction",
            "updated": "2023-10-30T18:59:32Z",
            "published": "2023-10-30T18:59:32Z",
            "summary": "The \\ac{CVAE} is one of the most widely-used models in trajectory prediction\nfor \\ac{AD}. It captures the interplay between a driving context and its\nground-truth future into a probabilistic latent space and uses it to produce\npredictions. In this paper, we challenge key components of the CVAE. We\nleverage recent advances in the space of the VAE, the foundation of the CVAE,\nwhich show that a simple change in the sampling procedure can greatly benefit\nperformance. We find that unscented sampling, which draws samples from any\nlearned distribution in a deterministic manner, can naturally be better suited\nto trajectory prediction than potentially dangerous random sampling. We go\nfurther and offer additional improvements, including a more structured mixture\nlatent space, as well as a novel, potentially more expressive way to do\ninference with CVAEs. We show wide applicability of our models by evaluating\nthem on the INTERACTION prediction dataset, outperforming the state of the art,\nas well as at the task of image modeling on the CelebA dataset, outperforming\nthe baseline vanilla CVAE. Code is available at\nhttps://github.com/boschresearch/cuae-prediction.",
            "author": [
                "Faris Janjo\u0161",
                "Marcel Hallgarten",
                "Anthony Knittel",
                "Maxim Dolgov",
                "Andreas Zell",
                "J. Marius Z\u00f6llner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19944v1",
                "http://arxiv.org/pdf/2310.19944v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19943v1",
            "title": "The Acquisition of Physical Knowledge in Generative Neural Networks",
            "updated": "2023-10-30T18:58:03Z",
            "published": "2023-10-30T18:58:03Z",
            "summary": "As children grow older, they develop an intuitive understanding of the\nphysical processes around them. Their physical understanding develops in\nstages, moving along developmental trajectories which have been mapped out\nextensively in previous empirical research. Here, we investigate how the\nlearning trajectories of deep generative neural networks compare to children's\ndevelopmental trajectories using physical understanding as a testbed. We\noutline an approach that allows us to examine two distinct hypotheses of human\ndevelopment - stochastic optimization and complexity increase. We find that\nwhile our models are able to accurately predict a number of physical processes,\ntheir learning trajectories under both hypotheses do not follow the\ndevelopmental trajectories of children.",
            "author": [
                "Luca M. Schulze Buschoff",
                "Eric Schulz",
                "Marcel Binz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19943v1",
                "http://arxiv.org/pdf/2310.19943v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19942v1",
            "title": "Split-NER: Named Entity Recognition via Two Question-Answering-based\n  Classifications",
            "updated": "2023-10-30T18:57:28Z",
            "published": "2023-10-30T18:57:28Z",
            "summary": "In this work, we address the NER problem by splitting it into two logical\nsub-tasks: (1) Span Detection which simply extracts entity mention spans\nirrespective of entity type; (2) Span Classification which classifies the spans\ninto their entity types. Further, we formulate both sub-tasks as\nquestion-answering (QA) problems and produce two leaner models which can be\noptimized separately for each sub-task. Experiments with four cross-domain\ndatasets demonstrate that this two-step approach is both effective and time\nefficient. Our system, SplitNER outperforms baselines on OntoNotes5.0, WNUT17\nand a cybersecurity dataset and gives on-par performance on BioNLP13CG. In all\ncases, it achieves a significant reduction in training time compared to its QA\nbaseline counterpart. The effectiveness of our system stems from fine-tuning\nthe BERT model twice, separately for span detection and classification. The\nsource code can be found at https://github.com/c3sr/split-ner.",
            "author": [
                "Jatin Arora",
                "Youngja Park"
            ],
            "link": [
                "http://dx.doi.org/10.18653/v1/2023.acl-short.36",
                "http://arxiv.org/abs/2310.19942v1",
                "http://arxiv.org/pdf/2310.19942v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.LG",
                "I.2.7; H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19938v1",
            "title": "Lyapunov-Based Dropout Deep Neural Network (Lb-DDNN) Controller",
            "updated": "2023-10-30T18:54:08Z",
            "published": "2023-10-30T18:54:08Z",
            "summary": "Deep neural network (DNN)-based adaptive controllers can be used to\ncompensate for unstructured uncertainties in nonlinear dynamic systems.\nHowever, DNNs are also very susceptible to overfitting and co-adaptation.\nDropout regularization is an approach where nodes are randomly dropped during\ntraining to alleviate issues such as overfitting and co-adaptation. In this\npaper, a dropout DNN-based adaptive controller is developed. The developed\ndropout technique allows the deactivation of weights that are stochastically\nselected for each individual layer within the DNN. Simultaneously, a\nLyapunov-based real-time weight adaptation law is introduced to update the\nweights of all layers of the DNN for online unsupervised learning. A non-smooth\nLyapunov-based stability analysis is performed to ensure asymptotic convergence\nof the tracking error. Simulation results of the developed dropout DNN-based\nadaptive controller indicate a 38.32% improvement in the tracking error, a\n53.67% improvement in the function approximation error, and 50.44% lower\ncontrol effort when compared to a baseline adaptive DNN-based controller\nwithout dropout regularization.",
            "author": [
                "Saiedeh Akbari",
                "Emily J. Griffis",
                "Omkar Sudhir Patil",
                "Warren E. Dixon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19938v1",
                "http://arxiv.org/pdf/2310.19938v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19936v1",
            "title": "Towards Few-Annotation Learning for Object Detection: Are\n  Transformer-based Models More Efficient ?",
            "updated": "2023-10-30T18:51:25Z",
            "published": "2023-10-30T18:51:25Z",
            "summary": "For specialized and dense downstream tasks such as object detection, labeling\ndata requires expertise and can be very expensive, making few-shot and\nsemi-supervised models much more attractive alternatives. While in the few-shot\nsetup we observe that transformer-based object detectors perform better than\nconvolution-based two-stage models for a similar amount of parameters, they are\nnot as effective when used with recent approaches in the semi-supervised\nsetting. In this paper, we propose a semi-supervised method tailored for the\ncurrent state-of-the-art object detector Deformable DETR in the few-annotation\nlearning setup using a student-teacher architecture, which avoids relying on a\nsensitive post-processing of the pseudo-labels generated by the teacher model.\nWe evaluate our method on the semi-supervised object detection benchmarks COCO\nand Pascal VOC, and it outperforms previous methods, especially when\nannotations are scarce. We believe that our contributions open new\npossibilities to adapt similar object detection methods in this setup as well.",
            "author": [
                "Quentin Bouniot",
                "Ang\u00e9lique Loesch",
                "Romaric Audigier",
                "Amaury Habrard"
            ],
            "link": [
                "http://dx.doi.org/10.1109/WACV56688.2023.00016",
                "http://arxiv.org/abs/2310.19936v1",
                "http://arxiv.org/pdf/2310.19936v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19932v1",
            "title": "Sim2Real for Environmental Neural Processes",
            "updated": "2023-10-30T18:49:06Z",
            "published": "2023-10-30T18:49:06Z",
            "summary": "Machine learning (ML)-based weather models have recently undergone rapid\nimprovements. These models are typically trained on gridded reanalysis data\nfrom numerical data assimilation systems. However, reanalysis data comes with\nlimitations, such as assumptions about physical laws and low spatiotemporal\nresolution. The gap between reanalysis and reality has sparked growing interest\nin training ML models directly on observations such as weather stations.\nModelling scattered and sparse environmental observations requires scalable and\nflexible ML architectures, one of which is the convolutional conditional neural\nprocess (ConvCNP). ConvCNPs can learn to condition on both gridded and\noff-the-grid context data to make uncertainty-aware predictions at target\nlocations. However, the sparsity of real observations presents a challenge for\ndata-hungry deep learning models like the ConvCNP. One potential solution is\n'Sim2Real': pre-training on reanalysis and fine-tuning on observational data.\nWe analyse Sim2Real with a ConvCNP trained to interpolate surface air\ntemperature over Germany, using varying numbers of weather stations for\nfine-tuning. On held-out weather stations, Sim2Real training substantially\noutperforms the same model architecture trained only with reanalysis data or\nonly with station data, showing that reanalysis data can serve as a stepping\nstone for learning from real observations. Sim2Real could thus enable more\naccurate models for weather prediction and climate monitoring.",
            "author": [
                "Jonas Scholz",
                "Tom R. Andersson",
                "Anna Vaughan",
                "James Requeima",
                "Richard E. Turner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19932v1",
                "http://arxiv.org/pdf/2310.19932v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19927v1",
            "title": "Model-Based Reparameterization Policy Gradient Methods: Theory and\n  Practical Algorithms",
            "updated": "2023-10-30T18:43:21Z",
            "published": "2023-10-30T18:43:21Z",
            "summary": "ReParameterization (RP) Policy Gradient Methods (PGMs) have been widely\nadopted for continuous control tasks in robotics and computer graphics.\nHowever, recent studies have revealed that, when applied to long-term\nreinforcement learning problems, model-based RP PGMs may experience chaotic and\nnon-smooth optimization landscapes with exploding gradient variance, which\nleads to slow convergence. This is in contrast to the conventional belief that\nreparameterization methods have low gradient estimation variance in problems\nsuch as training deep generative models. To comprehend this phenomenon, we\nconduct a theoretical examination of model-based RP PGMs and search for\nsolutions to the optimization difficulties. Specifically, we analyze the\nconvergence of the model-based RP PGMs and pinpoint the smoothness of function\napproximators as a major factor that affects the quality of gradient\nestimation. Based on our analysis, we propose a spectral normalization method\nto mitigate the exploding variance issue caused by long model unrolls. Our\nexperimental results demonstrate that proper normalization significantly\nreduces the gradient variance of model-based RP PGMs. As a result, the\nperformance of the proposed method is comparable or superior to other gradient\nestimators, such as the Likelihood Ratio (LR) gradient estimator. Our code is\navailable at https://github.com/agentification/RP_PGM.",
            "author": [
                "Shenao Zhang",
                "Boyi Liu",
                "Zhaoran Wang",
                "Tuo Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19927v1",
                "http://arxiv.org/pdf/2310.19927v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19923v1",
            "title": "Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long\n  Documents",
            "updated": "2023-10-30T18:35:30Z",
            "published": "2023-10-30T18:35:30Z",
            "summary": "Text embedding models have emerged as powerful tools for transforming\nsentences into fixed-sized feature vectors that encapsulate semantic\ninformation. While these models are essential for tasks like information\nretrieval, semantic clustering, and text re-ranking, most existing open-source\nmodels, especially those built on architectures like BERT, struggle to\nrepresent lengthy documents and often resort to truncation. One common approach\nto mitigate this challenge involves splitting documents into smaller paragraphs\nfor embedding. However, this strategy results in a much larger set of vectors,\nconsequently leading to increased memory consumption and computationally\nintensive vector searches with elevated latency.\n  To address these challenges, we introduce Jina Embeddings 2, an open-source\ntext embedding model capable of accommodating up to 8192 tokens. This model is\ndesigned to transcend the conventional 512-token limit and adeptly process long\ndocuments. Jina Embeddings 2 not only achieves state-of-the-art performance on\na range of embedding-related tasks in the MTEB benchmark but also matches the\nperformance of OpenAI's proprietary ada-002 model. Additionally, our\nexperiments indicate that an extended context can enhance performance in tasks\nsuch as NarrativeQA.",
            "author": [
                "Michael G\u00fcnther",
                "Jackmin Ong",
                "Isabelle Mohr",
                "Alaeddine Abdessalem",
                "Tanguy Abel",
                "Mohammad Kalim Akram",
                "Susana Guzman",
                "Georgios Mastrapas",
                "Saba Sturua",
                "Bo Wang",
                "Maximilian Werk",
                "Nan Wang",
                "Han Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19923v1",
                "http://arxiv.org/pdf/2310.19923v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "68T50",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19920v1",
            "title": "Solving a Class of Cut-Generating Linear Programs via Machine Learning",
            "updated": "2023-10-30T18:31:52Z",
            "published": "2023-10-30T18:31:52Z",
            "summary": "Cut-generating linear programs (CGLPs) play a key role as a separation oracle\nto produce valid inequalities for the feasible region of mixed-integer\nprograms. When incorporated inside branch-and-bound, the cutting planes\nobtained from CGLPs help to tighten relaxations and improve dual bounds.\nHowever, running the CGLPs at the nodes of the branch-and-bound tree is\ncomputationally cumbersome due to the large number of node candidates and the\nlack of a priori knowledge on which nodes admit useful cutting planes. As a\nresult, CGLPs are often avoided at default settings of branch-and-cut\nalgorithms despite their potential impact on improving dual bounds. In this\npaper, we propose a novel framework based on machine learning to approximate\nthe optimal value of a CGLP class that determines whether a cutting plane can\nbe generated at a node of the branch-and-bound tree. Translating the CGLP as an\nindicator function of the objective function vector, we show that it can be\napproximated through conventional data classification techniques. We provide a\nsystematic procedure to efficiently generate training data sets for the\ncorresponding classification problem based on the CGLP structure. We conduct\ncomputational experiments on benchmark instances using classification methods\nsuch as logistic regression. These results suggest that the approximate CGLP\nobtained from classification can improve the solution time compared to that of\nconventional cutting plane methods. Our proposed framework can be efficiently\napplied to a large number of nodes in the branch-and-bound tree to identify the\nbest candidates for adding a cut.",
            "author": [
                "Atefeh Rajabalizadeh",
                "Danial Davarnia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19920v1",
                "http://arxiv.org/pdf/2310.19920v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19919v1",
            "title": "Meta-Learning Strategies through Value Maximization in Neural Networks",
            "updated": "2023-10-30T18:29:26Z",
            "published": "2023-10-30T18:29:26Z",
            "summary": "Biological and artificial learning agents face numerous choices about how to\nlearn, ranging from hyperparameter selection to aspects of task distributions\nlike curricula. Understanding how to make these meta-learning choices could\noffer normative accounts of cognitive control functions in biological learners\nand improve engineered systems. Yet optimal strategies remain challenging to\ncompute in modern deep networks due to the complexity of optimizing through the\nentire learning process. Here we theoretically investigate optimal strategies\nin a tractable setting. We present a learning effort framework capable of\nefficiently optimizing control signals on a fully normative objective:\ndiscounted cumulative performance throughout learning. We obtain computational\ntractability by using average dynamical equations for gradient descent,\navailable for simple neural network architectures. Our framework accommodates a\nrange of meta-learning and automatic curriculum learning methods in a unified\nnormative setting. We apply this framework to investigate the effect of\napproximations in common meta-learning algorithms; infer aspects of optimal\ncurricula; and compute optimal neuronal resource allocation in a continual\nlearning setting. Across settings, we find that control effort is most\nbeneficial when applied to easier aspects of a task early in learning; followed\nby sustained effort on harder aspects. Overall, the learning effort framework\nprovides a tractable theoretical test bed to study normative benefits of\ninterventions in a variety of learning systems, as well as a formal account of\noptimal cognitive control strategies over learning trajectories posited by\nestablished theories in cognitive neuroscience.",
            "author": [
                "Rodrigo Carrasco-Davis",
                "Javier Mas\u00eds",
                "Andrew M. Saxe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19919v1",
                "http://arxiv.org/pdf/2310.19919v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19917v1",
            "title": "Unmasking Bias and Inequities: A Systematic Review of Bias Detection and\n  Mitigation in Healthcare Artificial Intelligence Using Electronic Health\n  Records",
            "updated": "2023-10-30T18:29:15Z",
            "published": "2023-10-30T18:29:15Z",
            "summary": "Objectives: Artificial intelligence (AI) applications utilizing electronic\nhealth records (EHRs) have gained popularity, but they also introduce various\ntypes of bias. This study aims to systematically review the literature that\naddress bias in AI research utilizing EHR data. Methods: A systematic review\nwas conducted following the Preferred Reporting Items for Systematic Reviews\nand Meta-analyses (PRISMA) guideline. We retrieved articles published between\nJanuary 1, 2010, and October 31, 2022, from PubMed, Web of Science, and the\nInstitute of Electrical and Electronics Engineers. We defined six major types\nof bias and summarized the existing approaches in bias handling. Results: Out\nof the 252 retrieved articles, 20 met the inclusion criteria for the final\nreview. Five out of six bias were covered in this review: eight studies\nanalyzed selection bias; six on implicit bias; five on confounding bias; four\non measurement bias; two on algorithmic bias. For bias handling approaches, ten\nstudies identified bias during model development, while seventeen presented\nmethods to mitigate the bias. Discussion: Bias may infiltrate the AI\napplication development process at various stages. Although this review\ndiscusses methods for addressing bias at different development stages, there is\nroom for implementing additional effective approaches. Conclusion: Despite\ngrowing attention to bias in healthcare AI, research using EHR data on this\ntopic is still limited. Detecting and mitigating AI bias with EHR data\ncontinues to pose challenges. Further research is needed to raise a\nstandardized method that is generalizable and interpretable to detect, mitigate\nand evaluate bias in medical AI.",
            "author": [
                "Feng Chen",
                "Liqin Wang",
                "Julie Hong",
                "Jiaqi Jiang",
                "Li Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19917v1",
                "http://arxiv.org/pdf/2310.19917v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19915v1",
            "title": "GPCR-BERT: Interpreting Sequential Design of G Protein Coupled Receptors\n  Using Protein Language Models",
            "updated": "2023-10-30T18:28:50Z",
            "published": "2023-10-30T18:28:50Z",
            "summary": "With the rise of Transformers and Large Language Models (LLMs) in Chemistry\nand Biology, new avenues for the design and understanding of therapeutics have\nopened up to the scientific community. Protein sequences can be modeled as\nlanguage and can take advantage of recent advances in LLMs, specifically with\nthe abundance of our access to the protein sequence datasets. In this paper, we\ndeveloped the GPCR-BERT model for understanding the sequential design of G\nProtein-Coupled Receptors (GPCRs). GPCRs are the target of over one-third of\nFDA-approved pharmaceuticals. However, there is a lack of comprehensive\nunderstanding regarding the relationship between amino acid sequence, ligand\nselectivity, and conformational motifs (such as NPxxY, CWxP, E/DRY). By\nutilizing the pre-trained protein model (Prot-Bert) and fine-tuning with\nprediction tasks of variations in the motifs, we were able to shed light on\nseveral relationships between residues in the binding pocket and some of the\nconserved motifs. To achieve this, we took advantage of attention weights, and\nhidden states of the model that are interpreted to extract the extent of\ncontributions of amino acids in dictating the type of masked ones. The\nfine-tuned models demonstrated high accuracy in predicting hidden residues\nwithin the motifs. In addition, the analysis of embedding was performed over 3D\nstructures to elucidate the higher-order interactions within the conformations\nof the receptors.",
            "author": [
                "Seongwon Kim",
                "Parisa Mollaei",
                "Akshay Antony",
                "Rishikesh Magar",
                "Amir Barati Farimani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19915v1",
                "http://arxiv.org/pdf/2310.19915v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19910v1",
            "title": "Bayesian Simulation-based Inference for Cosmological Initial Conditions",
            "updated": "2023-10-30T18:24:25Z",
            "published": "2023-10-30T18:24:25Z",
            "summary": "Reconstructing astrophysical and cosmological fields from observations is\nchallenging. It requires accounting for non-linear transformations, mixing of\nspatial structure, and noise. In contrast, forward simulators that map fields\nto observations are readily available for many applications. We present a\nversatile Bayesian field reconstruction algorithm rooted in simulation-based\ninference and enhanced by autoregressive modeling. The proposed technique is\napplicable to generic (non-differentiable) forward simulators and allows\nsampling from the posterior for the underlying field. We show first promising\nresults on a proof-of-concept application: the recovery of cosmological initial\nconditions from late-time density fields.",
            "author": [
                "Florian List",
                "Noemi Anau Montel",
                "Christoph Weniger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19910v1",
                "http://arxiv.org/pdf/2310.19910v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19909v2",
            "title": "Battle of the Backbones: A Large-Scale Comparison of Pretrained Models\n  across Computer Vision Tasks",
            "updated": "2023-11-20T03:05:50Z",
            "published": "2023-10-30T18:23:58Z",
            "summary": "Neural network based computer vision systems are typically built on a\nbackbone, a pretrained or randomly initialized feature extractor. Several years\nago, the default option was an ImageNet-trained convolutional neural network.\nHowever, the recent past has seen the emergence of countless backbones\npretrained using various algorithms and datasets. While this abundance of\nchoice has led to performance increases for a range of systems, it is difficult\nfor practitioners to make informed decisions about which backbone to choose.\nBattle of the Backbones (BoB) makes this choice easier by benchmarking a\ndiverse suite of pretrained models, including vision-language models, those\ntrained via self-supervised learning, and the Stable Diffusion backbone, across\na diverse set of computer vision tasks ranging from classification to object\ndetection to OOD generalization and more. Furthermore, BoB sheds light on\npromising directions for the research community to advance computer vision by\nilluminating strengths and weakness of existing approaches through a\ncomprehensive analysis conducted on more than 1500 training runs. While vision\ntransformers (ViTs) and self-supervised learning (SSL) are increasingly\npopular, we find that convolutional neural networks pretrained in a supervised\nfashion on large training sets still perform best on most tasks among the\nmodels we consider. Moreover, in apples-to-apples comparisons on the same\narchitectures and similarly sized pretraining datasets, we find that SSL\nbackbones are highly competitive, indicating that future works should perform\nSSL pretraining with advanced architectures and larger pretraining datasets. We\nrelease the raw results of our experiments along with code that allows\nresearchers to put their own backbones through the gauntlet here:\nhttps://github.com/hsouri/Battle-of-the-Backbones",
            "author": [
                "Micah Goldblum",
                "Hossein Souri",
                "Renkun Ni",
                "Manli Shu",
                "Viraj Prabhu",
                "Gowthami Somepalli",
                "Prithvijit Chattopadhyay",
                "Mark Ibrahim",
                "Adrien Bardes",
                "Judy Hoffman",
                "Rama Chellappa",
                "Andrew Gordon Wilson",
                "Tom Goldstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19909v2",
                "http://arxiv.org/pdf/2310.19909v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19906v1",
            "title": "Interpretable Prototype-based Graph Information Bottleneck",
            "updated": "2023-10-30T18:16:19Z",
            "published": "2023-10-30T18:16:19Z",
            "summary": "The success of Graph Neural Networks (GNNs) has led to a need for\nunderstanding their decision-making process and providing explanations for\ntheir predictions, which has given rise to explainable AI (XAI) that offers\ntransparent explanations for black-box models. Recently, the use of prototypes\nhas successfully improved the explainability of models by learning prototypes\nto imply training graphs that affect the prediction. However, these approaches\ntend to provide prototypes with excessive information from the entire graph,\nleading to the exclusion of key substructures or the inclusion of irrelevant\nsubstructures, which can limit both the interpretability and the performance of\nthe model in downstream tasks. In this work, we propose a novel framework of\nexplainable GNNs, called interpretable Prototype-based Graph Information\nBottleneck (PGIB) that incorporates prototype learning within the information\nbottleneck framework to provide prototypes with the key subgraph from the input\ngraph that is important for the model prediction. This is the first work that\nincorporates prototype learning into the process of identifying the key\nsubgraphs that have a critical impact on the prediction performance. Extensive\nexperiments, including qualitative analysis, demonstrate that PGIB outperforms\nstate-of-the-art methods in terms of both prediction performance and\nexplainability.",
            "author": [
                "Sangwoo Seo",
                "Sungwon Kim",
                "Chanyoung Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19906v1",
                "http://arxiv.org/pdf/2310.19906v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19904v1",
            "title": "ERGO-ML -- Comparing IllustrisTNG and HSC galaxy images via contrastive\n  learning",
            "updated": "2023-10-30T18:11:29Z",
            "published": "2023-10-30T18:11:29Z",
            "summary": "Modern cosmological hydrodynamical galaxy simulations provide tens of\nthousands of reasonably realistic synthetic galaxies across cosmic time.\nHowever, quantitatively assessing the level of realism of simulated universes\nin comparison to the real one is difficult. In this paper of the ERGO-ML series\n(Extracting Reality from Galaxy Observables with Machine Learning), we utilize\ncontrastive learning to directly compare a large sample of simulated and\nobserved galaxies based on their stellar-light images. This eliminates the need\nto specify summary statistics and allows to exploit the whole information\ncontent of the observations. We produce survey-realistic galaxy mock datasets\nresembling real Hyper Suprime-Cam (HSC) observations using the cosmological\nsimulations TNG50 and TNG100. Our focus is on galaxies with stellar masses\nbetween $10^9$ and $10^{12} M_\\odot$ at $z=0.1-0.4$. This allows us to evaluate\nthe realism of the simulated TNG galaxies in comparison to actual HSC\nobservations. We apply the self-supervised contrastive learning method NNCLR to\nthe images from both simulated and observed datasets (g, r, i - bands). This\nresults in a 256-dimensional representation space, encoding all relevant\nobservable galaxy properties. Firstly, this allows us to identify simulated\ngalaxies that closely resemble real ones by seeking similar images in this\nmulti-dimensional space. Even more powerful, we quantify the alignment between\nthe representations of these two image sets, finding that the majority\n($\\gtrsim 70$ per cent) of the TNG galaxies align well with observed HSC\nimages. However, a subset of simulated galaxies with larger sizes, steeper\nSersic profiles, smaller Sersic ellipticities, and larger asymmetries appears\nunrealistic. We also demonstrate the utility of our derived image\nrepresentations by inferring properties of real HSC galaxies using simulated\nTNG galaxies as the ground truth.",
            "author": [
                "Lukas Eisert",
                "Connor Bottrell",
                "Annalisa Pillepich",
                "Rhythm Shimakawa",
                "Vicente Rodriguez-Gomez",
                "Dylan Nelson",
                "Eirini Angeloudi",
                "Marc Huertas-Company"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19904v1",
                "http://arxiv.org/pdf/2310.19904v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19898v1",
            "title": "MIST: Medical Image Segmentation Transformer with Convolutional\n  Attention Mixing (CAM) Decoder",
            "updated": "2023-10-30T18:07:57Z",
            "published": "2023-10-30T18:07:57Z",
            "summary": "One of the common and promising deep learning approaches used for medical\nimage segmentation is transformers, as they can capture long-range dependencies\namong the pixels by utilizing self-attention. Despite being successful in\nmedical image segmentation, transformers face limitations in capturing local\ncontexts of pixels in multimodal dimensions. We propose a Medical Image\nSegmentation Transformer (MIST) incorporating a novel Convolutional Attention\nMixing (CAM) decoder to address this issue. MIST has two parts: a pre-trained\nmulti-axis vision transformer (MaxViT) is used as an encoder, and the encoded\nfeature representation is passed through the CAM decoder for segmenting the\nimages. In the CAM decoder, an attention-mixer combining multi-head\nself-attention, spatial attention, and squeeze and excitation attention modules\nis introduced to capture long-range dependencies in all spatial dimensions.\nMoreover, to enhance spatial information gain, deep and shallow convolutions\nare used for feature extraction and receptive field expansion, respectively.\nThe integration of low-level and high-level features from different network\nstages is enabled by skip connections, allowing MIST to suppress unnecessary\ninformation. The experiments show that our MIST transformer with CAM decoder\noutperforms the state-of-the-art models specifically designed for medical image\nsegmentation on the ACDC and Synapse datasets. Our results also demonstrate\nthat adding the CAM decoder with a hierarchical transformer improves\nsegmentation performance significantly. Our model with data and code is\npublicly available on GitHub.",
            "author": [
                "Md Motiur Rahman",
                "Shiva Shokouhmand",
                "Smriti Bhatt",
                "Miad Faezipour"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19898v1",
                "http://arxiv.org/pdf/2310.19898v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19889v1",
            "title": "Exploring Geometry of Blind Spots in Vision Models",
            "updated": "2023-10-30T18:00:33Z",
            "published": "2023-10-30T18:00:33Z",
            "summary": "Despite the remarkable success of deep neural networks in a myriad of\nsettings, several works have demonstrated their overwhelming sensitivity to\nnear-imperceptible perturbations, known as adversarial attacks. On the other\nhand, prior works have also observed that deep networks can be under-sensitive,\nwherein large-magnitude perturbations in input space do not induce appreciable\nchanges to network activations. In this work, we study in detail the phenomenon\nof under-sensitivity in vision models such as CNNs and Transformers, and\npresent techniques to study the geometry and extent of \"equi-confidence\" level\nsets of such networks. We propose a Level Set Traversal algorithm that\niteratively explores regions of high confidence with respect to the input space\nusing orthogonal components of the local gradients. Given a source image, we\nuse this algorithm to identify inputs that lie in the same equi-confidence\nlevel set as the source image despite being perceptually similar to arbitrary\nimages from other classes. We further observe that the source image is linearly\nconnected by a high-confidence path to these inputs, uncovering a star-like\nstructure for level sets of deep networks. Furthermore, we attempt to identify\nand estimate the extent of these connected higher-dimensional regions over\nwhich the model maintains a high degree of confidence. The code for this\nproject is publicly available at\nhttps://github.com/SriramB-98/blindspots-neurips-sub",
            "author": [
                "Sriram Balasubramanian",
                "Gaurang Sriramanan",
                "Vinu Sankar Sadasivan",
                "Soheil Feizi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19889v1",
                "http://arxiv.org/pdf/2310.19889v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "I.2.6; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19886v1",
            "title": "BTRec: BERT-Based Trajectory Recommendation for Personalized Tours",
            "updated": "2023-10-30T18:00:26Z",
            "published": "2023-10-30T18:00:26Z",
            "summary": "An essential task for tourists having a pleasant holiday is to have a\nwell-planned itinerary with relevant recommendations, especially when visiting\nunfamiliar cities. Many tour recommendation tools only take into account a\nlimited number of factors, such as popular Points of Interest (POIs) and\nrouting constraints. Consequently, the solutions they provide may not always\nalign with the individual users of the system. We propose an iterative\nalgorithm in this paper, namely: BTREC (BERT-based Trajectory Recommendation),\nthat extends from the POIBERT embedding algorithm to recommend personalized\nitineraries on POIs using the BERT framework. Our BTREC algorithm incorporates\nusers' demographic information alongside past POI visits into a modified BERT\nlanguage model to recommend a personalized POI itinerary prediction given a\npair of source and destination POIs. Our recommendation system can create a\ntravel itinerary that maximizes POIs visited, while also taking into account\nuser preferences for categories of POIs and time availability. Our\nrecommendation algorithm is largely inspired by the problem of sentence\ncompletion in natural language processing (NLP). Using a dataset of eight\ncities of different sizes, our experimental results demonstrate that our\nproposed algorithm is stable and outperforms many other sequence prediction\nalgorithms, measured by recall, precision, and F1-scores.",
            "author": [
                "Ngai Lam Ho",
                "Roy Ka-Wei Lee",
                "Kwan Hui Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19886v1",
                "http://arxiv.org/pdf/2310.19886v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19882v1",
            "title": "Learning quantum states and unitaries of bounded gate complexity",
            "updated": "2023-10-30T18:00:03Z",
            "published": "2023-10-30T18:00:03Z",
            "summary": "While quantum state tomography is notoriously hard, most states hold little\ninterest to practically-minded tomographers. Given that states and unitaries\nappearing in Nature are of bounded gate complexity, it is natural to ask if\nefficient learning becomes possible. In this work, we prove that to learn a\nstate generated by a quantum circuit with $G$ two-qubit gates to a small trace\ndistance, a sample complexity scaling linearly in $G$ is necessary and\nsufficient. We also prove that the optimal query complexity to learn a unitary\ngenerated by $G$ gates to a small average-case error scales linearly in $G$.\nWhile sample-efficient learning can be achieved, we show that under reasonable\ncryptographic conjectures, the computational complexity for learning states and\nunitaries of gate complexity $G$ must scale exponentially in $G$. We illustrate\nhow these results establish fundamental limitations on the expressivity of\nquantum machine learning models and provide new perspectives on no-free-lunch\ntheorems in unitary learning. Together, our results answer how the complexity\nof learning quantum states and unitaries relate to the complexity of creating\nthese states and unitaries.",
            "author": [
                "Haimeng Zhao",
                "Laura Lewis",
                "Ishaan Kannan",
                "Yihui Quek",
                "Hsin-Yuan Huang",
                "Matthias C. Caro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19882v1",
                "http://arxiv.org/pdf/2310.19882v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19870v1",
            "title": "Metric Flows with Neural Networks",
            "updated": "2023-10-30T18:00:01Z",
            "published": "2023-10-30T18:00:01Z",
            "summary": "We develop a theory of flows in the space of Riemannian metrics induced by\nneural network gradient descent. This is motivated in part by recent advances\nin approximating Calabi-Yau metrics with neural networks and is enabled by\nrecent advances in understanding flows in the space of neural networks. We\nderive the corresponding metric flow equations, which are governed by a metric\nneural tangent kernel, a complicated, non-local object that evolves in time.\nHowever, many architectures admit an infinite-width limit in which the kernel\nbecomes fixed and the dynamics simplify. Additional assumptions can induce\nlocality in the flow, which allows for the realization of Perelman's\nformulation of Ricci flow that was used to resolve the 3d Poincar\\'e\nconjecture. We apply these ideas to numerical Calabi-Yau metrics, including a\ndiscussion on the importance of feature learning.",
            "author": [
                "James Halverson",
                "Fabian Ruehle"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19870v1",
                "http://arxiv.org/pdf/2310.19870v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cs.LG",
                "math.DG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19798v1",
            "title": "Gradient-Based Dovetail Joint Shape Optimization for Stiffness",
            "updated": "2023-10-30T17:59:52Z",
            "published": "2023-10-30T17:59:52Z",
            "summary": "It is common to manufacture an object by decomposing it into parts that can\nbe assembled. This decomposition is often required by size limits of the\nmachine, the complex structure of the shape, etc. To make it possible to easily\nassemble the final object, it is often desirable to design geometry that\nenables robust connections between the subcomponents. In this project, we study\nthe task of dovetail-joint shape optimization for stiffness using\ngradient-based optimization. This optimization requires a differentiable\nsimulator that is capable of modeling the contact between the two parts of a\njoint, making it possible to reason about the gradient of the stiffness with\nrespect to shape parameters. Our simulation approach uses a penalty method that\nalternates between optimizing each side of the joint, using the adjoint method\nto compute gradients. We test our method by optimizing the joint shapes in\nthree different joint shape spaces, and evaluate optimized joint shapes in both\nsimulation and real-world tests. The experiments show that optimized joint\nshapes achieve higher stiffness, both synthetically and in real-world tests.",
            "author": [
                "Xingyuan Sun",
                "Chenyue Cai",
                "Ryan P. Adams",
                "Szymon Rusinkiewicz"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3623263.3623364",
                "http://arxiv.org/abs/2310.19798v1",
                "http://arxiv.org/pdf/2310.19798v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19797v1",
            "title": "DEFT: Dexterous Fine-Tuning for Real-World Hand Policies",
            "updated": "2023-10-30T17:59:35Z",
            "published": "2023-10-30T17:59:35Z",
            "summary": "Dexterity is often seen as a cornerstone of complex manipulation. Humans are\nable to perform a host of skills with their hands, from making food to\noperating tools. In this paper, we investigate these challenges, especially in\nthe case of soft, deformable objects as well as complex, relatively\nlong-horizon tasks. However, learning such behaviors from scratch can be data\ninefficient. To circumvent this, we propose a novel approach, DEFT (DExterous\nFine-Tuning for Hand Policies), that leverages human-driven priors, which are\nexecuted directly in the real world. In order to improve upon these priors,\nDEFT involves an efficient online optimization procedure. With the integration\nof human-based learning and online fine-tuning, coupled with a soft robotic\nhand, DEFT demonstrates success across various tasks, establishing a robust,\ndata-efficient pathway toward general dexterous manipulation. Please see our\nwebsite at https://dexterous-finetuning.github.io for video results.",
            "author": [
                "Aditya Kannan",
                "Kenneth Shaw",
                "Shikhar Bahl",
                "Pragna Mannam",
                "Deepak Pathak"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19797v1",
                "http://arxiv.org/pdf/2310.19797v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19861v1",
            "title": "Posterior Sampling for Competitive RL: Function Approximation and\n  Partial Observation",
            "updated": "2023-10-30T17:59:26Z",
            "published": "2023-10-30T17:59:26Z",
            "summary": "This paper investigates posterior sampling algorithms for competitive\nreinforcement learning (RL) in the context of general function approximations.\nFocusing on zero-sum Markov games (MGs) under two critical settings, namely\nself-play and adversarial learning, we first propose the self-play and\nadversarial generalized eluder coefficient (GEC) as complexity measures for\nfunction approximation, capturing the exploration-exploitation trade-off in\nMGs. Based on self-play GEC, we propose a model-based self-play posterior\nsampling method to control both players to learn Nash equilibrium, which can\nsuccessfully handle the partial observability of states. Furthermore, we\nidentify a set of partially observable MG models fitting MG learning with the\nadversarial policies of the opponent. Incorporating the adversarial GEC, we\npropose a model-based posterior sampling method for learning adversarial MG\nwith potential partial observability. We further provide low regret bounds for\nproposed algorithms that can scale sublinearly with the proposed GEC and the\nnumber of episodes $T$. To the best of our knowledge, we for the first time\ndevelop generic model-based posterior sampling algorithms for competitive RL\nthat can be applied to a majority of tractable zero-sum MG classes in both\nfully observable and partially observable MGs with self-play and adversarial\nlearning.",
            "author": [
                "Shuang Qiu",
                "Ziyu Dai",
                "Han Zhong",
                "Zhaoran Wang",
                "Zhuoran Yang",
                "Tong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19861v1",
                "http://arxiv.org/pdf/2310.19861v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19796v1",
            "title": "Re-evaluating Retrosynthesis Algorithms with Syntheseus",
            "updated": "2023-10-30T17:59:04Z",
            "published": "2023-10-30T17:59:04Z",
            "summary": "The planning of how to synthesize molecules, also known as retrosynthesis,\nhas been a growing focus of the machine learning and chemistry communities in\nrecent years. Despite the appearance of steady progress, we argue that\nimperfect benchmarks and inconsistent comparisons mask systematic shortcomings\nof existing techniques. To remedy this, we present a benchmarking library\ncalled syntheseus which promotes best practice by default, enabling consistent\nmeaningful evaluation of single-step and multi-step retrosynthesis algorithms.\nWe use syntheseus to re-evaluate a number of previous retrosynthesis\nalgorithms, and find that the ranking of state-of-the-art models changes when\nevaluated carefully. We end with guidance for future works in this area.",
            "author": [
                "Krzysztof Maziarz",
                "Austin Tripp",
                "Guoqing Liu",
                "Megan Stanley",
                "Shufang Xie",
                "Piotr Gai\u0144ski",
                "Philipp Seidl",
                "Marwin Segler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19796v1",
                "http://arxiv.org/pdf/2310.19796v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19859v1",
            "title": "Res-Tuning: A Flexible and Efficient Tuning Paradigm via Unbinding Tuner\n  from Backbone",
            "updated": "2023-10-30T17:58:19Z",
            "published": "2023-10-30T17:58:19Z",
            "summary": "Parameter-efficient tuning has become a trend in transferring large-scale\nfoundation models to downstream applications. Existing methods typically embed\nsome light-weight tuners into the backbone, where both the design and the\nlearning of the tuners are highly dependent on the base model. This work offers\na new tuning paradigm, dubbed Res-Tuning, which intentionally unbinds tuners\nfrom the backbone. With both theoretical and empirical evidence, we show that\npopular tuning approaches have their equivalent counterparts under our\nunbinding formulation, and hence can be integrated into our framework\neffortlessly. Thanks to the structural disentanglement, we manage to free the\ndesign of tuners from the network architecture, facilitating flexible\ncombination of various tuning strategies. We further propose a memory-efficient\nvariant of Res-Tuning, where the bypass i.e., formed by a sequence of tuners)\nis effectively detached from the main branch, such that the gradients are\nback-propagated only to the tuners but not to the backbone. Such a detachment\nalso allows one-time backbone forward for multi-task inference. Extensive\nexperiments on both discriminative and generative tasks demonstrate the\nsuperiority of our method over existing alternatives from the perspectives of\nefficacy and efficiency. Project page:\n$\\href{https://res-tuning.github.io/}{\\textit{https://res-tuning.github.io/}}$.",
            "author": [
                "Zeyinzi Jiang",
                "Chaojie Mao",
                "Ziyuan Huang",
                "Ao Ma",
                "Yiliang Lv",
                "Yujun Shen",
                "Deli Zhao",
                "Jingren Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19859v1",
                "http://arxiv.org/pdf/2310.19859v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19795v1",
            "title": "SimMMDG: A Simple and Effective Framework for Multi-modal Domain\n  Generalization",
            "updated": "2023-10-30T17:58:09Z",
            "published": "2023-10-30T17:58:09Z",
            "summary": "In real-world scenarios, achieving domain generalization (DG) presents\nsignificant challenges as models are required to generalize to unknown target\ndistributions. Generalizing to unseen multi-modal distributions poses even\ngreater difficulties due to the distinct properties exhibited by different\nmodalities. To overcome the challenges of achieving domain generalization in\nmulti-modal scenarios, we propose SimMMDG, a simple yet effective multi-modal\nDG framework. We argue that mapping features from different modalities into the\nsame embedding space impedes model generalization. To address this, we propose\nsplitting the features within each modality into modality-specific and\nmodality-shared components. We employ supervised contrastive learning on the\nmodality-shared features to ensure they possess joint properties and impose\ndistance constraints on modality-specific features to promote diversity. In\naddition, we introduce a cross-modal translation module to regularize the\nlearned features, which can also be used for missing-modality generalization.\nWe demonstrate that our framework is theoretically well-supported and achieves\nstrong performance in multi-modal DG on the EPIC-Kitchens dataset and the novel\nHuman-Animal-Cartoon (HAC) dataset introduced in this paper. Our source code\nand HAC dataset are available at https://github.com/donghao51/SimMMDG.",
            "author": [
                "Hao Dong",
                "Ismail Nejjar",
                "Han Sun",
                "Eleni Chatzi",
                "Olga Fink"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19795v1",
                "http://arxiv.org/pdf/2310.19795v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19794v1",
            "title": "Robust Causal Bandits for Linear Models",
            "updated": "2023-10-30T17:58:01Z",
            "published": "2023-10-30T17:58:01Z",
            "summary": "Sequential design of experiments for optimizing a reward function in causal\nsystems can be effectively modeled by the sequential design of interventions in\ncausal bandits (CBs). In the existing literature on CBs, a critical assumption\nis that the causal models remain constant over time. However, this assumption\ndoes not necessarily hold in complex systems, which constantly undergo temporal\nmodel fluctuations. This paper addresses the robustness of CBs to such model\nfluctuations. The focus is on causal systems with linear structural equation\nmodels (SEMs). The SEMs and the time-varying pre- and post-interventional\nstatistical models are all unknown. Cumulative regret is adopted as the design\ncriteria, based on which the objective is to design a sequence of interventions\nthat incur the smallest cumulative regret with respect to an oracle aware of\nthe entire causal model and its fluctuations. First, it is established that the\nexisting approaches fail to maintain regret sub-linearity with even a few\ninstances of model deviation. Specifically, when the number of instances with\nmodel deviation is as few as $T^\\frac{1}{2L}$, where $T$ is the time horizon\nand $L$ is the longest causal path in the graph, the existing algorithms will\nhave linear regret in $T$. Next, a robust CB algorithm is designed, and its\nregret is analyzed, where upper and information-theoretic lower bounds on the\nregret are established. Specifically, in a graph with $N$ nodes and maximum\ndegree $d$, under a general measure of model deviation $C$, the cumulative\nregret is upper bounded by $\\tilde{\\mathcal{O}}(d^{L-\\frac{1}{2}}(\\sqrt{NT} +\nNC))$ and lower bounded by $\\Omega(d^{\\frac{L}{2}-2}\\max\\{\\sqrt{T},d^2C\\})$.\nComparing these bounds establishes that the proposed algorithm achieves nearly\noptimal $\\tilde{\\mathcal{O}}(\\sqrt{T})$ regret when $C$ is $o(\\sqrt{T})$ and\nmaintains sub-linear regret for a broader range of $C$.",
            "author": [
                "Zirui Yan",
                "Arpan Mukherjee",
                "Burak Var\u0131c\u0131",
                "Ali Tajer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19794v1",
                "http://arxiv.org/pdf/2310.19794v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19858v1",
            "title": "iGEM: a model system for team science and innovation",
            "updated": "2023-10-30T17:58:01Z",
            "published": "2023-10-30T17:58:01Z",
            "summary": "Teams are a primary source of innovation in science and technology. Rather\nthan examining the lone genius, scholarly and policy attention has shifted to\nunderstanding how team interactions produce new and useful ideas. Yet the\norganizational roots of innovation remain unclear, in part because of the\nlimitations of current data. This paper introduces the international\nGenetically Engineered Machine (iGEM) competition, a model system for studying\nteam science and innovation. By combining digital laboratory notebooks with\nperformance data from 2,406 teams over multiple years of participation, we\nreveal shared dynamical and organizational patterns across teams and identify\nfeatures associated with team performance and success. This dataset makes\nvisible organizational behavior that is typically hidden, and thus\nunderstudied, creating new opportunities for the science of science and\ninnovation.",
            "author": [
                "Marc Santolini",
                "Leo Blondel",
                "Megan J. Palmer",
                "Robert N. Ward",
                "Rathin Jeyaram",
                "Kathryn R. Brink",
                "Abhijeet Krishna",
                "Albert-Laszlo Barabasi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19858v1",
                "http://arxiv.org/pdf/2310.19858v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19793v2",
            "title": "On Learning Gaussian Multi-index Models with Gradient Flow",
            "updated": "2023-11-02T17:33:13Z",
            "published": "2023-10-30T17:55:28Z",
            "summary": "We study gradient flow on the multi-index regression problem for\nhigh-dimensional Gaussian data. Multi-index functions consist of a composition\nof an unknown low-rank linear projection and an arbitrary unknown,\nlow-dimensional link function. As such, they constitute a natural template for\nfeature learning in neural networks.\n  We consider a two-timescale algorithm, whereby the low-dimensional link\nfunction is learnt with a non-parametric model infinitely faster than the\nsubspace parametrizing the low-rank projection. By appropriately exploiting the\nmatrix semigroup structure arising over the subspace correlation matrices, we\nestablish global convergence of the resulting Grassmannian population gradient\nflow dynamics, and provide a quantitative description of its associated\n`saddle-to-saddle' dynamics. Notably, the timescales associated with each\nsaddle can be explicitly characterized in terms of an appropriate Hermite\ndecomposition of the target link function. In contrast with these positive\nresults, we also show that the related \\emph{planted} problem, where the link\nfunction is known and fixed, in fact has a rough optimization landscape, in\nwhich gradient flow dynamics might get trapped with high probability.",
            "author": [
                "Alberto Bietti",
                "Joan Bruna",
                "Loucas Pillaud-Vivien"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19793v2",
                "http://arxiv.org/pdf/2310.19793v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19792v1",
            "title": "The Eval4NLP 2023 Shared Task on Prompting Large Language Models as\n  Explainable Metrics",
            "updated": "2023-10-30T17:55:08Z",
            "published": "2023-10-30T17:55:08Z",
            "summary": "With an increasing number of parameters and pre-training data, generative\nlarge language models (LLMs) have shown remarkable capabilities to solve tasks\nwith minimal or no task-related examples. Notably, LLMs have been successfully\nemployed as evaluation metrics in text generation tasks. Within this context,\nwe introduce the Eval4NLP 2023 shared task that asks participants to explore\nprompting and score extraction for machine translation (MT) and summarization\nevaluation. Specifically, we propose a novel competition setting in which we\nselect a list of allowed LLMs and disallow fine-tuning to ensure a focus on\nprompting. We present an overview of participants' approaches and evaluate them\non a new reference-free test set spanning three language pairs for MT and a\nsummarization dataset. Notably, despite the task's restrictions, the\nbest-performing systems achieve results on par with or even surpassing recent\nreference-free metrics developed using larger models, including GEMBA and\nComet-Kiwi-XXL. Finally, as a separate track, we perform a small-scale human\nevaluation of the plausibility of explanations given by the LLMs.",
            "author": [
                "Christoph Leiter",
                "Juri Opitz",
                "Daniel Deutsch",
                "Yang Gao",
                "Rotem Dror",
                "Steffen Eger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19792v1",
                "http://arxiv.org/pdf/2310.19792v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19790v1",
            "title": "Detection and Preliminary Characterisation of Polluted White Dwarfs from\n  Gaia EDR3 and LAMOST",
            "updated": "2023-10-30T17:55:02Z",
            "published": "2023-10-30T17:55:02Z",
            "summary": "We present a catalogue of 62 polluted white dwarfs observed by the 9th\nLow-Resolution Data Release of the Large Sky Area Multi-Object Fiber\nSpectroscopic Telescope (LAMOST LRS DR9v1; R$\\approx$1,800) and the Early Data\nRelease 3 (EDR3) of the Gaia Mission. Among these stellar remnants, 30 are new\ndiscoveries with previously unknown traces of calcium pollution. To generate\nour catalogue, we used a database of 4,324 unique Gaia EDR3 white dwarf\ncandidates with LAMOST LRS DR9v1 observations, many of which have been\nspectroscopically confirmed by other telescopes. For these stars, we developed\na quantitative method to detect calcium absorption in their spectra between\n3,900-4,000$\\mathring {\\mathrm A}$, which we then validated through visual\ninspection and multiple literature cross-checks. Our catalogue provides the\nastrometric and photometric properties of the white dwarf candidates,\nincorporates supplementary data (e.g. Montreal White Dwarf Database, MWDD;\nPanSTARRS; the Hubble Space Telescope), and indicates the possibility of\ncalcium pollution in their atmospheres. For our final sample of polluted white\ndwarfs, we also determine the main atmospheric properties of 23 sources with\neffective temperatures $T_{\\rm eff}$$\\leq$25,000K and no existing calcium\nabundances in the MWDD. Our analysis represents a first step towards measuring\nthe full atmospheric composition of these stars and learning about the bulk\nproperties of their accreted material. As we venture into the era of wide-field\nspectroscopic surveys, our work highlights the importance of combining\nlarge-scale databases for identifying and characterising new polluted white\ndwarfs.",
            "author": [
                "Mariona Badenas-Agusti",
                "Andrew Vanderburg",
                "Simon Blouin",
                "Patrick Dufour",
                "Javier Via\u00f1a",
                "Sara Seager",
                "Sharon X. Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19790v1",
                "http://arxiv.org/pdf/2310.19790v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19791v1",
            "title": "LILO: Learning Interpretable Libraries by Compressing and Documenting\n  Code",
            "updated": "2023-10-30T17:55:02Z",
            "published": "2023-10-30T17:55:02Z",
            "summary": "While large language models (LLMs) now excel at code generation, a key aspect\nof software development is the art of refactoring: consolidating code into\nlibraries of reusable and readable programs. In this paper, we introduce LILO,\na neurosymbolic framework that iteratively synthesizes, compresses, and\ndocuments code to build libraries tailored to particular problem domains. LILO\ncombines LLM-guided program synthesis with recent algorithmic advances in\nautomated refactoring from Stitch: a symbolic compression system that\nefficiently identifies optimal lambda abstractions across large code corpora.\nTo make these abstractions interpretable, we introduce an auto-documentation\n(AutoDoc) procedure that infers natural language names and docstrings based on\ncontextual examples of usage. In addition to improving human readability, we\nfind that AutoDoc boosts performance by helping LILO's synthesizer to interpret\nand deploy learned abstractions. We evaluate LILO on three inductive program\nsynthesis benchmarks for string editing, scene reasoning, and graphics\ncomposition. Compared to existing neural and symbolic methods - including the\nstate-of-the-art library learning algorithm DreamCoder - LILO solves more\ncomplex tasks and learns richer libraries that are grounded in linguistic\nknowledge.",
            "author": [
                "Gabriel Grand",
                "Lionel Wong",
                "Matthew Bowers",
                "Theo X. Olausson",
                "Muxin Liu",
                "Joshua B. Tenenbaum",
                "Jacob Andreas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19791v1",
                "http://arxiv.org/pdf/2310.19791v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19789v1",
            "title": "DiffEnc: Variational Diffusion with a Learned Encoder",
            "updated": "2023-10-30T17:54:36Z",
            "published": "2023-10-30T17:54:36Z",
            "summary": "Diffusion models may be viewed as hierarchical variational autoencoders\n(VAEs) with two improvements: parameter sharing for the conditional\ndistributions in the generative process and efficient computation of the loss\nas independent terms over the hierarchy. We consider two changes to the\ndiffusion model that retain these advantages while adding flexibility to the\nmodel. Firstly, we introduce a data- and depth-dependent mean function in the\ndiffusion process, which leads to a modified diffusion loss. Our proposed\nframework, DiffEnc, achieves state-of-the-art likelihood on CIFAR-10. Secondly,\nwe let the ratio of the noise variance of the reverse encoder process and the\ngenerative process be a free weight parameter rather than being fixed to 1.\nThis leads to theoretical insights: For a finite depth hierarchy, the evidence\nlower bound (ELBO) can be used as an objective for a weighted diffusion loss\napproach and for optimizing the noise schedule specifically for inference. For\nthe infinite-depth hierarchy, on the other hand, the weight parameter has to be\n1 to have a well-defined ELBO.",
            "author": [
                "Beatrix M. G. Nielsen",
                "Anders Christensen",
                "Andrea Dittadi",
                "Ole Winther"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19789v1",
                "http://arxiv.org/pdf/2310.19789v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19788v2",
            "title": "Worst-Case Optimal Multi-Armed Gaussian Best Arm Identification with a\n  Fixed Budget",
            "updated": "2023-12-02T14:36:15Z",
            "published": "2023-10-30T17:52:46Z",
            "summary": "Experimental design is crucial in evidence-based decision-making with\nmultiple treatment arms, such as online advertisements and medical treatments.\nThis study investigates the problem of identifying the treatment arm with the\nhighest expected outcome, referred to as the best treatment arm, while\nminimizing the probability of misidentification. This problem has been studied\nacross numerous research fields, including best arm identification (BAI) and\nordinal optimization. In our experiments, the number of treatment-allocation\nrounds is fixed. During each round, a decision-maker allocates a treatment arm\nto an experimental unit and observes a corresponding outcome, which follows a\nGaussian distribution with variances that can differ among the treatment arms.\nAt the end of the experiment, we recommend one of the treatment arms as an\nestimate of the best treatment arm based on the observations. To design an\nexperiment, we first discuss the worst-case lower bound for the probability of\nmisidentification through an information-theoretic approach. Then, under the\nassumption that the variances are known, we propose the\nGeneralized-Neyman-Allocation (GNA)-empirical-best-arm (EBA) strategy, an\nextension of the Neyman allocation proposed by Neyman (1934). We show that the\nGNA-EBA strategy is asymptotically optimal in the sense that its probability of\nmisidentification aligns with the lower bounds as the sample size increases\nindefinitely and the differences between the expected outcomes of the best and\nother suboptimal arms converge to a uniform value. We refer to such strategies\nas asymptotically worst-case optimal.",
            "author": [
                "Masahiro Kato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19788v2",
                "http://arxiv.org/pdf/2310.19788v2"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.LG",
                "econ.EM",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19787v1",
            "title": "$e^{\\text{RPCA}}$: Robust Principal Component Analysis for Exponential\n  Family Distributions",
            "updated": "2023-10-30T17:51:30Z",
            "published": "2023-10-30T17:51:30Z",
            "summary": "Robust Principal Component Analysis (RPCA) is a widely used method for\nrecovering low-rank structure from data matrices corrupted by significant and\nsparse outliers. These corruptions may arise from occlusions, malicious\ntampering, or other causes for anomalies, and the joint identification of such\ncorruptions with low-rank background is critical for process monitoring and\ndiagnosis. However, existing RPCA methods and their extensions largely do not\naccount for the underlying probabilistic distribution for the data matrices,\nwhich in many applications are known and can be highly non-Gaussian. We thus\npropose a new method called Robust Principal Component Analysis for Exponential\nFamily distributions ($e^{\\text{RPCA}}$), which can perform the desired\ndecomposition into low-rank and sparse matrices when such a distribution falls\nwithin the exponential family. We present a novel alternating direction method\nof multiplier optimization algorithm for efficient $e^{\\text{RPCA}}$\ndecomposition. The effectiveness of $e^{\\text{RPCA}}$ is then demonstrated in\ntwo applications: the first for steel sheet defect detection, and the second\nfor crime activity monitoring in the Atlanta metropolitan area.",
            "author": [
                "Xiaojun Zheng",
                "Simon Mak",
                "Liyan Xie",
                "Yao Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19787v1",
                "http://arxiv.org/pdf/2310.19787v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19786v3",
            "title": "From External to Swap Regret 2.0: An Efficient Reduction and Oblivious\n  Adversary for Large Action Spaces",
            "updated": "2023-12-06T07:34:24Z",
            "published": "2023-10-30T17:50:29Z",
            "summary": "We provide a novel reduction from swap-regret minimization to external-regret\nminimization, which improves upon the classical reductions of Blum-Mansour\n[BM07] and Stolz-Lugosi [SL05] in that it does not require finiteness of the\nspace of actions. We show that, whenever there exists a no-external-regret\nalgorithm for some hypothesis class, there must also exist a no-swap-regret\nalgorithm for that same class. For the problem of learning with expert advice,\nour result implies that it is possible to guarantee that the swap regret is\nbounded by {\\epsilon} after $\\log(N)^{O(1/\\epsilon)}$ rounds and with $O(N)$\nper iteration complexity, where $N$ is the number of experts, while the\nclassical reductions of Blum-Mansour and Stolz-Lugosi require $O(N/\\epsilon^2)$\nrounds and at least $\\Omega(N^2)$ per iteration complexity. Our result comes\nwith an associated lower bound, which -- in contrast to that in [BM07] -- holds\nfor oblivious and $\\ell_1$-constrained adversaries and learners that can employ\ndistributions over experts, showing that the number of rounds must be\n$\\tilde\\Omega(N/\\epsilon^2)$ or exponential in $1/\\epsilon$.\n  Our reduction implies that, if no-regret learning is possible in some game,\nthen this game must have approximate correlated equilibria, of arbitrarily good\napproximation. This strengthens the folklore implication of no-regret learning\nthat approximate coarse correlated equilibria exist. Importantly, it provides a\nsufficient condition for the existence of correlated equilibrium which vastly\nextends the requirement that the action set is finite, thus answering a\nquestion left open by [DG22; Ass+23]. Moreover, it answers several outstanding\nquestions about equilibrium computation and learning in games.",
            "author": [
                "Yuval Dagan",
                "Constantinos Daskalakis",
                "Maxwell Fishelson",
                "Noah Golowich"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19786v3",
                "http://arxiv.org/pdf/2310.19786v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19785v1",
            "title": "What's \"up\" with vision-language models? Investigating their struggle\n  with spatial reasoning",
            "updated": "2023-10-30T17:50:15Z",
            "published": "2023-10-30T17:50:15Z",
            "summary": "Recent vision-language (VL) models are powerful, but can they reliably\ndistinguish \"right\" from \"left\"? We curate three new corpora to quantify model\ncomprehension of such basic spatial relations. These tests isolate spatial\nreasoning more precisely than existing datasets like VQAv2, e.g., our What'sUp\nbenchmark contains sets of photographs varying only the spatial relations of\nobjects, keeping their identity fixed (see Figure 1: models must comprehend not\nonly the usual case of a dog under a table, but also, the same dog on top of\nthe same table). We evaluate 18 VL models, finding that all perform poorly,\ne.g., BLIP finetuned on VQAv2, which nears human parity on VQAv2, achieves 56%\naccuracy on our benchmarks vs. humans at 99%. We conclude by studying causes of\nthis surprising behavior, finding: 1) that popular vision-language pretraining\ncorpora like LAION-2B contain little reliable data for learning spatial\nrelationships; and 2) that basic modeling interventions like up-weighting\npreposition-containing instances or fine-tuning on our corpora are not\nsufficient to address the challenges our benchmarks pose. We are hopeful that\nthese corpora will facilitate further research, and we release our data and\ncode at https://github.com/amitakamath/whatsup_vlms.",
            "author": [
                "Amita Kamath",
                "Jack Hessel",
                "Kai-Wei Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19785v1",
                "http://arxiv.org/pdf/2310.19785v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19776v2",
            "title": "Learn to Categorize or Categorize to Learn? Self-Coding for Generalized\n  Category Discovery",
            "updated": "2023-11-06T14:00:11Z",
            "published": "2023-10-30T17:45:32Z",
            "summary": "In the quest for unveiling novel categories at test time, we confront the\ninherent limitations of traditional supervised recognition models that are\nrestricted by a predefined category set. While strides have been made in the\nrealms of self-supervised and open-world learning towards test-time category\ndiscovery, a crucial yet often overlooked question persists: what exactly\ndelineates a category? In this paper, we conceptualize a category through the\nlens of optimization, viewing it as an optimal solution to a well-defined\nproblem. Harnessing this unique conceptualization, we propose a novel,\nefficient and self-supervised method capable of discovering previously unknown\ncategories at test time. A salient feature of our approach is the assignment of\nminimum length category codes to individual data instances, which encapsulates\nthe implicit category hierarchy prevalent in real-world datasets. This\nmechanism affords us enhanced control over category granularity, thereby\nequipping our model to handle fine-grained categories adeptly. Experimental\nevaluations, bolstered by state-of-the-art benchmark comparisons, testify to\nthe efficacy of our solution in managing unknown categories at test time.\nFurthermore, we fortify our proposition with a theoretical foundation,\nproviding proof of its optimality. Our code is available at\nhttps://github.com/SarahRastegar/InfoSieve.",
            "author": [
                "Sarah Rastegar",
                "Hazel Doughty",
                "Cees G. M. Snoek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19776v2",
                "http://arxiv.org/pdf/2310.19776v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "I.2.1.b; I.2.6.g; I.5.4.b; I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19767v1",
            "title": "Autoregressive Attention Neural Networks for Non-Line-of-Sight User\n  Tracking with Dynamic Metasurface Antennas",
            "updated": "2023-10-30T17:38:16Z",
            "published": "2023-10-30T17:38:16Z",
            "summary": "User localization and tracking in the upcoming generation of wireless\nnetworks have the potential to be revolutionized by technologies such as the\nDynamic Metasurface Antennas (DMAs). Commonly proposed algorithmic approaches\nrely on assumptions about relatively dominant Line-of-Sight (LoS) paths, or\nrequire pilot transmission sequences whose length is comparable to the number\nof DMA elements, thus, leading to limited effectiveness and considerable\nmeasurement overheads in blocked LoS and dynamic multipath environments. In\nthis paper, we present a two-stage machine-learning-based approach for user\ntracking, specifically designed for non-LoS multipath settings. A newly\nproposed attention-based Neural Network (NN) is first trained to map noisy\nchannel responses to potential user positions, regardless of user mobility\npatterns. This architecture constitutes a modification of the prominent vision\ntransformer, specifically modified for extracting information from\nhigh-dimensional frequency response signals. As a second stage, the NN's\npredictions for the past user positions are passed through a learnable\nautoregressive model to exploit the time-correlated channel information and\nobtain the final position predictions. The channel estimation procedure\nleverages a DMA receive architecture with partially-connected radio frequency\nchains, which results to reduced numbers of pilots. The numerical evaluation\nover an outdoor ray-tracing scenario illustrates that despite LoS blockage,\nthis methodology is capable of achieving high position accuracy across various\nmultipath settings.",
            "author": [
                "Kyriakos Stylianopoulos",
                "Murat Bayraktar",
                "Nuria Gonz\u00e1lez Prelcic",
                "George C. Alexandropoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19767v1",
                "http://arxiv.org/pdf/2310.19767v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19763v1",
            "title": "Autoregressive Renaissance in Neural PDE Solvers",
            "updated": "2023-10-30T17:35:26Z",
            "published": "2023-10-30T17:35:26Z",
            "summary": "Recent developments in the field of neural partial differential equation\n(PDE) solvers have placed a strong emphasis on neural operators. However, the\npaper \"Message Passing Neural PDE Solver\" by Brandstetter et al. published in\nICLR 2022 revisits autoregressive models and designs a message passing graph\nneural network that is comparable with or outperforms both the state-of-the-art\nFourier Neural Operator and traditional classical PDE solvers in its\ngeneralization capabilities and performance. This blog post delves into the key\ncontributions of this work, exploring the strategies used to address the common\nproblem of instability in autoregressive models and the design choices of the\nmessage passing graph neural network architecture.",
            "author": [
                "Yolanne Yi Ran Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19763v1",
                "http://arxiv.org/pdf/2310.19763v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19760v1",
            "title": "Epidemic outbreak prediction using machine learning models",
            "updated": "2023-10-30T17:28:44Z",
            "published": "2023-10-30T17:28:44Z",
            "summary": "In today's world,the risk of emerging and re-emerging epidemics have\nincreased.The recent advancement in healthcare technology has made it possible\nto predict an epidemic outbreak in a region.Early prediction of an epidemic\noutbreak greatly helps the authorities to be prepared with the necessary\nmedications and logistics required to keep things in control. In this article,\nwe try to predict the epidemic outbreak (influenza, hepatitis and malaria) for\nthe state of New York, USA using machine and deep learning algorithms, and a\nportal has been created for the same which can alert the authorities and health\ncare organizations of the region in case of an outbreak. The algorithm takes\nhistorical data to predict the possible number of cases for 5 weeks into the\nfuture. Non-clinical factors like google search trends,social media data and\nweather data have also been used to predict the probability of an outbreak.",
            "author": [
                "Akshara Pramod",
                "JS Abhishek",
                "Dr. Suganthi K"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19760v1",
                "http://arxiv.org/pdf/2310.19760v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19756v2",
            "title": "Transmission line condition prediction based on semi-supervised learning",
            "updated": "2023-12-07T00:38:51Z",
            "published": "2023-10-30T17:25:39Z",
            "summary": "Transmission line state assessment and prediction are of great significance\nfor the rational formulation of operation and maintenance strategy and\nimprovement of operation and maintenance level. Aiming at the problem that\nexisting models cannot take into account the robustness and data demand, this\npaper proposes a state prediction method based on semi-supervised learning.\nFirstly, for the expanded feature vector, the regular matrix is used to fill in\nthe missing data, and the sparse coding problem is solved by representation\nlearning. Then, with the help of a small number of labelled samples to\ninitially determine the category centers of line segments in different\ndefective states. Finally, the estimated parameters of the model are corrected\nusing unlabeled samples. Example analysis shows that this method can improve\nthe recognition accuracy and use data more efficiently than the existing\nmodels.",
            "author": [
                "Sizhe Li",
                "Xun Ma",
                "Nan Liu",
                "Yi Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19756v2",
                "http://arxiv.org/pdf/2310.19756v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19752v1",
            "title": "Intra-Modal Proxy Learning for Zero-Shot Visual Categorization with CLIP",
            "updated": "2023-10-30T17:22:02Z",
            "published": "2023-10-30T17:22:02Z",
            "summary": "Vision-language pre-training methods, e.g., CLIP, demonstrate an impressive\nzero-shot performance on visual categorizations with the class proxy from the\ntext embedding of the class name. However, the modality gap between the text\nand vision space can result in a sub-optimal performance. We theoretically show\nthat the gap cannot be reduced sufficiently by minimizing the contrastive loss\nin CLIP and the optimal proxy for vision tasks may reside only in the vision\nspace. Therefore, given unlabeled target vision data, we propose to learn the\nvision proxy directly with the help from the text proxy for zero-shot transfer.\nMoreover, according to our theoretical analysis, strategies are developed to\nfurther refine the pseudo label obtained by the text proxy to facilitate the\nintra-modal proxy learning (InMaP) for vision. Experiments on extensive\ndownstream tasks confirm the effectiveness and efficiency of our proposal.\nConcretely, InMaP can obtain the vision proxy within one minute on a single GPU\nwhile improving the zero-shot accuracy from $77.02\\%$ to $80.21\\%$ on ImageNet\nwith ViT-L/14@336 pre-trained by CLIP. Code is available at\n\\url{https://github.com/idstcv/InMaP}.",
            "author": [
                "Qi Qian",
                "Yuanhong Xu",
                "Juhua Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19752v1",
                "http://arxiv.org/pdf/2310.19752v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19748v2",
            "title": "Efficient learning of arbitrary single-copy quantum states",
            "updated": "2023-11-13T04:55:28Z",
            "published": "2023-10-30T17:15:19Z",
            "summary": "Quantum state tomography is the problem of estimating a given quantum state.\nUsually, it is required to run the quantum experiment - state preparation,\nstate evolution, measurement - several times to be able to estimate the output\nquantum state of the experiment, because an exponentially high number of copies\nof the state is required. In this work, we present an efficient algorithm to\nestimate with a small but non-zero probability of error the output state of the\nexperiment using a single copy of the state, without knowing the evolution\ndynamics of the state. It also does not destroy the original state, which can\nbe recovered easily for any further quantum processing. As an example, it is\nusually required to repeat a quantum image processing experiment many times,\nsince many copies of the state of the output image are needed to extract the\ninformation from all its pixels. The information from $\\mathcal{N}$ pixels of\nthe image can be inferred from a single run of the image processing experiment\nin our algorithm, to efficiently estimate the density matrix of the image\nstate.",
            "author": [
                "Shibdas Roy",
                "Filippo Caruso",
                "Srushti Patil"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19748v2",
                "http://arxiv.org/pdf/2310.19748v2"
            ],
            "primary_category": "physics.gen-ph",
            "category": [
                "physics.gen-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19743v1",
            "title": "Tell Me What Is Good About This Property: Leveraging Reviews For\n  Segment-Personalized Image Collection Summarization",
            "updated": "2023-10-30T17:06:49Z",
            "published": "2023-10-30T17:06:49Z",
            "summary": "Image collection summarization techniques aim to present a compact\nrepresentation of an image gallery through a carefully selected subset of\nimages that captures its semantic content. When it comes to web content,\nhowever, the ideal selection can vary based on the user's specific intentions\nand preferences. This is particularly relevant at Booking.com, where presenting\nproperties and their visual summaries that align with users' expectations is\ncrucial. To address this challenge, we consider user intentions in the\nsummarization of property visuals by analyzing property reviews and extracting\nthe most significant aspects mentioned by users. By incorporating the insights\nfrom reviews in our visual summaries, we enhance the summaries by presenting\nthe relevant content to a user. Moreover, we achieve it without the need for\ncostly annotations. Our experiments, including human perceptual studies,\ndemonstrate the superiority of our cross-modal approach, which we coin as\nCrossSummarizer over the no-personalization and image-based clustering\nbaselines.",
            "author": [
                "Monika Wysoczanska",
                "Moran Beladev",
                "Karen Lastmann Assaraf",
                "Fengjun Wang",
                "Ofri Kleinfeld",
                "Gil Amsalem",
                "Hadas Harush Boker"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19743v1",
                "http://arxiv.org/pdf/2310.19743v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19733v1",
            "title": "Differentially Private Reward Estimation with Preference Feedback",
            "updated": "2023-10-30T16:58:30Z",
            "published": "2023-10-30T16:58:30Z",
            "summary": "Learning from preference-based feedback has recently gained considerable\ntraction as a promising approach to align generative models with human\ninterests. Instead of relying on numerical rewards, the generative models are\ntrained using reinforcement learning with human feedback (RLHF). These\napproaches first solicit feedback from human labelers typically in the form of\npairwise comparisons between two possible actions, then estimate a reward model\nusing these comparisons, and finally employ a policy based on the estimated\nreward model. An adversarial attack in any step of the above pipeline might\nreveal private and sensitive information of human labelers. In this work, we\nadopt the notion of label differential privacy (DP) and focus on the problem of\nreward estimation from preference-based feedback while protecting privacy of\neach individual labelers. Specifically, we consider the parametric\nBradley-Terry-Luce (BTL) model for such pairwise comparison feedback involving\na latent reward parameter $\\theta^* \\in \\mathbb{R}^d$. Within a standard\nminimax estimation framework, we provide tight upper and lower bounds on the\nerror in estimating $\\theta^*$ under both local and central models of DP. We\nshow, for a given privacy budget $\\epsilon$ and number of samples $n$, that the\nadditional cost to ensure label-DP under local model is $\\Theta \\big(\\frac{1}{\ne^\\epsilon-1}\\sqrt{\\frac{d}{n}}\\big)$, while it is\n$\\Theta\\big(\\frac{\\text{poly}(d)}{\\epsilon n} \\big)$ under the weaker central\nmodel. We perform simulations on synthetic data that corroborate these\ntheoretical results.",
            "author": [
                "Sayak Ray Chowdhury",
                "Xingyu Zhou",
                "Nagarajan Natarajan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19733v1",
                "http://arxiv.org/pdf/2310.19733v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19731v1",
            "title": "ViR: Vision Retention Networks",
            "updated": "2023-10-30T16:55:50Z",
            "published": "2023-10-30T16:55:50Z",
            "summary": "Vision Transformers (ViTs) have attracted a lot of popularity in recent\nyears, due to their exceptional capabilities in modeling long-range spatial\ndependencies and scalability for large scale training. Although the training\nparallelism of self-attention mechanism plays an important role in retaining\ngreat performance, its quadratic complexity baffles the application of ViTs in\nmany scenarios which demand fast inference. This effect is even more pronounced\nin applications in which autoregressive modeling of input features is required.\nIn Natural Language Processing (NLP), a new stream of efforts have proposed\nparallelizable models with recurrent formulation that allows for efficient\ninference in generative applications. Inspired by this trend, we propose a new\nclass of computer vision models, dubbed Vision Retention Networks (ViR), with\ndual parallel and recurrent formulations, which strike an optimal balance\nbetween fast inference and parallel training with competitive performance. In\nparticular, ViR scales favorably for image throughput and memory consumption in\ntasks that require higher-resolution images due to its flexible formulation in\nprocessing large sequence lengths. The ViR is the first attempt to realize dual\nparallel and recurrent equivalency in a general vision backbone for recognition\ntasks. We have validated the effectiveness of ViR through extensive experiments\nwith different dataset sizes and various image resolutions and achieved\ncompetitive performance. Our code and pretrained models will be made publicly\navailable.",
            "author": [
                "Ali Hatamizadeh",
                "Michael Ranzinger",
                "Jan Kautz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19731v1",
                "http://arxiv.org/pdf/2310.19731v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19727v2",
            "title": "Generating Medical Prescriptions with Conditional Transformer",
            "updated": "2023-11-18T17:10:29Z",
            "published": "2023-10-30T16:53:11Z",
            "summary": "Access to real-world medication prescriptions is essential for medical\nresearch and healthcare quality improvement. However, access to real medication\nprescriptions is often limited due to the sensitive nature of the information\nexpressed. Additionally, manually labelling these instructions for training and\nfine-tuning Natural Language Processing (NLP) models can be tedious and\nexpensive. We introduce a novel task-specific model architecture,\nLabel-To-Text-Transformer (\\textbf{LT3}), tailored to generate synthetic\nmedication prescriptions based on provided labels, such as a vocabulary list of\nmedications and their attributes. LT3 is trained on a set of around 2K lines of\nmedication prescriptions extracted from the MIMIC-III database, allowing the\nmodel to produce valuable synthetic medication prescriptions. We evaluate LT3's\nperformance by contrasting it with a state-of-the-art Pre-trained Language\nModel (PLM), T5, analysing the quality and diversity of generated texts. We\ndeploy the generated synthetic data to train the SpacyNER model for the Named\nEntity Recognition (NER) task over the n2c2-2018 dataset. The experiments show\nthat the model trained on synthetic data can achieve a 96-98\\% F1 score at\nLabel Recognition on Drug, Frequency, Route, Strength, and Form. LT3 codes and\ndata will be shared at\n\\url{https://github.com/HECTA-UoM/Label-To-Text-Transformer}",
            "author": [
                "Samuel Belkadi",
                "Nicolo Micheletti",
                "Lifeng Han",
                "Warren Del-Pinto",
                "Goran Nenadic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19727v2",
                "http://arxiv.org/pdf/2310.19727v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19726v1",
            "title": "A Path to Simpler Models Starts With Noise",
            "updated": "2023-10-30T16:52:57Z",
            "published": "2023-10-30T16:52:57Z",
            "summary": "The Rashomon set is the set of models that perform approximately equally well\non a given dataset, and the Rashomon ratio is the fraction of all models in a\ngiven hypothesis space that are in the Rashomon set. Rashomon ratios are often\nlarge for tabular datasets in criminal justice, healthcare, lending, education,\nand in other areas, which has practical implications about whether simpler\nmodels can attain the same level of accuracy as more complex models. An open\nquestion is why Rashomon ratios often tend to be large. In this work, we\npropose and study a mechanism of the data generation process, coupled with\nchoices usually made by the analyst during the learning process, that\ndetermines the size of the Rashomon ratio. Specifically, we demonstrate that\nnoisier datasets lead to larger Rashomon ratios through the way that\npractitioners train models. Additionally, we introduce a measure called pattern\ndiversity, which captures the average difference in predictions between\ndistinct classification patterns in the Rashomon set, and motivate why it tends\nto increase with label noise. Our results explain a key aspect of why simpler\nmodels often tend to perform as well as black box models on complex, noisier\ndatasets.",
            "author": [
                "Lesia Semenova",
                "Harry Chen",
                "Ronald Parr",
                "Cynthia Rudin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19726v1",
                "http://arxiv.org/pdf/2310.19726v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19721v3",
            "title": "Promise:Prompt-driven 3D Medical Image Segmentation Using Pretrained\n  Image Foundation Models",
            "updated": "2023-11-13T21:28:24Z",
            "published": "2023-10-30T16:49:03Z",
            "summary": "To address prevalent issues in medical imaging, such as data acquisition\nchallenges and label availability, transfer learning from natural to medical\nimage domains serves as a viable strategy to produce reliable segmentation\nresults. However, several existing barriers between domains need to be broken\ndown, including addressing contrast discrepancies, managing anatomical\nvariability, and adapting 2D pretrained models for 3D segmentation tasks. In\nthis paper, we propose ProMISe,a prompt-driven 3D medical image segmentation\nmodel using only a single point prompt to leverage knowledge from a pretrained\n2D image foundation model. In particular, we use the pretrained vision\ntransformer from the Segment Anything Model (SAM) and integrate lightweight\nadapters to extract depth-related (3D) spatial context without updating the\npretrained weights. For robust results, a hybrid network with complementary\nencoders is designed, and a boundary-aware loss is proposed to achieve precise\nboundaries. We evaluate our model on two public datasets for colon and pancreas\ntumor segmentations, respectively. Compared to the state-of-the-art\nsegmentation methods with and without prompt engineering, our proposed method\nachieves superior performance. The code is publicly available at\nhttps://github.com/MedICL-VU/ProMISe.",
            "author": [
                "Hao Li",
                "Han Liu",
                "Dewei Hu",
                "Jiacheng Wang",
                "Ipek Oguz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19721v3",
                "http://arxiv.org/pdf/2310.19721v3"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19717v1",
            "title": "Support matrix machine: A review",
            "updated": "2023-10-30T16:46:23Z",
            "published": "2023-10-30T16:46:23Z",
            "summary": "Support vector machine (SVM) is one of the most studied paradigms in the\nrealm of machine learning for classification and regression problems. It relies\non vectorized input data. However, a significant portion of the real-world data\nexists in matrix format, which is given as input to SVM by reshaping the\nmatrices into vectors. The process of reshaping disrupts the spatial\ncorrelations inherent in the matrix data. Also, converting matrices into\nvectors results in input data with a high dimensionality, which introduces\nsignificant computational complexity. To overcome these issues in classifying\nmatrix input data, support matrix machine (SMM) is proposed. It represents one\nof the emerging methodologies tailored for handling matrix input data. The SMM\nmethod preserves the structural information of the matrix data by using the\nspectral elastic net property which is a combination of the nuclear norm and\nFrobenius norm. This article provides the first in-depth analysis of the\ndevelopment of the SMM model, which can be used as a thorough summary by both\nnovices and experts. We discuss numerous SMM variants, such as robust, sparse,\nclass imbalance, and multi-class classification models. We also analyze the\napplications of the SMM model and conclude the article by outlining potential\nfuture research avenues and possibilities that may motivate academics to\nadvance the SMM algorithm.",
            "author": [
                "Anuradha Kumari",
                "Mushir Akhtar",
                "Rupal Shah",
                "M. Tanveer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19717v1",
                "http://arxiv.org/pdf/2310.19717v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19854v1",
            "title": "Exact Recovery and Bregman Hard Clustering of Node-Attributed Stochastic\n  Block Model",
            "updated": "2023-10-30T16:46:05Z",
            "published": "2023-10-30T16:46:05Z",
            "summary": "Network clustering tackles the problem of identifying sets of nodes\n(communities) that have similar connection patterns. However, in many\nscenarios, nodes also have attributes that are correlated with the clustering\nstructure. Thus, network information (edges) and node information (attributes)\ncan be jointly leveraged to design high-performance clustering algorithms.\nUnder a general model for the network and node attributes, this work\nestablishes an information-theoretic criterion for the exact recovery of\ncommunity labels and characterizes a phase transition determined by the\nChernoff-Hellinger divergence of the model. The criterion shows how network and\nattribute information can be exchanged in order to have exact recovery (e.g.,\nmore reliable network information requires less reliable attribute\ninformation). This work also presents an iterative clustering algorithm that\nmaximizes the joint likelihood, assuming that the probability distribution of\nnetwork interactions and node attributes belong to exponential families. This\ncovers a broad range of possible interactions (e.g., edges with weights) and\nattributes (e.g., non-Gaussian models), as well as sparse networks, while also\nexploring the connection between exponential families and Bregman divergences.\nExtensive numerical experiments using synthetic data indicate that the proposed\nalgorithm outperforms classic algorithms that leverage only network or only\nattribute information as well as state-of-the-art algorithms that also leverage\nboth sources of information. The contributions of this work provide insights\ninto the fundamental limits and practical techniques for inferring community\nlabels on node-attributed networks.",
            "author": [
                "Maximilien Dreveton",
                "Felipe S. Fernandes",
                "Daniel R. Figueiredo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19854v1",
                "http://arxiv.org/pdf/2310.19854v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG",
                "stat.ML",
                "62H30, 62F12"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19708v3",
            "title": "Combining Language Models For Specialized Domains: A Colorful Approach",
            "updated": "2023-11-01T07:55:28Z",
            "published": "2023-10-30T16:35:55Z",
            "summary": "General purpose language models (LMs) encounter difficulties when processing\ndomain-specific jargon and terminology, which are frequently utilized in\nspecialized fields such as medicine or industrial settings. Moreover, they\noften find it challenging to interpret mixed speech that blends general\nlanguage with specialized jargon. This poses a challenge for automatic speech\nrecognition systems operating within these specific domains. In this work, we\nintroduce a novel approach that integrates domain-specific or secondary LM into\ngeneral-purpose LM. This strategy involves labeling, or \"coloring\", each word\nto indicate its association with either the general or the domain-specific LM.\nWe develop an optimized algorithm that enhances the beam search algorithm to\neffectively handle inferences involving colored words. Our evaluations indicate\nthat this approach is highly effective in integrating jargon into language\ntasks. Notably, our method substantially lowers the error rate for\ndomain-specific words without compromising performance in the general domain.",
            "author": [
                "Daniel Eitan",
                "Menachem Pirchi",
                "Neta Glazer",
                "Shai Meital",
                "Gil Ayach",
                "Gidon Krendel",
                "Aviv Shamsian",
                "Aviv Navon",
                "Gil Hetz",
                "Joseph Keshet"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19708v3",
                "http://arxiv.org/pdf/2310.19708v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19704v1",
            "title": "A Survey on Knowledge Editing of Neural Networks",
            "updated": "2023-10-30T16:29:47Z",
            "published": "2023-10-30T16:29:47Z",
            "summary": "Deep neural networks are becoming increasingly pervasive in academia and\nindustry, matching and surpassing human performance on a wide variety of fields\nand related tasks. However, just as humans, even the largest artificial neural\nnetworks make mistakes, and once-correct predictions can become invalid as the\nworld progresses in time. Augmenting datasets with samples that account for\nmistakes or up-to-date information has become a common workaround in practical\napplications. However, the well-known phenomenon of catastrophic forgetting\nposes a challenge in achieving precise changes in the implicitly memorized\nknowledge of neural network parameters, often requiring a full model\nre-training to achieve desired behaviors. That is expensive, unreliable, and\nincompatible with the current trend of large self-supervised pre-training,\nmaking it necessary to find more efficient and effective methods for adapting\nneural network models to changing data. To address this need, knowledge editing\nis emerging as a novel area of research that aims to enable reliable,\ndata-efficient, and fast changes to a pre-trained target model, without\naffecting model behaviors on previously learned tasks. In this survey, we\nprovide a brief review of this recent artificial intelligence field of\nresearch. We first introduce the problem of editing neural networks, formalize\nit in a common framework and differentiate it from more notorious branches of\nresearch such as continuous learning. Next, we provide a review of the most\nrelevant knowledge editing approaches and datasets proposed so far, grouping\nworks under four different families: regularization techniques, meta-learning,\ndirect model editing, and architectural strategies. Finally, we outline some\nintersections with other fields of research and potential directions for future\nworks.",
            "author": [
                "Vittorio Mazzia",
                "Alessandro Pedrani",
                "Andrea Caciolai",
                "Kay Rottmann",
                "Davide Bernardi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19704v1",
                "http://arxiv.org/pdf/2310.19704v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19698v1",
            "title": "When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and\n  Limitations",
            "updated": "2023-10-30T16:19:34Z",
            "published": "2023-10-30T16:19:34Z",
            "summary": "Context-based fine-tuning methods, including prompting, in-context learning,\nsoft prompting (also known as prompt tuning), and prefix-tuning, have gained\npopularity due to their ability to often match the performance of full\nfine-tuning with a fraction of the parameters. Despite their empirical\nsuccesses, there is little theoretical understanding of how these techniques\ninfluence the internal computation of the model and their expressiveness\nlimitations. We show that despite the continuous embedding space being more\nexpressive than the discrete token space, soft-prompting and prefix-tuning are\nstrictly less expressive than full fine-tuning, even with the same number of\nlearnable parameters. Concretely, context-based fine-tuning cannot change the\nrelative attention pattern over the content and can only bias the outputs of an\nattention layer in a fixed direction. This suggests that while techniques like\nprompting, in-context learning, soft prompting, and prefix-tuning can\neffectively elicit skills present in the pretrained model, they cannot learn\nnovel tasks that require new attention patterns.",
            "author": [
                "Aleksandar Petrov",
                "Philip H. S. Torr",
                "Adel Bibi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19698v1",
                "http://arxiv.org/pdf/2310.19698v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19695v2",
            "title": "Deep-learning-based decomposition of overlapping-sparse images:\n  application at the vertex of neutrino interactions",
            "updated": "2023-11-06T21:46:56Z",
            "published": "2023-10-30T16:12:25Z",
            "summary": "Image decomposition plays a crucial role in various computer vision tasks,\nenabling the analysis and manipulation of visual content at a fundamental\nlevel. Overlapping images, which occur when multiple objects or scenes\npartially occlude each other, pose unique challenges for decomposition\nalgorithms. The task intensifies when working with sparse images, where the\nscarcity of meaningful information complicates the precise extraction of\ncomponents. This paper presents a solution that leverages the power of deep\nlearning to accurately extract individual objects within multi-dimensional\noverlapping-sparse images, with a direct application in high-energy physics\nwith decomposition of overlaid elementary particles obtained from imaging\ndetectors. In particular, the proposed approach tackles a highly complex yet\nunsolved problem: identifying and measuring independent particles at the vertex\nof neutrino interactions, where one expects to observe detector images with\nmultiple indiscernible overlapping charged particles. By decomposing the image\nof the detector activity at the vertex through deep learning, it is possible to\ninfer the kinematic parameters of the identified low-momentum particles - which\notherwise would remain neglected - and enhance the reconstructed energy\nresolution of the neutrino event. We also present an additional step - that can\nbe tuned directly on detector data - combining the above method with a\nfully-differentiable generative model to improve the image decomposition\nfurther and, consequently, the resolution of the measured parameters, achieving\nunprecedented results. This improvement is crucial for precisely measuring the\nparameters that govern neutrino flavour oscillations and searching for\nasymmetries between matter and antimatter.",
            "author": [
                "Sa\u00fal Alonso-Monsalve",
                "Davide Sgalaberna",
                "Xingyu Zhao",
                "Adrien Molines",
                "Clark McGrew",
                "Andr\u00e9 Rubbia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19695v2",
                "http://arxiv.org/pdf/2310.19695v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19694v1",
            "title": "Convolutional State Space Models for Long-Range Spatiotemporal Modeling",
            "updated": "2023-10-30T16:11:06Z",
            "published": "2023-10-30T16:11:06Z",
            "summary": "Effectively modeling long spatiotemporal sequences is challenging due to the\nneed to model complex spatial correlations and long-range temporal dependencies\nsimultaneously. ConvLSTMs attempt to address this by updating tensor-valued\nstates with recurrent neural networks, but their sequential computation makes\nthem slow to train. In contrast, Transformers can process an entire\nspatiotemporal sequence, compressed into tokens, in parallel. However, the cost\nof attention scales quadratically in length, limiting their scalability to\nlonger sequences. Here, we address the challenges of prior methods and\nintroduce convolutional state space models (ConvSSM) that combine the tensor\nmodeling ideas of ConvLSTM with the long sequence modeling approaches of state\nspace methods such as S4 and S5. First, we demonstrate how parallel scans can\nbe applied to convolutional recurrences to achieve subquadratic parallelization\nand fast autoregressive generation. We then establish an equivalence between\nthe dynamics of ConvSSMs and SSMs, which motivates parameterization and\ninitialization strategies for modeling long-range dependencies. The result is\nConvS5, an efficient ConvSSM variant for long-range spatiotemporal modeling.\nConvS5 significantly outperforms Transformers and ConvLSTM on a long horizon\nMoving-MNIST experiment while training 3X faster than ConvLSTM and generating\nsamples 400X faster than Transformers. In addition, ConvS5 matches or exceeds\nthe performance of state-of-the-art methods on challenging DMLab, Minecraft and\nHabitat prediction benchmarks and enables new directions for modeling long\nspatiotemporal sequences.",
            "author": [
                "Jimmy T. H. Smith",
                "Shalini De Mello",
                "Jan Kautz",
                "Scott W. Linderman",
                "Wonmin Byeon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19694v1",
                "http://arxiv.org/pdf/2310.19694v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19693v1",
            "title": "The Effect of Structural Phase Changes on Fermi Level Shifts and\n  Optoelectronic Properties of Lead-Free CsSnI3 Perovskites",
            "updated": "2023-10-30T16:09:35Z",
            "published": "2023-10-30T16:09:35Z",
            "summary": "The work carried out first-principles calculations within the framework of\ndensity functional theory to study the structural stability of the CsSnI3\ncompound and the influence of phase transitions on their electronic and optical\nproperties. Using the GGA and SCAN functionals, the relaxed structures of the\nCsSnI3 phases were obtained and their geometric characteristics were assessed.\nUsing the Phonopy code based on VASP, calculations of phonon and thermodynamic\nproperties were performed, and the temperatures of phase transitions of CsSnI3\nwere determined. Electronic properties and Fermi level shifts as a result of\nphase transformations of CsSnI3 were assessed using the HSE06 functional and\nmachine learning prediction. The values of the complex dielectric constant and\nthe refractive index of all phases of the CsSnI3 were determined.",
            "author": [
                "Dilshod D. Nematov",
                "Amondulloi S. Burhonzoda",
                "Mekhrdod S. Kurboniyon",
                "Umar Zafari",
                "Kholmirzo T. Kholmurodov",
                "Tomoyuki Yamamoto",
                "Farhod Shokir"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19693v1",
                "http://arxiv.org/pdf/2310.19693v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "00A79",
                "J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19691v1",
            "title": "Causal Context Connects Counterfactual Fairness to Robust Prediction and\n  Group Fairness",
            "updated": "2023-10-30T16:07:57Z",
            "published": "2023-10-30T16:07:57Z",
            "summary": "Counterfactual fairness requires that a person would have been classified in\nthe same way by an AI or other algorithmic system if they had a different\nprotected class, such as a different race or gender. This is an intuitive\nstandard, as reflected in the U.S. legal system, but its use is limited because\ncounterfactuals cannot be directly observed in real-world data. On the other\nhand, group fairness metrics (e.g., demographic parity or equalized odds) are\nless intuitive but more readily observed. In this paper, we use $\\textit{causal\ncontext}$ to bridge the gaps between counterfactual fairness, robust\nprediction, and group fairness. First, we motivate counterfactual fairness by\nshowing that there is not necessarily a fundamental trade-off between fairness\nand accuracy because, under plausible conditions, the counterfactually fair\npredictor is in fact accuracy-optimal in an unbiased target distribution.\nSecond, we develop a correspondence between the causal graph of the\ndata-generating process and which, if any, group fairness metrics are\nequivalent to counterfactual fairness. Third, we show that in three common\nfairness contexts$\\unicode{x2013}$measurement error, selection on label, and\nselection on predictors$\\unicode{x2013}$counterfactual fairness is equivalent\nto demographic parity, equalized odds, and calibration, respectively.\nCounterfactual fairness can sometimes be tested by measuring relatively simple\ngroup fairness metrics.",
            "author": [
                "Jacy Reese Anthis",
                "Victor Veitch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19691v1",
                "http://arxiv.org/pdf/2310.19691v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19690v1",
            "title": "Towards Practical Non-Adversarial Distribution Alignment via Variational\n  Bounds",
            "updated": "2023-10-30T16:05:46Z",
            "published": "2023-10-30T16:05:46Z",
            "summary": "Distribution alignment can be used to learn invariant representations with\napplications in fairness and robustness. Most prior works resort to adversarial\nalignment methods but the resulting minimax problems are unstable and\nchallenging to optimize. Non-adversarial likelihood-based approaches either\nrequire model invertibility, impose constraints on the latent prior, or lack a\ngeneric framework for alignment. To overcome these limitations, we propose a\nnon-adversarial VAE-based alignment method that can be applied to any model\npipeline. We develop a set of alignment upper bounds (including a noisy bound)\nthat have VAE-like objectives but with a different perspective. We carefully\ncompare our method to prior VAE-based alignment approaches both theoretically\nand empirically. Finally, we demonstrate that our novel alignment losses can\nreplace adversarial losses in standard invariant representation learning\npipelines without modifying the original architectures -- thereby significantly\nbroadening the applicability of non-adversarial alignment methods.",
            "author": [
                "Ziyu Gong",
                "Ben Usman",
                "Han Zhao",
                "David I. Inouye"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19690v1",
                "http://arxiv.org/pdf/2310.19690v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19686v1",
            "title": "Can input reconstruction be used to directly estimate uncertainty of a\n  regression U-Net model? -- Application to proton therapy dose prediction for\n  head and neck cancer patients",
            "updated": "2023-10-30T16:04:34Z",
            "published": "2023-10-30T16:04:34Z",
            "summary": "Estimating the uncertainty of deep learning models in a reliable and\nefficient way has remained an open problem, where many different solutions have\nbeen proposed in the literature. Most common methods are based on Bayesian\napproximations, like Monte Carlo dropout (MCDO) or Deep ensembling (DE), but\nthey have a high inference time (i.e. require multiple inference passes) and\nmight not work for out-of-distribution detection (OOD) data (i.e. similar\nuncertainty for in-distribution (ID) and OOD). In safety critical environments,\nlike medical applications, accurate and fast uncertainty estimation methods,\nable to detect OOD data, are crucial, since wrong predictions can jeopardize\npatients safety. In this study, we present an alternative direct uncertainty\nestimation method and apply it for a regression U-Net architecture. The method\nconsists in the addition of a branch from the bottleneck which reconstructs the\ninput. The input reconstruction error can be used as a surrogate of the model\nuncertainty. For the proof-of-concept, our method is applied to proton therapy\ndose prediction in head and neck cancer patients. Accuracy, time-gain, and OOD\ndetection are analyzed for our method in this particular application and\ncompared with the popular MCDO and DE. The input reconstruction method showed a\nhigher Pearson correlation coefficient with the prediction error (0.620) than\nDE and MCDO (between 0.447 and 0.612). Moreover, our method allows an easier\nidentification of OOD (Z-score of 34.05). It estimates the uncertainty\nsimultaneously to the regression task, therefore requires less time or\ncomputational resources.",
            "author": [
                "Margerie Huet-Dastarac",
                "Dan Nguyen",
                "Steve Jiang",
                "John Lee",
                "Ana Barragan Montero"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19686v1",
                "http://arxiv.org/pdf/2310.19686v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19685v3",
            "title": "DGFN: Double Generative Flow Networks",
            "updated": "2023-11-06T19:23:27Z",
            "published": "2023-10-30T16:04:02Z",
            "summary": "Deep learning is emerging as an effective tool in drug discovery, with\npotential applications in both predictive and generative models. Generative\nFlow Networks (GFlowNets/GFNs) are a recently introduced method recognized for\nthe ability to generate diverse candidates, in particular in small molecule\ngeneration tasks. In this work, we introduce double GFlowNets (DGFNs). Drawing\ninspiration from reinforcement learning and Double Deep Q-Learning, we\nintroduce a target network used to sample trajectories, while updating the main\nnetwork with these sampled trajectories. Empirical results confirm that DGFNs\neffectively enhance exploration in sparse reward domains and high-dimensional\nstate spaces, both challenging aspects of de-novo design in drug discovery.",
            "author": [
                "Elaine Lau",
                "Nikhil Vemgal",
                "Doina Precup",
                "Emmanuel Bengio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19685v3",
                "http://arxiv.org/pdf/2310.19685v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19684v1",
            "title": "Density Estimation for Entry Guidance Problems using Deep Learning",
            "updated": "2023-10-30T16:03:37Z",
            "published": "2023-10-30T16:03:37Z",
            "summary": "This work presents a deep-learning approach to estimate atmospheric density\nprofiles for use in planetary entry guidance problems. A long short-term memory\n(LSTM) neural network is trained to learn the mapping between measurements\navailable onboard an entry vehicle and the density profile through which it is\nflying. Measurements include the spherical state representation, Cartesian\nsensed acceleration components, and a surface-pressure measurement. Training\ndata for the network is initially generated by performing a Monte Carlo\nanalysis of an entry mission at Mars using the fully numerical\npredictor-corrector guidance (FNPEG) algorithm that utilizes an exponential\ndensity model, while the truth density profiles are sampled from MarsGRAM. A\ncurriculum learning procedure is developed to refine the LSTM network's\npredictions for integration within the FNPEG algorithm. The trained LSTM is\ncapable of both predicting the density profile through which the vehicle will\nfly and reconstructing the density profile through which it has already flown.\nThe performance of the FNPEG algorithm is assessed for three different density\nestimation techniques: an exponential model, an exponential model augmented\nwith a first-order fading-memory filter, and the LSTM network. Results\ndemonstrate that using the LSTM model results in superior terminal accuracy\ncompared to the other two techniques when considering both noisy and noiseless\nmeasurements.",
            "author": [
                "Jens A. Rataczak",
                "Davide Amato",
                "Jay W. McMahon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19684v1",
                "http://arxiv.org/pdf/2310.19684v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19683v1",
            "title": "An Online Bootstrap for Time Series",
            "updated": "2023-10-30T16:03:11Z",
            "published": "2023-10-30T16:03:11Z",
            "summary": "Resampling methods such as the bootstrap have proven invaluable in the field\nof machine learning. However, the applicability of traditional bootstrap\nmethods is limited when dealing with large streams of dependent data, such as\ntime series or spatially correlated observations. In this paper, we propose a\nnovel bootstrap method that is designed to account for data dependencies and\ncan be executed online, making it particularly suitable for real-time\napplications. This method is based on an autoregressive sequence of\nincreasingly dependent resampling weights. We prove the theoretical validity of\nthe proposed bootstrap scheme under general conditions. We demonstrate the\neffectiveness of our approach through extensive simulations and show that it\nprovides reliable uncertainty quantification even in the presence of complex\ndata dependencies. Our work bridges the gap between classical resampling\ntechniques and the demands of modern data analysis, providing a valuable tool\nfor researchers and practitioners in dynamic, data-rich environments.",
            "author": [
                "Nicolai Palm",
                "Thomas Nagler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19683v1",
                "http://arxiv.org/pdf/2310.19683v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.CO",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19680v3",
            "title": "Integrating Pre-trained Language Model into Neural Machine Translation",
            "updated": "2023-11-22T16:12:39Z",
            "published": "2023-10-30T16:00:13Z",
            "summary": "Neural Machine Translation (NMT) has become a significant technology in\nnatural language processing through extensive research and development.\nHowever, the deficiency of high-quality bilingual language pair data still\nposes a major challenge to improving NMT performance. Recent studies have been\nexploring the use of contextual information from pre-trained language model\n(PLM) to address this problem. Yet, the issue of incompatibility between PLM\nand NMT model remains unresolved. This study proposes PLM-integrated NMT\n(PiNMT) model to overcome the identified problems. PiNMT model consists of\nthree critical components, PLM Multi Layer Converter, Embedding Fusion, and\nCosine Alignment, each playing a vital role in providing effective PLM\ninformation to NMT. Furthermore, two training strategies, Separate Learning\nRates and Dual Step Training, are also introduced in this paper. By\nimplementing the proposed PiNMT model and training strategy, we achieve\nstate-of-the-art performance on the IWSLT'14 En$\\leftrightarrow$De dataset.\nThis study's outcomes are noteworthy as they demonstrate a novel approach for\nefficiently integrating PLM with NMT to overcome incompatibility and enhance\nperformance.",
            "author": [
                "Soon-Jae Hwang",
                "Chang-Sung Jeong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19680v3",
                "http://arxiv.org/pdf/2310.19680v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19676v1",
            "title": "HyPE: Attention with Hyperbolic Biases for Relative Positional Encoding",
            "updated": "2023-10-30T15:54:32Z",
            "published": "2023-10-30T15:54:32Z",
            "summary": "In Transformer-based architectures, the attention mechanism is inherently\npermutation-invariant with respect to the input sequence's tokens. To impose\nsequential order, token positions are typically encoded using a scheme with\neither fixed or learnable parameters. We introduce Hyperbolic Positional\nEncoding (HyPE), a novel method that utilizes hyperbolic functions' properties\nto encode tokens' relative positions. This approach biases the attention\nmechanism without the necessity of storing the $O(L^2)$ values of the mask,\nwith $L$ being the length of the input sequence. HyPE leverages preliminary\nconcatenation operations and matrix multiplications, facilitating the encoding\nof relative distances indirectly incorporating biases into the softmax\ncomputation. This design ensures compatibility with FlashAttention-2 and\nsupports the gradient backpropagation for any potential learnable parameters\nwithin the encoding. We analytically demonstrate that, by careful\nhyperparameter selection, HyPE can approximate the attention bias of ALiBi,\nthereby offering promising generalization capabilities for contexts extending\nbeyond the lengths encountered during pretraining. The experimental evaluation\nof HyPE is proposed as a direction for future research.",
            "author": [
                "Giorgio Angelotti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19676v1",
                "http://arxiv.org/pdf/2310.19676v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19675v1",
            "title": "A Principled Hierarchical Deep Learning Approach to Joint Image\n  Compression and Classification",
            "updated": "2023-10-30T15:52:18Z",
            "published": "2023-10-30T15:52:18Z",
            "summary": "Among applications of deep learning (DL) involving low cost sensors, remote\nimage classification involves a physical channel that separates edge sensors\nand cloud classifiers. Traditional DL models must be divided between an encoder\nfor the sensor and the decoder + classifier at the edge server. An important\nchallenge is to effectively train such distributed models when the connecting\nchannels have limited rate/capacity. Our goal is to optimize DL models such\nthat the encoder latent requires low channel bandwidth while still delivers\nfeature information for high classification accuracy. This work proposes a\nthree-step joint learning strategy to guide encoders to extract features that\nare compact, discriminative, and amenable to common\naugmentations/transformations. We optimize latent dimension through an initial\nscreening phase before end-to-end (E2E) training. To obtain an adjustable bit\nrate via a single pre-deployed encoder, we apply entropy-based quantization\nand/or manual truncation on the latent representations. Tests show that our\nproposed method achieves accuracy improvement of up to 1.5% on CIFAR-10 and 3%\non CIFAR-100 over conventional E2E cross-entropy training.",
            "author": [
                "Siyu Qi",
                "Achintha Wijesinghe",
                "Lahiru D. Chamain",
                "Zhi Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19675v1",
                "http://arxiv.org/pdf/2310.19675v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19852v2",
            "title": "AI Alignment: A Comprehensive Survey",
            "updated": "2023-11-01T14:18:52Z",
            "published": "2023-10-30T15:52:15Z",
            "summary": "AI alignment aims to make AI systems behave in line with human intentions and\nvalues. As AI systems grow more capable, the potential large-scale risks\nassociated with misaligned AI systems become salient. Hundreds of AI experts\nand public figures have expressed concerns about AI risks, arguing that\n\"mitigating the risk of extinction from AI should be a global priority,\nalongside other societal-scale risks such as pandemics and nuclear war\". To\nprovide a comprehensive and up-to-date overview of the alignment field, in this\nsurvey paper, we delve into the core concepts, methodology, and practice of\nalignment. We identify the RICE principles as the key objectives of AI\nalignment: Robustness, Interpretability, Controllability, and Ethicality.\nGuided by these four principles, we outline the landscape of current alignment\nresearch and decompose them into two key components: forward alignment and\nbackward alignment. The former aims to make AI systems aligned via alignment\ntraining, while the latter aims to gain evidence about the systems' alignment\nand govern them appropriately to avoid exacerbating misalignment risks. Forward\nalignment and backward alignment form a recurrent process where the alignment\nof AI systems from the forward process is verified in the backward process,\nmeanwhile providing updated objectives for forward alignment in the next round.\nOn forward alignment, we discuss learning from feedback and learning under\ndistribution shift. On backward alignment, we discuss assurance techniques and\ngovernance practices that apply to every stage of AI systems' lifecycle.\n  We also release and continually update the website (www.alignmentsurvey.com)\nwhich features tutorials, collections of papers, blog posts, and other\nresources.",
            "author": [
                "Jiaming Ji",
                "Tianyi Qiu",
                "Boyuan Chen",
                "Borong Zhang",
                "Hantao Lou",
                "Kaile Wang",
                "Yawen Duan",
                "Zhonghao He",
                "Jiayi Zhou",
                "Zhaowei Zhang",
                "Fanzhi Zeng",
                "Kwan Yee Ng",
                "Juntao Dai",
                "Xuehai Pan",
                "Aidan O'Gara",
                "Yingshan Lei",
                "Hua Xu",
                "Brian Tse",
                "Jie Fu",
                "Stephen McAleer",
                "Yaodong Yang",
                "Yizhou Wang",
                "Song-Chun Zhu",
                "Yike Guo",
                "Wen Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19852v2",
                "http://arxiv.org/pdf/2310.19852v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19671v2",
            "title": "Large Language Models: The Need for Nuance in Current Debates and a\n  Pragmatic Perspective on Understanding",
            "updated": "2023-10-31T08:17:29Z",
            "published": "2023-10-30T15:51:04Z",
            "summary": "Current Large Language Models (LLMs) are unparalleled in their ability to\ngenerate grammatically correct, fluent text. LLMs are appearing rapidly, and\ndebates on LLM capacities have taken off, but reflection is lagging behind.\nThus, in this position paper, we first zoom in on the debate and critically\nassess three points recurring in critiques of LLM capacities: i) that LLMs only\nparrot statistical patterns in the training data; ii) that LLMs master formal\nbut not functional language competence; and iii) that language learning in LLMs\ncannot inform human language learning. Drawing on empirical and theoretical\narguments, we show that these points need more nuance. Second, we outline a\npragmatic perspective on the issue of `real' understanding and intentionality\nin LLMs. Understanding and intentionality pertain to unobservable mental states\nwe attribute to other humans because they have pragmatic value: they allow us\nto abstract away from complex underlying mechanics and predict behaviour\neffectively. We reflect on the circumstances under which it would make sense\nfor humans to similarly attribute mental states to LLMs, thereby outlining a\npragmatic philosophical context for LLMs as an increasingly prominent\ntechnology in society.",
            "author": [
                "Bram M. A. van Dijk",
                "Tom Kouwenhoven",
                "Marco R. Spruit",
                "Max J. van Duijn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19671v2",
                "http://arxiv.org/pdf/2310.19671v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19670v1",
            "title": "Spatiotemporal Attention Enhances Lidar-Based Robot Navigation in\n  Dynamic Environments",
            "updated": "2023-10-30T15:50:59Z",
            "published": "2023-10-30T15:50:59Z",
            "summary": "Foresighted robot navigation in dynamic indoor environments with\ncost-efficient hardware necessitates the use of a lightweight yet dependable\ncontroller. So inferring the scene dynamics from sensor readings without\nexplicit object tracking is a pivotal aspect of foresighted navigation among\npedestrians. In this paper, we introduce a spatiotemporal attention pipeline\nfor enhanced navigation based on 2D lidar sensor readings. This pipeline is\ncomplemented by a novel lidar-state representation that emphasizes dynamic\nobstacles over static ones. Subsequently, the attention mechanism enables\nselective scene perception across both space and time, resulting in improved\noverall navigation performance within dynamic scenarios. We thoroughly\nevaluated the approach in different scenarios and simulators, finding good\ngeneralization to unseen environments. The results demonstrate outstanding\nperformance compared to state-of-the-art methods, thereby enabling the seamless\ndeployment of the learned controller on a real robot.",
            "author": [
                "Jorge de Heuvel",
                "Xiangyu Zeng",
                "Weixian Shi",
                "Tharun Sethuraman",
                "Maren Bennewitz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19670v1",
                "http://arxiv.org/pdf/2310.19670v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19668v1",
            "title": "DrM: Mastering Visual Reinforcement Learning through Dormant Ratio\n  Minimization",
            "updated": "2023-10-30T15:50:56Z",
            "published": "2023-10-30T15:50:56Z",
            "summary": "Visual reinforcement learning (RL) has shown promise in continuous control\ntasks. Despite its progress, current algorithms are still unsatisfactory in\nvirtually every aspect of the performance such as sample efficiency, asymptotic\nperformance, and their robustness to the choice of random seeds. In this paper,\nwe identify a major shortcoming in existing visual RL methods that is the\nagents often exhibit sustained inactivity during early training, thereby\nlimiting their ability to explore effectively. Expanding upon this crucial\nobservation, we additionally unveil a significant correlation between the\nagents' inclination towards motorically inactive exploration and the absence of\nneuronal activity within their policy networks. To quantify this inactivity, we\nadopt dormant ratio as a metric to measure inactivity in the RL agent's\nnetwork. Empirically, we also recognize that the dormant ratio can act as a\nstandalone indicator of an agent's activity level, regardless of the received\nreward signals. Leveraging the aforementioned insights, we introduce DrM, a\nmethod that uses three core mechanisms to guide agents'\nexploration-exploitation trade-offs by actively minimizing the dormant ratio.\nExperiments demonstrate that DrM achieves significant improvements in sample\nefficiency and asymptotic performance with no broken seeds (76 seeds in total)\nacross three continuous control benchmark environments, including DeepMind\nControl Suite, MetaWorld, and Adroit. Most importantly, DrM is the first\nmodel-free algorithm that consistently solves tasks in both the Dog and\nManipulator domains from the DeepMind Control Suite as well as three dexterous\nhand manipulation tasks without demonstrations in Adroit, all based on pixel\nobservations.",
            "author": [
                "Guowei Xu",
                "Ruijie Zheng",
                "Yongyuan Liang",
                "Xiyao Wang",
                "Zhecheng Yuan",
                "Tianying Ji",
                "Yu Luo",
                "Xiaoyu Liu",
                "Jiaxin Yuan",
                "Pu Hua",
                "Shuzhen Li",
                "Yanjie Ze",
                "Hal Daum\u00e9 III",
                "Furong Huang",
                "Huazhe Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19668v1",
                "http://arxiv.org/pdf/2310.19668v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19666v1",
            "title": "Dynamic Tensor Decomposition via Neural Diffusion-Reaction Processes",
            "updated": "2023-10-30T15:49:45Z",
            "published": "2023-10-30T15:49:45Z",
            "summary": "Tensor decomposition is an important tool for multiway data analysis. In\npractice, the data is often sparse yet associated with rich temporal\ninformation. Existing methods, however, often under-use the time information\nand ignore the structural knowledge within the sparsely observed tensor\nentries. To overcome these limitations and to better capture the underlying\ntemporal structure, we propose Dynamic EMbedIngs fOr dynamic Tensor\ndEcomposition (DEMOTE). We develop a neural diffusion-reaction process to\nestimate dynamic embeddings for the entities in each tensor mode. Specifically,\nbased on the observed tensor entries, we build a multi-partite graph to encode\nthe correlation between the entities. We construct a graph diffusion process to\nco-evolve the embedding trajectories of the correlated entities and use a\nneural network to construct a reaction process for each individual entity. In\nthis way, our model can capture both the commonalities and personalities during\nthe evolution of the embeddings for different entities. We then use a neural\nnetwork to model the entry value as a nonlinear function of the embedding\ntrajectories. For model estimation, we combine ODE solvers to develop a\nstochastic mini-batch learning algorithm. We propose a stratified sampling\nmethod to balance the cost of processing each mini-batch so as to improve the\noverall efficiency. We show the advantage of our approach in both simulation\nstudy and real-world applications. The code is available at\nhttps://github.com/wzhut/Dynamic-Tensor-Decomposition-via-Neural-Diffusion-Reaction-Processes.",
            "author": [
                "Zheng Wang",
                "Shikai Fang",
                "Shibo Li",
                "Shandian Zhe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19666v1",
                "http://arxiv.org/pdf/2310.19666v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19658v1",
            "title": "Explaining Tree Model Decisions in Natural Language for Network\n  Intrusion Detection",
            "updated": "2023-10-30T15:40:34Z",
            "published": "2023-10-30T15:40:34Z",
            "summary": "Network intrusion detection (NID) systems which leverage machine learning\nhave been shown to have strong performance in practice when used to detect\nmalicious network traffic. Decision trees in particular offer a strong balance\nbetween performance and simplicity, but require users of NID systems to have\nbackground knowledge in machine learning to interpret. In addition, they are\nunable to provide additional outside information as to why certain features may\nbe important for classification.\n  In this work, we explore the use of large language models (LLMs) to provide\nexplanations and additional background knowledge for decision tree NID systems.\nFurther, we introduce a new human evaluation framework for decision tree\nexplanations, which leverages automatically generated quiz questions that\nmeasure human evaluators' understanding of decision tree inference. Finally, we\nshow LLM generated decision tree explanations correlate highly with human\nratings of readability, quality, and use of background knowledge while\nsimultaneously providing better understanding of decision boundaries.",
            "author": [
                "Noah Ziems",
                "Gang Liu",
                "John Flanagan",
                "Meng Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19658v1",
                "http://arxiv.org/pdf/2310.19658v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19656v1",
            "title": "Domain Generalization in Computational Pathology: Survey and Guidelines",
            "updated": "2023-10-30T15:39:19Z",
            "published": "2023-10-30T15:39:19Z",
            "summary": "Deep learning models have exhibited exceptional effectiveness in\nComputational Pathology (CPath) by tackling intricate tasks across an array of\nhistology image analysis applications. Nevertheless, the presence of\nout-of-distribution data (stemming from a multitude of sources such as\ndisparate imaging devices and diverse tissue preparation methods) can cause\n\\emph{domain shift} (DS). DS decreases the generalization of trained models to\nunseen datasets with slightly different data distributions, prompting the need\nfor innovative \\emph{domain generalization} (DG) solutions. Recognizing the\npotential of DG methods to significantly influence diagnostic and prognostic\nmodels in cancer studies and clinical practice, we present this survey along\nwith guidelines on achieving DG in CPath. We rigorously define various DS\ntypes, systematically review and categorize existing DG approaches and\nresources in CPath, and provide insights into their advantages, limitations,\nand applicability. We also conduct thorough benchmarking experiments with 28\ncutting-edge DG algorithms to address a complex DG problem. Our findings\nsuggest that careful experiment design and CPath-specific Stain Augmentation\ntechnique can be very effective. However, there is no one-size-fits-all\nsolution for DG in CPath. Therefore, we establish clear guidelines for\ndetecting and managing DS depending on different scenarios. While most of the\nconcepts, guidelines, and recommendations are given for applications in CPath,\nwe believe that they are applicable to most medical image analysis tasks as\nwell.",
            "author": [
                "Mostafa Jahanifar",
                "Manahil Raza",
                "Kesi Xu",
                "Trinh Vuong",
                "Rob Jewsbury",
                "Adam Shephard",
                "Neda Zamanitajeddin",
                "Jin Tae Kwak",
                "Shan E Ahmed Raza",
                "Fayyaz Minhas",
                "Nasir Rajpoot"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19656v1",
                "http://arxiv.org/pdf/2310.19656v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19653v2",
            "title": "Upgrading VAE Training With Unlimited Data Plans Provided by Diffusion\n  Models",
            "updated": "2023-11-24T13:02:55Z",
            "published": "2023-10-30T15:38:39Z",
            "summary": "Variational autoencoders (VAEs) are popular models for representation\nlearning but their encoders are susceptible to overfitting (Cremer et al.,\n2018) because they are trained on a finite training set instead of the true\n(continuous) data distribution $p_{\\mathrm{data}}(\\mathbf{x})$. Diffusion\nmodels, on the other hand, avoid this issue by keeping the encoder fixed. This\nmakes their representations less interpretable, but it simplifies training,\nenabling accurate and continuous approximations of\n$p_{\\mathrm{data}}(\\mathbf{x})$. In this paper, we show that overfitting\nencoders in VAEs can be effectively mitigated by training on samples from a\npre-trained diffusion model. These results are somewhat unexpected as recent\nfindings (Alemohammad et al., 2023; Shumailov et al., 2023) observe a decay in\ngenerative performance when models are trained on data generated by another\ngenerative model. We analyze generalization performance, amortization gap, and\nrobustness of VAEs trained with our proposed method on three different data\nsets. We find improvements in all metrics compared to both normal training and\nconventional data augmentation methods, and we show that a modest amount of\nsamples from the diffusion model suffices to obtain these gains.",
            "author": [
                "Tim Z. Xiao",
                "Johannes Zenn",
                "Robert Bamler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19653v2",
                "http://arxiv.org/pdf/2310.19653v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.02168v2",
            "title": "The SVHN Dataset Is Deceptive for Probabilistic Generative Models Due to\n  a Distribution Mismatch",
            "updated": "2023-12-06T05:16:37Z",
            "published": "2023-10-30T15:38:31Z",
            "summary": "The Street View House Numbers (SVHN) dataset is a popular benchmark dataset\nin deep learning. Originally designed for digit classification tasks, the SVHN\ndataset has been widely used as a benchmark for various other tasks including\ngenerative modeling. However, with this work, we aim to warn the community\nabout an issue of the SVHN dataset as a benchmark for generative modeling\ntasks: we discover that the official split into training set and test set of\nthe SVHN dataset are not drawn from the same distribution. We empirically show\nthat this distribution mismatch has little impact on the classification task\n(which may explain why this issue has not been detected before), but it\nseverely affects the evaluation of probabilistic generative models, such as\nVariational Autoencoders and diffusion models. As a workaround, we propose to\nmix and re-split the official training and test set when SVHN is used for tasks\nother than classification. We publish a new split and the indices we used to\ncreate it at https://jzenn.github.io/svhn-remix/ .",
            "author": [
                "Tim Z. Xiao",
                "Johannes Zenn",
                "Robert Bamler"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02168v2",
                "http://arxiv.org/pdf/2312.02168v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19650v1",
            "title": "KeyGen2Vec: Learning Document Embedding via Multi-label Keyword\n  Generation in Question-Answering",
            "updated": "2023-10-30T15:35:45Z",
            "published": "2023-10-30T15:35:45Z",
            "summary": "Representing documents into high dimensional embedding space while preserving\nthe structural similarity between document sources has been an ultimate goal\nfor many works on text representation learning. Current embedding models,\nhowever, mainly rely on the availability of label supervision to increase the\nexpressiveness of the resulting embeddings. In contrast, unsupervised\nembeddings are cheap, but they often cannot capture implicit structure in\ntarget corpus, particularly for samples that come from different distribution\nwith the pretraining source.\n  Our study aims to loosen up the dependency on label supervision by learning\ndocument embeddings via Sequence-to-Sequence (Seq2Seq) text generator.\nSpecifically, we reformulate keyphrase generation task into multi-label keyword\ngeneration in community-based Question Answering (cQA). Our empirical results\nshow that KeyGen2Vec in general is superior than multi-label keyword classifier\nby up to 14.7% based on Purity, Normalized Mutual Information (NMI), and\nF1-Score metrics. Interestingly, although in general the absolute advantage of\nlearning embeddings through label supervision is highly positive across\nevaluation datasets, KeyGen2Vec is shown to be competitive with classifier that\nexploits topic label supervision in Yahoo! cQA with larger number of latent\ntopic labels.",
            "author": [
                "Iftitahu Ni'mah",
                "Samaneh Khoshrou",
                "Vlado Menkovski",
                "Mykola Pechenizkiy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19650v1",
                "http://arxiv.org/pdf/2310.19650v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19647v2",
            "title": "Fast swap regret minimization and applications to approximate correlated\n  equilibria",
            "updated": "2023-11-14T17:39:27Z",
            "published": "2023-10-30T15:35:24Z",
            "summary": "We give a simple and computationally efficient algorithm that, for any\nconstant $\\varepsilon>0$, obtains $\\varepsilon T$-swap regret within only $T =\n\\mathsf{polylog}(n)$ rounds; this is an exponential improvement compared to the\nsuper-linear number of rounds required by the state-of-the-art algorithm, and\nresolves the main open problem of [Blum and Mansour 2007]. Our algorithm has an\nexponential dependence on $\\varepsilon$, but we prove a new, matching lower\nbound.\n  Our algorithm for swap regret implies faster convergence to\n$\\varepsilon$-Correlated Equilibrium ($\\varepsilon$-CE) in several regimes: For\nnormal form two-player games with $n$ actions, it implies the first uncoupled\ndynamics that converges to the set of $\\varepsilon$-CE in polylogarithmic\nrounds; a $\\mathsf{polylog}(n)$-bit communication protocol for $\\varepsilon$-CE\nin two-player games (resolving an open problem mentioned by\n[Babichenko-Rubinstein'2017, Goos-Rubinstein'2018, Ganor-CS'2018]); and an\n$\\tilde{O}(n)$-query algorithm for $\\varepsilon$-CE (resolving an open problem\nof [Babichenko'2020] and obtaining the first separation between\n$\\varepsilon$-CE and $\\varepsilon$-Nash equilibrium in the query complexity\nmodel).\n  For extensive-form games, our algorithm implies a PTAS for $\\mathit{normal}$\n$\\mathit{form}$ $\\mathit{correlated}$ $\\mathit{equilibria}$, a solution concept\noften conjectured to be computationally intractable (e.g. [Stengel-Forges'08,\nFujii'23]).",
            "author": [
                "Binghui Peng",
                "Aviad Rubinstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19647v2",
                "http://arxiv.org/pdf/2310.19647v2"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.AI",
                "cs.DS",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19636v1",
            "title": "Leave No Stone Unturned: Mine Extra Knowledge for Imbalanced Facial\n  Expression Recognition",
            "updated": "2023-10-30T15:26:26Z",
            "published": "2023-10-30T15:26:26Z",
            "summary": "Facial expression data is characterized by a significant imbalance, with most\ncollected data showing happy or neutral expressions and fewer instances of fear\nor disgust. This imbalance poses challenges to facial expression recognition\n(FER) models, hindering their ability to fully understand various human\nemotional states. Existing FER methods typically report overall accuracy on\nhighly imbalanced test sets but exhibit low performance in terms of the mean\naccuracy across all expression classes. In this paper, our aim is to address\nthe imbalanced FER problem. Existing methods primarily focus on learning\nknowledge of minor classes solely from minor-class samples. However, we propose\na novel approach to extract extra knowledge related to the minor classes from\nboth major and minor class samples. Our motivation stems from the belief that\nFER resembles a distribution learning task, wherein a sample may contain\ninformation about multiple classes. For instance, a sample from the major class\nsurprise might also contain useful features of the minor class fear. Inspired\nby that, we propose a novel method that leverages re-balanced attention maps to\nregularize the model, enabling it to extract transformation invariant\ninformation about the minor classes from all training samples. Additionally, we\nintroduce re-balanced smooth labels to regulate the cross-entropy loss, guiding\nthe model to pay more attention to the minor classes by utilizing the extra\ninformation regarding the label distribution of the imbalanced training data.\nExtensive experiments on different datasets and backbones show that the two\nproposed modules work together to regularize the model and achieve\nstate-of-the-art performance under the imbalanced FER task. Code is available\nat https://github.com/zyh-uaiaaaa.",
            "author": [
                "Yuhang Zhang",
                "Yaqi Li",
                "Lixiong Qin",
                "Xuannan Liu",
                "Weihong Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19636v1",
                "http://arxiv.org/pdf/2310.19636v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19635v1",
            "title": "Bidirectional Captioning for Clinically Accurate and Interpretable\n  Models",
            "updated": "2023-10-30T15:25:29Z",
            "published": "2023-10-30T15:25:29Z",
            "summary": "Vision-language pretraining has been shown to produce high-quality visual\nencoders which transfer efficiently to downstream computer vision tasks. While\ngenerative language models have gained widespread attention, image captioning\nhas thus far been mostly overlooked as a form of cross-modal pretraining in\nfavor of contrastive learning, especially in medical image analysis. In this\npaper, we experiment with bidirectional captioning of radiology reports as a\nform of pretraining and compare the quality and utility of learned embeddings\nwith those from contrastive pretraining methods. We optimize a CNN encoder,\ntransformer decoder architecture named RadTex for the radiology domain. Results\nshow that not only does captioning pretraining yield visual encoders that are\ncompetitive with contrastive pretraining (CheXpert competition multi-label AUC\nof 89.4%), but also that our transformer decoder is capable of generating\nclinically relevant reports (captioning macro-F1 score of 0.349 using CheXpert\nlabeler) and responding to prompts with targeted, interactive outputs.",
            "author": [
                "Keegan Quigley",
                "Miriam Cha",
                "Josh Barua",
                "Geeticka Chauhan",
                "Seth Berkowitz",
                "Steven Horng",
                "Polina Golland"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19635v1",
                "http://arxiv.org/pdf/2310.19635v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19849v1",
            "title": "Predicting mutational effects on protein-protein binding via a\n  side-chain diffusion probabilistic model",
            "updated": "2023-10-30T15:23:42Z",
            "published": "2023-10-30T15:23:42Z",
            "summary": "Many crucial biological processes rely on networks of protein-protein\ninteractions. Predicting the effect of amino acid mutations on protein-protein\nbinding is vital in protein engineering and therapeutic discovery. However, the\nscarcity of annotated experimental data on binding energy poses a significant\nchallenge for developing computational approaches, particularly deep\nlearning-based methods. In this work, we propose SidechainDiff, a\nrepresentation learning-based approach that leverages unlabelled experimental\nprotein structures. SidechainDiff utilizes a Riemannian diffusion model to\nlearn the generative process of side-chain conformations and can also give the\nstructural context representations of mutations on the protein-protein\ninterface. Leveraging the learned representations, we achieve state-of-the-art\nperformance in predicting the mutational effects on protein-protein binding.\nFurthermore, SidechainDiff is the first diffusion-based generative model for\nside-chains, distinguishing it from prior efforts that have predominantly\nfocused on generating protein backbone structures.",
            "author": [
                "Shiwei Liu",
                "Tian Zhu",
                "Milong Ren",
                "Chungong Yu",
                "Dongbo Bu",
                "Haicang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19849v1",
                "http://arxiv.org/pdf/2310.19849v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19629v1",
            "title": "RayDF: Neural Ray-surface Distance Fields with Multi-view Consistency",
            "updated": "2023-10-30T15:22:50Z",
            "published": "2023-10-30T15:22:50Z",
            "summary": "In this paper, we study the problem of continuous 3D shape representations.\nThe majority of existing successful methods are coordinate-based implicit\nneural representations. However, they are inefficient to render novel views or\nrecover explicit surface points. A few works start to formulate 3D shapes as\nray-based neural functions, but the learned structures are inferior due to the\nlack of multi-view geometry consistency. To tackle these challenges, we propose\na new framework called RayDF. It consists of three major components: 1) the\nsimple ray-surface distance field, 2) the novel dual-ray visibility classifier,\nand 3) a multi-view consistency optimization module to drive the learned\nray-surface distances to be multi-view geometry consistent. We extensively\nevaluate our method on three public datasets, demonstrating remarkable\nperformance in 3D surface point reconstruction on both synthetic and\nchallenging real-world 3D scenes, clearly surpassing existing coordinate-based\nand ray-based baselines. Most notably, our method achieves a 1000x faster speed\nthan coordinate-based methods to render an 800x800 depth image, showing the\nsuperiority of our method for 3D shape representation. Our code and data are\navailable at https://github.com/vLAR-group/RayDF",
            "author": [
                "Zhuoman Liu",
                "Bo Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19629v1",
                "http://arxiv.org/pdf/2310.19629v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19624v1",
            "title": "Exploring Post-Training Quantization of Protein Language Models",
            "updated": "2023-10-30T15:18:06Z",
            "published": "2023-10-30T15:18:06Z",
            "summary": "Recent advancements in unsupervised protein language models (ProteinLMs),\nlike ESM-1b and ESM-2, have shown promise in different protein prediction\ntasks. However, these models face challenges due to their high computational\ndemands, significant memory needs, and latency, restricting their usage on\ndevices with limited resources. To tackle this, we explore post-training\nquantization (PTQ) for ProteinLMs, focusing on ESMFold, a simplified version of\nAlphaFold based on ESM-2 ProteinLM. Our study is the first attempt to quantize\nall weights and activations of ProteinLMs. We observed that the typical uniform\nquantization method performs poorly on ESMFold, causing a significant drop in\nTM-Score when using 8-bit quantization. We conducted extensive quantization\nexperiments, uncovering unique challenges associated with ESMFold, particularly\nhighly asymmetric activation ranges before Layer Normalization, making\nrepresentation difficult using low-bit fixed-point formats. To address these\nchallenges, we propose a new PTQ method for ProteinLMs, utilizing piecewise\nlinear quantization for asymmetric activation values to ensure accurate\napproximation. We demonstrated the effectiveness of our method in protein\nstructure prediction tasks, demonstrating that ESMFold can be accurately\nquantized to low-bit widths without compromising accuracy. Additionally, we\napplied our method to the contact prediction task, showcasing its versatility.\nIn summary, our study introduces an innovative PTQ method for ProteinLMs,\naddressing specific quantization challenges and potentially leading to the\ndevelopment of more efficient ProteinLMs with significant implications for\nvarious protein-related applications.",
            "author": [
                "Shuang Peng",
                "Fei Yang",
                "Ning Sun",
                "Sheng Chen",
                "Yanfeng Jiang",
                "Aimin Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19624v1",
                "http://arxiv.org/pdf/2310.19624v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19621v1",
            "title": "A Bayesian Methodology for Estimation for Sparse Canonical Correlation",
            "updated": "2023-10-30T15:14:25Z",
            "published": "2023-10-30T15:14:25Z",
            "summary": "It can be challenging to perform an integrative statistical analysis of\nmulti-view high-dimensional data acquired from different experiments on each\nsubject who participated in a joint study. Canonical Correlation Analysis (CCA)\nis a statistical procedure for identifying relationships between such data\nsets. In that context, Structured Sparse CCA (ScSCCA) is a rapidly emerging\nmethodological area that aims for robust modeling of the interrelations between\nthe different data modalities by assuming the corresponding CCA directional\nvectors to be sparse. Although it is a rapidly growing area of statistical\nmethodology development, there is a need for developing related methodologies\nin the Bayesian paradigm. In this manuscript, we propose a novel ScSCCA\napproach where we employ a Bayesian infinite factor model and aim to achieve\nrobust estimation by encouraging sparsity in two different levels of the\nmodeling framework. Firstly, we utilize a multiplicative Half-Cauchy process\nprior to encourage sparsity at the level of the latent variable loading\nmatrices. Additionally, we promote further sparsity in the covariance matrix by\nusing graphical horseshoe prior or diagonal structure. We conduct multiple\nsimulations to compare the performance of the proposed method with that of\nother frequently used CCA procedures, and we apply the developed procedures to\nanalyze multi-omics data arising from a breast cancer study.",
            "author": [
                "Siddhesh Kulkarni",
                "Subhadip Pal",
                "Jeremy T. Gaskins"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19621v1",
                "http://arxiv.org/pdf/2310.19621v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML",
                "62, 60"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19620v1",
            "title": "Large Trajectory Models are Scalable Motion Predictors and Planners",
            "updated": "2023-10-30T15:12:41Z",
            "published": "2023-10-30T15:12:41Z",
            "summary": "Motion prediction and planning are vital tasks in autonomous driving, and\nrecent efforts have shifted to machine learning-based approaches. The\nchallenges include understanding diverse road topologies, reasoning traffic\ndynamics over a long time horizon, interpreting heterogeneous behaviors, and\ngenerating policies in a large continuous state space. Inspired by the success\nof large language models in addressing similar complexities through model\nscaling, we introduce a scalable trajectory model called State Transformer\n(STR). STR reformulates the motion prediction and motion planning problems by\narranging observations, states, and actions into one unified sequence modeling\ntask. With a simple model design, STR consistently outperforms baseline\napproaches in both problems. Remarkably, experimental results reveal that large\ntrajectory models (LTMs), such as STR, adhere to the scaling laws by presenting\noutstanding adaptability and learning efficiency. Qualitative results further\ndemonstrate that LTMs are capable of making plausible predictions in scenarios\nthat diverge significantly from the training data distribution. LTMs also learn\nto make complex reasonings for long-term planning, without explicit loss\ndesigns or costly high-level annotations.",
            "author": [
                "Qiao Sun",
                "Shiduo Zhang",
                "Danjiao Ma",
                "Jingzhe Shi",
                "Derun Li",
                "Simian Luo",
                "Yu Wang",
                "Ningyi Xu",
                "Guangzhi Cao",
                "Hang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19620v1",
                "http://arxiv.org/pdf/2310.19620v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19619v1",
            "title": "Towards A Holistic Landscape of Situated Theory of Mind in Large\n  Language Models",
            "updated": "2023-10-30T15:12:09Z",
            "published": "2023-10-30T15:12:09Z",
            "summary": "Large Language Models (LLMs) have generated considerable interest and debate\nregarding their potential emergence of Theory of Mind (ToM). Several recent\ninquiries reveal a lack of robust ToM in these models and pose a pressing\ndemand to develop new benchmarks, as current ones primarily focus on different\naspects of ToM and are prone to shortcuts and data leakage. In this position\npaper, we seek to answer two road-blocking questions: (1) How can we taxonomize\na holistic landscape of machine ToM? (2) What is a more effective evaluation\nprotocol for machine ToM? Following psychological studies, we taxonomize\nmachine ToM into 7 mental state categories and delineate existing benchmarks to\nidentify under-explored aspects of ToM. We argue for a holistic and situated\nevaluation of ToM to break ToM into individual components and treat LLMs as an\nagent who is physically situated in environments and socially situated in\ninteractions with humans. Such situated evaluation provides a more\ncomprehensive assessment of mental states and potentially mitigates the risk of\nshortcuts and data leakage. We further present a pilot study in a grid world\nsetup as a proof of concept. We hope this position paper can facilitate future\nresearch to integrate ToM with LLMs and offer an intuitive means for\nresearchers to better position their work in the landscape of ToM. Project\npage: https://github.com/Mars-tin/awesome-theory-of-mind",
            "author": [
                "Ziqiao Ma",
                "Jacob Sansom",
                "Run Peng",
                "Joyce Chai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19619v1",
                "http://arxiv.org/pdf/2310.19619v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19614v1",
            "title": "Dis-inhibitory neuronal circuits can control the sign of synaptic\n  plasticity",
            "updated": "2023-10-30T15:06:19Z",
            "published": "2023-10-30T15:06:19Z",
            "summary": "How neuronal circuits achieve credit assignment remains a central unsolved\nquestion in systems neuroscience. Various studies have suggested plausible\nsolutions for back-propagating error signals through multi-layer networks.\nThese purely functionally motivated models assume distinct neuronal\ncompartments to represent local error signals that determine the sign of\nsynaptic plasticity. However, this explicit error modulation is inconsistent\nwith phenomenological plasticity models in which the sign depends primarily on\npostsynaptic activity. Here we show how a plausible microcircuit model and\nHebbian learning rule derived within an adaptive control theory framework can\nresolve this discrepancy. Assuming errors are encoded in top-down\ndis-inhibitory synaptic afferents, we show that error-modulated learning\nemerges naturally at the circuit level when recurrent inhibition explicitly\ninfluences Hebbian plasticity. The same learning rule accounts for\nexperimentally observed plasticity in the absence of inhibition and performs\ncomparably to back-propagation of error (BP) on several non-linearly separable\nbenchmarks. Our findings bridge the gap between functional and experimentally\nobserved plasticity rules and make concrete predictions on inhibitory\nmodulation of excitatory plasticity.",
            "author": [
                "Julian Rossbroich",
                "Friedemann Zenke"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19614v1",
                "http://arxiv.org/pdf/2310.19614v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19848v1",
            "title": "Efficient Exploration in Continuous-time Model-based Reinforcement\n  Learning",
            "updated": "2023-10-30T15:04:40Z",
            "published": "2023-10-30T15:04:40Z",
            "summary": "Reinforcement learning algorithms typically consider discrete-time dynamics,\neven though the underlying systems are often continuous in time. In this paper,\nwe introduce a model-based reinforcement learning algorithm that represents\ncontinuous-time dynamics using nonlinear ordinary differential equations\n(ODEs). We capture epistemic uncertainty using well-calibrated probabilistic\nmodels, and use the optimistic principle for exploration. Our regret bounds\nsurface the importance of the measurement selection strategy(MSS), since in\ncontinuous time we not only must decide how to explore, but also when to\nobserve the underlying system. Our analysis demonstrates that the regret is\nsublinear when modeling ODEs with Gaussian Processes (GP) for common choices of\nMSS, such as equidistant sampling. Additionally, we propose an adaptive,\ndata-dependent, practical MSS that, when combined with GP dynamics, also\nachieves sublinear regret with significantly fewer samples. We showcase the\nbenefits of continuous-time modeling over its discrete-time counterpart, as\nwell as our proposed adaptive MSS over standard baselines, on several\napplications.",
            "author": [
                "Lenart Treven",
                "Jonas H\u00fcbotter",
                "Bhavya Sukhija",
                "Florian D\u00f6rfler",
                "Andreas Krause"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19848v1",
                "http://arxiv.org/pdf/2310.19848v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19608v1",
            "title": "On Feynman--Kac training of partial Bayesian neural networks",
            "updated": "2023-10-30T15:03:15Z",
            "published": "2023-10-30T15:03:15Z",
            "summary": "Recently, partial Bayesian neural networks (pBNNs), which only consider a\nsubset of the parameters to be stochastic, were shown to perform competitively\nwith full Bayesian neural networks. However, pBNNs are often multi-modal in the\nlatent-variable space and thus challenging to approximate with parametric\nmodels. To address this problem, we propose an efficient sampling-based\ntraining strategy, wherein the training of a pBNN is formulated as simulating a\nFeynman--Kac model. We then describe variations of sequential Monte Carlo\nsamplers that allow us to simultaneously estimate the parameters and the latent\nposterior distribution of this model at a tractable computational cost. We show\non various synthetic and real-world datasets that our proposed training scheme\noutperforms the state of the art in terms of predictive performance.",
            "author": [
                "Zheng Zhao",
                "Sebastian Mair",
                "Thomas B. Sch\u00f6n",
                "Jens Sj\u00f6lund"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19608v1",
                "http://arxiv.org/pdf/2310.19608v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19607v1",
            "title": "Technical Report on the Learning of Case Relevance in Case-Based\n  Reasoning with Abstract Argumentation",
            "updated": "2023-10-30T15:01:41Z",
            "published": "2023-10-30T15:01:41Z",
            "summary": "Case-based reasoning is known to play an important role in several legal\nsettings. In this paper we focus on a recent approach to case-based reasoning,\nsupported by an instantiation of abstract argumentation whereby arguments\nrepresent cases and attack between arguments results from outcome disagreement\nbetween cases and a notion of relevance. In this context, relevance is\nconnected to a form of specificity among cases. We explore how relevance can be\nlearnt automatically in practice with the help of decision trees, and explore\nthe combination of case-based reasoning with abstract argumentation (AA-CBR)\nand learning of case relevance for prediction in legal settings. Specifically,\nwe show that, for two legal datasets, AA-CBR and decision-tree-based learning\nof case relevance perform competitively in comparison with decision trees. We\nalso show that AA-CBR with decision-tree-based learning of case relevance\nresults in a more compact representation than their decision tree counterparts,\nwhich could be beneficial for obtaining cognitively tractable explanations.",
            "author": [
                "Guilherme Paulino-Passos",
                "Francesca Toni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19607v1",
                "http://arxiv.org/pdf/2310.19607v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19603v1",
            "title": "Deep Kalman Filters Can Filter",
            "updated": "2023-10-30T14:58:12Z",
            "published": "2023-10-30T14:58:12Z",
            "summary": "Deep Kalman filters (DKFs) are a class of neural network models that generate\nGaussian probability measures from sequential data. Though DKFs are inspired by\nthe Kalman filter, they lack concrete theoretical ties to the stochastic\nfiltering problem, thus limiting their applicability to areas where traditional\nmodel-based filters have been used, e.g.\\ model calibration for bond and option\nprices in mathematical finance. We address this issue in the mathematical\nfoundations of deep learning by exhibiting a class of continuous-time DKFs\nwhich can approximately implement the conditional law of a broad class of\nnon-Markovian and conditionally Gaussian signal processes given noisy\ncontinuous-times measurements. Our approximation results hold uniformly over\nsufficiently regular compact subsets of paths, where the approximation error is\nquantified by the worst-case 2-Wasserstein distance computed uniformly over the\ngiven compact set of paths.",
            "author": [
                "Blanka Hovart",
                "Anastasis Kratsios",
                "Yannick Limmer",
                "Xuwei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19603v1",
                "http://arxiv.org/pdf/2310.19603v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "cs.NE",
                "math.NA",
                "math.PR",
                "stat.ML",
                "60G35, 62M20, 68T07, 41A65"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19602v1",
            "title": "DCHT: Deep Complex Hybrid Transformer for Speech Enhancement",
            "updated": "2023-10-30T14:58:11Z",
            "published": "2023-10-30T14:58:11Z",
            "summary": "Most of the current deep learning-based approaches for speech enhancement\nonly operate in the spectrogram or waveform domain. Although a cross-domain\ntransformer combining waveform- and spectrogram-domain inputs has been\nproposed, its performance can be further improved. In this paper, we present a\nnovel deep complex hybrid transformer that integrates both spectrogram and\nwaveform domains approaches to improve the performance of speech enhancement.\nThe proposed model consists of two parts: a complex Swin-Unet in the\nspectrogram domain and a dual-path transformer network (DPTnet) in the waveform\ndomain. We first construct a complex Swin-Unet network in the spectrogram\ndomain and perform speech enhancement in the complex audio spectrum. We then\nintroduce improved DPT by adding memory-compressed attention. Our model is\ncapable of learning multi-domain features to reduce existing noise on different\ndomains in a complementary way. The experimental results on the\nBirdSoundsDenoising dataset and the VCTK+DEMAND dataset indicate that our\nmethod can achieve better performance compared to state-of-the-art methods.",
            "author": [
                "Jialu Li",
                "Junhui Li",
                "Pu Wang",
                "Youshan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19602v1",
                "http://arxiv.org/pdf/2310.19602v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19596v2",
            "title": "LLMaAA: Making Large Language Models as Active Annotators",
            "updated": "2023-10-31T08:19:52Z",
            "published": "2023-10-30T14:54:15Z",
            "summary": "Prevalent supervised learning methods in natural language processing (NLP)\nare notoriously data-hungry, which demand large amounts of high-quality\nannotated data. In practice, acquiring such data is a costly endeavor.\nRecently, the superior few-shot performance of large language models (LLMs) has\npropelled the development of dataset generation, where the training data are\nsolely synthesized from LLMs. However, such an approach usually suffers from\nlow-quality issues, and requires orders of magnitude more labeled data to\nachieve satisfactory performance. To fully exploit the potential of LLMs and\nmake use of massive unlabeled data, we propose LLMaAA, which takes LLMs as\nannotators and puts them into an active learning loop to determine what to\nannotate efficiently. To learn robustly with pseudo labels, we optimize both\nthe annotation and training processes: (1) we draw k-NN examples from a small\ndemonstration pool as in-context examples, and (2) we adopt the example\nreweighting technique to assign training samples with learnable weights.\nCompared with previous approaches, LLMaAA features both efficiency and\nreliability. We conduct experiments and analysis on two classic NLP tasks,\nnamed entity recognition and relation extraction. With LLMaAA, task-specific\nmodels trained from LLM-generated labels can outperform the teacher within only\nhundreds of annotated examples, which is much more cost-effective than other\nbaselines.",
            "author": [
                "Ruoyu Zhang",
                "Yanzeng Li",
                "Yongliang Ma",
                "Ming Zhou",
                "Lei Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19596v2",
                "http://arxiv.org/pdf/2310.19596v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19591v1",
            "title": "Prediction of Locally Stationary Data Using Expert Advice",
            "updated": "2023-10-30T14:48:01Z",
            "published": "2023-10-30T14:48:01Z",
            "summary": "The problem of continuous machine learning is studied. Within the framework\nof the game-theoretic approach, when for calculating the next forecast, no\nassumptions about the stochastic nature of the source that generates the data\nflow are used -- the source can be analog, algorithmic or probabilistic, its\nparameters can change at random times, when building a prognostic model, only\nstructural assumptions are used about the nature of data generation. An online\nforecasting algorithm for a locally stationary time series is presented. An\nestimate of the efficiency of the proposed algorithm is obtained.",
            "author": [
                "Vladimir V'yugin",
                "Vladimir Trunov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19591v1",
                "http://arxiv.org/pdf/2310.19591v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19590v1",
            "title": "Operator Learning Enhanced Physics-informed Neural Networks for Solving\n  Partial Differential Equations Characterized by Sharp Solutions",
            "updated": "2023-10-30T14:47:55Z",
            "published": "2023-10-30T14:47:55Z",
            "summary": "Physics-informed Neural Networks (PINNs) have been shown as a promising\napproach for solving both forward and inverse problems of partial differential\nequations (PDEs). Meanwhile, the neural operator approach, including methods\nsuch as Deep Operator Network (DeepONet) and Fourier neural operator (FNO), has\nbeen introduced and extensively employed in approximating solution of PDEs.\nNevertheless, to solve problems consisting of sharp solutions poses a\nsignificant challenge when employing these two approaches. To address this\nissue, we propose in this work a novel framework termed Operator Learning\nEnhanced Physics-informed Neural Networks (OL-PINN). Initially, we utilize\nDeepONet to learn the solution operator for a set of smooth problems relevant\nto the PDEs characterized by sharp solutions. Subsequently, we integrate the\npre-trained DeepONet with PINN to resolve the target sharp solution problem. We\nshowcase the efficacy of OL-PINN by successfully addressing various problems,\nsuch as the nonlinear diffusion-reaction equation, the Burgers equation and the\nincompressible Navier-Stokes equation at high Reynolds number. Compared with\nthe vanilla PINN, the proposed method requires only a small number of residual\npoints to achieve a strong generalization capability. Moreover, it\nsubstantially enhances accuracy, while also ensuring a robust training process.\nFurthermore, OL-PINN inherits the advantage of PINN for solving inverse\nproblems. To this end, we apply the OL-PINN approach for solving problems with\nonly partial boundary conditions, which usually cannot be solved by the\nclassical numerical methods, showing its capacity in solving ill-posed problems\nand consequently more complex inverse problems.",
            "author": [
                "Bin Lin",
                "Zhiping Mao",
                "Zhicheng Wang",
                "George Em Karniadakis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19590v1",
                "http://arxiv.org/pdf/2310.19590v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19589v2",
            "title": "Modeling Dynamics over Meshes with Gauge Equivariant Nonlinear Message\n  Passing",
            "updated": "2023-11-03T02:20:30Z",
            "published": "2023-10-30T14:45:59Z",
            "summary": "Data over non-Euclidean manifolds, often discretized as surface meshes,\nnaturally arise in computer graphics and biological and physical systems. In\nparticular, solutions to partial differential equations (PDEs) over manifolds\ndepend critically on the underlying geometry. While graph neural networks have\nbeen successfully applied to PDEs, they do not incorporate surface geometry and\ndo not consider local gauge symmetries of the manifold. Alternatively, recent\nworks on gauge equivariant convolutional and attentional architectures on\nmeshes leverage the underlying geometry but underperform in modeling surface\nPDEs with complex nonlinear dynamics. To address these issues, we introduce a\nnew gauge equivariant architecture using nonlinear message passing. Our novel\narchitecture achieves higher performance than either convolutional or\nattentional networks on domains with highly complex and nonlinear dynamics.\nHowever, similar to the non-mesh case, design trade-offs favor convolutional,\nattentional, or message passing networks for different tasks; we investigate in\nwhich circumstances our message passing method provides the most benefit.",
            "author": [
                "Jung Yeon Park",
                "Lawson L. S. Wong",
                "Robin Walters"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19589v2",
                "http://arxiv.org/pdf/2310.19589v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19588v1",
            "title": "DPATD: Dual-Phase Audio Transformer for Denoising",
            "updated": "2023-10-30T14:44:59Z",
            "published": "2023-10-30T14:44:59Z",
            "summary": "Recent high-performance transformer-based speech enhancement models\ndemonstrate that time domain methods could achieve similar performance as\ntime-frequency domain methods. However, time-domain speech enhancement systems\ntypically receive input audio sequences consisting of a large number of time\nsteps, making it challenging to model extremely long sequences and train models\nto perform adequately. In this paper, we utilize smaller audio chunks as input\nto achieve efficient utilization of audio information to address the above\nchallenges. We propose a dual-phase audio transformer for denoising (DPATD), a\nnovel model to organize transformer layers in a deep structure to learn clean\naudio sequences for denoising. DPATD splits the audio input into smaller\nchunks, where the input length can be proportional to the square root of the\noriginal sequence length. Our memory-compressed explainable attention is\nefficient and converges faster compared to the frequently used self-attention\nmodule. Extensive experiments demonstrate that our model outperforms\nstate-of-the-art methods.",
            "author": [
                "Junhui Li",
                "Pu Wang",
                "Jialu Li",
                "Xinzhe Wang",
                "Youshan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19588v1",
                "http://arxiv.org/pdf/2310.19588v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19583v2",
            "title": "GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View\n  Stereo",
            "updated": "2023-11-29T14:33:09Z",
            "published": "2023-10-30T14:41:53Z",
            "summary": "Traditional multi-view stereo (MVS) methods rely heavily on photometric and\ngeometric consistency constraints, but newer machine learning-based MVS methods\ncheck geometric consistency across multiple source views only as a\npost-processing step. In this paper, we present a novel approach that\nexplicitly encourages geometric consistency of reference view depth maps across\nmultiple source views at different scales during learning (see Fig. 1). We find\nthat adding this geometric consistency loss significantly accelerates learning\nby explicitly penalizing geometrically inconsistent pixels, reducing the\ntraining iteration requirements to nearly half that of other MVS methods. Our\nextensive experiments show that our approach achieves a new state-of-the-art on\nthe DTU and BlendedMVS datasets, and competitive results on the Tanks and\nTemples benchmark. To the best of our knowledge, GC-MVSNet is the first attempt\nto enforce multi-view, multi-scale geometric consistency during learning.",
            "author": [
                "Vibhas K. Vats",
                "Sripad Joshi",
                "David J. Crandall",
                "Md. Alimoor Reza",
                "Soon-heung Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19583v2",
                "http://arxiv.org/pdf/2310.19583v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19582v2",
            "title": "Human-interpretable and deep features for image privacy classification",
            "updated": "2023-10-31T10:44:15Z",
            "published": "2023-10-30T14:39:43Z",
            "summary": "Privacy is a complex, subjective and contextual concept that is difficult to\ndefine. Therefore, the annotation of images to train privacy classifiers is a\nchallenging task. In this paper, we analyse privacy classification datasets and\nthe properties of controversial images that are annotated with contrasting\nprivacy labels by different assessors. We discuss suitable features for image\nprivacy classification and propose eight privacy-specific and\nhuman-interpretable features. These features increase the performance of deep\nlearning models and, on their own, improve the image representation for privacy\nclassification compared with much higher dimensional deep features.",
            "author": [
                "Darya Baranouskaya",
                "Andrea Cavallaro"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICIP49359.2023.10222833",
                "http://arxiv.org/abs/2310.19582v2",
                "http://arxiv.org/pdf/2310.19582v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19574v1",
            "title": "Skip-WaveNet: A Wavelet based Multi-scale Architecture to Trace Firn\n  Layers in Radar Echograms",
            "updated": "2023-10-30T14:30:27Z",
            "published": "2023-10-30T14:30:27Z",
            "summary": "Echograms created from airborne radar sensors capture the profile of firn\nlayers present on top of an ice sheet. Accurate tracking of these layers is\nessential to calculate the snow accumulation rates, which are required to\ninvestigate the contribution of polar ice cap melt to sea level rise. However,\nautomatically processing the radar echograms to detect the underlying firn\nlayers is a challenging problem. In our work, we develop wavelet-based\nmulti-scale deep learning architectures for these radar echograms to improve\nfirn layer detection. We show that wavelet based architectures improve the\noptimal dataset scale (ODS) and optimal image scale (OIS) F-scores by 3.99% and\n3.7%, respectively, over the non-wavelet architecture. Further, our proposed\nSkip-WaveNet architecture generates new wavelets in each iteration, achieves\nhigher generalizability as compared to state-of-the-art firn layer detection\nnetworks, and estimates layer depths with a mean absolute error of 3.31 pixels\nand 94.3% average precision. Such a network can be used by scientists to trace\nfirn layers, calculate the annual snow accumulation rates, estimate the\nresulting surface mass balance of the ice sheet, and help project global sea\nlevel rise.",
            "author": [
                "Debvrat Varshney",
                "Masoud Yari",
                "Oluwanisola Ibikunle",
                "Jilu Li",
                "John Paden",
                "Maryam Rahnemoonfar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19574v1",
                "http://arxiv.org/pdf/2310.19574v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19573v1",
            "title": "Model Uncertainty based Active Learning on Tabular Data using Boosted\n  Trees",
            "updated": "2023-10-30T14:29:53Z",
            "published": "2023-10-30T14:29:53Z",
            "summary": "Supervised machine learning relies on the availability of good labelled data\nfor model training. Labelled data is acquired by human annotation, which is a\ncumbersome and costly process, often requiring subject matter experts. Active\nlearning is a sub-field of machine learning which helps in obtaining the\nlabelled data efficiently by selecting the most valuable data instances for\nmodel training and querying the labels only for those instances from the human\nannotator. Recently, a lot of research has been done in the field of active\nlearning, especially for deep neural network based models. Although deep\nlearning shines when dealing with image\\textual\\multimodal data, gradient\nboosting methods still tend to achieve much better results on tabular data. In\nthis work, we explore active learning for tabular data using boosted trees.\nUncertainty based sampling in active learning is the most commonly used\nquerying strategy, wherein the labels of those instances are sequentially\nqueried for which the current model prediction is maximally uncertain. Entropy\nis often the choice for measuring uncertainty. However, entropy is not exactly\na measure of model uncertainty. Although there has been a lot of work in deep\nlearning for measuring model uncertainty and employing it in active learning,\nit is yet to be explored for non-neural network models. To this end, we explore\nthe effectiveness of boosted trees based model uncertainty methods in active\nlearning. Leveraging this model uncertainty, we propose an uncertainty based\nsampling in active learning for regression tasks on tabular data. Additionally,\nwe also propose a novel cost-effective active learning method for regression\ntasks along with an improved cost-effective active learning method for\nclassification tasks.",
            "author": [
                "Sharath M Shankaranarayana"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19573v1",
                "http://arxiv.org/pdf/2310.19573v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19572v1",
            "title": "Improving Input-label Mapping with Demonstration Replay for In-context\n  Learning",
            "updated": "2023-10-30T14:29:41Z",
            "published": "2023-10-30T14:29:41Z",
            "summary": "In-context learning (ICL) is an emerging capability of large autoregressive\nlanguage models where a few input-label demonstrations are appended to the\ninput to enhance the model's understanding of downstream NLP tasks, without\ndirectly adjusting the model parameters. The effectiveness of ICL can be\nattributed to the strong language modeling capabilities of large language\nmodels (LLMs), which enable them to learn the mapping between input and labels\nbased on in-context demonstrations. Despite achieving promising results, the\ncausal nature of language modeling in ICL restricts the attention to be\nbackward only, i.e., a token only attends to its previous tokens, failing to\ncapture the full input-label information and limiting the model's performance.\nIn this paper, we propose a novel ICL method called Repeated Demonstration with\nSliding Causal Attention, (RdSca). Specifically, we duplicate later\ndemonstrations and concatenate them to the front, allowing the model to\n`observe' the later information even under the causal restriction. Besides, we\nintroduce sliding causal attention, which customizes causal attention to avoid\ninformation leakage. Experimental results show that our method significantly\nimproves the input-label mapping in ICL demonstrations. We also conduct an\nin-depth analysis of how to customize the causal attention without training,\nwhich has been an unexplored area in previous research.",
            "author": [
                "Zhuocheng Gong",
                "Jiahao Liu",
                "Qifan Wang",
                "Jingang Wang",
                "Xunliang Cai",
                "Dongyan Zhao",
                "Rui Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19572v1",
                "http://arxiv.org/pdf/2310.19572v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19568v1",
            "title": "DataZoo: Streamlining Traffic Classification Experiments",
            "updated": "2023-10-30T14:24:25Z",
            "published": "2023-10-30T14:24:25Z",
            "summary": "The machine learning communities, such as those around computer vision or\nnatural language processing, have developed numerous supportive tools and\nbenchmark datasets to accelerate the development. In contrast, the network\ntraffic classification field lacks standard benchmark datasets for most tasks,\nand the available supportive software is rather limited in scope. This paper\naims to address the gap and introduces DataZoo, a toolset designed to\nstreamline dataset management in network traffic classification and to reduce\nthe space for potential mistakes in the evaluation setup. DataZoo provides a\nstandardized API for accessing three extensive datasets -- CESNET-QUIC22,\nCESNET-TLS22, and CESNET-TLS-Year22. Moreover, it includes methods for feature\nscaling and realistic dataset partitioning, taking into consideration temporal\nand service-related factors. The DataZoo toolset simplifies the creation of\nrealistic evaluation scenarios, making it easier to cross-compare\nclassification methods and reproduce results.",
            "author": [
                "Jan Luxemburk",
                "Karel Hynek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19568v1",
                "http://arxiv.org/pdf/2310.19568v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19567v1",
            "title": "CreoleVal: Multilingual Multitask Benchmarks for Creoles",
            "updated": "2023-10-30T14:24:20Z",
            "published": "2023-10-30T14:24:20Z",
            "summary": "Creoles represent an under-explored and marginalized group of languages, with\nfew available resources for NLP research. While the genealogical ties between\nCreoles and other highly-resourced languages imply a significant potential for\ntransfer learning, this potential is hampered due to this lack of annotated\ndata. In this work we present CreoleVal, a collection of benchmark datasets\nspanning 8 different NLP tasks, covering up to 28 Creole languages; it is an\naggregate of brand new development datasets for machine comprehension, relation\nclassification, and machine translation for Creoles, in addition to a practical\ngateway to a handful of preexisting benchmarks. For each benchmark, we conduct\nbaseline experiments in a zero-shot setting in order to further ascertain the\ncapabilities and limitations of transfer learning for Creoles. Ultimately, the\ngoal of CreoleVal is to empower research on Creoles in NLP and computational\nlinguistics. We hope this resource will contribute to technological inclusion\nfor Creole language users around the globe.",
            "author": [
                "Heather Lent",
                "Kushal Tatariya",
                "Raj Dabre",
                "Yiyi Chen",
                "Marcell Fekete",
                "Esther Ploeger",
                "Li Zhou",
                "Hans Erik Heje",
                "Diptesh Kanojia",
                "Paul Belony",
                "Marcel Bollmann",
                "Lo\u00efc Grobol",
                "Miryam de Lhoneux",
                "Daniel Hershcovich",
                "Michel DeGraff",
                "Anders S\u00f8gaard",
                "Johannes Bjerva"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19567v1",
                "http://arxiv.org/pdf/2310.19567v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19561v1",
            "title": "Non-parametric regression for robot learning on manifolds",
            "updated": "2023-10-30T14:17:32Z",
            "published": "2023-10-30T14:17:32Z",
            "summary": "Many of the tools available for robot learning were designed for Euclidean\ndata. However, many applications in robotics involve manifold-valued data. A\ncommon example is orientation; this can be represented as a 3-by-3 rotation\nmatrix or a quaternion, the spaces of which are non-Euclidean manifolds. In\nrobot learning, manifold-valued data are often handled by relating the manifold\nto a suitable Euclidean space, either by embedding the manifold or by\nprojecting the data onto one or several tangent spaces. These approaches can\nresult in poor predictive accuracy, and convoluted algorithms. In this paper,\nwe propose an \"intrinsic\" approach to regression that works directly within the\nmanifold. It involves taking a suitable probability distribution on the\nmanifold, letting its parameter be a function of a predictor variable, such as\ntime, then estimating that function non-parametrically via a \"local likelihood\"\nmethod that incorporates a kernel. We name the method kernelised likelihood\nestimation. The approach is conceptually simple, and generally applicable to\ndifferent manifolds. We implement it with three different types of\nmanifold-valued data that commonly appear in robotics applications. The results\nof these experiments show better predictive accuracy than projection-based\nalgorithms.",
            "author": [
                "P. C. Lopez-Custodio",
                "K. Bharath",
                "A. Kucukyilmaz",
                "S. P. Preston"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19561v1",
                "http://arxiv.org/pdf/2310.19561v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19559v2",
            "title": "Disentangled Counterfactual Learning for Physical Audiovisual\n  Commonsense Reasoning",
            "updated": "2023-11-02T02:36:12Z",
            "published": "2023-10-30T14:16:34Z",
            "summary": "In this paper, we propose a Disentangled Counterfactual Learning~(DCL)\napproach for physical audiovisual commonsense reasoning. The task aims to infer\nobjects' physics commonsense based on both video and audio input, with the main\nchallenge is how to imitate the reasoning ability of humans. Most of the\ncurrent methods fail to take full advantage of different characteristics in\nmulti-modal data, and lacking causal reasoning ability in models impedes the\nprogress of implicit physical knowledge inferring. To address these issues, our\nproposed DCL method decouples videos into static (time-invariant) and dynamic\n(time-varying) factors in the latent space by the disentangled sequential\nencoder, which adopts a variational autoencoder (VAE) to maximize the mutual\ninformation with a contrastive loss function. Furthermore, we introduce a\ncounterfactual learning module to augment the model's reasoning ability by\nmodeling physical knowledge relationships among different objects under\ncounterfactual intervention. Our proposed method is a plug-and-play module that\ncan be incorporated into any baseline. In experiments, we show that our\nproposed method improves baseline methods and achieves state-of-the-art\nperformance. Our source code is available at https://github.com/Andy20178/DCL.",
            "author": [
                "Changsheng Lv",
                "Shuai Zhang",
                "Yapeng Tian",
                "Mengshi Qi",
                "Huadong Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19559v2",
                "http://arxiv.org/pdf/2310.19559v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19558v1",
            "title": "Privacy-preserving Federated Primal-dual Learning for Non-convex and\n  Non-smooth Problems with Model Sparsification",
            "updated": "2023-10-30T14:15:47Z",
            "published": "2023-10-30T14:15:47Z",
            "summary": "Federated learning (FL) has been recognized as a rapidly growing research\narea, where the model is trained over massively distributed clients under the\norchestration of a parameter server (PS) without sharing clients' data. This\npaper delves into a class of federated problems characterized by non-convex and\nnon-smooth loss functions, that are prevalent in FL applications but\nchallenging to handle due to their intricate non-convexity and non-smoothness\nnature and the conflicting requirements on communication efficiency and privacy\nprotection. In this paper, we propose a novel federated primal-dual algorithm\nwith bidirectional model sparsification tailored for non-convex and non-smooth\nFL problems, and differential privacy is applied for strong privacy guarantee.\nIts unique insightful properties and some privacy and convergence analyses are\nalso presented for the FL algorithm design guidelines. Extensive experiments on\nreal-world data are conducted to demonstrate the effectiveness of the proposed\nalgorithm and much superior performance than some state-of-the-art FL\nalgorithms, together with the validation of all the analytical results and\nproperties.",
            "author": [
                "Yiwei Li",
                "Chien-Wei Huang",
                "Shuai Wang",
                "Chong-Yung Chi",
                "Tony Q. S. Quek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19558v1",
                "http://arxiv.org/pdf/2310.19558v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19554v1",
            "title": "Harvest Video Foundation Models via Efficient Post-Pretraining",
            "updated": "2023-10-30T14:06:16Z",
            "published": "2023-10-30T14:06:16Z",
            "summary": "Building video-language foundation models is costly and difficult due to the\nredundant nature of video data and the lack of high-quality video-language\ndatasets. In this paper, we propose an efficient framework to harvest video\nfoundation models from image ones. Our method is intuitively simple by randomly\ndropping input video patches and masking out input text during the\npost-pretraining procedure. The patch dropping boosts the training efficiency\nsignificantly and text masking enforces the learning of cross-modal fusion. We\nconduct extensive experiments to validate the effectiveness of our method on a\nwide range of video-language downstream tasks including various zero-shot\ntasks, video question answering, and video-text retrieval. Despite its\nsimplicity, our method achieves state-of-the-art performances, which are\ncomparable to some heavily pretrained video foundation models. Our method is\nextremely efficient and can be trained in less than one day on 8 GPUs,\nrequiring only WebVid-10M as pretraining data. We hope our method can serve as\na simple yet strong counterpart for prevalent video foundation models, provide\nuseful insights when building them, and make large pretrained models more\naccessible and sustainable. This is part of the InternVideo project\n\\url{https://github.com/OpenGVLab/InternVideo}.",
            "author": [
                "Yizhuo Li",
                "Kunchang Li",
                "Yinan He",
                "Yi Wang",
                "Yali Wang",
                "Limin Wang",
                "Yu Qiao",
                "Ping Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19554v1",
                "http://arxiv.org/pdf/2310.19554v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19548v2",
            "title": "Approximation Theory, Computing, and Deep Learning on the Wasserstein\n  Space",
            "updated": "2023-11-16T17:57:02Z",
            "published": "2023-10-30T13:59:47Z",
            "summary": "The challenge of approximating functions in infinite-dimensional spaces from\nfinite samples is widely regarded as formidable. In this study, we delve into\nthe challenging problem of the numerical approximation of Sobolev-smooth\nfunctions defined on probability spaces. Our particular focus centers on the\nWasserstein distance function, which serves as a relevant example. In contrast\nto the existing body of literature focused on approximating efficiently\npointwise evaluations, we chart a new course to define functional approximants\nby adopting three machine learning-based approaches: 1. Solving a finite number\nof optimal transport problems and computing the corresponding Wasserstein\npotentials. 2. Employing empirical risk minimization with Tikhonov\nregularization in Wasserstein Sobolev spaces. 3. Addressing the problem through\nthe saddle point formulation that characterizes the weak form of the Tikhonov\nfunctional's Euler-Lagrange equation. As a theoretical contribution, we furnish\nexplicit and quantitative bounds on generalization errors for each of these\nsolutions. In the proofs, we leverage the theory of metric Sobolev spaces and\nwe combine it with techniques of optimal transport, variational calculus, and\nlarge deviation bounds. In our numerical implementation, we harness\nappropriately designed neural networks to serve as basis functions. These\nnetworks undergo training using diverse methodologies. This approach allows us\nto obtain approximating functions that can be rapidly evaluated after training.\nConsequently, our constructive solutions significantly enhance at equal\naccuracy the evaluation speed, surpassing that of state-of-the-art methods by\nseveral orders of magnitude.",
            "author": [
                "Massimo Fornasier",
                "Pascal Heid",
                "Giacomo Enrico Sodini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19548v2",
                "http://arxiv.org/pdf/2310.19548v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "math.FA",
                "49Q22, 33F05, 46E36, 28A33, 68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19545v1",
            "title": "MENTOR: Human Perception-Guided Pretraining for Iris Presentation\n  Detection",
            "updated": "2023-10-30T13:50:44Z",
            "published": "2023-10-30T13:50:44Z",
            "summary": "Incorporating human salience into the training of CNNs has boosted\nperformance in difficult tasks such as biometric presentation attack detection.\nHowever, collecting human annotations is a laborious task, not to mention the\nquestions of how and where (in the model architecture) to efficiently\nincorporate this information into model's training once annotations are\nobtained. In this paper, we introduce MENTOR (huMan pErceptioN-guided\npreTraining fOr iris pResentation attack detection), which addresses both of\nthese issues through two unique rounds of training. First, we train an\nautoencoder to learn human saliency maps given an input iris image (both real\nand fake examples). Once this representation is learned, we utilize the trained\nautoencoder in two different ways: (a) as a pre-trained backbone for an iris\npresentation attack detector, and (b) as a human-inspired annotator of salient\nfeatures on unknown data. We show that MENTOR's benefits are threefold: (a)\nsignificant boost in iris PAD performance when using the human\nperception-trained encoder's weights compared to general-purpose weights (e.g.\nImageNet-sourced, or random), (b) capability of generating infinite number of\nhuman-like saliency maps for unseen iris PAD samples to be used in any human\nsaliency-guided training paradigm, and (c) increase in efficiency of iris PAD\nmodel training. Sources codes and weights are offered along with the paper.",
            "author": [
                "Colton R. Crum",
                "Adam Czajka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19545v1",
                "http://arxiv.org/pdf/2310.19545v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.02167v1",
            "title": "Uncertainty Quantification in Machine Learning Based Segmentation: A\n  Post-Hoc Approach for Left Ventricle Volume Estimation in MRI",
            "updated": "2023-10-30T13:44:55Z",
            "published": "2023-10-30T13:44:55Z",
            "summary": "Recent studies have confirmed cardiovascular diseases remain responsible for\nhighest death toll amongst non-communicable diseases. Accurate left ventricular\n(LV) volume estimation is critical for valid diagnosis and management of\nvarious cardiovascular conditions, but poses significant challenge due to\ninherent uncertainties associated with segmentation algorithms in magnetic\nresonance imaging (MRI). Recent machine learning advancements, particularly\nU-Net-like convolutional networks, have facilitated automated segmentation for\nmedical images, but struggles under certain pathologies and/or different\nscanner vendors and imaging protocols. This study proposes a novel methodology\nfor post-hoc uncertainty estimation in LV volume prediction using It\\^{o}\nstochastic differential equations (SDEs) to model path-wise behavior for the\nprediction error. The model describes the area of the left ventricle along the\nheart's long axis. The method is agnostic to the underlying segmentation\nalgorithm, facilitating its use with various existing and future segmentation\ntechnologies. The proposed approach provides a mechanism for quantifying\nuncertainty, enabling medical professionals to intervene for unreliable\npredictions. This is of utmost importance in critical applications such as\nmedical diagnosis, where prediction accuracy and reliability can directly\nimpact patient outcomes. The method is also robust to dataset changes, enabling\napplication for medical centers with limited access to labeled data. Our\nfindings highlight the proposed uncertainty estimation methodology's potential\nto enhance automated segmentation robustness and generalizability, paving the\nway for more reliable and accurate LV volume estimation in clinical settings as\nwell as opening new avenues for uncertainty quantification in biomedical image\nsegmentation, providing promising directions for future research.",
            "author": [
                "F. Terhag",
                "P. Knechtges",
                "A. Basermann",
                "R. Tempone"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02167v1",
                "http://arxiv.org/pdf/2312.02167v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ME",
                "68T07, 62P10, 92C55, 68T05, 65C20, 62M45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19537v2",
            "title": "On consequences of finetuning on data with highly discriminative\n  features",
            "updated": "2023-11-15T22:09:08Z",
            "published": "2023-10-30T13:43:50Z",
            "summary": "In the era of transfer learning, training neural networks from scratch is\nbecoming obsolete. Transfer learning leverages prior knowledge for new tasks,\nconserving computational resources. While its advantages are well-documented,\nwe uncover a notable drawback: networks tend to prioritize basic data patterns,\nforsaking valuable pre-learned features. We term this behavior \"feature\nerosion\" and analyze its impact on network performance and internal\nrepresentations.",
            "author": [
                "Wojciech Masarczyk",
                "Tomasz Trzci\u0144ski",
                "Mateusz Ostaszewski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19537v2",
                "http://arxiv.org/pdf/2310.19537v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19536v1",
            "title": "Adversarial Batch Inverse Reinforcement Learning: Learn to Reward from\n  Imperfect Demonstration for Interactive Recommendation",
            "updated": "2023-10-30T13:43:20Z",
            "published": "2023-10-30T13:43:20Z",
            "summary": "Rewards serve as a measure of user satisfaction and act as a limiting factor\nin interactive recommender systems. In this research, we focus on the problem\nof learning to reward (LTR), which is fundamental to reinforcement learning.\nPrevious approaches either introduce additional procedures for learning to\nreward, thereby increasing the complexity of optimization, or assume that\nuser-agent interactions provide perfect demonstrations, which is not feasible\nin practice. Ideally, we aim to employ a unified approach that optimizes both\nthe reward and policy using compositional demonstrations. However, this\nrequirement presents a challenge since rewards inherently quantify user\nfeedback on-policy, while recommender agents approximate off-policy future\ncumulative valuation. To tackle this challenge, we propose a novel batch\ninverse reinforcement learning paradigm that achieves the desired properties.\nOur method utilizes discounted stationary distribution correction to combine\nLTR and recommender agent evaluation. To fulfill the compositional requirement,\nwe incorporate the concept of pessimism through conservation. Specifically, we\nmodify the vanilla correction using Bellman transformation and enforce KL\nregularization to constrain consecutive policy updates. We use two real-world\ndatasets which represent two compositional coverage to conduct empirical\nstudies, the results also show that the proposed method relatively improves\nboth effectiveness (2.3\\%) and efficiency (11.53\\%)",
            "author": [
                "Jialin Liu",
                "Xinyan Su",
                "Zeyu He",
                "Xiangyu Zhao",
                "Jun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19536v1",
                "http://arxiv.org/pdf/2310.19536v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19535v2",
            "title": "Revitalizing Legacy Video Content: Deinterlacing with Bidirectional\n  Information Propagation",
            "updated": "2023-12-05T15:06:02Z",
            "published": "2023-10-30T13:43:19Z",
            "summary": "Due to old CRT display technology and limited transmission bandwidth, early\nfilm and TV broadcasts commonly used interlaced scanning. This meant each field\ncontained only half of the information. Since modern displays require full\nframes, this has spurred research into deinterlacing, i.e. restoring the\nmissing information in legacy video content. In this paper, we present a\ndeep-learning-based method for deinterlacing animated and live-action content.\nOur proposed method supports bidirectional spatio-temporal information\npropagation across multiple scales to leverage information in both space and\ntime. More specifically, we design a Flow-guided Refinement Block (FRB) which\nperforms feature refinement including alignment, fusion, and rectification.\nAdditionally, our method can process multiple fields simultaneously, reducing\nper-frame processing time, and potentially enabling real-time processing. Our\nexperimental results demonstrate that our proposed method achieves superior\nperformance compared to existing methods.",
            "author": [
                "Zhaowei Gao",
                "Mingyang Song",
                "Christopher Schroers",
                "Yang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19535v2",
                "http://arxiv.org/pdf/2310.19535v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19531v3",
            "title": "InfoEntropy Loss to Mitigate Bias of Learning Difficulties for\n  Generative Language Models",
            "updated": "2023-11-10T09:35:30Z",
            "published": "2023-10-30T13:33:21Z",
            "summary": "Generative language models are usually pretrained on large text corpus via\npredicting the next token (i.e., sub-word/word/phrase) given the previous ones.\nRecent works have demonstrated the impressive performance of large generative\nlanguage models on downstream tasks. However, existing generative language\nmodels generally neglect an inherent challenge in text corpus during training,\ni.e., the imbalance between frequent tokens and infrequent ones. It can lead a\nlanguage model to be dominated by common and easy-to-learn tokens, thereby\noverlooking the infrequent and difficult-to-learn ones. To alleviate that, we\npropose an Information Entropy Loss (InfoEntropy Loss) function. During\ntraining, it can dynamically assess the learning difficulty of a to-be-learned\ntoken, according to the information entropy of the corresponding predicted\nprobability distribution over the vocabulary. Then it scales the training loss\nadaptively, trying to lead the model to focus more on the difficult-to-learn\ntokens. On the Pile dataset, we train generative language models at different\nscales of 468M, 1.2B, and 6.7B parameters. Experiments reveal that models\nincorporating the proposed InfoEntropy Loss can gain consistent performance\nimprovement on downstream benchmarks.",
            "author": [
                "Zhenpeng Su",
                "Xing Wu",
                "Xue Bai",
                "Zijia Lin",
                "Hui Chen",
                "Guiguang Ding",
                "Wei Zhou",
                "Songlin Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19531v3",
                "http://arxiv.org/pdf/2310.19531v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19527v1",
            "title": "Decoupled Actor-Critic",
            "updated": "2023-10-30T13:28:06Z",
            "published": "2023-10-30T13:28:06Z",
            "summary": "Actor-Critic methods are in a stalemate of two seemingly irreconcilable\nproblems. Firstly, critic proneness towards overestimation requires sampling\ntemporal-difference targets from a conservative policy optimized using\nlower-bound Q-values. Secondly, well-known results show that policies that are\noptimistic in the face of uncertainty yield lower regret levels. To remedy this\ndichotomy, we propose Decoupled Actor-Critic (DAC). DAC is an off-policy\nalgorithm that learns two distinct actors by gradient backpropagation: a\nconservative actor used for temporal-difference learning and an optimistic\nactor used for exploration. We test DAC on DeepMind Control tasks in low and\nhigh replay ratio regimes and ablate multiple design choices. Despite minimal\ncomputational overhead, DAC achieves state-of-the-art performance and sample\nefficiency on locomotion tasks.",
            "author": [
                "Michal Nauman",
                "Marek Cygan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19527v1",
                "http://arxiv.org/pdf/2310.19527v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19522v2",
            "title": "Are Natural Domain Foundation Models Useful for Medical Image\n  Classification?",
            "updated": "2023-11-14T12:21:41Z",
            "published": "2023-10-30T13:21:56Z",
            "summary": "The deep learning field is converging towards the use of general foundation\nmodels that can be easily adapted for diverse tasks. While this paradigm shift\nhas become common practice within the field of natural language processing,\nprogress has been slower in computer vision. In this paper we attempt to\naddress this issue by investigating the transferability of various\nstate-of-the-art foundation models to medical image classification tasks.\nSpecifically, we evaluate the performance of five foundation models, namely\nSAM, SEEM, DINOv2, BLIP, and OpenCLIP across four well-established medical\nimaging datasets. We explore different training settings to fully harness the\npotential of these models. Our study shows mixed results. DINOv2 consistently\noutperforms the standard practice of ImageNet pretraining. However, other\nfoundation models failed to consistently beat this established baseline\nindicating limitations in their transferability to medical image classification\ntasks.",
            "author": [
                "Joana Pal\u00e9s Huix",
                "Adithya Raju Ganeshan",
                "Johan Fredin Haslum",
                "Magnus S\u00f6derberg",
                "Christos Matsoukas",
                "Kevin Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19522v2",
                "http://arxiv.org/pdf/2310.19522v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19519v1",
            "title": "A General Neural Causal Model for Interactive Recommendation",
            "updated": "2023-10-30T13:21:04Z",
            "published": "2023-10-30T13:21:04Z",
            "summary": "Survivor bias in observational data leads the optimization of recommender\nsystems towards local optima. Currently most solutions re-mines existing\nhuman-system collaboration patterns to maximize longer-term satisfaction by\nreinforcement learning. However, from the causal perspective, mitigating\nsurvivor effects requires answering a counterfactual problem, which is\ngenerally unidentifiable and inestimable. In this work, we propose a neural\ncausal model to achieve counterfactual inference. Specifically, we first build\na learnable structural causal model based on its available graphical\nrepresentations which qualitatively characterizes the preference transitions.\nMitigation of the survivor bias is achieved though counterfactual consistency.\nTo identify the consistency, we use the Gumbel-max function as structural\nconstrains. To estimate the consistency, we apply reinforcement optimizations,\nand use Gumbel-Softmax as a trade-off to get a differentiable function. Both\ntheoretical and empirical studies demonstrate the effectiveness of our\nsolution.",
            "author": [
                "Jialin Liu",
                "Xinyan Su",
                "Peng Zhou",
                "Xiangyu Zhao",
                "Jun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19519v1",
                "http://arxiv.org/pdf/2310.19519v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19515v1",
            "title": "Transformer-based nowcasting of radar composites from satellite images\n  for severe weather",
            "updated": "2023-10-30T13:17:38Z",
            "published": "2023-10-30T13:17:38Z",
            "summary": "Weather radar data are critical for nowcasting and an integral component of\nnumerical weather prediction models. While weather radar data provide valuable\ninformation at high resolution, their ground-based nature limits their\navailability, which impedes large-scale applications. In contrast,\nmeteorological satellites cover larger domains but with coarser resolution.\n  However, with the rapid advancements in data-driven methodologies and modern\nsensors aboard geostationary satellites, new opportunities are emerging to\nbridge the gap between ground- and space-based observations, ultimately leading\nto more skillful weather prediction with high accuracy.\n  Here, we present a Transformer-based model for nowcasting ground-based radar\nimage sequences using satellite data up to two hours lead time. Trained on a\ndataset reflecting severe weather conditions, the model predicts radar fields\noccurring under different weather phenomena and shows robustness against\nrapidly growing/decaying fields and complex field structures.\n  Model interpretation reveals that the infrared channel centered at 10.3 $\\mu\nm$ (C13) contains skillful information for all weather conditions, while\nlightning data have the highest relative feature importance in severe weather\nconditions, particularly in shorter lead times.\n  The model can support precipitation nowcasting across large domains without\nan explicit need for radar towers, enhance numerical weather prediction and\nhydrological models, and provide radar proxy for data-scarce regions. Moreover,\nthe open-source framework facilitates progress towards operational data-driven\nnowcasting.",
            "author": [
                "\u00c7a\u011flar K\u00fc\u00e7\u00fck",
                "Apostolos Giannakos",
                "Stefan Schneider",
                "Alexander Jann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19515v1",
                "http://arxiv.org/pdf/2310.19515v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19513v1",
            "title": "Inverse folding for antibody sequence design using deep learning",
            "updated": "2023-10-30T13:12:41Z",
            "published": "2023-10-30T13:12:41Z",
            "summary": "We consider the problem of antibody sequence design given 3D structural\ninformation. Building on previous work, we propose a fine-tuned inverse folding\nmodel that is specifically optimised for antibody structures and outperforms\ngeneric protein models on sequence recovery and structure robustness when\napplied on antibodies, with notable improvement on the hypervariable CDR-H3\nloop. We study the canonical conformations of complementarity-determining\nregions and find improved encoding of these loops into known clusters. Finally,\nwe consider the applications of our model to drug discovery and binder design\nand evaluate the quality of proposed sequences using physics-based methods.",
            "author": [
                "Fr\u00e9d\u00e9ric A. Dreyer",
                "Daniel Cutting",
                "Constantin Schneider",
                "Henry Kenlay",
                "Charlotte M. Deane"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19513v1",
                "http://arxiv.org/pdf/2310.19513v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19511v1",
            "title": "Rule-Based Lloyd Algorithm for Multi-Robot Motion Planning and Control\n  with Safety and Convergence Guarantees",
            "updated": "2023-10-30T13:10:05Z",
            "published": "2023-10-30T13:10:05Z",
            "summary": "This paper presents a distributed rule-based Lloyd algorithm (RBL) for\nmulti-robot motion planning and control. The main limitations of the basic\nLoyd-based algorithm (LB) concern deadlock issues and the failure to address\ndynamic constraints effectively. Our contribution is twofold. First, we show\nhow RBL is able to provide safety and convergence to the goal region without\nrelying on communication between robots, nor neighbors control inputs, nor\nsynchronization between the robots. We considered both case of holonomic and\nnon-holonomic robots with control inputs saturation. Second, we show that the\nLloyd-based algorithm (without rules) can be successfully used as a safety\nlayer for learning-based approaches, leading to non-negligible benefits. We\nfurther prove the soundness, reliability, and scalability of RBL through\nextensive simulations, an updated comparison with the state of the art, and\nexperimental validations on small-scale car-like robots.",
            "author": [
                "Manuel Boldrer",
                "Alvaro Serra-Gomez",
                "Lorenzo Lyons",
                "Javier Alonso-Mora",
                "Laura Ferranti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19511v1",
                "http://arxiv.org/pdf/2310.19511v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19503v2",
            "title": "Trust, Accountability, and Autonomy in Knowledge Graph-based AI for\n  Self-determination",
            "updated": "2023-10-31T09:16:13Z",
            "published": "2023-10-30T12:51:52Z",
            "summary": "Knowledge Graphs (KGs) have emerged as fundamental platforms for powering\nintelligent decision-making and a wide range of Artificial Intelligence (AI)\nservices across major corporations such as Google, Walmart, and AirBnb. KGs\ncomplement Machine Learning (ML) algorithms by providing data context and\nsemantics, thereby enabling further inference and question-answering\ncapabilities. The integration of KGs with neuronal learning (e.g., Large\nLanguage Models (LLMs)) is currently a topic of active research, commonly named\nneuro-symbolic AI. Despite the numerous benefits that can be accomplished with\nKG-based AI, its growing ubiquity within online services may result in the loss\nof self-determination for citizens as a fundamental societal issue. The more we\nrely on these technologies, which are often centralised, the less citizens will\nbe able to determine their own destinies. To counter this threat, AI\nregulation, such as the European Union (EU) AI Act, is being proposed in\ncertain regions. The regulation sets what technologists need to do, leading to\nquestions concerning: How can the output of AI systems be trusted? What is\nneeded to ensure that the data fuelling and the inner workings of these\nartefacts are transparent? How can AI be made accountable for its\ndecision-making? This paper conceptualises the foundational topics and research\npillars to support KG-based AI for self-determination. Drawing upon this\nconceptual framework, challenges and opportunities for citizen\nself-determination are illustrated and analysed in a real-world scenario. As a\nresult, we propose a research agenda aimed at accomplishing the recommended\nobjectives.",
            "author": [
                "Luis-Daniel Ib\u00e1\u00f1ez",
                "John Domingue",
                "Sabrina Kirrane",
                "Oshani Seneviratne",
                "Aisling Third",
                "Maria-Esther Vidal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19503v2",
                "http://arxiv.org/pdf/2310.19503v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19495v1",
            "title": "Deep Learning for Visual Navigation of Underwater Robots",
            "updated": "2023-10-30T12:37:49Z",
            "published": "2023-10-30T12:37:49Z",
            "summary": "This paper aims to briefly survey deep learning methods for visual navigation\nof underwater robotics. The scope of this paper includes the visual perception\nof underwater robotics with deep learning methods, the available visual\nunderwater datasets, imitation learning, and reinforcement learning methods for\nnavigation. Additionally, relevant works will be categorized under the\nimitation learning or deep learning paradigm for underwater robots for clarity\nof the training methodologies in the current landscape. Literature that uses\ndeep learning algorithms to process non-visual data for underwater navigation\nwill not be considered, except as contrasting examples.",
            "author": [
                "M. Sunbeam"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19495v1",
                "http://arxiv.org/pdf/2310.19495v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19491v1",
            "title": "Generator Identification for Linear SDEs with Additive and\n  Multiplicative Noise",
            "updated": "2023-10-30T12:28:53Z",
            "published": "2023-10-30T12:28:53Z",
            "summary": "In this paper, we present conditions for identifying the generator of a\nlinear stochastic differential equation (SDE) from the distribution of its\nsolution process with a given fixed initial state. These identifiability\nconditions are crucial in causal inference using linear SDEs as they enable the\nidentification of the post-intervention distributions from its observational\ndistribution. Specifically, we derive a sufficient and necessary condition for\nidentifying the generator of linear SDEs with additive noise, as well as a\nsufficient condition for identifying the generator of linear SDEs with\nmultiplicative noise. We show that the conditions derived for both types of\nSDEs are generic. Moreover, we offer geometric interpretations of the derived\nidentifiability conditions to enhance their understanding. To validate our\ntheoretical results, we perform a series of simulations, which support and\nsubstantiate the established findings.",
            "author": [
                "Yuanyuan Wang",
                "Xi Geng",
                "Wei Huang",
                "Biwei Huang",
                "Mingming Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19491v1",
                "http://arxiv.org/pdf/2310.19491v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.LG",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19489v1",
            "title": "Adaptive Meta-Learning-Based KKL Observer Design for Nonlinear Dynamical\n  Systems",
            "updated": "2023-10-30T12:25:14Z",
            "published": "2023-10-30T12:25:14Z",
            "summary": "The theory of Kazantzis-Kravaris/Luenberger (KKL) observer design introduces\na methodology that uses a nonlinear transformation map and its left inverse to\nestimate the state of a nonlinear system through the introduction of a linear\nobserver state space. Data-driven approaches using artificial neural networks\nhave demonstrated the ability to accurately approximate these transformation\nmaps. This paper presents a novel approach to observer design for nonlinear\ndynamical systems through meta-learning, a concept in machine learning that\naims to optimize learning models for fast adaptation to a distribution of tasks\nthrough an improved focus on the intrinsic properties of the underlying\nlearning problem. We introduce a framework that leverages information from\nmeasurements of the system output to design a learning-based KKL observer\ncapable of online adaptation to a variety of system conditions and attributes.\nTo validate the effectiveness of our approach, we present comprehensive\nexperimental results for the estimation of nonlinear system states with varying\ninitial conditions and internal parameters, demonstrating high accuracy,\ngeneralization capability, and robustness against noise.",
            "author": [
                "Lukas Trommer",
                "Halil Yigit Oksuz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19489v1",
                "http://arxiv.org/pdf/2310.19489v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19485v1",
            "title": "Anomalous tensile strength and thermal expansion, and low thermal\n  conductivity in wide band gap boron monoxide monolayer",
            "updated": "2023-10-30T12:13:58Z",
            "published": "2023-10-30T12:13:58Z",
            "summary": "Most recently the formation of boron monoxide (BO) in the two-dimensional\n(2D) form has been confirmed experimentally (J. Am. Chem. Soc. 2023, 145,\n14660). Motivated by the aforementioned finding, herein we theoretically\nexplore the key physical properties of the single-layer and suspended BO.\nDensity functional theory (DFT) results reveal that BO monolayer yields a large\nindirect band gap of 3.78 (2.18) eV on the basis of HSE06(PBE) functional.\nAb-initio molecular dynamics results reveal the remarkable thermal stability of\nthe BO monolayer at 1000 K. The thermal and mechanical properties at room\ntemperature are furthermore investigated using a machine learning interatomic\npotential (MLIP). The developed MLIP-based model close to the ground state\ncould very precisely reproduce the DFT predictions for the mechanical\nproperties of the BO monolayer. The elastic modulus, tensile strength and\nlattice thermal conductivity of the BO monolayer at room temperature are\npredicted to be 107 GPa, 25 GPa and 5.6 W/mK, respectively. At the room\ntemperature the BO monolayer is noticeably predicted to yield an ultrahigh\nnegative thermal expansion coefficient, by almost 17 folds larger than that of\nthe single-layer graphene. The presented results reveal the large indirect\nelectronic band gap, decent thermal and dynamical stability, anomalously low\nelastic modulus to tensile strength ratio, ultrahigh negative thermal expansion\ncoefficients and low lattice thermal conductivity of the BO monolayer.",
            "author": [
                "Bohayra Mortazavi",
                "Fazel Shojaei",
                "Fei Ding",
                "Xiaoying Zhuang"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.flatc.2023.100575",
                "http://arxiv.org/abs/2310.19485v1",
                "http://arxiv.org/pdf/2310.19485v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19477v2",
            "title": "VDIP-TGV: Blind Image Deconvolution via Variational Deep Image Prior\n  Empowered by Total Generalized Variation",
            "updated": "2023-11-10T14:26:34Z",
            "published": "2023-10-30T12:03:18Z",
            "summary": "Recovering clear images from blurry ones with an unknown blur kernel is a\nchallenging problem. Deep image prior (DIP) proposes to use the deep network as\na regularizer for a single image rather than as a supervised model, which\nachieves encouraging results in the nonblind deblurring problem. However, since\nthe relationship between images and the network architectures is unclear, it is\nhard to find a suitable architecture to provide sufficient constraints on the\nestimated blur kernels and clean images. Also, DIP uses the sparse maximum a\nposteriori (MAP), which is insufficient to enforce the selection of the\nrecovery image. Recently, variational deep image prior (VDIP) was proposed to\nimpose constraints on both blur kernels and recovery images and take the\nstandard deviation of the image into account during the optimization process by\nthe variational principle. However, we empirically find that VDIP struggles\nwith processing image details and tends to generate suboptimal results when the\nblur kernel is large. Therefore, we combine total generalized variational (TGV)\nregularization with VDIP in this paper to overcome these shortcomings of VDIP.\nTGV is a flexible regularization that utilizes the characteristics of partial\nderivatives of varying orders to regularize images at different scales,\nreducing oil painting artifacts while maintaining sharp edges. The proposed\nVDIP-TGV effectively recovers image edges and details by supplementing extra\ngradient information through TGV. Additionally, this model is solved by the\nalternating direction method of multipliers (ADMM), which effectively combines\ntraditional algorithms and deep learning methods. Experiments show that our\nproposed VDIP-TGV surpasses various state-of-the-art models quantitatively and\nqualitatively.",
            "author": [
                "Tingting Wu",
                "Zhiyan Du",
                "Zhi Li",
                "Feng-Lei Fan",
                "Tieyong Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19477v2",
                "http://arxiv.org/pdf/2310.19477v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19470v1",
            "title": "Grokking Tickets: Lottery Tickets Accelerate Grokking",
            "updated": "2023-10-30T11:58:44Z",
            "published": "2023-10-30T11:58:44Z",
            "summary": "Grokking is one of the most surprising puzzles in neural network\ngeneralization: a network first reaches a memorization solution with perfect\ntraining accuracy and poor generalization, but with further training, it\nreaches a perfectly generalized solution. We aim to analyze the mechanism of\ngrokking from the lottery ticket hypothesis, identifying the process to find\nthe lottery tickets (good sparse subnetworks) as the key to describing the\ntransitional phase between memorization and generalization. We refer to these\nsubnetworks as ''Grokking tickets'', which is identified via magnitude pruning\nafter perfect generalization. First, using ''Grokking tickets'', we show that\nthe lottery tickets drastically accelerate grokking compared to the dense\nnetworks on various configurations (MLP and Transformer, and an arithmetic and\nimage classification tasks). Additionally, to verify that ''Grokking ticket''\nare a more critical factor than weight norms, we compared the ''good''\nsubnetworks with a dense network having the same L1 and L2 norms. Results show\nthat the subnetworks generalize faster than the controlled dense model. In\nfurther investigations, we discovered that at an appropriate pruning rate,\ngrokking can be achieved even without weight decay. We also show that speedup\ndoes not happen when using tickets identified at the memorization solution or\ntransition between memorization and generalization or when pruning networks at\nthe initialization (Random pruning, Grasp, SNIP, and Synflow). The results\nindicate that the weight norm of network parameters is not enough to explain\nthe process of grokking, but the importance of finding good subnetworks to\ndescribe the transition from memorization to generalization. The implementation\ncode can be accessed via this link:\n\\url{https://github.com/gouki510/Grokking-Tickets}.",
            "author": [
                "Gouki Minegishi",
                "Yusuke Iwasawa",
                "Yutaka Matsuo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19470v1",
                "http://arxiv.org/pdf/2310.19470v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19468v1",
            "title": "Regret-Minimization Algorithms for Multi-Agent Cooperative Learning\n  Systems",
            "updated": "2023-10-30T11:50:31Z",
            "published": "2023-10-30T11:50:31Z",
            "summary": "A Multi-Agent Cooperative Learning (MACL) system is an artificial\nintelligence (AI) system where multiple learning agents work together to\ncomplete a common task. Recent empirical success of MACL systems in various\ndomains (e.g. traffic control, cloud computing, robotics) has sparked active\nresearch into the design and analysis of MACL systems for sequential decision\nmaking problems. One important metric of the learning algorithm for decision\nmaking problems is its regret, i.e. the difference between the highest\nachievable reward and the actual reward that the algorithm gains. The design\nand development of a MACL system with low-regret learning algorithms can create\nhuge economic values. In this thesis, I analyze MACL systems for different\nsequential decision making problems. Concretely, the Chapter 3 and 4\ninvestigate the cooperative multi-agent multi-armed bandit problems, with\nfull-information or bandit feedback, in which multiple learning agents can\nexchange their information through a communication network and the agents can\nonly observe the rewards of the actions they choose. Chapter 5 considers the\ncommunication-regret trade-off for online convex optimization in the\ndistributed setting. Chapter 6 discusses how to form high-productive teams for\nagents based on their unknown but fixed types using adaptive incremental\nmatchings. For the above problems, I present the regret lower bounds for\nfeasible learning algorithms and provide the efficient algorithms to achieve\nthis bound. The regret bounds I present in Chapter 3, 4 and 5 quantify how the\nregret depends on the connectivity of the communication network and the\ncommunication delay, thus giving useful guidance on design of the communication\nprotocol in MACL systems",
            "author": [
                "Jialin Yi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19468v1",
                "http://arxiv.org/pdf/2310.19468v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19464v1",
            "title": "Generative Neural Fields by Mixtures of Neural Implicit Functions",
            "updated": "2023-10-30T11:41:41Z",
            "published": "2023-10-30T11:41:41Z",
            "summary": "We propose a novel approach to learning the generative neural fields\nrepresented by linear combinations of implicit basis networks. Our algorithm\nlearns basis networks in the form of implicit neural representations and their\ncoefficients in a latent space by either conducting meta-learning or adopting\nauto-decoding paradigms. The proposed method easily enlarges the capacity of\ngenerative neural fields by increasing the number of basis networks while\nmaintaining the size of a network for inference to be small through their\nweighted model averaging. Consequently, sampling instances using the model is\nefficient in terms of latency and memory footprint. Moreover, we customize\ndenoising diffusion probabilistic model for a target task to sample latent\nmixture coefficients, which allows our final model to generate unseen data\neffectively. Experiments show that our approach achieves competitive generation\nperformance on diverse benchmarks for images, voxel data, and NeRF scenes\nwithout sophisticated designs for specific modalities and domains.",
            "author": [
                "Tackgeun You",
                "Mijeong Kim",
                "Jungtaek Kim",
                "Bohyung Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19464v1",
                "http://arxiv.org/pdf/2310.19464v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19463v1",
            "title": "Optimize Planning Heuristics to Rank, not to Estimate Cost-to-Goal",
            "updated": "2023-10-30T11:39:49Z",
            "published": "2023-10-30T11:39:49Z",
            "summary": "In imitation learning for planning, parameters of heuristic functions are\noptimized against a set of solved problem instances. This work revisits the\nnecessary and sufficient conditions of strictly optimally efficient heuristics\nfor forward search algorithms, mainly A* and greedy best-first search, which\nexpand only states on the returned optimal path. It then proposes a family of\nloss functions based on ranking tailored for a given variant of the forward\nsearch algorithm. Furthermore, from a learning theory point of view, it\ndiscusses why optimizing cost-to-goal \\hstar\\ is unnecessarily difficult. The\nexperimental comparison on a diverse set of problems unequivocally supports the\nderived theory.",
            "author": [
                "Leah Chrestien",
                "Tom\u00e1s Pevn\u00fd",
                "Stefan Edelkamp",
                "Anton\u00edn Komenda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19463v1",
                "http://arxiv.org/pdf/2310.19463v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19462v2",
            "title": "Constituency Parsing using LLMs",
            "updated": "2023-10-31T07:19:51Z",
            "published": "2023-10-30T11:39:11Z",
            "summary": "Constituency parsing is a fundamental yet unsolved natural language\nprocessing task. In this paper, we explore the potential of recent large\nlanguage models (LLMs) that have exhibited remarkable performance across\nvarious domains and tasks to tackle this task. We employ three linearization\nstrategies to transform output trees into symbol sequences, such that LLMs can\nsolve constituency parsing by generating linearized trees. We conduct\nexperiments using a diverse range of LLMs, including ChatGPT, GPT-4, OPT,\nLLaMA, and Alpaca, comparing their performance against the state-of-the-art\nconstituency parsers. Our experiments encompass zero-shot, few-shot, and\nfull-training learning settings, and we evaluate the models on one in-domain\nand five out-of-domain test datasets. Our findings reveal insights into LLMs'\nperformance, generalization abilities, and challenges in constituency parsing.",
            "author": [
                "Xuefeng Bai",
                "Jialong Wu",
                "Yulong Chen",
                "Zhongqing Wang",
                "Yue Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19462v2",
                "http://arxiv.org/pdf/2310.19462v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19460v1",
            "title": "Denoising Diffusion Probabilistic Models for Hardware-Impaired\n  Communication Systems: Towards Wireless Generative AI",
            "updated": "2023-10-30T11:33:01Z",
            "published": "2023-10-30T11:33:01Z",
            "summary": "Thanks to the outstanding achievements from state-of-the-art generative\nmodels like ChatGPT and diffusion models, generative AI has gained substantial\nattention across various industrial and academic domains. In this paper,\ndenoising diffusion probabilistic models (DDPMs) are proposed for a practical\nfinite-precision wireless communication system with hardware-impaired\ntransceivers. The intuition behind DDPM is to decompose the data generation\nprocess over the so-called \"denoising\" steps. Inspired by this, a DDPM-based\nreceiver is proposed for a practical wireless communication scheme that faces\nrealistic non-idealities, including hardware impairments (HWI), channel\ndistortions, and quantization errors. It is shown that our approach provides\nnetwork resilience under low-SNR regimes, near-invariant reconstruction\nperformance with respect to different HWI levels and quantization errors, and\nrobust out-of-distribution performance against non-Gaussian noise. Moreover,\nthe reconstruction performance of our scheme is evaluated in terms of cosine\nsimilarity and mean-squared error (MSE), highlighting more than 25 dB\nimprovement compared to the conventional deep neural network (DNN)-based\nreceivers.",
            "author": [
                "Mehdi Letafati",
                "Samad Ali",
                "Matti Latva-aho"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19460v1",
                "http://arxiv.org/pdf/2310.19460v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19459v2",
            "title": "Security Challenges for Cloud or Fog Computing-Based AI Applications",
            "updated": "2023-11-03T08:40:42Z",
            "published": "2023-10-30T11:32:50Z",
            "summary": "Security challenges for Cloud or Fog-based machine learning services pose\nseveral concerns. Securing the underlying Cloud or Fog services is essential,\nas successful attacks against these services, on which machine learning\napplications rely, can lead to significant impairments of these applications.\nBecause the requirements for AI applications can also be different, we\ndifferentiate according to whether they are used in the Cloud or in a Fog\nComputing network. This then also results in different threats or attack\npossibilities. For Cloud platforms, the responsibility for security can be\ndivided between different parties. Security deficiencies at a lower level can\nhave a direct impact on the higher level where user data is stored. While\nresponsibilities are simpler for Fog Computing networks, by moving services to\nthe edge of the network, we have to secure them against physical access to the\ndevices. We conclude by outlining specific information security requirements\nfor AI applications.",
            "author": [
                "Amir Pakmehr",
                "Andreas A\u00dfmuth",
                "Christoph P. Neumann",
                "Gerald Pirkl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19459v2",
                "http://arxiv.org/pdf/2310.19459v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19454v1",
            "title": "MMM and MMMSynth: Clustering of heterogeneous tabular data, and\n  synthetic data generation",
            "updated": "2023-10-30T11:26:01Z",
            "published": "2023-10-30T11:26:01Z",
            "summary": "We provide new algorithms for two tasks relating to heterogeneous tabular\ndatasets: clustering, and synthetic data generation. Tabular datasets typically\nconsist of heterogeneous data types (numerical, ordinal, categorical) in\ncolumns, but may also have hidden cluster structure in their rows: for example,\nthey may be drawn from heterogeneous (geographical, socioeconomic,\nmethodological) sources, such that the outcome variable they describe (such as\nthe presence of a disease) may depend not only on the other variables but on\nthe cluster context. Moreover, sharing of biomedical data is often hindered by\npatient confidentiality laws, and there is current interest in algorithms to\ngenerate synthetic tabular data from real data, for example via deep learning.\n  We demonstrate a novel EM-based clustering algorithm, MMM (``Madras Mixture\nModel''), that outperforms standard algorithms in determining clusters in\nsynthetic heterogeneous data, and recovers structure in real data. Based on\nthis, we demonstrate a synthetic tabular data generation algorithm, MMMsynth,\nthat pre-clusters the input data, and generates cluster-wise synthetic data\nassuming cluster-specific data distributions for the input columns. We\nbenchmark this algorithm by testing the performance of standard ML algorithms\nwhen they are trained on synthetic data and tested on real published datasets.\nOur synthetic data generation algorithm outperforms other literature\ntabular-data generators, and approaches the performance of training purely with\nreal data.",
            "author": [
                "Chandrani Kumari",
                "Rahul Siddharthan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19454v1",
                "http://arxiv.org/pdf/2310.19454v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19450v2",
            "title": "Hodge-Compositional Edge Gaussian Processes",
            "updated": "2023-10-31T11:57:06Z",
            "published": "2023-10-30T11:22:25Z",
            "summary": "We propose principled Gaussian processes (GPs) for modeling functions defined\nover the edge set of a simplicial 2-complex, a structure similar to a graph in\nwhich edges may form triangular faces. This approach is intended for learning\nflow-type data on networks where edge flows can be characterized by the\ndiscrete divergence and curl. Drawing upon the Hodge decomposition, we first\ndevelop classes of divergence-free and curl-free edge GPs, suitable for various\napplications. We then combine them to create \\emph{Hodge-compositional edge\nGPs} that are expressive enough to represent any edge function. These GPs\nfacilitate direct and independent learning for the different Hodge components\nof edge functions, enabling us to capture their relevance during hyperparameter\noptimization. To highlight their practical potential, we apply them for flow\ndata inference in currency exchange, ocean flows and water supply networks,\ncomparing them to alternative models.",
            "author": [
                "Maosheng Yang",
                "Viacheslav Borovitskiy",
                "Elvin Isufi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19450v2",
                "http://arxiv.org/pdf/2310.19450v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19449v1",
            "title": "Large-Scale Application of Fault Injection into PyTorch Models -- an\n  Extension to PyTorchFI for Validation Efficiency",
            "updated": "2023-10-30T11:18:35Z",
            "published": "2023-10-30T11:18:35Z",
            "summary": "Transient or permanent faults in hardware can render the output of Neural\nNetworks (NN) incorrect without user-specific traces of the error, i.e. silent\ndata errors (SDE). On the other hand, modern NNs also possess an inherent\nredundancy that can tolerate specific faults. To establish a safety case, it is\nnecessary to distinguish and quantify both types of corruptions. To study the\neffects of hardware (HW) faults on software (SW) in general and NN models in\nparticular, several fault injection (FI) methods have been established in\nrecent years. Current FI methods focus on the methodology of injecting faults\nbut often fall short of accounting for large-scale FI tests, where many fault\nlocations based on a particular fault model need to be analyzed in a short\ntime. Results need to be concise, repeatable, and comparable. To address these\nrequirements and enable fault injection as the default component in a machine\nlearning development cycle, we introduce a novel fault injection framework\ncalled PyTorchALFI (Application Level Fault Injection for PyTorch) based on\nPyTorchFI. PyTorchALFI provides an efficient way to define randomly generated\nand reusable sets of faults to inject into PyTorch models, defines complex test\nscenarios, enhances data sets, and generates test KPIs while tightly coupling\nfault-free, faulty, and modified NN. In this paper, we provide details about\nthe definition of test scenarios, software architecture, and several examples\nof how to use the new framework to apply iterative changes in fault location\nand number, compare different model modifications, and analyze test results.",
            "author": [
                "Ralf Graafe",
                "Qutub Syed Sha",
                "Florian Geissler",
                "Michael Paulitsch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19449v1",
                "http://arxiv.org/pdf/2310.19449v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19445v1",
            "title": "A Federated Learning Framework for Stenosis Detection",
            "updated": "2023-10-30T11:13:40Z",
            "published": "2023-10-30T11:13:40Z",
            "summary": "This study explores the use of Federated Learning (FL) for stenosis detection\nin coronary angiography images (CA). Two heterogeneous datasets from two\ninstitutions were considered: Dataset 1 includes 1219 images from 200 patients,\nwhich we acquired at the Ospedale Riuniti of Ancona (Italy); Dataset 2 includes\n7492 sequential images from 90 patients from a previous study available in the\nliterature. Stenosis detection was performed by using a Faster R-CNN model. In\nour FL framework, only the weights of the model backbone were shared among the\ntwo client institutions, using Federated Averaging (FedAvg) for weight\naggregation. We assessed the performance of stenosis detection using Precision\n(P rec), Recall (Rec), and F1 score (F1). Our results showed that the FL\nframework does not substantially affects clients 2 performance, which already\nachieved good performance with local training; for client 1, instead, FL\nframework increases the performance with respect to local model of +3.76%,\n+17.21% and +10.80%, respectively, reaching P rec = 73.56, Rec = 67.01 and F1 =\n70.13. With such results, we showed that FL may enable multicentric studies\nrelevant to automatic stenosis detection in CA by addressing data heterogeneity\nfrom various institutions, while preserving patient privacy.",
            "author": [
                "Mariachiara Di Cosmo",
                "Giovanna Migliorelli",
                "Matteo Francioni",
                "Andi Mucaj",
                "Alessandro Maolo",
                "Alessandro Aprile",
                "Emanuele Frontoni",
                "Maria Chiara Fiorentino",
                "Sara Moccia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19445v1",
                "http://arxiv.org/pdf/2310.19445v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19444v1",
            "title": "One-for-All: Bridge the Gap Between Heterogeneous Architectures in\n  Knowledge Distillation",
            "updated": "2023-10-30T11:13:02Z",
            "published": "2023-10-30T11:13:02Z",
            "summary": "Knowledge distillation~(KD) has proven to be a highly effective approach for\nenhancing model performance through a teacher-student training scheme. However,\nmost existing distillation methods are designed under the assumption that the\nteacher and student models belong to the same model family, particularly the\nhint-based approaches. By using centered kernel alignment (CKA) to compare the\nlearned features between heterogeneous teacher and student models, we observe\nsignificant feature divergence. This divergence illustrates the ineffectiveness\nof previous hint-based methods in cross-architecture distillation. To tackle\nthe challenge in distilling heterogeneous models, we propose a simple yet\neffective one-for-all KD framework called OFA-KD, which significantly improves\nthe distillation performance between heterogeneous architectures. Specifically,\nwe project intermediate features into an aligned latent space such as the\nlogits space, where architecture-specific information is discarded.\nAdditionally, we introduce an adaptive target enhancement scheme to prevent the\nstudent from being disturbed by irrelevant information. Extensive experiments\nwith various architectures, including CNN, Transformer, and MLP, demonstrate\nthe superiority of our OFA-KD framework in enabling distillation between\nheterogeneous architectures. Specifically, when equipped with our OFA-KD, the\nstudent models achieve notable performance improvements, with a maximum gain of\n8.0% on the CIFAR-100 dataset and 0.7% on the ImageNet-1K dataset. PyTorch code\nand checkpoints can be found at https://github.com/Hao840/OFAKD.",
            "author": [
                "Zhiwei Hao",
                "Jianyuan Guo",
                "Kai Han",
                "Yehui Tang",
                "Han Hu",
                "Yunhe Wang",
                "Chang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19444v1",
                "http://arxiv.org/pdf/2310.19444v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19439v1",
            "title": "Asymmetric Diffusion Based Channel-Adaptive Secure Wireless Semantic\n  Communications",
            "updated": "2023-10-30T11:00:47Z",
            "published": "2023-10-30T11:00:47Z",
            "summary": "Semantic communication has emerged as a new deep learning-based communication\nparadigm that drives the research of end-to-end data transmission in tasks like\nimage classification, and image reconstruction. However, the security problem\ncaused by semantic attacks has not been well explored, resulting in\nvulnerabilities within semantic communication systems exposed to potential\nsemantic perturbations. In this paper, we propose a secure semantic\ncommunication system, DiffuSeC, which leverages the diffusion model and deep\nreinforcement learning (DRL) to address this issue. With the diffusing module\nin the sender end and the asymmetric denoising module in the receiver end, the\nDiffuSeC mitigates the perturbations added by semantic attacks, including data\nsource attacks and channel attacks. To further improve the robustness under\nunstable channel conditions caused by semantic attacks, we developed a\nDRL-based channel-adaptive diffusion step selection scheme to achieve stable\nperformance under fluctuating environments. A timestep synchronization scheme\nis designed for diffusion timestep coordination between the two ends.\nSimulation results demonstrate that the proposed DiffuSeC shows higher robust\naccuracy than previous works under a wide range of channel conditions, and can\nquickly adjust the model state according to signal-to-noise ratios (SNRs) in\nunstable environments.",
            "author": [
                "Xintian Ren",
                "Jun Wu",
                "Hansong Xu",
                "Qianqian Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19439v1",
                "http://arxiv.org/pdf/2310.19439v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19433v1",
            "title": "Ordinal classification for interval-valued data and interval-valued\n  functional data",
            "updated": "2023-10-30T10:45:03Z",
            "published": "2023-10-30T10:45:03Z",
            "summary": "The aim of ordinal classification is to predict the ordered labels of the\noutput from a set of observed inputs. Interval-valued data refers to data in\nthe form of intervals. For the first time, interval-valued data and\ninterval-valued functional data are considered as inputs in an ordinal\nclassification problem. Six ordinal classifiers for interval data and\ninterval-valued functional data are proposed. Three of them are parametric, one\nof them is based on ordinal binary decompositions and the other two are based\non ordered logistic regression. The other three methods are based on the use of\ndistances between interval data and kernels on interval data. One of the\nmethods uses the weighted $k$-nearest-neighbor technique for ordinal\nclassification. Another method considers kernel principal component analysis\nplus an ordinal classifier. And the sixth method, which is the method that\nperforms best, uses a kernel-induced ordinal random forest. They are compared\nwith na\\\"ive approaches in an extensive experimental study with synthetic and\noriginal real data sets, about human global development, and weather data. The\nresults show that considering ordering and interval-valued information improves\nthe accuracy. The source code and data sets are available at\nhttps://github.com/aleixalcacer/OCFIVD.",
            "author": [
                "Aleix Alcacer",
                "Marina Mart\u00ednez-Garcia",
                "Irene Epifanio"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.eswa.2023.122277",
                "http://arxiv.org/abs/2310.19433v1",
                "http://arxiv.org/pdf/2310.19433v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP",
                "stat.ML",
                "62H30, 62R10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19432v1",
            "title": "Explaining the Decisions of Deep Policy Networks for Robotic\n  Manipulations",
            "updated": "2023-10-30T10:44:12Z",
            "published": "2023-10-30T10:44:12Z",
            "summary": "Deep policy networks enable robots to learn behaviors to solve various\nreal-world complex tasks in an end-to-end fashion. However, they lack\ntransparency to provide the reasons of actions. Thus, such a black-box model\noften results in low reliability and disruptive actions during the deployment\nof the robot in practice. To enhance its transparency, it is important to\nexplain robot behaviors by considering the extent to which each input feature\ncontributes to determining a given action. In this paper, we present an\nexplicit analysis of deep policy models through input attribution methods to\nexplain how and to what extent each input feature affects the decisions of the\nrobot policy models. To this end, we present two methods for applying input\nattribution methods to robot policy networks: (1) we measure the importance\nfactor of each joint torque to reflect the influence of the motor torque on the\nend-effector movement, and (2) we modify a relevance propagation method to\nhandle negative inputs and outputs in deep policy networks properly. To the\nbest of our knowledge, this is the first report to identify the dynamic changes\nof input attributions of multi-modal sensor inputs in deep policy networks\nonline for robotic manipulation.",
            "author": [
                "Seongun Kim",
                "Jaesik Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19432v1",
                "http://arxiv.org/pdf/2310.19432v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19430v1",
            "title": "Roadmap on Photovoltaic Absorber Materials for Sustainable Energy\n  Conversion",
            "updated": "2023-10-30T10:43:25Z",
            "published": "2023-10-30T10:43:25Z",
            "summary": "Photovoltaics (PVs) are a critical technology for curbing growing levels of\nanthropogenic greenhouse gas emissions, and meeting increases in future demand\nfor low-carbon electricity. In order to fulfil ambitions for net-zero carbon\ndioxide equivalent (CO<sub>2</sub>eq) emissions worldwide, the global\ncumulative capacity of solar PVs must increase by an order of magnitude from\n0.9 TWp in 2021 to 8.5 TWp by 2050 according to the International Renewable\nEnergy Agency, which is considered to be a highly conservative estimate. In\n2020, the Henry Royce Institute brought together the UK PV community to discuss\nthe critical technological and infrastructure challenges that need to be\novercome to address the vast challenges in accelerating PV deployment. Herein,\nwe examine the key developments in the global community, especially the\nprogress made in the field since this earlier roadmap, bringing together\nexperts primarily from the UK across the breadth of the photovoltaics\ncommunity. The focus is both on the challenges in improving the efficiency,\nstability and levelized cost of electricity of current technologies for\nutility-scale PVs, as well as the fundamental questions in novel technologies\nthat can have a significant impact on emerging markets, such as indoor PVs,\nspace PVs, and agrivoltaics. We discuss challenges in advanced metrology and\ncomputational tools, as well as the growing synergies between PVs and solar\nfuels, and offer a perspective on the environmental sustainability of the PV\nindustry. Through this roadmap, we emphasize promising pathways forward in both\nthe short- and long-term, and for communities working on technologies across a\nrange of maturity levels to learn from each other.",
            "author": [
                "James C. Blakesley",
                "Ruy S. Bonilla",
                "Marina Freitag",
                "Alex M. Ganose",
                "Nicola Gasparini",
                "Pascal Kaienburg",
                "George Koutsourakis",
                "Jonathan D. Major",
                "Jenny Nelson",
                "Nakita K. Noel",
                "Bart Roose",
                "Jae Sung Yun",
                "Simon Aliwell",
                "Pietro P. Altermatt",
                "Tayebeh Ameri",
                "Virgil Andrei",
                "Ardalan Armin",
                "Diego Bagnis",
                "Jenny Baker",
                "Hamish Beath",
                "Mathieu Bellanger",
                "Philippe Berrouard",
                "Jochen Blumberger",
                "Stuart A. Boden",
                "Hugo Bronstein",
                "Matthew J. Carnie",
                "Chris Case",
                "Fernando A. Castro",
                "Yi-Ming Chang",
                "Elmer Chao",
                "Tracey M. Clarke",
                "Graeme Cooke",
                "Pablo Docampo",
                "Ken Durose",
                "James R. Durrant",
                "Marina R. Filip",
                "Richard H. Friend",
                "Jarvist M. Frost",
                "Elizabeth A. Gibson",
                "Alexander J. Gillett",
                "Pooja Goddard",
                "Severin N. Habisreutinger",
                "Martin Heeney",
                "Arthur D. Hendsbee",
                "Louise C. Hirst",
                "M. Saiful Islam",
                "K. D. G. Imalka Jayawardena",
                "Michael B. Johnston",
                "Matthias Kauer",
                "Jeff Kettle",
                "Ji-Seon Kim",
                "Dan Lamb",
                "David Lidzey",
                "Jihoo Lim",
                "Roderick MacKenzie",
                "Nigel Mason",
                "Iain McCulloch",
                "Keith P. McKenna",
                "Sebastian B. Meier",
                "Paul Meredith",
                "Graham Morse",
                "John D. Murphy",
                "Chris Nicklin",
                "Paloma Ortega-Arriaga",
                "Thomas Osterberg",
                "Jay B. Patel",
                "Anthony Peaker",
                "Moritz Riede",
                "Martyn Rush",
                "James W. Ryan",
                "David O. Scanlon",
                "Peter J. Skabara",
                "Franky So",
                "Henry J. Snaith",
                "Ludmilla Steier",
                "Jarla Thiesbrummel",
                "Alessandro Troisi",
                "Craig Underwood",
                "Karsten Walzer",
                "Trystan Watson",
                "J. Michael Walls",
                "Aron Walsh",
                "Lucy D. Whalley",
                "Benedict Winchester",
                "Samuel D. Stranks",
                "Robert L. Z. Hoye"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19430v1",
                "http://arxiv.org/pdf/2310.19430v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19427v1",
            "title": "Refining Diffusion Planner for Reliable Behavior Synthesis by Automatic\n  Detection of Infeasible Plans",
            "updated": "2023-10-30T10:35:42Z",
            "published": "2023-10-30T10:35:42Z",
            "summary": "Diffusion-based planning has shown promising results in long-horizon,\nsparse-reward tasks by training trajectory diffusion models and conditioning\nthe sampled trajectories using auxiliary guidance functions. However, due to\ntheir nature as generative models, diffusion models are not guaranteed to\ngenerate feasible plans, resulting in failed execution and precluding planners\nfrom being useful in safety-critical applications. In this work, we propose a\nnovel approach to refine unreliable plans generated by diffusion models by\nproviding refining guidance to error-prone plans. To this end, we suggest a new\nmetric named restoration gap for evaluating the quality of individual plans\ngenerated by the diffusion model. A restoration gap is estimated by a gap\npredictor which produces restoration gap guidance to refine a diffusion\nplanner. We additionally present an attribution map regularizer to prevent\nadversarial refining guidance that could be generated from the sub-optimal gap\npredictor, which enables further refinement of infeasible plans. We demonstrate\nthe effectiveness of our approach on three different benchmarks in offline\ncontrol settings that require long-horizon planning. We also illustrate that\nour approach presents explainability by presenting the attribution maps of the\ngap predictor and highlighting error-prone transitions, allowing for a deeper\nunderstanding of the generated plans.",
            "author": [
                "Kyowoon Lee",
                "Seongun Kim",
                "Jaesik Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19427v1",
                "http://arxiv.org/pdf/2310.19427v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19424v1",
            "title": "Variational Curriculum Reinforcement Learning for Unsupervised Discovery\n  of Skills",
            "updated": "2023-10-30T10:34:25Z",
            "published": "2023-10-30T10:34:25Z",
            "summary": "Mutual information-based reinforcement learning (RL) has been proposed as a\npromising framework for retrieving complex skills autonomously without a\ntask-oriented reward function through mutual information (MI) maximization or\nvariational empowerment. However, learning complex skills is still challenging,\ndue to the fact that the order of training skills can largely affect sample\nefficiency. Inspired by this, we recast variational empowerment as curriculum\nlearning in goal-conditioned RL with an intrinsic reward function, which we\nname Variational Curriculum RL (VCRL). From this perspective, we propose a\nnovel approach to unsupervised skill discovery based on information theory,\ncalled Value Uncertainty Variational Curriculum (VUVC). We prove that, under\nregularity conditions, VUVC accelerates the increase of entropy in the visited\nstates compared to the uniform curriculum. We validate the effectiveness of our\napproach on complex navigation and robotic manipulation tasks in terms of\nsample efficiency and state coverage speed. We also demonstrate that the skills\ndiscovered by our method successfully complete a real-world robot navigation\ntask in a zero-shot setup and that incorporating these skills with a global\nplanner further increases the performance.",
            "author": [
                "Seongun Kim",
                "Kyowoon Lee",
                "Jaesik Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19424v1",
                "http://arxiv.org/pdf/2310.19424v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19420v1",
            "title": "Mean BERTs make erratic language teachers: the effectiveness of latent\n  bootstrapping in low-resource settings",
            "updated": "2023-10-30T10:31:32Z",
            "published": "2023-10-30T10:31:32Z",
            "summary": "This paper explores the use of latent bootstrapping, an alternative\nself-supervision technique, for pretraining language models. Unlike the typical\npractice of using self-supervision on discrete subwords, latent bootstrapping\nleverages contextualized embeddings for a richer supervision signal. We conduct\nexperiments to assess how effective this approach is for acquiring linguistic\nknowledge from limited resources. Specifically, our experiments are based on\nthe BabyLM shared task, which includes pretraining on two small curated corpora\nand an evaluation on four linguistic benchmarks.",
            "author": [
                "David Samuel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19420v1",
                "http://arxiv.org/pdf/2310.19420v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19418v1",
            "title": "GaitFormer: Learning Gait Representations with Noisy Multi-Task Learning",
            "updated": "2023-10-30T10:28:44Z",
            "published": "2023-10-30T10:28:44Z",
            "summary": "Gait analysis is proven to be a reliable way to perform person identification\nwithout relying on subject cooperation. Walking is a biometric that does not\nsignificantly change in short periods of time and can be regarded as unique to\neach person. So far, the study of gait analysis focused mostly on\nidentification and demographics estimation, without considering many of the\npedestrian attributes that appearance-based methods rely on. In this work,\nalongside gait-based person identification, we explore pedestrian attribute\nidentification solely from movement patterns. We propose DenseGait, the largest\ndataset for pretraining gait analysis systems containing 217K anonymized\ntracklets, annotated automatically with 42 appearance attributes. DenseGait is\nconstructed by automatically processing video streams and offers the full array\nof gait covariates present in the real world. We make the dataset available to\nthe research community. Additionally, we propose GaitFormer, a\ntransformer-based model that after pretraining in a multi-task fashion on\nDenseGait, achieves 92.5% accuracy on CASIA-B and 85.33% on FVG, without\nutilizing any manually annotated data. This corresponds to a +14.2% and +9.67%\naccuracy increase compared to similar methods. Moreover, GaitFormer is able to\naccurately identify gender information and a multitude of appearance attributes\nutilizing only movement patterns. The code to reproduce the experiments is made\npublicly.",
            "author": [
                "Adrian Cosma",
                "Emilian Radoi"
            ],
            "link": [
                "http://dx.doi.org/10.3390/s22186803",
                "http://arxiv.org/abs/2310.19418v1",
                "http://arxiv.org/pdf/2310.19418v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19416v1",
            "title": "Machine learning on quantum experimental data toward solving quantum\n  many-body problems",
            "updated": "2023-10-30T10:25:59Z",
            "published": "2023-10-30T10:25:59Z",
            "summary": "Advancements in the implementation of quantum hardware have enabled the\nacquisition of data that are intractable for emulation with classical\ncomputers. The integration of classical machine learning (ML) algorithms with\nthese data holds potential for unveiling obscure patterns. Although this hybrid\napproach extends the class of efficiently solvable problems compared to using\nonly classical computers, this approach has been realized for solving\nrestricted problems because of the prevalence of noise in current quantum\ncomputers. Here, we extend the applicability of the hybrid approach to problems\nof interest in many-body physics, such as predicting the properties of the\nground state of a given Hamiltonian and classifying quantum phases. By\nperforming experiments with various error-reducing procedures on\nsuperconducting quantum hardware with 127 qubits, we managed to acquire refined\ndata from the quantum computer. This enabled us to demonstrate the successful\nimplementation of classical ML algorithms for systems with up to 44 qubits. Our\nresults verify the scalability and effectiveness of the classical ML algorithms\nfor processing quantum experimental data.",
            "author": [
                "Gyungmin Cho",
                "Dohun Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19416v1",
                "http://arxiv.org/pdf/2310.19416v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19411v1",
            "title": "Intelligent Breast Cancer Diagnosis with Heuristic-assisted\n  Trans-Res-U-Net and Multiscale DenseNet using Mammogram Images",
            "updated": "2023-10-30T10:22:14Z",
            "published": "2023-10-30T10:22:14Z",
            "summary": "Breast cancer (BC) significantly contributes to cancer-related mortality in\nwomen, underscoring the criticality of early detection for optimal patient\noutcomes. A mammography is a key tool for identifying and diagnosing breast\nabnormalities; however, accurately distinguishing malignant mass lesions\nremains challenging. To address this issue, we propose a novel deep learning\napproach for BC screening utilizing mammography images. Our proposed model\ncomprises three distinct stages: data collection from established benchmark\nsources, image segmentation employing an Atrous Convolution-based Attentive and\nAdaptive Trans-Res-UNet (ACA-ATRUNet) architecture, and BC identification via\nan Atrous Convolution-based Attentive and Adaptive Multi-scale DenseNet\n(ACA-AMDN) model. The hyperparameters within the ACA-ATRUNet and ACA-AMDN\nmodels are optimised using the Modified Mussel Length-based Eurasian\nOystercatcher Optimization (MML-EOO) algorithm. Performance evaluation,\nleveraging multiple metrics, is conducted, and a comparative analysis against\nconventional methods is presented. Our experimental findings reveal that the\nproposed BC detection framework attains superior precision rates in early\ndisease detection, demonstrating its potential to enhance mammography-based\nscreening methodologies.",
            "author": [
                "Muhammad Yaqub",
                "Feng Jinchao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19411v1",
                "http://arxiv.org/pdf/2310.19411v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19410v1",
            "title": "Generated Distributions Are All You Need for Membership Inference\n  Attacks Against Generative Models",
            "updated": "2023-10-30T10:21:26Z",
            "published": "2023-10-30T10:21:26Z",
            "summary": "Generative models have demonstrated revolutionary success in various visual\ncreation tasks, but in the meantime, they have been exposed to the threat of\nleaking private information of their training data. Several membership\ninference attacks (MIAs) have been proposed to exhibit the privacy\nvulnerability of generative models by classifying a query image as a training\ndataset member or nonmember. However, these attacks suffer from major\nlimitations, such as requiring shadow models and white-box access, and either\nignoring or only focusing on the unique property of diffusion models, which\nblock their generalization to multiple generative models. In contrast, we\npropose the first generalized membership inference attack against a variety of\ngenerative models such as generative adversarial networks, [variational]\nautoencoders, implicit functions, and the emerging diffusion models. We\nleverage only generated distributions from target generators and auxiliary\nnon-member datasets, therefore regarding target generators as black boxes and\nagnostic to their architectures or application scenarios. Experiments validate\nthat all the generative models are vulnerable to our attack. For instance, our\nwork achieves attack AUC $>0.99$ against DDPM, DDIM, and FastDPM trained on\nCIFAR-10 and CelebA. And the attack against VQGAN, LDM (for the\ntext-conditional generation), and LIIF achieves AUC $>0.90.$ As a result, we\nappeal to our community to be aware of such privacy leakage risks when\ndesigning and publishing generative models.",
            "author": [
                "Minxing Zhang",
                "Ning Yu",
                "Rui Wen",
                "Michael Backes",
                "Yang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19410v1",
                "http://arxiv.org/pdf/2310.19410v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19407v1",
            "title": "Resource Constrained Semantic Segmentation for Waste Sorting",
            "updated": "2023-10-30T10:19:40Z",
            "published": "2023-10-30T10:19:40Z",
            "summary": "This work addresses the need for efficient waste sorting strategies in\nMaterials Recovery Facilities to minimize the environmental impact of rising\nwaste. We propose resource-constrained semantic segmentation models for\nsegmenting recyclable waste in industrial settings. Our goal is to develop\nmodels that fit within a 10MB memory constraint, suitable for edge applications\nwith limited processing capacity. We perform the experiments on three networks:\nICNet, BiSeNet (Xception39 backbone), and ENet. Given the aforementioned\nlimitation, we implement quantization and pruning techniques on the broader\nnets, achieving positive results while marginally impacting the Mean IoU\nmetric. Furthermore, we propose a combination of Focal and Lov\\'asz loss that\naddresses the implicit class imbalance resulting in better performance compared\nwith the Cross-entropy loss function.",
            "author": [
                "Elisa Cascina",
                "Andrea Pellegrino",
                "Lorenzo Tozzi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19407v1",
                "http://arxiv.org/pdf/2310.19407v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19406v2",
            "title": "Discovering Black Hole Mass Scaling Relations with Symbolic Regression",
            "updated": "2023-11-20T10:33:36Z",
            "published": "2023-10-30T10:19:38Z",
            "summary": "Our knowledge of supermassive black holes (SMBHs) and their relation to their\nhost galaxies is still limited, and there are only around 150 SMBHs that have\ntheir masses directly measured and confirmed. Better black hole mass scaling\nrelations will help us reveal the physics of black holes, as well as predict\nblack hole masses that are not yet measured. Here, we apply symbolic\nregression, combined with random forest to those directly-measured black hole\nmasses and host galaxy properties, and find a collection of higher-dimensional\n(N-D) black hole mass scaling relations. These N-D black hole mass scaling\nrelations have scatter smaller than any of the existing black hole mass scaling\nrelations. One of the best among them involves the parameters of central\nstellar velocity dispersion, bulge-to-total ratio, and density at the black\nhole's sphere-of-influence with an intrinsic scatter of $\\epsilon=0.083\\,\\\n\\text{dex}$, significantly lower than $\\epsilon \\sim 0.3\\,\\ \\text{dex}$ for the\nM-$\\sigma$ relation. These relations will inspire black hole physics, test\nblack hole models implemented in simulations, and estimate unknown black hole\nmasses on an unprecedented precision.",
            "author": [
                "Zehao Jin",
                "Benjamin L. Davis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19406v2",
                "http://arxiv.org/pdf/2310.19406v2"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06284v1",
            "title": "Efficient Generation of Multimodal Fluid Simulation Data",
            "updated": "2023-10-30T10:05:11Z",
            "published": "2023-10-30T10:05:11Z",
            "summary": "Applying the representational power of machine learning to the prediction of\ncomplex fluid dynamics has been a relevant subject of study for years. However,\nthe amount of available fluid simulation data does not match the notoriously\nhigh requirements of machine learning methods. Researchers have typically\naddressed this issue by generating their own datasets, preventing a consistent\nevaluation of their proposed approaches. Our work introduces a generation\nprocedure for synthetic multi-modal fluid simulations datasets. By leveraging a\nGPU implementation, our procedure is also efficient enough that no data needs\nto be exchanged between users, except for configuration files required to\nreproduce the dataset. Furthermore, our procedure allows multiple modalities\n(generating both geometry and photorealistic renderings) and is general enough\nfor it to be applied to various tasks in data-driven fluid simulation. We then\nemploy our framework to generate a set of thoughtfully designed benchmark\ndatasets, which attempt to span specific fluid simulation scenarios in a\nmeaningful way. The properties of our contributions are demonstrated by\nevaluating recently published algorithms for the neural fluid simulation and\nfluid inverse rendering tasks using our benchmark datasets. Our contribution\naims to fulfill the community's need for standardized benchmarks, fostering\nresearch that is more reproducible and robust than previous endeavors.",
            "author": [
                "Daniele Baieri",
                "Donato Crisostomi",
                "Stefano Esposito",
                "Filippo Maggioli",
                "Emanuele Rodol\u00e0"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06284v1",
                "http://arxiv.org/pdf/2311.06284v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cs.GR",
                "physics.flu-dyn",
                "68U20",
                "I.2.6; I.3; I.6.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19394v1",
            "title": "LightSAGE: Graph Neural Networks for Large Scale Item Retrieval in\n  Shopee's Advertisement Recommendation",
            "updated": "2023-10-30T09:57:06Z",
            "published": "2023-10-30T09:57:06Z",
            "summary": "Graph Neural Network (GNN) is the trending solution for item retrieval in\nrecommendation problems. Most recent reports, however, focus heavily on new\nmodel architectures. This may bring some gaps when applying GNN in the\nindustrial setup, where, besides the model, constructing the graph and handling\ndata sparsity also play critical roles in the overall success of the project.\nIn this work, we report how GNN is applied for large-scale e-commerce item\nretrieval at Shopee. We introduce our simple yet novel and impactful techniques\nin graph construction, modeling, and handling data skewness. Specifically, we\nconstruct high-quality item graphs by combining strong-signal user behaviors\nwith high-precision collaborative filtering (CF) algorithm. We then develop a\nnew GNN architecture named LightSAGE to produce high-quality items' embeddings\nfor vector search. Finally, we design multiple strategies to handle cold-start\nand long-tail items, which are critical in an advertisement (ads) system. Our\nmodels bring improvement in offline evaluations, online A/B tests, and are\ndeployed to the main traffic of Shopee's Recommendation Advertisement system.",
            "author": [
                "Dang Minh Nguyen",
                "Chenfei Wang",
                "Yan Shen",
                "Yifan Zeng"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3604915.3608863",
                "http://arxiv.org/abs/2310.19394v1",
                "http://arxiv.org/pdf/2310.19394v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG",
                "H.3.3; I.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19392v1",
            "title": "A Clinical Guideline Driven Automated Linear Feature Extraction for\n  Vestibular Schwannoma",
            "updated": "2023-10-30T09:54:24Z",
            "published": "2023-10-30T09:54:24Z",
            "summary": "Vestibular Schwannoma is a benign brain tumour that grows from one of the\nbalance nerves. Patients may be treated by surgery, radiosurgery or with a\nconservative \"wait-and-scan\" strategy. Clinicians typically use manually\nextracted linear measurements to aid clinical decision making. This work aims\nto automate and improve this process by using deep learning based segmentation\nto extract relevant clinical features through computational algorithms. To the\nbest of our knowledge, our study is the first to propose an automated approach\nto replicate local clinical guidelines. Our deep learning based segmentation\nprovided Dice-scores of 0.8124 +- 0.2343 and 0.8969 +- 0.0521 for extrameatal\nand whole tumour regions respectively for T2 weighted MRI, whereas 0.8222 +-\n0.2108 and 0.9049 +- 0.0646 were obtained for T1 weighted MRI. We propose a\nnovel algorithm to choose and extract the most appropriate maximum linear\nmeasurement from the segmented regions based on the size of the extrameatal\nportion of the tumour. Using this tool, clinicians will be provided with a\nvisual guide and related metrics relating to tumour progression that will\nfunction as a clinical decision aid. In this study, we utilize 187 scans\nobtained from 50 patients referred to a tertiary specialist neurosurgical\nservice in the United Kingdom. The measurements extracted manually by an expert\nneuroradiologist indicated a significant correlation with the automated\nmeasurements (p < 0.0001).",
            "author": [
                "Navodini Wijethilake",
                "Steve Connor",
                "Anna Oviedova",
                "Rebecca Burger",
                "Tom Vercauteren",
                "Jonathan Shapey"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19392v1",
                "http://arxiv.org/pdf/2310.19392v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19391v1",
            "title": "Causal Fair Metric: Bridging Causality, Individual Fairness, and\n  Adversarial Robustness",
            "updated": "2023-10-30T09:53:42Z",
            "published": "2023-10-30T09:53:42Z",
            "summary": "Adversarial perturbation is used to expose vulnerabilities in machine\nlearning models, while the concept of individual fairness aims to ensure\nequitable treatment regardless of sensitive attributes. Despite their initial\ndifferences, both concepts rely on metrics to generate similar input data\ninstances. These metrics should be designed to align with the data's\ncharacteristics, especially when it is derived from causal structure and should\nreflect counterfactuals proximity. Previous attempts to define such metrics\noften lack general assumptions about data or structural causal models. In this\nresearch, we introduce a causal fair metric formulated based on causal\nstructures that encompass sensitive attributes. For robustness analysis, the\nconcept of protected causal perturbation is presented. Additionally, we delve\ninto metric learning, proposing a method for metric estimation and deployment\nin real-world problems. The introduced metric has applications in the fields\nadversarial training, fair learning, algorithmic recourse, and causal\nreinforcement learning.",
            "author": [
                "Ahmad-Reza Ehyaei",
                "Golnoosh Farnadi",
                "Samira Samadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19391v1",
                "http://arxiv.org/pdf/2310.19391v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19390v1",
            "title": "Implicit Manifold Gaussian Process Regression",
            "updated": "2023-10-30T09:52:48Z",
            "published": "2023-10-30T09:52:48Z",
            "summary": "Gaussian process regression is widely used because of its ability to provide\nwell-calibrated uncertainty estimates and handle small or sparse datasets.\nHowever, it struggles with high-dimensional data. One possible way to scale\nthis technique to higher dimensions is to leverage the implicit low-dimensional\nmanifold upon which the data actually lies, as postulated by the manifold\nhypothesis. Prior work ordinarily requires the manifold structure to be\nexplicitly provided though, i.e. given by a mesh or be known to be one of the\nwell-known manifolds like the sphere. In contrast, in this paper we propose a\nGaussian process regression technique capable of inferring implicit structure\ndirectly from data (labeled and unlabeled) in a fully differentiable way. For\nthe resulting model, we discuss its convergence to the Mat\\'ern Gaussian\nprocess on the assumed manifold. Our technique scales up to hundreds of\nthousands of data points, and may improve the predictive performance and\ncalibration of the standard Gaussian process regression in\nhigh-dimensional~settings.",
            "author": [
                "Bernardo Fichera",
                "Viacheslav Borovitskiy",
                "Andreas Krause",
                "Aude Billard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19390v1",
                "http://arxiv.org/pdf/2310.19390v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19385v2",
            "title": "Gradient-free online learning of subgrid-scale dynamics with neural\n  emulators",
            "updated": "2023-11-02T10:44:56Z",
            "published": "2023-10-30T09:46:35Z",
            "summary": "In this paper, we propose a generic algorithm to train machine learning-based\nsubgrid parametrizations online, i.e., with $\\textit{a posteriori}$ loss\nfunctions for non-differentiable numerical solvers. The proposed approach\nleverage neural emulators to train an approximation of the reduced state-space\nsolver, which is then used to allows gradient propagation through temporal\nintegration steps. The algorithm is able to recover most of the benefit of\nonline strategies without having to compute the gradient of the original\nsolver. It is demonstrated that training the neural emulator and\nparametrization components separately with respective loss quantities is\nnecessary in order to minimize the propagation of some approximation bias.",
            "author": [
                "Hugo Frezat",
                "Ronan Fablet",
                "Guillaume Balarac",
                "Julien Le Sommer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19385v2",
                "http://arxiv.org/pdf/2310.19385v2"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cs.LG",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19384v1",
            "title": "Deep anytime-valid hypothesis testing",
            "updated": "2023-10-30T09:46:19Z",
            "published": "2023-10-30T09:46:19Z",
            "summary": "We propose a general framework for constructing powerful, sequential\nhypothesis tests for a large class of nonparametric testing problems. The null\nhypothesis for these problems is defined in an abstract form using the action\nof two known operators on the data distribution. This abstraction allows for a\nunified treatment of several classical tasks, such as two-sample testing,\nindependence testing, and conditional-independence testing, as well as modern\nproblems, such as testing for adversarial robustness of machine learning (ML)\nmodels. Our proposed framework has the following advantages over classical\nbatch tests: 1) it continuously monitors online data streams and efficiently\naggregates evidence against the null, 2) it provides tight control over the\ntype I error without the need for multiple testing correction, 3) it adapts the\nsample size requirement to the unknown hardness of the problem. We develop a\nprincipled approach of leveraging the representation capability of ML models\nwithin the testing-by-betting framework, a game-theoretic approach for\ndesigning sequential tests. Empirical results on synthetic and real-world\ndatasets demonstrate that tests instantiated using our general framework are\ncompetitive against specialized baselines on several tasks.",
            "author": [
                "Teodora Pandeva",
                "Patrick Forr\u00e9",
                "Aaditya Ramdas",
                "Shubhanshu Shekhar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19384v1",
                "http://arxiv.org/pdf/2310.19384v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19381v1",
            "title": "Protecting Publicly Available Data With Machine Learning Shortcuts",
            "updated": "2023-10-30T09:38:03Z",
            "published": "2023-10-30T09:38:03Z",
            "summary": "Machine-learning (ML) shortcuts or spurious correlations are artifacts in\ndatasets that lead to very good training and test performance but severely\nlimit the model's generalization capability. Such shortcuts are insidious\nbecause they go unnoticed due to good in-domain test performance. In this\npaper, we explore the influence of different shortcuts and show that even\nsimple shortcuts are difficult to detect by explainable AI methods. We then\nexploit this fact and design an approach to defend online databases against\ncrawlers: providers such as dating platforms, clothing manufacturers, or used\ncar dealers have to deal with a professionalized crawling industry that grabs\nand resells data points on a large scale. We show that a deterrent can be\ncreated by deliberately adding ML shortcuts. Such augmented datasets are then\nunusable for ML use cases, which deters crawlers and the unauthorized use of\ndata from the internet. Using real-world data from three use cases, we show\nthat the proposed approach renders such collected data unusable, while the\nshortcut is at the same time difficult to notice in human perception. Thus, our\nproposed approach can serve as a proactive protection against illegitimate data\ncrawling.",
            "author": [
                "Nicolas M. M\u00fcller",
                "Maximilian Burgert",
                "Pascal Debus",
                "Jennifer Williams",
                "Philip Sperl",
                "Konstantin B\u00f6ttinger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19381v1",
                "http://arxiv.org/pdf/2310.19381v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19380v2",
            "title": "TransXNet: Learning Both Global and Local Dynamics with a Dual Dynamic\n  Token Mixer for Visual Recognition",
            "updated": "2023-11-30T01:48:03Z",
            "published": "2023-10-30T09:35:56Z",
            "summary": "Recent studies have integrated convolution into transformers to introduce\ninductive bias and improve generalization performance. However, the static\nnature of conventional convolution prevents it from dynamically adapting to\ninput variations, resulting in a representation discrepancy between convolution\nand self-attention as self-attention calculates attention matrices dynamically.\nFurthermore, when stacking token mixers that consist of convolution and\nself-attention to form a deep network, the static nature of convolution hinders\nthe fusion of features previously generated by self-attention into convolution\nkernels. These two limitations result in a sub-optimal representation capacity\nof the constructed networks. To find a solution, we propose a lightweight Dual\nDynamic Token Mixer (D-Mixer) that aggregates global information and local\ndetails in an input-dependent way. D-Mixer works by applying an efficient\nglobal attention module and an input-dependent depthwise convolution separately\non evenly split feature segments, endowing the network with strong inductive\nbias and an enlarged effective receptive field. We use D-Mixer as the basic\nbuilding block to design TransXNet, a novel hybrid CNN-Transformer vision\nbackbone network that delivers compelling performance. In the ImageNet-1K image\nclassification task, TransXNet-T surpasses Swin-T by 0.3% in top-1 accuracy\nwhile requiring less than half of the computational cost. Furthermore,\nTransXNet-S and TransXNet-B exhibit excellent model scalability, achieving\ntop-1 accuracy of 83.8% and 84.6% respectively, with reasonable computational\ncosts. Additionally, our proposed network architecture demonstrates strong\ngeneralization capabilities in various dense prediction tasks, outperforming\nother state-of-the-art networks while having lower computational costs. Code is\navailable at https://github.com/LMMMEng/TransXNet.",
            "author": [
                "Meng Lou",
                "Hong-Yu Zhou",
                "Sibei Yang",
                "Yizhou Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19380v2",
                "http://arxiv.org/pdf/2310.19380v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19374v1",
            "title": "Measuring arrangement and size distributions of flowing droplets in\n  microchannels through deep learning",
            "updated": "2023-10-30T09:29:39Z",
            "published": "2023-10-30T09:29:39Z",
            "summary": "In microfluidic systems, droplets undergo intricate deformations as they\ntraverse flow-focusing junctions, posing a challenging task for accurate\nmeasurement, especially during short transit times. This study investigates the\nphysical behavior of droplets within dense emulsions in diverse microchannel\ngeometries, specifically focusing on the impact of varying opening angles\nwithin the primary channel and injection rates of fluid components. Employing a\nsophisticated droplet tracking tool based on deep-learning techniques, we\nanalyze multiple frames from flow-focusing experiments to quantitatively\ncharacterize droplet deformation in terms of ratio between maximum width and\nheight and propensity to form liquid with hexagonal crystalline order. Our\nfindings reveal the existence of an optimal opening angle where shape\ndeformations are minimal and crystal-like arrangement is maximal. Variations of\nfluid injection rates are also found to affect size and packing fraction of the\nemulsion in the exit channel. This paper offers insights into deformations,\nsize and structure of fluid emulsions relative to microchannel geometry and\nother flow-related parameters captured through machine learning, with potential\nimplications for the design of microchips utilized in cellular transport and\ntissue engineering applications.",
            "author": [
                "Mihir Durve",
                "Sibilla Orsini",
                "Adriano Tiribocchi",
                "Andrea Montessori",
                "Jean-Michel Tucny",
                "Marco Lauricella",
                "Andrea Camposeo",
                "Dario Pisignano",
                "Sauro Succi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19374v1",
                "http://arxiv.org/pdf/2310.19374v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19368v1",
            "title": "Color Equivariant Convolutional Networks",
            "updated": "2023-10-30T09:18:49Z",
            "published": "2023-10-30T09:18:49Z",
            "summary": "Color is a crucial visual cue readily exploited by Convolutional Neural\nNetworks (CNNs) for object recognition. However, CNNs struggle if there is data\nimbalance between color variations introduced by accidental recording\nconditions. Color invariance addresses this issue but does so at the cost of\nremoving all color information, which sacrifices discriminative power. In this\npaper, we propose Color Equivariant Convolutions (CEConvs), a novel deep\nlearning building block that enables shape feature sharing across the color\nspectrum while retaining important color information. We extend the notion of\nequivariance from geometric to photometric transformations by incorporating\nparameter sharing over hue-shifts in a neural network. We demonstrate the\nbenefits of CEConvs in terms of downstream performance to various tasks and\nimproved robustness to color changes, including train-test distribution shifts.\nOur approach can be seamlessly integrated into existing architectures, such as\nResNets, and offers a promising solution for addressing color-based domain\nshifts in CNNs.",
            "author": [
                "Attila Lengyel",
                "Ombretta Strafforello",
                "Robert-Jan Bruintjes",
                "Alexander Gielisse",
                "Jan van Gemert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19368v1",
                "http://arxiv.org/pdf/2310.19368v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19360v1",
            "title": "Balance, Imbalance, and Rebalance: Understanding Robust Overfitting from\n  a Minimax Game Perspective",
            "updated": "2023-10-30T09:00:11Z",
            "published": "2023-10-30T09:00:11Z",
            "summary": "Adversarial Training (AT) has become arguably the state-of-the-art algorithm\nfor extracting robust features. However, researchers recently notice that AT\nsuffers from severe robust overfitting problems, particularly after learning\nrate (LR) decay. In this paper, we explain this phenomenon by viewing\nadversarial training as a dynamic minimax game between the model trainer and\nthe attacker. Specifically, we analyze how LR decay breaks the balance between\nthe minimax game by empowering the trainer with a stronger memorization\nability, and show such imbalance induces robust overfitting as a result of\nmemorizing non-robust features. We validate this understanding with extensive\nexperiments, and provide a holistic view of robust overfitting from the\ndynamics of both the two game players. This understanding further inspires us\nto alleviate robust overfitting by rebalancing the two players by either\nregularizing the trainer's capacity or improving the attack strength.\nExperiments show that the proposed ReBalanced Adversarial Training (ReBAT) can\nattain good robustness and does not suffer from robust overfitting even after\nvery long training. Code is available at https://github.com/PKU-ML/ReBAT.",
            "author": [
                "Yifei Wang",
                "Liangchen Li",
                "Jiansheng Yang",
                "Zhouchen Lin",
                "Yisen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19360v1",
                "http://arxiv.org/pdf/2310.19360v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19845v1",
            "title": "Modified Genetic Algorithm for Feature Selection and Hyper Parameter\n  Optimization: Case of XGBoost in Spam Prediction",
            "updated": "2023-10-30T09:00:05Z",
            "published": "2023-10-30T09:00:05Z",
            "summary": "Recently, spam on online social networks has attracted attention in the\nresearch and business world. Twitter has become the preferred medium to spread\nspam content. Many research efforts attempted to encounter social networks\nspam. Twitter brought extra challenges represented by the feature space size,\nand imbalanced data distributions. Usually, the related research works focus on\npart of these main challenges or produce black-box models. In this paper, we\npropose a modified genetic algorithm for simultaneous dimensionality reduction\nand hyper parameter optimization over imbalanced datasets. The algorithm\ninitialized an eXtreme Gradient Boosting classifier and reduced the features\nspace of tweets dataset; to generate a spam prediction model. The model is\nvalidated using a 50 times repeated 10-fold stratified cross-validation, and\nanalyzed using nonparametric statistical tests. The resulted prediction model\nattains on average 82.32\\% and 92.67\\% in terms of geometric mean and accuracy\nrespectively, utilizing less than 10\\% of the total feature space. The\nempirical results show that the modified genetic algorithm outperforms $Chi^2$\nand $PCA$ feature selection methods. In addition, eXtreme Gradient Boosting\noutperforms many machine learning algorithms, including BERT-based deep\nlearning model, in spam prediction. Furthermore, the proposed approach is\napplied to SMS spam modeling and compared to related works.",
            "author": [
                "Nazeeh Ghatasheh",
                "Ismail Altaharwa",
                "Khaled Aldebei"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ACCESS.2022.3196905",
                "http://arxiv.org/abs/2310.19845v1",
                "http://arxiv.org/pdf/2310.19845v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.NE",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19359v1",
            "title": "Introducing instance label correlation in multiple instance learning.\n  Application to cancer detection on histopathological images",
            "updated": "2023-10-30T08:57:59Z",
            "published": "2023-10-30T08:57:59Z",
            "summary": "In the last years, the weakly supervised paradigm of multiple instance\nlearning (MIL) has become very popular in many different areas. A paradigmatic\nexample is computational pathology, where the lack of patch-level labels for\nwhole-slide images prevents the application of supervised models. Probabilistic\nMIL methods based on Gaussian Processes (GPs) have obtained promising results\ndue to their excellent uncertainty estimation capabilities. However, these are\ngeneral-purpose MIL methods that do not take into account one important fact:\nin (histopathological) images, the labels of neighboring patches are expected\nto be correlated. In this work, we extend a state-of-the-art GP-based MIL\nmethod, which is called VGPMIL-PR, to exploit such correlation. To do so, we\ndevelop a novel coupling term inspired by the statistical physics Ising model.\nWe use variational inference to estimate all the model parameters.\nInterestingly, the VGPMIL-PR formulation is recovered when the weight that\nregulates the strength of the Ising term vanishes. The performance of the\nproposed method is assessed in two real-world problems of prostate cancer\ndetection. We show that our model achieves better results than other\nstate-of-the-art probabilistic MIL methods. We also provide different\nvisualizations and analysis to gain insights into the influence of the novel\nIsing term. These insights are expected to facilitate the application of the\nproposed model to other research areas.",
            "author": [
                "Pablo Morales-\u00c1lvarez",
                "Arne Schmidt",
                "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
                "Rafael Molina"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.patcog.2023.110057",
                "http://arxiv.org/abs/2310.19359v1",
                "http://arxiv.org/pdf/2310.19359v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19843v1",
            "title": "Modeling the Telemarketing Process using Genetic Algorithms and Extreme\n  Boosting: Feature Selection and Cost-Sensitive Analytical Approach",
            "updated": "2023-10-30T08:46:55Z",
            "published": "2023-10-30T08:46:55Z",
            "summary": "Currently, almost all direct marketing activities take place virtually rather\nthan in person, weakening interpersonal skills at an alarming pace.\nFurthermore, businesses have been striving to sense and foster the tendency of\ntheir clients to accept a marketing offer. The digital transformation and the\nincreased virtual presence forced firms to seek novel marketing research\napproaches. This research aims at leveraging the power of telemarketing data in\nmodeling the willingness of clients to make a term deposit and finding the most\nsignificant characteristics of the clients. Real-world data from a Portuguese\nbank and national socio-economic metrics are used to model the telemarketing\ndecision-making process. This research makes two key contributions. First,\npropose a novel genetic algorithm-based classifier to select the best\ndiscriminating features and tune classifier parameters simultaneously. Second,\nbuild an explainable prediction model. The best-generated classification models\nwere intensively validated using 50 times repeated 10-fold stratified\ncross-validation and the selected features have been analyzed. The models\nsignificantly outperform the related works in terms of class of interest\naccuracy, they attained an average of 89.07\\% and 0.059 in terms of geometric\nmean and type I error respectively. The model is expected to maximize the\npotential profit margin at the least possible cost and provide more insights to\nsupport marketing decision-making.",
            "author": [
                "Nazeeh Ghatasheh",
                "Ismail Altaharwa",
                "Khaled Aldebei"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ACCESS.2023.3292840",
                "http://arxiv.org/abs/2310.19843v1",
                "http://arxiv.org/pdf/2310.19843v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19351v1",
            "title": "Semi- and Weakly-Supervised Domain Generalization for Object Detection",
            "updated": "2023-10-30T08:46:26Z",
            "published": "2023-10-30T08:46:26Z",
            "summary": "Object detectors do not work well when domains largely differ between\ntraining and testing data. To solve this problem, domain generalization\napproaches, which require training data with ground-truth labels from multiple\ndomains, have been proposed. However, it is time-consuming and labor-intensive\nto collect those data for object detection because not only class labels but\nalso bounding boxes must be annotated. To overcome the problem of domain gap in\nobject detection without requiring expensive annotations, we propose to\nconsider two new problem settings: semi-supervised domain generalizable object\ndetection (SS-DGOD) and weakly-supervised DGOD (WS-DGOD). In contrast to the\nconventional domain generalization for object detection that requires labeled\ndata from multiple domains, SS-DGOD and WS-DGOD require labeled data only from\none domain and unlabeled or weakly-labeled data from multiple domains for\ntraining. We show that object detectors can be effectively trained on the\nproposed settings with the same student-teacher learning framework, where a\nstudent network is trained with pseudo labels output from a teacher on the\nunlabeled or weakly-labeled data. The experimental results demonstrate that the\nobject detectors trained on the proposed settings significantly outperform\nbaseline detectors trained on one labeled domain data and perform comparably to\nor better than those trained on unsupervised domain adaptation (UDA) settings,\nwhile ours do not use target domain data for training in contrast to UDA.",
            "author": [
                "Ryosuke Furuta",
                "Yoichi Sato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19351v1",
                "http://arxiv.org/pdf/2310.19351v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19350v1",
            "title": "Disorder-dependent Li diffusion in $\\mathrm{Li_6PS_5Cl}$ investigated by\n  machine learning potential",
            "updated": "2023-10-30T08:46:07Z",
            "published": "2023-10-30T08:46:07Z",
            "summary": "Solid-state electrolytes with argyrodite structures, such as\n$\\mathrm{Li_6PS_5Cl}$, have attracted considerable attention due to their\nsuperior safety compared to liquid electrolytes and higher ionic conductivity\nthan other solid electrolytes. Although experimental efforts have been made to\nenhance conductivity by controlling the degree of disorder, the underlying\ndiffusion mechanism is not yet fully understood. Moreover, existing theoretical\nanalyses based on ab initio MD simulations have limitations in addressing\nvarious types of disorder at room temperature. In this study, we directly\ninvestigate Li-ion diffusion in $\\mathrm{Li_6PS_5Cl}$ at 300 K using\nlarge-scale, long-term MD simulations empowered by machine learning potentials\n(MLPs). To ensure the convergence of conductivity values within an error range\nof 10%, we employ a 25 ns simulation using a $5\\times5\\times5$ supercell\ncontaining 6500 atoms. The computed Li-ion conductivity, activation energies,\nand equilibrium site occupancies align well with experimental observations.\nNotably, Li-ion conductivity peaks when Cl ions occupy 25% of the 4c sites,\nrather than at 50% where the disorder is maximized. This phenomenon is\nexplained by the interplay between inter-cage and intra-cage jumps. By\nelucidating the key factors affecting Li-ion diffusion in\n$\\mathrm{Li_6PS_5Cl}$, this work paves the way for optimizing ionic\nconductivity in the argyrodite family.",
            "author": [
                "Jiho Lee",
                "Suyeon Ju",
                "Seungwoo Hwang",
                "Jinmu You",
                "Jisu Jung",
                "Youngho Kang",
                "Seungwu Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19350v1",
                "http://arxiv.org/pdf/2310.19350v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.00721v1",
            "title": "Empathy Detection Using Machine Learning on Text, Audiovisual, Audio or\n  Physiological Signals",
            "updated": "2023-10-30T08:34:12Z",
            "published": "2023-10-30T08:34:12Z",
            "summary": "Empathy is a social skill that indicates an individual's ability to\nunderstand others. Over the past few years, empathy has drawn attention from\nvarious disciplines, including but not limited to Affective Computing,\nCognitive Science and Psychology. Empathy is a context-dependent term; thus,\ndetecting or recognising empathy has potential applications in society,\nhealthcare and education. Despite being a broad and overlapping topic, the\navenue of empathy detection studies leveraging Machine Learning remains\nunderexplored from a holistic literature perspective. To this end, we\nsystematically collect and screen 801 papers from 10 well-known databases and\nanalyse the selected 54 papers. We group the papers based on input modalities\nof empathy detection systems, i.e., text, audiovisual, audio and physiological\nsignals. We examine modality-specific pre-processing and network architecture\ndesign protocols, popular dataset descriptions and availability details, and\nevaluation protocols. We further discuss the potential applications, deployment\nchallenges and research gaps in the Affective Computing-based empathy domain,\nwhich can facilitate new avenues of exploration. We believe that our work is a\nstepping stone to developing a privacy-preserving and unbiased empathic system\ninclusive of culture, diversity and multilingualism that can be deployed in\npractice to enhance the overall well-being of human life.",
            "author": [
                "Md Rakibul Hasan",
                "Md Zakir Hossain",
                "Shreya Ghosh",
                "Susannah Soon",
                "Tom Gedeon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00721v1",
                "http://arxiv.org/pdf/2311.00721v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19343v1",
            "title": "Quantile Super Learning for independent and online settings with\n  application to solar power forecasting",
            "updated": "2023-10-30T08:34:07Z",
            "published": "2023-10-30T08:34:07Z",
            "summary": "Estimating quantiles of an outcome conditional on covariates is of\nfundamental interest in statistics with broad application in probabilistic\nprediction and forecasting. We propose an ensemble method for conditional\nquantile estimation, Quantile Super Learning, that combines predictions from\nmultiple candidate algorithms based on their empirical performance measured\nwith respect to a cross-validated empirical risk of the quantile loss function.\nWe present theoretical guarantees for both iid and online data scenarios. The\nperformance of our approach for quantile estimation and in forming prediction\nintervals is tested in simulation studies. Two case studies related to solar\nenergy are used to illustrate Quantile Super Learning: in an iid setting, we\npredict the physical properties of perovskite materials for photovoltaic cells,\nand in an online setting we forecast ground solar irradiance based on output\nfrom dynamic weather ensemble models.",
            "author": [
                "Herbert Susmann",
                "Antoine Chambaz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19343v1",
                "http://arxiv.org/pdf/2310.19343v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19342v1",
            "title": "Label-Only Model Inversion Attacks via Knowledge Transfer",
            "updated": "2023-10-30T08:32:12Z",
            "published": "2023-10-30T08:32:12Z",
            "summary": "In a model inversion (MI) attack, an adversary abuses access to a machine\nlearning (ML) model to infer and reconstruct private training data. Remarkable\nprogress has been made in the white-box and black-box setups, where the\nadversary has access to the complete model or the model's soft output\nrespectively. However, there is very limited study in the most challenging but\npractically important setup: Label-only MI attacks, where the adversary only\nhas access to the model's predicted label (hard label) without confidence\nscores nor any other model information.\n  In this work, we propose LOKT, a novel approach for label-only MI attacks.\nOur idea is based on transfer of knowledge from the opaque target model to\nsurrogate models. Subsequently, using these surrogate models, our approach can\nharness advanced white-box attacks. We propose knowledge transfer based on\ngenerative modelling, and introduce a new model, Target model-assisted ACGAN\n(T-ACGAN), for effective knowledge transfer. Our method casts the challenging\nlabel-only MI into the more tractable white-box setup. We provide analysis to\nsupport that surrogate models based on our approach serve as effective proxies\nfor the target model for MI. Our experiments show that our method significantly\noutperforms existing SOTA Label-only MI attack by more than 15% across all MI\nbenchmarks. Furthermore, our method compares favorably in terms of query\nbudget. Our study highlights rising privacy threats for ML models even when\nminimal information (i.e., hard labels) is exposed. Our study highlights rising\nprivacy threats for ML models even when minimal information (i.e., hard labels)\nis exposed. Our code, demo, models and reconstructed data are available at our\nproject page: https://ngoc-nguyen-0.github.io/lokt/",
            "author": [
                "Ngoc-Bao Nguyen",
                "Keshigeyan Chandrasegaran",
                "Milad Abdollahzadeh",
                "Ngai-Man Cheung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19342v1",
                "http://arxiv.org/pdf/2310.19342v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19332v1",
            "title": "Solar Flare Prediction and Feature Selection using Light Gradient\n  Boosting Machine Algorithm",
            "updated": "2023-10-30T08:04:48Z",
            "published": "2023-10-30T08:04:48Z",
            "summary": "Solar flares are among the most severe space weather phenomena, and they have\nthe capacity to generate radiation storms and radio disruptions on Earth. The\naccurate prediction of solar flare events remains a significant challenge,\nrequiring continuous monitoring and identification of specific features that\ncan aid in forecasting this phenomenon, particularly for different classes of\nsolar flares. In this study, we aim to forecast C and M class solar flares\nutilising a machine-learning algorithm, namely the Light Gradient Boosting\nMachine. We have utilised a dataset spanning 9 years, obtained from the\nSpace-weather Helioseismic and Magnetic Imager Active Region Patches (SHARP),\nwith a temporal resolution of 1 hour. A total of 37 flare features were\nconsidered in our analysis, comprising of 25 active region parameters and 12\nflare history features. To address the issue of class imbalance in solar flare\ndata, we employed the Synthetic Minority Oversampling Technique (SMOTE). We\nused two labeling approaches in our study: a fixed 24-hour window label and a\nvarying window that considers the changing nature of solar activity. Then, the\ndeveloped machine learning algorithm was trained and tested using forecast\nverification metrics, with an emphasis on evaluating the true skill statistic\n(TSS). Furthermore, we implemented a feature selection algorithm to determine\nthe most significant features from the pool of 37 features that could\ndistinguish between flaring and non-flaring active regions. We found that\nutilising a limited set of useful features resulted in improved prediction\nperformance. For the 24-hour prediction window, we achieved a TSS of 0.63\n(0.69) and accuracy of 0.90 (0.97) for $\\geq$C ($\\geq$M) class solar flares.",
            "author": [
                "Vysakh P. A.",
                "Prateek Mayank"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19332v1",
                "http://arxiv.org/pdf/2310.19332v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19331v1",
            "title": "AdapINT: A Flexible and Adaptive In-Band Network Telemetry System Based\n  on Deep Reinforcement Learning",
            "updated": "2023-10-30T08:02:35Z",
            "published": "2023-10-30T08:02:35Z",
            "summary": "In-band Network Telemetry (INT) has emerged as a promising network\nmeasurement technology. However, existing network telemetry systems lack the\nflexibility to meet diverse telemetry requirements and are also difficult to\nadapt to dynamic network environments. In this paper, we propose AdapINT, a\nversatile and adaptive in-band network telemetry framework assisted by\ndual-timescale probes, including long-period auxiliary probes (APs) and\nshort-period dynamic probes (DPs). Technically, the APs collect basic network\nstatus information, which is used for the path planning of DPs. To achieve full\nnetwork coverage, we propose an auxiliary probes path deployment (APPD)\nalgorithm based on the Depth-First-Search (DFS). The DPs collect specific\nnetwork information for telemetry tasks. To ensure that the DPs can meet\ndiverse telemetry requirements and adapt to dynamic network environments, we\napply the deep reinforcement learning (DRL) technique and transfer learning\nmethod to design the dynamic probes path deployment (DPPD) algorithm. The\nevaluation results show that AdapINT can redesign the telemetry system\naccording to telemetry requirements and network environments. AdapINT can\nreduce telemetry latency by 75\\% in online games and video conferencing\nscenarios. For overhead-aware networks, AdapINT can reduce control overheads by\n34\\% in cloud computing services.",
            "author": [
                "Penghui Zhang",
                "Hua Zhang",
                "Yibo Pi",
                "Zijian Cao",
                "Jingyu Wang",
                "Jianxin Liao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19331v1",
                "http://arxiv.org/pdf/2310.19331v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19842v1",
            "title": "Musical Form Generation",
            "updated": "2023-10-30T08:02:08Z",
            "published": "2023-10-30T08:02:08Z",
            "summary": "While recent generative models can produce engaging music, their utility is\nlimited. The variation in the music is often left to chance, resulting in\ncompositions that lack structure. Pieces extending beyond a minute can become\nincoherent or repetitive. This paper introduces an approach for generating\nstructured, arbitrarily long musical pieces. Central to this approach is the\ncreation of musical segments using a conditional generative model, with\ntransitions between these segments. The generation of prompts that determine\nthe high-level composition is distinct from the creation of finer, lower-level\ndetails. A large language model is then used to suggest the musical form.",
            "author": [
                "Lilac Atassi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19842v1",
                "http://arxiv.org/pdf/2310.19842v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19841v1",
            "title": "An interpretable clustering approach to safety climate analysis:\n  examining driver group distinction in safety climate perceptions",
            "updated": "2023-10-30T07:53:42Z",
            "published": "2023-10-30T07:53:42Z",
            "summary": "The transportation industry, particularly the trucking sector, is prone to\nworkplace accidents and fatalities. Accidents involving large trucks accounted\nfor a considerable percentage of overall traffic fatalities. Recognizing the\ncrucial role of safety climate in accident prevention, researchers have sought\nto understand its factors and measure its impact within organizations. While\nexisting data-driven safety climate studies have made remarkable progress,\nclustering employees based on their safety climate perception is innovative and\nhas not been extensively utilized in research. Identifying clusters of drivers\nbased on their safety climate perception allows the organization to profile its\nworkforce and devise more impactful interventions. The lack of utilizing the\nclustering approach could be due to difficulties interpreting or explaining the\nfactors influencing employees' cluster membership. Moreover, existing\nsafety-related studies did not compare multiple clustering algorithms,\nresulting in potential bias. To address these issues, this study introduces an\ninterpretable clustering approach for safety climate analysis. This study\ncompares 5 algorithms for clustering truck drivers based on their safety\nclimate perceptions. It proposes a novel method for quantitatively evaluating\npartial dependence plots (QPDP). To better interpret the clustering results,\nthis study introduces different interpretable machine learning measures (SHAP,\nPFI, and QPDP). Drawing on data collected from more than 7,000 American truck\ndrivers, this study significantly contributes to the scientific literature. It\nhighlights the critical role of supervisory care promotion in distinguishing\nvarious driver groups. The Python code is available at\nhttps://github.com/NUS-DBE/truck-driver-safety-climate.",
            "author": [
                "Kailai Sun",
                "Tianxiang Lan",
                "Yang Miang Goh",
                "Sufiana Safiena",
                "Yueng-Hsiang Huang",
                "Bailey Lytle",
                "Yimin He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19841v1",
                "http://arxiv.org/pdf/2310.19841v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19324v1",
            "title": "TempME: Towards the Explainability of Temporal Graph Neural Networks via\n  Motif Discovery",
            "updated": "2023-10-30T07:51:41Z",
            "published": "2023-10-30T07:51:41Z",
            "summary": "Temporal graphs are widely used to model dynamic systems with time-varying\ninteractions. In real-world scenarios, the underlying mechanisms of generating\nfuture interactions in dynamic systems are typically governed by a set of\nrecurring substructures within the graph, known as temporal motifs. Despite the\nsuccess and prevalence of current temporal graph neural networks (TGNN), it\nremains uncertain which temporal motifs are recognized as the significant\nindications that trigger a certain prediction from the model, which is a\ncritical challenge for advancing the explainability and trustworthiness of\ncurrent TGNNs. To address this challenge, we propose a novel approach, called\nTemporal Motifs Explainer (TempME), which uncovers the most pivotal temporal\nmotifs guiding the prediction of TGNNs. Derived from the information bottleneck\nprinciple, TempME extracts the most interaction-related motifs while minimizing\nthe amount of contained information to preserve the sparsity and succinctness\nof the explanation. Events in the explanations generated by TempME are verified\nto be more spatiotemporally correlated than those of existing approaches,\nproviding more understandable insights. Extensive experiments validate the\nsuperiority of TempME, with up to 8.21% increase in terms of explanation\naccuracy across six real-world datasets and up to 22.96% increase in boosting\nthe prediction Average Precision of current TGNNs.",
            "author": [
                "Jialin Chen",
                "Rex Ying"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19324v1",
                "http://arxiv.org/pdf/2310.19324v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19323v1",
            "title": "A Low-Complexity Machine Learning Design for mmWave Beam Prediction",
            "updated": "2023-10-30T07:48:15Z",
            "published": "2023-10-30T07:48:15Z",
            "summary": "The 3rd Generation Partnership Project (3GPP) is currently studying machine\nlearning (ML) for the fifth generation (5G)-Advanced New Radio (NR) air\ninterface, where spatial and temporal-domain beam prediction are important use\ncases. With this background, this letter presents a low-complexity ML design\nthat expedites the spatial-domain beam prediction to reduce the power\nconsumption and the reference signaling overhead, which are currently\nimperative for frequent beam measurements. Complexity analysis and evaluation\nresults showcase that the proposed model achieves state-of-the-art accuracy\nwith lower computational complexity, resulting in reduced power consumption and\nfaster beam prediction. Furthermore, important observations on the\ngeneralization of the proposed model are presented in this letter.",
            "author": [
                "Muhammad Qurratulain Khan",
                "Abdo Gaber",
                "Mohammad Parvini",
                "Philipp Schulz",
                "Gerhard Fettweis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19323v1",
                "http://arxiv.org/pdf/2310.19323v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19322v1",
            "title": "ProNet: Progressive Neural Network for Multi-Horizon Time Series\n  Forecasting",
            "updated": "2023-10-30T07:46:40Z",
            "published": "2023-10-30T07:46:40Z",
            "summary": "In this paper, we introduce ProNet, an novel deep learning approach designed\nfor multi-horizon time series forecasting, adaptively blending autoregressive\n(AR) and non-autoregressive (NAR) strategies. Our method involves dividing the\nforecasting horizon into segments, predicting the most crucial steps in each\nsegment non-autoregressively, and the remaining steps autoregressively. The\nsegmentation process relies on latent variables, which effectively capture the\nsignificance of individual time steps through variational inference. In\ncomparison to AR models, ProNet showcases remarkable advantages, requiring\nfewer AR iterations, resulting in faster prediction speed, and mitigating error\naccumulation. On the other hand, when compared to NAR models, ProNet takes into\naccount the interdependency of predictions in the output space, leading to\nimproved forecasting accuracy. Our comprehensive evaluation, encompassing four\nlarge datasets, and an ablation study, demonstrate the effectiveness of ProNet,\nhighlighting its superior performance in terms of accuracy and prediction\nspeed, outperforming state-of-the-art AR and NAR forecasting models.",
            "author": [
                "Yang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19322v1",
                "http://arxiv.org/pdf/2310.19322v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19321v1",
            "title": "D4Explainer: In-Distribution GNN Explanations via Discrete Denoising\n  Diffusion",
            "updated": "2023-10-30T07:41:42Z",
            "published": "2023-10-30T07:41:42Z",
            "summary": "The widespread deployment of Graph Neural Networks (GNNs) sparks significant\ninterest in their explainability, which plays a vital role in model auditing\nand ensuring trustworthy graph learning. The objective of GNN explainability is\nto discern the underlying graph structures that have the most significant\nimpact on model predictions. Ensuring that explanations generated are reliable\nnecessitates consideration of the in-distribution property, particularly due to\nthe vulnerability of GNNs to out-of-distribution data. Unfortunately,\nprevailing explainability methods tend to constrain the generated explanations\nto the structure of the original graph, thereby downplaying the significance of\nthe in-distribution property and resulting in explanations that lack\nreliability. To address these challenges, we propose D4Explainer, a novel\napproach that provides in-distribution GNN explanations for both counterfactual\nand model-level explanation scenarios. The proposed D4Explainer incorporates\ngenerative graph distribution learning into the optimization objective, which\naccomplishes two goals: 1) generate a collection of diverse counterfactual\ngraphs that conform to the in-distribution property for a given instance, and\n2) identify the most discriminative graph patterns that contribute to a\nspecific class prediction, thus serving as model-level explanations. It is\nworth mentioning that D4Explainer is the first unified framework that combines\nboth counterfactual and model-level explanations. Empirical evaluations\nconducted on synthetic and real-world datasets provide compelling evidence of\nthe state-of-the-art performance achieved by D4Explainer in terms of\nexplanation accuracy, faithfulness, diversity, and robustness.",
            "author": [
                "Jialin Chen",
                "Shirley Wu",
                "Abhijit Gupta",
                "Rex Ying"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19321v1",
                "http://arxiv.org/pdf/2310.19321v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19319v1",
            "title": "Dual-Directed Algorithm Design for Efficient Pure Exploration",
            "updated": "2023-10-30T07:29:17Z",
            "published": "2023-10-30T07:29:17Z",
            "summary": "We consider pure-exploration problems in the context of stochastic sequential\nadaptive experiments with a finite set of alternative options. The goal of the\ndecision-maker is to accurately answer a query question regarding the\nalternatives with high confidence with minimal measurement efforts. A typical\nquery question is to identify the alternative with the best performance,\nleading to ranking and selection problems, or best-arm identification in the\nmachine learning literature. We focus on the fixed-precision setting and derive\na sufficient condition for optimality in terms of a notion of strong\nconvergence to the optimal allocation of samples. Using dual variables, we\ncharacterize the necessary and sufficient conditions for an allocation to be\noptimal. The use of dual variables allow us to bypass the combinatorial\nstructure of the optimality conditions that relies solely on primal variables.\nRemarkably, these optimality conditions enable an extension of top-two\nalgorithm design principle, initially proposed for best-arm identification.\nFurthermore, our optimality conditions give rise to a straightforward yet\nefficient selection rule, termed information-directed selection, which\nadaptively picks from a candidate set based on information gain of the\ncandidates. We outline the broad contexts where our algorithmic approach can be\nimplemented. We establish that, paired with information-directed selection,\ntop-two Thompson sampling is (asymptotically) optimal for Gaussian best-arm\nidentification, solving a glaring open problem in the pure exploration\nliterature. Our algorithm is optimal for $\\epsilon$-best-arm identification and\nthresholding bandit problems. Our analysis also leads to a general principle to\nguide adaptations of Thompson sampling for pure-exploration problems. Numerical\nexperiments highlight the exceptional efficiency of our proposed algorithms\nrelative to existing ones.",
            "author": [
                "Chao Qin",
                "Wei You"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19319v1",
                "http://arxiv.org/pdf/2310.19319v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19313v1",
            "title": "L2T-DLN: Learning to Teach with Dynamic Loss Network",
            "updated": "2023-10-30T07:21:40Z",
            "published": "2023-10-30T07:21:40Z",
            "summary": "With the concept of teaching being introduced to the machine learning\ncommunity, a teacher model start using dynamic loss functions to teach the\ntraining of a student model. The dynamic intends to set adaptive loss functions\nto different phases of student model learning. In existing works, the teacher\nmodel 1) merely determines the loss function based on the present states of the\nstudent model, i.e., disregards the experience of the teacher; 2) only utilizes\nthe states of the student model, e.g., training iteration number and\nloss/accuracy from training/validation sets, while ignoring the states of the\nloss function. In this paper, we first formulate the loss adjustment as a\ntemporal task by designing a teacher model with memory units, and, therefore,\nenables the student learning to be guided by the experience of the teacher\nmodel. Then, with a dynamic loss network, we can additionally use the states of\nthe loss to assist the teacher learning in enhancing the interactions between\nthe teacher and the student model. Extensive experiments demonstrate our\napproach can enhance student learning and improve the performance of various\ndeep models on real-world tasks, including classification, objective detection,\nand semantic segmentation scenarios.",
            "author": [
                "Zhoyang Hai",
                "Liyuan Pan",
                "Xiabi Liu",
                "Zhengzheng Liu",
                "Mirna Yunita"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19313v1",
                "http://arxiv.org/pdf/2310.19313v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19308v2",
            "title": "Free from Bellman Completeness: Trajectory Stitching via Model-based\n  Return-conditioned Supervised Learning",
            "updated": "2023-12-02T11:27:53Z",
            "published": "2023-10-30T07:03:14Z",
            "summary": "Off-policy dynamic programming (DP) techniques such as $Q$-learning have\nproven to be important in sequential decision-making problems. In the presence\nof function approximation, however, these techniques often diverge due to the\nabsence of Bellman completeness in the function classes considered, a crucial\ncondition for the success of DP-based methods. In this paper, we show how\noff-policy learning techniques based on return-conditioned supervised learning\n(RCSL) are able to circumvent these challenges of Bellman completeness,\nconverging under significantly more relaxed assumptions inherited from\nsupervised learning. We prove there exists a natural environment in which if\none uses two-layer multilayer perceptron as the function approximator, the\nlayer width needs to grow linearly with the state space size to satisfy Bellman\ncompleteness while a constant layer width is enough for RCSL. These findings\ntake a step towards explaining the superior empirical performance of RCSL\nmethods compared to DP-based methods in environments with near-optimal\ndatasets. Furthermore, in order to learn from sub-optimal datasets, we propose\na simple framework called MBRCSL, granting RCSL methods the ability of dynamic\nprogramming to stitch together segments from distinct trajectories. MBRCSL\nleverages learned dynamics models and forward sampling to accomplish trajectory\nstitching while avoiding the need for Bellman completeness that plagues all\ndynamic programming algorithms. We propose both theoretical analysis and\nexperimental evaluation to back these claims, outperforming state-of-the-art\nmodel-free and model-based offline RL algorithms across several simulated\nrobotics problems.",
            "author": [
                "Zhaoyi Zhou",
                "Chuning Zhu",
                "Runlong Zhou",
                "Qiwen Cui",
                "Abhishek Gupta",
                "Simon Shaolei Du"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19308v2",
                "http://arxiv.org/pdf/2310.19308v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.02165v1",
            "title": "Teaching mathematical modeling for sustainability: Enhancing\n  interdisciplinary skills in students",
            "updated": "2023-10-30T07:00:38Z",
            "published": "2023-10-30T07:00:38Z",
            "summary": "We developed a pilot course focused on mathematical modeling within the\ntertiary education framework, with a distinct emphasis on sustainability and\nsustainable development. While an applicable textbook exists for this liberal\narts course, it is noticeable that numerous examples within it are not directly\naligned with sustainability concerns. To address this gap, our study\nstrategically integrated the teaching and learning of modeling by carefully\nselecting classroom examples that closely align with the context of\nsustainability. By employing an innovative and adaptable approach to the course\ncontent delivery, we fostered interdisciplinary collaboration among students,\nimproved their comprehension, and enhanced their interdisciplinary skills.",
            "author": [
                "N. Karjanto"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02165v1",
                "http://arxiv.org/pdf/2312.02165v1"
            ],
            "primary_category": "math.HO",
            "category": [
                "math.HO",
                "97M10, 97U20, 97U30"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19306v1",
            "title": "A Planning-and-Exploring Approach to Extreme-Mechanics Force Fields",
            "updated": "2023-10-30T06:59:01Z",
            "published": "2023-10-30T06:59:01Z",
            "summary": "Extreme mechanical processes such as strong lattice distortion and bond\nbreakage during fracture are ubiquitous in nature and engineering, which often\nlead to catastrophic failure of structures. However, understanding the\nnucleation and growth of cracks is challenged by their multiscale\ncharacteristics spanning from atomic-level structures at the crack tip to the\nstructural features where the load is applied. Molecular simulations offer an\nimportant tool to resolve the progressive microstructural changes at crack\nfronts and are widely used to explore processes therein, such as mechanical\nenergy dissipation, crack path selection, and dynamic instabilities (e.g.,\nkinking, branching). Empirical force fields developed based on local\ndescriptors based on atomic positions and the bond orders do not yield\nsatisfying predictions of fracture, even for the nonlinear, anisotropic\nstress-strain relations and the energy densities of edges. High-fidelity force\nfields thus should include the tensorial nature of strain and the energetics of\nrare events during fracture, which, unfortunately, have not been taken into\naccount in both the state-of-the-art empirical and machine-learning force\nfields. Based on data generated by first-principles calculations, we develop a\nneural network-based force field for fracture, NN-F$^3$, by combining\npre-sampling of the space of strain states and active-learning techniques to\nexplore the transition states at critical bonding distances. The capability of\nNN-F$^3$ is demonstrated by studying the rupture of h-BN and twisted bilayer\ngraphene as model problems. The simulation results confirm recent experimental\nfindings and highlight the necessity to include the knowledge of electronic\nstructures from first-principles calculations in predicting extreme mechanical\nprocesses.",
            "author": [
                "Pengjie Shi",
                "Zhiping Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19306v1",
                "http://arxiv.org/pdf/2310.19306v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.stat-mech",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19304v1",
            "title": "Privacy-Preserving Federated Learning over Vertically and Horizontally\n  Partitioned Data for Financial Anomaly Detection",
            "updated": "2023-10-30T06:51:33Z",
            "published": "2023-10-30T06:51:33Z",
            "summary": "The effective detection of evidence of financial anomalies requires\ncollaboration among multiple entities who own a diverse set of data, such as a\npayment network system (PNS) and its partner banks. Trust among these financial\ninstitutions is limited by regulation and competition. Federated learning (FL)\nenables entities to collaboratively train a model when data is either\nvertically or horizontally partitioned across the entities. However, in\nreal-world financial anomaly detection scenarios, the data is partitioned both\nvertically and horizontally and hence it is not possible to use existing FL\napproaches in a plug-and-play manner.\n  Our novel solution, PV4FAD, combines fully homomorphic encryption (HE),\nsecure multi-party computation (SMPC), differential privacy (DP), and\nrandomization techniques to balance privacy and accuracy during training and to\nprevent inference threats at model deployment time. Our solution provides input\nprivacy through HE and SMPC, and output privacy against inference time attacks\nthrough DP. Specifically, we show that, in the honest-but-curious threat model,\nbanks do not learn any sensitive features about PNS transactions, and the PNS\ndoes not learn any information about the banks' dataset but only learns\nprediction labels. We also develop and analyze a DP mechanism to protect output\nprivacy during inference. Our solution generates high-utility models by\nsignificantly reducing the per-bank noise level while satisfying distributed\nDP. To ensure high accuracy, our approach produces an ensemble model, in\nparticular, a random forest. This enables us to take advantage of the\nwell-known properties of ensembles to reduce variance and increase accuracy.\nOur solution won second prize in the first phase of the U.S. Privacy Enhancing\nTechnologies (PETs) Prize Challenge.",
            "author": [
                "Swanand Ravindra Kadhe",
                "Heiko Ludwig",
                "Nathalie Baracaldo",
                "Alan King",
                "Yi Zhou",
                "Keith Houck",
                "Ambrish Rawat",
                "Mark Purcell",
                "Naoise Holohan",
                "Mikio Takeuchi",
                "Ryo Kawahara",
                "Nir Drucker",
                "Hayim Shaul",
                "Eyal Kushnir",
                "Omri Soceanu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19304v1",
                "http://arxiv.org/pdf/2310.19304v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19300v1",
            "title": "Stage-Aware Learning for Dynamic Treatments",
            "updated": "2023-10-30T06:35:31Z",
            "published": "2023-10-30T06:35:31Z",
            "summary": "Recent advances in dynamic treatment regimes (DTRs) provide powerful optimal\ntreatment searching algorithms, which are tailored to individuals' specific\nneeds and able to maximize their expected clinical benefits. However, existing\nalgorithms could suffer from insufficient sample size under optimal treatments,\nespecially for chronic diseases involving long stages of decision-making. To\naddress these challenges, we propose a novel individualized learning method\nwhich estimates the DTR with a focus on prioritizing alignment between the\nobserved treatment trajectory and the one obtained by the optimal regime across\ndecision stages. By relaxing the restriction that the observed trajectory must\nbe fully aligned with the optimal treatments, our approach substantially\nimproves the sample efficiency and stability of inverse probability weighted\nbased methods. In particular, the proposed learning scheme builds a more\ngeneral framework which includes the popular outcome weighted learning\nframework as a special case of ours. Moreover, we introduce the notion of stage\nimportance scores along with an attention mechanism to explicitly account for\nheterogeneity among decision stages. We establish the theoretical properties of\nthe proposed approach, including the Fisher consistency and finite-sample\nperformance bound. Empirically, we evaluate the proposed method in extensive\nsimulated environments and a real case study for COVID-19 pandemic.",
            "author": [
                "Hanwen Ye",
                "Wenzhuo Zhou",
                "Ruoqing Zhu",
                "Annie Qu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19300v1",
                "http://arxiv.org/pdf/2310.19300v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19297v1",
            "title": "On Measuring Fairness in Generative Models",
            "updated": "2023-10-30T06:33:48Z",
            "published": "2023-10-30T06:33:48Z",
            "summary": "Recently, there has been increased interest in fair generative models. In\nthis work, we conduct, for the first time, an in-depth study on fairness\nmeasurement, a critical component in gauging progress on fair generative\nmodels. We make three contributions. First, we conduct a study that reveals\nthat the existing fairness measurement framework has considerable measurement\nerrors, even when highly accurate sensitive attribute (SA) classifiers are\nused. These findings cast doubts on previously reported fairness improvements.\nSecond, to address this issue, we propose CLassifier Error-Aware Measurement\n(CLEAM), a new framework which uses a statistical model to account for\ninaccuracies in SA classifiers. Our proposed CLEAM reduces measurement errors\nsignificantly, e.g., 4.98% $\\rightarrow$ 0.62% for StyleGAN2 w.r.t. Gender.\nAdditionally, CLEAM achieves this with minimal additional overhead. Third, we\nutilize CLEAM to measure fairness in important text-to-image generator and\nGANs, revealing considerable biases in these models that raise concerns about\ntheir applications. Code and more resources:\nhttps://sutd-visual-computing-group.github.io/CLEAM/.",
            "author": [
                "Christopher T. H. Teo",
                "Milad Abdollahzadeh",
                "Ngai-Man Cheung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19297v1",
                "http://arxiv.org/pdf/2310.19297v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19295v1",
            "title": "ROAM: memory-efficient large DNN training via optimized operator\n  ordering and memory layout",
            "updated": "2023-10-30T06:29:21Z",
            "published": "2023-10-30T06:29:21Z",
            "summary": "As deep learning models continue to increase in size, the memory requirements\nfor training have surged. While high-level techniques like offloading,\nrecomputation, and compression can alleviate memory pressure, they also\nintroduce overheads. However, a memory-efficient execution plan that includes a\nreasonable operator execution order and tensor memory layout can significantly\nincrease the models' memory efficiency and reduce overheads from high-level\ntechniques. In this paper, we propose ROAM which operates on computation graph\nlevel to derive memory-efficient execution plan with optimized operator order\nand tensor memory layout for models. We first propose sophisticated theories\nthat carefully consider model structure and training memory load to support\noptimization for large complex graphs that have not been well supported in the\npast. An efficient tree-based algorithm is further proposed to search task\ndivisions automatically, along with delivering high performance and\neffectiveness to solve the problem. Experiments show that ROAM achieves a\nsubstantial memory reduction of 35.7%, 13.3%, and 27.2% compared to Pytorch and\ntwo state-of-the-art methods and offers a remarkable 53.7x speedup. The\nevaluation conducted on the expansive GPT2-XL further validates ROAM's\nscalability.",
            "author": [
                "Huiyao Shu",
                "Ang Wang",
                "Ziji Shi",
                "Hanyu Zhao",
                "Yong Li",
                "Lu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19295v1",
                "http://arxiv.org/pdf/2310.19295v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19293v1",
            "title": "FetusMapV2: Enhanced Fetal Pose Estimation in 3D Ultrasound",
            "updated": "2023-10-30T06:18:47Z",
            "published": "2023-10-30T06:18:47Z",
            "summary": "Fetal pose estimation in 3D ultrasound (US) involves identifying a set of\nassociated fetal anatomical landmarks. Its primary objective is to provide\ncomprehensive information about the fetus through landmark connections, thus\nbenefiting various critical applications, such as biometric measurements, plane\nlocalization, and fetal movement monitoring. However, accurately estimating the\n3D fetal pose in US volume has several challenges, including poor image\nquality, limited GPU memory for tackling high dimensional data, symmetrical or\nambiguous anatomical structures, and considerable variations in fetal poses. In\nthis study, we propose a novel 3D fetal pose estimation framework (called\nFetusMapV2) to overcome the above challenges. Our contribution is three-fold.\nFirst, we propose a heuristic scheme that explores the complementary network\nstructure-unconstrained and activation-unreserved GPU memory management\napproaches, which can enlarge the input image resolution for better results\nunder limited GPU memory. Second, we design a novel Pair Loss to mitigate\nconfusion caused by symmetrical and similar anatomical structures. It separates\nthe hidden classification task from the landmark localization task and thus\nprogressively eases model learning. Last, we propose a shape priors-based\nself-supervised learning by selecting the relatively stable landmarks to refine\nthe pose online. Extensive experiments and diverse applications on a\nlarge-scale fetal US dataset including 1000 volumes with 22 landmarks per\nvolume demonstrate that our method outperforms other strong competitors.",
            "author": [
                "Chaoyu Chen",
                "Xin Yang",
                "Yuhao Huang",
                "Wenlong Shi",
                "Yan Cao",
                "Mingyuan Luo",
                "Xindi Hu",
                "Lei Zhue",
                "Lequan Yu",
                "Kejuan Yue",
                "Yuanji Zhang",
                "Yi Xiong",
                "Dong Ni",
                "Weijun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19293v1",
                "http://arxiv.org/pdf/2310.19293v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19291v2",
            "title": "A3SA: Advanced Data Augmentation via Adjoint Sensitivity Analysis",
            "updated": "2023-11-06T05:54:31Z",
            "published": "2023-10-30T06:12:44Z",
            "summary": "Innovative machine learning techniques have facilitated the inverse design of\nphotonic structures for numerous practical applications. Nevertheless, within\nthese approaches, the quantity of data and the initial data distribution are\nparamount for the discovery of highly efficient photonic devices. These devices\noften require simulated data ranging from thousands to several hundred thousand\ndata points. This issue has consistently posed a major hurdle in machine\nlearning-based photonic design problems. Therefore, we propose a novel data\naugmentation algorithm grounded in the adjoint method, capable of generating\nmore than 300 times the amount of original data while enhancing device\nefficiency. The adjoint method forecasts changes in the figure of merit (FoM)\nresulting from structural perturbations, requiring only two full-wave Maxwell\nsimulations for this prediction. By leveraging the adjoint gradient values, we\ncan augment and label several thousand new data points without any additional\ncomputations. Furthermore, the augmented data generated by the proposed\nalgorithm displays significantly improved FoMs owing to the precise FoM change\npredictions enabled by the adjoint gradients. We apply this algorithm to a\nmulti-layered metalens design problem and demonstrate that it consequently\nexhibits a 343-fold increase in data generation efficiency. After incorporating\nthe proposed algorithm into a generative adversarial network (GAN), the\noptimized metalens exhibits a maximum focusing efficiency of 92.93%, comparable\nto the theoretical upper bound (93.80%).",
            "author": [
                "Chanik Kang",
                "Dongjin Seo",
                "Svetlana V Boriskina",
                "Haejun Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19291v2",
                "http://arxiv.org/pdf/2310.19291v2"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19290v1",
            "title": "Analyzing eyebrow region for morphed image detection",
            "updated": "2023-10-30T06:11:27Z",
            "published": "2023-10-30T06:11:27Z",
            "summary": "Facial images in passports are designated as primary identifiers for the\nverification of travelers according to the International Civil Aviation\nOrganization (ICAO). Hence, it is important to ascertain the sanctity of the\nfacial images stored in the electronic Machine-Readable Travel Document\n(eMRTD). With the introduction of automated border control (ABC) systems that\nrely on face recognition for the verification of travelers, it is even more\ncrucial to have a system to ensure that the image stored in the eMRTD is free\nfrom any alteration that can hinder or abuse the normal working of a facial\nrecognition system. One such attack against these systems is the face-morphing\nattack. Even though many techniques exist to detect morphed images, morphing\nalgorithms are also improving to evade these detections. In this work, we\nanalyze the eyebrow region for morphed image detection. The proposed method is\nbased on analyzing the frequency content of the eyebrow region. The method was\nevaluated on two datasets that each consisted of morphed images created using\ntwo algorithms. The findings suggest that the proposed method can serve as a\nvaluable tool in morphed image detection, and can be used in various\napplications where image authenticity is critical.",
            "author": [
                "Abdullah Zafar",
                "Christoph Busch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19290v1",
                "http://arxiv.org/pdf/2310.19290v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19289v1",
            "title": "AMLNet: Adversarial Mutual Learning Neural Network for\n  Non-AutoRegressive Multi-Horizon Time Series Forecasting",
            "updated": "2023-10-30T06:10:00Z",
            "published": "2023-10-30T06:10:00Z",
            "summary": "Multi-horizon time series forecasting, crucial across diverse domains,\ndemands high accuracy and speed. While AutoRegressive (AR) models excel in\nshort-term predictions, they suffer speed and error issues as the horizon\nextends. Non-AutoRegressive (NAR) models suit long-term predictions but\nstruggle with interdependence, yielding unrealistic results. We introduce\nAMLNet, an innovative NAR model that achieves realistic forecasts through an\nonline Knowledge Distillation (KD) approach. AMLNet harnesses the strengths of\nboth AR and NAR models by training a deep AR decoder and a deep NAR decoder in\na collaborative manner, serving as ensemble teachers that impart knowledge to a\nshallower NAR decoder. This knowledge transfer is facilitated through two key\nmechanisms: 1) outcome-driven KD, which dynamically weights the contribution of\nKD losses from the teacher models, enabling the shallow NAR decoder to\nincorporate the ensemble's diversity; and 2) hint-driven KD, which employs\nadversarial training to extract valuable insights from the model's hidden\nstates for distillation. Extensive experimentation showcases AMLNet's\nsuperiority over conventional AR and NAR models, thereby presenting a promising\navenue for multi-horizon time series forecasting that enhances accuracy and\nexpedites computation.",
            "author": [
                "Yang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19289v1",
                "http://arxiv.org/pdf/2310.19289v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19287v1",
            "title": "Enhancing Scalability and Reliability in Semi-Decentralized Federated\n  Learning With Blockchain: Trust Penalization and Asynchronous Functionality",
            "updated": "2023-10-30T06:05:50Z",
            "published": "2023-10-30T06:05:50Z",
            "summary": "The paper presents an innovative approach to address the challenges of\nscalability and reliability in Distributed Federated Learning by leveraging the\nintegration of blockchain technology. The paper focuses on enhancing the\ntrustworthiness of participating nodes through a trust penalization mechanism\nwhile also enabling asynchronous functionality for efficient and robust model\nupdates. By combining Semi-Decentralized Federated Learning with Blockchain\n(SDFL-B), the proposed system aims to create a fair, secure and transparent\nenvironment for collaborative machine learning without compromising data\nprivacy. The research presents a comprehensive system architecture,\nmethodologies, experimental results, and discussions that demonstrate the\nadvantages of this novel approach in fostering scalable and reliable SDFL-B\nsystems.",
            "author": [
                "Ajay Kumar Shrestha",
                "Faijan Ahamad Khan",
                "Mohammed Afaan Shaikh",
                "Amir Jaberzadeh",
                "Jason Geng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19287v1",
                "http://arxiv.org/pdf/2310.19287v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19285v1",
            "title": "Facilitating Graph Neural Networks with Random Walk on Simplicial\n  Complexes",
            "updated": "2023-10-30T06:03:34Z",
            "published": "2023-10-30T06:03:34Z",
            "summary": "Node-level random walk has been widely used to improve Graph Neural Networks.\nHowever, there is limited attention to random walk on edge and, more generally,\non $k$-simplices. This paper systematically analyzes how random walk on\ndifferent orders of simplicial complexes (SC) facilitates GNNs in their\ntheoretical expressivity. First, on $0$-simplices or node level, we establish a\nconnection between existing positional encoding (PE) and structure encoding\n(SE) methods through the bridge of random walk. Second, on $1$-simplices or\nedge level, we bridge edge-level random walk and Hodge $1$-Laplacians and\ndesign corresponding edge PE respectively. In the spatial domain, we directly\nmake use of edge level random walk to construct EdgeRWSE. Based on the spectral\nanalysis of Hodge $1$-Laplcians, we propose Hodge1Lap, a permutation\nequivariant and expressive edge-level positional encoding. Third, we generalize\nour theory to random walk on higher-order simplices and propose the general\nprinciple to design PE on simplices based on random walk and Hodge Laplacians.\nInter-level random walk is also introduced to unify a wide range of simplicial\nnetworks. Extensive experiments verify the effectiveness of our random\nwalk-based methods.",
            "author": [
                "Cai Zhou",
                "Xiyuan Wang",
                "Muhan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19285v1",
                "http://arxiv.org/pdf/2310.19285v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19283v2",
            "title": "rTsfNet: a DNN model with Multi-head 3D Rotation and Time Series Feature\n  Extraction for IMU-based Human Activity Recognition",
            "updated": "2023-11-01T06:01:12Z",
            "published": "2023-10-30T05:51:50Z",
            "summary": "This paper proposes rTsfNet, a DNN model with Multi-head 3D Rotation and Time\nSeries Feature Extraction, as a new DNN model for IMU-based human activity\nrecognition (HAR). rTsfNet automatically selects 3D bases from which features\nshould be derived by deriving 3D rotation parameters within the DNN. Then, time\nseries features (TSFs), the wisdom of many researchers, are derived and realize\nHAR using MLP. Although a model that does not use CNN, it achieved the highest\naccuracy than existing models under well-managed benchmark conditions and\nmultiple datasets: UCI HAR, PAMAP2, Daphnet, and OPPORTUNITY, which target\ndifferent activities.",
            "author": [
                "Yu Enokibori"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19283v2",
                "http://arxiv.org/pdf/2310.19283v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19276v1",
            "title": "Machine Learning Regularization for the Minimum Volume Formula of Toric\n  Calabi-Yau 3-folds",
            "updated": "2023-10-30T05:25:50Z",
            "published": "2023-10-30T05:25:50Z",
            "summary": "We present a collection of explicit formulas for the minimum volume of\nSasaki-Einstein 5-manifolds. The cone over these 5-manifolds is a toric\nCalabi-Yau 3-fold. These toric Calabi-Yau 3-folds are associated with an\ninfinite class of 4d N=1 supersymmetric gauge theories, which are realized as\nworldvolume theories of D3-branes probing the toric Calabi-Yau 3-folds. Under\nthe AdS/CFT correspondence, the minimum volume of the Sasaki-Einstein base is\ninversely proportional to the central charge of the corresponding 4d N=1\nsuperconformal field theories. The presented formulas for the minimum volume\nare in terms of geometric invariants of the toric Calabi-Yau 3-folds. These\nexplicit results are derived by implementing machine learning regularization\ntechniques that advance beyond previous applications of machine learning for\ndetermining the minimum volume. Moreover, the use of machine learning\nregularization allows us to present interpretable and explainable formulas for\nthe minimum volume. Our work confirms that, even for extensive sets of toric\nCalabi-Yau 3-folds, the proposed formulas approximate the minimum volume with\nremarkable accuracy.",
            "author": [
                "Eugene Choi",
                "Rak-Kyeong Seong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19276v1",
                "http://arxiv.org/pdf/2310.19276v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cs.LG",
                "math-ph",
                "math.AG",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19274v2",
            "title": "Prediction of Effective Elastic Moduli of Rocks using Graph Neural\n  Networks",
            "updated": "2023-11-22T18:27:15Z",
            "published": "2023-10-30T05:13:58Z",
            "summary": "This study presents a Graph Neural Networks (GNNs)-based approach for\npredicting the effective elastic moduli of rocks from their digital CT-scan\nimages. We use the Mapper algorithm to transform 3D digital rock images into\ngraph datasets, encapsulating essential geometrical information. These graphs,\nafter training, prove effective in predicting elastic moduli. Our GNN model\nshows robust predictive capabilities across various graph sizes derived from\nvarious subcube dimensions. Not only does it perform well on the test dataset,\nbut it also maintains high prediction accuracy for unseen rocks and unexplored\nsubcube sizes. Comparative analysis with Convolutional Neural Networks (CNNs)\nreveals the superior performance of GNNs in predicting unseen rock properties.\nMoreover, the graph representation of microstructures significantly reduces GPU\nmemory requirements (compared to the grid representation for CNNs), enabling\ngreater flexibility in the batch size selection. This work demonstrates the\npotential of GNN models in enhancing the prediction accuracy of rock properties\nand boosting the efficiency of digital rock analysis.",
            "author": [
                "Jaehong Chung",
                "Rasool Ahmad",
                "WaiChing Sun",
                "Wei Cai",
                "Tapan Mukerji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19274v2",
                "http://arxiv.org/pdf/2310.19274v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.comp-ph",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19273v1",
            "title": "The Memory Perturbation Equation: Understanding Model's Sensitivity to\n  Data",
            "updated": "2023-10-30T05:12:24Z",
            "published": "2023-10-30T05:12:24Z",
            "summary": "Understanding model's sensitivity to its training data is crucial but can\nalso be challenging and costly, especially during training. To simplify such\nissues, we present the Memory-Perturbation Equation (MPE) which relates model's\nsensitivity to perturbation in its training data. Derived using Bayesian\nprinciples, the MPE unifies existing sensitivity measures, generalizes them to\na wide-variety of models and algorithms, and unravels useful properties\nregarding sensitivities. Our empirical results show that sensitivity estimates\nobtained during training can be used to faithfully predict generalization on\nunseen test data. The proposed equation is expected to be useful for future\nresearch on robust and adaptive learning.",
            "author": [
                "Peter Nickl",
                "Lu Xu",
                "Dharmesh Tailor",
                "Thomas M\u00f6llenhoff",
                "Mohammad Emtiyaz Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19273v1",
                "http://arxiv.org/pdf/2310.19273v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19272v1",
            "title": "NPCL: Neural Processes for Uncertainty-Aware Continual Learning",
            "updated": "2023-10-30T05:10:00Z",
            "published": "2023-10-30T05:10:00Z",
            "summary": "Continual learning (CL) aims to train deep neural networks efficiently on\nstreaming data while limiting the forgetting caused by new tasks. However,\nlearning transferable knowledge with less interference between tasks is\ndifficult, and real-world deployment of CL models is limited by their inability\nto measure predictive uncertainties. To address these issues, we propose\nhandling CL tasks with neural processes (NPs), a class of meta-learners that\nencode different tasks into probabilistic distributions over functions all\nwhile providing reliable uncertainty estimates. Specifically, we propose an\nNP-based CL approach (NPCL) with task-specific modules arranged in a\nhierarchical latent variable model. We tailor regularizers on the learned\nlatent distributions to alleviate forgetting. The uncertainty estimation\ncapabilities of the NPCL can also be used to handle the task head/module\ninference challenge in CL. Our experiments show that the NPCL outperforms\nprevious CL approaches. We validate the effectiveness of uncertainty estimation\nin the NPCL for identifying novel data and evaluating instance-level model\nconfidence. Code is available at \\url{https://github.com/srvCodes/NPCL}.",
            "author": [
                "Saurav Jha",
                "Dong Gong",
                "He Zhao",
                "Lina Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19272v1",
                "http://arxiv.org/pdf/2310.19272v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19271v1",
            "title": "Learning to love diligent trolls: Accounting for rater effects in the\n  dialogue safety task",
            "updated": "2023-10-30T05:08:23Z",
            "published": "2023-10-30T05:08:23Z",
            "summary": "Chatbots have the risk of generating offensive utterances, which must be\navoided. Post-deployment, one way for a chatbot to continuously improve is to\nsource utterance/label pairs from feedback by live users. However, among users\nare trolls, who provide training examples with incorrect labels. To de-troll\ntraining data, previous work removed training examples that have high\nuser-aggregated cross-validation (CV) error. However, CV is expensive; and in a\ncoordinated attack, CV may be overwhelmed by trolls in number and in\nconsistency among themselves. In the present work, I address both limitations\nby proposing a solution inspired by methodology in automated essay scoring\n(AES): have multiple users rate each utterance, then perform latent class\nanalysis (LCA) to infer correct labels. As it does not require GPU\ncomputations, LCA is inexpensive. In experiments, I found that the AES-like\nsolution can infer training labels with high accuracy when trolls are\nconsistent, even when trolls are the majority.",
            "author": [
                "Michael John Ilagan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19271v1",
                "http://arxiv.org/pdf/2310.19271v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19270v1",
            "title": "Invariant kernels on Riemannian symmetric spaces: a harmonic-analytic\n  approach",
            "updated": "2023-10-30T05:06:52Z",
            "published": "2023-10-30T05:06:52Z",
            "summary": "This work aims to prove that the classical Gaussian kernel, when defined on a\nnon-Euclidean symmetric space, is never positive-definite for any choice of\nparameter. To achieve this goal, the paper develops new geometric and\nanalytical arguments. These provide a rigorous characterization of the\npositive-definiteness of the Gaussian kernel, which is complete but for a\nlimited number of scenarios in low dimensions that are treated by numerical\ncomputations. Chief among these results are the L$^{\\!\\scriptscriptstyle\np}$-$\\hspace{0.02cm}$Godement theorems (where $p = 1,2$), which provide\nverifiable necessary and sufficient conditions for a kernel defined on a\nsymmetric space of non-compact type to be positive-definite. A celebrated\ntheorem, sometimes called the Bochner-Godement theorem, already gives such\nconditions and is far more general in its scope, but is especially hard to\napply. Beyond the connection with the Gaussian kernel, the new results in this\nwork lay out a blueprint for the study of invariant kernels on symmetric\nspaces, bringing forth specific harmonic analysis tools that suggest many\nfuture applications.",
            "author": [
                "Nathael Da Costa",
                "Cyrus Mostajeran",
                "Juan-Pablo Ortega",
                "Salem Said"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19270v1",
                "http://arxiv.org/pdf/2310.19270v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.DG",
                "stat.ML",
                "43A35, 43A85, 43A90, 46E22, 53C35, 53Z50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19263v1",
            "title": "A Metadata-Driven Approach to Understand Graph Neural Networks",
            "updated": "2023-10-30T04:25:02Z",
            "published": "2023-10-30T04:25:02Z",
            "summary": "Graph Neural Networks (GNNs) have achieved remarkable success in various\napplications, but their performance can be sensitive to specific data\nproperties of the graph datasets they operate on. Current literature on\nunderstanding the limitations of GNNs has primarily employed a\n$\\textit{model-driven}$ approach that leverage heuristics and domain knowledge\nfrom network science or graph theory to model the GNN behaviors, which is\ntime-consuming and highly subjective. In this work, we propose a\n$\\textit{metadata-driven}$ approach to analyze the sensitivity of GNNs to graph\ndata properties, motivated by the increasing availability of graph learning\nbenchmarks. We perform a multivariate sparse regression analysis on the\nmetadata derived from benchmarking GNN performance across diverse datasets,\nyielding a set of salient data properties. To validate the effectiveness of our\ndata-driven approach, we focus on one identified data property, the degree\ndistribution, and investigate how this property influences GNN performance\nthrough theoretical analysis and controlled experiments. Our theoretical\nfindings reveal that datasets with more balanced degree distribution exhibit\nbetter linear separability of node representations, thus leading to better GNN\nperformance. We also conduct controlled experiments using synthetic datasets\nwith varying degree distributions, and the results align well with our\ntheoretical findings. Collectively, both the theoretical analysis and\ncontrolled experiments verify that the proposed metadata-driven approach is\neffective in identifying critical data properties for GNNs.",
            "author": [
                "Ting Wei Li",
                "Qiaozhu Mei",
                "Jiaqi Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19263v1",
                "http://arxiv.org/pdf/2310.19263v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19261v1",
            "title": "Diversify & Conquer: Outcome-directed Curriculum RL via\n  Out-of-Distribution Disagreement",
            "updated": "2023-10-30T04:12:19Z",
            "published": "2023-10-30T04:12:19Z",
            "summary": "Reinforcement learning (RL) often faces the challenges of uninformed search\nproblems where the agent should explore without access to the domain knowledge\nsuch as characteristics of the environment or external rewards. To tackle these\nchallenges, this work proposes a new approach for curriculum RL called\nDiversify for Disagreement & Conquer (D2C). Unlike previous curriculum learning\nmethods, D2C requires only a few examples of desired outcomes and works in any\nenvironment, regardless of its geometry or the distribution of the desired\noutcome examples. The proposed method performs diversification of the\ngoal-conditional classifiers to identify similarities between visited and\ndesired outcome states and ensures that the classifiers disagree on states from\nout-of-distribution, which enables quantifying the unexplored region and\ndesigning an arbitrary goal-conditioned intrinsic reward signal in a simple and\nintuitive way. The proposed method then employs bipartite matching to define a\ncurriculum learning objective that produces a sequence of well-adjusted\nintermediate goals, which enable the agent to automatically explore and conquer\nthe unexplored region. We present experimental results demonstrating that D2C\noutperforms prior curriculum RL methods in both quantitative and qualitative\naspects, even with the arbitrarily distributed desired outcome examples.",
            "author": [
                "Daesol Cho",
                "Seungjae Lee",
                "H. Jin Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19261v1",
                "http://arxiv.org/pdf/2310.19261v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19253v2",
            "title": "Flow-based distributionally robust optimization",
            "updated": "2023-11-07T02:09:17Z",
            "published": "2023-10-30T03:53:31Z",
            "summary": "We present a computationally efficient framework, called FlowDRO, for solving\nflow-based distributionally robust optimization (DRO) problems with Wasserstein\nuncertainty sets while aiming to find continuous worst-case distribution (also\ncalled the Least Favorable Distribution, LFD). The requirement for LFD to be\ncontinuous is so that the algorithm can be scalable to problems with larger\nsample sizes and achieve better generalization capability for the induced\nrobust algorithms. To tackle the computationally challenging infinitely\ndimensional optimization problem, we leverage flow-based models and\ncontinuous-time invertible transport maps between the data distribution and the\ntarget distribution. We also develop a Wasserstein proximal gradient flow type\nof algorithm. In theory, we establish the equivalence of the solution by\noptimal transport map to the original formulation, as well as the dual form of\nthe problem through Wasserstein calculus and Brenier theorem. In practice, we\nparameterize the transport maps by a sequence of neural networks progressively\ntrained in blocks by gradient descent. Our computational framework is general,\ncan handle high-dimensional data with large sample sizes, and can be useful for\nvarious applications. We demonstrate its usage in adversarial learning,\ndistributionally robust hypothesis testing, and a new mechanism for data-driven\ndistribution perturbation differential privacy, where the proposed method gives\nstrong empirical performance on real high-dimensional data.",
            "author": [
                "Chen Xu",
                "Jonghyeok Lee",
                "Xiuyuan Cheng",
                "Yao Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19253v2",
                "http://arxiv.org/pdf/2310.19253v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19252v1",
            "title": "Revisiting Evaluation Metrics for Semantic Segmentation: Optimization\n  and Evaluation of Fine-grained Intersection over Union",
            "updated": "2023-10-30T03:45:15Z",
            "published": "2023-10-30T03:45:15Z",
            "summary": "Semantic segmentation datasets often exhibit two types of imbalance:\n\\textit{class imbalance}, where some classes appear more frequently than others\nand \\textit{size imbalance}, where some objects occupy more pixels than others.\nThis causes traditional evaluation metrics to be biased towards\n\\textit{majority classes} (e.g. overall pixel-wise accuracy) and \\textit{large\nobjects} (e.g. mean pixel-wise accuracy and per-dataset mean intersection over\nunion). To address these shortcomings, we propose the use of fine-grained mIoUs\nalong with corresponding worst-case metrics, thereby offering a more holistic\nevaluation of segmentation techniques. These fine-grained metrics offer less\nbias towards large objects, richer statistical information, and valuable\ninsights into model and dataset auditing. Furthermore, we undertake an\nextensive benchmark study, where we train and evaluate 15 modern neural\nnetworks with the proposed metrics on 12 diverse natural and aerial\nsegmentation datasets. Our benchmark study highlights the necessity of not\nbasing evaluations on a single metric and confirms that fine-grained mIoUs\nreduce the bias towards large objects. Moreover, we identify the crucial role\nplayed by architecture designs and loss functions, which lead to best practices\nin optimizing fine-grained metrics. The code is available at\n\\href{https://github.com/zifuwanggg/JDTLosses}{https://github.com/zifuwanggg/JDTLosses}.",
            "author": [
                "Zifu Wang",
                "Maxim Berman",
                "Amal Rannen-Triki",
                "Philip H. S. Torr",
                "Devis Tuia",
                "Tinne Tuytelaars",
                "Luc Van Gool",
                "Jiaqian Yu",
                "Matthew B. Blaschko"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19252v1",
                "http://arxiv.org/pdf/2310.19252v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19251v1",
            "title": "Pre-trained Recommender Systems: A Causal Debiasing Perspective",
            "updated": "2023-10-30T03:37:32Z",
            "published": "2023-10-30T03:37:32Z",
            "summary": "Recent studies on pre-trained vision/language models have demonstrated the\npractical benefit of a new, promising solution-building paradigm in AI where\nmodels can be pre-trained on broad data describing a generic task space and\nthen adapted successfully to solve a wide range of downstream tasks, even when\ntraining data is severely limited (e.g., in zero- or few-shot learning\nscenarios). Inspired by such progress, we investigate in this paper the\npossibilities and challenges of adapting such a paradigm to the context of\nrecommender systems, which is less investigated from the perspective of\npre-trained model. In particular, we propose to develop a generic recommender\nthat captures universal interaction patterns by training on generic user-item\ninteraction data extracted from different domains, which can then be fast\nadapted to improve few-shot learning performance in unseen new domains (with\nlimited data).\n  However, unlike vision/language data which share strong conformity in the\nsemantic space, universal patterns underlying recommendation data collected\nacross different domains (e.g., different countries or different E-commerce\nplatforms) are often occluded by both in-domain and cross-domain biases\nimplicitly imposed by the cultural differences in their user and item bases, as\nwell as their uses of different e-commerce platforms. As shown in our\nexperiments, such heterogeneous biases in the data tend to hinder the\neffectiveness of the pre-trained model. To address this challenge, we further\nintroduce and formalize a causal debiasing perspective, which is substantiated\nvia a hierarchical Bayesian deep learning model, named PreRec. Our empirical\nstudies on real-world data show that the proposed model could significantly\nimprove the recommendation performance in zero- and few-shot learning settings\nunder both cross-market and cross-platform scenarios.",
            "author": [
                "Ziqian Lin",
                "Hao Ding",
                "Nghia Hoang",
                "Branislav Kveton",
                "Anoop Deoras",
                "Hao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19251v1",
                "http://arxiv.org/pdf/2310.19251v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19250v1",
            "title": "Assessment of Differentially Private Synthetic Data for Utility and\n  Fairness in End-to-End Machine Learning Pipelines for Tabular Data",
            "updated": "2023-10-30T03:37:16Z",
            "published": "2023-10-30T03:37:16Z",
            "summary": "Differentially private (DP) synthetic data sets are a solution for sharing\ndata while preserving the privacy of individual data providers. Understanding\nthe effects of utilizing DP synthetic data in end-to-end machine learning\npipelines impacts areas such as health care and humanitarian action, where data\nis scarce and regulated by restrictive privacy laws. In this work, we\ninvestigate the extent to which synthetic data can replace real, tabular data\nin machine learning pipelines and identify the most effective synthetic data\ngeneration techniques for training and evaluating machine learning models. We\ninvestigate the impacts of differentially private synthetic data on downstream\nclassification tasks from the point of view of utility as well as fairness. Our\nanalysis is comprehensive and includes representatives of the two main types of\nsynthetic data generation algorithms: marginal-based and GAN-based. To the best\nof our knowledge, our work is the first that: (i) proposes a training and\nevaluation framework that does not assume that real data is available for\ntesting the utility and fairness of machine learning models trained on\nsynthetic data; (ii) presents the most extensive analysis of synthetic data set\ngeneration algorithms in terms of utility and fairness when used for training\nmachine learning models; and (iii) encompasses several different definitions of\nfairness. Our findings demonstrate that marginal-based synthetic data\ngenerators surpass GAN-based ones regarding model training utility for tabular\ndata. Indeed, we show that models trained using data generated by\nmarginal-based algorithms can exhibit similar utility to models trained using\nreal data. Our analysis also reveals that the marginal-based synthetic data\ngenerator MWEM PGM can train models that simultaneously achieve utility and\nfairness characteristics close to those obtained by models trained with real\ndata.",
            "author": [
                "Mayana Pereira",
                "Meghana Kshirsagar",
                "Sumit Mukherjee",
                "Rahul Dodhia",
                "Juan Lavista Ferres",
                "Rafael de Sousa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19250v1",
                "http://arxiv.org/pdf/2310.19250v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19248v1",
            "title": "IMPRESS: Evaluating the Resilience of Imperceptible Perturbations\n  Against Unauthorized Data Usage in Diffusion-Based Generative AI",
            "updated": "2023-10-30T03:33:41Z",
            "published": "2023-10-30T03:33:41Z",
            "summary": "Diffusion-based image generation models, such as Stable Diffusion or DALL-E\n2, are able to learn from given images and generate high-quality samples\nfollowing the guidance from prompts. For instance, they can be used to create\nartistic images that mimic the style of an artist based on his/her original\nartworks or to maliciously edit the original images for fake content. However,\nsuch ability also brings serious ethical issues without proper authorization\nfrom the owner of the original images. In response, several attempts have been\nmade to protect the original images from such unauthorized data usage by adding\nimperceptible perturbations, which are designed to mislead the diffusion model\nand make it unable to properly generate new samples. In this work, we introduce\na perturbation purification platform, named IMPRESS, to evaluate the\neffectiveness of imperceptible perturbations as a protective measure. IMPRESS\nis based on the key observation that imperceptible perturbations could lead to\na perceptible inconsistency between the original image and the\ndiffusion-reconstructed image, which can be used to devise a new optimization\nstrategy for purifying the image, which may weaken the protection of the\noriginal image from unauthorized data usage (e.g., style mimicking, malicious\nediting). The proposed IMPRESS platform offers a comprehensive evaluation of\nseveral contemporary protection methods, and can be used as an evaluation\nplatform for future protection methods.",
            "author": [
                "Bochuan Cao",
                "Changjiang Li",
                "Ting Wang",
                "Jinyuan Jia",
                "Bo Li",
                "Jinghui Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19248v1",
                "http://arxiv.org/pdf/2310.19248v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19247v1",
            "title": "Uncertainty-guided Boundary Learning for Imbalanced Social Event\n  Detection",
            "updated": "2023-10-30T03:32:04Z",
            "published": "2023-10-30T03:32:04Z",
            "summary": "Real-world social events typically exhibit a severe class-imbalance\ndistribution, which makes the trained detection model encounter a serious\ngeneralization challenge. Most studies solve this problem from the frequency\nperspective and emphasize the representation or classifier learning for tail\nclasses. While in our observation, compared to the rarity of classes, the\ncalibrated uncertainty estimated from well-trained evidential deep learning\nnetworks better reflects model performance. To this end, we propose a novel\nuncertainty-guided class imbalance learning framework - UCL$_{SED}$, and its\nvariant - UCL-EC$_{SED}$, for imbalanced social event detection tasks. We aim\nto improve the overall model performance by enhancing model generalization to\nthose uncertain classes. Considering performance degradation usually comes from\nmisclassifying samples as their confusing neighboring classes, we focus on\nboundary learning in latent space and classifier learning with high-quality\nuncertainty estimation. First, we design a novel uncertainty-guided contrastive\nlearning loss, namely UCL and its variant - UCL-EC, to manipulate\ndistinguishable representation distribution for imbalanced data. During\ntraining, they force all classes, especially uncertain ones, to adaptively\nadjust a clear separable boundary in the feature space. Second, to obtain more\nrobust and accurate class uncertainty, we combine the results of multi-view\nevidential classifiers via the Dempster-Shafer theory under the supervision of\nan additional calibration method. We conduct experiments on three severely\nimbalanced social event datasets including Events2012\\_100, Events2018\\_100,\nand CrisisLexT\\_7. Our model significantly improves social event representation\nand classification tasks in almost all classes, especially those uncertain\nones.",
            "author": [
                "Jiaqian Ren",
                "Hao Peng",
                "Lei Jiang",
                "Zhiwei Liu",
                "Jia Wu",
                "Zhengtao Yu",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19247v1",
                "http://arxiv.org/pdf/2310.19247v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19246v1",
            "title": "A spectral regularisation framework for latent variable models designed\n  for single channel applications",
            "updated": "2023-10-30T03:24:54Z",
            "published": "2023-10-30T03:24:54Z",
            "summary": "Latent variable models (LVMs) are commonly used to capture the underlying\ndependencies, patterns, and hidden structure in observed data. Source\nduplication is a by-product of the data hankelisation pre-processing step\ncommon to single channel LVM applications, which hinders practical LVM\nutilisation. In this article, a Python package titled\nspectrally-regularised-LVMs is presented. The proposed package addresses the\nsource duplication issue via the addition of a novel spectral regularisation\nterm. This package provides a framework for spectral regularisation in single\nchannel LVM applications, thereby making it easier to investigate and utilise\nLVMs with spectral regularisation. This is achieved via the use of symbolic or\nexplicit representations of potential LVM objective functions which are\nincorporated into a framework that uses spectral regularisation during the LVM\nparameter estimation process. The objective of this package is to provide a\nconsistent linear LVM optimisation framework which incorporates spectral\nregularisation and caters to single channel time-series applications.",
            "author": [
                "Ryan Balshaw",
                "P. Stephan Heyns",
                "Daniel N. Wilke",
                "Stephan Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19246v1",
                "http://arxiv.org/pdf/2310.19246v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME",
                "60G35, 62M15, 62M10, 91B84, 49K45",
                "G.3; I.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16126v1",
            "title": "A Hierarchical Training Paradigm for Antibody Structure-sequence\n  Co-design",
            "updated": "2023-10-30T02:39:15Z",
            "published": "2023-10-30T02:39:15Z",
            "summary": "Therapeutic antibodies are an essential and rapidly expanding drug modality.\nThe binding specificity between antibodies and antigens is decided by\ncomplementarity-determining regions (CDRs) at the tips of these Y-shaped\nproteins. In this paper, we propose a hierarchical training paradigm (HTP) for\nthe antibody sequence-structure co-design. HTP consists of four levels of\ntraining stages, each corresponding to a specific protein modality within a\nparticular protein domain. Through carefully crafted tasks in different stages,\nHTP seamlessly and effectively integrates geometric graph neural networks\n(GNNs) with large-scale protein language models to excavate evolutionary\ninformation from not only geometric structures but also vast antibody and\nnon-antibody sequence databases, which determines ligand binding pose and\nstrength. Empirical experiments show that HTP sets the new state-of-the-art\nperformance in the co-design problem as well as the fix-backbone design. Our\nresearch offers a hopeful path to unleash the potential of deep generative\narchitectures and seeks to illuminate the way forward for the antibody sequence\nand structure co-design challenge.",
            "author": [
                "Fang Wu",
                "Stan Z. Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16126v1",
                "http://arxiv.org/pdf/2311.16126v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19232v1",
            "title": "Adapter Pruning using Tropical Characterization",
            "updated": "2023-10-30T02:20:44Z",
            "published": "2023-10-30T02:20:44Z",
            "summary": "Adapters are widely popular parameter-efficient transfer learning approaches\nin natural language processing that insert trainable modules in between layers\nof a pre-trained language model. Apart from several heuristics, however, there\nhas been a lack of studies analyzing the optimal number of adapter parameters\nneeded for downstream applications. In this paper, we propose an adapter\npruning approach by studying the tropical characteristics of trainable modules.\nWe cast it as an optimization problem that aims to prune parameters from the\nadapter layers without changing the orientation of underlying tropical\nhypersurfaces. Our experiments on five NLP datasets show that tropical geometry\ntends to identify more relevant parameters to prune when compared with the\nmagnitude-based baseline, while a combined approach works best across the\ntasks.",
            "author": [
                "Rishabh Bhardwaj",
                "Tushar Vaidya",
                "Soujanya Poria"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19232v1",
                "http://arxiv.org/pdf/2310.19232v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19231v1",
            "title": "There Are No Data Like More Data- Datasets for Deep Learning in Earth\n  Observation",
            "updated": "2023-10-30T02:19:16Z",
            "published": "2023-10-30T02:19:16Z",
            "summary": "Carefully curated and annotated datasets are the foundation of machine\nlearning, with particularly data-hungry deep neural networks forming the core\nof what is often called Artificial Intelligence (AI). Due to the massive\nsuccess of deep learning applied to Earth Observation (EO) problems, the focus\nof the community has been largely on the development of ever-more sophisticated\ndeep neural network architectures and training strategies largely ignoring the\noverall importance of datasets. For that purpose, numerous task-specific\ndatasets have been created that were largely ignored by previously published\nreview articles on AI for Earth observation. With this article, we want to\nchange the perspective and put machine learning datasets dedicated to Earth\nobservation data and applications into the spotlight. Based on a review of the\nhistorical developments, currently available resources are described and a\nperspective for future developments is formed. We hope to contribute to an\nunderstanding that the nature of our data is what distinguishes the Earth\nobservation community from many other communities that apply deep learning\ntechniques to image data, and that a detailed understanding of EO data\npeculiarities is among the core competencies of our discipline.",
            "author": [
                "Michael Schmitt",
                "Seyed Ali Ahmadi",
                "Yonghao Xu",
                "Gulsen Taskin",
                "Ujjwal Verma",
                "Francescopaolo Sica",
                "Ronny Hansch"
            ],
            "link": [
                "http://dx.doi.org/10.1109/MGRS.2023.3293459",
                "http://arxiv.org/abs/2310.19231v1",
                "http://arxiv.org/pdf/2310.19231v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19226v1",
            "title": "Knolling bot 2.0: Enhancing Object Organization with Self-supervised\n  Graspability Estimation",
            "updated": "2023-10-30T02:14:11Z",
            "published": "2023-10-30T02:14:11Z",
            "summary": "Building on recent advancements in transformer based approaches for domestic\nrobots performing knolling, the art of organizing scattered items into neat\narrangements. This paper introduces Knolling bot 2.0. Recognizing the\nchallenges posed by piles of objects or items situated closely together, this\nupgraded system incorporates a self-supervised graspability estimation model.\nIf objects are deemed ungraspable, an additional behavior will be executed to\nseparate the objects before knolling the table. By integrating this grasp\nprediction mechanism with existing visual perception and transformer based\nknolling models, an advanced system capable of decluttering and organizing even\nmore complex and densely populated table settings is demonstrated. Experimental\nevaluations demonstrate the effectiveness of this module, yielding a\ngraspability prediction accuracy of 95.7%.",
            "author": [
                "Yuhang Hu",
                "Zhizhuo Zhang",
                "Hod Lipson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19226v1",
                "http://arxiv.org/pdf/2310.19226v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19225v1",
            "title": "Stochastic Configuration Machines: FPGA Implementation",
            "updated": "2023-10-30T02:04:20Z",
            "published": "2023-10-30T02:04:20Z",
            "summary": "Neural networks for industrial applications generally have additional\nconstraints such as response speed, memory size and power usage. Randomized\nlearners can address some of these issues. However, hardware solutions can\nprovide better resource reduction whilst maintaining the model's performance.\nStochastic configuration networks (SCNs) are a prime choice in industrial\napplications due to their merits and feasibility for data modelling. Stochastic\nConfiguration Machines (SCMs) extend this to focus on reducing the memory\nconstraints by limiting the randomized weights to a binary value with a scalar\nfor each node and using a mechanism model to improve the learning performance\nand result interpretability. This paper aims to implement SCM models on a field\nprogrammable gate array (FPGA) and introduce binary-coded inputs to the\nalgorithm. Results are reported for two benchmark and two industrial datasets,\nincluding SCM with single-layer and deep architectures.",
            "author": [
                "Matthew J. Felicetti",
                "Dianhui Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19225v1",
                "http://arxiv.org/pdf/2310.19225v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19223v1",
            "title": "Modular Anti-noise Deep Learning Network for Robotic Grasp Detection\n  Based on RGB Images",
            "updated": "2023-10-30T02:01:49Z",
            "published": "2023-10-30T02:01:49Z",
            "summary": "While traditional methods relies on depth sensors, the current trend leans\ntowards utilizing cost-effective RGB images, despite their absence of depth\ncues. This paper introduces an interesting approach to detect grasping pose\nfrom a single RGB image. To this end, we propose a modular learning network\naugmented with grasp detection and semantic segmentation, tailored for robots\nequipped with parallel-plate grippers. Our network not only identifies\ngraspable objects but also fuses prior grasp analyses with semantic\nsegmentation, thereby boosting grasp detection precision. Significantly, our\ndesign exhibits resilience, adeptly handling blurred and noisy visuals. Key\ncontributions encompass a trainable network for grasp detection from RGB\nimages, a modular design facilitating feasible grasp implementation, and an\narchitecture robust against common image distortions. We demonstrate the\nfeasibility and accuracy of our proposed approach through practical experiments\nand evaluations.",
            "author": [
                "Zhaocong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19223v1",
                "http://arxiv.org/pdf/2310.19223v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19222v1",
            "title": "Maximum Knowledge Orthogonality Reconstruction with Gradients in\n  Federated Learning",
            "updated": "2023-10-30T02:01:48Z",
            "published": "2023-10-30T02:01:48Z",
            "summary": "Federated learning (FL) aims at keeping client data local to preserve\nprivacy. Instead of gathering the data itself, the server only collects\naggregated gradient updates from clients. Following the popularity of FL, there\nhas been considerable amount of work, revealing the vulnerability of FL\napproaches by reconstructing the input data from gradient updates. Yet, most\nexisting works assume an FL setting with unrealistically small batch size, and\nhave poor image quality when the batch size is large. Other works modify the\nneural network architectures or parameters to the point of being suspicious,\nand thus, can be detected by clients. Moreover, most of them can only\nreconstruct one sample input from a large batch. To address these limitations,\nwe propose a novel and completely analytical approach, referred to as the\nmaximum knowledge orthogonality reconstruction (MKOR), to reconstruct clients'\ninput data. Our proposed method reconstructs a mathematically proven high\nquality image from large batches. MKOR only requires the server to send\nsecretly modified parameters to clients and can efficiently and inconspicuously\nreconstruct the input images from clients' gradient updates. We evaluate MKOR's\nperformance on the MNIST, CIFAR-100, and ImageNet dataset and compare it with\nthe state-of-the-art works. The results show that MKOR outperforms the existing\napproaches, and draws attention to a pressing need for further research on the\nprivacy protection of FL so that comprehensive defense approaches can be\ndeveloped.",
            "author": [
                "Feng Wang",
                "Senem Velipasalar",
                "M. Cenk Gursoy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19222v1",
                "http://arxiv.org/pdf/2310.19222v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19220v1",
            "title": "From Stream to Pool: Dynamic Pricing Beyond i.i.d. Arrivals",
            "updated": "2023-10-30T01:53:37Z",
            "published": "2023-10-30T01:53:37Z",
            "summary": "The dynamic pricing problem has been extensively studied under the\n\\textbf{stream} model: A stream of customers arrives sequentially, each with an\nindependently and identically distributed valuation. However, this formulation\nis not entirely reflective of the real world. In many scenarios, high-valuation\ncustomers tend to make purchases earlier and leave the market, leading to a\n\\emph{shift} in the valuation distribution. Thus motivated, we consider a model\nwhere a \\textbf{pool} of $n$ non-strategic unit-demand customers interact\nrepeatedly with the seller. Each customer monitors the price intermittently\naccording to an independent Poisson process and makes a purchase if the\nobserved price is lower than her \\emph{private} valuation, whereupon she leaves\nthe market permanently. We present a minimax \\emph{optimal} algorithm that\nefficiently computes a non-adaptive policy which guarantees a $1/k$ fraction of\nthe optimal revenue, given any set of $k$ prices. Moreover, we present an\nadaptive \\emph{learn-then-earn} policy based on a novel \\emph{debiasing}\napproach, and prove an $\\tilde O(kn^{3/4})$ regret bound. We further improve\nthe bound to $\\tilde O(k^{3/4} n^{3/4})$ using martingale concentration\ninequalities.",
            "author": [
                "Titing Cui",
                "Su Jia",
                "Thomas Lavastida"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19220v1",
                "http://arxiv.org/pdf/2310.19220v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19218v2",
            "title": "A Survey of Federated Unlearning: A Taxonomy, Challenges and Future\n  Directions",
            "updated": "2023-11-09T18:26:11Z",
            "published": "2023-10-30T01:34:33Z",
            "summary": "With the development of trustworthy Federated Learning (FL), the requirement\nof implementing right to be forgotten gives rise to the area of Federated\nUnlearning (FU). Comparing to machine unlearning, a major challenge of FU lies\nin the decentralized and privacy-preserving nature of FL, in which clients\njointly train a global model without sharing their raw data, making it\nsubstantially more intricate to selectively unlearn specific information. In\nthat regard, many efforts have been made to tackle the challenges of FU and\nhave achieved significant progress. In this paper, we present a comprehensive\nsurvey of FU. Specially, we provide the existing algorithms, objectives,\nevaluation metrics, and identify some challenges of FU. By reviewing and\ncomparing some studies, we summarize them into a taxonomy for various schemes,\npotential applications and future directions.",
            "author": [
                "Jiaxi Yang",
                "Yang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19218v2",
                "http://arxiv.org/pdf/2310.19218v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19216v1",
            "title": "Optimal Status Updates for Minimizing Age of Correlated Information in\n  IoT Networks with Energy Harvesting Sensors",
            "updated": "2023-10-30T01:03:47Z",
            "published": "2023-10-30T01:03:47Z",
            "summary": "Many real-time applications of the Internet of Things (IoT) need to deal with\ncorrelated information generated by multiple sensors. The design of efficient\nstatus update strategies that minimize the Age of Correlated Information (AoCI)\nis a key factor. In this paper, we consider an IoT network consisting of\nsensors equipped with the energy harvesting (EH) capability. We optimize the\naverage AoCI at the data fusion center (DFC) by appropriately managing the\nenergy harvested by sensors, whose true battery states are unobservable during\nthe decision-making process. Particularly, we first formulate the dynamic\nstatus update procedure as a partially observable Markov decision process\n(POMDP), where the environmental dynamics are unknown to the DFC. In order to\naddress the challenges arising from the causality of energy usage, unknown\nenvironmental dynamics, unobservability of sensors'true battery states, and\nlarge-scale discrete action space, we devise a deep reinforcement learning\n(DRL)-based dynamic status update algorithm. The algorithm leverages the\nadvantages of the soft actor-critic and long short-term memory techniques.\nMeanwhile, it incorporates our proposed action decomposition and mapping\nmechanism. Extensive simulations are conducted to validate the effectiveness of\nour proposed algorithm by comparing it with available DRL algorithms for\nPOMDPs.",
            "author": [
                "Chao Xu",
                "Xinyan Zhang",
                "Howard H. Yang",
                "Xijun Wang",
                "Nikolaos Pappas",
                "Dusit Niyato",
                "Tony Q. S. Quek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19216v1",
                "http://arxiv.org/pdf/2310.19216v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19215v1",
            "title": "On the accuracy and efficiency of group-wise clipping in differentially\n  private optimization",
            "updated": "2023-10-30T01:01:15Z",
            "published": "2023-10-30T01:01:15Z",
            "summary": "Recent advances have substantially improved the accuracy, memory cost, and\ntraining speed of differentially private (DP) deep learning, especially on\nlarge vision and language models with millions to billions of parameters. In\nthis work, we thoroughly study the per-sample gradient clipping style, a key\ncomponent in DP optimization. We show that different clipping styles have the\nsame time complexity but instantiate an accuracy-memory trade-off: while the\nall-layer clipping (of coarse granularity) is the most prevalent and usually\ngives the best accuracy, it incurs heavier memory cost compared to other\ngroup-wise clipping, such as the layer-wise clipping (of finer granularity). We\nformalize this trade-off through our convergence theory and complexity\nanalysis. Importantly, we demonstrate that the accuracy gap between group-wise\nclipping and all-layer clipping becomes smaller for larger models, while the\nmemory advantage of the group-wise clipping remains. Consequently, the\ngroup-wise clipping allows DP optimization of large models to achieve high\naccuracy and low peak memory simultaneously.",
            "author": [
                "Zhiqi Bu",
                "Ruixuan Liu",
                "Yu-Xiang Wang",
                "Sheng Zha",
                "George Karypis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19215v1",
                "http://arxiv.org/pdf/2310.19215v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CC",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19214v1",
            "title": "Factor Fitting, Rank Allocation, and Partitioning in Multilevel Low Rank\n  Matrices",
            "updated": "2023-10-30T00:52:17Z",
            "published": "2023-10-30T00:52:17Z",
            "summary": "We consider multilevel low rank (MLR) matrices, defined as a row and column\npermutation of a sum of matrices, each one a block diagonal refinement of the\nprevious one, with all blocks low rank given in factored form. MLR matrices\nextend low rank matrices but share many of their properties, such as the total\nstorage required and complexity of matrix-vector multiplication. We address\nthree problems that arise in fitting a given matrix by an MLR matrix in the\nFrobenius norm. The first problem is factor fitting, where we adjust the\nfactors of the MLR matrix. The second is rank allocation, where we choose the\nranks of the blocks in each level, subject to the total rank having a given\nvalue, which preserves the total storage needed for the MLR matrix. The final\nproblem is to choose the hierarchical partition of rows and columns, along with\nthe ranks and factors. This paper is accompanied by an open source package that\nimplements the proposed methods.",
            "author": [
                "Tetiana Parshakova",
                "Trevor Hastie",
                "Eric Darve",
                "Stephen Boyd"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19214v1",
                "http://arxiv.org/pdf/2310.19214v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.MS",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19211v1",
            "title": "Investigative Pattern Detection Framework for Counterterrorism",
            "updated": "2023-10-30T00:45:05Z",
            "published": "2023-10-30T00:45:05Z",
            "summary": "Law-enforcement investigations aimed at preventing attacks by violent\nextremists have become increasingly important for public safety. The problem is\nexacerbated by the massive data volumes that need to be scanned to identify\ncomplex behaviors of extremists and groups. Automated tools are required to\nextract information to respond queries from analysts, continually scan new\ninformation, integrate them with past events, and then alert about emerging\nthreats. We address challenges in investigative pattern detection and develop\nan Investigative Pattern Detection Framework for Counterterrorism (INSPECT).\nThe framework integrates numerous computing tools that include machine learning\ntechniques to identify behavioral indicators and graph pattern matching\ntechniques to detect risk profiles/groups. INSPECT also automates multiple\ntasks for large-scale mining of detailed forensic biographies, forming\nknowledge networks, and querying for behavioral indicators and radicalization\ntrajectories. INSPECT targets human-in-the-loop mode of investigative search\nand has been validated and evaluated using an evolving dataset on domestic\njihadism.",
            "author": [
                "Shashika R. Muramudalige",
                "Benjamin W. K. Hung",
                "Rosanne Libretti",
                "Jytte Klausen",
                "Anura P. Jayasumana"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19211v1",
                "http://arxiv.org/pdf/2310.19211v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19210v1",
            "title": "Generalized Category Discovery with Clustering Assignment Consistency",
            "updated": "2023-10-30T00:32:47Z",
            "published": "2023-10-30T00:32:47Z",
            "summary": "Generalized category discovery (GCD) is a recently proposed open-world task.\nGiven a set of images consisting of labeled and unlabeled instances, the goal\nof GCD is to automatically cluster the unlabeled samples using information\ntransferred from the labeled dataset. The unlabeled dataset comprises both\nknown and novel classes. The main challenge is that unlabeled novel class\nsamples and unlabeled known class samples are mixed together in the unlabeled\ndataset. To address the GCD without knowing the class number of unlabeled\ndataset, we propose a co-training-based framework that encourages clustering\nconsistency. Specifically, we first introduce weak and strong augmentation\ntransformations to generate two sufficiently different views for the same\nsample. Then, based on the co-training assumption, we propose a consistency\nrepresentation learning strategy, which encourages consistency between\nfeature-prototype similarity and clustering assignment. Finally, we use the\ndiscriminative embeddings learned from the semi-supervised representation\nlearning process to construct an original sparse network and use a community\ndetection method to obtain the clustering results and the number of categories\nsimultaneously. Extensive experiments show that our method achieves\nstate-of-the-art performance on three generic benchmarks and three fine-grained\nvisual recognition datasets. Especially in the ImageNet-100 data set, our\nmethod significantly exceeds the best baseline by 15.5\\% and 7.0\\% on the\n\\texttt{Novel} and \\texttt{All} classes, respectively.",
            "author": [
                "Xiangli Yang",
                "Xinglin Pan",
                "Irwin King",
                "Zenglin Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19210v1",
                "http://arxiv.org/pdf/2310.19210v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19206v1",
            "title": "Leveraging generative artificial intelligence to simulate student\n  learning behavior",
            "updated": "2023-10-30T00:09:59Z",
            "published": "2023-10-30T00:09:59Z",
            "summary": "Student simulation presents a transformative approach to enhance learning\noutcomes, advance educational research, and ultimately shape the future of\neffective pedagogy. We explore the feasibility of using large language models\n(LLMs), a remarkable achievement in AI, to simulate student learning behaviors.\nUnlike conventional machine learning based prediction, we leverage LLMs to\ninstantiate virtual students with specific demographics and uncover intricate\ncorrelations among learning experiences, course materials, understanding\nlevels, and engagement. Our objective is not merely to predict learning\noutcomes but to replicate learning behaviors and patterns of real students. We\nvalidate this hypothesis through three experiments. The first experiment, based\non a dataset of N = 145, simulates student learning outcomes from demographic\ndata, revealing parallels with actual students concerning various demographic\nfactors. The second experiment (N = 4524) results in increasingly realistic\nsimulated behaviors with more assessment history for virtual students\nmodelling. The third experiment (N = 27), incorporating prior knowledge and\ncourse interactions, indicates a strong link between virtual students' learning\nbehaviors and fine-grained mappings from test questions, course materials,\nengagement and understanding levels. Collectively, these findings deepen our\nunderstanding of LLMs and demonstrate its viability for student simulation,\nempowering more adaptable curricula design to enhance inclusivity and\neducational effectiveness.",
            "author": [
                "Songlin Xu",
                "Xinyu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19206v1",
                "http://arxiv.org/pdf/2310.19206v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19202v1",
            "title": "Improved Motor Imagery Classification Using Adaptive Spatial Filters\n  Based on Particle Swarm Optimization Algorithm",
            "updated": "2023-10-29T23:53:37Z",
            "published": "2023-10-29T23:53:37Z",
            "summary": "As a typical self-paced brain-computer interface (BCI) system, the motor\nimagery (MI) BCI has been widely applied in fields such as robot control,\nstroke rehabilitation, and assistance for patients with stroke or spinal cord\ninjury. Many studies have focused on the traditional spatial filters obtained\nthrough the common spatial pattern (CSP) method. However, the CSP method can\nonly obtain fixed spatial filters for specific input signals. Besides, CSP\nmethod only focuses on the variance difference of two types of\nelectroencephalogram (EEG) signals, so the decoding ability of EEG signals is\nlimited. To obtain more effective spatial filters for better extraction of\nspatial features that can improve classification to MI-EEG, this paper proposes\nan adaptive spatial filter solving method based on particle swarm optimization\nalgorithm (PSO). A training and testing framework based on filter bank and\nspatial filters (FBCSP-ASP) is designed for MI EEG signal classification.\nComparative experiments are conducted on two public datasets (2a and 2b) from\nBCI competition IV, which show the outstanding average recognition accuracy of\nFBCSP-ASP. The proposed method has achieved significant performance improvement\non MI-BCI. The classification accuracy of the proposed method has reached\n74.61% and 81.19% on datasets 2a and 2b, respectively. Compared with the\nbaseline algorithm (FBCSP), the proposed algorithm improves 11.44% and 7.11% on\ntwo datasets respectively. Furthermore, the analysis based on mutual\ninformation, t-SNE and Shapley values further proves that ASP features have\nexcellent decoding ability for MI-EEG signals, and explains the improvement of\nclassification performance by the introduction of ASP features.",
            "author": [
                "Xiong Xiong",
                "Ying Wang",
                "Tianyuan Song",
                "Jinguo Huang",
                "Guixia Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19202v1",
                "http://arxiv.org/pdf/2310.19202v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19200v1",
            "title": "Popularity, face and voice: Predicting and interpreting livestreamers'\n  retail performance using machine learning techniques",
            "updated": "2023-10-29T23:48:34Z",
            "published": "2023-10-29T23:48:34Z",
            "summary": "Livestreaming commerce, a hybrid of e-commerce and self-media, has expanded\nthe broad spectrum of traditional sales performance determinants. To\ninvestigate the factors that contribute to the success of livestreaming\ncommerce, we construct a longitudinal firm-level database with 19,175\nobservations, covering an entire livestreaming subsector. By comparing the\nforecasting accuracy of eight machine learning models, we identify a random\nforest model that provides the best prediction of gross merchandise volume\n(GMV). Furthermore, we utilize explainable artificial intelligence to open the\nblack-box of machine learning model, discovering four new facts: 1) variables\nrepresenting the popularity of livestreaming events are crucial features in\npredicting GMV. And voice attributes are more important than appearance; 2)\npopularity is a major determinant of sales for female hosts, while vocal\naesthetics is more decisive for their male counterparts; 3) merits and\ndrawbacks of the voice are not equally valued in the livestreaming market; 4)\nbased on changes of comments, page views and likes, sales growth can be divided\ninto three stages. Finally, we innovatively propose a 3D-SHAP diagram that\ndemonstrates the relationship between predicting feature importance, target\nvariable, and its predictors. This diagram identifies bottlenecks for both\nbeginner and top livestreamers, providing insights into ways to optimize their\nsales performance.",
            "author": [
                "Xiong Xiong",
                "Fan Yang",
                "Li Su"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19200v1",
                "http://arxiv.org/pdf/2310.19200v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19198v1",
            "title": "Enhancing Motor Imagery Decoding in Brain Computer Interfaces using\n  Riemann Tangent Space Mapping and Cross Frequency Coupling",
            "updated": "2023-10-29T23:37:47Z",
            "published": "2023-10-29T23:37:47Z",
            "summary": "Objective: Motor Imagery (MI) serves as a crucial experimental paradigm\nwithin the realm of Brain Computer Interfaces (BCIs), aiming to decoding motor\nintentions from electroencephalogram (EEG) signals. Method: Drawing inspiration\nfrom Riemannian geometry and Cross-Frequency Coupling (CFC), this paper\nintroduces a novel approach termed Riemann Tangent Space Mapping using\nDichotomous Filter Bank with Convolutional Neural Network (DFBRTS) to enhance\nthe representation quality and decoding capability pertaining to MI features.\nDFBRTS first initiates the process by meticulously filtering EEG signals\nthrough a Dichotomous Filter Bank, structured in the fashion of a complete\nbinary tree. Subsequently, it employs Riemann Tangent Space Mapping to extract\nsalient EEG signal features within each sub-band. Finally, a lightweight\nconvolutional neural network is employed for further feature extraction and\nclassification, operating under the joint supervision of cross-entropy and\ncenter loss. To validate the efficacy, extensive experiments were conducted\nusing DFBRTS on two well-established benchmark datasets: the BCI competition IV\n2a (BCIC-IV-2a) dataset and the OpenBMI dataset. The performance of DFBRTS was\nbenchmarked against several state-of-the-art MI decoding methods, alongside\nother Riemannian geometry-based MI decoding approaches. Results: DFBRTS\nsignificantly outperforms other MI decoding algorithms on both datasets,\nachieving a remarkable classification accuracy of 78.16% for four-class and\n71.58% for two-class hold-out classification, as compared to the existing\nbenchmarks.",
            "author": [
                "Xiong Xiong",
                "Li Su",
                "Jinguo Huang",
                "Guixia Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19198v1",
                "http://arxiv.org/pdf/2310.19198v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19197v1",
            "title": "concrete: Targeted Estimation of Survival and Competing Risks in\n  Continuous Time",
            "updated": "2023-10-29T23:36:41Z",
            "published": "2023-10-29T23:36:41Z",
            "summary": "This article introduces the R package concrete, which implements a recently\ndeveloped targeted maximum likelihood estimator (TMLE) for the cause-specific\nabsolute risks of time-to-event outcomes measured in continuous time.\nCross-validated Super Learner machine learning ensembles are used to estimate\npropensity scores and conditional cause-specific hazards, which are then\ntargeted to produce robust and efficient plug-in estimates of the effects of\nstatic or dynamic interventions on a binary treatment given at baseline\nquantified as risk differences or risk ratios. Influence curve-based asymptotic\ninference is provided for TMLE estimates and simultaneous confidence bands can\nbe computed for target estimands spanning multiple multiple times or events. In\nthis paper we review the one-step continuous-time TMLE methodology as it is\nsituated in an overarching causal inference workflow, describe its\nimplementation, and demonstrate the use of the package on the PBC dataset.",
            "author": [
                "David Chen",
                "Helene C. W. Rytgaard",
                "Edwin C. H. Fong",
                "Jens M. Tarp",
                "Maya L. Petersen",
                "Mark J. van der Laan",
                "Thomas A. Gerds"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19197v1",
                "http://arxiv.org/pdf/2310.19197v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.02096v2",
            "title": "Variational Autoencoders for Noise Reduction in Industrial LLRF Systems",
            "updated": "2023-11-07T19:01:44Z",
            "published": "2023-10-29T23:29:49Z",
            "summary": "Industrial particle accelerators inherently operate in much dirtier\nenvironments than typical research accelerators. This leads to an increase in\nnoise both in the RF system and in other electronic systems. Combined with the\nfact that industrial accelerators are mass produced, there is less attention\ngiven to optimizing the performance of an individual system. As a result,\nindustrial systems tend to under perform considering their hardware hardware\ncapabilities. With the growing demand for accelerators for medical\nsterilization, food irradiation, cancer treatment, and imaging, improving the\nsignal processing of these machines will increase the margin for the deployment\nof these systems. Our work is focusing on using machine learning techniques to\nreduce the noise of RF signals used for pulse-to-pulse feedback in industrial\naccelerators. We will review our algorithms, simulation results, and results\nworking with measured data. We will then discuss next steps for deployment and\ntesting on an industrial system.",
            "author": [
                "J. P. Edelen",
                "M. J. Henderson",
                "J. Einstein-Curtis",
                "C. C. Hall",
                "J. A. Diaz Cruz",
                "A. L. Edelen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02096v2",
                "http://arxiv.org/pdf/2311.02096v2"
            ],
            "primary_category": "physics.acc-ph",
            "category": [
                "physics.acc-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.10931v1",
            "title": "FLORIDA: Fake-looking Real Images Dataset",
            "updated": "2023-10-29T23:25:10Z",
            "published": "2023-10-29T23:25:10Z",
            "summary": "Although extensive research has been carried out to evaluate the\neffectiveness of AI tools and models in detecting deep fakes, the question\nremains unanswered regarding whether these models can accurately identify\ngenuine images that appear artificial. In this study, as an initial step\ntowards addressing this issue, we have curated a dataset of 510 genuine images\nthat exhibit a fake appearance and conducted an assessment using two AI models.\nWe show that two models exhibited subpar performance when applied to our\ndataset. Additionally, our dataset can serve as a valuable tool for assessing\nthe ability of deep learning models to comprehend complex visual stimuli. We\nanticipate that this research will stimulate further discussions and\ninvestigations in this area. Our dataset is accessible at\nhttps://github.com/aliborji/FLORIDA.",
            "author": [
                "Ali Borji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10931v1",
                "http://arxiv.org/pdf/2311.10931v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19192v1",
            "title": "Conformal Normalization in Recurrent Neural Network of Grid Cells",
            "updated": "2023-10-29T23:12:56Z",
            "published": "2023-10-29T23:12:56Z",
            "summary": "Grid cells in the entorhinal cortex of the mammalian brain exhibit striking\nhexagon firing patterns in their response maps as the animal (e.g., a rat)\nnavigates in a 2D open environment. The responses of the population of grid\ncells collectively form a vector in a high-dimensional neural activity space,\nand this vector represents the self-position of the agent in the 2D physical\nspace. As the agent moves, the vector is transformed by a recurrent neural\nnetwork that takes the velocity of the agent as input. In this paper, we\npropose a simple and general conformal normalization of the input velocity for\nthe recurrent neural network, so that the local displacement of the position\nvector in the high-dimensional neural space is proportional to the local\ndisplacement of the agent in the 2D physical space, regardless of the direction\nof the input velocity. Our numerical experiments on the minimally simple linear\nand non-linear recurrent networks show that conformal normalization leads to\nthe emergence of the hexagon grid patterns. Furthermore, we derive a new\ntheoretical understanding that connects conformal normalization to the\nemergence of hexagon grid patterns in navigation tasks.",
            "author": [
                "Dehong Xu",
                "Ruiqi Gao",
                "Wen-Hao Zhang",
                "Xue-Xin Wei",
                "Ying Nian Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19192v1",
                "http://arxiv.org/pdf/2310.19192v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19188v1",
            "title": "3DMiner: Discovering Shapes from Large-Scale Unannotated Image Datasets",
            "updated": "2023-10-29T23:08:19Z",
            "published": "2023-10-29T23:08:19Z",
            "summary": "We present 3DMiner -- a pipeline for mining 3D shapes from challenging\nlarge-scale unannotated image datasets. Unlike other unsupervised 3D\nreconstruction methods, we assume that, within a large-enough dataset, there\nmust exist images of objects with similar shapes but varying backgrounds,\ntextures, and viewpoints. Our approach leverages the recent advances in\nlearning self-supervised image representations to cluster images with\ngeometrically similar shapes and find common image correspondences between\nthem. We then exploit these correspondences to obtain rough camera estimates as\ninitialization for bundle-adjustment. Finally, for every image cluster, we\napply a progressive bundle-adjusting reconstruction method to learn a neural\noccupancy field representing the underlying shape. We show that this procedure\nis robust to several types of errors introduced in previous steps (e.g., wrong\ncamera poses, images containing dissimilar shapes, etc.), allowing us to obtain\nshape and pose annotations for images in-the-wild. When using images from Pix3D\nchairs, our method is capable of producing significantly better results than\nstate-of-the-art unsupervised 3D reconstruction techniques, both quantitatively\nand qualitatively. Furthermore, we show how 3DMiner can be applied to\nin-the-wild data by reconstructing shapes present in images from the LAION-5B\ndataset. Project Page: https://ttchengab.github.io/3dminerOfficial",
            "author": [
                "Ta-Ying Cheng",
                "Matheus Gadelha",
                "Soren Pirk",
                "Thibault Groueix",
                "Radomir Mech",
                "Andrew Markham",
                "Niki Trigoni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19188v1",
                "http://arxiv.org/pdf/2310.19188v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19187v1",
            "title": "Haptic-Enhanced Virtual Reality Simulator for Robot-Assisted Femur\n  Fracture Surgery",
            "updated": "2023-10-29T23:07:51Z",
            "published": "2023-10-29T23:07:51Z",
            "summary": "In this paper, we develop a virtual reality (VR) simulator for the Robossis\nrobot-assisted femur fracture surgery. Due to the steep learning curve for such\nprocedures, a VR simulator is essential for training surgeon(s) and staff. The\nRobossis Surgical Simulator (RSS) is designed to immerse user(s) in a realistic\nsurgery setting using the Robossis system as completed in a previous real-world\ncadaveric procedure. The RSS is designed to interface the Sigma-7 Haptic\nController with the Robossis Surgical Robot (RSR) and the Meta Quest VR\nheadset. Results show that the RSR follows user commands in 6 DOF and prevents\nthe overlapping of bone segments. This development demonstrates a promising\navenue for future implementation of the Robossis system.",
            "author": [
                "Fayez H. Alruwaili",
                "David W. Halim-Banoub",
                "Jessica Rodgers",
                "Adam Dalkilic",
                "Christopher Haydel",
                "Javad Parvizi",
                "Iulian I. Iordachita",
                "Mohammad H. Abedin-Nasab"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19187v1",
                "http://arxiv.org/pdf/2310.19187v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19182v1",
            "title": "Fast Trainable Projection for Robust Fine-Tuning",
            "updated": "2023-10-29T22:52:43Z",
            "published": "2023-10-29T22:52:43Z",
            "summary": "Robust fine-tuning aims to achieve competitive in-distribution (ID)\nperformance while maintaining the out-of-distribution (OOD) robustness of a\npre-trained model when transferring it to a downstream task. Recently,\nprojected gradient descent has been successfully used in robust fine-tuning by\nconstraining the deviation from the initialization of the fine-tuned model\nexplicitly through projection. However, algorithmically, two limitations\nprevent this method from being adopted more widely, scalability and efficiency.\nIn this paper, we propose a new projection-based fine-tuning algorithm, Fast\nTrainable Projection (FTP) for computationally efficient learning of per-layer\nprojection constraints, resulting in an average $35\\%$ speedup on our\nbenchmarks compared to prior works. FTP can be combined with existing\noptimizers such as AdamW, and be used in a plug-and-play fashion. Finally, we\nshow that FTP is a special instance of hyper-optimizers that tune the\nhyper-parameters of optimizers in a learnable manner through nested\ndifferentiation. Empirically, we show superior robustness on OOD datasets,\nincluding domain shifts and natural corruptions, across four different vision\ntasks with five different pre-trained models. Additionally, we demonstrate that\nFTP is broadly applicable and beneficial to other learning scenarios such as\nlow-label and continual learning settings thanks to its easy adaptability. The\ncode will be available at https://github.com/GT-RIPL/FTP.git.",
            "author": [
                "Junjiao Tian",
                "Yen-Cheng Liu",
                "James Seale Smith",
                "Zsolt Kira"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19182v1",
                "http://arxiv.org/pdf/2310.19182v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19179v1",
            "title": "Subjective Quality Evaluation of Point Clouds Using a Head Mounted\n  Display",
            "updated": "2023-10-29T22:45:07Z",
            "published": "2023-10-29T22:45:07Z",
            "summary": "This paper reports on a subjective quality evaluation of static point clouds\nencoded with the MPEG codecs V-PCC and G-PCC, the deep learning-based codec\nRS-DLPCC, and the popular Draco codec. 18 subjects visualized 3D\nrepresentations of distorted point clouds using a Head Mounted Display, which\nallowed for a direct comparison with their reference. The Mean Opinion Scores\n(MOS) obtained in this subjective evaluation were compared with the MOS from\ntwo previous studies, where the same content was visualized either on a 2D\ndisplay or a 3D stereoscopic display, through the Pearson Correlation, Spearman\nRank Order Correlation, Root Mean Square Error, and the Outlier Ratio. The\nresults indicate that the three studies are highly correlated with one another.\nMoreover, a statistical analysis between all evaluations showed no significant\ndifferences between them.",
            "author": [
                "Joao Prazeres",
                "Rafael Rodrigues",
                "Manuela Pereira",
                "Antonio M. G. Pinheiro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19179v1",
                "http://arxiv.org/pdf/2310.19179v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19177v1",
            "title": "Robustifying Language Models with Test-Time Adaptation",
            "updated": "2023-10-29T22:37:54Z",
            "published": "2023-10-29T22:37:54Z",
            "summary": "Large-scale language models achieved state-of-the-art performance over a\nnumber of language tasks. However, they fail on adversarial language examples,\nwhich are sentences optimized to fool the language models but with similar\nsemantic meanings for humans. While prior work focuses on making the language\nmodel robust at training time, retraining for robustness is often unrealistic\nfor large-scale foundation models. Instead, we propose to make the language\nmodels robust at test time. By dynamically adapting the input sentence with\npredictions from masked words, we show that we can reverse many language\nadversarial attacks. Since our approach does not require any training, it works\nfor novel tasks at test time and can adapt to novel adversarial corruptions.\nVisualizations and empirical results on two popular sentence classification\ndatasets demonstrate that our method can repair adversarial language attacks\nover 65% o",
            "author": [
                "Noah Thomas McDermott",
                "Junfeng Yang",
                "Chengzhi Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19177v1",
                "http://arxiv.org/pdf/2310.19177v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19174v1",
            "title": "Predicting recovery following stroke: deep learning, multimodal data and\n  feature selection using explainable AI",
            "updated": "2023-10-29T22:31:20Z",
            "published": "2023-10-29T22:31:20Z",
            "summary": "Machine learning offers great potential for automated prediction of\npost-stroke symptoms and their response to rehabilitation. Major challenges for\nthis endeavour include the very high dimensionality of neuroimaging data, the\nrelatively small size of the datasets available for learning, and how to\neffectively combine neuroimaging and tabular data (e.g. demographic information\nand clinical characteristics). This paper evaluates several solutions based on\ntwo strategies. The first is to use 2D images that summarise MRI scans. The\nsecond is to select key features that improve classification accuracy.\nAdditionally, we introduce the novel approach of training a convolutional\nneural network (CNN) on images that combine regions-of-interest extracted from\nMRIs, with symbolic representations of tabular data. We evaluate a series of\nCNN architectures (both 2D and a 3D) that are trained on different\nrepresentations of MRI and tabular data, to predict whether a composite measure\nof post-stroke spoken picture description ability is in the aphasic or\nnon-aphasic range. MRI and tabular data were acquired from 758 English speaking\nstroke survivors who participated in the PLORAS study. The classification\naccuracy for a baseline logistic regression was 0.678 for lesion size alone,\nrising to 0.757 and 0.813 when initial symptom severity and recovery time were\nsuccessively added. The highest classification accuracy 0.854 was observed when\n8 regions-of-interest was extracted from each MRI scan and combined with lesion\nsize, initial severity and recovery time in a 2D Residual Neural Network.Our\nfindings demonstrate how imaging and tabular data can be combined for high\npost-stroke classification accuracy, even when the dataset is small in machine\nlearning terms. We conclude by proposing how the current models could be\nimproved to achieve even higher levels of accuracy using images from hospital\nscanners.",
            "author": [
                "Adam White",
                "Margarita Saranti",
                "Artur d'Avila Garcez",
                "Thomas M. H. Hope",
                "Cathy J. Price",
                "Howard Bowman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19174v1",
                "http://arxiv.org/pdf/2310.19174v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19168v1",
            "title": "BirdSAT: Cross-View Contrastive Masked Autoencoders for Bird Species\n  Classification and Mapping",
            "updated": "2023-10-29T22:08:00Z",
            "published": "2023-10-29T22:08:00Z",
            "summary": "We propose a metadata-aware self-supervised learning~(SSL)~framework useful\nfor fine-grained classification and ecological mapping of bird species around\nthe world. Our framework unifies two SSL strategies: Contrastive Learning~(CL)\nand Masked Image Modeling~(MIM), while also enriching the embedding space with\nmetadata available with ground-level imagery of birds. We separately train\nuni-modal and cross-modal ViT on a novel cross-view global bird species dataset\ncontaining ground-level imagery, metadata (location, time), and corresponding\nsatellite imagery. We demonstrate that our models learn fine-grained and\ngeographically conditioned features of birds, by evaluating on two downstream\ntasks: fine-grained visual classification~(FGVC) and cross-modal retrieval.\nPre-trained models learned using our framework achieve SotA performance on FGVC\nof iNAT-2021 birds and in transfer learning settings for CUB-200-2011 and\nNABirds datasets. Moreover, the impressive cross-modal retrieval performance of\nour model enables the creation of species distribution maps across any\ngeographic region. The dataset and source code will be released at\nhttps://github.com/mvrl/BirdSAT}.",
            "author": [
                "Srikumar Sastry",
                "Subash Khanal",
                "Aayush Dhakal",
                "Di Huang",
                "Nathan Jacobs"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19168v1",
                "http://arxiv.org/pdf/2310.19168v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19167v1",
            "title": "Rare Event Probability Learning by Normalizing Flows",
            "updated": "2023-10-29T21:59:33Z",
            "published": "2023-10-29T21:59:33Z",
            "summary": "A rare event is defined by a low probability of occurrence. Accurate\nestimation of such small probabilities is of utmost importance across diverse\ndomains. Conventional Monte Carlo methods are inefficient, demanding an\nexorbitant number of samples to achieve reliable estimates. Inspired by the\nexact sampling capabilities of normalizing flows, we revisit this challenge and\npropose normalizing flow assisted importance sampling, termed NOFIS. NOFIS\nfirst learns a sequence of proposal distributions associated with predefined\nnested subset events by minimizing KL divergence losses. Next, it estimates the\nrare event probability by utilizing importance sampling in conjunction with the\nlast proposal. The efficacy of our NOFIS method is substantiated through\ncomprehensive qualitative visualizations, affirming the optimality of the\nlearned proposal distribution, as well as a series of quantitative experiments\nencompassing $10$ distinct test cases, which highlight NOFIS's superiority over\nbaseline approaches.",
            "author": [
                "Zhenggqi Gao",
                "Dinghuai Zhang",
                "Luca Daniel",
                "Duane S. Boning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19167v1",
                "http://arxiv.org/pdf/2310.19167v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19166v1",
            "title": "The Power of Explainability in Forecast-Informed Deep Learning Models\n  for Flood Mitigation",
            "updated": "2023-10-29T21:56:22Z",
            "published": "2023-10-29T21:56:22Z",
            "summary": "Floods can cause horrific harm to life and property. However, they can be\nmitigated or even avoided by the effective use of hydraulic structures such as\ndams, gates, and pumps. By pre-releasing water via these structures in advance\nof extreme weather events, water levels are sufficiently lowered to prevent\nfloods. In this work, we propose FIDLAR, a Forecast Informed Deep Learning\nArchitecture, achieving flood management in watersheds with hydraulic\nstructures in an optimal manner by balancing out flood mitigation and\nunnecessary wastage of water via pre-releases. We perform experiments with\nFIDLAR using data from the South Florida Water Management District, which\nmanages a coastal area that is highly prone to frequent storms and floods.\nResults show that FIDLAR performs better than the current state-of-the-art with\nseveral orders of magnitude speedup and with provably better pre-release\nschedules. The dramatic speedups make it possible for FIDLAR to be used for\nreal-time flood management. The main contribution of this paper is the\neffective use of tools for model explainability, allowing us to understand the\ncontribution of the various environmental factors towards its decisions.",
            "author": [
                "Jimeng Shi",
                "Vitalii Stebliankin",
                "Giri Narasimhan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19166v1",
                "http://arxiv.org/pdf/2310.19166v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19163v1",
            "title": "RAIFLE: Reconstruction Attacks on Interaction-based Federated Learning\n  with Active Data Manipulation",
            "updated": "2023-10-29T21:47:24Z",
            "published": "2023-10-29T21:47:24Z",
            "summary": "Federated learning (FL) has recently emerged as a privacy-preserving approach\nfor machine learning in domains that rely on user interactions, particularly\nrecommender systems (RS) and online learning to rank (OLTR). While there has\nbeen substantial research on the privacy of traditional FL, little attention\nhas been paid to studying the privacy properties of these interaction-based FL\n(IFL) systems. In this work, we show that IFL can introduce unique challenges\nconcerning user privacy, particularly when the central server has knowledge and\ncontrol over the items that users interact with. Specifically, we demonstrate\nthe threat of reconstructing user interactions by presenting RAIFLE, a general\noptimization-based reconstruction attack framework customized for IFL. RAIFLE\nemploys Active Data Manipulation (ADM), a novel attack technique unique to IFL,\nwhere the server actively manipulates the training features of the items to\ninduce adversarial behaviors in the local FL updates. We show that RAIFLE is\nmore impactful than existing FL privacy attacks in the IFL context, and\ndescribe how it can undermine privacy defenses like secure aggregation and\nprivate information retrieval. Based on our findings, we propose and discuss\ncountermeasure guidelines to mitigate our attack in the context of federated\nRS/OLTR specifically and IFL more broadly.",
            "author": [
                "Dzung Pham",
                "Shreyas Kulkarni",
                "Amir Houmansadr"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19163v1",
                "http://arxiv.org/pdf/2310.19163v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19159v1",
            "title": "Transfer Learning in Transformer-Based Demand Forecasting For Home\n  Energy Management System",
            "updated": "2023-10-29T21:19:08Z",
            "published": "2023-10-29T21:19:08Z",
            "summary": "Increasingly, homeowners opt for photovoltaic (PV) systems and/or battery\nstorage to minimize their energy bills and maximize renewable energy usage.\nThis has spurred the development of advanced control algorithms that maximally\nachieve those goals. However, a common challenge faced while developing such\ncontrollers is the unavailability of accurate forecasts of household power\nconsumption, especially for shorter time resolutions (15 minutes) and in a\ndata-efficient manner. In this paper, we analyze how transfer learning can help\nby exploiting data from multiple households to improve a single house's load\nforecasting. Specifically, we train an advanced forecasting model (a temporal\nfusion transformer) using data from multiple different households, and then\nfinetune this global model on a new household with limited data (i.e. only a\nfew days). The obtained models are used for forecasting power consumption of\nthe household for the next 24 hours~(day-ahead) at a time resolution of 15\nminutes, with the intention of using these forecasts in advanced controllers\nsuch as Model Predictive Control. We show the benefit of this transfer learning\nsetup versus solely using the individual new household's data, both in terms of\n(i) forecasting accuracy ($\\sim$15\\% MAE reduction) and (ii) control\nperformance ($\\sim$2\\% energy cost reduction), using real-world household data.",
            "author": [
                "Gargya Gokhale",
                "Jonas Van Gompel",
                "Bert Claessens",
                "Chris Develder"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3600100.3626635",
                "http://arxiv.org/abs/2310.19159v1",
                "http://arxiv.org/pdf/2310.19159v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19155v1",
            "title": "Real-World Implementation of Reinforcement Learning Based Energy\n  Coordination for a Cluster of Households",
            "updated": "2023-10-29T21:10:38Z",
            "published": "2023-10-29T21:10:38Z",
            "summary": "Given its substantial contribution of 40\\% to global power consumption, the\nbuilt environment has received increasing attention to serve as a source of\nflexibility to assist the modern power grid. In that respect, previous research\nmainly focused on energy management of individual buildings. In contrast, in\nthis paper, we focus on aggregated control of a set of residential buildings,\nto provide grid supporting services, that eventually should include ancillary\nservices. In particular, we present a real-life pilot study that studies the\neffectiveness of reinforcement-learning (RL) in coordinating the power\nconsumption of 8 residential buildings to jointly track a target power signal.\nOur RL approach relies solely on observed data from individual households and\ndoes not require any explicit building models or simulators, making it\npractical to implement and easy to scale. We show the feasibility of our\nproposed RL-based coordination strategy in a real-world setting. In a 4-week\ncase study, we demonstrate a hierarchical control system, relying on an\nRL-based ranking system to select which households to activate flex assets\nfrom, and a real-time PI control-based power dispatch mechanism to control the\nselected assets. Our results demonstrate satisfactory power tracking, and the\neffectiveness of the RL-based ranks which are learnt in a purely data-driven\nmanner.",
            "author": [
                "Gargya Gokhale",
                "Niels Tiben",
                "Marie-Sophie Verwee",
                "Manu Lahariya",
                "Bert Claessens",
                "Chris Develder"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3600100.3625681",
                "http://arxiv.org/abs/2310.19155v1",
                "http://arxiv.org/pdf/2310.19155v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19152v2",
            "title": "BERT Lost Patience Won't Be Robust to Adversarial Slowdown",
            "updated": "2023-10-31T04:19:59Z",
            "published": "2023-10-29T21:06:34Z",
            "summary": "In this paper, we systematically evaluate the robustness of multi-exit\nlanguage models against adversarial slowdown. To audit their robustness, we\ndesign a slowdown attack that generates natural adversarial text bypassing\nearly-exit points. We use the resulting WAFFLE attack as a vehicle to conduct a\ncomprehensive evaluation of three multi-exit mechanisms with the GLUE benchmark\nagainst adversarial slowdown. We then show our attack significantly reduces the\ncomputational savings provided by the three methods in both white-box and\nblack-box settings. The more complex a mechanism is, the more vulnerable it is\nto adversarial slowdown. We also perform a linguistic analysis of the perturbed\ntext inputs, identifying common perturbation patterns that our attack\ngenerates, and comparing them with standard adversarial text attacks. Moreover,\nwe show that adversarial training is ineffective in defeating our slowdown\nattack, but input sanitization with a conversational model, e.g., ChatGPT, can\nremove perturbations effectively. This result suggests that future work is\nneeded for developing efficient yet robust multi-exit models. Our code is\navailable at: https://github.com/ztcoalson/WAFFLE",
            "author": [
                "Zachary Coalson",
                "Gabriel Ritter",
                "Rakesh Bobba",
                "Sanghyun Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19152v2",
                "http://arxiv.org/pdf/2310.19152v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19147v1",
            "title": "Optimal Scoring for Dynamic Information Acquisition",
            "updated": "2023-10-29T20:46:05Z",
            "published": "2023-10-29T20:46:05Z",
            "summary": "A principal seeks to learn about a binary state and can do so by enlisting an\nagent to acquire information over time using a Poisson information arrival\ntechnology. The agent learns about this state privately, and his effort choices\nare unobserved by the principal. The principal can reward the agent with a\nprize of fixed value as a function of the agent's sequence of reports and the\nrealized state. We identify conditions that each individually ensure that the\nprincipal cannot do better than by eliciting a single report from the agent\nafter all information has been acquired. We also show that such a static\ncontract is suboptimal under sufficiently strong violations of these\nconditions. We contrast our solution to the case where the agent acquires\ninformation \"all at once;\" notably, the optimal contract in the dynamic\nenvironment may provide strictly positive base rewards to the agent even if his\nprediction about the state is incorrect.",
            "author": [
                "Yingkai Li",
                "Jonathan Libgober"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19147v1",
                "http://arxiv.org/pdf/2310.19147v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19145v1",
            "title": "Learning to Follow Object-Centric Image Editing Instructions Faithfully",
            "updated": "2023-10-29T20:39:11Z",
            "published": "2023-10-29T20:39:11Z",
            "summary": "Natural language instructions are a powerful interface for editing the\noutputs of text-to-image diffusion models. However, several challenges need to\nbe addressed: 1) underspecification (the need to model the implicit meaning of\ninstructions) 2) grounding (the need to localize where the edit has to be\nperformed), 3) faithfulness (the need to preserve the elements of the image not\naffected by the edit instruction). Current approaches focusing on image editing\nwith natural language instructions rely on automatically generated paired data,\nwhich, as shown in our investigation, is noisy and sometimes nonsensical,\nexacerbating the above issues. Building on recent advances in segmentation,\nChain-of-Thought prompting, and visual question answering, we significantly\nimprove the quality of the paired data. In addition, we enhance the supervision\nsignal by highlighting parts of the image that need to be changed by the\ninstruction. The model fine-tuned on the improved data is capable of performing\nfine-grained object-centric edits better than state-of-the-art baselines,\nmitigating the problems outlined above, as shown by automatic and human\nevaluations. Moreover, our model is capable of generalizing to domains unseen\nduring training, such as visual metaphors.",
            "author": [
                "Tuhin Chakrabarty",
                "Kanishk Singh",
                "Arkadiy Saakyan",
                "Smaranda Muresan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19145v1",
                "http://arxiv.org/pdf/2310.19145v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19142v1",
            "title": "MAG-GNN: Reinforcement Learning Boosted Graph Neural Network",
            "updated": "2023-10-29T20:32:21Z",
            "published": "2023-10-29T20:32:21Z",
            "summary": "While Graph Neural Networks (GNNs) recently became powerful tools in graph\nlearning tasks, considerable efforts have been spent on improving GNNs'\nstructural encoding ability. A particular line of work proposed subgraph GNNs\nthat use subgraph information to improve GNNs' expressivity and achieved great\nsuccess. However, such effectivity sacrifices the efficiency of GNNs by\nenumerating all possible subgraphs. In this paper, we analyze the necessity of\ncomplete subgraph enumeration and show that a model can achieve a comparable\nlevel of expressivity by considering a small subset of the subgraphs. We then\nformulate the identification of the optimal subset as a combinatorial\noptimization problem and propose Magnetic Graph Neural Network (MAG-GNN), a\nreinforcement learning (RL) boosted GNN, to solve the problem. Starting with a\ncandidate subgraph set, MAG-GNN employs an RL agent to iteratively update the\nsubgraphs to locate the most expressive set for prediction. This reduces the\nexponential complexity of subgraph enumeration to the constant complexity of a\nsubgraph search algorithm while keeping good expressivity. We conduct extensive\nexperiments on many datasets, showing that MAG-GNN achieves competitive\nperformance to state-of-the-art methods and even outperforms many subgraph\nGNNs. We also demonstrate that MAG-GNN effectively reduces the running time of\nsubgraph GNNs.",
            "author": [
                "Lecheng Kong",
                "Jiarui Feng",
                "Hao Liu",
                "Dacheng Tao",
                "Yixin Chen",
                "Muhan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19142v1",
                "http://arxiv.org/pdf/2310.19142v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19138v1",
            "title": "Backward and Forward Inference in Interacting Independent-Cascade\n  Processes: A Scalable and Convergent Message-Passing Approach",
            "updated": "2023-10-29T20:03:38Z",
            "published": "2023-10-29T20:03:38Z",
            "summary": "We study the problems of estimating the past and future evolutions of two\ndiffusion processes that spread concurrently on a network. Specifically, given\na known network $G=(V, \\overrightarrow{E})$ and a (possibly noisy) snapshot\n$\\mathcal{O}_n$ of its state taken at (a possibly unknown) time $W$, we wish to\ndetermine the posterior distributions of the initial state of the network and\nthe infection times of its nodes. These distributions are useful in finding\nsource nodes of epidemics and rumors -- $\\textit{backward inference}$ -- , and\nestimating the spread of a fixed set of source nodes -- $\\textit{forward\ninference}$.\n  To model the interaction between the two processes, we study an extension of\nthe independent-cascade (IC) model where, when a node gets infected with either\nprocess, its susceptibility to the other one changes. First, we derive the\nexact joint probability of the initial state of the network and the\nobservation-snapshot $\\mathcal{O}_n$. Then, using the machinery of\nfactor-graphs, factor-graph transformations, and the generalized\ndistributive-law, we derive a Belief-Propagation (BP) based algorithm that is\nscalable to large networks and can converge on graphs of arbitrary topology (at\na likely expense in approximation accuracy).",
            "author": [
                "Nouman Khan",
                "Kangle Mu",
                "Mehrdad Moharrami",
                "Vijay Subramanian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19138v1",
                "http://arxiv.org/pdf/2310.19138v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19137v1",
            "title": "Automaton Distillation: Neuro-Symbolic Transfer Learning for Deep\n  Reinforcement Learning",
            "updated": "2023-10-29T19:59:55Z",
            "published": "2023-10-29T19:59:55Z",
            "summary": "Reinforcement learning (RL) is a powerful tool for finding optimal policies\nin sequential decision processes. However, deep RL methods suffer from two\nweaknesses: collecting the amount of agent experience required for practical RL\nproblems is prohibitively expensive, and the learned policies exhibit poor\ngeneralization on tasks outside of the training distribution. To mitigate these\nissues, we introduce automaton distillation, a form of neuro-symbolic transfer\nlearning in which Q-value estimates from a teacher are distilled into a\nlow-dimensional representation in the form of an automaton. We then propose two\nmethods for generating Q-value estimates: static transfer, which reasons over\nan abstract Markov Decision Process constructed based on prior knowledge, and\ndynamic transfer, where symbolic information is extracted from a teacher Deep\nQ-Network (DQN). The resulting Q-value estimates from either method are used to\nbootstrap learning in the target environment via a modified DQN loss function.\nWe list several failure modes of existing automaton-based transfer methods and\ndemonstrate that both static and dynamic automaton distillation decrease the\ntime required to find optimal policies for various decision tasks.",
            "author": [
                "Suraj Singireddy",
                "Andre Beckus",
                "George Atia",
                "Sumit Jha",
                "Alvaro Velasquez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19137v1",
                "http://arxiv.org/pdf/2310.19137v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19128v1",
            "title": "Prediction of local elasto-plastic stress and strain fields in a\n  two-phase composite microstructure using a deep convolutional neural network",
            "updated": "2023-10-29T19:34:53Z",
            "published": "2023-10-29T19:34:53Z",
            "summary": "Design and analysis of inelastic materials requires prediction of physical\nresponses that evolve under loading. Numerical simulation of such behavior\nusing finite element (FE) approaches can call for significant time and\ncomputational effort. To address this challenge, this paper demonstrates a deep\nlearning (DL) framework that is capable of predicting micro-scale\nelasto-plastic strains and stresses in a two-phase medium, at a much greater\nspeed than traditional FE simulations. The proposed framework uses a deep\nconvolutional neural network (CNN), specifically a U-Net architecture with 3D\noperations, to map the composite microstructure to the corresponding stress and\nstrain fields under a predetermined load path. In particular, the model is\napplied to a two-phase fiber reinforced plastic (FRP) composite microstructure\nsubjected to a given loading-unloading path, predicting the corresponding\nstress and strain fields at discrete intermediate load steps. A novel two-step\ntraining approach provides more accurate predictions of stress, by first\ntraining the model to predict strain fields and then using those strain fields\nas input to the model that predicts the stress fields. This efficient\ndata-driven approach enables accurate prediction of physical fields in\ninelastic materials, based solely on microstructure images and loading\ninformation.",
            "author": [
                "Indrashish Saha",
                "Ashwini Gupta",
                "Lori Graham-Brady"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19128v1",
                "http://arxiv.org/pdf/2310.19128v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19126v1",
            "title": "Worst-case Performance of Popular Approximate Nearest Neighbor Search\n  Implementations: Guarantees and Limitations",
            "updated": "2023-10-29T19:25:48Z",
            "published": "2023-10-29T19:25:48Z",
            "summary": "Graph-based approaches to nearest neighbor search are popular and powerful\ntools for handling large datasets in practice, but they have limited\ntheoretical guarantees. We study the worst-case performance of recent\ngraph-based approximate nearest neighbor search algorithms, such as HNSW, NSG\nand DiskANN. For DiskANN, we show that its \"slow preprocessing\" version\nprovably supports approximate nearest neighbor search query with constant\napproximation ratio and poly-logarithmic query time, on data sets with bounded\n\"intrinsic\" dimension. For the other data structure variants studied, including\nDiskANN with \"fast preprocessing\", HNSW and NSG, we present a family of\ninstances on which the empirical query time required to achieve a \"reasonable\"\naccuracy is linear in instance size. For example, for DiskANN, we show that the\nquery procedure can take at least $0.1 n$ steps on instances of size $n$ before\nit encounters any of the $5$ nearest neighbors of the query.",
            "author": [
                "Piotr Indyk",
                "Haike Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19126v1",
                "http://arxiv.org/pdf/2310.19126v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CG",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19124v1",
            "title": "Software engineering for deep learning applications: usage of SWEng and\n  MLops tools in GitHub repositories",
            "updated": "2023-10-29T19:21:33Z",
            "published": "2023-10-29T19:21:33Z",
            "summary": "The rising popularity of deep learning (DL) methods and techniques has\ninvigorated interest in the topic of SE4DL, the application of software\nengineering (SE) practices on deep learning software. Despite the novel\nengineering challenges brought on by the data-driven and non-deterministic\nparadigm of DL software, little work has been invested into developing\nAI-targeted SE tools. On the other hand, tools tackling more general\nengineering issues in DL are actively used and referred to under the umbrella\nterm of ``MLOps tools''. Furthermore, the available literature supports the\nutility of conventional SE tooling in DL software development. Building upon\nprevious MSR research on tool usage in open-source software works, we identify\nconventional and MLOps tools adopted in popular applied DL projects that use\nPython as the main programming language. About 70% of the GitHub repositories\nmined contained at least one conventional SE tool. Software configuration\nmanagement tools are the most adopted, while the opposite applies to\nmaintenance tools. Substantially fewer MLOps tools were in use, with only 9\ntools out of a sample of 80 used in at least one repository. The majority of\nthem were open-source rather than proprietary. One of these tools, TensorBoard,\nwas found to be adopted in about half of the repositories in our study.\nConsequently, the use of conventional SE tooling demonstrates its relevance to\nDL software. Further research is recommended on the adoption of MLOps tooling\nby open-source projects, focusing on the relevance of particular tool types,\nthe development of required tools, as well as ways to promote the use of\nalready available tools.",
            "author": [
                "Evangelia Panourgia",
                "Theodoros Plessas",
                "Diomidis Spinellis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19124v1",
                "http://arxiv.org/pdf/2310.19124v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19117v1",
            "title": "Finding Optimal Training Parameters for Quantum Generative Adversarial\n  Networks",
            "updated": "2023-10-29T19:09:18Z",
            "published": "2023-10-29T19:09:18Z",
            "summary": "Some of the most impressive achievements of contemporary Machine Learning\nsystems comes from the GAN (Generative Adversarial Network) structure. DALLE-2\nand GPT- 3, two of the most impressive and recognizable feats of ML in recent\nyears, were both trained using adversarial techniques. The world of Quantum\nComputing is already well aware of the value of such techniques on near-term\nQuantum Hardware: QGANs provide a highly efficient method for loading classical\ndata into a quantum state. We investigate the performance of these techniques\nin an attempt to determine some of the optimal training parameters in a\nQiskit-style Parameterized Circuit QGAN framework.",
            "author": [
                "C. Strynar",
                "R. M. Rajapakse"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19117v1",
                "http://arxiv.org/pdf/2310.19117v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19112v2",
            "title": "Efficient IoT Inference via Context-Awareness",
            "updated": "2023-12-03T09:15:04Z",
            "published": "2023-10-29T18:57:15Z",
            "summary": "While existing strategies to execute deep learning-based classification on\nlow-power platforms assume the models are trained on all classes of interest,\nthis paper posits that adopting context-awareness i.e. narrowing down a\nclassification task to the current deployment context consisting of only recent\ninference queries can substantially enhance performance in resource-constrained\nenvironments. We propose a new paradigm, CACTUS, for scalable and efficient\ncontext-aware classification where a micro-classifier recognizes a small set of\nclasses relevant to the current context and, when context change happens (e.g.,\na new class comes into the scene), rapidly switches to another suitable\nmicro-classifier. CACTUS features several innovations, including optimizing the\ntraining cost of context-aware classifiers, enabling on-the-fly context-aware\nswitching between classifiers, and balancing context switching costs and\nperformance gains via simple yet effective switching policies. We show that\nCACTUS achieves significant benefits in accuracy, latency, and compute budget\nacross a range of datasets and IoT platforms.",
            "author": [
                "Mohammad Mehdi Rastikerdar",
                "Jin Huang",
                "Shiwei Fang",
                "Hui Guan",
                "Deepak Ganesan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19112v2",
                "http://arxiv.org/pdf/2310.19112v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19836v1",
            "title": "Two-dimensional Parameter Relationships for W UMa-type Systems Revisited",
            "updated": "2023-10-29T18:52:26Z",
            "published": "2023-10-29T18:52:26Z",
            "summary": "Reviewing the empirical and theoretical parameter relationships between\nvarious parameters is a good way to understand more about contact binary\nsystems. In this investigation, two-dimensional (2D) relationships for\nP-M_V(system), P-L_1,2, M_1,2-L_1,2, and q-L_ratio were revisited. The sample\nused is related to 118 contact binary systems with an orbital period shorter\nthan 0.6 days whose absolute parameters were estimated based on the Gaia Data\nRelease 3 (DR3) parallax. We reviewed previous studies on 2D relationships and\nupdated six parameter relationships. Therefore, Markov chain Monte Carlo (MCMC)\nand Machine Learning (ML) methods were used, and the outcomes were compared. We\nselected 22 contact binary systems from eight previous studies for comparison,\nwhich had light curve solutions using spectroscopic data. The results show that\nthe systems are in good agreement with the results of this study.",
            "author": [
                "Atila Poro",
                "Ehsan Paki",
                "Ailar Alizadehsabegh",
                "Mehdi Khodadadilori",
                "Selda Ranjbar Salehian",
                "Mahya Hedayatjoo",
                "Fatemeh Hashemi",
                "Yasaman Dashti",
                "Fatemeh Mohammadizadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19836v1",
                "http://arxiv.org/pdf/2310.19836v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19109v2",
            "title": "Dynamic Task and Weight Prioritization Curriculum Learning for\n  Multimodal Imagery",
            "updated": "2023-11-07T14:59:17Z",
            "published": "2023-10-29T18:46:33Z",
            "summary": "This paper explores post-disaster analytics using multimodal deep learning\nmodels trained with curriculum learning method. Studying post-disaster\nanalytics is important as it plays a crucial role in mitigating the impact of\ndisasters by providing timely and accurate insights into the extent of damage\nand the allocation of resources. We propose a curriculum learning strategy to\nenhance the performance of multimodal deep learning models. Curriculum learning\nemulates the progressive learning sequence in human education by training deep\nlearning models on increasingly complex data. Our primary objective is to\ndevelop a curriculum-trained multimodal deep learning model, with a particular\nfocus on visual question answering (VQA) capable of jointly processing image\nand text data, in conjunction with semantic segmentation for disaster analytics\nusing the\nFloodNet\\footnote{https://github.com/BinaLab/FloodNet-Challenge-EARTHVISION2021}\ndataset. To achieve this, U-Net model is used for semantic segmentation and\nimage encoding. A custom built text classifier is used for visual question\nanswering. Existing curriculum learning methods rely on manually defined\ndifficulty functions. We introduce a novel curriculum learning approach termed\nDynamic Task and Weight Prioritization (DATWEP), which leverages a\ngradient-based method to automatically decide task difficulty during curriculum\nlearning training, thereby eliminating the need for explicit difficulty\ncomputation. The integration of DATWEP into our multimodal model shows\nimprovement on VQA performance. Source code is available at\nhttps://github.com/fualsan/DATWEP.",
            "author": [
                "Huseyin Fuat Alsan",
                "Taner Arsan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19109v2",
                "http://arxiv.org/pdf/2310.19109v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19103v1",
            "title": "Proving Linear Mode Connectivity of Neural Networks via Optimal\n  Transport",
            "updated": "2023-10-29T18:35:05Z",
            "published": "2023-10-29T18:35:05Z",
            "summary": "The energy landscape of high-dimensional non-convex optimization problems is\ncrucial to understanding the effectiveness of modern deep neural network\narchitectures. Recent works have experimentally shown that two different\nsolutions found after two runs of a stochastic training are often connected by\nvery simple continuous paths (e.g., linear) modulo a permutation of the\nweights. In this paper, we provide a framework theoretically explaining this\nempirical observation. Based on convergence rates in Wasserstein distance of\nempirical measures, we show that, with high probability, two wide enough\ntwo-layer neural networks trained with stochastic gradient descent are linearly\nconnected. Additionally, we express upper and lower bounds on the width of each\nlayer of two deep neural networks with independent neuron weights to be\nlinearly connected. Finally, we empirically demonstrate the validity of our\napproach by showing how the dimension of the support of the weight distribution\nof neurons, which dictates Wasserstein convergence rates is correlated with\nlinear mode connectivity.",
            "author": [
                "Damien Ferbach",
                "Baptiste Goujaud",
                "Gauthier Gidel",
                "Aymeric Dieuleveut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19103v1",
                "http://arxiv.org/pdf/2310.19103v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19102v2",
            "title": "Atom: Low-bit Quantization for Efficient and Accurate LLM Serving",
            "updated": "2023-11-07T17:47:11Z",
            "published": "2023-10-29T18:33:05Z",
            "summary": "The growing demand for Large Language Models (LLMs) in applications such as\ncontent generation, intelligent chatbots, and sentiment analysis poses\nconsiderable challenges for LLM service providers. To efficiently use GPU\nresources and boost throughput, batching multiple requests has emerged as a\npopular paradigm; to further speed up batching, LLM quantization techniques\nreduce memory consumption and increase computing capacity. However, prevalent\nquantization schemes (e.g., 8-bit weight-activation quantization) cannot fully\nleverage the capabilities of modern GPUs, such as 4-bit integer operators,\nresulting in sub-optimal performance.\n  To maximize LLMs' serving throughput, we introduce Atom, a low-bit\nquantization method that achieves high throughput improvements with negligible\naccuracy loss. Atom significantly boosts serving throughput by using low-bit\noperators and considerably reduces memory consumption via low-bit quantization.\nIt attains high accuracy by applying a novel mixed-precision and fine-grained\nquantization process. We evaluate Atom on 4-bit weight-activation quantization\nsetups in the serving context. Atom improves end-to-end throughput by up to\n$7.73\\times$ compared to the FP16 and by $2.53\\times$ compared to INT8\nquantization, while maintaining the same latency target.",
            "author": [
                "Yilong Zhao",
                "Chien-Yu Lin",
                "Kan Zhu",
                "Zihao Ye",
                "Lequn Chen",
                "Size Zheng",
                "Luis Ceze",
                "Arvind Krishnamurthy",
                "Tianqi Chen",
                "Baris Kasikci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19102v2",
                "http://arxiv.org/pdf/2310.19102v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19835v1",
            "title": "CrossEAI: Using Explainable AI to generate better bounding boxes for\n  Chest X-ray images",
            "updated": "2023-10-29T17:48:39Z",
            "published": "2023-10-29T17:48:39Z",
            "summary": "Explainability is critical for deep learning applications in healthcare which\nare mandated to provide interpretations to both patients and doctors according\nto legal regulations and responsibilities. Explainable AI methods, such as\nfeature importance using integrated gradients, model approximation using LIME,\nor neuron activation and layer conductance to provide interpretations for\ncertain health risk predictions. In medical imaging diagnosis, disease\nclassification usually achieves high accuracy, but generated bounding boxes\nhave much lower Intersection over Union (IoU). Different methods with\nself-supervised or semi-supervised learning strategies have been proposed, but\nfew improvements have been identified for bounding box generation. Previous\nwork shows that bounding boxes generated by these methods are usually larger\nthan ground truth and contain major non-disease area. This paper utilizes the\nadvantages of post-hoc AI explainable methods to generate bounding boxes for\nchest x-ray image diagnosis. In this work, we propose CrossEAI which combines\nheatmap and gradient map to generate more targeted bounding boxes. By using\nweighted average of Guided Backpropagation and Grad-CAM++, we are able to\ngenerate bounding boxes which are closer to the ground truth. We evaluate our\nmodel on a chest x-ray dataset. The performance has significant improvement\nover the state of the art model with the same setting, with $9\\%$ improvement\nin average of all diseases over all IoU. Moreover, as a model that does not use\nany ground truth bounding box information for training, we achieve same\nperformance in general as the model that uses $80\\%$ of the ground truth\nbounding box information for training",
            "author": [
                "Jinze Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19835v1",
                "http://arxiv.org/pdf/2310.19835v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19094v1",
            "title": "Performance Characterization of NVMe Flash Devices with Zoned Namespaces\n  (ZNS)",
            "updated": "2023-10-29T17:48:30Z",
            "published": "2023-10-29T17:48:30Z",
            "summary": "The recent emergence of NVMe flash devices with Zoned Namespace support, ZNS\nSSDs, represents a significant new advancement in flash storage. ZNS SSDs\nintroduce a new storage abstraction of append-only zones with a set of new I/O\n(i.e., append) and management (zone state machine transition) commands. With\nthe new abstraction and commands, ZNS SSDs offer more control to the host\nsoftware stack than a non-zoned SSD for flash management, which is known to be\ncomplex (because of garbage collection, scheduling, block allocation,\nparallelism management, overprovisioning). ZNS SSDs are, consequently, gaining\nadoption in a variety of applications (e.g., file systems, key-value stores,\nand databases), particularly latency-sensitive big-data applications. Despite\nthis enthusiasm, there has yet to be a systematic characterization of ZNS SSD\nperformance with its zoned storage model abstractions and I/O operations. This\nwork addresses this crucial shortcoming. We report on the performance features\nof a commercially available ZNS SSD (13 key observations), explain how these\nfeatures can be incorporated into publicly available state-of-the-art ZNS\nemulators, and recommend guidelines for ZNS SSD application developers. All\nartifacts (code and data sets) of this study are publicly available at\nhttps://github.com/stonet-research/NVMeBenchmarks.",
            "author": [
                "Krijn Doekemeijer",
                "Nick Tehrany",
                "Balakrishnan Chandrasekaran",
                "Matias Bj\u00f8rling",
                "Animesh Trivedi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19094v1",
                "http://arxiv.org/pdf/2310.19094v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19091v1",
            "title": "Bridging the Gap: Towards an Expanded Toolkit for ML-Supported\n  Decision-Making in the Public Sector",
            "updated": "2023-10-29T17:44:48Z",
            "published": "2023-10-29T17:44:48Z",
            "summary": "Machine Learning (ML) systems are becoming instrumental in the public sector,\nwith applications spanning areas like criminal justice, social welfare,\nfinancial fraud detection, and public health. While these systems offer great\npotential benefits to institutional decision-making processes, such as improved\nefficiency and reliability, they still face the challenge of aligning intricate\nand nuanced policy objectives with the precise formalization requirements\nnecessitated by ML models. In this paper, we aim to bridge the gap between ML\nand public sector decision-making by presenting a comprehensive overview of key\ntechnical challenges where disjunctions between policy goals and ML models\ncommonly arise. We concentrate on pivotal points of the ML pipeline that\nconnect the model to its operational environment, delving into the significance\nof representative training data and highlighting the importance of a model\nsetup that facilitates effective decision-making. Additionally, we link these\nchallenges with emerging methodological advancements, encompassing causal ML,\ndomain adaptation, uncertainty quantification, and multi-objective\noptimization, illustrating the path forward for harmonizing ML and public\nsector objectives.",
            "author": [
                "Unai Fischer Abaigar",
                "Christoph Kern",
                "Noam Barda",
                "Frauke Kreuter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19091v1",
                "http://arxiv.org/pdf/2310.19091v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "cs.HC",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19089v1",
            "title": "Pushdown Layers: Encoding Recursive Structure in Transformer Language\n  Models",
            "updated": "2023-10-29T17:27:18Z",
            "published": "2023-10-29T17:27:18Z",
            "summary": "Recursion is a prominent feature of human language, and fundamentally\nchallenging for self-attention due to the lack of an explicit recursive-state\ntracking mechanism. Consequently, Transformer language models poorly capture\nlong-tail recursive structure and exhibit sample-inefficient syntactic\ngeneralization. This work introduces Pushdown Layers, a new self-attention\nlayer that models recursive state via a stack tape that tracks estimated depths\nof every token in an incremental parse of the observed prefix. Transformer LMs\nwith Pushdown Layers are syntactic language models that autoregressively and\nsynchronously update this stack tape as they predict new tokens, in turn using\nthe stack tape to softly modulate attention over tokens -- for instance,\nlearning to \"skip\" over closed constituents. When trained on a corpus of\nstrings annotated with silver constituency parses, Transformers equipped with\nPushdown Layers achieve dramatically better and 3-5x more sample-efficient\nsyntactic generalization, while maintaining similar perplexities. Pushdown\nLayers are a drop-in replacement for standard self-attention. We illustrate\nthis by finetuning GPT2-medium with Pushdown Layers on an automatically parsed\nWikiText-103, leading to improvements on several GLUE text classification\ntasks.",
            "author": [
                "Shikhar Murty",
                "Pratyusha Sharma",
                "Jacob Andreas",
                "Christopher D. Manning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19089v1",
                "http://arxiv.org/pdf/2310.19089v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19081v1",
            "title": "Deep Audio Analyzer: a Framework to Industrialize the Research on Audio\n  Forensics",
            "updated": "2023-10-29T17:04:24Z",
            "published": "2023-10-29T17:04:24Z",
            "summary": "Deep Audio Analyzer is an open source speech framework that aims to simplify\nthe research and the development process of neural speech processing pipelines,\nallowing users to conceive, compare and share results in a fast and\nreproducible way. This paper describes the core architecture designed to\nsupport several tasks of common interest in the audio forensics field, showing\npossibility of creating new tasks thus customizing the framework. By means of\nDeep Audio Analyzer, forensics examiners (i.e. from Law Enforcement Agencies)\nand researchers will be able to visualize audio features, easily evaluate\nperformances on pretrained models, to create, export and share new audio\nanalysis workflows by combining deep neural network models with few clicks. One\nof the advantages of this tool is to speed up research and practical\nexperimentation, in the field of audio forensics analysis thus also improving\nexperimental reproducibility by exporting and sharing pipelines. All features\nare developed in modules accessible by the user through a Graphic User\nInterface. Index Terms: Speech Processing, Deep Learning Audio, Deep Learning\nAudio Pipeline creation, Audio Forensics.",
            "author": [
                "Valerio Francesco Puglisi",
                "Oliver Giudice",
                "Sebastiano Battiato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19081v1",
                "http://arxiv.org/pdf/2310.19081v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19080v2",
            "title": "Reward Finetuning for Faster and More Accurate Unsupervised Object\n  Discovery",
            "updated": "2023-11-05T18:57:59Z",
            "published": "2023-10-29T17:03:12Z",
            "summary": "Recent advances in machine learning have shown that Reinforcement Learning\nfrom Human Feedback (RLHF) can improve machine learning models and align them\nwith human preferences. Although very successful for Large Language Models\n(LLMs), these advancements have not had a comparable impact in research for\nautonomous vehicles -- where alignment with human expectations can be\nimperative. In this paper, we propose to adapt similar RL-based methods to\nunsupervised object discovery, i.e. learning to detect objects from LiDAR\npoints without any training labels. Instead of labels, we use simple heuristics\nto mimic human feedback. More explicitly, we combine multiple heuristics into a\nsimple reward function that positively correlates its score with bounding box\naccuracy, i.e., boxes containing objects are scored higher than those without.\nWe start from the detector's own predictions to explore the space and reinforce\nboxes with high rewards through gradient updates. Empirically, we demonstrate\nthat our approach is not only more accurate, but also orders of magnitudes\nfaster to train compared to prior works on object discovery.",
            "author": [
                "Katie Z Luo",
                "Zhenzhen Liu",
                "Xiangyu Chen",
                "Yurong You",
                "Sagie Benaim",
                "Cheng Perng Phoo",
                "Mark Campbell",
                "Wen Sun",
                "Bharath Hariharan",
                "Kilian Q. Weinberger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19080v2",
                "http://arxiv.org/pdf/2310.19080v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19075v1",
            "title": "Bespoke Solvers for Generative Flow Models",
            "updated": "2023-10-29T16:58:31Z",
            "published": "2023-10-29T16:58:31Z",
            "summary": "Diffusion or flow-based models are powerful generative paradigms that are\nnotoriously hard to sample as samples are defined as solutions to\nhigh-dimensional Ordinary or Stochastic Differential Equations (ODEs/SDEs)\nwhich require a large Number of Function Evaluations (NFE) to approximate well.\nExisting methods to alleviate the costly sampling process include model\ndistillation and designing dedicated ODE solvers. However, distillation is\ncostly to train and sometimes can deteriorate quality, while dedicated solvers\nstill require relatively large NFE to produce high quality samples. In this\npaper we introduce \"Bespoke solvers\", a novel framework for constructing custom\nODE solvers tailored to the ODE of a given pre-trained flow model. Our approach\noptimizes an order consistent and parameter-efficient solver (e.g., with 80\nlearnable parameters), is trained for roughly 1% of the GPU time required for\ntraining the pre-trained model, and significantly improves approximation and\ngeneration quality compared to dedicated solvers. For example, a Bespoke solver\nfor a CIFAR10 model produces samples with Fr\\'echet Inception Distance (FID) of\n2.73 with 10 NFE, and gets to 1% of the Ground Truth (GT) FID (2.59) for this\nmodel with only 20 NFE. On the more challenging ImageNet-64$\\times$64, Bespoke\nsamples at 2.2 FID with 10 NFE, and gets within 2% of GT FID (1.71) with 20\nNFE.",
            "author": [
                "Neta Shaul",
                "Juan Perez",
                "Ricky T. Q. Chen",
                "Ali Thabet",
                "Albert Pumarola",
                "Yaron Lipman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19075v1",
                "http://arxiv.org/pdf/2310.19075v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19069v1",
            "title": "Efficient Cluster Selection for Personalized Federated Learning: A\n  Multi-Armed Bandit Approach",
            "updated": "2023-10-29T16:46:50Z",
            "published": "2023-10-29T16:46:50Z",
            "summary": "Federated learning (FL) offers a decentralized training approach for machine\nlearning models, prioritizing data privacy. However, the inherent heterogeneity\nin FL networks, arising from variations in data distribution, size, and device\ncapabilities, poses challenges in user federation. Recognizing this,\nPersonalized Federated Learning (PFL) emphasizes tailoring learning processes\nto individual data profiles. In this paper, we address the complexity of\nclustering users in PFL, especially in dynamic networks, by introducing a\ndynamic Upper Confidence Bound (dUCB) algorithm inspired by the multi-armed\nbandit (MAB) approach. The dUCB algorithm ensures that new users can\neffectively find the best cluster for their data distribution by balancing\nexploration and exploitation. The performance of our algorithm is evaluated in\nvarious cases, showing its effectiveness in handling dynamic federated learning\nscenarios.",
            "author": [
                "Zhou Ni",
                "Morteza Hashemi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19069v1",
                "http://arxiv.org/pdf/2310.19069v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19068v1",
            "title": "Sketching Algorithms for Sparse Dictionary Learning: PTAS and Turnstile\n  Streaming",
            "updated": "2023-10-29T16:46:26Z",
            "published": "2023-10-29T16:46:26Z",
            "summary": "Sketching algorithms have recently proven to be a powerful approach both for\ndesigning low-space streaming algorithms as well as fast polynomial time\napproximation schemes (PTAS). In this work, we develop new techniques to extend\nthe applicability of sketching-based approaches to the sparse dictionary\nlearning and the Euclidean $k$-means clustering problems. In particular, we\ninitiate the study of the challenging setting where the dictionary/clustering\nassignment for each of the $n$ input points must be output, which has\nsurprisingly received little attention in prior work. On the fast algorithms\nfront, we obtain a new approach for designing PTAS's for the $k$-means\nclustering problem, which generalizes to the first PTAS for the sparse\ndictionary learning problem. On the streaming algorithms front, we obtain new\nupper bounds and lower bounds for dictionary learning and $k$-means clustering.\nIn particular, given a design matrix $\\mathbf A\\in\\mathbb R^{n\\times d}$ in a\nturnstile stream, we show an $\\tilde O(nr/\\epsilon^2 + dk/\\epsilon)$ space\nupper bound for $r$-sparse dictionary learning of size $k$, an $\\tilde\nO(n/\\epsilon^2 + dk/\\epsilon)$ space upper bound for $k$-means clustering, as\nwell as an $\\tilde O(n)$ space upper bound for $k$-means clustering on random\norder row insertion streams with a natural \"bounded sensitivity\" assumption. On\nthe lower bounds side, we obtain a general $\\tilde\\Omega(n/\\epsilon +\ndk/\\epsilon)$ lower bound for $k$-means clustering, as well as an\n$\\tilde\\Omega(n/\\epsilon^2)$ lower bound for algorithms which can estimate the\ncost of a single fixed set of candidate centers.",
            "author": [
                "Gregory Dexter",
                "Petros Drineas",
                "David P. Woodruff",
                "Taisuke Yasuda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19068v1",
                "http://arxiv.org/pdf/2310.19068v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19066v1",
            "title": "Gauge-optimal approximate learning for small data classification\n  problems",
            "updated": "2023-10-29T16:46:05Z",
            "published": "2023-10-29T16:46:05Z",
            "summary": "Small data learning problems are characterized by a significant discrepancy\nbetween the limited amount of response variable observations and the large\nfeature space dimension. In this setting, the common learning tools struggle to\nidentify the features important for the classification task from those that\nbear no relevant information, and cannot derive an appropriate learning rule\nwhich allows to discriminate between different classes. As a potential solution\nto this problem, here we exploit the idea of reducing and rotating the feature\nspace in a lower-dimensional gauge and propose the Gauge-Optimal Approximate\nLearning (GOAL) algorithm, which provides an analytically tractable joint\nsolution to the dimension reduction, feature segmentation and classification\nproblems for small data learning problems. We prove that the optimal solution\nof the GOAL algorithm consists in piecewise-linear functions in the Euclidean\nspace, and that it can be approximated through a monotonically convergent\nalgorithm which presents -- under the assumption of a discrete segmentation of\nthe feature space -- a closed-form solution for each optimization substep and\nan overall linear iteration cost scaling. The GOAL algorithm has been compared\nto other state-of-the-art machine learning (ML) tools on both synthetic data\nand challenging real-world applications from climate science and bioinformatics\n(i.e., prediction of the El Nino Southern Oscillation and inference of\nepigenetically-induced gene-activity networks from limited experimental data).\nThe experimental results show that the proposed algorithm outperforms the\nreported best competitors for these problems both in learning performance and\ncomputational cost.",
            "author": [
                "Edoardo Vecchi",
                "Davide Bassetti",
                "Fabio Graziato",
                "Lukas Pospisil",
                "Illia Horenko"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19066v1",
                "http://arxiv.org/pdf/2310.19066v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19065v1",
            "title": "Evaluating LLP Methods: Challenges and Approaches",
            "updated": "2023-10-29T16:45:20Z",
            "published": "2023-10-29T16:45:20Z",
            "summary": "Learning from Label Proportions (LLP) is an established machine learning\nproblem with numerous real-world applications. In this setting, data items are\ngrouped into bags, and the goal is to learn individual item labels, knowing\nonly the features of the data and the proportions of labels in each bag.\nAlthough LLP is a well-established problem, it has several unusual aspects that\ncreate challenges for benchmarking learning methods. Fundamental complications\narise because of the existence of different LLP variants, i.e., dependence\nstructures that can exist between items, labels, and bags. Accordingly, the\nfirst algorithmic challenge is the generation of variant-specific datasets\ncapturing the diversity of dependence structures and bag characteristics. The\nsecond methodological challenge is model selection, i.e., hyperparameter\ntuning; due to the nature of LLP, model selection cannot easily use the\nstandard machine learning paradigm. The final benchmarking challenge consists\nof properly evaluating LLP solution methods across various LLP variants. We\nnote that there is very little consideration of these issues in prior work, and\nthere are no general solutions for these challenges proposed to date. To\naddress these challenges, we develop methods capable of generating LLP datasets\nmeeting the requirements of different variants. We use these methods to\ngenerate a collection of datasets encompassing the spectrum of LLP problem\ncharacteristics, which can be used in future evaluation studies. Additionally,\nwe develop guidelines for benchmarking LLP algorithms, including the model\nselection and evaluation steps. Finally, we illustrate the new methods and\nguidelines by performing an extensive benchmark of a set of well-known LLP\nalgorithms. We show that choosing the best algorithm depends critically on the\nLLP variant and model selection method, demonstrating the need for our proposed\napproach.",
            "author": [
                "Gabriel Franco",
                "Giovanni Comarela",
                "Mark Crovella"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19065v1",
                "http://arxiv.org/pdf/2310.19065v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19064v1",
            "title": "Revisiting the Learnability of Apple Tasting",
            "updated": "2023-10-29T16:37:51Z",
            "published": "2023-10-29T16:37:51Z",
            "summary": "In online binary classification under \\textit{apple tasting} feedback, the\nlearner only observes the true label if it predicts \"1\". First studied by\n\\cite{helmbold2000apple}, we revisit this classical partial-feedback setting\nand study online learnability from a combinatorial perspective. We show that\nthe Littlestone dimension continues to prove a tight quantitative\ncharacterization of apple tasting in the agnostic setting, closing an open\nquestion posed by \\cite{helmbold2000apple}. In addition, we give a new\ncombinatorial parameter, called the Effective width, that tightly quantifies\nthe minimax expected mistakes in the realizable setting. As a corollary, we use\nthe Effective width to establish a \\textit{trichotomy} of the minimax expected\nnumber of mistakes in the realizable setting. In particular, we show that in\nthe realizable setting, the expected number of mistakes for any learner under\napple tasting feedback can only be $\\Theta(1), \\Theta(\\sqrt{T})$, or\n$\\Theta(T)$.",
            "author": [
                "Vinod Raman",
                "Unique Subedi",
                "Ananth Raman",
                "Ambuj Tewari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19064v1",
                "http://arxiv.org/pdf/2310.19064v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19063v1",
            "title": "Feature Aggregation in Joint Sound Classification and Localization\n  Neural Networks",
            "updated": "2023-10-29T16:37:14Z",
            "published": "2023-10-29T16:37:14Z",
            "summary": "This study addresses the application of deep learning techniques in joint\nsound signal classification and localization networks. Current state-of-the-art\nsound source localization deep learning networks lack feature aggregation\nwithin their architecture. Feature aggregation enhances model performance by\nenabling the consolidation of information from different feature scales,\nthereby improving feature robustness and invariance. This is particularly\nimportant in SSL networks, which must differentiate direct and indirect\nacoustic signals. To address this gap, we adapt feature aggregation techniques\nfrom computer vision neural networks to signal detection neural networks.\nAdditionally, we propose the Scale Encoding Network (SEN) for feature\naggregation to encode features from various scales, compressing the network for\nmore computationally efficient aggregation. To evaluate the efficacy of feature\naggregation in SSL networks, we integrated the following computer vision\nfeature aggregation sub-architectures into a SSL control architecture: Path\nAggregation Network (PANet), Weighted Bi-directional Feature Pyramid Network\n(BiFPN), and SEN. These sub-architectures were evaluated using two metrics for\nsignal classification and two metrics for direction-of-arrival regression.\nPANet and BiFPN are established aggregators in computer vision models, while\nthe proposed SEN is a more compact aggregator. The results suggest that models\nincorporating feature aggregations outperformed the control model, the Sound\nEvent Localization and Detection network (SELDnet), in both sound signal\nclassification and localization. The feature aggregation techniques enhance the\nperformance of sound detection neural networks, particularly in\ndirection-of-arrival regression.",
            "author": [
                "Brendan Healy",
                "Patrick McNamee",
                "Zahra Nili Ahmadabadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19063v1",
                "http://arxiv.org/pdf/2310.19063v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19062v2",
            "title": "A multi-modal table tennis robot system",
            "updated": "2023-11-25T15:29:59Z",
            "published": "2023-10-29T16:35:29Z",
            "summary": "In recent years, robotic table tennis has become a popular research challenge\nfor perception and robot control. Here, we present an improved table tennis\nrobot system with high accuracy vision detection and fast robot reaction. Based\non previous work, our system contains a KUKA robot arm with 6 DOF, with four\nframe-based cameras and two additional event-based cameras. We developed a\nnovel calibration approach to calibrate this multimodal perception system. For\ntable tennis, spin estimation is crucial. Therefore, we introduced a novel, and\nmore accurate spin estimation approach. Finally, we show how combining the\noutput of an event-based camera and a Spiking Neural Network (SNN) can be used\nfor accurate ball detection.",
            "author": [
                "Andreas Ziegler",
                "Thomas Gossard",
                "Karl Vetter",
                "Jonas Tebbe",
                "Andreas Zell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19062v2",
                "http://arxiv.org/pdf/2310.19062v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19059v1",
            "title": "Escaping Saddle Points in Heterogeneous Federated Learning via\n  Distributed SGD with Communication Compression",
            "updated": "2023-10-29T16:24:53Z",
            "published": "2023-10-29T16:24:53Z",
            "summary": "We consider the problem of finding second-order stationary points of\nheterogeneous federated learning (FL). Previous works in FL mostly focus on\nfirst-order convergence guarantees, which do not rule out the scenario of\nunstable saddle points. Meanwhile, it is a key bottleneck of FL to achieve\ncommunication efficiency without compensating the learning accuracy, especially\nwhen local data are highly heterogeneous across different clients. Given this,\nwe propose a novel algorithm Power-EF that only communicates compressed\ninformation via a novel error-feedback scheme. To our knowledge, Power-EF is\nthe first distributed and compressed SGD algorithm that provably escapes saddle\npoints in heterogeneous FL without any data homogeneity assumptions. In\nparticular, Power-EF improves to second-order stationary points after visiting\nfirst-order (possibly saddle) points, using additional gradient queries and\ncommunication rounds only of almost the same order required by first-order\nconvergence, and the convergence rate exhibits a linear speedup in terms of the\nnumber of workers. Our theory improves/recovers previous results, while\nextending to much more tolerant settings on the local data. Numerical\nexperiments are provided to complement the theory.",
            "author": [
                "Sijin Chen",
                "Zhize Li",
                "Yuejie Chi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19059v1",
                "http://arxiv.org/pdf/2310.19059v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19057v1",
            "title": "A Unique Training Strategy to Enhance Language Models Capabilities for\n  Health Mention Detection from Social Media Content",
            "updated": "2023-10-29T16:08:33Z",
            "published": "2023-10-29T16:08:33Z",
            "summary": "An ever-increasing amount of social media content requires advanced AI-based\ncomputer programs capable of extracting useful information. Specifically, the\nextraction of health-related content from social media is useful for the\ndevelopment of diverse types of applications including disease spread,\nmortality rate prediction, and finding the impact of diverse types of drugs on\ndiverse types of diseases. Language models are competent in extracting the\nsyntactic and semantics of text. However, they face a hard time extracting\nsimilar patterns from social media texts. The primary reason for this shortfall\nlies in the non-standardized writing style commonly employed by social media\nusers. Following the need for an optimal language model competent in extracting\nuseful patterns from social media text, the key goal of this paper is to train\nlanguage models in such a way that they learn to derive generalized patterns.\nThe key goal is achieved through the incorporation of random weighted\nperturbation and contrastive learning strategies. On top of a unique training\nstrategy, a meta predictor is proposed that reaps the benefits of 5 different\nlanguage models for discriminating posts of social media text into non-health\nand health-related classes. Comprehensive experimentation across 3 public\nbenchmark datasets reveals that the proposed training strategy improves the\nperformance of the language models up to 3.87%, in terms of F1-score, as\ncompared to their performance with traditional training. Furthermore, the\nproposed meta predictor outperforms existing health mention classification\npredictors across all 3 benchmark datasets.",
            "author": [
                "Pervaiz Iqbal Khan",
                "Muhammad Nabeel Asim",
                "Andreas Dengel",
                "Sheraz Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19057v1",
                "http://arxiv.org/pdf/2310.19057v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19055v1",
            "title": "A Survey on Recent Named Entity Recognition and Relation Classification\n  Methods with Focus on Few-Shot Learning Approaches",
            "updated": "2023-10-29T16:02:46Z",
            "published": "2023-10-29T16:02:46Z",
            "summary": "Named entity recognition and relation classification are key stages for\nextracting information from unstructured text. Several natural language\nprocessing applications utilize the two tasks, such as information retrieval,\nknowledge graph construction and completion, question answering and other\ndomain-specific applications, such as biomedical data mining. We present a\nsurvey of recent approaches in the two tasks with focus on few-shot learning\napproaches. Our work compares the main approaches followed in the two\nparadigms. Additionally, we report the latest metric scores in the two tasks\nwith a structured analysis that considers the results in the few-shot learning\nscope.",
            "author": [
                "Sakher Alqaaidi",
                "Elika Bozorgi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19055v1",
                "http://arxiv.org/pdf/2310.19055v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19054v1",
            "title": "Object-centric architectures enable efficient causal representation\n  learning",
            "updated": "2023-10-29T16:01:03Z",
            "published": "2023-10-29T16:01:03Z",
            "summary": "Causal representation learning has showed a variety of settings in which we\ncan disentangle latent variables with identifiability guarantees (up to some\nreasonable equivalence class). Common to all of these approaches is the\nassumption that (1) the latent variables are represented as $d$-dimensional\nvectors, and (2) that the observations are the output of some injective\ngenerative function of these latent variables. While these assumptions appear\nbenign, we show that when the observations are of multiple objects, the\ngenerative function is no longer injective and disentanglement fails in\npractice. We can address this failure by combining recent developments in\nobject-centric learning and causal representation learning. By modifying the\nSlot Attention architecture arXiv:2006.15055, we develop an object-centric\narchitecture that leverages weak supervision from sparse perturbations to\ndisentangle each object's properties. This approach is more data-efficient in\nthe sense that it requires significantly fewer perturbations than a comparable\napproach that encodes to a Euclidean space and we show that this approach\nsuccessfully disentangles the properties of a set of objects in a series of\nsimple image-based disentanglement experiments.",
            "author": [
                "Amin Mansouri",
                "Jason Hartford",
                "Yan Zhang",
                "Yoshua Bengio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19054v1",
                "http://arxiv.org/pdf/2310.19054v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19053v1",
            "title": "Datasets and Benchmarks for Nanophotonic Structure and Parametric Design\n  Simulations",
            "updated": "2023-10-29T15:57:42Z",
            "published": "2023-10-29T15:57:42Z",
            "summary": "Nanophotonic structures have versatile applications including solar cells,\nanti-reflective coatings, electromagnetic interference shielding, optical\nfilters, and light emitting diodes. To design and understand these nanophotonic\nstructures, electrodynamic simulations are essential. These simulations enable\nus to model electromagnetic fields over time and calculate optical properties.\nIn this work, we introduce frameworks and benchmarks to evaluate nanophotonic\nstructures in the context of parametric structure design problems. The\nbenchmarks are instrumental in assessing the performance of optimization\nalgorithms and identifying an optimal structure based on target optical\nproperties. Moreover, we explore the impact of varying grid sizes in\nelectrodynamic simulations, shedding light on how evaluation fidelity can be\nstrategically leveraged in enhancing structure designs.",
            "author": [
                "Jungtaek Kim",
                "Mingxuan Li",
                "Oliver Hinder",
                "Paul W. Leu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19053v1",
                "http://arxiv.org/pdf/2310.19053v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.optics",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19043v1",
            "title": "Differentially Private Permutation Tests: Applications to Kernel Methods",
            "updated": "2023-10-29T15:13:36Z",
            "published": "2023-10-29T15:13:36Z",
            "summary": "Recent years have witnessed growing concerns about the privacy of sensitive\ndata. In response to these concerns, differential privacy has emerged as a\nrigorous framework for privacy protection, gaining widespread recognition in\nboth academic and industrial circles. While substantial progress has been made\nin private data analysis, existing methods often suffer from impracticality or\na significant loss of statistical efficiency. This paper aims to alleviate\nthese concerns in the context of hypothesis testing by introducing\ndifferentially private permutation tests. The proposed framework extends\nclassical non-private permutation tests to private settings, maintaining both\nfinite-sample validity and differential privacy in a rigorous manner. The power\nof the proposed test depends on the choice of a test statistic, and we\nestablish general conditions for consistency and non-asymptotic uniform power.\nTo demonstrate the utility and practicality of our framework, we focus on\nreproducing kernel-based test statistics and introduce differentially private\nkernel tests for two-sample and independence testing: dpMMD and dpHSIC. The\nproposed kernel tests are straightforward to implement, applicable to various\ntypes of data, and attain minimax optimal power across different privacy\nregimes. Our empirical evaluations further highlight their competitive power\nunder various synthetic and real-world scenarios, emphasizing their practical\nvalue. The code is publicly available to facilitate the implementation of our\nframework.",
            "author": [
                "Ilmun Kim",
                "Antonin Schrab"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19043v1",
                "http://arxiv.org/pdf/2310.19043v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.CR",
                "cs.LG",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19041v1",
            "title": "On Linear Separation Capacity of Self-Supervised Representation Learning",
            "updated": "2023-10-29T15:08:35Z",
            "published": "2023-10-29T15:08:35Z",
            "summary": "Recent advances in self-supervised learning have highlighted the efficacy of\ndata augmentation in learning data representation from unlabeled data. Training\na linear model atop these enhanced representations can yield an adept\nclassifier. Despite the remarkable empirical performance, the underlying\nmechanisms that enable data augmentation to unravel nonlinear data structures\ninto linearly separable representations remain elusive. This paper seeks to\nbridge this gap by investigating under what conditions learned representations\ncan linearly separate manifolds when data is drawn from a multi-manifold model.\nOur investigation reveals that data augmentation offers additional information\nbeyond observed data and can thus improve the information-theoretic optimal\nrate of linear separation capacity. In particular, we show that self-supervised\nlearning can linearly separate manifolds with a smaller distance than\nunsupervised learning, underscoring the additional benefits of data\naugmentation. Our theoretical analysis further underscores that the performance\nof downstream linear classifiers primarily hinges on the linear separability of\ndata representations rather than the size of the labeled data set, reaffirming\nthe viability of constructing efficient classifiers with limited labeled data\namid an expansive unlabeled data set.",
            "author": [
                "Shulei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19041v1",
                "http://arxiv.org/pdf/2310.19041v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19039v1",
            "title": "Machine Learning for the identification of phase-transitions in\n  interacting agent-based systems",
            "updated": "2023-10-29T15:07:08Z",
            "published": "2023-10-29T15:07:08Z",
            "summary": "Deriving closed-form, analytical expressions for reduced-order models, and\njudiciously choosing the closures leading to them, has long been the strategy\nof choice for studying phase- and noise-induced transitions for agent-based\nmodels (ABMs). In this paper, we propose a data-driven framework that pinpoints\nphase transitions for an ABM in its mean-field limit, using a smaller number of\nvariables than traditional closed-form models. To this end, we use the manifold\nlearning algorithm Diffusion Maps to identify a parsimonious set of data-driven\nlatent variables, and show that they are in one-to-one correspondence with the\nexpected theoretical order parameter of the ABM. We then utilize a deep\nlearning framework to obtain a conformal reparametrization of the data-driven\ncoordinates that facilitates, in our example, the identification of a single\nparameter-dependent ODE in these coordinates. We identify this ODE through a\nresidual neural network inspired by a numerical integration scheme (forward\nEuler). We then use the identified ODE -- enabled through an odd symmetry\ntransformation -- to construct the bifurcation diagram exhibiting the phase\ntransition.",
            "author": [
                "Nikolaos Evangelou",
                "Dimitrios G. Giovanis",
                "George A. Kevrekidis",
                "Grigorios A. Pavliotis",
                "Ioannis G. Kevrekidis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19039v1",
                "http://arxiv.org/pdf/2310.19039v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19038v1",
            "title": "Boosting Decision-Based Black-Box Adversarial Attack with Gradient\n  Priors",
            "updated": "2023-10-29T15:05:39Z",
            "published": "2023-10-29T15:05:39Z",
            "summary": "Decision-based methods have shown to be effective in black-box adversarial\nattacks, as they can obtain satisfactory performance and only require to access\nthe final model prediction. Gradient estimation is a critical step in black-box\nadversarial attacks, as it will directly affect the query efficiency. Recent\nworks have attempted to utilize gradient priors to facilitate score-based\nmethods to obtain better results. However, these gradient priors still suffer\nfrom the edge gradient discrepancy issue and the successive iteration gradient\ndirection issue, thus are difficult to simply extend to decision-based methods.\nIn this paper, we propose a novel Decision-based Black-box Attack framework\nwith Gradient Priors (DBA-GP), which seamlessly integrates the data-dependent\ngradient prior and time-dependent prior into the gradient estimation procedure.\nFirst, by leveraging the joint bilateral filter to deal with each random\nperturbation, DBA-GP can guarantee that the generated perturbations in edge\nlocations are hardly smoothed, i.e., alleviating the edge gradient discrepancy,\nthus remaining the characteristics of the original image as much as possible.\nSecond, by utilizing a new gradient updating strategy to automatically adjust\nthe successive iteration gradient direction, DBA-GP can accelerate the\nconvergence speed, thus improving the query efficiency. Extensive experiments\nhave demonstrated that the proposed method outperforms other strong baselines\nsignificantly.",
            "author": [
                "Han Liu",
                "Xingshuo Huang",
                "Xiaotong Zhang",
                "Qimai Li",
                "Fenglong Ma",
                "Wei Wang",
                "Hongyang Chen",
                "Hong Yu",
                "Xianchao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19038v1",
                "http://arxiv.org/pdf/2310.19038v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19035v1",
            "title": "Does Invariant Graph Learning via Environment Augmentation Learn\n  Invariance?",
            "updated": "2023-10-29T14:57:37Z",
            "published": "2023-10-29T14:57:37Z",
            "summary": "Invariant graph representation learning aims to learn the invariance among\ndata from different environments for out-of-distribution generalization on\ngraphs. As the graph environment partitions are usually expensive to obtain,\naugmenting the environment information has become the de facto approach.\nHowever, the usefulness of the augmented environment information has never been\nverified. In this work, we find that it is fundamentally impossible to learn\ninvariant graph representations via environment augmentation without additional\nassumptions. Therefore, we develop a set of minimal assumptions, including\nvariation sufficiency and variation consistency, for feasible invariant graph\nlearning. We then propose a new framework Graph invAriant Learning Assistant\n(GALA). GALA incorporates an assistant model that needs to be sensitive to\ngraph environment changes or distribution shifts. The correctness of the proxy\npredictions by the assistant model hence can differentiate the variations in\nspurious subgraphs. We show that extracting the maximally invariant subgraph to\nthe proxy predictions provably identifies the underlying invariant subgraph for\nsuccessful OOD generalization under the established minimal assumptions.\nExtensive experiments on datasets including DrugOOD with various graph\ndistribution shifts confirm the effectiveness of GALA.",
            "author": [
                "Yongqiang Chen",
                "Yatao Bian",
                "Kaiwen Zhou",
                "Binghui Xie",
                "Bo Han",
                "James Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19035v1",
                "http://arxiv.org/pdf/2310.19035v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19025v2",
            "title": "An Improved Relaxation for Oracle-Efficient Adversarial Contextual\n  Bandits",
            "updated": "2023-11-10T16:14:10Z",
            "published": "2023-10-29T14:31:34Z",
            "summary": "We present an oracle-efficient relaxation for the adversarial contextual\nbandits problem, where the contexts are sequentially drawn i.i.d from a known\ndistribution and the cost sequence is chosen by an online adversary. Our\nalgorithm has a regret bound of\n$O(T^{\\frac{2}{3}}(K\\log(|\\Pi|))^{\\frac{1}{3}})$ and makes at most $O(K)$ calls\nper round to an offline optimization oracle, where $K$ denotes the number of\nactions, $T$ denotes the number of rounds and $\\Pi$ denotes the set of\npolicies. This is the first result to improve the prior best bound of\n$O((TK)^{\\frac{2}{3}}(\\log(|\\Pi|))^{\\frac{1}{3}})$ as obtained by Syrgkanis et\nal. at NeurIPS 2016, and the first to match the original bound of Langford and\nZhang at NeurIPS 2007 which was obtained for the stochastic case.",
            "author": [
                "Kiarash Banihashem",
                "MohammadTaghi Hajiaghayi",
                "Suho Shin",
                "Max Springer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19025v2",
                "http://arxiv.org/pdf/2310.19025v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19022v1",
            "title": "Optimization Landscape of Policy Gradient Methods for Discrete-time\n  Static Output Feedback",
            "updated": "2023-10-29T14:25:57Z",
            "published": "2023-10-29T14:25:57Z",
            "summary": "In recent times, significant advancements have been made in delving into the\noptimization landscape of policy gradient methods for achieving optimal control\nin linear time-invariant (LTI) systems. Compared with state-feedback control,\noutput-feedback control is more prevalent since the underlying state of the\nsystem may not be fully observed in many practical settings. This paper\nanalyzes the optimization landscape inherent to policy gradient methods when\napplied to static output feedback (SOF) control in discrete-time LTI systems\nsubject to quadratic cost. We begin by establishing crucial properties of the\nSOF cost, encompassing coercivity, L-smoothness, and M-Lipschitz continuous\nHessian. Despite the absence of convexity, we leverage these properties to\nderive novel findings regarding convergence (and nearly dimension-free rate) to\nstationary points for three policy gradient methods, including the vanilla\npolicy gradient method, the natural policy gradient method, and the\nGauss-Newton method. Moreover, we provide proof that the vanilla policy\ngradient method exhibits linear convergence towards local minima when\ninitialized near such minima. The paper concludes by presenting numerical\nexamples that validate our theoretical findings. These results not only\ncharacterize the performance of gradient descent for optimizing the SOF problem\nbut also provide insights into the effectiveness of general policy gradient\nmethods within the realm of reinforcement learning.",
            "author": [
                "Jingliang Duan",
                "Jie Li",
                "Xuyang Chen",
                "Kai Zhao",
                "Shengbo Eben Li",
                "Lin Zhao"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TCYB.2023.3323316",
                "http://arxiv.org/abs/2310.19022v1",
                "http://arxiv.org/pdf/2310.19022v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19019v2",
            "title": "TeacherLM: Teaching to Fish Rather Than Giving the Fish, Language\n  Modeling Likewise",
            "updated": "2023-10-31T06:49:13Z",
            "published": "2023-10-29T14:16:54Z",
            "summary": "Large Language Models (LLMs) exhibit impressive reasoning and data\naugmentation capabilities in various NLP tasks. However, what about small\nmodels? In this work, we propose TeacherLM-7.1B, capable of annotating relevant\nfundamentals, chain of thought, and common mistakes for most NLP samples, which\nmakes annotation more than just an answer, thus allowing other models to learn\n\"why\" instead of just \"what\". The TeacherLM-7.1B model achieved a zero-shot\nscore of 52.3 on MMLU, surpassing most models with over 100B parameters. Even\nmore remarkable is its data augmentation ability. Based on TeacherLM-7.1B, we\naugmented 58 NLP datasets and taught various student models with different\nparameters from OPT and BLOOM series in a multi-task setting. The experimental\nresults indicate that the data augmentation provided by TeacherLM has brought\nsignificant benefits. We will release the TeacherLM series of models and\naugmented datasets as open-source.",
            "author": [
                "Nan He",
                "Hanyu Lai",
                "Chenyang Zhao",
                "Zirui Cheng",
                "Junting Pan",
                "Ruoyu Qin",
                "Ruofan Lu",
                "Rui Lu",
                "Yunchen Zhang",
                "Gangming Zhao",
                "Zhaohui Hou",
                "Zhiyuan Huang",
                "Shaoqing Lu",
                "Ding Liang",
                "Mingjie Zhan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19019v2",
                "http://arxiv.org/pdf/2310.19019v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19011v1",
            "title": "Efficient Test-Time Adaptation for Super-Resolution with Second-Order\n  Degradation and Reconstruction",
            "updated": "2023-10-29T13:58:57Z",
            "published": "2023-10-29T13:58:57Z",
            "summary": "Image super-resolution (SR) aims to learn a mapping from low-resolution (LR)\nto high-resolution (HR) using paired HR-LR training images. Conventional SR\nmethods typically gather the paired training data by synthesizing LR images\nfrom HR images using a predetermined degradation model, e.g., Bicubic\ndown-sampling. However, the realistic degradation type of test images may\nmismatch with the training-time degradation type due to the dynamic changes of\nthe real-world scenarios, resulting in inferior-quality SR images. To address\nthis, existing methods attempt to estimate the degradation model and train an\nimage-specific model, which, however, is quite time-consuming and impracticable\nto handle rapidly changing domain shifts. Moreover, these methods largely\nconcentrate on the estimation of one degradation type (e.g., blur degradation),\noverlooking other degradation types like noise and JPEG in real-world test-time\nscenarios, thus limiting their practicality. To tackle these problems, we\npresent an efficient test-time adaptation framework for SR, named SRTTA, which\nis able to quickly adapt SR models to test domains with different/unknown\ndegradation types. Specifically, we design a second-order degradation scheme to\nconstruct paired data based on the degradation type of the test image, which is\npredicted by a pre-trained degradation classifier. Then, we adapt the SR model\nby implementing feature-level reconstruction learning from the initial test\nimage to its second-order degraded counterparts, which helps the SR model\ngenerate plausible HR images. Extensive experiments are conducted on newly\nsynthesized corrupted DIV2K datasets with 8 different degradations and several\nreal-world datasets, demonstrating that our SRTTA framework achieves an\nimpressive improvement over existing methods with satisfying speed. The source\ncode is available at https://github.com/DengZeshuai/SRTTA.",
            "author": [
                "Zeshuai Deng",
                "Zhuokun Chen",
                "Shuaicheng Niu",
                "Thomas H. Li",
                "Bohan Zhuang",
                "Mingkui Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19011v1",
                "http://arxiv.org/pdf/2310.19011v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19007v2",
            "title": "Behavior Alignment via Reward Function Optimization",
            "updated": "2023-10-31T04:58:20Z",
            "published": "2023-10-29T13:45:07Z",
            "summary": "Designing reward functions for efficiently guiding reinforcement learning\n(RL) agents toward specific behaviors is a complex task. This is challenging\nsince it requires the identification of reward structures that are not sparse\nand that avoid inadvertently inducing undesirable behaviors. Naively modifying\nthe reward structure to offer denser and more frequent feedback can lead to\nunintended outcomes and promote behaviors that are not aligned with the\ndesigner's intended goal. Although potential-based reward shaping is often\nsuggested as a remedy, we systematically investigate settings where deploying\nit often significantly impairs performance. To address these issues, we\nintroduce a new framework that uses a bi-level objective to learn\n\\emph{behavior alignment reward functions}. These functions integrate auxiliary\nrewards reflecting a designer's heuristics and domain knowledge with the\nenvironment's primary rewards. Our approach automatically determines the most\neffective way to blend these types of feedback, thereby enhancing robustness\nagainst heuristic reward misspecification. Remarkably, it can also adapt an\nagent's policy optimization process to mitigate suboptimalities resulting from\nlimitations and biases inherent in the underlying RL algorithms. We evaluate\nour method's efficacy on a diverse set of tasks, from small-scale experiments\nto high-dimensional control challenges. We investigate heuristic auxiliary\nrewards of varying quality -- some of which are beneficial and others\ndetrimental to the learning process. Our results show that our framework offers\na robust and principled way to integrate designer-specified heuristics. It not\nonly addresses key shortcomings of existing approaches but also consistently\nleads to high-performing solutions, even when given misaligned or\npoorly-specified auxiliary reward functions.",
            "author": [
                "Dhawal Gupta",
                "Yash Chandak",
                "Scott M. Jordan",
                "Philip S. Thomas",
                "Bruno Castro da Silva"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19007v2",
                "http://arxiv.org/pdf/2310.19007v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19005v2",
            "title": "Kernel-based Joint Multiple Graph Learning and Clustering of Graph\n  Signals",
            "updated": "2023-11-07T11:12:31Z",
            "published": "2023-10-29T13:41:12Z",
            "summary": "Within the context of Graph Signal Processing (GSP), Graph Learning (GL) is\nconcerned with the inference of the graph's underlying structure from nodal\nobservations. However, real-world data often contains diverse information,\nnecessitating the simultaneous clustering and learning of multiple graphs. In\npractical applications, valuable node-specific covariates, represented as\nkernels, have been underutilized by existing graph signal clustering methods.\nIn this letter, we propose a new framework, named Kernel-based joint Multiple\nGL and clustering of graph signals (KMGL), that leverages a multi-convex\noptimization approach. This allows us to integrate node-side information,\nconstruct low-pass filters, and efficiently solve the optimization problem. The\nexperiments demonstrate that KMGL significantly enhances the robustness of GL\nand clustering, particularly in scenarios with high noise levels and a\nsubstantial number of clusters. These findings underscore the potential of KMGL\nfor improving the performance of GSP methods in diverse, real-world\napplications.",
            "author": [
                "Mohamad H. Alizade",
                "Aref Einizade",
                "Jhony H. Giraldo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19005v2",
                "http://arxiv.org/pdf/2310.19005v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.19001v1",
            "title": "Uncovering Prototypical Knowledge for Weakly Open-Vocabulary Semantic\n  Segmentation",
            "updated": "2023-10-29T13:18:00Z",
            "published": "2023-10-29T13:18:00Z",
            "summary": "This paper studies the problem of weakly open-vocabulary semantic\nsegmentation (WOVSS), which learns to segment objects of arbitrary classes\nusing mere image-text pairs. Existing works turn to enhance the vanilla vision\ntransformer by introducing explicit grouping recognition, i.e., employing\nseveral group tokens/centroids to cluster the image tokens and perform the\ngroup-text alignment. Nevertheless, these methods suffer from a granularity\ninconsistency regarding the usage of group tokens, which are aligned in the\nall-to-one v.s. one-to-one manners during the training and inference phases,\nrespectively. We argue that this discrepancy arises from the lack of elaborate\nsupervision for each group token. To bridge this granularity gap, this paper\nexplores explicit supervision for the group tokens from the prototypical\nknowledge. To this end, this paper proposes the non-learnable prototypical\nregularization (NPR) where non-learnable prototypes are estimated from source\nfeatures to serve as supervision and enable contrastive matching of the group\ntokens. This regularization encourages the group tokens to segment objects with\nless redundancy and capture more comprehensive semantic regions, leading to\nincreased compactness and richness. Based on NPR, we propose the prototypical\nguidance segmentation network (PGSeg) that incorporates multi-modal\nregularization by leveraging prototypical sources from both images and texts at\ndifferent levels, progressively enhancing the segmentation capability with\ndiverse prototypical patterns. Experimental results show that our proposed\nmethod achieves state-of-the-art performance on several benchmark datasets. The\nsource code is available at https://github.com/Ferenas/PGSeg.",
            "author": [
                "Fei Zhang",
                "Tianfei Zhou",
                "Boyang Li",
                "Hao He",
                "Chaofan Ma",
                "Tianjiao Zhang",
                "Jiangchao Yao",
                "Ya Zhang",
                "Yanfeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19001v1",
                "http://arxiv.org/pdf/2310.19001v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18999v2",
            "title": "DynPoint: Dynamic Neural Point For View Synthesis",
            "updated": "2023-10-31T05:33:03Z",
            "published": "2023-10-29T12:55:53Z",
            "summary": "The introduction of neural radiance fields has greatly improved the\neffectiveness of view synthesis for monocular videos. However, existing\nalgorithms face difficulties when dealing with uncontrolled or lengthy\nscenarios, and require extensive training time specific to each new scenario.\nTo tackle these limitations, we propose DynPoint, an algorithm designed to\nfacilitate the rapid synthesis of novel views for unconstrained monocular\nvideos. Rather than encoding the entirety of the scenario information into a\nlatent representation, DynPoint concentrates on predicting the explicit 3D\ncorrespondence between neighboring frames to realize information aggregation.\nSpecifically, this correspondence prediction is achieved through the estimation\nof consistent depth and scene flow information across frames. Subsequently, the\nacquired correspondence is utilized to aggregate information from multiple\nreference frames to a target frame, by constructing hierarchical neural point\nclouds. The resulting framework enables swift and accurate view synthesis for\ndesired views of target frames. The experimental results obtained demonstrate\nthe considerable acceleration of training time achieved - typically an order of\nmagnitude - by our proposed method while yielding comparable outcomes compared\nto prior approaches. Furthermore, our method exhibits strong robustness in\nhandling long-duration videos without learning a canonical representation of\nvideo content.",
            "author": [
                "Kaichen Zhou",
                "Jia-Xing Zhong",
                "Sangyun Shin",
                "Kai Lu",
                "Yiyuan Yang",
                "Andrew Markham",
                "Niki Trigoni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18999v2",
                "http://arxiv.org/pdf/2310.18999v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18988v1",
            "title": "A U-turn on Double Descent: Rethinking Parameter Counting in Statistical\n  Learning",
            "updated": "2023-10-29T12:05:39Z",
            "published": "2023-10-29T12:05:39Z",
            "summary": "Conventional statistical wisdom established a well-understood relationship\nbetween model complexity and prediction error, typically presented as a\nU-shaped curve reflecting a transition between under- and overfitting regimes.\nHowever, motivated by the success of overparametrized neural networks, recent\ninfluential work has suggested this theory to be generally incomplete,\nintroducing an additional regime that exhibits a second descent in test error\nas the parameter count p grows past sample size n - a phenomenon dubbed double\ndescent. While most attention has naturally been given to the deep-learning\nsetting, double descent was shown to emerge more generally across non-neural\nmodels: known cases include linear regression, trees, and boosting. In this\nwork, we take a closer look at evidence surrounding these more classical\nstatistical machine learning methods and challenge the claim that observed\ncases of double descent truly extend the limits of a traditional U-shaped\ncomplexity-generalization curve therein. We show that once careful\nconsideration is given to what is being plotted on the x-axes of their double\ndescent plots, it becomes apparent that there are implicitly multiple\ncomplexity axes along which the parameter count grows. We demonstrate that the\nsecond descent appears exactly (and only) when and where the transition between\nthese underlying axes occurs, and that its location is thus not inherently tied\nto the interpolation threshold p=n. We then gain further insight by adopting a\nclassical nonparametric statistics perspective. We interpret the investigated\nmethods as smoothers and propose a generalized measure for the effective number\nof parameters they use on unseen examples, using which we find that their\napparent double descent curves indeed fold back into more traditional convex\nshapes - providing a resolution to tensions between double descent and\nstatistical intuition.",
            "author": [
                "Alicia Curth",
                "Alan Jeffares",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18988v1",
                "http://arxiv.org/pdf/2310.18988v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18987v2",
            "title": "Path Analysis for Effective Fault Localization in Deep Neural Networks",
            "updated": "2023-11-06T16:27:58Z",
            "published": "2023-10-29T12:01:15Z",
            "summary": "Deep learning has revolutionized various real-world applications, but the\nquality of Deep Neural Networks (DNNs) remains a concern. DNNs are complex and\nhave millions of parameters, making it difficult to determine their\ncontributions to fulfilling a task. Moreover, the behavior of a DNN is highly\ninfluenced by the data used during training, making it challenging to collect\nenough data to exercise all potential DNN behavior under all possible\nscenarios. This paper proposes NP SBFL method to locate faulty neural pathways\n(NP) using spectrum-based fault localization (SBFL). Our method identifies\ncritical neurons using the layer-wise relevance propagation (LRP) technique and\ndetermines which critical neurons are faulty. Moreover, we propose a\nmulti-stage gradient ascent (MGA), an extension of gradient ascent (GA), to\neffectively activate a sequence of neurons one at a time while maintaining the\nactivation of previous neurons, so we are able to test the reported faulty\npathways. We evaluated the effectiveness of our method, i.e. NP-SBFL-MGA, on\ntwo commonly used datasets, MNIST and CIFAR-10, two baselines DeepFault and\nNP-SBFL-GA, and three suspicious neuron measures, Tarantula, Ochiai, and\nBarinel. The empirical results showed that NP-SBFL-MGA is statistically more\neffective than the baselines at identifying suspicious paths and synthesizing\nadversarial inputs. Particularly, Tarantula on NP-SBFL-MGA had the highest\nfault detection rate at 96.75%, surpassing DeepFault on Ochiai (89.90%) and\nNP-SBFL-GA on Ochiai (60.61%). Our approach also yielded comparable results to\nthe baselines in synthesizing naturalness inputs, and we found a positive\ncorrelation between the coverage of critical paths and the number of failed\ntests in DNN fault localization.",
            "author": [
                "Soroush Hashemifar",
                "Saeed Parsa",
                "Akram Kalaee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18987v2",
                "http://arxiv.org/pdf/2310.18987v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.NE",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18985v1",
            "title": "Predicting RNA-small molecule binding sites by 3D structure",
            "updated": "2023-10-29T11:50:18Z",
            "published": "2023-10-29T11:50:18Z",
            "summary": "The prediction of RNA-small molecule binding sites is crucial for the\ndiscovery of effective drugs. Various computational methods have been developed\nto address this challenge, using information about the structure and sequence\nof RNA. In this study, we introduce CplxCavity, a combination of a new\nalgorithm and a machine learning model specifically designed to predict\nRNA-small molecule binding sites. CplxCavity leverages the 3D structure of RNA\nor RNA complexes to identify surface cavities that have the potential to bind\nwith small molecules. Our results demonstrate that CplxCavity outperforms\nexisting methods by accurately identifying binding sites for small molecules on\nRNA or RNA complexes. The introduction of CplxCavity represents a significant\nadvancement in computational tools for studying RNA-ligand interactions, and\noffers promising prospects for accelerating drug discovery and the development\nof therapies targeting RNA.",
            "author": [
                "Nan Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18985v1",
                "http://arxiv.org/pdf/2310.18985v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18975v1",
            "title": "Blacksmith: Fast Adversarial Training of Vision Transformers via a\n  Mixture of Single-step and Multi-step Methods",
            "updated": "2023-10-29T10:48:44Z",
            "published": "2023-10-29T10:48:44Z",
            "summary": "Despite the remarkable success achieved by deep learning algorithms in\nvarious domains, such as computer vision, they remain vulnerable to adversarial\nperturbations. Adversarial Training (AT) stands out as one of the most\neffective solutions to address this issue; however, single-step AT can lead to\nCatastrophic Overfitting (CO). This scenario occurs when the adversarially\ntrained network suddenly loses robustness against multi-step attacks like\nProjected Gradient Descent (PGD). Although several approaches have been\nproposed to address this problem in Convolutional Neural Networks (CNNs), we\nfound out that they do not perform well when applied to Vision Transformers\n(ViTs). In this paper, we propose Blacksmith, a novel training strategy to\novercome the CO problem, specifically in ViTs. Our approach utilizes either of\nPGD-2 or Fast Gradient Sign Method (FGSM) randomly in a mini-batch during the\nadversarial training of the neural network. This will increase the diversity of\nour training attacks, which could potentially mitigate the CO issue. To manage\nthe increased training time resulting from this combination, we craft the PGD-2\nattack based on only the first half of the layers, while FGSM is applied\nend-to-end. Through our experiments, we demonstrate that our novel method\neffectively prevents CO, achieves PGD-2 level performance, and outperforms\nother existing techniques including N-FGSM, which is the state-of-the-art\nmethod in fast training for CNNs.",
            "author": [
                "Mahdi Salmani",
                "Alireza Dehghanpour Farashah",
                "Mohammad Azizmalayeri",
                "Mahdi Amiri",
                "Navid Eslami",
                "Mohammad Taghi Manzuri",
                "Mohammad Hossein Rohban"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18975v1",
                "http://arxiv.org/pdf/2310.18975v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18974v1",
            "title": "EtiCor: Corpus for Analyzing LLMs for Etiquettes",
            "updated": "2023-10-29T10:47:23Z",
            "published": "2023-10-29T10:47:23Z",
            "summary": "Etiquettes are an essential ingredient of day-to-day interactions among\npeople. Moreover, etiquettes are region-specific, and etiquettes in one region\nmight contradict those in other regions. In this paper, we propose EtiCor, an\nEtiquettes Corpus, having texts about social norms from five different regions\nacross the globe. The corpus provides a test bed for evaluating LLMs for\nknowledge and understanding of region-specific etiquettes. Additionally, we\npropose the task of Etiquette Sensitivity. We experiment with state-of-the-art\nLLMs (Delphi, Falcon40B, and GPT-3.5). Initial results indicate that LLMs,\nmostly fail to understand etiquettes from regions from non-Western world.",
            "author": [
                "Ashutosh Dwivedi",
                "Pradhyumna Lavania",
                "Ashutosh Modi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18974v1",
                "http://arxiv.org/pdf/2310.18974v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18970v1",
            "title": "TRIAGE: Characterizing and auditing training data for improved\n  regression",
            "updated": "2023-10-29T10:31:59Z",
            "published": "2023-10-29T10:31:59Z",
            "summary": "Data quality is crucial for robust machine learning algorithms, with the\nrecent interest in data-centric AI emphasizing the importance of training data\ncharacterization. However, current data characterization methods are largely\nfocused on classification settings, with regression settings largely\nunderstudied. To address this, we introduce TRIAGE, a novel data\ncharacterization framework tailored to regression tasks and compatible with a\nbroad class of regressors. TRIAGE utilizes conformal predictive distributions\nto provide a model-agnostic scoring method, the TRIAGE score. We operationalize\nthe score to analyze individual samples' training dynamics and characterize\nsamples as under-, over-, or well-estimated by the model. We show that TRIAGE's\ncharacterization is consistent and highlight its utility to improve performance\nvia data sculpting/filtering, in multiple regression settings. Additionally,\nbeyond sample level, we show TRIAGE enables new approaches to dataset selection\nand feature acquisition. Overall, TRIAGE highlights the value unlocked by data\ncharacterization in real-world regression applications",
            "author": [
                "Nabeel Seedat",
                "Jonathan Crabb\u00e9",
                "Zhaozhi Qian",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18970v1",
                "http://arxiv.org/pdf/2310.18970v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18969v1",
            "title": "Analyzing Vision Transformers for Image Classification in Class\n  Embedding Space",
            "updated": "2023-10-29T10:25:23Z",
            "published": "2023-10-29T10:25:23Z",
            "summary": "Despite the growing use of transformer models in computer vision, a\nmechanistic understanding of these networks is still needed. This work\nintroduces a method to reverse-engineer Vision Transformers trained to solve\nimage classification tasks. Inspired by previous research in NLP, we\ndemonstrate how the inner representations at any level of the hierarchy can be\nprojected onto the learned class embedding space to uncover how these networks\nbuild categorical representations for their predictions. We use our framework\nto show how image tokens develop class-specific representations that depend on\nattention mechanisms and contextual information, and give insights on how\nself-attention and MLP layers differentially contribute to this categorical\ncomposition. We additionally demonstrate that this method (1) can be used to\ndetermine the parts of an image that would be important for detecting the class\nof interest, and (2) exhibits significant advantages over traditional linear\nprobing approaches. Taken together, our results position our proposed framework\nas a powerful tool for mechanistic interpretability and explainability\nresearch.",
            "author": [
                "Martina G. Vilas",
                "Timothy Schauml\u00f6ffel",
                "Gemma Roig"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18969v1",
                "http://arxiv.org/pdf/2310.18969v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18968v1",
            "title": "A hybrid deep learning method for finite-horizon mean-field game\n  problems",
            "updated": "2023-10-29T10:20:58Z",
            "published": "2023-10-29T10:20:58Z",
            "summary": "This paper develops a new deep learning algorithm to solve a class of\nfinite-horizon mean-field games. The proposed hybrid algorithm uses Markov\nchain approximation method combined with a stochastic approximation-based\niterative deep learning algorithm. Under the framework of finite-horizon\nmean-field games, the induced measure and Monte-Carlo algorithm are adopted to\nestablish the iterative mean-field interaction in MCAM and deep learning,\nrespectively. The Markov chain approximation method plays a key role in\nconstructing the iterative algorithm and estimating an initial value of a\nneural network, whereas stochastic approximation is used to find accurate\nparameters in a bounded region. The convergence of the hybrid algorithm is\nproved; two numerical examples are provided to illustrate the results.",
            "author": [
                "Yu Zhang",
                "Zhuo Jin",
                "Jiaqin Wei",
                "George Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18968v1",
                "http://arxiv.org/pdf/2310.18968v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18966v1",
            "title": "Spacecraft Autonomous Decision-Planning for Collision Avoidance: a\n  Reinforcement Learning Approach",
            "updated": "2023-10-29T10:15:33Z",
            "published": "2023-10-29T10:15:33Z",
            "summary": "The space environment around the Earth is becoming increasingly populated by\nboth active spacecraft and space debris. To avoid potential collision events,\nsignificant improvements in Space Situational Awareness (SSA) activities and\nCollision Avoidance (CA) technologies are allowing the tracking and maneuvering\nof spacecraft with increasing accuracy and reliability. However, these\nprocedures still largely involve a high level of human intervention to make the\nnecessary decisions. For an increasingly complex space environment, this\ndecision-making strategy is not likely to be sustainable. Therefore, it is\nimportant to successfully introduce higher levels of automation for key Space\nTraffic Management (STM) processes to ensure the level of reliability needed\nfor navigating a large number of spacecraft. These processes range from\ncollision risk detection to the identification of the appropriate action to\ntake and the execution of avoidance maneuvers. This work proposes an\nimplementation of autonomous CA decision-making capabilities on spacecraft\nbased on Reinforcement Learning (RL) techniques. A novel methodology based on a\nPartially Observable Markov Decision Process (POMDP) framework is developed to\ntrain the Artificial Intelligence (AI) system on board the spacecraft,\nconsidering epistemic and aleatory uncertainties. The proposed framework\nconsiders imperfect monitoring information about the status of the debris in\norbit and allows the AI system to effectively learn stochastic policies to\nperform accurate Collision Avoidance Maneuvers (CAMs). The objective is to\nsuccessfully delegate the decision-making process for autonomously implementing\na CAM to the spacecraft without human intervention. This approach would allow\nfor a faster response in the decision-making process and for highly\ndecentralized operations.",
            "author": [
                "Nicolas Bourriez",
                "Adrien Loizeau",
                "Adam F. Abdin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18966v1",
                "http://arxiv.org/pdf/2310.18966v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18961v3",
            "title": "AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly\n  Detection",
            "updated": "2023-12-03T07:26:16Z",
            "published": "2023-10-29T10:03:49Z",
            "summary": "Zero-shot anomaly detection (ZSAD) requires detection models trained using\nauxiliary data to detect anomalies without any training sample in a target\ndataset. It is a crucial task when training data is not accessible due to\nvarious concerns, \\eg, data privacy, yet it is challenging since the models\nneed to generalize to anomalies across different domains where the appearance\nof foreground objects, abnormal regions, and background features, such as\ndefects/tumors on different products/organs, can vary significantly. Recently\nlarge pre-trained vision-language models (VLMs), such as CLIP, have\ndemonstrated strong zero-shot recognition ability in various vision tasks,\nincluding anomaly detection. However, their ZSAD performance is weak since the\nVLMs focus more on modeling the class semantics of the foreground objects\nrather than the abnormality/normality in the images. In this paper we introduce\na novel approach, namely AnomalyCLIP, to adapt CLIP for accurate ZSAD across\ndifferent domains. The key insight of AnomalyCLIP is to learn object-agnostic\ntext prompts that capture generic normality and abnormality in an image\nregardless of its foreground objects. This allows our model to focus on the\nabnormal image regions rather than the object semantics, enabling generalized\nnormality and abnormality recognition on diverse types of objects. Large-scale\nexperiments on 17 real-world anomaly detection datasets show that AnomalyCLIP\nachieves superior zero-shot performance of detecting and segmenting anomalies\nin datasets of highly diverse class semantics from various defect inspection\nand medical imaging domains. Code will be made available at\nhttps://github.com/zqhang/AnomalyCLIP.",
            "author": [
                "Qihang Zhou",
                "Guansong Pang",
                "Yu Tian",
                "Shibo He",
                "Jiming Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18961v3",
                "http://arxiv.org/pdf/2310.18961v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18956v1",
            "title": "End-to-End Autoregressive Retrieval via Bootstrapping for Smart Reply\n  Systems",
            "updated": "2023-10-29T09:56:17Z",
            "published": "2023-10-29T09:56:17Z",
            "summary": "Reply suggestion systems represent a staple component of many instant\nmessaging and email systems. However, the requirement to produce sets of\nreplies, rather than individual replies, makes the task poorly suited for\nout-of-the-box retrieval architectures, which only consider individual\nmessage-reply similarity. As a result, these system often rely on additional\npost-processing modules to diversify the outputs. However, these approaches are\nultimately bottlenecked by the performance of the initial retriever, which in\npractice struggles to present a sufficiently diverse range of options to the\ndownstream diversification module, leading to the suggestions being less\nrelevant to the user. In this paper, we consider a novel approach that\nradically simplifies this pipeline through an autoregressive text-to-text\nretrieval model, that learns the smart reply task end-to-end from a dataset of\n(message, reply set) pairs obtained via bootstrapping. Empirical results show\nthis method consistently outperforms a range of state-of-the-art baselines\nacross three datasets, corresponding to a 5.1%-17.9% improvement in relevance,\nand a 0.5%-63.1% improvement in diversity compared to the best baseline\napproach. We make our code publicly available.",
            "author": [
                "Benjamin Towle",
                "Ke Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18956v1",
                "http://arxiv.org/pdf/2310.18956v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18955v1",
            "title": "Playing in the Dark: No-regret Learning with Adversarial Constraints",
            "updated": "2023-10-29T09:55:41Z",
            "published": "2023-10-29T09:55:41Z",
            "summary": "We study a generalization of the classic Online Convex Optimization (OCO)\nframework by considering additional long-term adversarial constraints.\nSpecifically, after an online policy decides its action on a round, in addition\nto a convex cost function, the adversary also reveals a set of $k$ convex\nconstraints. The cost and the constraint functions could change arbitrarily\nwith time, and no information about the future functions is assumed to be\navailable. In this paper, we propose a meta-policy that simultaneously achieves\na sublinear cumulative constraint violation and a sublinear regret. This is\nachieved via a black box reduction of the constrained problem to the standard\nOCO problem for a recursively constructed sequence of surrogate cost functions.\nWe show that optimal performance bounds can be achieved by solving the\nsurrogate problem using any adaptive OCO policy enjoying a standard\ndata-dependent regret bound. A new Lyapunov-based proof technique is presented\nthat reveals a connection between regret and certain sequential inequalities\nthrough a novel decomposition result. We conclude the paper by highlighting\napplications to online multi-task learning and network control problems.",
            "author": [
                "Abhishek Sinha",
                "Rahul Vaze"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18955v1",
                "http://arxiv.org/pdf/2310.18955v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18954v1",
            "title": "Mask Propagation for Efficient Video Semantic Segmentation",
            "updated": "2023-10-29T09:55:28Z",
            "published": "2023-10-29T09:55:28Z",
            "summary": "Video Semantic Segmentation (VSS) involves assigning a semantic label to each\npixel in a video sequence. Prior work in this field has demonstrated promising\nresults by extending image semantic segmentation models to exploit temporal\nrelationships across video frames; however, these approaches often incur\nsignificant computational costs. In this paper, we propose an efficient mask\npropagation framework for VSS, called MPVSS. Our approach first employs a\nstrong query-based image segmentor on sparse key frames to generate accurate\nbinary masks and class predictions. We then design a flow estimation module\nutilizing the learned queries to generate a set of segment-aware flow maps,\neach associated with a mask prediction from the key frame. Finally, the\nmask-flow pairs are warped to serve as the mask predictions for the non-key\nframes. By reusing predictions from key frames, we circumvent the need to\nprocess a large volume of video frames individually with resource-intensive\nsegmentors, alleviating temporal redundancy and significantly reducing\ncomputational costs. Extensive experiments on VSPW and Cityscapes demonstrate\nthat our mask propagation framework achieves SOTA accuracy and efficiency\ntrade-offs. For instance, our best model with Swin-L backbone outperforms the\nSOTA MRCFA using MiT-B5 by 4.0% mIoU, requiring only 26% FLOPs on the VSPW\ndataset. Moreover, our framework reduces up to 4x FLOPs compared to the\nper-frame Mask2Former baseline with only up to 2% mIoU degradation on the\nCityscapes validation set. Code is available at\nhttps://github.com/ziplab/MPVSS.",
            "author": [
                "Yuetian Weng",
                "Mingfei Han",
                "Haoyu He",
                "Mingjie Li",
                "Lina Yao",
                "Xiaojun Chang",
                "Bohan Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18954v1",
                "http://arxiv.org/pdf/2310.18954v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18953v1",
            "title": "TIC-TAC: A Framework To Learn And Evaluate Your Covariance",
            "updated": "2023-10-29T09:54:03Z",
            "published": "2023-10-29T09:54:03Z",
            "summary": "We study the problem of unsupervised heteroscedastic covariance estimation,\nwhere the goal is to learn the multivariate target distribution $\\mathcal{N}(y,\n\\Sigma_y | x )$ given an observation $x$. This problem is particularly\nchallenging as $\\Sigma_{y}$ varies for different samples (heteroscedastic) and\nno annotation for the covariance is available (unsupervised). Typically,\nstate-of-the-art methods predict the mean $f_{\\theta}(x)$ and covariance\n$\\textrm{Cov}(f_{\\theta}(x))$ of the target distribution through two neural\nnetworks trained using the negative log-likelihood. This raises two questions:\n(1) Does the predicted covariance truly capture the randomness of the predicted\nmean? (2) In the absence of ground-truth annotation, how can we quantify the\nperformance of covariance estimation? We address (1) by deriving TIC: Taylor\nInduced Covariance, which captures the randomness of the multivariate\n$f_{\\theta}(x)$ by incorporating its gradient and curvature around $x$ through\nthe second order Taylor polynomial. Furthermore, we tackle (2) by introducing\nTAC: Task Agnostic Correlations, a metric which leverages conditioning of the\nnormal distribution to evaluate the covariance. We verify the effectiveness of\nTIC through multiple experiments spanning synthetic (univariate, multivariate)\nand real-world datasets (UCI Regression, LSP, and MPII Human Pose Estimation).\nOur experiments show that TIC outperforms state-of-the-art in accurately\nlearning the covariance, as quantified through TAC.",
            "author": [
                "Megh Shukla",
                "Mathieu Salzmann",
                "Alexandre Alahi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18953v1",
                "http://arxiv.org/pdf/2310.18953v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18949v1",
            "title": "Customize StyleGAN with One Hand Sketch",
            "updated": "2023-10-29T09:32:33Z",
            "published": "2023-10-29T09:32:33Z",
            "summary": "Generating images from human sketches typically requires dedicated networks\ntrained from scratch. In contrast, the emergence of the pre-trained\nVision-Language models (e.g., CLIP) has propelled generative applications based\non controlling the output imagery of existing StyleGAN models with text inputs\nor reference images. Parallelly, our work proposes a framework to control\nStyleGAN imagery with a single user sketch. In particular, we learn a\nconditional distribution in the latent space of a pre-trained StyleGAN model\nvia energy-based learning and propose two novel energy functions leveraging\nCLIP for cross-domain semantic supervision. Once trained, our model can\ngenerate multi-modal images semantically aligned with the input sketch.\nQuantitative evaluations on synthesized datasets have shown that our approach\nimproves significantly from previous methods in the one-shot regime. The\nsuperiority of our method is further underscored when experimenting with a wide\nrange of human sketches of diverse styles and poses. Surprisingly, our models\noutperform the previous baseline regarding both the range of sketch inputs and\nimage qualities despite operating with a stricter setting: with no extra\ntraining data and single sketch input.",
            "author": [
                "Shaocong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18949v1",
                "http://arxiv.org/pdf/2310.18949v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18948v2",
            "title": "Building a Safer Maritime Environment Through Multi-Path Long-Term\n  Vessel Trajectory Forecasting",
            "updated": "2023-11-18T10:51:15Z",
            "published": "2023-10-29T09:15:22Z",
            "summary": "Maritime transportation is paramount in achieving global economic growth,\nentailing concurrent ecological obligations in sustainability and safeguarding\nendangered marine species, most notably preserving large whale populations. In\nthis regard, the Automatic Identification System (AIS) data plays a significant\nrole by offering real-time streaming data on vessel movement, allowing enhanced\ntraffic monitoring. This study explores using AIS data to prevent\nvessel-to-whale collisions by forecasting long-term vessel trajectories from\nengineered AIS data sequences. For such a task, we have developed an\nencoder-decoder model architecture using Bidirectional Long Short-Term Memory\nNetworks (Bi-LSTM) to predict the next 12 hours of vessel trajectories using 1\nto 3 hours of AIS data as input. We feed the model with probabilistic features\nengineered from historical AIS data that refer to each trajectory's potential\nroute and destination. The model then predicts the vessel's trajectory,\nconsidering these additional features by leveraging convolutional layers for\nspatial feature learning and a position-aware attention mechanism that\nincreases the importance of recent timesteps of a sequence during temporal\nfeature learning. The probabilistic features have an F1 Score of approximately\n85% and 75% for each feature type, respectively, demonstrating their\neffectiveness in augmenting information to the neural network. We test our\nmodel on the Gulf of St. Lawrence, a region known to be the habitat of North\nAtlantic Right Whales (NARW). Our model achieved a high R2 score of over 98%\nusing various techniques and features. It stands out among other approaches as\nit can make complex decisions during turnings and path selection. Our study\nhighlights the potential of data engineering and trajectory forecasting models\nfor marine life species preservation.",
            "author": [
                "Gabriel Spadon",
                "Jay Kumar",
                "Matthew Smith",
                "Sarah Vela",
                "Romina Gehrmann",
                "Derek Eden",
                "Joshua van Berkel",
                "Amilcar Soares",
                "Ronan Fablet",
                "Ronald Pelot",
                "Stan Matwin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18948v2",
                "http://arxiv.org/pdf/2310.18948v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DM",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18940v2",
            "title": "Language Agents with Reinforcement Learning for Strategic Play in the\n  Werewolf Game",
            "updated": "2023-12-04T07:34:35Z",
            "published": "2023-10-29T09:02:57Z",
            "summary": "Agents built with large language models (LLMs) have recently achieved great\nadvancements. However, most of the efforts focus on single-agent or cooperative\nsettings, leaving more general multi-agent environments underexplored. We\npropose a new framework powered by reinforcement learning (RL) to develop\nstrategic language agents, i.e., LLM-based agents with strategic thinking\nability, for a popular language game, Werewolf. Werewolf is a social deduction\ngame with hidden roles that involves both cooperation and competition and\nemphasizes deceptive communication and diverse gameplay. Our agent tackles this\ngame by first using LLMs to reason about potential deceptions and generate a\nset of strategically diverse actions. Then an RL policy, which selects an\naction from the candidates, is learned by population-based training to enhance\nthe agents' decision-making ability. By combining LLMs with the RL policy, our\nagent produces a variety of emergent strategies, achieves the highest win rate\nagainst other LLM-based agents, and stays robust against adversarial human\nplayers in the Werewolf game.",
            "author": [
                "Zelai Xu",
                "Chao Yu",
                "Fei Fang",
                "Yu Wang",
                "Yi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18940v2",
                "http://arxiv.org/pdf/2310.18940v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18938v1",
            "title": "Machine Learning Algorithms to Predict Chess960 Result and Develop\n  Opening Themes",
            "updated": "2023-10-29T08:54:26Z",
            "published": "2023-10-29T08:54:26Z",
            "summary": "This work focuses on the analysis of Chess 960, also known as Fischer Random\nChess, a variant of traditional chess where the starting positions of the\npieces are randomized. The study aims to predict the game outcome using machine\nlearning techniques and develop an opening theme for each starting position.\nThe first part of the analysis utilizes machine learning models to predict the\ngame result based on certain moves in each position. The methodology involves\nsegregating raw data from .pgn files into usable formats and creating datasets\ncomprising approximately 500 games for each starting position. Three machine\nlearning algorithms -- KNN Clustering, Random Forest, and Gradient Boosted\nTrees -- have been used to predict the game outcome. To establish an opening\ntheme, the board is divided into five regions: center, white kingside, white\nqueenside, black kingside, and black queenside. The data from games played by\ntop engines in all 960 positions is used to track the movement of pieces in the\nopening. By analysing the change in the number of pieces in each region at\nspecific moves, the report predicts the region towards which the game is\ndeveloping. These models provide valuable insights into predicting game\noutcomes and understanding the opening theme in Chess 960.",
            "author": [
                "Shreyan Deo",
                "Nishchal Dwivedi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18938v1",
                "http://arxiv.org/pdf/2310.18938v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18937v1",
            "title": "The Utility of \"Even if...\" Semifactual Explanation to Optimise Positive\n  Outcomes",
            "updated": "2023-10-29T08:52:23Z",
            "published": "2023-10-29T08:52:23Z",
            "summary": "When users receive either a positive or negative outcome from an automated\nsystem, Explainable AI (XAI) has almost exclusively focused on how to mutate\nnegative outcomes into positive ones by crossing a decision boundary using\ncounterfactuals (e.g., \\textit{\"If you earn 2k more, we will accept your loan\napplication\"}). Here, we instead focus on \\textit{positive} outcomes, and take\nthe novel step of using XAI to optimise them (e.g., \\textit{\"Even if you wish\nto half your down-payment, we will still accept your loan application\"}).\nExplanations such as these that employ \"even if...\" reasoning, and do not cross\na decision boundary, are known as semifactuals. To instantiate semifactuals in\nthis context, we introduce the concept of \\textit{Gain} (i.e., how much a user\nstands to benefit from the explanation), and consider the first causal\nformalisation of semifactuals. Tests on benchmark datasets show our algorithms\nare better at maximising gain compared to prior work, and that causality is\nimportant in the process. Most importantly however, a user study supports our\nmain hypothesis by showing people find semifactual explanations more useful\nthan counterfactuals when they receive the positive outcome of a loan\nacceptance.",
            "author": [
                "Eoin M. Kenny",
                "Weipeng Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18937v1",
                "http://arxiv.org/pdf/2310.18937v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2310.18936v2",
            "title": "Adversarial Examples Are Not Real Features",
            "updated": "2023-11-20T12:35:55Z",
            "published": "2023-10-29T08:50:27Z",
            "summary": "The existence of adversarial examples has been a mystery for years and\nattracted much interest. A well-known theory by \\citet{ilyas2019adversarial}\nexplains adversarial vulnerability from a data perspective by showing that one\ncan extract non-robust features from adversarial examples and these features\nalone are useful for classification. However, the explanation remains quite\ncounter-intuitive since non-robust features are mostly noise features to\nhumans. In this paper, we re-examine the theory from a larger context by\nincorporating multiple learning paradigms. Notably, we find that contrary to\ntheir good usefulness under supervised learning, non-robust features attain\npoor usefulness when transferred to other self-supervised learning paradigms,\nsuch as contrastive learning, masked image modeling, and diffusion models. It\nreveals that non-robust features are not really as useful as robust or natural\nfeatures that enjoy good transferability between these paradigms. Meanwhile,\nfor robustness, we also show that naturally trained encoders from robust\nfeatures are largely non-robust under AutoAttack. Our cross-paradigm\nexamination suggests that the non-robust features are not really useful but\nmore like paradigm-wise shortcuts, and robust features alone might be\ninsufficient to attain reliable model robustness. Code is available at\n\\url{https://github.com/PKU-ML/AdvNotRealFeatures}.",
            "author": [
                "Ang Li",
                "Yifei Wang",
                "Yiwen Guo",
                "Yisen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18936v2",
                "http://arxiv.org/pdf/2310.18936v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    }
]